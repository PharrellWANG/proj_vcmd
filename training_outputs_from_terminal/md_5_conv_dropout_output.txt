number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:03:42.435129   ***-------> now start reading the testing csv file 17.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py", line 670, in _call_cpp_shape_fn_impl
    status)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py", line 89, in __exit__
    next(self.gen)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 3840 and 256 for 'MatMul' (op: 'MatMul') with input shapes: [?,3840], [256,1000].

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "md_5.0_conv.py", line 75, in <module>
    Y1 = tf.nn.relu(tf.matmul(YY, W1) + B1)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py", line 1855, in matmul
    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py", line 1454, in _mat_mul
    transpose_b=transpose_b, name=name)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 763, in apply_op
    op_def=op_def)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 2397, in create_op
    set_shapes_for_outputs(ret)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1757, in set_shapes_for_outputs
    shapes = shape_func(op)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1707, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py", line 675, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Dimensions must be equal, but are 3840 and 256 for 'MatMul' (op: 'MatMul') with input shapes: [?,3840], [256,1000].
Pharrell-WANGs-MacBook-Pro:proj_vcmd Pharrell_WANG$ 
Pharrell-WANGs-MacBook-Pro:proj_vcmd Pharrell_WANG$ 
Pharrell-WANGs-MacBook-Pro:proj_vcmd Pharrell_WANG$ 
Pharrell-WANGs-MacBook-Pro:proj_vcmd Pharrell_WANG$ 
Pharrell-WANGs-MacBook-Pro:proj_vcmd Pharrell_WANG$ CLEAR

Pharrell-WANGs-MacBook-Pro:proj_vcmd Pharrell_WANG$ python3 md_5.0_conv.py 
2017-05-01 01:05:56.016356 >>>>-------> start reading the training csv file.
duration for reading training csv: 0:00:00.000165
row_count of the training csv file: 972582
duration for row counting of training csv: 0:00:24.341729
number of labels : 972582
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (972582, 37)
2017-05-01 01:07:42.316115   ***-------> now end reading the training csv file.
duration for loading_csv_without_header: 0:01:21.957865
2017-05-01 01:07:42.316182   ***-------> now start reading the testing csv file 1.
number of labels : 74000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (74000, 37)
2017-05-01 01:07:49.813857   ***-------> now start reading the testing csv file 2.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:07:50.008143   ***-------> now start reading the testing csv file 3.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:07:50.220792   ***-------> now start reading the testing csv file 4.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:07:50.449939   ***-------> now start reading the testing csv file 5.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:07:50.664728   ***-------> now start reading the testing csv file 6.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:07:50.892002   ***-------> now start reading the testing csv file 7.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:07:51.116049   ***-------> now start reading the testing csv file 8.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:07:51.333816   ***-------> now start reading the testing csv file 9.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:07:51.562946   ***-------> now start reading the testing csv file 10.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:07:51.776688   ***-------> now start reading the testing csv file 11.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:07:51.967907   ***-------> now start reading the testing csv file 12.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:07:52.163165   ***-------> now start reading the testing csv file 13.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:07:52.360595   ***-------> now start reading the testing csv file 14.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:07:52.555061   ***-------> now start reading the testing csv file 15.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:07:52.773338   ***-------> now start reading the testing csv file 16.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 01:07:52.997830   ***-------> now start reading the testing csv file 17.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
======------------>>>>>>>    972582
0: accuracy:0.0 loss: 1179.1 (lr:0.005)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
0: ********* epoch 1 ********* test accuracy for all:0.0270405 test loss: 1636.6
0: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 1355.03
0: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 227.835
0: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 1328.0
0: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 2519.62
0: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 2623.49
0: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 341.068
0: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 1457.44
0: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 2325.8
0: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 1052.53
0: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 1866.83
0: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 2472.69
0: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 2004.59
0: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 3071.95
0: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 1681.66
0: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 1745.79
0: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 1463.49
10: accuracy:0.32 loss: 323.51 (lr:0.004975561148044144)
20: accuracy:0.24 loss: 313.957 (lr:0.004951244185370924)
30: accuracy:0.32 loss: 320.325 (lr:0.004927048504055007)
40: accuracy:0.23 loss: 334.954 (lr:0.0049029734992031004)
50: accuracy:0.41 loss: 301.051 (lr:0.00487901856893883)
60: accuracy:0.34 loss: 294.371 (lr:0.00485518311438769)
70: accuracy:0.46 loss: 241.21 (lr:0.004831466539662076)
80: accuracy:0.29 loss: 315.906 (lr:0.004807868251846384)
90: accuracy:0.32 loss: 305.117 (lr:0.00478438766098219)
100: accuracy:0.32 loss: 266.532 (lr:0.004761024180053499)
110: accuracy:0.31 loss: 319.954 (lr:0.004737777224972071)
120: accuracy:0.51 loss: 238.704 (lr:0.004714646214562819)
130: accuracy:0.03 loss: 295.644 (lr:0.004691630570549277)
140: accuracy:0.05 loss: 248.853 (lr:0.004668729717539147)
150: accuracy:0.07 loss: 230.156 (lr:0.004645943083009909)
160: accuracy:0.0 loss: 296.293 (lr:0.004623270097294515)
170: accuracy:0.29 loss: 277.28 (lr:0.0046007101935671415)
180: accuracy:0.46 loss: 307.573 (lr:0.0045782628078290186)
190: accuracy:0.44 loss: 282.459 (lr:0.004555927378894334)
200: accuracy:0.4 loss: 316.685 (lr:0.004533703348376202)
210: accuracy:0.0 loss: 345.603 (lr:0.004511590160672702)
220: accuracy:0.84 loss: 108.149 (lr:0.004489587262952988)
230: accuracy:0.7 loss: 214.34 (lr:0.004467694105143473)
240: accuracy:0.65 loss: 198.95 (lr:0.004445910139914072)
250: accuracy:0.0 loss: 313.556 (lr:0.004424234822664518)
260: accuracy:0.0 loss: 318.064 (lr:0.004402667611510751)
270: accuracy:0.31 loss: 312.479 (lr:0.004381207967271369)
280: accuracy:0.3 loss: 270.515 (lr:0.004359855353454149)
290: accuracy:0.37 loss: 315.341 (lr:0.0043386092362426324)
300: accuracy:0.39 loss: 292.088 (lr:0.004317469084482784)
310: accuracy:0.22 loss: 288.8 (lr:0.004296434369669706)
320: accuracy:0.25 loss: 343.453 (lr:0.004275504565934436)
330: accuracy:0.31 loss: 317.147 (lr:0.004254679150030788)
340: accuracy:0.29 loss: 249.982 (lr:0.00423395760132228)
350: accuracy:0.44 loss: 284.998 (lr:0.004213339401769116)
360: accuracy:0.03 loss: 301.505 (lr:0.004192824035915233)
370: accuracy:0.1 loss: 221.813 (lr:0.004172410990875416)
380: accuracy:0.57 loss: 217.198 (lr:0.004152099756322475)
390: accuracy:0.0 loss: 314.476 (lr:0.00413188982447449)
400: accuracy:0.35 loss: 309.793 (lr:0.004111780690082111)
410: accuracy:0.39 loss: 313.855 (lr:0.004091771850415931)
420: accuracy:0.03 loss: 196.603 (lr:0.004071862805253917)
430: accuracy:0.28 loss: 277.603 (lr:0.004052053056868902)
440: accuracy:0.0 loss: 257.4 (lr:0.004032342110016145)
450: accuracy:0.59 loss: 214.062 (lr:0.004012729471920948)
460: accuracy:0.68 loss: 160.987 (lr:0.003993214652266337)
470: accuracy:0.9 loss: 99.7171 (lr:0.003973797163180804)
480: accuracy:0.38 loss: 319.259 (lr:0.003954476519226112)
490: accuracy:0.41 loss: 284.156 (lr:0.003935252237385153)
500: accuracy:0.0 loss: 303.274 (lr:0.003916123837049884)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
500: ********* epoch 1 ********* test accuracy for all:0.027027 test loss: 426.294
500: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 147.35
500: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 324.114
500: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 450.5
500: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 402.556
500: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 422.335
500: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 346.56
500: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 452.392
500: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 407.911
500: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 417.025
500: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 430.139
500: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 452.742
500: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 441.187
500: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 456.787
500: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 455.764
500: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 337.299
500: ********* epoch 1 ********* test accuracy for mode 36:1.0 test loss: 116.463
510: accuracy:0.65 loss: 194.618 (lr:0.0038970908400092967)
520: accuracy:0.75 loss: 191.253 (lr:0.0038781527704374744)
530: accuracy:0.0 loss: 277.999 (lr:0.0038593091548816925)
540: accuracy:0.56 loss: 209.352 (lr:0.00384055952225058)
550: accuracy:0.64 loss: 183.506 (lr:0.003821903403802345)
560: accuracy:0.65 loss: 181.912 (lr:0.0038033403331330547)
570: accuracy:0.0 loss: 363.897 (lr:0.0037848698461649746)
580: accuracy:0.0 loss: 367.849 (lr:0.0037664914811349694)
590: accuracy:0.36 loss: 309.614 (lr:0.0037482047785829557)
600: accuracy:0.33 loss: 274.816 (lr:0.0037300092813404174)
610: accuracy:0.54 loss: 270.029 (lr:0.0037119045345189758)
620: accuracy:0.27 loss: 311.481 (lr:0.003693890085499017)
630: accuracy:0.36 loss: 237.333 (lr:0.0036759654839183782)
640: accuracy:0.5 loss: 269.915 (lr:0.0036581302816610854)
650: accuracy:0.31 loss: 309.463 (lr:0.0036403840328461537)
660: accuracy:0.29 loss: 280.834 (lr:0.003622726293816438)
670: accuracy:0.21 loss: 310.345 (lr:0.0036051566231275435)
680: accuracy:0.32 loss: 306.766 (lr:0.003587674581536787)
690: accuracy:0.0 loss: 199.866 (lr:0.00357027973199222)
700: accuracy:0.28 loss: 335.193 (lr:0.0035529716396216957)
710: accuracy:0.87 loss: 128.087 (lr:0.003535749871722005)
720: accuracy:0.87 loss: 154.574 (lr:0.0035186139977480516)
730: accuracy:0.98 loss: 105.658 (lr:0.0035015635893020963)
740: accuracy:0.0 loss: 341.803 (lr:0.0034845982201230376)
750: accuracy:0.0 loss: 313.937 (lr:0.003467717466075764)
760: accuracy:0.3 loss: 302.703 (lr:0.0034509209051405434)
770: accuracy:0.06 loss: 249.975 (lr:0.0034342081174024795)
780: accuracy:0.0 loss: 321.204 (lr:0.0034175786850410067)
790: accuracy:0.79 loss: 174.952 (lr:0.003401032192319451)
800: accuracy:0.0 loss: 322.138 (lr:0.0033845682255746324)
810: accuracy:0.88 loss: 154.494 (lr:0.0033681863732065243)
820: accuracy:0.0 loss: 338.454 (lr:0.003351886225667965)
830: accuracy:0.87 loss: 127.073 (lr:0.003335667375454416)
840: accuracy:0.74 loss: 150.788 (lr:0.003319529417093778)
850: accuracy:0.89 loss: 91.57 (lr:0.0033034719471362515)
860: accuracy:0.0 loss: 323.53 (lr:0.0032874945641442506)
870: accuracy:0.0 loss: 312.211 (lr:0.0032715968686823694)
880: accuracy:0.0 loss: 340.319 (lr:0.0032557784633073924)
890: accuracy:0.67 loss: 214.104 (lr:0.0032400389525583614)
900: accuracy:0.0 loss: 332.488 (lr:0.003224377942946689)
910: accuracy:0.58 loss: 215.465 (lr:0.003208795042946318)
920: accuracy:0.0 loss: 294.99 (lr:0.0031932898629839367)
930: accuracy:0.1 loss: 209.618 (lr:0.0031778620154292395)
940: accuracy:0.07 loss: 305.21 (lr:0.0031625111145852335)
950: accuracy:0.75 loss: 163.234 (lr:0.0031472367766785985)
960: accuracy:0.93 loss: 92.8626 (lr:0.00313203861985009)
970: accuracy:0.64 loss: 176.906 (lr:0.003116916264144997)
980: accuracy:0.0 loss: 395.979 (lr:0.0031018693315036385)
990: accuracy:0.0 loss: 336.015 (lr:0.003086897445751915)
1000: accuracy:0.0 loss: 322.212 (lr:0.0030720002325919037)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
1000: ********* epoch 1 ********* test accuracy for all:0.027027 test loss: 423.216
1000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 161.534
1000: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 308.498
1000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 452.249
1000: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 419.567
1000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 435.164
1000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 356.65
1000: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 433.554
1000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 403.64
1000: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 417.245
1000: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 442.715
1000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 434.368
1000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 472.829
1000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 480.682
1000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 485.4
1000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 356.237
1000: ********* epoch 1 ********* test accuracy for mode 36:1.0 test loss: 111.761
1010: accuracy:0.07 loss: 297.809 (lr:0.003057177319592498)
1020: accuracy:0.01 loss: 292.669 (lr:0.0030424283361801027)
1030: accuracy:0.0 loss: 369.951 (lr:0.0030277529136293634)
1040: accuracy:0.18 loss: 331.706 (lr:0.0030131506850539524)
1050: accuracy:0.05 loss: 366.973 (lr:0.0029986212853973936)
1060: accuracy:0.13 loss: 313.557 (lr:0.00298416435142394)
1070: accuracy:0.01 loss: 299.039 (lr:0.002969779521709489)
1080: accuracy:0.0 loss: 371.755 (lr:0.002955466436632549)
1090: accuracy:0.0 loss: 378.157 (lr:0.002941224738365247)
1100: accuracy:0.5 loss: 309.526 (lr:0.0029270540708643844)
1110: accuracy:0.04 loss: 361.829 (lr:0.002912954079862536)
1120: accuracy:0.0 loss: 360.277 (lr:0.002898924412859193)
1130: accuracy:0.0 loss: 358.864 (lr:0.0028849647191119482)
1140: accuracy:0.28 loss: 335.607 (lr:0.0028710746496277313)
1150: accuracy:0.0 loss: 350.168 (lr:0.0028572538571540827)
1160: accuracy:0.08 loss: 332.058 (lr:0.00284350199617047)
1170: accuracy:0.06 loss: 354.719 (lr:0.002829818722879652)
1180: accuracy:0.0 loss: 373.953 (lr:0.0028162036951990847)
1190: accuracy:0.0 loss: 349.649 (lr:0.0028026565727523657)
1200: accuracy:0.21 loss: 332.018 (lr:0.0027891770168607297)
1210: accuracy:0.0 loss: 357.714 (lr:0.0027757646905345757)
1220: accuracy:0.02 loss: 358.691 (lr:0.0027624192584650487)
1230: accuracy:0.07 loss: 315.305 (lr:0.002749140387015651)
1240: accuracy:0.08 loss: 351.609 (lr:0.0027359277442139045)
1250: accuracy:0.1 loss: 312.167 (lr:0.002722780999743052)
1260: accuracy:0.0 loss: 373.726 (lr:0.002709699824933796)
1270: accuracy:0.23 loss: 311.14 (lr:0.0026966838927560857)
1280: accuracy:0.0 loss: 357.697 (lr:0.0026837328778109375)
1290: accuracy:0.25 loss: 323.01 (lr:0.002670846456322305)
1300: accuracy:0.0 loss: 347.181 (lr:0.0026580243061289782)
1310: accuracy:0.06 loss: 361.562 (lr:0.002645266106676536)
1320: accuracy:0.08 loss: 351.411 (lr:0.0026325715390093257)
1330: accuracy:0.0 loss: 359.147 (lr:0.002619940285762496)
1340: accuracy:0.0 loss: 352.939 (lr:0.002607372031154058)
1350: accuracy:0.0 loss: 363.271 (lr:0.002594866460976991)
1360: accuracy:0.07 loss: 349.102 (lr:0.0025824232625913887)
1370: accuracy:0.03 loss: 355.63 (lr:0.002570042124916645)
1380: accuracy:0.03 loss: 360.128 (lr:0.002557722738423672)
1390: accuracy:0.08 loss: 352.615 (lr:0.0025454647951271663)
1400: accuracy:0.06 loss: 340.012 (lr:0.0025332679885779062)
1410: accuracy:0.0 loss: 346.878 (lr:0.002521132013855094)
1420: accuracy:0.11 loss: 344.99 (lr:0.0025090565675587287)
1430: accuracy:0.07 loss: 316.102 (lr:0.0024970413478020244)
1440: accuracy:0.05 loss: 353.997 (lr:0.002485086054203861)
1450: accuracy:0.15 loss: 336.274 (lr:0.002473190387881276)
1460: accuracy:0.05 loss: 354.929 (lr:0.0024613540514419915)
1470: accuracy:0.12 loss: 338.11 (lr:0.002449576748976981)
1480: accuracy:0.3 loss: 315.47 (lr:0.002437858186053068)
1490: accuracy:0.02 loss: 360.978 (lr:0.0024261980697055704)
1500: accuracy:0.0 loss: 355.109 (lr:0.002414596108430972)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
1500: ********* epoch 1 ********* test accuracy for all:0.027027 test loss: 377.289
1500: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 608.981
1500: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 243.69
1500: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 404.908
1500: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 340.11
1500: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 361.266
1500: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 274.488
1500: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 382.74
1500: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 343.615
1500: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 344.059
1500: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 368.775
1500: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 373.983
1500: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 374.13
1500: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 386.034
1500: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 376.77
1500: ********* epoch 1 ********* test accuracy for mode 35:1.0 test loss: 242.634
1500: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 548.749
1510: accuracy:0.07 loss: 346.894 (lr:0.002403052012179636)
1520: accuracy:0.09 loss: 358.24 (lr:0.002391565492348555)
1530: accuracy:0.07 loss: 358.618 (lr:0.0023801362617741355)
1540: accuracy:0.01 loss: 366.264 (lr:0.0023687640347250173)
1550: accuracy:0.0 loss: 356.701 (lr:0.002357448526894932)
1560: accuracy:0.0 loss: 363.921 (lr:0.002346189455395595)
1570: accuracy:0.0 loss: 357.316 (lr:0.002334986538749632)
1580: accuracy:0.0 loss: 363.391 (lr:0.0023238394968835433)
1590: accuracy:0.09 loss: 348.043 (lr:0.0023127480511207017)
1600: accuracy:0.0 loss: 343.925 (lr:0.0023017119241743856)
1610: accuracy:0.1 loss: 353.982 (lr:0.002290730840140846)
1620: accuracy:0.09 loss: 355.742 (lr:0.002279804524492411)
1630: accuracy:0.14 loss: 291.814 (lr:0.0022689327040706204)
1640: accuracy:0.09 loss: 357.729 (lr:0.0022581151070793963)
1650: accuracy:0.12 loss: 291.806 (lr:0.002247351463078251)
1660: accuracy:0.0 loss: 354.412 (lr:0.0022366415029755242)
1670: accuracy:0.07 loss: 354.192 (lr:0.0022259849590216554)
1680: accuracy:0.0 loss: 345.116 (lr:0.0022153815648024906)
1690: accuracy:0.05 loss: 362.956 (lr:0.0022048310552326214)
1700: accuracy:0.0 loss: 358.515 (lr:0.0021943331665487606)
1710: accuracy:0.0 loss: 365.122 (lr:0.0021838876363031432)
1720: accuracy:0.2 loss: 336.67 (lr:0.002173494203356969)
1730: accuracy:0.0 loss: 349.774 (lr:0.0021631526078738734)
1740: accuracy:0.07 loss: 360.694 (lr:0.0021528625913134307)
1750: accuracy:0.05 loss: 346.635 (lr:0.0021426238964246907)
1760: accuracy:0.08 loss: 352.758 (lr:0.0021324362672397487)
1770: accuracy:0.0 loss: 348.212 (lr:0.0021222994490673434)
1780: accuracy:0.3 loss: 330.351 (lr:0.002112213188486493)
1790: accuracy:0.06 loss: 299.416 (lr:0.0021021772333401573)
1800: accuracy:0.09 loss: 352.884 (lr:0.0020921913327289353)
1810: accuracy:0.08 loss: 312.787 (lr:0.002082255237004792)
1820: accuracy:0.11 loss: 354.885 (lr:0.002072368697764816)
1830: accuracy:0.16 loss: 307.219 (lr:0.0020625314678450117)
1840: accuracy:0.2 loss: 329.047 (lr:0.002052743301314119)
1850: accuracy:0.0 loss: 333.203 (lr:0.002043003953467465)
1860: accuracy:0.05 loss: 325.583 (lr:0.002033313180820845)
1870: accuracy:0.1 loss: 357.63 (lr:0.00202367074110444)
1880: accuracy:0.17 loss: 337.414 (lr:0.0020140763932567536)
1890: accuracy:0.03 loss: 348.225 (lr:0.0020045298974185896)
1900: accuracy:0.21 loss: 336.114 (lr:0.001995031014927056)
1910: accuracy:0.05 loss: 349.268 (lr:0.001985579508309595)
1920: accuracy:0.09 loss: 354.306 (lr:0.001976175141278049)
1930: accuracy:0.14 loss: 346.872 (lr:0.0019668176787227525)
1940: accuracy:0.07 loss: 353.814 (lr:0.001957506886706654)
1950: accuracy:0.23 loss: 338.589 (lr:0.001948242532459469)
1960: accuracy:0.29 loss: 321.571 (lr:0.0019390243843718578)
1970: accuracy:0.09 loss: 295.875 (lr:0.0019298522119896384)
1980: accuracy:0.08 loss: 356.843 (lr:0.001920725786008024)
1990: accuracy:0.15 loss: 304.72 (lr:0.001911644878265889)
2000: accuracy:0.1 loss: 353.851 (lr:0.0019026092617400673)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
2000: ********* epoch 1 ********* test accuracy for all:0.027027 test loss: 392.356
2000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 824.531
2000: ********* epoch 1 ********* test accuracy for mode 1:1.0 test loss: 212.452
2000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 386.196
2000: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 378.965
2000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 384.673
2000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 273.847
2000: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 392.927
2000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 351.905
2000: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 345.98
2000: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 357.104
2000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 383.323
2000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 376.892
2000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 400.832
2000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 391.958
2000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 234.051
2000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 776.663
2010: accuracy:0.08 loss: 345.675 (lr:0.0018936187105396754)
2020: accuracy:0.08 loss: 361.165 (lr:0.0018846729999004643)
2030: accuracy:0.16 loss: 353.404 (lr:0.0018757719061792029)
2040: accuracy:0.1 loss: 352.455 (lr:0.0018669152068480836)
2050: accuracy:0.09 loss: 353.866 (lr:0.001858102680489163)
2060: accuracy:0.07 loss: 327.454 (lr:0.0018493341067888221)
2070: accuracy:0.08 loss: 341.848 (lr:0.0018406092665322624)
2080: accuracy:0.17 loss: 349.467 (lr:0.0018319279415980228)
2090: accuracy:0.05 loss: 358.287 (lr:0.0018232899149525279)
2100: accuracy:0.08 loss: 350.626 (lr:0.0018146949706446612)
2110: accuracy:0.2 loss: 333.229 (lr:0.0018061428938003683)
2120: accuracy:0.05 loss: 340.136 (lr:0.0017976334706172813)
2130: accuracy:0.18 loss: 344.669 (lr:0.0017891664883593788)
2140: accuracy:0.11 loss: 352.096 (lr:0.0017807417353516626)
2150: accuracy:0.12 loss: 350.777 (lr:0.001772359000974869)
2160: accuracy:0.16 loss: 299.605 (lr:0.0017640180756602016)
2170: accuracy:0.14 loss: 351.811 (lr:0.001755718750884094)
2180: accuracy:0.24 loss: 288.028 (lr:0.001747460819162993)
2190: accuracy:0.06 loss: 351.454 (lr:0.0017392440740481773)
2200: accuracy:0.11 loss: 364.891 (lr:0.0017310683101205897)
2210: accuracy:0.08 loss: 361.085 (lr:0.0017229333229857068)
2220: accuracy:0.08 loss: 309.237 (lr:0.0017148389092684264)
2230: accuracy:0.16 loss: 343.063 (lr:0.001706784866607984)
2240: accuracy:0.04 loss: 345.863 (lr:0.0016987709936528933)
2250: accuracy:0.17 loss: 345.029 (lr:0.0016907970900559136)
2260: accuracy:0.03 loss: 321.134 (lr:0.0016828629564690394)
2270: accuracy:0.09 loss: 349.242 (lr:0.0016749683945385177)
2280: accuracy:0.06 loss: 357.85 (lr:0.0016671132068998894)
2290: accuracy:0.02 loss: 352.353 (lr:0.0016592971971730536)
2300: accuracy:0.21 loss: 342.768 (lr:0.001651520169957361)
2310: accuracy:0.16 loss: 345.601 (lr:0.0016437819308267251)
2320: accuracy:0.12 loss: 351.088 (lr:0.001636082286324766)
2330: accuracy:0.12 loss: 294.876 (lr:0.001628421043959969)
2340: accuracy:0.12 loss: 352.563 (lr:0.0016207980122008767)
2350: accuracy:0.2 loss: 289.606 (lr:0.0016132130004712973)
2360: accuracy:0.04 loss: 328.308 (lr:0.001605665819145543)
2370: accuracy:0.25 loss: 337.496 (lr:0.0015981562795436876)
2380: accuracy:0.13 loss: 351.377 (lr:0.00159068419392685)
2390: accuracy:0.07 loss: 358.291 (lr:0.0015832493754925)
2400: accuracy:0.05 loss: 349.105 (lr:0.0015758516383697905)
2410: accuracy:0.02 loss: 348.906 (lr:0.001568490797614907)
2420: accuracy:0.21 loss: 343.979 (lr:0.0015611666692064482)
2430: accuracy:0.08 loss: 325.917 (lr:0.0015538790700408216)
2440: accuracy:0.06 loss: 324.95 (lr:0.0015466278179276697)
2450: accuracy:0.07 loss: 358.351 (lr:0.0015394127315853105)
2460: accuracy:0.01 loss: 366.152 (lr:0.0015322336306362113)
2470: accuracy:0.16 loss: 348.58 (lr:0.0015250903356024727)
2480: accuracy:0.25 loss: 325.346 (lr:0.001517982667901348)
2490: accuracy:0.03 loss: 302.399 (lr:0.001510910449840774)
2500: accuracy:0.06 loss: 359.14 (lr:0.0015038735046149314)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
2500: ********* epoch 1 ********* test accuracy for all:0.027027 test loss: 390.679
2500: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 848.735
2500: ********* epoch 1 ********* test accuracy for mode 1:1.0 test loss: 218.642
2500: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 392.579
2500: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 342.76
2500: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 382.479
2500: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 292.8
2500: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 388.95
2500: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 334.377
2500: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 359.339
2500: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 371.277
2500: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 378.045
2500: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 370.34
2500: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 385.471
2500: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 376.074
2500: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 253.25
2500: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 798.681
2510: accuracy:0.12 loss: 352.389 (lr:0.0014968716562998225)
2520: accuracy:0.14 loss: 306.565 (lr:0.001489904729848875)
2530: accuracy:0.09 loss: 340.468 (lr:0.0014829725510885645)
2540: accuracy:0.02 loss: 372.271 (lr:0.0014760749467140608)
2550: accuracy:0.24 loss: 328.471 (lr:0.0014692117442848959)
2560: accuracy:0.08 loss: 357.545 (lr:0.0014623827722206513)
2570: accuracy:0.05 loss: 319.598 (lr:0.0014555878597966698)
2580: accuracy:0.07 loss: 338.835 (lr:0.0014488268371397864)
2590: accuracy:0.19 loss: 343.58 (lr:0.0014420995352240834)
2600: accuracy:0.08 loss: 356.868 (lr:0.0014354057858666617)
2610: accuracy:0.06 loss: 356.485 (lr:0.0014287454217234395)
2620: accuracy:0.03 loss: 305.605 (lr:0.0014221182762849654)
2630: accuracy:0.04 loss: 362.016 (lr:0.0014155241838722593)
2640: accuracy:0.26 loss: 338.585 (lr:0.0014089629796326666)
2650: accuracy:0.17 loss: 346.011 (lr:0.0014024344995357404)
2660: accuracy:0.12 loss: 306.275 (lr:0.0013959385803691375)
2670: accuracy:0.09 loss: 356.193 (lr:0.0013894750597345407)
2680: accuracy:0.11 loss: 352.338 (lr:0.0013830437760435973)
2690: accuracy:0.06 loss: 323.223 (lr:0.0013766445685138805)
2700: accuracy:0.09 loss: 357.39 (lr:0.0013702772771648684)
2710: accuracy:0.07 loss: 356.348 (lr:0.0013639417428139458)
2720: accuracy:0.17 loss: 347.073 (lr:0.0013576378070724237)
2730: accuracy:0.02 loss: 296.151 (lr:0.0013513653123415805)
2740: accuracy:0.05 loss: 345.374 (lr:0.0013451241018087212)
2750: accuracy:0.06 loss: 361.849 (lr:0.0013389140194432576)
2760: accuracy:0.04 loss: 359.705 (lr:0.001332734909992807)
2770: accuracy:0.06 loss: 356.163 (lr:0.001326586618979311)
2780: accuracy:0.2 loss: 336.219 (lr:0.0013204689926951743)
2790: accuracy:0.08 loss: 345.831 (lr:0.0013143818781994208)
2800: accuracy:0.15 loss: 329.077 (lr:0.0013083251233138719)
2810: accuracy:0.38 loss: 294.115 (lr:0.001302298576619339)
2820: accuracy:0.44 loss: 274.073 (lr:0.0012963020874518418)
2830: accuracy:0.33 loss: 295.038 (lr:0.0012903355058988379)
2840: accuracy:0.42 loss: 253.262 (lr:0.0012843986827954785)
2850: accuracy:0.22 loss: 296.209 (lr:0.0012784914697208764)
2860: accuracy:0.11 loss: 337.274 (lr:0.0012726137189943974)
2870: accuracy:0.19 loss: 322.574 (lr:0.0012667652836719663)
2880: accuracy:0.07 loss: 308.222 (lr:0.0012609460175423966)
2890: accuracy:0.18 loss: 308.405 (lr:0.0012551557751237312)
2900: accuracy:0.1 loss: 305.122 (lr:0.0012493944116596086)
2910: accuracy:0.0 loss: 330.1 (lr:0.0012436617831156414)
2920: accuracy:0.0 loss: 341.06 (lr:0.0012379577461758182)
2930: accuracy:0.0 loss: 339.051 (lr:0.001232282158238918)
2940: accuracy:0.0 loss: 347.592 (lr:0.0012266348774149468)
2950: accuracy:0.27 loss: 312.276 (lr:0.00122101576252159)
2960: accuracy:0.16 loss: 309.356 (lr:0.0012154246730806824)
2970: accuracy:0.05 loss: 330.333 (lr:0.001209861469314697)
2980: accuracy:0.04 loss: 335.046 (lr:0.0012043260121432497)
2990: accuracy:0.05 loss: 309.354 (lr:0.001198818163179623)
3000: accuracy:0.06 loss: 363.455 (lr:0.0011933377847273062)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
3000: ********* epoch 1 ********* test accuracy for all:0.027027 test loss: 437.266
3000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 1259.42
3000: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 307.561
3000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 412.5
3000: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 418.171
3000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 429.409
3000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 249.642
3000: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 310.144
3000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 393.72
3000: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 465.659
3000: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 483.405
3000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 465.002
3000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 477.679
3000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 479.502
3000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 460.615
3000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 260.303
3000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 1176.65
3010: accuracy:0.12 loss: 334.168 (lr:0.0011878847397765522)
3020: accuracy:0.14 loss: 304.765 (lr:0.001182458892000953)
3030: accuracy:0.04 loss: 304.34 (lr:0.0011770601057540324)
3040: accuracy:0.15 loss: 333.384 (lr:0.0011716882460658523)
3050: accuracy:0.27 loss: 295.893 (lr:0.001166343178639641)
3060: accuracy:0.13 loss: 302.765 (lr:0.0011610247698484347)
3070: accuracy:0.13 loss: 325.33 (lr:0.0011557328867317362)
3080: accuracy:0.07 loss: 352.703 (lr:0.001150467396992192)
3090: accuracy:0.26 loss: 309.587 (lr:0.0011452281689922847)
3100: accuracy:0.23 loss: 306.403 (lr:0.001140015071751041)
3110: accuracy:0.17 loss: 288.684 (lr:0.0011348279749407587)
3120: accuracy:0.13 loss: 298.624 (lr:0.0011296667488837472)
3130: accuracy:0.09 loss: 362.466 (lr:0.0011245312645490864)
3140: accuracy:0.31 loss: 294.218 (lr:0.0011194213935494003)
3150: accuracy:0.24 loss: 302.137 (lr:0.001114337008137648)
3160: accuracy:0.18 loss: 289.337 (lr:0.001109277981203929)
3170: accuracy:0.01 loss: 304.832 (lr:0.001104244186272307)
3180: accuracy:0.06 loss: 302.338 (lr:0.0010992354974976458)
3190: accuracy:0.17 loss: 374.764 (lr:0.001094251789662466)
3200: accuracy:0.07 loss: 348.601 (lr:0.0010892929381738114)
3210: accuracy:0.01 loss: 297.651 (lr:0.0010843588190601373)
3220: accuracy:0.19 loss: 316.483 (lr:0.0010794493089682081)
3230: accuracy:0.12 loss: 287.27 (lr:0.0010745642851600161)
3240: accuracy:0.04 loss: 281.281 (lr:0.0010697036255097117)
3250: accuracy:0.14 loss: 321.33 (lr:0.0010648672085005507)
3260: accuracy:0.05 loss: 327.759 (lr:0.001060054913221856)
3270: accuracy:0.19 loss: 304.841 (lr:0.0010552666193659943)
3280: accuracy:0.09 loss: 328.658 (lr:0.0010505022072253704)
3290: accuracy:0.21 loss: 325.75 (lr:0.0010457615576894325)
3300: accuracy:0.3 loss: 287.394 (lr:0.0010410445522416952)
3310: accuracy:0.1 loss: 329.811 (lr:0.0010363510729567767)
3320: accuracy:0.29 loss: 281.233 (lr:0.0010316810024974506)
3330: accuracy:0.31 loss: 324.698 (lr:0.0010270342241117118)
3340: accuracy:0.28 loss: 291.652 (lr:0.0010224106216298592)
3350: accuracy:0.12 loss: 343.946 (lr:0.0010178100794615893)
3360: accuracy:0.35 loss: 271.33 (lr:0.001013232482593109)
3370: accuracy:0.03 loss: 328.859 (lr:0.0010086777165842574)
3380: accuracy:0.11 loss: 296.794 (lr:0.0010041456675656474)
3390: accuracy:0.01 loss: 303.995 (lr:0.0009996362222358176)
3400: accuracy:0.15 loss: 333.603 (lr:0.0009951492678583998)
3410: accuracy:0.18 loss: 337.53 (lr:0.0009906846922593008)
3420: accuracy:0.16 loss: 333.769 (lr:0.0009862423838238983)
3430: accuracy:0.19 loss: 327.643 (lr:0.0009818222314942496)
3440: accuracy:0.23 loss: 322.739 (lr:0.0009774241247663168)
3450: accuracy:0.14 loss: 336.197 (lr:0.0009730479536872022)
3460: accuracy:0.31 loss: 275.398 (lr:0.0009686936088524013)
3470: accuracy:0.07 loss: 299.129 (lr:0.000964360981403066)
3480: accuracy:0.0 loss: 301.505 (lr:0.0009600499630232846)
3490: accuracy:0.19 loss: 326.409 (lr:0.0009557604459373732)
3500: accuracy:0.16 loss: 318.656 (lr:0.0009514923229071812)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
3500: ********* epoch 1 ********* test accuracy for all:0.027027 test loss: 437.038
3500: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 1302.88
3500: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 473.864
3500: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 391.263
3500: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 398.153
3500: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 344.703
3500: ********* epoch 1 ********* test accuracy for mode 26:1.0 test loss: 201.766
3500: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 280.295
3500: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 338.414
3500: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 448.601
3500: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 479.559
3500: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 481.138
3500: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 470.214
3500: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 485.492
3500: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 439.991
3500: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 347.032
3500: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 1219.23
3510: accuracy:0.21 loss: 280.191 (lr:0.0009472454872294103)
3520: accuracy:0.21 loss: 311.028 (lr:0.0009430198327329476)
3530: accuracy:0.04 loss: 290.268 (lr:0.0009388152537762107)
3540: accuracy:0.08 loss: 308.314 (lr:0.0009346316452445062)
3550: accuracy:0.09 loss: 361.531 (lr:0.0009304689025474036)
3560: accuracy:0.23 loss: 298.373 (lr:0.0009263269216161179)
3570: accuracy:0.06 loss: 322.423 (lr:0.0009222055989009109)
3580: accuracy:0.23 loss: 314.916 (lr:0.0009181048313684994)
3590: accuracy:0.13 loss: 277.295 (lr:0.0009140245164994821)
3600: accuracy:0.0 loss: 338.599 (lr:0.0009099645522857741)
3610: accuracy:0.08 loss: 322.456 (lr:0.000905924837228059)
3620: accuracy:0.38 loss: 282.65 (lr:0.0009019052703332499)
3630: accuracy:0.07 loss: 371.355 (lr:0.0008979057511119651)
3640: accuracy:0.09 loss: 354.999 (lr:0.0008939261795760157)
3650: accuracy:0.25 loss: 317.53 (lr:0.0008899664562359062)
3660: accuracy:0.14 loss: 343.341 (lr:0.0008860264820983464)
3670: accuracy:0.2 loss: 302.994 (lr:0.0008821061586637784)
3680: accuracy:0.29 loss: 301.922 (lr:0.0008782053879239114)
3690: accuracy:0.2 loss: 326.996 (lr:0.0008743240723592742)
3700: accuracy:0.23 loss: 315.74 (lr:0.0008704621149367753)
3710: accuracy:0.0 loss: 351.032 (lr:0.0008666194191072783)
3720: accuracy:0.0 loss: 292.69 (lr:0.0008627958888031868)
3730: accuracy:0.0 loss: 373.119 (lr:0.0008589914284360445)
3740: accuracy:0.0 loss: 362.593 (lr:0.0008552059428941439)
3750: accuracy:0.0 loss: 351.68 (lr:0.0008514393375401495)
3760: accuracy:0.06 loss: 355.435 (lr:0.000847691518208731)
3770: accuracy:0.09 loss: 337.16 (lr:0.0008439623912042099)
3780: accuracy:0.16 loss: 319.104 (lr:0.0008402518632982173)
3790: accuracy:0.19 loss: 301.963 (lr:0.0008365598417273616)
3800: accuracy:0.05 loss: 347.52 (lr:0.0008328862341909118)
3810: accuracy:0.04 loss: 388.835 (lr:0.0008292309488484879)
3820: accuracy:0.15 loss: 319.947 (lr:0.0008255938943177661)
3830: accuracy:0.22 loss: 287.479 (lr:0.0008219749796721935)
3840: accuracy:0.28 loss: 278.756 (lr:0.0008183741144387157)
3850: accuracy:0.09 loss: 293.21 (lr:0.0008147912085955141)
3860: accuracy:0.39 loss: 274.332 (lr:0.0008112261725697563)
3870: accuracy:0.11 loss: 306.394 (lr:0.0008076789172353557)
3880: accuracy:0.03 loss: 319.639 (lr:0.0008041493539107443)
3890: accuracy:0.08 loss: 331.988 (lr:0.0008006373943566552)
3900: accuracy:0.02 loss: 388.108 (lr:0.0007971429507739167)
3910: accuracy:0.2 loss: 276.194 (lr:0.0007936659358012567)
3920: accuracy:0.12 loss: 344.46 (lr:0.0007902062625131205)
3930: accuracy:0.01 loss: 302.035 (lr:0.0007867638444174952)
3940: accuracy:0.29 loss: 280.637 (lr:0.0007833385954537496)
3950: accuracy:0.08 loss: 350.377 (lr:0.0007799304299904807)
3960: accuracy:0.13 loss: 322.357 (lr:0.0007765392628233749)
3970: accuracy:0.22 loss: 317.124 (lr:0.0007731650091730757)
3980: accuracy:0.22 loss: 315.214 (lr:0.0007698075846830669)
3990: accuracy:0.18 loss: 285.908 (lr:0.0007664669054175608)
4000: accuracy:0.06 loss: 282.967 (lr:0.0007631428878594023)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
4000: ********* epoch 1 ********* test accuracy for all:0.027027 test loss: 481.119
4000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 1805.34
4000: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 663.357
4000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 422.69
4000: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 356.138
4000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 266.299
4000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 395.67
4000: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 256.579
4000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 313.7
4000: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 436.686
4000: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 497.285
4000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 495.801
4000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 509.402
4000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 511.891
4000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 459.72
4000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 510.969
4000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 1681.31
4010: accuracy:0.15 loss: 312.598 (lr:0.0007598354489079788)
4020: accuracy:0.06 loss: 337.647 (lr:0.0007565445058771445)
4030: accuracy:0.05 loss: 309.211 (lr:0.0007532699764931518)
4040: accuracy:0.24 loss: 291.789 (lr:0.0007500117788925964)
4050: accuracy:0.21 loss: 308.562 (lr:0.0007467698316203682)
4060: accuracy:0.06 loss: 322.497 (lr:0.0007435440536276163)
4070: accuracy:0.3 loss: 297.469 (lr:0.0007403343642697227)
4080: accuracy:0.08 loss: 324.228 (lr:0.000737140683304287)
4090: accuracy:0.03 loss: 330.783 (lr:0.0007339629308891183)
4100: accuracy:0.04 loss: 289.217 (lr:0.0007308010275802408)
4110: accuracy:0.18 loss: 296.649 (lr:0.0007276548943299068)
4120: accuracy:0.09 loss: 300.431 (lr:0.0007245244524846216)
4130: accuracy:0.36 loss: 270.445 (lr:0.0007214096237831759)
4140: accuracy:0.09 loss: 342.048 (lr:0.00071831033035469)
4150: accuracy:0.17 loss: 288.622 (lr:0.0007152264947166663)
4160: accuracy:0.48 loss: 244.615 (lr:0.0007121580397730538)
4170: accuracy:0.09 loss: 331.907 (lr:0.000709104888812319)
4180: accuracy:0.1 loss: 332.535 (lr:0.0007060669655055287)
4190: accuracy:0.42 loss: 246.381 (lr:0.0007030441939044418)
4200: accuracy:0.21 loss: 290.514 (lr:0.0007000364984396113)
4210: accuracy:0.06 loss: 302.755 (lr:0.0006970438039184938)
4220: accuracy:0.0 loss: 377.562 (lr:0.0006940660355235702)
4230: accuracy:0.27 loss: 319.613 (lr:0.0006911031188104756)
4240: accuracy:0.2 loss: 266.842 (lr:0.000688154979706138)
4250: accuracy:0.21 loss: 312.749 (lr:0.0006852215445069262)
4260: accuracy:0.04 loss: 317.351 (lr:0.0006823027398768074)
4270: accuracy:0.22 loss: 286.655 (lr:0.0006793984928455136)
4280: accuracy:0.35 loss: 274.036 (lr:0.000676508730806718)
4290: accuracy:0.14 loss: 290.811 (lr:0.0006736333815162192)
4300: accuracy:0.32 loss: 278.042 (lr:0.0006707723730901352)
4310: accuracy:0.26 loss: 287.986 (lr:0.0006679256340031061)
4320: accuracy:0.23 loss: 289.465 (lr:0.0006650930930865063)
4330: accuracy:0.08 loss: 311.41 (lr:0.0006622746795266659)
4340: accuracy:0.24 loss: 297.778 (lr:0.0006594703228630989)
4350: accuracy:0.18 loss: 278.896 (lr:0.0006566799529867424)
4360: accuracy:0.0 loss: 325.417 (lr:0.0006539035001382042)
4370: accuracy:0.0 loss: 342.518 (lr:0.000651140894906019)
4380: accuracy:0.0 loss: 296.343 (lr:0.0006483920682249115)
4390: accuracy:0.0 loss: 325.859 (lr:0.0006456569513740718)
4400: accuracy:0.0 loss: 271.825 (lr:0.000642935475975436)
4410: accuracy:0.23 loss: 314.064 (lr:0.0006402275739919776)
4420: accuracy:0.17 loss: 323.186 (lr:0.0006375331777260059)
4430: accuracy:0.06 loss: 317.706 (lr:0.0006348522198174739)
4440: accuracy:0.14 loss: 324.394 (lr:0.000632184633242294)
4450: accuracy:0.08 loss: 293.291 (lr:0.0006295303513106634)
4460: accuracy:0.07 loss: 309.071 (lr:0.0006268893076653953)
4470: accuracy:0.13 loss: 336.808 (lr:0.000624261436280261)
4480: accuracy:0.08 loss: 305.973 (lr:0.0006216466714583388)
4490: accuracy:0.09 loss: 318.486 (lr:0.0006190449478303723)
4500: accuracy:0.14 loss: 316.971 (lr:0.0006164562003531353)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
4500: ********* epoch 1 ********* test accuracy for all:0.027027 test loss: 452.78
4500: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 1592.91
4500: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 639.118
4500: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 401.139
4500: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 298.499
4500: ********* epoch 1 ********* test accuracy for mode 25:1.0 test loss: 236.158
4500: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 462.876
4500: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 246.853
4500: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 306.791
4500: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 384.11
4500: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 432.749
4500: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 451.206
4500: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 469.702
4500: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 469.082
4500: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 433.934
4500: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 520.35
4500: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 1486.95
4510: accuracy:0.11 loss: 307.614 (lr:0.0006138803643078058)
4520: accuracy:0.22 loss: 311.108 (lr:0.0006113173752983487)
4530: accuracy:0.2 loss: 325.538 (lr:0.000608767169249905)
4540: accuracy:0.08 loss: 331.504 (lr:0.000606229682407191)
4550: accuracy:0.0 loss: 315.8 (lr:0.0006037048513329034)
4560: accuracy:0.14 loss: 289.793 (lr:0.0006011926129061337)
4570: accuracy:0.0 loss: 324.103 (lr:0.0005986929043207902)
4580: accuracy:0.02 loss: 357.838 (lr:0.0005962056630840287)
4590: accuracy:0.34 loss: 303.934 (lr:0.0005937308270146883)
4600: accuracy:0.19 loss: 306.584 (lr:0.0005912683342417384)
4610: accuracy:0.04 loss: 322.192 (lr:0.0005888181232027313)
4620: accuracy:0.07 loss: 354.821 (lr:0.0005863801326422638)
4630: accuracy:0.12 loss: 308.181 (lr:0.0005839543016104445)
4640: accuracy:0.17 loss: 300.165 (lr:0.0005815405694613716)
4650: accuracy:0.03 loss: 290.197 (lr:0.0005791388758516152)
4660: accuracy:0.13 loss: 310.953 (lr:0.0005767491607387105)
4670: accuracy:0.06 loss: 355.619 (lr:0.0005743713643796551)
4680: accuracy:0.09 loss: 337.199 (lr:0.0005720054273294159)
4690: accuracy:0.13 loss: 299.043 (lr:0.0005696512904394433)
4700: accuracy:0.09 loss: 305.119 (lr:0.0005673088948561931)
4710: accuracy:0.0 loss: 342.81 (lr:0.0005649781820196532)
4720: accuracy:0.09 loss: 283.418 (lr:0.0005626590936618815)
4730: accuracy:0.06 loss: 335.32 (lr:0.000560351571805548)
4740: accuracy:0.07 loss: 310.674 (lr:0.0005580555587624865)
4750: accuracy:0.12 loss: 329.801 (lr:0.0005557709971322511)
4760: accuracy:0.16 loss: 319.646 (lr:0.0005534978298006822)
4770: accuracy:0.04 loss: 339.958 (lr:0.0005512359999384779)
4780: accuracy:0.33 loss: 272.951 (lr:0.0005489854509997736)
4790: accuracy:0.11 loss: 268.171 (lr:0.0005467461267207295)
4800: accuracy:0.07 loss: 329.736 (lr:0.0005445179711181214)
4810: accuracy:0.01 loss: 330.798 (lr:0.0005423009284879431)
4820: accuracy:0.03 loss: 322.805 (lr:0.0005400949434040134)
4830: accuracy:0.07 loss: 308.557 (lr:0.0005378999607165907)
4840: accuracy:0.04 loss: 329.698 (lr:0.0005357159255509931)
4850: accuracy:0.2 loss: 287.459 (lr:0.0005335427833062278)
4860: accuracy:0.06 loss: 262.635 (lr:0.0005313804796536255)
4870: accuracy:0.09 loss: 265.575 (lr:0.0005292289605354824)
4880: accuracy:0.06 loss: 339.904 (lr:0.0005270881721637084)
4890: accuracy:0.01 loss: 279.239 (lr:0.0005249580610184826)
4900: accuracy:0.2 loss: 301.409 (lr:0.0005228385738469154)
4910: accuracy:0.11 loss: 305.788 (lr:0.0005207296576617175)
4920: accuracy:0.04 loss: 295.091 (lr:0.000518631259739874)
4930: accuracy:0.07 loss: 279.883 (lr:0.0005165433276213278)
4940: accuracy:0.0 loss: 351.591 (lr:0.000514465809107667)
4950: accuracy:0.11 loss: 324.522 (lr:0.0005123986522608207)
4960: accuracy:0.0 loss: 338.596 (lr:0.0005103418054017602)
4970: accuracy:0.31 loss: 306.632 (lr:0.0005082952171092067)
4980: accuracy:0.3 loss: 307.139 (lr:0.0005062588362183461)
4990: accuracy:0.1 loss: 288.64 (lr:0.0005042326118195504)
5000: accuracy:0.03 loss: 276.145 (lr:0.0005022164932571041)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
5000: ********* epoch 1 ********* test accuracy for all:0.027027 test loss: 503.492
5000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 2138.99
5000: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 822.088
5000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 392.123
5000: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 361.131
5000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 261.289
5000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 605.071
5000: ********* epoch 1 ********* test accuracy for mode 27:1.0 test loss: 213.653
5000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 335.342
5000: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 401.662
5000: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 436.246
5000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 456.374
5000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 473.548
5000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 460.471
5000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 443.75
5000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 690.927
5000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 2057.79
5010: accuracy:0.0 loss: 297.8 (lr:0.000500210430127938)
5020: accuracy:0.11 loss: 343.043 (lr:0.0004982143722803694)
5030: accuracy:0.29 loss: 290.123 (lr:0.000496228269812848)
5040: accuracy:0.06 loss: 332.397 (lr:0.0004942520730727089)
5050: accuracy:0.03 loss: 349.093 (lr:0.0004922857326549306)
5060: accuracy:0.03 loss: 323.963 (lr:0.0004903291994009004)
5070: accuracy:0.41 loss: 283.016 (lr:0.0004883824243971846)
5080: accuracy:0.31 loss: 297.995 (lr:0.0004864453589743072)
5090: accuracy:0.03 loss: 272.464 (lr:0.00048451795470553155)
5100: accuracy:0.19 loss: 292.102 (lr:0.0004826001634056505)
5110: accuracy:0.27 loss: 268.761 (lr:0.00048069193712978154)
5120: accuracy:0.07 loss: 368.125 (lr:0.0004787932281721687)
5130: accuracy:0.03 loss: 373.843 (lr:0.000476903989064989)
5140: accuracy:0.11 loss: 333.887 (lr:0.0004750241725771664)
5150: accuracy:0.01 loss: 357.423 (lr:0.00047315373171319055)
5160: accuracy:0.14 loss: 321.096 (lr:0.00047129261971194284)
5170: accuracy:0.08 loss: 325.466 (lr:0.000469440790045526)
5180: accuracy:0.25 loss: 308.543 (lr:0.00046759819641810217)
5190: accuracy:0.03 loss: 305.746 (lr:0.00046576479276473425)
5200: accuracy:0.12 loss: 321.067 (lr:0.000463940533250236)
5210: accuracy:0.26 loss: 298.985 (lr:0.00046212537226802416)
5220: accuracy:0.03 loss: 334.347 (lr:0.00046031926443897977)
5230: accuracy:0.44 loss: 278.804 (lr:0.00045852216461031285)
5240: accuracy:0.07 loss: 335.286 (lr:0.00045673402785443434)
5250: accuracy:0.05 loss: 351.728 (lr:0.0004549548094678321)
5260: accuracy:0.36 loss: 305.037 (lr:0.00045318446496995385)
5270: accuracy:0.05 loss: 350.962 (lr:0.0004514229501020949)
5280: accuracy:0.21 loss: 307.406 (lr:0.00044967022082629166)
5290: accuracy:0.23 loss: 305.044 (lr:0.0004479262333242212)
5300: accuracy:0.08 loss: 351.776 (lr:0.000446190943996105)
5310: accuracy:0.12 loss: 327.559 (lr:0.0004444643094596195)
5320: accuracy:0.03 loss: 340.068 (lr:0.0004427462865488112)
5330: accuracy:0.2 loss: 330.368 (lr:0.00044103683231301816)
5340: accuracy:0.06 loss: 347.826 (lr:0.00043933590401579534)
5350: accuracy:0.29 loss: 317.981 (lr:0.00043764345913384665)
5360: accuracy:0.06 loss: 332.627 (lr:0.00043595945535596174)
5370: accuracy:0.09 loss: 331.891 (lr:0.0004342838505819588)
5380: accuracy:0.0 loss: 353.967 (lr:0.00043261660292163106)
5390: accuracy:0.15 loss: 313.074 (lr:0.0004309576706937001)
5400: accuracy:0.23 loss: 336.155 (lr:0.0004293070124247738)
5410: accuracy:0.1 loss: 332.39 (lr:0.0004276645868483096)
5420: accuracy:0.0 loss: 347.481 (lr:0.0004260303529035826)
5430: accuracy:0.0 loss: 351.734 (lr:0.00042440426973465884)
5440: accuracy:0.0 loss: 340.068 (lr:0.00042278629668937443)
5450: accuracy:0.0 loss: 360.727 (lr:0.0004211763933183192)
5460: accuracy:0.0 loss: 347.58 (lr:0.00041957451937382485)
5470: accuracy:0.0 loss: 340.021 (lr:0.0004179806348089594)
5480: accuracy:0.0 loss: 346.871 (lr:0.00041639469977652546)
5490: accuracy:0.0 loss: 349.65 (lr:0.0004148166746280651)
5500: accuracy:0.07 loss: 337.48 (lr:0.0004132465199128671)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
5500: ********* epoch 1 ********* test accuracy for all:0.027027 test loss: 457.011
5500: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 1813.69
5500: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 757.862
5500: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 364.296
5500: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 295.825
5500: ********* epoch 1 ********* test accuracy for mode 25:1.0 test loss: 277.157
5500: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 590.198
5500: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 284.516
5500: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 291.533
5500: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 333.052
5500: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 348.221
5500: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 376.359
5500: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 407.96
5500: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 405.605
5500: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 388.332
5500: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 630.511
5500: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 1678.48
5510: accuracy:0.09 loss: 338.139 (lr:0.00041168419637698184)
5520: accuracy:0.09 loss: 328.79 (lr:0.0004101296649622396)
5530: accuracy:0.03 loss: 344.516 (lr:0.0004085828868052738)
5540: accuracy:0.02 loss: 348.502 (lr:0.00040704382323655043)
5550: accuracy:0.0 loss: 350.781 (lr:0.0004055124357793998)
5560: accuracy:0.13 loss: 340.049 (lr:0.00040398868614905574)
5570: accuracy:0.03 loss: 341.591 (lr:0.00040247253625169807)
5580: accuracy:0.06 loss: 338.098 (lr:0.0004009639481835006)
5590: accuracy:0.04 loss: 336.135 (lr:0.00039946288422968297)
5600: accuracy:0.09 loss: 326.97 (lr:0.00039796930686356805)
5610: accuracy:0.01 loss: 346.284 (lr:0.0003964831787456439)
5620: accuracy:0.1 loss: 344.368 (lr:0.00039500446272263036)
5630: accuracy:0.15 loss: 321.469 (lr:0.00039353312182654966)
5640: accuracy:0.06 loss: 347.414 (lr:0.0003920691192738029)
5650: accuracy:0.06 loss: 334.332 (lr:0.0003906124184642497)
5660: accuracy:0.04 loss: 347.32 (lr:0.0003891629829802944)
5670: accuracy:0.01 loss: 347.76 (lr:0.00038772077658597416)
5680: accuracy:0.08 loss: 342.868 (lr:0.000386285763226054)
5690: accuracy:0.02 loss: 333.77 (lr:0.00038485790702512515)
5700: accuracy:0.04 loss: 331.868 (lr:0.00038343717228670843)
5710: accuracy:0.11 loss: 321.581 (lr:0.0003820235234923612)
5720: accuracy:0.08 loss: 337.246 (lr:0.00038061692530079005)
5730: accuracy:0.12 loss: 324.968 (lr:0.00037921734254696676)
5740: accuracy:0.08 loss: 327.144 (lr:0.00037782474024124983)
5750: accuracy:0.04 loss: 315.155 (lr:0.000376439083568509)
5760: accuracy:0.1 loss: 333.182 (lr:0.00037506033788725526)
5770: accuracy:0.06 loss: 326.99 (lr:0.00037368846872877477)
5780: accuracy:0.05 loss: 325.976 (lr:0.000372323441796267)
5790: accuracy:0.01 loss: 339.09 (lr:0.0003709652229639878)
5800: accuracy:0.08 loss: 323.519 (lr:0.0003696137782763954)
5810: accuracy:0.06 loss: 323.159 (lr:0.0003682690739473024)
5820: accuracy:0.09 loss: 314.645 (lr:0.0003669310763590303)
5830: accuracy:0.1 loss: 322.414 (lr:0.00036559975206156996)
5840: accuracy:0.07 loss: 322.087 (lr:0.0003642750677717445)
5850: accuracy:0.11 loss: 313.174 (lr:0.00036295699037237764)
5860: accuracy:0.06 loss: 322.686 (lr:0.0003616454869114657)
5870: accuracy:0.07 loss: 322.868 (lr:0.000360340524601354)
5880: accuracy:0.02 loss: 339.531 (lr:0.0003590420708179168)
5890: accuracy:0.06 loss: 324.257 (lr:0.0003577500930997418)
5900: accuracy:0.08 loss: 326.456 (lr:0.00035646455914731864)
5910: accuracy:0.06 loss: 327.056 (lr:0.00035518543682223186)
5920: accuracy:0.12 loss: 318.396 (lr:0.00035391269414635656)
5930: accuracy:0.03 loss: 327.45 (lr:0.00035264629930105955)
5940: accuracy:0.01 loss: 337.296 (lr:0.0003513862206264036)
5950: accuracy:0.11 loss: 323.513 (lr:0.0003501324266203565)
5960: accuracy:0.11 loss: 324.749 (lr:0.00034888488593800264)
5970: accuracy:0.09 loss: 316.188 (lr:0.00034764356739076)
5980: accuracy:0.03 loss: 323.001 (lr:0.0003464084399456001)
5990: accuracy:0.06 loss: 315.559 (lr:0.00034517947272427274)
6000: accuracy:0.03 loss: 325.468 (lr:0.00034395663500253333)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
6000: ********* epoch 1 ********* test accuracy for all:0.0270135 test loss: 888.153
6000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 6897.0
6000: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 2425.63
6000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 374.613
6000: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 279.332
6000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 298.673
6000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 1709.76
6000: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 657.662
6000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 278.786
6000: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 280.547
6000: ********* epoch 1 ********* test accuracy for mode 30:0.9995 test loss: 268.755
6000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 343.288
6000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 380.011
6000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 401.191
6000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 373.736
6000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 2047.17
6000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 6746.86
6010: accuracy:0.07 loss: 323.127 (lr:0.000342739896209375)
6020: accuracy:0.06 loss: 319.306 (lr:0.00034152922592626465)
6030: accuracy:0.05 loss: 327.931 (lr:0.00034032459388638194)
6040: accuracy:0.08 loss: 318.019 (lr:0.0003391259699738635)
6050: accuracy:0.04 loss: 327.313 (lr:0.00033793332422304886)
6060: accuracy:0.09 loss: 321.307 (lr:0.0003367466268177322)
6070: accuracy:0.12 loss: 311.934 (lr:0.0003355658480904164)
6080: accuracy:0.15 loss: 305.698 (lr:0.000334390958521572)
6090: accuracy:0.04 loss: 327.065 (lr:0.00033322192873889853)
6100: accuracy:0.15 loss: 316.846 (lr:0.00033205872951659057)
6110: accuracy:0.08 loss: 323.931 (lr:0.0003309013317746068)
6120: accuracy:0.15 loss: 305.524 (lr:0.00032974970657794356)
6130: accuracy:0.17 loss: 307.381 (lr:0.000328603825135911)
6140: accuracy:0.05 loss: 323.406 (lr:0.0003274636588014132)
6150: accuracy:0.08 loss: 315.853 (lr:0.0003263291790702325)
6160: accuracy:0.11 loss: 305.348 (lr:0.0003252003575803166)
6170: accuracy:0.06 loss: 312.185 (lr:0.00032407716611106943)
6180: accuracy:0.02 loss: 346.995 (lr:0.00032295957658264566)
6190: accuracy:0.06 loss: 325.944 (lr:0.0003218475610552489)
6200: accuracy:0.03 loss: 323.858 (lr:0.0003207410917284332)
6210: accuracy:0.06 loss: 322.418 (lr:0.00031964014094040767)
6220: accuracy:0.09 loss: 304.018 (lr:0.0003185446811673452)
6230: accuracy:0.08 loss: 326.82 (lr:0.0003174546850226944)
6240: accuracy:0.08 loss: 322.244 (lr:0.000316370125256495)
6250: accuracy:0.09 loss: 294.09 (lr:0.00031529097475469636)
6260: accuracy:0.06 loss: 310.657 (lr:0.0003142172065384796)
6270: accuracy:0.0 loss: 319.382 (lr:0.00031314879376358347)
6280: accuracy:0.17 loss: 301.514 (lr:0.00031208570971963287)
6290: accuracy:0.04 loss: 322.617 (lr:0.0003110279278294715)
6300: accuracy:0.06 loss: 320.89 (lr:0.0003099754216484969)
6310: accuracy:0.05 loss: 330.01 (lr:0.00030892816486399977)
6320: accuracy:0.09 loss: 318.793 (lr:0.0003078861312945058)
6330: accuracy:0.06 loss: 311.978 (lr:0.0003068492948891217)
6340: accuracy:0.11 loss: 291.823 (lr:0.0003058176297268832)
6350: accuracy:0.04 loss: 301.591 (lr:0.0003047911100161076)
6360: accuracy:0.05 loss: 321.517 (lr:0.00030376971009374846)
6370: accuracy:0.07 loss: 310.552 (lr:0.00030275340442475487)
6380: accuracy:0.41 loss: 225.928 (lr:0.00030174216760143194)
6390: accuracy:0.08 loss: 324.375 (lr:0.0003007359743428064)
6400: accuracy:0.06 loss: 313.401 (lr:0.00029973479949399446)
6410: accuracy:0.1 loss: 277.474 (lr:0.0002987386180255727)
6420: accuracy:0.06 loss: 334.399 (lr:0.0002977474050329526)
6430: accuracy:0.09 loss: 310.89 (lr:0.00029676113573575774)
6440: accuracy:0.06 loss: 316.158 (lr:0.0002957797854772041)
6450: accuracy:0.12 loss: 301.543 (lr:0.0002948033297234844)
6460: accuracy:0.09 loss: 311.048 (lr:0.00029383174406315374)
6470: accuracy:0.1 loss: 300.004 (lr:0.0002928650042065201)
6480: accuracy:0.15 loss: 278.792 (lr:0.0002919030859850366)
6490: accuracy:0.09 loss: 302.025 (lr:0.0002909459653506978)
6500: accuracy:0.04 loss: 292.872 (lr:0.0002899936183754378)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
6500: ********* epoch 1 ********* test accuracy for all:0.0253378 test loss: 1295.64
6500: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 8855.63
6500: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 2772.61
6500: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 364.227
6500: ********* epoch 1 ********* test accuracy for mode 24:0.345 test loss: 218.909
6500: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 751.322
6500: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 7498.04
6500: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 2102.4
6500: ********* epoch 1 ********* test accuracy for mode 28:0.1985 test loss: 237.978
6500: ********* epoch 1 ********* test accuracy for mode 29:0.394 test loss: 225.768
6500: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 276.948
6500: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 299.127
6500: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 331.973
6500: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 371.34
6500: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 363.114
6500: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 3936.43
6500: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 10634.5
6510: accuracy:0.11 loss: 300.664 (lr:0.0002890460212505328)
6520: accuracy:0.05 loss: 296.167 (lr:0.00028810315028600516)
6530: accuracy:0.02 loss: 330.357 (lr:0.00028716498191003165)
6540: accuracy:0.05 loss: 317.159 (lr:0.00028623149266835416)
6550: accuracy:0.03 loss: 310.141 (lr:0.0002853026592236929)
6560: accuracy:0.13 loss: 291.975 (lr:0.00028437845835516346)
6570: accuracy:0.05 loss: 296.511 (lr:0.0002834588669576959)
6580: accuracy:0.06 loss: 307.767 (lr:0.0002825438620414575)
6590: accuracy:0.04 loss: 319.324 (lr:0.00028163342073127755)
6600: accuracy:0.15 loss: 291.449 (lr:0.0002807275202660761)
6610: accuracy:0.03 loss: 313.371 (lr:0.000279826137998294)
6620: accuracy:0.05 loss: 285.095 (lr:0.00027892925139332795)
6630: accuracy:0.05 loss: 304.796 (lr:0.000278036838028966)
6640: accuracy:0.05 loss: 314.631 (lr:0.0002771488755948275)
6650: accuracy:0.08 loss: 310.932 (lr:0.0002762653418918053)
6660: accuracy:0.11 loss: 291.652 (lr:0.00027538621483151095)
6670: accuracy:0.14 loss: 307.195 (lr:0.0002745114724357221)
6680: accuracy:0.09 loss: 292.288 (lr:0.00027364109283583335)
6690: accuracy:0.08 loss: 298.05 (lr:0.0002727750542723092)
6700: accuracy:0.08 loss: 326.361 (lr:0.0002719133350941406)
6710: accuracy:0.07 loss: 304.273 (lr:0.0002710559137583032)
6720: accuracy:0.06 loss: 304.515 (lr:0.00027020276882921897)
6730: accuracy:0.1 loss: 260.104 (lr:0.0002693538789782201)
6740: accuracy:0.14 loss: 280.95 (lr:0.0002685092229830163)
6750: accuracy:0.11 loss: 294.737 (lr:0.00026766877972716357)
6760: accuracy:0.1 loss: 299.707 (lr:0.0002668325281995368)
6770: accuracy:0.02 loss: 324.494 (lr:0.00026600044749380423)
6780: accuracy:0.07 loss: 311.812 (lr:0.00026517251680790473)
6790: accuracy:0.05 loss: 315.118 (lr:0.00026434871544352834)
6800: accuracy:0.07 loss: 303.497 (lr:0.0002635290228055978)
6810: accuracy:0.09 loss: 288.559 (lr:0.00026271341840175457)
6820: accuracy:0.07 loss: 301.505 (lr:0.00026190188184184595)
6830: accuracy:0.09 loss: 308.037 (lr:0.0002610943928374159)
6840: accuracy:0.07 loss: 301.268 (lr:0.0002602909312011971)
6850: accuracy:0.09 loss: 309.879 (lr:0.00025949147684660684)
6860: accuracy:0.05 loss: 319.408 (lr:0.0002586960097872445)
6870: accuracy:0.09 loss: 303.711 (lr:0.0002579045101363923)
6880: accuracy:0.03 loss: 317.782 (lr:0.0002571169581065178)
6890: accuracy:0.06 loss: 303.007 (lr:0.0002563333340087791)
6900: accuracy:0.05 loss: 304.38 (lr:0.0002555536182525329)
6910: accuracy:0.1 loss: 309.855 (lr:0.0002547777913448448)
6920: accuracy:0.06 loss: 310.612 (lr:0.0002540058338900018)
6930: accuracy:0.05 loss: 303.566 (lr:0.0002532377265890271)
6940: accuracy:0.17 loss: 290.11 (lr:0.0002524734502391982)
6950: accuracy:0.18 loss: 291.989 (lr:0.00025171298573356673)
6960: accuracy:0.09 loss: 295.641 (lr:0.00025095631406048025)
6970: accuracy:0.16 loss: 290.444 (lr:0.00025020341630310766)
6980: accuracy:0.18 loss: 284.469 (lr:0.0002494542736389657)
6990: accuracy:0.13 loss: 280.797 (lr:0.0002487088673394488)
7000: accuracy:0.14 loss: 277.317 (lr:0.0002479671787693607)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
7000: ********* epoch 1 ********* test accuracy for all:0.0455405 test loss: 2291.22
7000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 13914.8
7000: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 3581.35
7000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 332.448
7000: ********* epoch 1 ********* test accuracy for mode 24:0.955 test loss: 199.367
7000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 2092.24
7000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 17508.1
7000: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 5184.13
7000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 968.299
7000: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 211.255
7000: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 284.672
7000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 297.737
7000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 318.509
7000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 349.334
7000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 343.921
7000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 8138.5
7000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 21993.0
7010: accuracy:0.15 loss: 284.695 (lr:0.0002472291893864484)
7020: accuracy:0.1 loss: 279.947 (lr:0.000246494880740939)
7030: accuracy:0.15 loss: 276.352 (lr:0.00024576423447507796)
7040: accuracy:0.15 loss: 291.742 (lr:0.0002450372323226708)
7050: accuracy:0.11 loss: 295.055 (lr:0.00024431385610862574)
7060: accuracy:0.1 loss: 282.853 (lr:0.00024359408774849974)
7070: accuracy:0.2 loss: 267.782 (lr:0.00024287790924804622)
7080: accuracy:0.07 loss: 294.536 (lr:0.00024216530270276555)
7090: accuracy:0.11 loss: 282.166 (lr:0.00024145625029745694)
7100: accuracy:0.1 loss: 282.085 (lr:0.00024075073430577322)
7110: accuracy:0.07 loss: 272.392 (lr:0.00024004873708977792)
7120: accuracy:0.19 loss: 282.928 (lr:0.00023935024109950407)
7130: accuracy:0.16 loss: 289.175 (lr:0.0002386552288725156)
7140: accuracy:0.14 loss: 271.972 (lr:0.0002379636830334705)
7150: accuracy:0.14 loss: 268.742 (lr:0.00023727558629368684)
7160: accuracy:0.14 loss: 288.74 (lr:0.0002365909214507104)
7170: accuracy:0.15 loss: 271.269 (lr:0.00023590967138788427)
7180: accuracy:0.06 loss: 274.554 (lr:0.0002352318190739215)
7190: accuracy:0.02 loss: 251.033 (lr:0.00023455734756247884)
7200: accuracy:0.15 loss: 278.743 (lr:0.00023388623999173356)
7210: accuracy:0.12 loss: 288.06 (lr:0.00023321847958396124)
7220: accuracy:0.23 loss: 266.325 (lr:0.00023255404964511706)
7230: accuracy:0.1 loss: 280.702 (lr:0.00023189293356441776)
7240: accuracy:0.04 loss: 274.539 (lr:0.00023123511481392707)
7250: accuracy:0.12 loss: 264.038 (lr:0.00023058057694814185)
7260: accuracy:0.17 loss: 271.698 (lr:0.00022992930360358148)
7270: accuracy:0.09 loss: 268.633 (lr:0.00022928127849837835)
7280: accuracy:0.14 loss: 287.375 (lr:0.00022863648543187102)
7290: accuracy:0.11 loss: 292.281 (lr:0.00022799490828419934)
7300: accuracy:0.1 loss: 281.333 (lr:0.00022735653101590118)
7310: accuracy:0.1 loss: 295.548 (lr:0.00022672133766751161)
7320: accuracy:0.27 loss: 267.866 (lr:0.00022608931235916372)
7330: accuracy:0.19 loss: 279.258 (lr:0.00022546043929019203)
7340: accuracy:0.17 loss: 271.763 (lr:0.00022483470273873698)
7350: accuracy:0.18 loss: 283.592 (lr:0.00022421208706135221)
7360: accuracy:0.11 loss: 287.83 (lr:0.00022359257669261336)
7370: accuracy:0.14 loss: 283.354 (lr:0.00022297615614472893)
7380: accuracy:0.1 loss: 285.826 (lr:0.00022236281000715319)
7390: accuracy:0.08 loss: 287.649 (lr:0.00022175252294620064)
7400: accuracy:0.08 loss: 292.535 (lr:0.000221145279704663)
7410: accuracy:0.14 loss: 261.44 (lr:0.00022054106510142768)
7420: accuracy:0.17 loss: 265.324 (lr:0.00021993986403109808)
7430: accuracy:0.12 loss: 270.235 (lr:0.00021934166146361615)
7440: accuracy:0.11 loss: 269.22 (lr:0.00021874644244388646)
7450: accuracy:0.07 loss: 276.439 (lr:0.00021815419209140265)
7460: accuracy:0.09 loss: 280.858 (lr:0.00021756489559987498)
7470: accuracy:0.15 loss: 281.704 (lr:0.00021697853823686046)
7480: accuracy:0.13 loss: 276.519 (lr:0.00021639510534339447)
7490: accuracy:0.07 loss: 278.35 (lr:0.00021581458233362437)
7500: accuracy:0.04 loss: 293.516 (lr:0.00021523695469444464)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
7500: ********* epoch 1 ********* test accuracy for all:0.0465676 test loss: 2463.64
7500: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 15068.2
7500: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 3956.73
7500: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 350.537
7500: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 830.659
7500: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 2514.84
7500: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 19077.4
7500: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 5658.72
7500: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 1421.5
7500: ********* epoch 1 ********* test accuracy for mode 29:0.9375 test loss: 201.665
7500: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 235.67
7500: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 296.92
7500: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 286.335
7500: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 331.452
7500: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 324.934
7500: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 8243.56
7500: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 22141.3
7510: accuracy:0.28 loss: 266.568 (lr:0.00021466220798513417)
7520: accuracy:0.05 loss: 295.519 (lr:0.00021409032783699535)
7530: accuracy:0.08 loss: 289.535 (lr:0.0002135212999529946)
7540: accuracy:0.13 loss: 297.461 (lr:0.0002129551101074053)
7550: accuracy:0.13 loss: 273.044 (lr:0.00021239174414545175)
7560: accuracy:0.18 loss: 256.059 (lr:0.0002118311879829556)
7570: accuracy:0.1 loss: 279.979 (lr:0.00021127342760598352)
7580: accuracy:0.13 loss: 274.997 (lr:0.00021071844907049713)
7590: accuracy:0.06 loss: 281.911 (lr:0.00021016623850200408)
7600: accuracy:0.07 loss: 275.118 (lr:0.00020961678209521144)
7610: accuracy:0.15 loss: 278.556 (lr:0.00020907006611368034)
7620: accuracy:0.12 loss: 269.926 (lr:0.00020852607688948285)
7630: accuracy:0.15 loss: 273.461 (lr:0.00020798480082286)
7640: accuracy:0.09 loss: 268.34 (lr:0.00020744622438188194)
7650: accuracy:0.07 loss: 273.98 (lr:0.00020691033410210954)
7660: accuracy:0.06 loss: 292.8 (lr:0.000206377116586258)
7670: accuracy:0.13 loss: 290.474 (lr:0.00020584655850386157)
7680: accuracy:0.06 loss: 301.071 (lr:0.00020531864659094064)
7690: accuracy:0.11 loss: 285.587 (lr:0.00020479336764966973)
7700: accuracy:0.11 loss: 270.282 (lr:0.00020427070854804814)
7710: accuracy:0.17 loss: 276.351 (lr:0.000203750656219571)
7720: accuracy:0.2 loss: 258.014 (lr:0.000203233197662903)
7730: accuracy:0.18 loss: 253.266 (lr:0.00020271831994155335)
7740: accuracy:0.09 loss: 292.571 (lr:0.0002022060101835521)
7750: accuracy:0.11 loss: 266.093 (lr:0.00020169625558112876)
7760: accuracy:0.11 loss: 262.637 (lr:0.0002011890433903916)
7770: accuracy:0.1 loss: 263.266 (lr:0.00020068436093100944)
7780: accuracy:0.07 loss: 301.483 (lr:0.00020018219558589451)
7790: accuracy:0.33 loss: 299.972 (lr:0.0001996825348008871)
7800: accuracy:0.07 loss: 295.878 (lr:0.0001991853660844415)
7810: accuracy:0.3 loss: 291.261 (lr:0.00019869067700731394)
7820: accuracy:0.1 loss: 308.961 (lr:0.00019819845520225167)
7830: accuracy:0.02 loss: 312.606 (lr:0.000197708688363684)
7840: accuracy:0.08 loss: 298.078 (lr:0.00019722136424741443)
7850: accuracy:0.05 loss: 283.655 (lr:0.00019673647067031463)
7860: accuracy:0.1 loss: 277.778 (lr:0.00019625399551001992)
7870: accuracy:0.08 loss: 258.012 (lr:0.00019577392670462626)
7880: accuracy:0.44 loss: 257.192 (lr:0.00019529625225238843)
7890: accuracy:0.11 loss: 273.516 (lr:0.00019482096021142026)
7900: accuracy:0.03 loss: 304.147 (lr:0.0001943480386993959)
7910: accuracy:0.01 loss: 299.134 (lr:0.00019387747589325307)
7920: accuracy:0.22 loss: 272.34 (lr:0.00019340926002889703)
7930: accuracy:0.26 loss: 273.451 (lr:0.00019294337940090677)
7940: accuracy:0.02 loss: 274.351 (lr:0.00019247982236224228)
7950: accuracy:0.05 loss: 253.417 (lr:0.00019201857732395355)
7960: accuracy:0.11 loss: 294.252 (lr:0.00019155963275489058)
7970: accuracy:0.05 loss: 301.405 (lr:0.00019110297718141523)
7980: accuracy:0.26 loss: 248.524 (lr:0.00019064859918711428)
7990: accuracy:0.05 loss: 275.171 (lr:0.00019019648741251435)
8000: accuracy:0.18 loss: 255.713 (lr:0.00018974663055479747)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
8000: ********* epoch 1 ********* test accuracy for all:0.045527 test loss: 2283.82
8000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 14391.6
8000: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 3403.95
8000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 328.644
8000: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 976.657
8000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 2255.4
8000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 16025.9
8000: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 4915.75
8000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 1419.24
8000: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 546.221
8000: ********* epoch 1 ********* test accuracy for mode 30:0.4565 test loss: 280.908
8000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 296.975
8000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 299.854
8000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 332.33
8000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 343.852
8000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 7992.88
8000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 18800.9
8010: accuracy:0.07 loss: 293.634 (lr:0.0001892990173675188)
8020: accuracy:0.02 loss: 275.137 (lr:0.00018885363666032527)
8030: accuracy:0.19 loss: 302.249 (lr:0.00018841047729867608)
8040: accuracy:0.14 loss: 257.88 (lr:0.00018796952820356405)
8050: accuracy:0.14 loss: 273.666 (lr:0.00018753077835123876)
8060: accuracy:0.24 loss: 244.355 (lr:0.00018709421677293126)
8070: accuracy:0.35 loss: 227.627 (lr:0.00018665983255457925)
8080: accuracy:0.15 loss: 257.923 (lr:0.00018622761483655463)
8090: accuracy:0.17 loss: 266.338 (lr:0.00018579755281339193)
8100: accuracy:0.08 loss: 296.979 (lr:0.00018536963573351822)
8110: accuracy:0.35 loss: 229.343 (lr:0.00018494385289898418)
8120: accuracy:0.34 loss: 245.027 (lr:0.00018452019366519676)
8130: accuracy:0.2 loss: 257.077 (lr:0.000184098647440653)
8140: accuracy:0.13 loss: 279.002 (lr:0.0001836792036866755)
8150: accuracy:0.2 loss: 251.257 (lr:0.00018326185191714842)
8160: accuracy:0.06 loss: 285.221 (lr:0.00018284658169825588)
8170: accuracy:0.07 loss: 286.436 (lr:0.0001824333826482207)
8180: accuracy:0.17 loss: 270.697 (lr:0.0001820222444370451)
8190: accuracy:0.3 loss: 220.773 (lr:0.00018161315678625245)
8200: accuracy:0.29 loss: 255.527 (lr:0.00018120610946863015)
8210: accuracy:0.04 loss: 290.458 (lr:0.00018080109230797397)
8220: accuracy:0.17 loss: 268.635 (lr:0.00018039809517883396)
8230: accuracy:0.18 loss: 280.39 (lr:0.00017999710800626083)
8240: accuracy:0.06 loss: 263.186 (lr:0.00017959812076555437)
8250: accuracy:0.16 loss: 247.965 (lr:0.0001792011234820128)
8260: accuracy:0.06 loss: 281.373 (lr:0.00017880610623068332)
8270: accuracy:0.14 loss: 253.287 (lr:0.00017841305913611412)
8280: accuracy:0.2 loss: 253.703 (lr:0.0001780219723721073)
8290: accuracy:0.29 loss: 236.576 (lr:0.00017763283616147347)
8300: accuracy:0.07 loss: 306.461 (lr:0.00017724564077578698)
8310: accuracy:0.05 loss: 273.207 (lr:0.00017686037653514316)
8320: accuracy:0.1 loss: 272.366 (lr:0.00017647703380791586)
8330: accuracy:0.18 loss: 251.049 (lr:0.00017609560301051698)
8340: accuracy:0.1 loss: 285.441 (lr:0.00017571607460715663)
8350: accuracy:0.08 loss: 275.769 (lr:0.00017533843910960502)
8360: accuracy:0.19 loss: 259.42 (lr:0.00017496268707695503)
8370: accuracy:0.09 loss: 279.853 (lr:0.00017458880911538628)
8380: accuracy:0.1 loss: 285.752 (lr:0.0001742167958779302)
8390: accuracy:0.15 loss: 263.991 (lr:0.00017384663806423658)
8400: accuracy:0.16 loss: 276.299 (lr:0.00017347832642034076)
8410: accuracy:0.14 loss: 291.043 (lr:0.00017311185173843243)
8420: accuracy:0.25 loss: 246.682 (lr:0.00017274720485662548)
8430: accuracy:0.28 loss: 228.837 (lr:0.00017238437665872887)
8440: accuracy:0.07 loss: 288.064 (lr:0.00017202335807401875)
8450: accuracy:0.16 loss: 270.117 (lr:0.0001716641400770117)
8460: accuracy:0.06 loss: 281.993 (lr:0.000171306713687239)
8470: accuracy:0.17 loss: 262.637 (lr:0.00017095106996902246)
8480: accuracy:0.25 loss: 257.991 (lr:0.00017059720003125052)
8490: accuracy:0.07 loss: 294.104 (lr:0.0001702450950271563)
8500: accuracy:0.1 loss: 288.215 (lr:0.00016989474615409635)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
8500: ********* epoch 1 ********* test accuracy for all:0.046473 test loss: 3100.53
8500: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 20718.5
8500: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 4985.67
8500: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 306.114
8500: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 1530.39
8500: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 3210.76
8500: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 21267.6
8500: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 6828.32
8500: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 2146.55
8500: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 938.164
8500: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 289.684
8500: ********* epoch 1 ********* test accuracy for mode 31:0.01 test loss: 285.08
8500: ********* epoch 1 ********* test accuracy for mode 32:0.5345 test loss: 270.88
8500: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 336.895
8500: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 322.064
8500: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 10936.7
8500: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 25642.7
8510: accuracy:0.14 loss: 285.233 (lr:0.00016954614465333062)
8520: accuracy:0.23 loss: 241.4 (lr:0.00016919928180980342)
8530: accuracy:0.15 loss: 268.93 (lr:0.00016885414895192558)
8540: accuracy:0.16 loss: 280.833 (lr:0.0001685107374513577)
8550: accuracy:0.25 loss: 251.77 (lr:0.00016816903872279433)
8560: accuracy:0.16 loss: 289.544 (lr:0.00016782904422374956)
8570: accuracy:0.24 loss: 263.144 (lr:0.00016749074545434312)
8580: accuracy:0.21 loss: 269.76 (lr:0.00016715413395708824)
8590: accuracy:0.12 loss: 289.776 (lr:0.00016681920131667987)
8600: accuracy:0.14 loss: 271.668 (lr:0.00016648593915978457)
8610: accuracy:0.29 loss: 223.829 (lr:0.0001661543391548311)
8620: accuracy:0.15 loss: 268.629 (lr:0.00016582439301180205)
8630: accuracy:0.06 loss: 277.01 (lr:0.00016549609248202657)
8640: accuracy:0.2 loss: 266.387 (lr:0.00016516942935797447)
8650: accuracy:0.04 loss: 293.815 (lr:0.00016484439547305056)
8660: accuracy:0.12 loss: 287.872 (lr:0.00016452098270139078)
8670: accuracy:0.31 loss: 234.719 (lr:0.00016419918295765902)
8680: accuracy:0.12 loss: 263.1 (lr:0.0001638789881968449)
8690: accuracy:0.17 loss: 269.469 (lr:0.00016356039041406277)
8700: accuracy:0.24 loss: 255.078 (lr:0.00016324338164435138)
8710: accuracy:0.11 loss: 280.127 (lr:0.00016292795396247498)
8720: accuracy:0.1 loss: 286.728 (lr:0.00016261409948272522)
8730: accuracy:0.19 loss: 275.772 (lr:0.0001623018103587237)
8740: accuracy:0.17 loss: 219.729 (lr:0.00016199107878322598)
8750: accuracy:0.21 loss: 243.693 (lr:0.0001616818969879266)
8760: accuracy:0.17 loss: 248.635 (lr:0.0001613742572432645)
8770: accuracy:0.12 loss: 248.33 (lr:0.00016106815185823003)
8780: accuracy:0.14 loss: 255.448 (lr:0.0001607635731801727)
8790: accuracy:0.07 loss: 281.41 (lr:0.00016046051359460962)
8800: accuracy:0.07 loss: 282.127 (lr:0.00016015896552503534)
8810: accuracy:0.05 loss: 293.457 (lr:0.00015985892143273252)
8820: accuracy:0.25 loss: 216.745 (lr:0.00015956037381658318)
8830: accuracy:0.17 loss: 254.613 (lr:0.00015926331521288136)
8840: accuracy:0.13 loss: 243.864 (lr:0.0001589677381951465)
8850: accuracy:0.12 loss: 275.137 (lr:0.00015867363537393775)
8860: accuracy:0.11 loss: 250.934 (lr:0.00015838099939666927)
8870: accuracy:0.21 loss: 236.172 (lr:0.0001580898229474264)
8880: accuracy:0.06 loss: 285.402 (lr:0.00015780009874678266)
8890: accuracy:0.11 loss: 270.845 (lr:0.00015751181955161807)
8900: accuracy:0.18 loss: 258.164 (lr:0.00015722497815493766)
8910: accuracy:0.18 loss: 243.533 (lr:0.00015693956738569164)
8920: accuracy:0.16 loss: 245.89 (lr:0.00015665558010859583)
8930: accuracy:0.24 loss: 244.744 (lr:0.00015637300922395357)
8940: accuracy:0.15 loss: 260.584 (lr:0.00015609184766747798)
8950: accuracy:0.19 loss: 246.384 (lr:0.00015581208841011556)
8960: accuracy:0.12 loss: 267.352 (lr:0.0001555337244578702)
8970: accuracy:0.11 loss: 253.69 (lr:0.00015525674885162873)
8980: accuracy:0.07 loss: 252.001 (lr:0.00015498115466698652)
8990: accuracy:0.17 loss: 250.456 (lr:0.00015470693501407458)
9000: accuracy:0.17 loss: 255.377 (lr:0.0001544340830373873)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
9000: ********* epoch 1 ********* test accuracy for all:0.0571487 test loss: 5404.35
9000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 38291.6
9000: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 9705.79
9000: ********* epoch 1 ********* test accuracy for mode 2:0.0025 test loss: 269.398
9000: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 2523.48
9000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 5409.64
9000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 35763.1
9000: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 11909.4
9000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 3799.21
9000: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 1738.59
9000: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 733.55
9000: ********* epoch 1 ********* test accuracy for mode 31:0.6245 test loss: 227.793
9000: ********* epoch 1 ********* test accuracy for mode 32:0.0415 test loss: 238.484
9000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 304.807
9000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 298.037
9000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 19615.6
9000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 48061.5
9010: accuracy:0.15 loss: 247.139 (lr:0.0001541625919156111)
9020: accuracy:0.14 loss: 265.057 (lr:0.00015389245486145372)
9030: accuracy:0.16 loss: 246.812 (lr:0.0001536236651214748)
9040: accuracy:0.1 loss: 248.621 (lr:0.0001533562159759168)
9050: accuracy:0.13 loss: 241.215 (lr:0.00015309010073853715)
9060: accuracy:0.17 loss: 221.311 (lr:0.00015282531275644112)
9070: accuracy:0.14 loss: 260.404 (lr:0.0001525618454099153)
9080: accuracy:0.3 loss: 196.173 (lr:0.00015229969211226233)
9090: accuracy:0.14 loss: 235.729 (lr:0.00015203884630963612)
9100: accuracy:0.17 loss: 240.556 (lr:0.00015177930148087802)
9110: accuracy:0.17 loss: 232.386 (lr:0.00015152105113735377)
9120: accuracy:0.03 loss: 278.163 (lr:0.00015126408882279135)
9130: accuracy:0.12 loss: 252.906 (lr:0.00015100840811311945)
9140: accuracy:0.17 loss: 241.727 (lr:0.00015075400261630711)
9150: accuracy:0.15 loss: 251.218 (lr:0.00015050086597220364)
9160: accuracy:0.22 loss: 241.383 (lr:0.0001502489918523797)
9170: accuracy:0.14 loss: 241.418 (lr:0.00014999837395996923)
9180: accuracy:0.12 loss: 255.073 (lr:0.00014974900602951184)
9190: accuracy:0.14 loss: 254.397 (lr:0.0001495008818267963)
9200: accuracy:0.18 loss: 240.827 (lr:0.00014925399514870456)
9210: accuracy:0.17 loss: 254.909 (lr:0.00014900833982305685)
9220: accuracy:0.19 loss: 246.158 (lr:0.00014876390970845727)
9230: accuracy:0.17 loss: 245.035 (lr:0.00014852069869414016)
9240: accuracy:0.12 loss: 247.4 (lr:0.00014827870069981756)
9250: accuracy:0.07 loss: 252.484 (lr:0.00014803790967552697)
9260: accuracy:0.22 loss: 246.322 (lr:0.00014779831960148022)
9270: accuracy:0.14 loss: 238.762 (lr:0.00014755992448791305)
9280: accuracy:0.11 loss: 239.726 (lr:0.0001473227183749351)
9290: accuracy:0.16 loss: 239.29 (lr:0.0001470866953323813)
9300: accuracy:0.19 loss: 233.525 (lr:0.00014685184945966318)
9310: accuracy:0.21 loss: 238.314 (lr:0.0001466181748856218)
9320: accuracy:0.13 loss: 231.49 (lr:0.0001463856657683806)
9330: accuracy:0.23 loss: 239.681 (lr:0.00014615431629519951)
9340: accuracy:0.19 loss: 226.426 (lr:0.00014592412068232968)
9350: accuracy:0.24 loss: 218.394 (lr:0.0001456950731748688)
9360: accuracy:0.09 loss: 232.594 (lr:0.00014546716804661724)
9370: accuracy:0.14 loss: 223.244 (lr:0.00014524039959993494)
9380: accuracy:0.18 loss: 217.733 (lr:0.00014501476216559887)
9390: accuracy:0.15 loss: 237.193 (lr:0.00014479025010266148)
9400: accuracy:0.1 loss: 230.429 (lr:0.0001445668577983095)
9410: accuracy:0.27 loss: 209.758 (lr:0.00014434457966772368)
9420: accuracy:0.18 loss: 209.32 (lr:0.00014412341015393915)
9430: accuracy:0.25 loss: 192.181 (lr:0.00014390334372770656)
9440: accuracy:0.27 loss: 189.642 (lr:0.00014368437488735381)
9450: accuracy:0.3 loss: 189.809 (lr:0.00014346649815864847)
9460: accuracy:0.3 loss: 186.583 (lr:0.00014324970809466095)
9470: accuracy:0.18 loss: 213.069 (lr:0.00014303399927562843)
9480: accuracy:0.25 loss: 194.778 (lr:0.00014281936630881914)
9490: accuracy:0.3 loss: 187.274 (lr:0.00014260580382839775)
9500: accuracy:0.25 loss: 182.826 (lr:0.0001423933064952911)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
9500: ********* epoch 1 ********* test accuracy for all:0.0617703 test loss: 6100.98
9500: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 41339.3
9500: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 10995.5
9500: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 502.516
9500: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 2918.36
9500: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 5805.97
9500: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 36058.3
9500: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 12176.9
9500: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 4265.59
9500: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 2198.97
9500: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 1396.22
9500: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 746.434
9500: ********* epoch 1 ********* test accuracy for mode 32:0.3425 test loss: 216.954
9500: ********* epoch 1 ********* test accuracy for mode 33:0.098 test loss: 208.643
9500: ********* epoch 1 ********* test accuracy for mode 34:0.0615 test loss: 198.231
9500: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 21693.0
9500: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 54321.7
9510: accuracy:0.25 loss: 182.315 (lr:0.00014218186899705486)
9520: accuracy:0.33 loss: 182.473 (lr:0.0001419714860477405)
9530: accuracy:0.29 loss: 177.495 (lr:0.00014176215238776335)
9540: accuracy:0.27 loss: 184.033 (lr:0.00014155386278377101)
9550: accuracy:0.3 loss: 179.123 (lr:0.0001413466120285125)
9560: accuracy:0.32 loss: 183.82 (lr:0.00014114039494070822)
9570: accuracy:0.23 loss: 192.495 (lr:0.00014093520636492018)
9580: accuracy:0.3 loss: 175.734 (lr:0.0001407310411714233)
9590: accuracy:0.3 loss: 172.912 (lr:0.0001405278942560771)
9600: accuracy:0.13 loss: 191.72 (lr:0.00014032576054019816)
9610: accuracy:0.48 loss: 147.274 (lr:0.00014012463497043302)
9620: accuracy:0.35 loss: 139.547 (lr:0.00013992451251863196)
9630: accuracy:0.2 loss: 177.761 (lr:0.00013972538818172322)
9640: accuracy:0.46 loss: 136.796 (lr:0.0001395272569815881)
9650: accuracy:0.48 loss: 131.822 (lr:0.00013933011396493627)
9660: accuracy:0.53 loss: 120.711 (lr:0.00013913395420318196)
9670: accuracy:0.39 loss: 128.073 (lr:0.00013893877279232098)
9680: accuracy:0.37 loss: 147.421 (lr:0.00013874456485280786)
9690: accuracy:0.45 loss: 128.692 (lr:0.00013855132552943402)
9700: accuracy:0.55 loss: 97.8652 (lr:0.00013835904999120628)
9710: accuracy:0.63 loss: 84.9654 (lr:0.0001381677334312262)
9720: accuracy:1.0 loss: 1.48985 (lr:0.0001379773710665698)
9730: accuracy:0.04 loss: 1154.79 (lr:0.00013778795813816806)
9740: accuracy:0.02 loss: 474.872 (lr:0.00013759948991068789)
9750: accuracy:0.04 loss: 367.387 (lr:0.0001374119616724138)
9760: accuracy:0.04 loss: 362.411 (lr:0.0001372253687351301)
9770: accuracy:0.02 loss: 367.718 (lr:0.00013703970643400357)
9780: accuracy:0.02 loss: 364.316 (lr:0.00013685497012746702)
9790: accuracy:0.03 loss: 364.173 (lr:0.0001366711551971032)
9800: accuracy:0.02 loss: 364.775 (lr:0.00013648825704752927)
9810: accuracy:0.03 loss: 362.527 (lr:0.00013630627110628195)
9820: accuracy:0.02 loss: 360.449 (lr:0.00013612519282370325)
9830: accuracy:0.02 loss: 364.488 (lr:0.0001359450176728267)
9840: accuracy:0.0 loss: 365.411 (lr:0.00013576574114926407)
9850: accuracy:0.05 loss: 360.291 (lr:0.00013558735877109297)
9860: accuracy:0.03 loss: 363.364 (lr:0.00013540986607874465)
9870: accuracy:0.03 loss: 362.797 (lr:0.0001352332586348926)
9880: accuracy:0.01 loss: 361.379 (lr:0.00013505753202434144)
9890: accuracy:0.01 loss: 361.109 (lr:0.00013488268185391682)
9900: accuracy:0.03 loss: 359.237 (lr:0.0001347087037523554)
9910: accuracy:0.03 loss: 361.161 (lr:0.0001345355933701955)
9920: accuracy:0.03 loss: 360.96 (lr:0.00013436334637966857)
9930: accuracy:0.07 loss: 359.879 (lr:0.00013419195847459093)
9940: accuracy:0.06 loss: 360.326 (lr:0.00013402142537025596)
9950: accuracy:0.02 loss: 361.904 (lr:0.00013385174280332722)
9960: accuracy:0.08 loss: 358.817 (lr:0.0001336829065317316)
9970: accuracy:0.01 loss: 361.996 (lr:0.00013351491233455368)
9980: accuracy:0.05 loss: 357.498 (lr:0.00013334775601192968)
9990: accuracy:0.04 loss: 358.407 (lr:0.00013318143338494283)
10000: accuracy:0.02 loss: 359.572 (lr:0.0001330159402955188)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
10000: ********* epoch 2 ********* test accuracy for all:0.0206351 test loss: 361.696
10000: ********* epoch 2 ********* test accuracy for mode 0:0.0 test loss: 395.515
10000: ********* epoch 2 ********* test accuracy for mode 1:0.0075 test loss: 342.638
10000: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 368.298
10000: ********* epoch 2 ********* test accuracy for mode 24:0.0 test loss: 358.613
10000: ********* epoch 2 ********* test accuracy for mode 25:0.0 test loss: 358.266
10000: ********* epoch 2 ********* test accuracy for mode 26:0.0205 test loss: 343.789
10000: ********* epoch 2 ********* test accuracy for mode 27:0.0585 test loss: 350.022
10000: ********* epoch 2 ********* test accuracy for mode 28:0.0 test loss: 355.482
10000: ********* epoch 2 ********* test accuracy for mode 29:0.0 test loss: 362.195
10000: ********* epoch 2 ********* test accuracy for mode 30:0.0 test loss: 370.891
10000: ********* epoch 2 ********* test accuracy for mode 31:0.0 test loss: 367.72
10000: ********* epoch 2 ********* test accuracy for mode 32:0.0 test loss: 370.977
10000: ********* epoch 2 ********* test accuracy for mode 33:0.01 test loss: 371.719
10000: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 364.573
10000: ********* epoch 2 ********* test accuracy for mode 35:0.499 test loss: 338.021
10000: ********* epoch 2 ********* test accuracy for mode 36:0.0515 test loss: 349.723
10010: accuracy:0.05 loss: 359.721 (lr:0.00013285127260632173)
10020: accuracy:0.06 loss: 361.942 (lr:0.00013268742620065085)
10030: accuracy:0.02 loss: 357.651 (lr:0.00013252439698233743)
10040: accuracy:0.06 loss: 360.598 (lr:0.00013236218087564258)
10050: accuracy:0.03 loss: 362.052 (lr:0.00013220077382515512)
10060: accuracy:0.01 loss: 361.467 (lr:0.0001320401717956904)
10070: accuracy:0.08 loss: 357.603 (lr:0.0001318803707721894)
10080: accuracy:0.08 loss: 361.322 (lr:0.00013172136675961807)
10090: accuracy:0.01 loss: 362.904 (lr:0.00013156315578286796)
10100: accuracy:0.02 loss: 362.456 (lr:0.00013140573388665627)
10110: accuracy:0.02 loss: 362.697 (lr:0.0001312490971354275)
10120: accuracy:0.04 loss: 359.552 (lr:0.00013109324161325467)
10130: accuracy:0.09 loss: 357.911 (lr:0.0001309381634237416)
10140: accuracy:0.05 loss: 359.449 (lr:0.00013078385868992546)
10150: accuracy:0.02 loss: 359.908 (lr:0.00013063032355417996)
10160: accuracy:0.06 loss: 358.634 (lr:0.00013047755417811861)
10170: accuracy:0.02 loss: 362.867 (lr:0.0001303255467424991)
10180: accuracy:0.06 loss: 360.451 (lr:0.0001301742974471276)
10190: accuracy:0.04 loss: 358.303 (lr:0.00013002380251076387)
10200: accuracy:0.07 loss: 358.954 (lr:0.00012987405817102663)
10210: accuracy:0.04 loss: 360.178 (lr:0.0001297250606842996)
10220: accuracy:0.05 loss: 359.902 (lr:0.00012957680632563789)
10230: accuracy:0.03 loss: 360.548 (lr:0.00012942929138867474)
10240: accuracy:0.05 loss: 357.546 (lr:0.0001292825121855291)
10250: accuracy:0.06 loss: 360.106 (lr:0.00012913646504671326)
10260: accuracy:0.09 loss: 358.883 (lr:0.0001289911463210411)
10270: accuracy:0.01 loss: 360.18 (lr:0.00012884655237553692)
10280: accuracy:0.04 loss: 358.388 (lr:0.00012870267959534456)
10290: accuracy:0.04 loss: 359.71 (lr:0.000128559524383637)
10300: accuracy:0.03 loss: 361.001 (lr:0.0001284170831615265)
10310: accuracy:0.02 loss: 362.281 (lr:0.00012827535236797512)
10320: accuracy:0.02 loss: 360.274 (lr:0.0001281343284597056)
10330: accuracy:0.02 loss: 358.909 (lr:0.0001279940079111129)
10340: accuracy:0.07 loss: 357.693 (lr:0.00012785438721417603)
10350: accuracy:0.02 loss: 362.025 (lr:0.00012771546287837024)
10360: accuracy:0.02 loss: 361.306 (lr:0.00012757723143057992)
10370: accuracy:0.05 loss: 361.893 (lr:0.0001274396894150117)
10380: accuracy:0.07 loss: 357.607 (lr:0.00012730283339310798)
10390: accuracy:0.06 loss: 359.059 (lr:0.0001271666599434611)
10400: accuracy:0.05 loss: 358.524 (lr:0.0001270311656617278)
10410: accuracy:0.05 loss: 357.617 (lr:0.00012689634716054387)
10420: accuracy:0.06 loss: 358.656 (lr:0.00012676220106943982)
10430: accuracy:0.04 loss: 360.413 (lr:0.00012662872403475638)
10440: accuracy:0.03 loss: 357.256 (lr:0.0001264959127195607)
10450: accuracy:0.06 loss: 360.474 (lr:0.00012636376380356304)
10460: accuracy:0.03 loss: 358.466 (lr:0.00012623227398303352)
10470: accuracy:0.05 loss: 357.579 (lr:0.0001261014399707199)
10480: accuracy:0.03 loss: 357.424 (lr:0.00012597125849576497)
10490: accuracy:0.02 loss: 358.311 (lr:0.00012584172630362512)
10500: accuracy:0.04 loss: 358.141 (lr:0.0001257128401559888)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
10500: ********* epoch 2 ********* test accuracy for all:0.0240541 test loss: 362.157
10500: ********* epoch 2 ********* test accuracy for mode 0:0.0015 test loss: 371.947
10500: ********* epoch 2 ********* test accuracy for mode 1:0.033 test loss: 337.861
10500: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 367.682
10500: ********* epoch 2 ********* test accuracy for mode 24:0.001 test loss: 363.668
10500: ********* epoch 2 ********* test accuracy for mode 25:0.0 test loss: 364.919
10500: ********* epoch 2 ********* test accuracy for mode 26:0.0135 test loss: 344.707
10500: ********* epoch 2 ********* test accuracy for mode 27:0.0525 test loss: 358.592
10500: ********* epoch 2 ********* test accuracy for mode 28:0.0075 test loss: 360.167
10500: ********* epoch 2 ********* test accuracy for mode 29:0.0 test loss: 364.256
10500: ********* epoch 2 ********* test accuracy for mode 30:0.0 test loss: 369.215
10500: ********* epoch 2 ********* test accuracy for mode 31:0.0 test loss: 367.497
10500: ********* epoch 2 ********* test accuracy for mode 32:0.0 test loss: 371.448
10500: ********* epoch 2 ********* test accuracy for mode 33:0.0 test loss: 372.565
10500: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 366.329
10500: ********* epoch 2 ********* test accuracy for mode 35:0.08 test loss: 347.21
10500: ********* epoch 2 ********* test accuracy for mode 36:0.5975 test loss: 355.163
10510: accuracy:0.02 loss: 357.531 (lr:0.00012558459683069555)
10520: accuracy:0.05 loss: 357.804 (lr:0.00012545699312165563)
10530: accuracy:0.05 loss: 357.646 (lr:0.00012533002583876965)
10540: accuracy:0.06 loss: 359.847 (lr:0.00012520369180784888)
10550: accuracy:0.04 loss: 361.907 (lr:0.000125077987870536)
10560: accuracy:0.06 loss: 357.883 (lr:0.00012495291088422604)
10570: accuracy:0.01 loss: 358.034 (lr:0.0001248284577219878)
10580: accuracy:0.04 loss: 359.991 (lr:0.0001247046252724858)
10590: accuracy:0.06 loss: 358.593 (lr:0.0001245814104399023)
10600: accuracy:0.09 loss: 356.862 (lr:0.00012445881014386007)
10610: accuracy:0.03 loss: 360.796 (lr:0.00012433682131934534)
10620: accuracy:0.07 loss: 355.921 (lr:0.00012421544091663112)
10630: accuracy:0.05 loss: 358.217 (lr:0.00012409466590120104)
10640: accuracy:0.01 loss: 360.308 (lr:0.00012397449325367342)
10650: accuracy:0.05 loss: 357.063 (lr:0.00012385491996972584)
10660: accuracy:0.04 loss: 359.982 (lr:0.00012373594306001995)
10670: accuracy:0.02 loss: 356.794 (lr:0.0001236175595501268)
10680: accuracy:0.05 loss: 359.404 (lr:0.00012349976648045246)
10690: accuracy:0.07 loss: 357.185 (lr:0.0001233825609061641)
10700: accuracy:0.01 loss: 359.095 (lr:0.00012326593989711625)
10710: accuracy:0.06 loss: 357.926 (lr:0.00012314990053777756)
10720: accuracy:0.06 loss: 358.819 (lr:0.00012303443992715804)
10730: accuracy:0.02 loss: 359.041 (lr:0.00012291955517873646)
10740: accuracy:0.07 loss: 358.605 (lr:0.00012280524342038804)
10750: accuracy:0.1 loss: 355.092 (lr:0.0001226915017943129)
10760: accuracy:0.08 loss: 355.612 (lr:0.0001225783274569645)
10770: accuracy:0.04 loss: 359.637 (lr:0.00012246571757897846)
10780: accuracy:0.05 loss: 359.291 (lr:0.00012235366934510198)
10790: accuracy:0.05 loss: 358.832 (lr:0.00012224217995412338)
10800: accuracy:0.04 loss: 359.517 (lr:0.00012213124661880208)
10810: accuracy:0.06 loss: 361.015 (lr:0.00012202086656579892)
10820: accuracy:0.01 loss: 360.917 (lr:0.00012191103703560683)
10830: accuracy:0.07 loss: 355.34 (lr:0.00012180175528248184)
10840: accuracy:0.01 loss: 356.509 (lr:0.00012169301857437441)
10850: accuracy:0.06 loss: 359.747 (lr:0.0001215848241928612)
10860: accuracy:0.05 loss: 358.427 (lr:0.00012147716943307701)
10870: accuracy:0.06 loss: 356.693 (lr:0.00012137005160364724)
10880: accuracy:0.06 loss: 357.728 (lr:0.00012126346802662059)
10890: accuracy:0.02 loss: 361.725 (lr:0.00012115741603740209)
10900: accuracy:0.03 loss: 361.039 (lr:0.00012105189298468647)
10910: accuracy:0.05 loss: 360.717 (lr:0.00012094689623039192)
10920: accuracy:0.03 loss: 356.569 (lr:0.00012084242314959412)
10930: accuracy:0.08 loss: 360.493 (lr:0.00012073847113046061)
10940: accuracy:0.01 loss: 359.856 (lr:0.00012063503757418548)
10950: accuracy:0.09 loss: 357.025 (lr:0.00012053211989492444)
10960: accuracy:0.0 loss: 361.047 (lr:0.00012042971551973016)
10970: accuracy:0.03 loss: 359.505 (lr:0.00012032782188848792)
10980: accuracy:0.09 loss: 358.057 (lr:0.00012022643645385164)
10990: accuracy:0.09 loss: 355.516 (lr:0.00012012555668118016)
11000: accuracy:0.03 loss: 359.353 (lr:0.00012002518004847394)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
11000: ********* epoch 2 ********* test accuracy for all:0.0280946 test loss: 361.934
11000: ********* epoch 2 ********* test accuracy for mode 0:0.047 test loss: 356.047
11000: ********* epoch 2 ********* test accuracy for mode 1:0.0415 test loss: 334.632
11000: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 365.279
11000: ********* epoch 2 ********* test accuracy for mode 24:0.0085 test loss: 370.281
11000: ********* epoch 2 ********* test accuracy for mode 25:0.0 test loss: 369.235
11000: ********* epoch 2 ********* test accuracy for mode 26:0.025 test loss: 348.343
11000: ********* epoch 2 ********* test accuracy for mode 27:0.1565 test loss: 366.021
11000: ********* epoch 2 ********* test accuracy for mode 28:0.058 test loss: 363.484
11000: ********* epoch 2 ********* test accuracy for mode 29:0.0 test loss: 366.887
11000: ********* epoch 2 ********* test accuracy for mode 30:0.0 test loss: 368.438
11000: ********* epoch 2 ********* test accuracy for mode 31:0.0 test loss: 365.755
11000: ********* epoch 2 ********* test accuracy for mode 32:0.0 test loss: 368.513
11000: ********* epoch 2 ********* test accuracy for mode 33:0.0 test loss: 372.103
11000: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 365.128
11000: ********* epoch 2 ********* test accuracy for mode 35:0.0245 test loss: 353.321
11000: ********* epoch 2 ********* test accuracy for mode 36:0.6265 test loss: 345.83
11010: accuracy:0.05 loss: 361.379 (lr:0.00011992530404631189)
11020: accuracy:0.06 loss: 356.206 (lr:0.00011982592617778879)
11030: accuracy:0.0 loss: 360.91 (lr:0.00011972704395845271)
11040: accuracy:0.09 loss: 354.496 (lr:0.00011962865491624306)
11050: accuracy:0.05 loss: 356.691 (lr:0.00011953075659142863)
11060: accuracy:0.03 loss: 359.303 (lr:0.00011943334653654622)
11070: accuracy:0.06 loss: 358.105 (lr:0.00011933642231633938)
11080: accuracy:0.02 loss: 359.666 (lr:0.00011923998150769756)
11090: accuracy:0.09 loss: 357.043 (lr:0.00011914402169959551)
11100: accuracy:0.05 loss: 359.341 (lr:0.00011904854049303305)
11110: accuracy:0.05 loss: 358.755 (lr:0.00011895353550097501)
11120: accuracy:0.03 loss: 358.694 (lr:0.00011885900434829166)
11130: accuracy:0.05 loss: 360.173 (lr:0.00011876494467169925)
11140: accuracy:0.03 loss: 358.894 (lr:0.00011867135411970099)
11150: accuracy:0.05 loss: 355.565 (lr:0.00011857823035252818)
11160: accuracy:0.12 loss: 355.282 (lr:0.00011848557104208181)
11170: accuracy:0.05 loss: 357.737 (lr:0.00011839337387187427)
11180: accuracy:0.04 loss: 359.452 (lr:0.00011830163653697153)
11190: accuracy:0.04 loss: 357.973 (lr:0.00011821035674393543)
11200: accuracy:0.03 loss: 356.843 (lr:0.00011811953221076637)
11210: accuracy:0.06 loss: 357.11 (lr:0.0001180291606668463)
11220: accuracy:0.1 loss: 355.047 (lr:0.00011793923985288192)
11230: accuracy:0.02 loss: 358.613 (lr:0.00011784976752084822)
11240: accuracy:0.09 loss: 353.425 (lr:0.0001177607414339322)
11250: accuracy:0.07 loss: 356.224 (lr:0.00011767215936647708)
11260: accuracy:0.05 loss: 357.032 (lr:0.00011758401910392655)
11270: accuracy:0.09 loss: 355.465 (lr:0.00011749631844276944)
11280: accuracy:0.03 loss: 358.793 (lr:0.00011740905519048468)
11290: accuracy:0.08 loss: 352.636 (lr:0.0001173222271654864)
11300: accuracy:0.01 loss: 358.817 (lr:0.00011723583219706943)
11310: accuracy:0.02 loss: 359.208 (lr:0.00011714986812535512)
11320: accuracy:0.04 loss: 356.649 (lr:0.00011706433280123715)
11330: accuracy:0.06 loss: 355.856 (lr:0.00011697922408632799)
11340: accuracy:0.04 loss: 357.305 (lr:0.00011689453985290532)
11350: accuracy:0.06 loss: 359.676 (lr:0.0001168102779838589)
11360: accuracy:0.04 loss: 359.438 (lr:0.00011672643637263762)
11370: accuracy:0.06 loss: 356.223 (lr:0.00011664301292319682)
11380: accuracy:0.04 loss: 358.301 (lr:0.0001165600055499459)
11390: accuracy:0.03 loss: 356.909 (lr:0.00011647741217769625)
11400: accuracy:0.09 loss: 355.909 (lr:0.00011639523074160924)
11410: accuracy:0.07 loss: 357.978 (lr:0.00011631345918714468)
11420: accuracy:0.12 loss: 353.925 (lr:0.00011623209547000948)
11430: accuracy:0.04 loss: 358.619 (lr:0.00011615113755610645)
11440: accuracy:0.05 loss: 358.39 (lr:0.0001160705834214835)
11450: accuracy:0.08 loss: 359.455 (lr:0.00011599043105228313)
11460: accuracy:0.06 loss: 357.537 (lr:0.00011591067844469189)
11470: accuracy:0.05 loss: 357.612 (lr:0.00011583132360489044)
11480: accuracy:0.05 loss: 356.426 (lr:0.00011575236454900367)
11490: accuracy:0.04 loss: 356.311 (lr:0.00011567379930305106)
11500: accuracy:0.03 loss: 356.103 (lr:0.00011559562590289738)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
11500: ********* epoch 2 ********* test accuracy for all:0.0336216 test loss: 361.767
11500: ********* epoch 2 ********* test accuracy for mode 0:0.027 test loss: 375.072
11500: ********* epoch 2 ********* test accuracy for mode 1:0.0875 test loss: 335.322
11500: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 362.601
11500: ********* epoch 2 ********* test accuracy for mode 24:0.0295 test loss: 366.958
11500: ********* epoch 2 ********* test accuracy for mode 25:0.0 test loss: 371.297
11500: ********* epoch 2 ********* test accuracy for mode 26:0.0035 test loss: 356.952
11500: ********* epoch 2 ********* test accuracy for mode 27:0.127 test loss: 371.183
11500: ********* epoch 2 ********* test accuracy for mode 28:0.1675 test loss: 362.691
11500: ********* epoch 2 ********* test accuracy for mode 29:0.0 test loss: 362.639
11500: ********* epoch 2 ********* test accuracy for mode 30:0.0 test loss: 364.693
11500: ********* epoch 2 ********* test accuracy for mode 31:0.0 test loss: 362.573
11500: ********* epoch 2 ********* test accuracy for mode 32:0.0 test loss: 365.329
11500: ********* epoch 2 ********* test accuracy for mode 33:0.001 test loss: 365.585
11500: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 361.566
11500: ********* epoch 2 ********* test accuracy for mode 35:0.031 test loss: 364.053
11500: ********* epoch 2 ********* test accuracy for mode 36:0.6155 test loss: 373.945
11510: accuracy:0.06 loss: 355.085 (lr:0.00011551784239420353)
11520: accuracy:0.08 loss: 356.747 (lr:0.00011544044683237777)
11530: accuracy:0.03 loss: 358.141 (lr:0.000115363437282527)
11540: accuracy:0.03 loss: 355.699 (lr:0.00011528681181940847)
11550: accuracy:0.08 loss: 357.739 (lr:0.00011521056852738162)
11560: accuracy:0.08 loss: 349.363 (lr:0.00011513470550036017)
11570: accuracy:0.04 loss: 359.221 (lr:0.0001150592208417645)
11580: accuracy:0.05 loss: 355.842 (lr:0.00011498411266447421)
11590: accuracy:0.04 loss: 359.011 (lr:0.00011490937909078095)
11600: accuracy:0.06 loss: 357.628 (lr:0.0001148350182523415)
11610: accuracy:0.07 loss: 358.083 (lr:0.00011476102829013102)
11620: accuracy:0.06 loss: 358.541 (lr:0.00011468740735439657)
11630: accuracy:0.03 loss: 356.395 (lr:0.00011461415360461096)
11640: accuracy:0.04 loss: 355.032 (lr:0.00011454126520942663)
11650: accuracy:0.07 loss: 354.301 (lr:0.0001144687403466299)
11660: accuracy:0.04 loss: 354.672 (lr:0.0001143965772030954)
11670: accuracy:0.03 loss: 358.071 (lr:0.00011432477397474081)
11680: accuracy:0.02 loss: 356.068 (lr:0.00011425332886648166)
11690: accuracy:0.06 loss: 356.884 (lr:0.00011418224009218655)
11700: accuracy:0.06 loss: 354.966 (lr:0.00011411150587463239)
11710: accuracy:0.06 loss: 354.601 (lr:0.00011404112444546007)
11720: accuracy:0.04 loss: 360.85 (lr:0.0001139710940451302)
11730: accuracy:0.04 loss: 356.79 (lr:0.00011390141292287912)
11740: accuracy:0.03 loss: 357.635 (lr:0.00011383207933667516)
11750: accuracy:0.08 loss: 356.757 (lr:0.00011376309155317502)
11760: accuracy:0.05 loss: 356.964 (lr:0.00011369444784768054)
11770: accuracy:0.11 loss: 351.667 (lr:0.0001136261465040955)
11780: accuracy:0.06 loss: 355.936 (lr:0.00011355818581488278)
11790: accuracy:0.08 loss: 355.063 (lr:0.00011349056408102157)
11800: accuracy:0.07 loss: 354.579 (lr:0.00011342327961196501)
11810: accuracy:0.06 loss: 353.942 (lr:0.0001133563307255979)
11820: accuracy:0.05 loss: 359.415 (lr:0.00011328971574819455)
11830: accuracy:0.04 loss: 356.972 (lr:0.0001132234330143771)
11840: accuracy:0.05 loss: 355.415 (lr:0.00011315748086707373)
11850: accuracy:0.02 loss: 358.676 (lr:0.00011309185765747731)
11860: accuracy:0.03 loss: 354.103 (lr:0.0001130265617450042)
11870: accuracy:0.04 loss: 355.613 (lr:0.00011296159149725319)
11880: accuracy:0.12 loss: 355.239 (lr:0.00011289694528996468)
11890: accuracy:0.04 loss: 357.175 (lr:0.00011283262150698014)
11900: accuracy:0.09 loss: 353.617 (lr:0.00011276861854020164)
11910: accuracy:0.02 loss: 359.382 (lr:0.00011270493478955168)
11920: accuracy:0.04 loss: 356.999 (lr:0.00011264156866293318)
11930: accuracy:0.09 loss: 353.266 (lr:0.00011257851857618967)
11940: accuracy:0.05 loss: 355.864 (lr:0.00011251578295306569)
11950: accuracy:0.04 loss: 356.578 (lr:0.0001124533602251674)
11960: accuracy:0.04 loss: 361.755 (lr:0.00011239124883192336)
11970: accuracy:0.07 loss: 358.408 (lr:0.0001123294472205455)
11980: accuracy:0.03 loss: 357.357 (lr:0.0001122679538459903)
11990: accuracy:0.05 loss: 353.322 (lr:0.0001122067671709202)
12000: accuracy:0.02 loss: 352.322 (lr:0.00011214588566566516)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
12000: ********* epoch 2 ********* test accuracy for all:0.0381216 test loss: 360.046
12000: ********* epoch 2 ********* test accuracy for mode 0:0.111 test loss: 355.684
12000: ********* epoch 2 ********* test accuracy for mode 1:0.0545 test loss: 332.185
12000: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 361.324
12000: ********* epoch 2 ********* test accuracy for mode 24:0.031 test loss: 370.585
12000: ********* epoch 2 ********* test accuracy for mode 25:0.05 test loss: 372.619
12000: ********* epoch 2 ********* test accuracy for mode 26:0.015 test loss: 356.45
12000: ********* epoch 2 ********* test accuracy for mode 27:0.257 test loss: 370.134
12000: ********* epoch 2 ********* test accuracy for mode 28:0.0545 test loss: 362.613
12000: ********* epoch 2 ********* test accuracy for mode 29:0.0 test loss: 364.383
12000: ********* epoch 2 ********* test accuracy for mode 30:0.0 test loss: 366.22
12000: ********* epoch 2 ********* test accuracy for mode 31:0.0 test loss: 365.758
12000: ********* epoch 2 ********* test accuracy for mode 32:0.0 test loss: 366.793
12000: ********* epoch 2 ********* test accuracy for mode 33:0.001 test loss: 367.009
12000: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 358.406
12000: ********* epoch 2 ********* test accuracy for mode 35:0.0175 test loss: 374.813
12000: ********* epoch 2 ********* test accuracy for mode 36:0.5995 test loss: 372.718
12010: accuracy:0.06 loss: 355.79 (lr:0.00011208530780818436)
12020: accuracy:0.06 loss: 354.407 (lr:0.0001120250320840282)
12030: accuracy:0.03 loss: 355.077 (lr:0.00011196505698630045)
12040: accuracy:0.07 loss: 353.359 (lr:0.00011190538101562054)
12050: accuracy:0.09 loss: 353.856 (lr:0.00011184600268008608)
12060: accuracy:0.07 loss: 352.304 (lr:0.0001117869204952356)
12070: accuracy:0.06 loss: 356.464 (lr:0.00011172813298401141)
12080: accuracy:0.05 loss: 351.852 (lr:0.00011166963867672268)
12090: accuracy:0.07 loss: 354.741 (lr:0.00011161143611100863)
12100: accuracy:0.02 loss: 360.15 (lr:0.00011155352383180215)
12110: accuracy:0.03 loss: 355.628 (lr:0.0001114959003912932)
12120: accuracy:0.07 loss: 356.437 (lr:0.00011143856434889277)
12130: accuracy:0.02 loss: 354.994 (lr:0.00011138151427119682)
12140: accuracy:0.01 loss: 355.053 (lr:0.00011132474873195044)
12150: accuracy:0.02 loss: 358.479 (lr:0.00011126826631201219)
12160: accuracy:0.02 loss: 355.315 (lr:0.00011121206559931864)
12170: accuracy:0.05 loss: 353.35 (lr:0.00011115614518884903)
12180: accuracy:0.04 loss: 353.122 (lr:0.00011110050368259019)
12190: accuracy:0.05 loss: 352.688 (lr:0.00011104513968950156)
12200: accuracy:0.06 loss: 351.974 (lr:0.00011099005182548044)
12210: accuracy:0.06 loss: 353.615 (lr:0.00011093523871332735)
12220: accuracy:0.06 loss: 351.708 (lr:0.00011088069898271165)
12230: accuracy:0.06 loss: 352.464 (lr:0.00011082643127013721)
12240: accuracy:0.09 loss: 351.222 (lr:0.0001107724342189084)
12250: accuracy:0.06 loss: 349.931 (lr:0.00011071870647909614)
12260: accuracy:0.07 loss: 354.329 (lr:0.00011066524670750411)
12270: accuracy:0.08 loss: 350.229 (lr:0.00011061205356763526)
12280: accuracy:0.06 loss: 352.197 (lr:0.00011055912572965832)
12290: accuracy:0.1 loss: 348.865 (lr:0.00011050646187037456)
12300: accuracy:0.03 loss: 350.858 (lr:0.00011045406067318478)
12310: accuracy:0.05 loss: 343.298 (lr:0.0001104019208280563)
12320: accuracy:0.06 loss: 350.867 (lr:0.0001103500410314903)
12330: accuracy:0.02 loss: 352.968 (lr:0.00011029841998648916)
12340: accuracy:0.06 loss: 348.313 (lr:0.00011024705640252404)
12350: accuracy:0.06 loss: 348.869 (lr:0.0001101959489955027)
12360: accuracy:0.1 loss: 345.992 (lr:0.00011014509648773728)
12370: accuracy:0.03 loss: 351.477 (lr:0.00011009449760791244)
12380: accuracy:0.11 loss: 347.431 (lr:0.00011004415109105356)
12390: accuracy:0.04 loss: 355.958 (lr:0.00010999405567849509)
12400: accuracy:0.05 loss: 351.324 (lr:0.0001099442101178491)
12410: accuracy:0.02 loss: 355.788 (lr:0.000109894613162974)
12420: accuracy:0.07 loss: 345.28 (lr:0.0001098452635739433)
12430: accuracy:0.06 loss: 347.524 (lr:0.00010979616011701473)
12440: accuracy:0.1 loss: 346.035 (lr:0.0001097473015645993)
12450: accuracy:0.04 loss: 354.631 (lr:0.00010969868669523067)
12460: accuracy:0.05 loss: 348.615 (lr:0.00010965031429353454)
12470: accuracy:0.05 loss: 349.843 (lr:0.00010960218315019839)
12480: accuracy:0.02 loss: 355.946 (lr:0.0001095542920619411)
12490: accuracy:0.03 loss: 355.503 (lr:0.00010950663983148298)
12500: accuracy:0.05 loss: 350.313 (lr:0.00010945922526751578)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
12500: ********* epoch 2 ********* test accuracy for all:0.0451081 test loss: 355.68
12500: ********* epoch 2 ********* test accuracy for mode 0:0.1375 test loss: 382.443
12500: ********* epoch 2 ********* test accuracy for mode 1:0.0805 test loss: 340.672
12500: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 358.8
12500: ********* epoch 2 ********* test accuracy for mode 24:0.0305 test loss: 363.614
12500: ********* epoch 2 ********* test accuracy for mode 25:0.089 test loss: 357.064
12500: ********* epoch 2 ********* test accuracy for mode 26:0.0035 test loss: 362.278
12500: ********* epoch 2 ********* test accuracy for mode 27:0.2895 test loss: 353.969
12500: ********* epoch 2 ********* test accuracy for mode 28:0.04 test loss: 351.459
12500: ********* epoch 2 ********* test accuracy for mode 29:0.0 test loss: 358.183
12500: ********* epoch 2 ********* test accuracy for mode 30:0.0 test loss: 363.454
12500: ********* epoch 2 ********* test accuracy for mode 31:0.0 test loss: 366.484
12500: ********* epoch 2 ********* test accuracy for mode 32:0.0 test loss: 362.185
12500: ********* epoch 2 ********* test accuracy for mode 33:0.002 test loss: 369.231
12500: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 351.781
12500: ********* epoch 2 ********* test accuracy for mode 35:0.008 test loss: 407.068
12500: ********* epoch 2 ********* test accuracy for mode 36:0.5265 test loss: 396.166
12510: accuracy:0.08 loss: 344.375 (lr:0.00010941204718467295)
12520: accuracy:0.02 loss: 356.069 (lr:0.00010936510440349993)
12530: accuracy:0.08 loss: 344.938 (lr:0.00010931839575042477)
12540: accuracy:0.06 loss: 344.095 (lr:0.00010927192005772871)
12550: accuracy:0.06 loss: 341.011 (lr:0.000109225676163517)
12560: accuracy:0.07 loss: 347.101 (lr:0.00010917966291168988)
12570: accuracy:0.06 loss: 350.229 (lr:0.00010913387915191366)
12580: accuracy:0.02 loss: 354.492 (lr:0.00010908832373959197)
12590: accuracy:0.02 loss: 350.418 (lr:0.00010904299553583712)
12600: accuracy:0.03 loss: 352.146 (lr:0.00010899789340744165)
12610: accuracy:0.02 loss: 353.576 (lr:0.00010895301622685001)
12620: accuracy:0.07 loss: 346.584 (lr:0.00010890836287213034)
12630: accuracy:0.02 loss: 351.854 (lr:0.00010886393222694645)
12640: accuracy:0.05 loss: 349.0 (lr:0.00010881972318052991)
12650: accuracy:0.04 loss: 349.168 (lr:0.00010877573462765222)
12660: accuracy:0.03 loss: 350.273 (lr:0.00010873196546859731)
12670: accuracy:0.06 loss: 347.634 (lr:0.0001086884146091339)
12680: accuracy:0.07 loss: 345.608 (lr:0.00010864508096048825)
12690: accuracy:0.05 loss: 344.86 (lr:0.00010860196343931686)
12700: accuracy:0.05 loss: 350.849 (lr:0.00010855906096767949)
12710: accuracy:0.02 loss: 354.388 (lr:0.00010851637247301209)
12720: accuracy:0.05 loss: 343.385 (lr:0.00010847389688810007)
12730: accuracy:0.05 loss: 347.823 (lr:0.0001084316331510516)
12740: accuracy:0.05 loss: 342.32 (lr:0.00010838958020527107)
12750: accuracy:0.03 loss: 344.793 (lr:0.00010834773699943262)
12760: accuracy:0.09 loss: 338.893 (lr:0.00010830610248745394)
12770: accuracy:0.05 loss: 345.866 (lr:0.00010826467562847005)
12780: accuracy:0.06 loss: 348.834 (lr:0.00010822345538680732)
12790: accuracy:0.06 loss: 347.846 (lr:0.00010818244073195756)
12800: accuracy:0.08 loss: 343.217 (lr:0.00010814163063855228)
12810: accuracy:0.04 loss: 343.361 (lr:0.00010810102408633701)
12820: accuracy:0.03 loss: 340.735 (lr:0.00010806062006014583)
12830: accuracy:0.08 loss: 342.683 (lr:0.00010802041754987595)
12840: accuracy:0.07 loss: 343.182 (lr:0.00010798041555046258)
12850: accuracy:0.08 loss: 339.567 (lr:0.0001079406130618536)
12860: accuracy:0.05 loss: 349.389 (lr:0.00010790100908898476)
12870: accuracy:0.06 loss: 351.52 (lr:0.00010786160264175464)
12880: accuracy:0.05 loss: 346.472 (lr:0.00010782239273500002)
12890: accuracy:0.05 loss: 349.197 (lr:0.0001077833783884712)
12900: accuracy:0.04 loss: 348.873 (lr:0.00010774455862680747)
12910: accuracy:0.04 loss: 344.594 (lr:0.00010770593247951278)
12920: accuracy:0.03 loss: 352.757 (lr:0.00010766749898093143)
12930: accuracy:0.05 loss: 340.353 (lr:0.00010762925717022394)
12940: accuracy:0.04 loss: 344.261 (lr:0.00010759120609134307)
12950: accuracy:0.07 loss: 339.465 (lr:0.00010755334479300986)
12960: accuracy:0.05 loss: 338.942 (lr:0.00010751567232868988)
12970: accuracy:0.05 loss: 349.185 (lr:0.00010747818775656956)
12980: accuracy:0.06 loss: 347.191 (lr:0.00010744089013953263)
12990: accuracy:0.02 loss: 344.126 (lr:0.00010740377854513675)
13000: accuracy:0.07 loss: 341.041 (lr:0.0001073668520455901)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
13000: ********* epoch 2 ********* test accuracy for all:0.0490946 test loss: 348.208
13000: ********* epoch 2 ********* test accuracy for mode 0:0.0315 test loss: 385.572
13000: ********* epoch 2 ********* test accuracy for mode 1:0.1155 test loss: 349.927
13000: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 356.138
13000: ********* epoch 2 ********* test accuracy for mode 24:0.1405 test loss: 329.674
13000: ********* epoch 2 ********* test accuracy for mode 25:0.0 test loss: 339.285
13000: ********* epoch 2 ********* test accuracy for mode 26:0.001 test loss: 314.873
13000: ********* epoch 2 ********* test accuracy for mode 27:0.4285 test loss: 326.866
13000: ********* epoch 2 ********* test accuracy for mode 28:0.0055 test loss: 335.636
13000: ********* epoch 2 ********* test accuracy for mode 29:0.0 test loss: 347.476
13000: ********* epoch 2 ********* test accuracy for mode 30:0.0 test loss: 355.162
13000: ********* epoch 2 ********* test accuracy for mode 31:0.0 test loss: 370.684
13000: ********* epoch 2 ********* test accuracy for mode 32:0.0 test loss: 364.404
13000: ********* epoch 2 ********* test accuracy for mode 33:0.0 test loss: 368.57
13000: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 350.108
13000: ********* epoch 2 ********* test accuracy for mode 35:0.01 test loss: 415.721
13000: ********* epoch 2 ********* test accuracy for mode 36:0.4505 test loss: 414.175
13010: accuracy:0.04 loss: 348.805 (lr:0.0001073301097177283)
13020: accuracy:0.03 loss: 343.48 (lr:0.00010729355064299121)
13030: accuracy:0.05 loss: 349.959 (lr:0.00010725717390740007)
13040: accuracy:0.07 loss: 343.652 (lr:0.00010722097860153458)
13050: accuracy:0.07 loss: 339.988 (lr:0.00010718496382051023)
13060: accuracy:0.04 loss: 343.579 (lr:0.00010714912866395562)
13070: accuracy:0.08 loss: 343.208 (lr:0.00010711347223598994)
13080: accuracy:0.03 loss: 345.234 (lr:0.00010707799364520067)
13090: accuracy:0.1 loss: 342.059 (lr:0.00010704269200462116)
13100: accuracy:0.04 loss: 342.265 (lr:0.00010700756643170859)
13110: accuracy:0.09 loss: 344.861 (lr:0.00010697261604832178)
13120: accuracy:0.07 loss: 341.137 (lr:0.00010693783998069935)
13130: accuracy:0.06 loss: 334.539 (lr:0.00010690323735943776)
13140: accuracy:0.12 loss: 338.154 (lr:0.0001068688073194697)
13150: accuracy:0.07 loss: 341.11 (lr:0.0001068345490000424)
13160: accuracy:0.05 loss: 344.462 (lr:0.00010680046154469605)
13170: accuracy:0.04 loss: 342.129 (lr:0.00010676654410124252)
13180: accuracy:0.05 loss: 344.086 (lr:0.00010673279582174395)
13190: accuracy:0.04 loss: 344.941 (lr:0.00010669921586249157)
13200: accuracy:0.06 loss: 342.516 (lr:0.00010666580338398469)
13210: accuracy:0.05 loss: 340.364 (lr:0.00010663255755090957)
13220: accuracy:0.08 loss: 342.867 (lr:0.00010659947753211868)
13230: accuracy:0.08 loss: 335.828 (lr:0.00010656656250060981)
13240: accuracy:0.01 loss: 352.353 (lr:0.00010653381163350546)
13250: accuracy:0.05 loss: 340.142 (lr:0.00010650122411203227)
13260: accuracy:0.05 loss: 337.997 (lr:0.00010646879912150047)
13270: accuracy:0.09 loss: 334.243 (lr:0.00010643653585128363)
13280: accuracy:0.05 loss: 338.143 (lr:0.0001064044334947983)
13290: accuracy:0.04 loss: 339.561 (lr:0.00010637249124948391)
13300: accuracy:0.08 loss: 329.795 (lr:0.00010634070831678266)
13310: accuracy:0.02 loss: 338.605 (lr:0.00010630908390211957)
13320: accuracy:0.07 loss: 335.269 (lr:0.00010627761721488264)
13330: accuracy:0.08 loss: 334.864 (lr:0.00010624630746840303)
13340: accuracy:0.07 loss: 337.905 (lr:0.00010621515387993547)
13350: accuracy:0.1 loss: 333.908 (lr:0.00010618415567063861)
13360: accuracy:0.06 loss: 339.31 (lr:0.00010615331206555562)
13370: accuracy:0.05 loss: 339.881 (lr:0.00010612262229359474)
13380: accuracy:0.08 loss: 332.98 (lr:0.00010609208558751009)
13390: accuracy:0.13 loss: 328.953 (lr:0.00010606170118388241)
13400: accuracy:0.04 loss: 333.632 (lr:0.00010603146832310006)
13410: accuracy:0.03 loss: 336.922 (lr:0.00010600138624933993)
13420: accuracy:0.03 loss: 342.436 (lr:0.00010597145421054859)
13430: accuracy:0.05 loss: 334.719 (lr:0.00010594167145842354)
13440: accuracy:0.03 loss: 343.081 (lr:0.0001059120372483944)
13450: accuracy:0.07 loss: 340.102 (lr:0.0001058825508396044)
13460: accuracy:0.07 loss: 327.734 (lr:0.00010585321149489177)
13470: accuracy:0.09 loss: 329.956 (lr:0.00010582401848077137)
13480: accuracy:0.02 loss: 341.628 (lr:0.00010579497106741631)
13490: accuracy:0.05 loss: 333.181 (lr:0.00010576606852863977)
13500: accuracy:0.06 loss: 336.351 (lr:0.00010573731014187676)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
13500: ********* epoch 2 ********* test accuracy for all:0.0555405 test loss: 342.996
13500: ********* epoch 2 ********* test accuracy for mode 0:0.0225 test loss: 405.181
13500: ********* epoch 2 ********* test accuracy for mode 1:0.0855 test loss: 355.519
13500: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 358.875
13500: ********* epoch 2 ********* test accuracy for mode 24:0.231 test loss: 321.927
13500: ********* epoch 2 ********* test accuracy for mode 25:0.0 test loss: 323.323
13500: ********* epoch 2 ********* test accuracy for mode 26:0.003 test loss: 289.47
13500: ********* epoch 2 ********* test accuracy for mode 27:0.3565 test loss: 315.871
13500: ********* epoch 2 ********* test accuracy for mode 28:0.0185 test loss: 321.001
13500: ********* epoch 2 ********* test accuracy for mode 29:0.0035 test loss: 335.885
13500: ********* epoch 2 ********* test accuracy for mode 30:0.0 test loss: 346.37
13500: ********* epoch 2 ********* test accuracy for mode 31:0.0 test loss: 371.154
13500: ********* epoch 2 ********* test accuracy for mode 32:0.0 test loss: 365.264
13500: ********* epoch 2 ********* test accuracy for mode 33:0.0025 test loss: 366.783
13500: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 351.345
13500: ********* epoch 2 ********* test accuracy for mode 35:0.01 test loss: 436.838
13500: ********* epoch 2 ********* test accuracy for mode 36:0.4655 test loss: 441.032
13510: accuracy:0.09 loss: 334.584 (lr:0.00010570869518816612)
13520: accuracy:0.07 loss: 329.447 (lr:0.00010568022295213251)
13530: accuracy:0.07 loss: 335.63 (lr:0.00010565189272196854)
13540: accuracy:0.06 loss: 337.121 (lr:0.00010562370378941699)
13550: accuracy:0.03 loss: 332.477 (lr:0.00010559565544975309)
13560: accuracy:0.06 loss: 336.068 (lr:0.00010556774700176685)
13570: accuracy:0.06 loss: 333.981 (lr:0.00010553997774774566)
13580: accuracy:0.05 loss: 335.733 (lr:0.0001055123469934567)
13590: accuracy:0.05 loss: 331.892 (lr:0.00010548485404812968)
13600: accuracy:0.1 loss: 329.604 (lr:0.00010545749822443955)
13610: accuracy:0.07 loss: 339.213 (lr:0.00010543027883848924)
13620: accuracy:0.06 loss: 335.018 (lr:0.00010540319520979275)
13630: accuracy:0.03 loss: 331.375 (lr:0.00010537624666125791)
13640: accuracy:0.07 loss: 340.722 (lr:0.0001053494325191696)
13650: accuracy:0.09 loss: 337.488 (lr:0.00010532275211317291)
13660: accuracy:0.09 loss: 331.972 (lr:0.00010529620477625627)
13670: accuracy:0.04 loss: 341.465 (lr:0.00010526978984473488)
13680: accuracy:0.04 loss: 340.774 (lr:0.00010524350665823407)
13690: accuracy:0.05 loss: 338.685 (lr:0.00010521735455967282)
13700: accuracy:0.11 loss: 338.646 (lr:0.0001051913328952473)
13710: accuracy:0.05 loss: 325.323 (lr:0.00010516544101441454)
13720: accuracy:0.07 loss: 332.907 (lr:0.00010513967826987616)
13730: accuracy:0.07 loss: 331.812 (lr:0.00010511404401756224)
13740: accuracy:0.09 loss: 335.028 (lr:0.0001050885376166151)
13750: accuracy:0.07 loss: 340.885 (lr:0.00010506315842937343)
13760: accuracy:0.07 loss: 347.749 (lr:0.00010503790582135619)
13770: accuracy:0.04 loss: 338.406 (lr:0.00010501277916124686)
13780: accuracy:0.08 loss: 330.258 (lr:0.00010498777782087766)
13790: accuracy:0.09 loss: 330.876 (lr:0.00010496290117521375)
13800: accuracy:0.06 loss: 330.419 (lr:0.0001049381486023377)
13810: accuracy:0.05 loss: 327.435 (lr:0.00010491351948343392)
13820: accuracy:0.07 loss: 325.483 (lr:0.00010488901320277314)
13830: accuracy:0.05 loss: 337.445 (lr:0.00010486462914769705)
13840: accuracy:0.05 loss: 349.261 (lr:0.00010484036670860302)
13850: accuracy:0.07 loss: 343.1 (lr:0.00010481622527892882)
13860: accuracy:0.07 loss: 338.258 (lr:0.00010479220425513744)
13870: accuracy:0.12 loss: 328.723 (lr:0.00010476830303670203)
13880: accuracy:0.1 loss: 323.288 (lr:0.00010474452102609087)
13890: accuracy:0.11 loss: 326.038 (lr:0.0001047208576287525)
13900: accuracy:0.04 loss: 336.594 (lr:0.0001046973122531007)
13910: accuracy:0.12 loss: 333.085 (lr:0.0001046738843104999)
13920: accuracy:0.08 loss: 319.259 (lr:0.00010465057321525029)
13930: accuracy:0.08 loss: 334.078 (lr:0.00010462737838457327)
13940: accuracy:0.06 loss: 333.469 (lr:0.00010460429923859688)
13950: accuracy:0.07 loss: 326.513 (lr:0.00010458133520034126)
13960: accuracy:0.1 loss: 324.752 (lr:0.00010455848569570426)
13970: accuracy:0.06 loss: 337.927 (lr:0.00010453575015344707)
13980: accuracy:0.04 loss: 335.242 (lr:0.00010451312800517996)
13990: accuracy:0.09 loss: 328.526 (lr:0.00010449061868534804)
14000: accuracy:0.06 loss: 340.585 (lr:0.00010446822163121714)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
14000: ********* epoch 2 ********* test accuracy for all:0.0631757 test loss: 339.477
14000: ********* epoch 2 ********* test accuracy for mode 0:0.011 test loss: 435.278
14000: ********* epoch 2 ********* test accuracy for mode 1:0.061 test loss: 365.069
14000: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 353.475
14000: ********* epoch 2 ********* test accuracy for mode 24:0.2535 test loss: 332.551
14000: ********* epoch 2 ********* test accuracy for mode 25:0.0 test loss: 336.68
14000: ********* epoch 2 ********* test accuracy for mode 26:0.0265 test loss: 277.559
14000: ********* epoch 2 ********* test accuracy for mode 27:0.347 test loss: 318.907
14000: ********* epoch 2 ********* test accuracy for mode 28:0.006 test loss: 326.711
14000: ********* epoch 2 ********* test accuracy for mode 29:0.0005 test loss: 344.165
14000: ********* epoch 2 ********* test accuracy for mode 30:0.0 test loss: 352.267
14000: ********* epoch 2 ********* test accuracy for mode 31:0.0045 test loss: 370.657
14000: ********* epoch 2 ********* test accuracy for mode 32:0.0 test loss: 363.107
14000: ********* epoch 2 ********* test accuracy for mode 33:0.011 test loss: 363.33
14000: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 350.813
14000: ********* epoch 2 ********* test accuracy for mode 35:0.008 test loss: 463.133
14000: ********* epoch 2 ********* test accuracy for mode 36:0.4125 test loss: 443.936
14010: accuracy:0.09 loss: 321.083 (lr:0.00010444593628285973)
14020: accuracy:0.04 loss: 335.811 (lr:0.00010442376208314096)
14030: accuracy:0.07 loss: 330.746 (lr:0.00010440169847770468)
14040: accuracy:0.06 loss: 332.547 (lr:0.00010437974491495959)
14050: accuracy:0.04 loss: 330.327 (lr:0.00010435790084606547)
14060: accuracy:0.03 loss: 333.888 (lr:0.00010433616572491949)
14070: accuracy:0.05 loss: 329.854 (lr:0.00010431453900814249)
14080: accuracy:0.07 loss: 331.633 (lr:0.00010429302015506539)
14090: accuracy:0.09 loss: 339.806 (lr:0.00010427160862771576)
14100: accuracy:0.04 loss: 326.946 (lr:0.00010425030389080431)
14110: accuracy:0.07 loss: 332.142 (lr:0.00010422910541171151)
14120: accuracy:0.06 loss: 331.07 (lr:0.00010420801266047426)
14130: accuracy:0.05 loss: 326.358 (lr:0.00010418702510977268)
14140: accuracy:0.06 loss: 334.76 (lr:0.00010416614223491692)
14150: accuracy:0.06 loss: 328.906 (lr:0.00010414536351383404)
14160: accuracy:0.04 loss: 336.587 (lr:0.0001041246884270549)
14170: accuracy:0.05 loss: 330.058 (lr:0.00010410411645770126)
14180: accuracy:0.13 loss: 321.984 (lr:0.00010408364709147281)
14190: accuracy:0.09 loss: 322.682 (lr:0.00010406327981663435)
14200: accuracy:0.06 loss: 331.768 (lr:0.00010404301412400293)
14210: accuracy:0.07 loss: 328.926 (lr:0.00010402284950693519)
14220: accuracy:0.05 loss: 326.422 (lr:0.00010400278546131464)
14230: accuracy:0.07 loss: 324.371 (lr:0.0001039828214855391)
14240: accuracy:0.1 loss: 320.536 (lr:0.00010396295708050815)
14250: accuracy:0.12 loss: 324.724 (lr:0.0001039431917496106)
14260: accuracy:0.06 loss: 328.946 (lr:0.00010392352499871219)
14270: accuracy:0.06 loss: 326.037 (lr:0.00010390395633614307)
14280: accuracy:0.1 loss: 321.227 (lr:0.0001038844852726857)
14290: accuracy:0.03 loss: 318.007 (lr:0.00010386511132156246)
14300: accuracy:0.06 loss: 331.501 (lr:0.00010384583399842356)
14310: accuracy:0.06 loss: 324.256 (lr:0.00010382665282133495)
14320: accuracy:0.04 loss: 330.841 (lr:0.00010380756731076616)
14330: accuracy:0.1 loss: 325.109 (lr:0.00010378857698957845)
14340: accuracy:0.07 loss: 320.19 (lr:0.0001037696813830128)
14350: accuracy:0.1 loss: 322.488 (lr:0.00010375088001867806)
14360: accuracy:0.03 loss: 322.75 (lr:0.00010373217242653915)
14370: accuracy:0.03 loss: 331.664 (lr:0.00010371355813890529)
14380: accuracy:0.12 loss: 325.001 (lr:0.00010369503669041831)
14390: accuracy:0.07 loss: 319.969 (lr:0.00010367660761804106)
14400: accuracy:0.07 loss: 326.51 (lr:0.00010365827046104573)
14410: accuracy:0.08 loss: 315.784 (lr:0.00010364002476100247)
14420: accuracy:0.07 loss: 329.1 (lr:0.00010362187006176782)
14430: accuracy:0.04 loss: 327.845 (lr:0.00010360380590947336)
14440: accuracy:0.06 loss: 329.886 (lr:0.00010358583185251433)
14450: accuracy:0.07 loss: 313.781 (lr:0.00010356794744153837)
14460: accuracy:0.1 loss: 321.658 (lr:0.00010355015222943427)
14470: accuracy:0.09 loss: 327.305 (lr:0.00010353244577132083)
14480: accuracy:0.03 loss: 322.944 (lr:0.00010351482762453563)
14490: accuracy:0.03 loss: 329.948 (lr:0.00010349729734862413)
14500: accuracy:0.06 loss: 323.196 (lr:0.00010347985450532849)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
14500: ********* epoch 2 ********* test accuracy for all:0.0753784 test loss: 329.907
14500: ********* epoch 2 ********* test accuracy for mode 0:0.0085 test loss: 419.881
14500: ********* epoch 2 ********* test accuracy for mode 1:0.0575 test loss: 360.025
14500: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 356.456
14500: ********* epoch 2 ********* test accuracy for mode 24:0.0225 test loss: 311.02
14500: ********* epoch 2 ********* test accuracy for mode 25:0.0005 test loss: 311.161
14500: ********* epoch 2 ********* test accuracy for mode 26:0.477 test loss: 255.884
14500: ********* epoch 2 ********* test accuracy for mode 27:0.28 test loss: 295.773
14500: ********* epoch 2 ********* test accuracy for mode 28:0.004 test loss: 305.41
14500: ********* epoch 2 ********* test accuracy for mode 29:0.0 test loss: 326.172
14500: ********* epoch 2 ********* test accuracy for mode 30:0.0 test loss: 343.454
14500: ********* epoch 2 ********* test accuracy for mode 31:0.0065 test loss: 358.195
14500: ********* epoch 2 ********* test accuracy for mode 32:0.0 test loss: 361.114
14500: ********* epoch 2 ********* test accuracy for mode 33:0.052 test loss: 359.176
14500: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 351.778
14500: ********* epoch 2 ********* test accuracy for mode 35:0.0285 test loss: 441.168
14500: ********* epoch 2 ********* test accuracy for mode 36:0.401 test loss: 422.977
14510: accuracy:0.1 loss: 322.359 (lr:0.00010346249865857673)
14520: accuracy:0.07 loss: 316.445 (lr:0.00010344522937447176)
14530: accuracy:0.08 loss: 317.026 (lr:0.00010342804622128061)
14540: accuracy:0.04 loss: 335.616 (lr:0.00010341094876942353)
14550: accuracy:0.08 loss: 314.521 (lr:0.00010339393659146333)
14560: accuracy:0.09 loss: 322.086 (lr:0.0001033770092620947)
14570: accuracy:0.07 loss: 321.697 (lr:0.00010336016635813349)
14580: accuracy:0.09 loss: 315.615 (lr:0.00010334340745850626)
14590: accuracy:0.06 loss: 328.996 (lr:0.00010332673214423961)
14600: accuracy:0.07 loss: 328.73 (lr:0.00010331013999844984)
14610: accuracy:0.11 loss: 327.813 (lr:0.00010329363060633244)
14620: accuracy:0.09 loss: 321.367 (lr:0.00010327720355515173)
14630: accuracy:0.06 loss: 317.985 (lr:0.0001032608584342306)
14640: accuracy:0.1 loss: 317.362 (lr:0.00010324459483494016)
14650: accuracy:0.08 loss: 330.998 (lr:0.00010322841235068959)
14660: accuracy:0.1 loss: 327.547 (lr:0.00010321231057691591)
14670: accuracy:0.14 loss: 316.916 (lr:0.00010319628911107398)
14680: accuracy:0.08 loss: 318.714 (lr:0.0001031803475526263)
14690: accuracy:0.09 loss: 321.402 (lr:0.00010316448550303307)
14700: accuracy:0.08 loss: 310.585 (lr:0.00010314870256574223)
14710: accuracy:0.1 loss: 320.878 (lr:0.00010313299834617954)
14720: accuracy:0.05 loss: 318.51 (lr:0.00010311737245173868)
14730: accuracy:0.05 loss: 325.041 (lr:0.00010310182449177147)
14740: accuracy:0.1 loss: 316.546 (lr:0.00010308635407757811)
14750: accuracy:0.07 loss: 319.447 (lr:0.00010307096082239745)
14760: accuracy:0.09 loss: 324.554 (lr:0.00010305564434139728)
14770: accuracy:0.06 loss: 330.068 (lr:0.0001030404042516648)
14780: accuracy:0.04 loss: 322.2 (lr:0.00010302524017219696)
14790: accuracy:0.13 loss: 325.978 (lr:0.000103010151723891)
14800: accuracy:0.07 loss: 315.545 (lr:0.00010299513852953492)
14810: accuracy:0.04 loss: 334.78 (lr:0.00010298020021379806)
14820: accuracy:0.11 loss: 321.047 (lr:0.00010296533640322177)
14830: accuracy:0.15 loss: 322.577 (lr:0.00010295054672621)
14840: accuracy:0.07 loss: 319.729 (lr:0.00010293583081302007)
14850: accuracy:0.13 loss: 312.873 (lr:0.00010292118829575336)
14860: accuracy:0.09 loss: 333.289 (lr:0.0001029066188083462)
14870: accuracy:0.1 loss: 318.114 (lr:0.00010289212198656063)
14880: accuracy:0.1 loss: 316.29 (lr:0.00010287769746797535)
14890: accuracy:0.1 loss: 312.597 (lr:0.00010286334489197667)
14900: accuracy:0.16 loss: 308.973 (lr:0.0001028490638997494)
14910: accuracy:0.08 loss: 309.964 (lr:0.00010283485413426803)
14920: accuracy:0.05 loss: 317.085 (lr:0.00010282071524028766)
14930: accuracy:0.1 loss: 316.538 (lr:0.0001028066468643352)
14940: accuracy:0.15 loss: 314.646 (lr:0.00010279264865470054)
14950: accuracy:0.07 loss: 316.453 (lr:0.0001027787202614277)
14960: accuracy:0.06 loss: 318.367 (lr:0.0001027648613363061)
14970: accuracy:0.09 loss: 303.411 (lr:0.00010275107153286193)
14980: accuracy:0.1 loss: 315.012 (lr:0.00010273735050634937)
14990: accuracy:0.13 loss: 305.277 (lr:0.00010272369791374203)
15000: accuracy:0.1 loss: 309.068 (lr:0.00010271011341372439)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
15000: ********* epoch 2 ********* test accuracy for all:0.099973 test loss: 322.913
15000: ********* epoch 2 ********* test accuracy for mode 0:0.0045 test loss: 448.744
15000: ********* epoch 2 ********* test accuracy for mode 1:0.0285 test loss: 366.341
15000: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 351.054
15000: ********* epoch 2 ********* test accuracy for mode 24:0.061 test loss: 317.595
15000: ********* epoch 2 ********* test accuracy for mode 25:0.0015 test loss: 312.695
15000: ********* epoch 2 ********* test accuracy for mode 26:0.345 test loss: 258.397
15000: ********* epoch 2 ********* test accuracy for mode 27:0.352 test loss: 300.562
15000: ********* epoch 2 ********* test accuracy for mode 28:0.0025 test loss: 311.059
15000: ********* epoch 2 ********* test accuracy for mode 29:0.0 test loss: 334.807
15000: ********* epoch 2 ********* test accuracy for mode 30:0.0 test loss: 347.766
15000: ********* epoch 2 ********* test accuracy for mode 31:0.0175 test loss: 359.588
15000: ********* epoch 2 ********* test accuracy for mode 32:0.007 test loss: 353.066
15000: ********* epoch 2 ********* test accuracy for mode 33:0.1385 test loss: 349.996
15000: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 345.996
15000: ********* epoch 2 ********* test accuracy for mode 35:0.005 test loss: 465.302
15000: ********* epoch 2 ********* test accuracy for mode 36:0.4745 test loss: 428.752
15010: accuracy:0.12 loss: 315.465 (lr:0.00010269659666668325)
15020: accuracy:0.1 loss: 310.583 (lr:0.00010268314733469922)
15030: accuracy:0.08 loss: 316.098 (lr:0.00010266976508153831)
15040: accuracy:0.13 loss: 313.162 (lr:0.00010265644957264349)
15050: accuracy:0.08 loss: 302.575 (lr:0.00010264320047512634)
15060: accuracy:0.15 loss: 308.194 (lr:0.00010263001745775873)
15070: accuracy:0.08 loss: 312.063 (lr:0.00010261690019096456)
15080: accuracy:0.16 loss: 306.898 (lr:0.00010260384834681144)
15090: accuracy:0.12 loss: 317.384 (lr:0.00010259086159900263)
15100: accuracy:0.08 loss: 313.309 (lr:0.00010257793962286872)
15110: accuracy:0.06 loss: 315.406 (lr:0.00010256508209535965)
15120: accuracy:0.06 loss: 315.765 (lr:0.00010255228869503656)
15130: accuracy:0.11 loss: 314.411 (lr:0.00010253955910206379)
15140: accuracy:0.08 loss: 312.22 (lr:0.00010252689299820083)
15150: accuracy:0.09 loss: 318.556 (lr:0.00010251429006679444)
15160: accuracy:0.12 loss: 317.39 (lr:0.00010250174999277067)
15170: accuracy:0.06 loss: 326.114 (lr:0.00010248927246262702)
15180: accuracy:0.09 loss: 314.89 (lr:0.00010247685716442459)
15190: accuracy:0.09 loss: 315.731 (lr:0.00010246450378778026)
15200: accuracy:0.08 loss: 310.982 (lr:0.000102452212023859)
15210: accuracy:0.12 loss: 319.733 (lr:0.00010243998156536604)
15220: accuracy:0.18 loss: 306.363 (lr:0.00010242781210653931)
15230: accuracy:0.09 loss: 316.78 (lr:0.00010241570334314169)
15240: accuracy:0.05 loss: 323.087 (lr:0.00010240365497245346)
15250: accuracy:0.15 loss: 303.871 (lr:0.00010239166669326474)
15260: accuracy:0.1 loss: 315.285 (lr:0.00010237973820586791)
15270: accuracy:0.09 loss: 318.185 (lr:0.00010236786921205017)
15280: accuracy:0.14 loss: 308.167 (lr:0.00010235605941508607)
15290: accuracy:0.1 loss: 309.17 (lr:0.00010234430851973005)
15300: accuracy:0.07 loss: 310.453 (lr:0.00010233261623220912)
15310: accuracy:0.09 loss: 308.281 (lr:0.00010232098226021549)
15320: accuracy:0.07 loss: 307.949 (lr:0.00010230940631289926)
15330: accuracy:0.1 loss: 321.439 (lr:0.00010229788810086112)
15340: accuracy:0.09 loss: 322.814 (lr:0.00010228642733614519)
15350: accuracy:0.07 loss: 312.369 (lr:0.00010227502373223175)
15360: accuracy:0.06 loss: 309.193 (lr:0.0001022636770040301)
15370: accuracy:0.14 loss: 309.563 (lr:0.00010225238686787145)
15380: accuracy:0.13 loss: 285.676 (lr:0.0001022411530415018)
15390: accuracy:0.13 loss: 309.042 (lr:0.00010222997524407494)
15400: accuracy:0.13 loss: 303.633 (lr:0.00010221885319614532)
15410: accuracy:0.1 loss: 299.499 (lr:0.00010220778661966115)
15420: accuracy:0.16 loss: 313.718 (lr:0.00010219677523795747)
15430: accuracy:0.12 loss: 303.091 (lr:0.00010218581877574916)
15440: accuracy:0.12 loss: 311.395 (lr:0.00010217491695912408)
15450: accuracy:0.05 loss: 316.306 (lr:0.00010216406951553626)
15460: accuracy:0.11 loss: 314.39 (lr:0.00010215327617379905)
15470: accuracy:0.12 loss: 314.066 (lr:0.00010214253666407833)
15480: accuracy:0.14 loss: 303.37 (lr:0.00010213185071788579)
15490: accuracy:0.16 loss: 308.367 (lr:0.00010212121806807225)
15500: accuracy:0.12 loss: 301.937 (lr:0.00010211063844882088)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
15500: ********* epoch 2 ********* test accuracy for all:0.121905 test loss: 312.391
15500: ********* epoch 2 ********* test accuracy for mode 0:0.0085 test loss: 445.26
15500: ********* epoch 2 ********* test accuracy for mode 1:0.028 test loss: 370.734
15500: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 335.606
15500: ********* epoch 2 ********* test accuracy for mode 24:0.1605 test loss: 305.628
15500: ********* epoch 2 ********* test accuracy for mode 25:0.0 test loss: 301.489
15500: ********* epoch 2 ********* test accuracy for mode 26:0.2825 test loss: 252.271
15500: ********* epoch 2 ********* test accuracy for mode 27:0.438 test loss: 286.897
15500: ********* epoch 2 ********* test accuracy for mode 28:0.001 test loss: 300.989
15500: ********* epoch 2 ********* test accuracy for mode 29:0.0 test loss: 327.852
15500: ********* epoch 2 ********* test accuracy for mode 30:0.0 test loss: 333.532
15500: ********* epoch 2 ********* test accuracy for mode 31:0.089 test loss: 336.584
15500: ********* epoch 2 ********* test accuracy for mode 32:0.1535 test loss: 320.661
15500: ********* epoch 2 ********* test accuracy for mode 33:0.271 test loss: 323.056
15500: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 330.923
15500: ********* epoch 2 ********* test accuracy for mode 35:0.008 test loss: 473.044
15500: ********* epoch 2 ********* test accuracy for mode 36:0.386 test loss: 441.545
15510: accuracy:0.19 loss: 291.98 (lr:0.00010210011159564065)
15520: accuracy:0.07 loss: 317.704 (lr:0.0001020896372453597)
15530: accuracy:0.16 loss: 297.294 (lr:0.00010207921513611873)
15540: accuracy:0.15 loss: 302.463 (lr:0.00010206884500736445)
15550: accuracy:0.07 loss: 308.632 (lr:0.00010205852659984311)
15560: accuracy:0.09 loss: 308.902 (lr:0.00010204825965559396)
15570: accuracy:0.14 loss: 303.732 (lr:0.0001020380439179429)
15580: accuracy:0.12 loss: 297.636 (lr:0.00010202787913149593)
15590: accuracy:0.18 loss: 304.579 (lr:0.00010201776504213287)
15600: accuracy:0.14 loss: 306.101 (lr:0.00010200770139700096)
15610: accuracy:0.15 loss: 301.262 (lr:0.00010199768794450854)
15620: accuracy:0.1 loss: 316.782 (lr:0.00010198772443431878)
15630: accuracy:0.09 loss: 298.78 (lr:0.0001019778106173434)
15640: accuracy:0.11 loss: 309.342 (lr:0.00010196794624573646)
15650: accuracy:0.14 loss: 293.332 (lr:0.00010195813107288817)
15660: accuracy:0.17 loss: 315.046 (lr:0.00010194836485341868)
15670: accuracy:0.11 loss: 292.672 (lr:0.00010193864734317201)
15680: accuracy:0.11 loss: 307.998 (lr:0.00010192897829920989)
15690: accuracy:0.11 loss: 303.26 (lr:0.00010191935747980571)
15700: accuracy:0.13 loss: 306.144 (lr:0.0001019097846444385)
15710: accuracy:0.16 loss: 300.039 (lr:0.00010190025955378687)
15720: accuracy:0.16 loss: 291.931 (lr:0.00010189078196972305)
15730: accuracy:0.14 loss: 296.296 (lr:0.00010188135165530696)
15740: accuracy:0.13 loss: 313.901 (lr:0.00010187196837478024)
15750: accuracy:0.19 loss: 307.615 (lr:0.00010186263189356038)
15760: accuracy:0.17 loss: 300.077 (lr:0.00010185334197823488)
15770: accuracy:0.1 loss: 300.987 (lr:0.00010184409839655534)
15780: accuracy:0.15 loss: 297.116 (lr:0.00010183490091743179)
15790: accuracy:0.15 loss: 301.857 (lr:0.00010182574931092674)
15800: accuracy:0.1 loss: 303.56 (lr:0.00010181664334824954)
15810: accuracy:0.11 loss: 308.381 (lr:0.00010180758280175066)
15820: accuracy:0.12 loss: 302.764 (lr:0.00010179856744491598)
15830: accuracy:0.1 loss: 290.582 (lr:0.00010178959705236111)
15840: accuracy:0.14 loss: 302.949 (lr:0.00010178067139982574)
15850: accuracy:0.09 loss: 315.881 (lr:0.00010177179026416811)
15860: accuracy:0.12 loss: 316.703 (lr:0.00010176295342335937)
15870: accuracy:0.19 loss: 297.404 (lr:0.00010175416065647803)
15880: accuracy:0.2 loss: 294.109 (lr:0.00010174541174370448)
15890: accuracy:0.14 loss: 310.219 (lr:0.00010173670646631541)
15900: accuracy:0.13 loss: 306.211 (lr:0.00010172804460667846)
15910: accuracy:0.1 loss: 302.602 (lr:0.00010171942594824668)
15920: accuracy:0.15 loss: 297.1 (lr:0.00010171085027555316)
15930: accuracy:0.14 loss: 314.29 (lr:0.00010170231737420563)
15940: accuracy:0.16 loss: 305.052 (lr:0.00010169382703088112)
15950: accuracy:0.12 loss: 308.831 (lr:0.0001016853790333206)
15960: accuracy:0.15 loss: 310.713 (lr:0.0001016769731703237)
15970: accuracy:0.13 loss: 308.334 (lr:0.0001016686092317434)
15980: accuracy:0.11 loss: 306.493 (lr:0.0001016602870084808)
15990: accuracy:0.18 loss: 300.307 (lr:0.00010165200629247988)
16000: accuracy:0.17 loss: 289.265 (lr:0.00010164376687672231)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
16000: ********* epoch 2 ********* test accuracy for all:0.137986 test loss: 304.305
16000: ********* epoch 2 ********* test accuracy for mode 0:0.0075 test loss: 415.929
16000: ********* epoch 2 ********* test accuracy for mode 1:0.04 test loss: 364.807
16000: ********* epoch 2 ********* test accuracy for mode 2:0.0005 test loss: 334.194
16000: ********* epoch 2 ********* test accuracy for mode 24:0.2315 test loss: 298.908
16000: ********* epoch 2 ********* test accuracy for mode 25:0.004 test loss: 298.062
16000: ********* epoch 2 ********* test accuracy for mode 26:0.144 test loss: 247.888
16000: ********* epoch 2 ********* test accuracy for mode 27:0.398 test loss: 290.158
16000: ********* epoch 2 ********* test accuracy for mode 28:0.0 test loss: 299.737
16000: ********* epoch 2 ********* test accuracy for mode 29:0.0 test loss: 321.938
16000: ********* epoch 2 ********* test accuracy for mode 30:0.0225 test loss: 324.487
16000: ********* epoch 2 ********* test accuracy for mode 31:0.1915 test loss: 325.876
16000: ********* epoch 2 ********* test accuracy for mode 32:0.1555 test loss: 312.808
16000: ********* epoch 2 ********* test accuracy for mode 33:0.26 test loss: 319.252
16000: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 323.0
16000: ********* epoch 2 ********* test accuracy for mode 35:0.007 test loss: 465.991
16000: ********* epoch 2 ********* test accuracy for mode 36:0.396 test loss: 434.841
16010: accuracy:0.13 loss: 295.965 (lr:0.00010163556855522228)
16020: accuracy:0.14 loss: 296.733 (lr:0.00010162741112302131)
16030: accuracy:0.1 loss: 292.557 (lr:0.00010161929437618318)
16040: accuracy:0.14 loss: 310.942 (lr:0.0001016112181117888)
16050: accuracy:0.14 loss: 300.51 (lr:0.00010160318212793113)
16060: accuracy:0.12 loss: 299.506 (lr:0.00010159518622371015)
16070: accuracy:0.14 loss: 308.208 (lr:0.00010158723019922785)
16080: accuracy:0.18 loss: 286.304 (lr:0.0001015793138555832)
16090: accuracy:0.21 loss: 289.184 (lr:0.00010157143699486719)
16100: accuracy:0.04 loss: 302.289 (lr:0.0001015635994201579)
16110: accuracy:0.12 loss: 305.43 (lr:0.00010155580093551555)
16120: accuracy:0.18 loss: 298.788 (lr:0.00010154804134597762)
16130: accuracy:0.1 loss: 313.085 (lr:0.00010154032045755397)
16140: accuracy:0.18 loss: 307.111 (lr:0.00010153263807722199)
16150: accuracy:0.16 loss: 293.792 (lr:0.00010152499401292175)
16160: accuracy:0.14 loss: 286.106 (lr:0.00010151738807355128)
16170: accuracy:0.11 loss: 298.126 (lr:0.00010150982006896166)
16180: accuracy:0.15 loss: 294.803 (lr:0.00010150228980995241)
16190: accuracy:0.17 loss: 296.195 (lr:0.00010149479710826665)
16200: accuracy:0.14 loss: 313.14 (lr:0.00010148734177658646)
16210: accuracy:0.11 loss: 296.738 (lr:0.00010147992362852813)
16220: accuracy:0.11 loss: 307.366 (lr:0.0001014725424786376)
16230: accuracy:0.18 loss: 308.176 (lr:0.00010146519814238575)
16240: accuracy:0.12 loss: 305.769 (lr:0.00010145789043616376)
16250: accuracy:0.21 loss: 299.898 (lr:0.0001014506191772786)
16260: accuracy:0.12 loss: 277.137 (lr:0.00010144338418394842)
16270: accuracy:0.15 loss: 314.329 (lr:0.00010143618527529803)
16280: accuracy:0.11 loss: 297.696 (lr:0.00010142902227135431)
16290: accuracy:0.14 loss: 284.606 (lr:0.00010142189499304181)
16300: accuracy:0.17 loss: 303.335 (lr:0.0001014148032621782)
16310: accuracy:0.12 loss: 292.23 (lr:0.00010140774690146983)
16320: accuracy:0.11 loss: 310.068 (lr:0.0001014007257345073)
16330: accuracy:0.14 loss: 283.544 (lr:0.0001013937395857611)
16340: accuracy:0.22 loss: 289.34 (lr:0.00010138678828057715)
16350: accuracy:0.15 loss: 293.285 (lr:0.00010137987164517241)
16360: accuracy:0.15 loss: 287.422 (lr:0.00010137298950663069)
16370: accuracy:0.1 loss: 296.543 (lr:0.00010136614169289814)
16380: accuracy:0.17 loss: 288.224 (lr:0.00010135932803277907)
16390: accuracy:0.17 loss: 294.405 (lr:0.00010135254835593161)
16400: accuracy:0.18 loss: 290.512 (lr:0.0001013458024928635)
16410: accuracy:0.21 loss: 284.72 (lr:0.0001013390902749278)
16420: accuracy:0.08 loss: 294.112 (lr:0.00010133241153431872)
16430: accuracy:0.14 loss: 300.239 (lr:0.0001013257661040674)
16440: accuracy:0.14 loss: 288.506 (lr:0.00010131915381803773)
16450: accuracy:0.1 loss: 293.679 (lr:0.00010131257451092222)
16460: accuracy:0.15 loss: 293.097 (lr:0.00010130602801823783)
16470: accuracy:0.13 loss: 299.481 (lr:0.00010129951417632193)
16480: accuracy:0.1 loss: 284.292 (lr:0.00010129303282232813)
16490: accuracy:0.14 loss: 292.22 (lr:0.00010128658379422221)
16500: accuracy:0.13 loss: 288.785 (lr:0.00010128016693077818)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
16500: ********* epoch 2 ********* test accuracy for all:0.146324 test loss: 298.39
16500: ********* epoch 2 ********* test accuracy for mode 0:0.003 test loss: 416.389
16500: ********* epoch 2 ********* test accuracy for mode 1:0.0595 test loss: 359.258
16500: ********* epoch 2 ********* test accuracy for mode 2:0.008 test loss: 327.962
16500: ********* epoch 2 ********* test accuracy for mode 24:0.288 test loss: 291.943
16500: ********* epoch 2 ********* test accuracy for mode 25:0.1085 test loss: 285.221
16500: ********* epoch 2 ********* test accuracy for mode 26:0.0605 test loss: 246.99
16500: ********* epoch 2 ********* test accuracy for mode 27:0.3845 test loss: 285.765
16500: ********* epoch 2 ********* test accuracy for mode 28:0.0 test loss: 298.226
16500: ********* epoch 2 ********* test accuracy for mode 29:0.001 test loss: 316.712
16500: ********* epoch 2 ********* test accuracy for mode 30:0.054 test loss: 319.161
16500: ********* epoch 2 ********* test accuracy for mode 31:0.24 test loss: 316.585
16500: ********* epoch 2 ********* test accuracy for mode 32:0.1455 test loss: 305.388
16500: ********* epoch 2 ********* test accuracy for mode 33:0.191 test loss: 312.173
16500: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 312.774
16500: ********* epoch 2 ********* test accuracy for mode 35:0.0075 test loss: 459.911
16500: ********* epoch 2 ********* test accuracy for mode 36:0.3915 test loss: 436.307
16510: accuracy:0.18 loss: 294.644 (lr:0.00010127378207157408)
16520: accuracy:0.14 loss: 294.129 (lr:0.00010126742905698812)
16530: accuracy:0.18 loss: 283.839 (lr:0.00010126110772819459)
16540: accuracy:0.1 loss: 311.575 (lr:0.00010125481792715995)
16550: accuracy:0.12 loss: 294.137 (lr:0.00010124855949663884)
16560: accuracy:0.19 loss: 274.112 (lr:0.00010124233228017018)
16570: accuracy:0.11 loss: 300.066 (lr:0.00010123613612207323)
16580: accuracy:0.14 loss: 294.168 (lr:0.00010122997086744372)
16590: accuracy:0.15 loss: 302.262 (lr:0.00010122383636214995)
16600: accuracy:0.14 loss: 290.649 (lr:0.00010121773245282897)
16610: accuracy:0.17 loss: 275.451 (lr:0.00010121165898688274)
16620: accuracy:0.15 loss: 290.793 (lr:0.00010120561581247429)
16630: accuracy:0.14 loss: 290.8 (lr:0.00010119960277852394)
16640: accuracy:0.19 loss: 285.537 (lr:0.00010119361973470553)
16650: accuracy:0.11 loss: 287.525 (lr:0.00010118766653144267)
16660: accuracy:0.07 loss: 305.514 (lr:0.00010118174301990494)
16670: accuracy:0.17 loss: 283.654 (lr:0.00010117584905200426)
16680: accuracy:0.15 loss: 295.067 (lr:0.00010116998448039112)
16690: accuracy:0.17 loss: 289.465 (lr:0.00010116414915845094)
16700: accuracy:0.17 loss: 295.096 (lr:0.00010115834294030034)
16710: accuracy:0.17 loss: 293.612 (lr:0.00010115256568078358)
16720: accuracy:0.17 loss: 290.371 (lr:0.00010114681723546888)
16730: accuracy:0.13 loss: 287.852 (lr:0.00010114109746064479)
16740: accuracy:0.22 loss: 276.206 (lr:0.00010113540621331665)
16750: accuracy:0.17 loss: 297.804 (lr:0.00010112974335120297)
16760: accuracy:0.17 loss: 293.408 (lr:0.00010112410873273191)
16770: accuracy:0.12 loss: 290.996 (lr:0.00010111850221703772)
16780: accuracy:0.24 loss: 279.977 (lr:0.00010111292366395723)
16790: accuracy:0.14 loss: 288.402 (lr:0.00010110737293402628)
16800: accuracy:0.17 loss: 299.71 (lr:0.00010110184988847636)
16810: accuracy:0.24 loss: 269.679 (lr:0.00010109635438923105)
16820: accuracy:0.18 loss: 279.248 (lr:0.00010109088629890257)
16830: accuracy:0.22 loss: 291.924 (lr:0.00010108544548078837)
16840: accuracy:0.12 loss: 290.743 (lr:0.00010108003179886773)
16850: accuracy:0.12 loss: 295.295 (lr:0.00010107464511779831)
16860: accuracy:0.21 loss: 285.723 (lr:0.00010106928530291281)
16870: accuracy:0.14 loss: 289.211 (lr:0.00010106395222021556)
16880: accuracy:0.17 loss: 293.577 (lr:0.00010105864573637925)
16890: accuracy:0.12 loss: 291.052 (lr:0.00010105336571874149)
16900: accuracy:0.13 loss: 289.876 (lr:0.00010104811203530154)
16910: accuracy:0.12 loss: 291.214 (lr:0.00010104288455471708)
16920: accuracy:0.18 loss: 290.701 (lr:0.0001010376831463008)
16930: accuracy:0.16 loss: 283.999 (lr:0.00010103250768001722)
16940: accuracy:0.26 loss: 264.377 (lr:0.00010102735802647941)
16950: accuracy:0.2 loss: 286.241 (lr:0.00010102223405694579)
16960: accuracy:0.15 loss: 280.041 (lr:0.00010101713564331682)
16970: accuracy:0.13 loss: 284.351 (lr:0.00010101206265813191)
16980: accuracy:0.17 loss: 280.904 (lr:0.00010100701497456617)
16990: accuracy:0.19 loss: 281.004 (lr:0.00010100199246642724)
17000: accuracy:0.18 loss: 261.166 (lr:0.00010099699500815216)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
17000: ********* epoch 2 ********* test accuracy for all:0.154824 test loss: 292.627
17000: ********* epoch 2 ********* test accuracy for mode 0:0.013 test loss: 391.274
17000: ********* epoch 2 ********* test accuracy for mode 1:0.0795 test loss: 355.948
17000: ********* epoch 2 ********* test accuracy for mode 2:0.0285 test loss: 316.185
17000: ********* epoch 2 ********* test accuracy for mode 24:0.3055 test loss: 291.362
17000: ********* epoch 2 ********* test accuracy for mode 25:0.1635 test loss: 279.525
17000: ********* epoch 2 ********* test accuracy for mode 26:0.0215 test loss: 253.994
17000: ********* epoch 2 ********* test accuracy for mode 27:0.4715 test loss: 272.824
17000: ********* epoch 2 ********* test accuracy for mode 28:0.0005 test loss: 286.993
17000: ********* epoch 2 ********* test accuracy for mode 29:0.0725 test loss: 302.635
17000: ********* epoch 2 ********* test accuracy for mode 30:0.092 test loss: 305.25
17000: ********* epoch 2 ********* test accuracy for mode 31:0.2065 test loss: 307.025
17000: ********* epoch 2 ********* test accuracy for mode 32:0.207 test loss: 292.379
17000: ********* epoch 2 ********* test accuracy for mode 33:0.083 test loss: 304.948
17000: ********* epoch 2 ********* test accuracy for mode 34:0.0055 test loss: 298.569
17000: ********* epoch 2 ********* test accuracy for mode 35:0.0055 test loss: 450.727
17000: ********* epoch 2 ********* test accuracy for mode 36:0.112 test loss: 437.081
17010: accuracy:0.18 loss: 293.414 (lr:0.00010099202247480422)
17020: accuracy:0.15 loss: 297.16 (lr:0.00010098707474206979)
17030: accuracy:0.11 loss: 290.501 (lr:0.00010098215168625534)
17040: accuracy:0.17 loss: 279.596 (lr:0.00010097725318428421)
17050: accuracy:0.18 loss: 288.048 (lr:0.00010097237911369357)
17060: accuracy:0.17 loss: 285.15 (lr:0.00010096752935263143)
17070: accuracy:0.17 loss: 303.247 (lr:0.00010096270377985349)
17080: accuracy:0.19 loss: 277.776 (lr:0.00010095790227472018)
17090: accuracy:0.12 loss: 287.56 (lr:0.00010095312471719364)
17100: accuracy:0.21 loss: 291.385 (lr:0.00010094837098783466)
17110: accuracy:0.2 loss: 283.344 (lr:0.00010094364096779978)
17120: accuracy:0.22 loss: 274.786 (lr:0.00010093893453883824)
17130: accuracy:0.1 loss: 290.577 (lr:0.00010093425158328908)
17140: accuracy:0.13 loss: 291.714 (lr:0.00010092959198407815)
17150: accuracy:0.14 loss: 287.093 (lr:0.00010092495562471525)
17160: accuracy:0.15 loss: 282.444 (lr:0.00010092034238929114)
17170: accuracy:0.21 loss: 293.457 (lr:0.00010091575216247468)
17180: accuracy:0.2 loss: 285.547 (lr:0.00010091118482951)
17190: accuracy:0.19 loss: 283.414 (lr:0.0001009066402762135)
17200: accuracy:0.15 loss: 285.255 (lr:0.00010090211838897114)
17210: accuracy:0.25 loss: 256.477 (lr:0.00010089761905473549)
17220: accuracy:0.11 loss: 298.523 (lr:0.00010089314216102294)
17230: accuracy:0.16 loss: 310.474 (lr:0.00010088868759591095)
17240: accuracy:0.12 loss: 291.35 (lr:0.00010088425524803514)
17250: accuracy:0.16 loss: 274.498 (lr:0.00010087984500658659)
17260: accuracy:0.16 loss: 290.429 (lr:0.00010087545676130902)
17270: accuracy:0.17 loss: 275.935 (lr:0.00010087109040249608)
17280: accuracy:0.21 loss: 281.734 (lr:0.00010086674582098858)
17290: accuracy:0.15 loss: 288.032 (lr:0.00010086242290817175)
17300: accuracy:0.2 loss: 286.083 (lr:0.00010085812155597252)
17310: accuracy:0.16 loss: 285.444 (lr:0.00010085384165685691)
17320: accuracy:0.22 loss: 285.152 (lr:0.00010084958310382718)
17330: accuracy:0.19 loss: 271.748 (lr:0.0001008453457904193)
17340: accuracy:0.14 loss: 278.49 (lr:0.0001008411296107002)
17350: accuracy:0.18 loss: 279.3 (lr:0.00010083693445926518)
17360: accuracy:0.23 loss: 282.401 (lr:0.00010083276023123524)
17370: accuracy:0.16 loss: 297.567 (lr:0.00010082860682225445)
17380: accuracy:0.21 loss: 284.244 (lr:0.00010082447412848736)
17390: accuracy:0.12 loss: 287.117 (lr:0.00010082036204661644)
17400: accuracy:0.22 loss: 276.348 (lr:0.0001008162704738394)
17410: accuracy:0.17 loss: 274.878 (lr:0.00010081219930786673)
17420: accuracy:0.14 loss: 290.215 (lr:0.00010080814844691906)
17430: accuracy:0.22 loss: 280.558 (lr:0.00010080411778972465)
17440: accuracy:0.17 loss: 280.099 (lr:0.00010080010723551686)
17450: accuracy:0.1 loss: 299.883 (lr:0.00010079611668403163)
17460: accuracy:0.27 loss: 280.326 (lr:0.00010079214603550498)
17470: accuracy:0.18 loss: 284.058 (lr:0.00010078819519067047)
17480: accuracy:0.16 loss: 279.953 (lr:0.00010078426405075677)
17490: accuracy:0.15 loss: 265.538 (lr:0.00010078035251748518)
17500: accuracy:0.17 loss: 286.344 (lr:0.00010077646049306718)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
17500: ********* epoch 2 ********* test accuracy for all:0.165743 test loss: 289.643
17500: ********* epoch 2 ********* test accuracy for mode 0:0.0055 test loss: 389.984
17500: ********* epoch 2 ********* test accuracy for mode 1:0.1025 test loss: 355.603
17500: ********* epoch 2 ********* test accuracy for mode 2:0.0775 test loss: 312.771
17500: ********* epoch 2 ********* test accuracy for mode 24:0.2115 test loss: 296.303
17500: ********* epoch 2 ********* test accuracy for mode 25:0.272 test loss: 278.11
17500: ********* epoch 2 ********* test accuracy for mode 26:0.0295 test loss: 249.476
17500: ********* epoch 2 ********* test accuracy for mode 27:0.308 test loss: 286.16
17500: ********* epoch 2 ********* test accuracy for mode 28:0.028 test loss: 292.644
17500: ********* epoch 2 ********* test accuracy for mode 29:0.1485 test loss: 304.863
17500: ********* epoch 2 ********* test accuracy for mode 30:0.08 test loss: 307.002
17500: ********* epoch 2 ********* test accuracy for mode 31:0.2365 test loss: 309.852
17500: ********* epoch 2 ********* test accuracy for mode 32:0.1125 test loss: 295.99
17500: ********* epoch 2 ********* test accuracy for mode 33:0.1925 test loss: 302.316
17500: ********* epoch 2 ********* test accuracy for mode 34:0.0005 test loss: 300.133
17500: ********* epoch 2 ********* test accuracy for mode 35:0.002 test loss: 444.696
17500: ********* epoch 2 ********* test accuracy for mode 36:0.3265 test loss: 432.299
17510: accuracy:0.2 loss: 270.739 (lr:0.00010077258788020195)
17520: accuracy:0.2 loss: 284.646 (lr:0.00010076873458207397)
17530: accuracy:0.22 loss: 273.362 (lr:0.00010076490050235057)
17540: accuracy:0.14 loss: 278.854 (lr:0.00010076108554517956)
17550: accuracy:0.25 loss: 270.405 (lr:0.00010075728961518684)
17560: accuracy:0.22 loss: 266.46 (lr:0.00010075351261747393)
17570: accuracy:0.15 loss: 275.802 (lr:0.00010074975445761569)
17580: accuracy:0.18 loss: 288.615 (lr:0.00010074601504165796)
17590: accuracy:0.2 loss: 291.059 (lr:0.00010074229427611512)
17600: accuracy:0.15 loss: 282.415 (lr:0.00010073859206796784)
17610: accuracy:0.12 loss: 295.691 (lr:0.00010073490832466073)
17620: accuracy:0.12 loss: 281.926 (lr:0.00010073124295410002)
17630: accuracy:0.15 loss: 273.459 (lr:0.00010072759586465124)
17640: accuracy:0.15 loss: 312.726 (lr:0.00010072396696513697)
17650: accuracy:0.24 loss: 273.342 (lr:0.00010072035616483453)
17660: accuracy:0.25 loss: 258.819 (lr:0.00010071676337347374)
17670: accuracy:0.15 loss: 299.539 (lr:0.00010071318850123462)
17680: accuracy:0.15 loss: 283.667 (lr:0.00010070963145874517)
17690: accuracy:0.15 loss: 300.41 (lr:0.00010070609215707916)
17700: accuracy:0.11 loss: 291.517 (lr:0.00010070257050775384)
17710: accuracy:0.21 loss: 275.368 (lr:0.00010069906642272781)
17720: accuracy:0.16 loss: 278.813 (lr:0.00010069557981439876)
17730: accuracy:0.2 loss: 290.777 (lr:0.0001006921105956013)
17740: accuracy:0.24 loss: 259.313 (lr:0.00010068865867960476)
17750: accuracy:0.18 loss: 276.829 (lr:0.0001006852239801111)
17760: accuracy:0.13 loss: 299.113 (lr:0.00010068180641125263)
17770: accuracy:0.18 loss: 277.423 (lr:0.00010067840588758994)
17780: accuracy:0.16 loss: 279.534 (lr:0.00010067502232410977)
17790: accuracy:0.21 loss: 276.071 (lr:0.00010067165563622287)
17800: accuracy:0.21 loss: 283.852 (lr:0.00010066830573976186)
17810: accuracy:0.21 loss: 281.659 (lr:0.00010066497255097915)
17820: accuracy:0.14 loss: 290.602 (lr:0.00010066165598654485)
17830: accuracy:0.14 loss: 297.881 (lr:0.00010065835596354466)
17840: accuracy:0.16 loss: 295.395 (lr:0.00010065507239947787)
17850: accuracy:0.17 loss: 282.754 (lr:0.00010065180521225517)
17860: accuracy:0.18 loss: 288.691 (lr:0.00010064855432019673)
17870: accuracy:0.17 loss: 273.051 (lr:0.00010064531964203007)
17880: accuracy:0.18 loss: 279.927 (lr:0.00010064210109688808)
17890: accuracy:0.22 loss: 275.026 (lr:0.00010063889860430694)
17900: accuracy:0.14 loss: 277.815 (lr:0.0001006357120842242)
17910: accuracy:0.17 loss: 285.7 (lr:0.00010063254145697666)
17920: accuracy:0.17 loss: 282.289 (lr:0.0001006293866432985)
17930: accuracy:0.14 loss: 285.537 (lr:0.0001006262475643192)
17940: accuracy:0.1 loss: 289.879 (lr:0.00010062312414156163)
17950: accuracy:0.17 loss: 285.515 (lr:0.00010062001629694006)
17960: accuracy:0.13 loss: 283.659 (lr:0.00010061692395275819)
17970: accuracy:0.17 loss: 267.3 (lr:0.00010061384703170727)
17980: accuracy:0.19 loss: 282.995 (lr:0.00010061078545686413)
17990: accuracy:0.23 loss: 276.592 (lr:0.0001006077391516892)
18000: accuracy:0.13 loss: 281.899 (lr:0.00010060470804002474)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
18000: ********* epoch 2 ********* test accuracy for all:0.171068 test loss: 287.907
18000: ********* epoch 2 ********* test accuracy for mode 0:0.0025 test loss: 385.284
18000: ********* epoch 2 ********* test accuracy for mode 1:0.1345 test loss: 353.209
18000: ********* epoch 2 ********* test accuracy for mode 2:0.0545 test loss: 314.859
18000: ********* epoch 2 ********* test accuracy for mode 24:0.2655 test loss: 287.384
18000: ********* epoch 2 ********* test accuracy for mode 25:0.2635 test loss: 269.936
18000: ********* epoch 2 ********* test accuracy for mode 26:0.0285 test loss: 244.553
18000: ********* epoch 2 ********* test accuracy for mode 27:0.3725 test loss: 274.86
18000: ********* epoch 2 ********* test accuracy for mode 28:0.0245 test loss: 287.378
18000: ********* epoch 2 ********* test accuracy for mode 29:0.162 test loss: 299.545
18000: ********* epoch 2 ********* test accuracy for mode 30:0.1005 test loss: 299.866
18000: ********* epoch 2 ********* test accuracy for mode 31:0.209 test loss: 305.787
18000: ********* epoch 2 ********* test accuracy for mode 32:0.1095 test loss: 293.029
18000: ********* epoch 2 ********* test accuracy for mode 33:0.205 test loss: 300.303
18000: ********* epoch 2 ********* test accuracy for mode 34:0.0025 test loss: 298.419
18000: ********* epoch 2 ********* test accuracy for mode 35:0.004 test loss: 449.645
18000: ********* epoch 2 ********* test accuracy for mode 36:0.312 test loss: 428.661
18010: accuracy:0.19 loss: 275.198 (lr:0.00010060169204609276)
18020: accuracy:0.16 loss: 298.273 (lr:0.00010059869109449328)
18030: accuracy:0.14 loss: 266.117 (lr:0.00010059570511020233)
18040: accuracy:0.14 loss: 279.977 (lr:0.00010059273401857017)
18050: accuracy:0.14 loss: 276.253 (lr:0.00010058977774531935)
18060: accuracy:0.17 loss: 280.507 (lr:0.00010058683621654287)
18070: accuracy:0.22 loss: 274.47 (lr:0.00010058390935870238)
18080: accuracy:0.21 loss: 278.861 (lr:0.00010058099709862627)
18090: accuracy:0.21 loss: 266.943 (lr:0.00010057809936350787)
18100: accuracy:0.13 loss: 273.006 (lr:0.00010057521608090368)
18110: accuracy:0.14 loss: 278.778 (lr:0.00010057234717873147)
18120: accuracy:0.14 loss: 270.88 (lr:0.00010056949258526853)
18130: accuracy:0.13 loss: 281.21 (lr:0.0001005666522291499)
18140: accuracy:0.18 loss: 274.184 (lr:0.0001005638260393665)
18150: accuracy:0.12 loss: 284.957 (lr:0.00010056101394526346)
18160: accuracy:0.17 loss: 276.402 (lr:0.00010055821587653825)
18170: accuracy:0.22 loss: 285.832 (lr:0.00010055543176323904)
18180: accuracy:0.18 loss: 283.927 (lr:0.00010055266153576285)
18190: accuracy:0.1 loss: 294.049 (lr:0.00010054990512485383)
18200: accuracy:0.27 loss: 286.638 (lr:0.00010054716246160157)
18210: accuracy:0.24 loss: 277.107 (lr:0.00010054443347743935)
18220: accuracy:0.2 loss: 274.903 (lr:0.00010054171810414242)
18230: accuracy:0.21 loss: 274.772 (lr:0.0001005390162738263)
18240: accuracy:0.11 loss: 295.567 (lr:0.00010053632791894512)
18250: accuracy:0.11 loss: 281.068 (lr:0.00010053365297228983)
18260: accuracy:0.16 loss: 290.059 (lr:0.00010053099136698665)
18270: accuracy:0.19 loss: 265.586 (lr:0.0001005283430364953)
18280: accuracy:0.13 loss: 278.075 (lr:0.00010052570791460738)
18290: accuracy:0.27 loss: 266.32 (lr:0.0001005230859354447)
18300: accuracy:0.24 loss: 268.699 (lr:0.00010052047703345765)
18310: accuracy:0.23 loss: 259.269 (lr:0.00010051788114342355)
18320: accuracy:0.15 loss: 273.985 (lr:0.000100515298200445)
18330: accuracy:0.14 loss: 285.492 (lr:0.00010051272813994832)
18340: accuracy:0.19 loss: 276.63 (lr:0.00010051017089768183)
18350: accuracy:0.2 loss: 288.958 (lr:0.00010050762640971435)
18360: accuracy:0.13 loss: 271.923 (lr:0.00010050509461243356)
18370: accuracy:0.16 loss: 276.802 (lr:0.00010050257544254438)
18380: accuracy:0.15 loss: 284.901 (lr:0.00010050006883706744)
18390: accuracy:0.17 loss: 277.077 (lr:0.00010049757473333748)
18400: accuracy:0.17 loss: 262.221 (lr:0.00010049509306900176)
18410: accuracy:0.18 loss: 270.264 (lr:0.00010049262378201855)
18420: accuracy:0.17 loss: 270.315 (lr:0.00010049016681065556)
18430: accuracy:0.27 loss: 257.635 (lr:0.00010048772209348836)
18440: accuracy:0.16 loss: 289.637 (lr:0.00010048528956939889)
18450: accuracy:0.2 loss: 260.743 (lr:0.00010048286917757394)
18460: accuracy:0.16 loss: 264.728 (lr:0.00010048046085750358)
18470: accuracy:0.2 loss: 262.354 (lr:0.00010047806454897968)
18480: accuracy:0.18 loss: 277.955 (lr:0.00010047568019209441)
18490: accuracy:0.28 loss: 251.423 (lr:0.00010047330772723871)
18500: accuracy:0.19 loss: 275.915 (lr:0.00010047094709510084)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
18500: ********* epoch 2 ********* test accuracy for all:0.165946 test loss: 284.74
18500: ********* epoch 2 ********* test accuracy for mode 0:0.002 test loss: 375.25
18500: ********* epoch 2 ********* test accuracy for mode 1:0.176 test loss: 343.776
18500: ********* epoch 2 ********* test accuracy for mode 2:0.003 test loss: 317.825
18500: ********* epoch 2 ********* test accuracy for mode 24:0.2865 test loss: 272.139
18500: ********* epoch 2 ********* test accuracy for mode 25:0.248 test loss: 257.197
18500: ********* epoch 2 ********* test accuracy for mode 26:0.025 test loss: 238.162
18500: ********* epoch 2 ********* test accuracy for mode 27:0.4175 test loss: 257.377
18500: ********* epoch 2 ********* test accuracy for mode 28:0.073 test loss: 270.382
18500: ********* epoch 2 ********* test accuracy for mode 29:0.202 test loss: 281.195
18500: ********* epoch 2 ********* test accuracy for mode 30:0.091 test loss: 286.502
18500: ********* epoch 2 ********* test accuracy for mode 31:0.284 test loss: 291.078
18500: ********* epoch 2 ********* test accuracy for mode 32:0.0335 test loss: 285.987
18500: ********* epoch 2 ********* test accuracy for mode 33:0.255 test loss: 291.706
18500: ********* epoch 2 ********* test accuracy for mode 34:0.0005 test loss: 296.056
18500: ********* epoch 2 ********* test accuracy for mode 35:0.001 test loss: 430.985
18500: ********* epoch 2 ********* test accuracy for mode 36:0.128 test loss: 404.225
18510: accuracy:0.19 loss: 270.011 (lr:0.00010046859823666488)
18520: accuracy:0.19 loss: 261.298 (lr:0.00010046626109320924)
18530: accuracy:0.25 loss: 279.12 (lr:0.00010046393560630522)
18540: accuracy:0.17 loss: 257.504 (lr:0.00010046162171781551)
18550: accuracy:0.25 loss: 257.504 (lr:0.0001004593193698928)
18560: accuracy:0.16 loss: 269.34 (lr:0.00010045702850497825)
18570: accuracy:0.15 loss: 266.049 (lr:0.00010045474906580013)
18580: accuracy:0.1 loss: 298.469 (lr:0.00010045248099537235)
18590: accuracy:0.29 loss: 278.711 (lr:0.00010045022423699302)
18600: accuracy:0.16 loss: 270.445 (lr:0.00010044797873424305)
18610: accuracy:0.22 loss: 254.548 (lr:0.00010044574443098478)
18620: accuracy:0.16 loss: 297.269 (lr:0.0001004435212713605)
18630: accuracy:0.3 loss: 272.166 (lr:0.0001004413091997911)
18640: accuracy:0.21 loss: 274.142 (lr:0.00010043910816097468)
18650: accuracy:0.19 loss: 271.032 (lr:0.00010043691809988516)
18660: accuracy:0.09 loss: 279.824 (lr:0.00010043473896177089)
18670: accuracy:0.2 loss: 281.832 (lr:0.0001004325706921533)
18680: accuracy:0.17 loss: 278.018 (lr:0.00010043041323682555)
18690: accuracy:0.16 loss: 271.866 (lr:0.00010042826654185114)
18700: accuracy:0.19 loss: 277.696 (lr:0.00010042613055356258)
18710: accuracy:0.21 loss: 276.945 (lr:0.00010042400521856005)
18720: accuracy:0.19 loss: 292.942 (lr:0.00010042189048371008)
18730: accuracy:0.17 loss: 282.801 (lr:0.00010041978629614416)
18740: accuracy:0.19 loss: 288.187 (lr:0.00010041769260325751)
18750: accuracy:0.16 loss: 290.379 (lr:0.0001004156093527077)
18760: accuracy:0.15 loss: 272.251 (lr:0.00010041353649241336)
18770: accuracy:0.2 loss: 269.226 (lr:0.00010041147397055287)
18780: accuracy:0.21 loss: 279.854 (lr:0.00010040942173556306)
18790: accuracy:0.2 loss: 282.364 (lr:0.00010040737973613798)
18800: accuracy:0.22 loss: 264.642 (lr:0.0001004053479212275)
18810: accuracy:0.27 loss: 277.896 (lr:0.00010040332624003617)
18820: accuracy:0.2 loss: 268.312 (lr:0.00010040131464202186)
18830: accuracy:0.2 loss: 279.985 (lr:0.0001003993130768945)
18840: accuracy:0.24 loss: 272.01 (lr:0.00010039732149461485)
18850: accuracy:0.2 loss: 270.558 (lr:0.00010039533984539326)
18860: accuracy:0.16 loss: 276.216 (lr:0.0001003933680796884)
18870: accuracy:0.16 loss: 271.99 (lr:0.00010039140614820602)
18880: accuracy:0.2 loss: 273.642 (lr:0.00010038945400189774)
18890: accuracy:0.2 loss: 274.519 (lr:0.00010038751159195978)
18900: accuracy:0.2 loss: 261.311 (lr:0.0001003855788698318)
18910: accuracy:0.17 loss: 264.891 (lr:0.00010038365578719566)
18920: accuracy:0.23 loss: 262.101 (lr:0.00010038174229597416)
18930: accuracy:0.18 loss: 282.766 (lr:0.00010037983834832996)
18940: accuracy:0.14 loss: 257.183 (lr:0.00010037794389666424)
18950: accuracy:0.25 loss: 260.896 (lr:0.00010037605889361564)
18960: accuracy:0.16 loss: 273.867 (lr:0.00010037418329205895)
18970: accuracy:0.23 loss: 264.813 (lr:0.00010037231704510406)
18980: accuracy:0.17 loss: 291.029 (lr:0.00010037046010609468)
18990: accuracy:0.15 loss: 283.021 (lr:0.00010036861242860726)
19000: accuracy:0.18 loss: 282.512 (lr:0.00010036677396644973)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
19000: ********* epoch 2 ********* test accuracy for all:0.173162 test loss: 284.717
19000: ********* epoch 2 ********* test accuracy for mode 0:0.0045 test loss: 379.734
19000: ********* epoch 2 ********* test accuracy for mode 1:0.196 test loss: 345.278
19000: ********* epoch 2 ********* test accuracy for mode 2:0.015 test loss: 305.982
19000: ********* epoch 2 ********* test accuracy for mode 24:0.191 test loss: 289.809
19000: ********* epoch 2 ********* test accuracy for mode 25:0.424 test loss: 261.118
19000: ********* epoch 2 ********* test accuracy for mode 26:0.03 test loss: 232.518
19000: ********* epoch 2 ********* test accuracy for mode 27:0.2865 test loss: 268.697
19000: ********* epoch 2 ********* test accuracy for mode 28:0.171 test loss: 277.068
19000: ********* epoch 2 ********* test accuracy for mode 29:0.228 test loss: 285.88
19000: ********* epoch 2 ********* test accuracy for mode 30:0.052 test loss: 285.839
19000: ********* epoch 2 ********* test accuracy for mode 31:0.303 test loss: 284.732
19000: ********* epoch 2 ********* test accuracy for mode 32:0.137 test loss: 274.468
19000: ********* epoch 2 ********* test accuracy for mode 33:0.191 test loss: 286.458
19000: ********* epoch 2 ********* test accuracy for mode 34:0.0045 test loss: 288.459
19000: ********* epoch 2 ********* test accuracy for mode 35:0.003 test loss: 435.099
19000: ********* epoch 2 ********* test accuracy for mode 36:0.053 test loss: 431.005
19010: accuracy:0.18 loss: 278.344 (lr:0.00010036494467366048)
19020: accuracy:0.21 loss: 286.14 (lr:0.00010036312450450709)
19030: accuracy:0.22 loss: 278.376 (lr:0.00010036131341348521)
19040: accuracy:0.19 loss: 270.196 (lr:0.00010035951135531748)
19050: accuracy:0.29 loss: 253.073 (lr:0.00010035771828495238)
19060: accuracy:0.14 loss: 289.182 (lr:0.00010035593415756301)
19070: accuracy:0.1 loss: 299.351 (lr:0.00010035415892854614)
19080: accuracy:0.21 loss: 275.176 (lr:0.00010035239255352092)
19090: accuracy:0.21 loss: 270.506 (lr:0.00010035063498832788)
19100: accuracy:0.2 loss: 266.286 (lr:0.00010034888618902782)
19110: accuracy:0.19 loss: 274.36 (lr:0.00010034714611190066)
19120: accuracy:0.15 loss: 291.816 (lr:0.00010034541471344439)
19130: accuracy:0.19 loss: 282.201 (lr:0.00010034369195037392)
19140: accuracy:0.2 loss: 261.224 (lr:0.00010034197777962012)
19150: accuracy:0.23 loss: 263.067 (lr:0.00010034027215832863)
19160: accuracy:0.25 loss: 271.709 (lr:0.00010033857504385882)
19170: accuracy:0.17 loss: 270.795 (lr:0.00010033688639378274)
19180: accuracy:0.19 loss: 275.852 (lr:0.00010033520616588404)
19190: accuracy:0.16 loss: 289.33 (lr:0.00010033353431815696)
19200: accuracy:0.27 loss: 272.859 (lr:0.00010033187080880519)
19210: accuracy:0.27 loss: 269.12 (lr:0.00010033021559624093)
19220: accuracy:0.22 loss: 279.527 (lr:0.00010032856863908378)
19230: accuracy:0.19 loss: 281.349 (lr:0.00010032692989615972)
19240: accuracy:0.2 loss: 267.295 (lr:0.00010032529932650008)
19250: accuracy:0.17 loss: 270.033 (lr:0.00010032367688934057)
19260: accuracy:0.21 loss: 279.707 (lr:0.00010032206254412013)
19270: accuracy:0.22 loss: 270.659 (lr:0.00010032045625048007)
19280: accuracy:0.16 loss: 281.292 (lr:0.00010031885796826296)
19290: accuracy:0.17 loss: 276.725 (lr:0.00010031726765751167)
19300: accuracy:0.24 loss: 254.983 (lr:0.00010031568527846835)
19310: accuracy:0.24 loss: 278.411 (lr:0.00010031411079157343)
19320: accuracy:0.2 loss: 272.105 (lr:0.00010031254415746465)
19330: accuracy:0.23 loss: 266.168 (lr:0.00010031098533697608)
19340: accuracy:0.24 loss: 256.197 (lr:0.00010030943429113714)
19350: accuracy:0.23 loss: 275.674 (lr:0.0001003078909811716)
19360: accuracy:0.2 loss: 265.643 (lr:0.00010030635536849662)
19370: accuracy:0.18 loss: 279.539 (lr:0.00010030482741472181)
19380: accuracy:0.19 loss: 268.014 (lr:0.00010030330708164824)
19390: accuracy:0.14 loss: 286.535 (lr:0.00010030179433126752)
19400: accuracy:0.22 loss: 277.35 (lr:0.0001003002891257608)
19410: accuracy:0.18 loss: 264.407 (lr:0.00010029879142749784)
19420: accuracy:0.2 loss: 266.893 (lr:0.00010029730119903615)
19430: accuracy:0.22 loss: 272.034 (lr:0.00010029581840311992)
19440: accuracy:0.23 loss: 266.523 (lr:0.00010029434300267917)
19450: accuracy:0.18 loss: 278.989 (lr:0.00010029287496082883)
19460: accuracy:0.19 loss: 265.268 (lr:0.00010029141424086774)
19470: accuracy:0.18 loss: 272.478 (lr:0.00010028996080627787)
19480: accuracy:0.16 loss: 276.679 (lr:0.00010028851462072326)
19490: accuracy:0.12 loss: 261.581 (lr:0.00010028707564804918)
19500: accuracy:0.2 loss: 256.79 (lr:0.00010028564385228126)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
19500: ********* epoch 3 ********* test accuracy for all:0.175784 test loss: 282.485
19500: ********* epoch 3 ********* test accuracy for mode 0:0.001 test loss: 380.923
19500: ********* epoch 3 ********* test accuracy for mode 1:0.1875 test loss: 346.533
19500: ********* epoch 3 ********* test accuracy for mode 2:0.0515 test loss: 306.416
19500: ********* epoch 3 ********* test accuracy for mode 24:0.2445 test loss: 282.113
19500: ********* epoch 3 ********* test accuracy for mode 25:0.2585 test loss: 261.679
19500: ********* epoch 3 ********* test accuracy for mode 26:0.0245 test loss: 228.382
19500: ********* epoch 3 ********* test accuracy for mode 27:0.351 test loss: 261.6
19500: ********* epoch 3 ********* test accuracy for mode 28:0.167 test loss: 267.73
19500: ********* epoch 3 ********* test accuracy for mode 29:0.3115 test loss: 270.974
19500: ********* epoch 3 ********* test accuracy for mode 30:0.0345 test loss: 279.214
19500: ********* epoch 3 ********* test accuracy for mode 31:0.2615 test loss: 279.189
19500: ********* epoch 3 ********* test accuracy for mode 32:0.182 test loss: 269.007
19500: ********* epoch 3 ********* test accuracy for mode 33:0.2245 test loss: 281.274
19500: ********* epoch 3 ********* test accuracy for mode 34:0.005 test loss: 285.421
19500: ********* epoch 3 ********* test accuracy for mode 35:0.001 test loss: 431.185
19500: ********* epoch 3 ********* test accuracy for mode 36:0.056 test loss: 425.354
19510: accuracy:0.19 loss: 284.215 (lr:0.00010028421919762453)
19520: accuracy:0.23 loss: 262.057 (lr:0.00010028280164846254)
19530: accuracy:0.13 loss: 274.793 (lr:0.00010028139116935648)
19540: accuracy:0.19 loss: 271.938 (lr:0.00010027998772504433)
19550: accuracy:0.22 loss: 254.797 (lr:0.00010027859128043987)
19560: accuracy:0.17 loss: 262.045 (lr:0.00010027720180063194)
19570: accuracy:0.18 loss: 278.589 (lr:0.00010027581925088347)
19580: accuracy:0.17 loss: 260.328 (lr:0.00010027444359663063)
19590: accuracy:0.18 loss: 272.653 (lr:0.00010027307480348199)
19600: accuracy:0.19 loss: 282.212 (lr:0.00010027171283721767)
19610: accuracy:0.22 loss: 278.334 (lr:0.00010027035766378844)
19620: accuracy:0.17 loss: 288.338 (lr:0.00010026900924931487)
19630: accuracy:0.18 loss: 277.59 (lr:0.00010026766756008655)
19640: accuracy:0.17 loss: 279.63 (lr:0.00010026633256256118)
19650: accuracy:0.2 loss: 270.742 (lr:0.00010026500422336374)
19660: accuracy:0.16 loss: 261.534 (lr:0.00010026368250928569)
19670: accuracy:0.28 loss: 256.646 (lr:0.0001002623673872841)
19680: accuracy:0.21 loss: 281.108 (lr:0.00010026105882448086)
19690: accuracy:0.25 loss: 273.897 (lr:0.00010025975678816182)
19700: accuracy:0.23 loss: 281.617 (lr:0.00010025846124577602)
19710: accuracy:0.16 loss: 279.496 (lr:0.00010025717216493483)
19720: accuracy:0.24 loss: 267.635 (lr:0.00010025588951341115)
19730: accuracy:0.23 loss: 264.577 (lr:0.00010025461325913864)
19740: accuracy:0.21 loss: 276.409 (lr:0.00010025334337021086)
19750: accuracy:0.14 loss: 279.363 (lr:0.00010025207981488055)
19760: accuracy:0.24 loss: 260.784 (lr:0.00010025082256155873)
19770: accuracy:0.09 loss: 274.37 (lr:0.000100249571578814)
19780: accuracy:0.17 loss: 272.728 (lr:0.00010024832683537176)
19790: accuracy:0.27 loss: 264.02 (lr:0.00010024708830011332)
19800: accuracy:0.22 loss: 254.95 (lr:0.00010024585594207526)
19810: accuracy:0.2 loss: 291.548 (lr:0.00010024462973044856)
19820: accuracy:0.17 loss: 266.98 (lr:0.00010024340963457785)
19830: accuracy:0.12 loss: 281.628 (lr:0.0001002421956239607)
19840: accuracy:0.23 loss: 264.793 (lr:0.00010024098766824675)
19850: accuracy:0.21 loss: 264.733 (lr:0.00010023978573723707)
19860: accuracy:0.36 loss: 260.542 (lr:0.0001002385898008833)
19870: accuracy:0.23 loss: 272.787 (lr:0.00010023739982928698)
19880: accuracy:0.26 loss: 283.255 (lr:0.00010023621579269875)
19890: accuracy:0.17 loss: 262.52 (lr:0.00010023503766151765)
19900: accuracy:0.14 loss: 293.861 (lr:0.00010023386540629033)
19910: accuracy:0.26 loss: 273.767 (lr:0.00010023269899771035)
19920: accuracy:0.25 loss: 273.887 (lr:0.00010023153840661742)
19930: accuracy:0.2 loss: 286.764 (lr:0.00010023038360399673)
19940: accuracy:0.21 loss: 276.223 (lr:0.00010022923456097814)
19950: accuracy:0.19 loss: 282.323 (lr:0.00010022809124883549)
19960: accuracy:0.17 loss: 270.898 (lr:0.00010022695363898596)
19970: accuracy:0.23 loss: 260.908 (lr:0.00010022582170298922)
19980: accuracy:0.21 loss: 282.194 (lr:0.00010022469541254682)
19990: accuracy:0.17 loss: 278.07 (lr:0.00010022357473950144)
20000: accuracy:0.2 loss: 264.846 (lr:0.00010022245965583618)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
20000: ********* epoch 3 ********* test accuracy for all:0.176541 test loss: 281.205
20000: ********* epoch 3 ********* test accuracy for mode 0:0.0 test loss: 384.944
20000: ********* epoch 3 ********* test accuracy for mode 1:0.198 test loss: 345.529
20000: ********* epoch 3 ********* test accuracy for mode 2:0.051 test loss: 312.535
20000: ********* epoch 3 ********* test accuracy for mode 24:0.248 test loss: 279.975
20000: ********* epoch 3 ********* test accuracy for mode 25:0.2885 test loss: 259.762
20000: ********* epoch 3 ********* test accuracy for mode 26:0.0255 test loss: 231.837
20000: ********* epoch 3 ********* test accuracy for mode 27:0.2915 test loss: 273.302
20000: ********* epoch 3 ********* test accuracy for mode 28:0.148 test loss: 278.896
20000: ********* epoch 3 ********* test accuracy for mode 29:0.258 test loss: 285.499
20000: ********* epoch 3 ********* test accuracy for mode 30:0.0805 test loss: 290.045
20000: ********* epoch 3 ********* test accuracy for mode 31:0.1775 test loss: 291.84
20000: ********* epoch 3 ********* test accuracy for mode 32:0.17 test loss: 281.472
20000: ********* epoch 3 ********* test accuracy for mode 33:0.2065 test loss: 291.004
20000: ********* epoch 3 ********* test accuracy for mode 34:0.008 test loss: 292.028
20000: ********* epoch 3 ********* test accuracy for mode 35:0.0005 test loss: 424.394
20000: ********* epoch 3 ********* test accuracy for mode 36:0.057 test loss: 412.008
20010: accuracy:0.25 loss: 258.85 (lr:0.00010022135013367391)
20020: accuracy:0.18 loss: 283.683 (lr:0.00010022024614527651)
20030: accuracy:0.19 loss: 280.741 (lr:0.00010021914766304421)
20040: accuracy:0.21 loss: 269.986 (lr:0.0001002180546595149)
20050: accuracy:0.19 loss: 285.65 (lr:0.00010021696710736343)
20060: accuracy:0.22 loss: 263.168 (lr:0.00010021588497940096)
20070: accuracy:0.22 loss: 265.646 (lr:0.00010021480824857422)
20080: accuracy:0.22 loss: 261.713 (lr:0.00010021373688796486)
20090: accuracy:0.19 loss: 279.08 (lr:0.00010021267087078885)
20100: accuracy:0.19 loss: 273.664 (lr:0.00010021161017039568)
20110: accuracy:0.2 loss: 275.899 (lr:0.00010021055476026778)
20120: accuracy:0.24 loss: 255.386 (lr:0.00010020950461401987)
20130: accuracy:0.24 loss: 260.948 (lr:0.00010020845970539822)
20140: accuracy:0.18 loss: 278.961 (lr:0.00010020742000828007)
20150: accuracy:0.21 loss: 271.172 (lr:0.00010020638549667291)
20160: accuracy:0.16 loss: 270.539 (lr:0.00010020535614471392)
20170: accuracy:0.19 loss: 254.666 (lr:0.00010020433192666925)
20180: accuracy:0.29 loss: 278.629 (lr:0.0001002033128169334)
20190: accuracy:0.17 loss: 275.982 (lr:0.00010020229879002854)
20200: accuracy:0.22 loss: 265.854 (lr:0.00010020128982060398)
20210: accuracy:0.18 loss: 267.399 (lr:0.00010020028588343541)
20220: accuracy:0.28 loss: 253.753 (lr:0.00010019928695342437)
20230: accuracy:0.22 loss: 263.514 (lr:0.00010019829300559753)
20240: accuracy:0.22 loss: 280.076 (lr:0.00010019730401510617)
20250: accuracy:0.24 loss: 267.016 (lr:0.00010019631995722547)
20260: accuracy:0.25 loss: 248.356 (lr:0.00010019534080735391)
20270: accuracy:0.18 loss: 266.093 (lr:0.00010019436654101272)
20280: accuracy:0.23 loss: 268.603 (lr:0.00010019339713384517)
20290: accuracy:0.21 loss: 261.855 (lr:0.00010019243256161603)
20300: accuracy:0.24 loss: 268.965 (lr:0.00010019147280021097)
20310: accuracy:0.2 loss: 274.344 (lr:0.00010019051782563589)
20320: accuracy:0.15 loss: 283.622 (lr:0.00010018956761401636)
20330: accuracy:0.18 loss: 282.791 (lr:0.00010018862214159707)
20340: accuracy:0.22 loss: 271.451 (lr:0.00010018768138474113)
20350: accuracy:0.17 loss: 267.275 (lr:0.00010018674531992959)
20360: accuracy:0.22 loss: 271.224 (lr:0.00010018581392376076)
20370: accuracy:0.21 loss: 284.771 (lr:0.00010018488717294972)
20380: accuracy:0.09 loss: 290.673 (lr:0.00010018396504432763)
20390: accuracy:0.17 loss: 279.938 (lr:0.00010018304751484122)
20400: accuracy:0.18 loss: 274.264 (lr:0.00010018213456155222)
20410: accuracy:0.2 loss: 258.657 (lr:0.00010018122616163675)
20420: accuracy:0.24 loss: 270.965 (lr:0.00010018032229238476)
20430: accuracy:0.2 loss: 274.573 (lr:0.00010017942293119947)
20440: accuracy:0.2 loss: 274.686 (lr:0.0001001785280555968)
20450: accuracy:0.27 loss: 252.197 (lr:0.00010017763764320483)
20460: accuracy:0.24 loss: 250.206 (lr:0.00010017675167176317)
20470: accuracy:0.22 loss: 275.332 (lr:0.00010017587011912253)
20480: accuracy:0.21 loss: 267.67 (lr:0.00010017499296324401)
20490: accuracy:0.23 loss: 267.262 (lr:0.0001001741201821987)
20500: accuracy:0.16 loss: 280.656 (lr:0.00010017325175416701)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
20500: ********* epoch 3 ********* test accuracy for all:0.177257 test loss: 281.667
20500: ********* epoch 3 ********* test accuracy for mode 0:0.0005 test loss: 379.784
20500: ********* epoch 3 ********* test accuracy for mode 1:0.2065 test loss: 344.067
20500: ********* epoch 3 ********* test accuracy for mode 2:0.008 test loss: 314.243
20500: ********* epoch 3 ********* test accuracy for mode 24:0.2755 test loss: 272.364
20500: ********* epoch 3 ********* test accuracy for mode 25:0.245 test loss: 257.579
20500: ********* epoch 3 ********* test accuracy for mode 26:0.0335 test loss: 223.371
20500: ********* epoch 3 ********* test accuracy for mode 27:0.3235 test loss: 264.808
20500: ********* epoch 3 ********* test accuracy for mode 28:0.1575 test loss: 273.177
20500: ********* epoch 3 ********* test accuracy for mode 29:0.2625 test loss: 281.374
20500: ********* epoch 3 ********* test accuracy for mode 30:0.1695 test loss: 281.833
20500: ********* epoch 3 ********* test accuracy for mode 31:0.126 test loss: 290.04
20500: ********* epoch 3 ********* test accuracy for mode 32:0.1735 test loss: 279.029
20500: ********* epoch 3 ********* test accuracy for mode 33:0.215 test loss: 289.56
20500: ********* epoch 3 ********* test accuracy for mode 34:0.012 test loss: 294.372
20500: ********* epoch 3 ********* test accuracy for mode 35:0.0005 test loss: 412.23
20500: ********* epoch 3 ********* test accuracy for mode 36:0.1345 test loss: 397.073
20510: accuracy:0.23 loss: 269.388 (lr:0.0001001723876574382)
20520: accuracy:0.25 loss: 262.436 (lr:0.0001001715278704098)
20530: accuracy:0.18 loss: 278.469 (lr:0.0001001706723715871)
20540: accuracy:0.21 loss: 269.617 (lr:0.00010016982113958258)
20550: accuracy:0.2 loss: 274.162 (lr:0.00010016897415311539)
20560: accuracy:0.2 loss: 272.816 (lr:0.00010016813139101082)
20570: accuracy:0.18 loss: 256.879 (lr:0.00010016729283219979)
20580: accuracy:0.2 loss: 274.661 (lr:0.00010016645845571828)
20590: accuracy:0.17 loss: 260.676 (lr:0.00010016562824070683)
20600: accuracy:0.26 loss: 249.499 (lr:0.00010016480216641002)
20610: accuracy:0.22 loss: 262.977 (lr:0.00010016398021217596)
20620: accuracy:0.14 loss: 270.541 (lr:0.00010016316235745575)
20630: accuracy:0.21 loss: 276.778 (lr:0.00010016234858180297)
20640: accuracy:0.26 loss: 274.039 (lr:0.00010016153886487319)
20650: accuracy:0.23 loss: 270.969 (lr:0.00010016073318642344)
20660: accuracy:0.23 loss: 271.126 (lr:0.00010015993152631174)
20670: accuracy:0.24 loss: 259.107 (lr:0.0001001591338644965)
20680: accuracy:0.17 loss: 270.535 (lr:0.00010015834018103618)
20690: accuracy:0.22 loss: 273.297 (lr:0.00010015755045608863)
20700: accuracy:0.16 loss: 281.346 (lr:0.00010015676466991068)
20710: accuracy:0.23 loss: 261.051 (lr:0.00010015598280285764)
20720: accuracy:0.28 loss: 266.675 (lr:0.00010015520483538282)
20730: accuracy:0.25 loss: 264.185 (lr:0.00010015443074803695)
20740: accuracy:0.16 loss: 266.087 (lr:0.00010015366052146782)
20750: accuracy:0.16 loss: 272.58 (lr:0.00010015289413641974)
20760: accuracy:0.24 loss: 279.309 (lr:0.00010015213157373303)
20770: accuracy:0.26 loss: 266.252 (lr:0.00010015137281434359)
20780: accuracy:0.24 loss: 264.405 (lr:0.00010015061783928239)
20790: accuracy:0.32 loss: 272.321 (lr:0.00010014986662967501)
20800: accuracy:0.19 loss: 272.913 (lr:0.00010014911916674118)
20810: accuracy:0.15 loss: 269.958 (lr:0.00010014837543179429)
20820: accuracy:0.14 loss: 274.832 (lr:0.00010014763540624092)
20830: accuracy:0.22 loss: 251.69 (lr:0.0001001468990715804)
20840: accuracy:0.21 loss: 270.787 (lr:0.00010014616640940432)
20850: accuracy:0.17 loss: 276.32 (lr:0.00010014543740139608)
20860: accuracy:0.12 loss: 277.816 (lr:0.00010014471202933046)
20870: accuracy:0.24 loss: 262.075 (lr:0.0001001439902750731)
20880: accuracy:0.15 loss: 275.234 (lr:0.00010014327212058012)
20890: accuracy:0.23 loss: 273.302 (lr:0.00010014255754789763)
20900: accuracy:0.27 loss: 267.624 (lr:0.00010014184653916124)
20910: accuracy:0.19 loss: 256.471 (lr:0.00010014113907659573)
20920: accuracy:0.18 loss: 280.647 (lr:0.00010014043514251448)
20930: accuracy:0.18 loss: 276.302 (lr:0.00010013973471931911)
20940: accuracy:0.23 loss: 277.211 (lr:0.000100139037789499)
20950: accuracy:0.21 loss: 267.711 (lr:0.00010013834433563087)
20960: accuracy:0.22 loss: 268.142 (lr:0.00010013765434037834)
20970: accuracy:0.22 loss: 264.7 (lr:0.00010013696778649148)
20980: accuracy:0.24 loss: 266.326 (lr:0.00010013628465680643)
20990: accuracy:0.22 loss: 266.434 (lr:0.00010013560493424488)
21000: accuracy:0.27 loss: 270.285 (lr:0.00010013492860181377)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
21000: ********* epoch 3 ********* test accuracy for all:0.18373 test loss: 279.967
21000: ********* epoch 3 ********* test accuracy for mode 0:0.0 test loss: 396.158
21000: ********* epoch 3 ********* test accuracy for mode 1:0.1815 test loss: 353.922
21000: ********* epoch 3 ********* test accuracy for mode 2:0.035 test loss: 302.567
21000: ********* epoch 3 ********* test accuracy for mode 24:0.252 test loss: 283.443
21000: ********* epoch 3 ********* test accuracy for mode 25:0.321 test loss: 259.519
21000: ********* epoch 3 ********* test accuracy for mode 26:0.0185 test loss: 228.879
21000: ********* epoch 3 ********* test accuracy for mode 27:0.351 test loss: 268.348
21000: ********* epoch 3 ********* test accuracy for mode 28:0.1415 test loss: 277.431
21000: ********* epoch 3 ********* test accuracy for mode 29:0.248 test loss: 285.484
21000: ********* epoch 3 ********* test accuracy for mode 30:0.1745 test loss: 282.897
21000: ********* epoch 3 ********* test accuracy for mode 31:0.166 test loss: 286.981
21000: ********* epoch 3 ********* test accuracy for mode 32:0.168 test loss: 276.741
21000: ********* epoch 3 ********* test accuracy for mode 33:0.1465 test loss: 286.6
21000: ********* epoch 3 ********* test accuracy for mode 34:0.1365 test loss: 280.605
21000: ********* epoch 3 ********* test accuracy for mode 35:0.0005 test loss: 437.602
21000: ********* epoch 3 ********* test accuracy for mode 36:0.021 test loss: 438.472
21010: accuracy:0.13 loss: 260.983 (lr:0.00010013425564260471)
21020: accuracy:0.21 loss: 272.217 (lr:0.00010013358603979373)
21030: accuracy:0.29 loss: 260.888 (lr:0.00010013291977664068)
21040: accuracy:0.22 loss: 258.313 (lr:0.00010013225683648899)
21050: accuracy:0.27 loss: 279.744 (lr:0.00010013159720276509)
21060: accuracy:0.22 loss: 276.046 (lr:0.00010013094085897812)
21070: accuracy:0.18 loss: 275.299 (lr:0.00010013028778871943)
21080: accuracy:0.19 loss: 252.467 (lr:0.00010012963797566225)
21090: accuracy:0.24 loss: 263.472 (lr:0.00010012899140356122)
21100: accuracy:0.2 loss: 271.047 (lr:0.00010012834805625199)
21110: accuracy:0.16 loss: 275.943 (lr:0.00010012770791765086)
21120: accuracy:0.22 loss: 271.898 (lr:0.00010012707097175431)
21130: accuracy:0.21 loss: 255.947 (lr:0.00010012643720263869)
21140: accuracy:0.24 loss: 265.283 (lr:0.0001001258065944597)
21150: accuracy:0.28 loss: 247.65 (lr:0.00010012517913145214)
21160: accuracy:0.2 loss: 269.871 (lr:0.00010012455479792938)
21170: accuracy:0.24 loss: 263.434 (lr:0.00010012393357828306)
21180: accuracy:0.18 loss: 268.631 (lr:0.00010012331545698264)
21190: accuracy:0.22 loss: 261.729 (lr:0.00010012270041857508)
21200: accuracy:0.15 loss: 287.227 (lr:0.00010012208844768437)
21210: accuracy:0.22 loss: 262.391 (lr:0.00010012147952901121)
21220: accuracy:0.22 loss: 261.546 (lr:0.0001001208736473326)
21230: accuracy:0.27 loss: 264.316 (lr:0.00010012027078750148)
21240: accuracy:0.23 loss: 272.548 (lr:0.0001001196709344463)
21250: accuracy:0.23 loss: 273.794 (lr:0.00010011907407317071)
21260: accuracy:0.19 loss: 256.828 (lr:0.00010011848018875317)
21270: accuracy:0.16 loss: 276.97 (lr:0.0001001178892663465)
21280: accuracy:0.32 loss: 268.123 (lr:0.00010011730129117764)
21290: accuracy:0.21 loss: 260.604 (lr:0.00010011671624854717)
21300: accuracy:0.24 loss: 267.237 (lr:0.00010011613412382899)
21310: accuracy:0.2 loss: 270.16 (lr:0.00010011555490246995)
21320: accuracy:0.23 loss: 249.297 (lr:0.0001001149785699895)
21330: accuracy:0.22 loss: 260.187 (lr:0.00010011440511197928)
21340: accuracy:0.11 loss: 296.417 (lr:0.00010011383451410282)
21350: accuracy:0.27 loss: 268.22 (lr:0.00010011326676209514)
21360: accuracy:0.23 loss: 258.871 (lr:0.00010011270184176241)
21370: accuracy:0.22 loss: 275.397 (lr:0.0001001121397389816)
21380: accuracy:0.2 loss: 269.723 (lr:0.0001001115804397001)
21390: accuracy:0.22 loss: 270.546 (lr:0.0001001110239299354)
21400: accuracy:0.21 loss: 265.676 (lr:0.00010011047019577475)
21410: accuracy:0.18 loss: 254.54 (lr:0.00010010991922337473)
21420: accuracy:0.29 loss: 256.585 (lr:0.00010010937099896102)
21430: accuracy:0.31 loss: 268.856 (lr:0.00010010882550882799)
21440: accuracy:0.29 loss: 269.056 (lr:0.00010010828273933834)
21450: accuracy:0.2 loss: 257.492 (lr:0.00010010774267692282)
21460: accuracy:0.27 loss: 262.989 (lr:0.00010010720530807983)
21470: accuracy:0.2 loss: 262.172 (lr:0.00010010667061937513)
21480: accuracy:0.22 loss: 261.558 (lr:0.00010010613859744146)
21490: accuracy:0.27 loss: 253.065 (lr:0.00010010560922897826)
21500: accuracy:0.19 loss: 258.423 (lr:0.0001001050825007513)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
21500: ********* epoch 3 ********* test accuracy for all:0.190459 test loss: 278.381
21500: ********* epoch 3 ********* test accuracy for mode 0:0.0 test loss: 389.881
21500: ********* epoch 3 ********* test accuracy for mode 1:0.1965 test loss: 344.891
21500: ********* epoch 3 ********* test accuracy for mode 2:0.022 test loss: 307.593
21500: ********* epoch 3 ********* test accuracy for mode 24:0.26 test loss: 273.263
21500: ********* epoch 3 ********* test accuracy for mode 25:0.301 test loss: 250.235
21500: ********* epoch 3 ********* test accuracy for mode 26:0.0175 test loss: 227.944
21500: ********* epoch 3 ********* test accuracy for mode 27:0.3215 test loss: 259.783
21500: ********* epoch 3 ********* test accuracy for mode 28:0.249 test loss: 262.317
21500: ********* epoch 3 ********* test accuracy for mode 29:0.262 test loss: 274.296
21500: ********* epoch 3 ********* test accuracy for mode 30:0.131 test loss: 279.127
21500: ********* epoch 3 ********* test accuracy for mode 31:0.166 test loss: 284.9
21500: ********* epoch 3 ********* test accuracy for mode 32:0.137 test loss: 277.146
21500: ********* epoch 3 ********* test accuracy for mode 33:0.194 test loss: 285.71
21500: ********* epoch 3 ********* test accuracy for mode 34:0.0705 test loss: 286.121
21500: ********* epoch 3 ********* test accuracy for mode 35:0.002 test loss: 427.23
21500: ********* epoch 3 ********* test accuracy for mode 36:0.081 test loss: 414.286
21510: accuracy:0.23 loss: 261.236 (lr:0.00010010455839959231)
21520: accuracy:0.12 loss: 279.117 (lr:0.00010010403691239876)
21530: accuracy:0.24 loss: 258.286 (lr:0.00010010351802613345)
21540: accuracy:0.17 loss: 272.062 (lr:0.00010010300172782417)
21550: accuracy:0.19 loss: 278.937 (lr:0.00010010248800456346)
21560: accuracy:0.19 loss: 267.26 (lr:0.0001001019768435082)
21570: accuracy:0.15 loss: 268.342 (lr:0.00010010146823187933)
21580: accuracy:0.24 loss: 241.786 (lr:0.00010010096215696156)
21590: accuracy:0.18 loss: 266.142 (lr:0.00010010045860610296)
21600: accuracy:0.26 loss: 259.914 (lr:0.00010009995756671474)
21610: accuracy:0.18 loss: 285.017 (lr:0.00010009945902627091)
21620: accuracy:0.24 loss: 265.17 (lr:0.00010009896297230791)
21630: accuracy:0.14 loss: 260.929 (lr:0.00010009846939242437)
21640: accuracy:0.27 loss: 253.503 (lr:0.00010009797827428077)
21650: accuracy:0.26 loss: 254.73 (lr:0.00010009748960559913)
21660: accuracy:0.2 loss: 273.419 (lr:0.0001000970033741627)
21670: accuracy:0.21 loss: 277.464 (lr:0.00010009651956781569)
21680: accuracy:0.26 loss: 262.442 (lr:0.0001000960381744629)
21690: accuracy:0.21 loss: 255.973 (lr:0.00010009555918206946)
21700: accuracy:0.27 loss: 263.371 (lr:0.00010009508257866057)
21710: accuracy:0.23 loss: 268.116 (lr:0.00010009460835232108)
21720: accuracy:0.23 loss: 257.155 (lr:0.00010009413649119533)
21730: accuracy:0.34 loss: 245.941 (lr:0.00010009366698348677)
21740: accuracy:0.18 loss: 260.48 (lr:0.00010009319981745767)
21750: accuracy:0.25 loss: 260.045 (lr:0.00010009273498142886)
21760: accuracy:0.26 loss: 254.37 (lr:0.00010009227246377942)
21770: accuracy:0.18 loss: 260.836 (lr:0.00010009181225294637)
21780: accuracy:0.26 loss: 259.705 (lr:0.00010009135433742443)
21790: accuracy:0.23 loss: 276.583 (lr:0.00010009089870576569)
21800: accuracy:0.26 loss: 261.114 (lr:0.00010009044534657933)
21810: accuracy:0.25 loss: 245.503 (lr:0.00010008999424853133)
21820: accuracy:0.25 loss: 265.688 (lr:0.00010008954540034426)
21830: accuracy:0.24 loss: 261.499 (lr:0.00010008909879079683)
21840: accuracy:0.17 loss: 266.626 (lr:0.00010008865440872383)
21850: accuracy:0.21 loss: 258.105 (lr:0.00010008821224301566)
21860: accuracy:0.24 loss: 258.821 (lr:0.00010008777228261815)
21870: accuracy:0.17 loss: 279.331 (lr:0.00010008733451653229)
21880: accuracy:0.21 loss: 277.17 (lr:0.00010008689893381389)
21890: accuracy:0.24 loss: 258.35 (lr:0.00010008646552357336)
21900: accuracy:0.18 loss: 289.819 (lr:0.00010008603427497543)
21910: accuracy:0.26 loss: 257.234 (lr:0.00010008560517723884)
21920: accuracy:0.3 loss: 264.573 (lr:0.00010008517821963615)
21930: accuracy:0.19 loss: 274.216 (lr:0.00010008475339149338)
21940: accuracy:0.21 loss: 267.941 (lr:0.00010008433068218981)
21950: accuracy:0.16 loss: 280.208 (lr:0.0001000839100811577)
21960: accuracy:0.24 loss: 280.68 (lr:0.00010008349157788198)
21970: accuracy:0.22 loss: 256.317 (lr:0.00010008307516190006)
21980: accuracy:0.12 loss: 293.319 (lr:0.00010008266082280152)
21990: accuracy:0.21 loss: 244.67 (lr:0.00010008224855022784)
22000: accuracy:0.23 loss: 262.763 (lr:0.0001000818383338722)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
22000: ********* epoch 3 ********* test accuracy for all:0.188581 test loss: 279.15
22000: ********* epoch 3 ********* test accuracy for mode 0:0.0 test loss: 401.433
22000: ********* epoch 3 ********* test accuracy for mode 1:0.1805 test loss: 351.802
22000: ********* epoch 3 ********* test accuracy for mode 2:0.038 test loss: 298.576
22000: ********* epoch 3 ********* test accuracy for mode 24:0.2015 test loss: 284.57
22000: ********* epoch 3 ********* test accuracy for mode 25:0.274 test loss: 262.806
22000: ********* epoch 3 ********* test accuracy for mode 26:0.022 test loss: 223.695
22000: ********* epoch 3 ********* test accuracy for mode 27:0.361 test loss: 268.974
22000: ********* epoch 3 ********* test accuracy for mode 28:0.1665 test loss: 272.362
22000: ********* epoch 3 ********* test accuracy for mode 29:0.3005 test loss: 277.653
22000: ********* epoch 3 ********* test accuracy for mode 30:0.1635 test loss: 279.325
22000: ********* epoch 3 ********* test accuracy for mode 31:0.145 test loss: 284.14
22000: ********* epoch 3 ********* test accuracy for mode 32:0.1675 test loss: 271.929
22000: ********* epoch 3 ********* test accuracy for mode 33:0.233 test loss: 279.103
22000: ********* epoch 3 ********* test accuracy for mode 34:0.0755 test loss: 280.483
22000: ********* epoch 3 ********* test accuracy for mode 35:0.0005 test loss: 440.427
22000: ********* epoch 3 ********* test accuracy for mode 36:0.016 test loss: 443.018
22010: accuracy:0.23 loss: 266.669 (lr:0.00010008143016347918)
22020: accuracy:0.21 loss: 270.473 (lr:0.00010008102402884449)
22030: accuracy:0.22 loss: 263.509 (lr:0.00010008061991981473)
22040: accuracy:0.19 loss: 269.013 (lr:0.00010008021782628718)
22050: accuracy:0.17 loss: 272.121 (lr:0.00010007981773820945)
22060: accuracy:0.21 loss: 271.125 (lr:0.00010007941964557934)
22070: accuracy:0.17 loss: 256.299 (lr:0.0001000790235384445)
22080: accuracy:0.23 loss: 278.732 (lr:0.00010007862940690223)
22090: accuracy:0.18 loss: 273.873 (lr:0.00010007823724109924)
22100: accuracy:0.21 loss: 283.505 (lr:0.00010007784703123135)
22110: accuracy:0.31 loss: 262.051 (lr:0.0001000774587675433)
22120: accuracy:0.2 loss: 268.012 (lr:0.00010007707244032847)
22130: accuracy:0.23 loss: 267.244 (lr:0.00010007668803992867)
22140: accuracy:0.22 loss: 264.42 (lr:0.00010007630555673384)
22150: accuracy:0.26 loss: 274.599 (lr:0.00010007592498118192)
22160: accuracy:0.31 loss: 262.15 (lr:0.00010007554630375848)
22170: accuracy:0.32 loss: 268.249 (lr:0.00010007516951499657)
22180: accuracy:0.25 loss: 278.572 (lr:0.00010007479460547645)
22190: accuracy:0.23 loss: 273.79 (lr:0.00010007442156582536)
22200: accuracy:0.22 loss: 275.059 (lr:0.00010007405038671729)
22210: accuracy:0.24 loss: 272.684 (lr:0.00010007368105887275)
22220: accuracy:0.2 loss: 271.452 (lr:0.00010007331357305851)
22230: accuracy:0.24 loss: 259.496 (lr:0.00010007294792008744)
22240: accuracy:0.16 loss: 269.607 (lr:0.00010007258409081814)
22250: accuracy:0.21 loss: 280.043 (lr:0.00010007222207615491)
22260: accuracy:0.17 loss: 269.817 (lr:0.00010007186186704733)
22270: accuracy:0.19 loss: 257.098 (lr:0.00010007150345449019)
22280: accuracy:0.21 loss: 256.493 (lr:0.00010007114682952312)
22290: accuracy:0.25 loss: 255.563 (lr:0.0001000707919832305)
22300: accuracy:0.23 loss: 265.545 (lr:0.00010007043890674115)
22310: accuracy:0.2 loss: 266.573 (lr:0.00010007008759122813)
22320: accuracy:0.29 loss: 255.18 (lr:0.00010006973802790854)
22330: accuracy:0.25 loss: 275.258 (lr:0.00010006939020804329)
22340: accuracy:0.22 loss: 258.878 (lr:0.00010006904412293685)
22350: accuracy:0.27 loss: 249.239 (lr:0.00010006869976393708)
22360: accuracy:0.23 loss: 260.652 (lr:0.00010006835712243498)
22370: accuracy:0.17 loss: 282.962 (lr:0.00010006801618986452)
22380: accuracy:0.21 loss: 279.992 (lr:0.00010006767695770233)
22390: accuracy:0.15 loss: 261.064 (lr:0.00010006733941746762)
22400: accuracy:0.28 loss: 249.484 (lr:0.00010006700356072184)
22410: accuracy:0.27 loss: 267.856 (lr:0.00010006666937906857)
22420: accuracy:0.23 loss: 251.282 (lr:0.00010006633686415326)
22430: accuracy:0.22 loss: 259.736 (lr:0.00010006600600766301)
22440: accuracy:0.25 loss: 259.74 (lr:0.00010006567680132638)
22450: accuracy:0.19 loss: 251.312 (lr:0.0001000653492369132)
22460: accuracy:0.2 loss: 274.288 (lr:0.00010006502330623435)
22470: accuracy:0.16 loss: 278.404 (lr:0.00010006469900114155)
22480: accuracy:0.26 loss: 252.803 (lr:0.00010006437631352714)
22490: accuracy:0.17 loss: 259.108 (lr:0.00010006405523532393)
22500: accuracy:0.2 loss: 261.691 (lr:0.00010006373575850494)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
22500: ********* epoch 3 ********* test accuracy for all:0.187716 test loss: 277.537
22500: ********* epoch 3 ********* test accuracy for mode 0:0.0 test loss: 392.767
22500: ********* epoch 3 ********* test accuracy for mode 1:0.167 test loss: 355.479
22500: ********* epoch 3 ********* test accuracy for mode 2:0.072 test loss: 303.717
22500: ********* epoch 3 ********* test accuracy for mode 24:0.2375 test loss: 281.243
22500: ********* epoch 3 ********* test accuracy for mode 25:0.2895 test loss: 263.164
22500: ********* epoch 3 ********* test accuracy for mode 26:0.0245 test loss: 220.402
22500: ********* epoch 3 ********* test accuracy for mode 27:0.314 test loss: 276.938
22500: ********* epoch 3 ********* test accuracy for mode 28:0.1825 test loss: 277.524
22500: ********* epoch 3 ********* test accuracy for mode 29:0.2855 test loss: 287.327
22500: ********* epoch 3 ********* test accuracy for mode 30:0.08 test loss: 291.861
22500: ********* epoch 3 ********* test accuracy for mode 31:0.204 test loss: 291.922
22500: ********* epoch 3 ********* test accuracy for mode 32:0.1095 test loss: 280.7
22500: ********* epoch 3 ********* test accuracy for mode 33:0.2035 test loss: 285.591
22500: ********* epoch 3 ********* test accuracy for mode 34:0.1385 test loss: 281.601
22500: ********* epoch 3 ********* test accuracy for mode 35:0.0 test loss: 434.582
22500: ********* epoch 3 ********* test accuracy for mode 36:0.0155 test loss: 423.562
22510: accuracy:0.22 loss: 243.663 (lr:0.00010006341787508322)
22520: accuracy:0.17 loss: 258.774 (lr:0.00010006310157711169)
22530: accuracy:0.25 loss: 255.119 (lr:0.00010006278685668287)
22540: accuracy:0.21 loss: 264.121 (lr:0.00010006247370592874)
22550: accuracy:0.25 loss: 261.022 (lr:0.00010006216211702051)
22560: accuracy:0.18 loss: 266.903 (lr:0.00010006185208216844)
22570: accuracy:0.2 loss: 264.885 (lr:0.00010006154359362166)
22580: accuracy:0.18 loss: 273.34 (lr:0.00010006123664366791)
22590: accuracy:0.24 loss: 258.411 (lr:0.00010006093122463344)
22600: accuracy:0.27 loss: 264.654 (lr:0.00010006062732888277)
22610: accuracy:0.23 loss: 263.415 (lr:0.00010006032494881848)
22620: accuracy:0.25 loss: 255.921 (lr:0.00010006002407688103)
22630: accuracy:0.23 loss: 256.221 (lr:0.00010005972470554865)
22640: accuracy:0.28 loss: 251.534 (lr:0.00010005942682733702)
22650: accuracy:0.19 loss: 265.852 (lr:0.00010005913043479916)
22660: accuracy:0.23 loss: 251.597 (lr:0.00010005883552052525)
22670: accuracy:0.19 loss: 263.309 (lr:0.00010005854207714243)
22680: accuracy:0.19 loss: 275.575 (lr:0.00010005825009731457)
22690: accuracy:0.2 loss: 266.018 (lr:0.0001000579595737422)
22700: accuracy:0.17 loss: 281.876 (lr:0.00010005767049916217)
22710: accuracy:0.2 loss: 268.52 (lr:0.00010005738286634763)
22720: accuracy:0.28 loss: 264.3 (lr:0.00010005709666810774)
22730: accuracy:0.29 loss: 269.021 (lr:0.00010005681189728752)
22740: accuracy:0.26 loss: 271.124 (lr:0.00010005652854676769)
22750: accuracy:0.23 loss: 264.531 (lr:0.00010005624660946449)
22760: accuracy:0.24 loss: 253.49 (lr:0.00010005596607832944)
22770: accuracy:0.26 loss: 253.744 (lr:0.00010005568694634927)
22780: accuracy:0.25 loss: 258.088 (lr:0.00010005540920654566)
22790: accuracy:0.1 loss: 279.813 (lr:0.0001000551328519751)
22800: accuracy:0.17 loss: 261.378 (lr:0.0001000548578757287)
22810: accuracy:0.15 loss: 266.758 (lr:0.00010005458427093205)
22820: accuracy:0.21 loss: 257.748 (lr:0.00010005431203074503)
22830: accuracy:0.26 loss: 253.374 (lr:0.0001000540411483616)
22840: accuracy:0.2 loss: 250.116 (lr:0.0001000537716170097)
22850: accuracy:0.21 loss: 267.377 (lr:0.00010005350342995102)
22860: accuracy:0.22 loss: 251.415 (lr:0.00010005323658048087)
22870: accuracy:0.34 loss: 251.611 (lr:0.00010005297106192802)
22880: accuracy:0.2 loss: 265.452 (lr:0.00010005270686765447)
22890: accuracy:0.25 loss: 261.254 (lr:0.00010005244399105536)
22900: accuracy:0.23 loss: 277.13 (lr:0.00010005218242555875)
22910: accuracy:0.18 loss: 278.687 (lr:0.0001000519221646255)
22920: accuracy:0.18 loss: 274.042 (lr:0.00010005166320174906)
22930: accuracy:0.22 loss: 267.82 (lr:0.00010005140553045536)
22940: accuracy:0.23 loss: 261.174 (lr:0.00010005114914430262)
22950: accuracy:0.27 loss: 251.953 (lr:0.00010005089403688113)
22960: accuracy:0.23 loss: 250.61 (lr:0.00010005064020181321)
22970: accuracy:0.21 loss: 256.374 (lr:0.00010005038763275298)
22980: accuracy:0.32 loss: 260.07 (lr:0.00010005013632338619)
22990: accuracy:0.26 loss: 248.238 (lr:0.00010004988626743011)
23000: accuracy:0.25 loss: 258.509 (lr:0.0001000496374586333)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
23000: ********* epoch 3 ********* test accuracy for all:0.192068 test loss: 275.474
23000: ********* epoch 3 ********* test accuracy for mode 0:0.0 test loss: 388.909
23000: ********* epoch 3 ********* test accuracy for mode 1:0.1665 test loss: 351.329
23000: ********* epoch 3 ********* test accuracy for mode 2:0.0585 test loss: 303.493
23000: ********* epoch 3 ********* test accuracy for mode 24:0.197 test loss: 277.404
23000: ********* epoch 3 ********* test accuracy for mode 25:0.2935 test loss: 253.921
23000: ********* epoch 3 ********* test accuracy for mode 26:0.019 test loss: 217.161
23000: ********* epoch 3 ********* test accuracy for mode 27:0.364 test loss: 260.83
23000: ********* epoch 3 ********* test accuracy for mode 28:0.2235 test loss: 264.685
23000: ********* epoch 3 ********* test accuracy for mode 29:0.312 test loss: 274.913
23000: ********* epoch 3 ********* test accuracy for mode 30:0.1355 test loss: 280.675
23000: ********* epoch 3 ********* test accuracy for mode 31:0.08 test loss: 290.276
23000: ********* epoch 3 ********* test accuracy for mode 32:0.2215 test loss: 277.464
23000: ********* epoch 3 ********* test accuracy for mode 33:0.147 test loss: 289.537
23000: ********* epoch 3 ********* test accuracy for mode 34:0.0535 test loss: 286.253
23000: ********* epoch 3 ********* test accuracy for mode 35:0.001 test loss: 421.8
23000: ********* epoch 3 ********* test accuracy for mode 36:0.078 test loss: 392.286
23010: accuracy:0.21 loss: 272.906 (lr:0.00010004938989077554)
23020: accuracy:0.2 loss: 265.975 (lr:0.00010004914355766763)
23030: accuracy:0.15 loss: 275.048 (lr:0.00010004889845315121)
23040: accuracy:0.23 loss: 274.976 (lr:0.00010004865457109867)
23050: accuracy:0.21 loss: 254.185 (lr:0.00010004841190541295)
23060: accuracy:0.26 loss: 255.307 (lr:0.00010004817045002739)
23070: accuracy:0.22 loss: 266.203 (lr:0.00010004793019890557)
23080: accuracy:0.22 loss: 254.166 (lr:0.00010004769114604124)
23090: accuracy:0.26 loss: 255.582 (lr:0.00010004745328545802)
23100: accuracy:0.18 loss: 263.777 (lr:0.00010004721661120942)
23110: accuracy:0.29 loss: 241.195 (lr:0.00010004698111737857)
23120: accuracy:0.26 loss: 269.336 (lr:0.00010004674679807809)
23130: accuracy:0.27 loss: 251.901 (lr:0.00010004651364745)
23140: accuracy:0.27 loss: 262.256 (lr:0.00010004628165966552)
23150: accuracy:0.23 loss: 260.253 (lr:0.00010004605082892494)
23160: accuracy:0.2 loss: 257.146 (lr:0.00010004582114945748)
23170: accuracy:0.22 loss: 260.512 (lr:0.00010004559261552116)
23180: accuracy:0.13 loss: 267.919 (lr:0.00010004536522140258)
23190: accuracy:0.24 loss: 271.52 (lr:0.0001000451389614169)
23200: accuracy:0.27 loss: 255.38 (lr:0.00010004491382990761)
23210: accuracy:0.25 loss: 258.798 (lr:0.00010004468982124642)
23220: accuracy:0.18 loss: 237.893 (lr:0.00010004446692983308)
23230: accuracy:0.16 loss: 261.099 (lr:0.0001000442451500953)
23240: accuracy:0.17 loss: 279.774 (lr:0.00010004402447648858)
23250: accuracy:0.23 loss: 257.556 (lr:0.00010004380490349606)
23260: accuracy:0.23 loss: 255.399 (lr:0.00010004358642562841)
23270: accuracy:0.14 loss: 275.609 (lr:0.00010004336903742367)
23280: accuracy:0.16 loss: 273.35 (lr:0.00010004315273344712)
23290: accuracy:0.21 loss: 266.536 (lr:0.00010004293750829116)
23300: accuracy:0.14 loss: 272.025 (lr:0.00010004272335657515)
23310: accuracy:0.27 loss: 243.556 (lr:0.00010004251027294526)
23320: accuracy:0.23 loss: 249.753 (lr:0.00010004229825207443)
23330: accuracy:0.23 loss: 254.857 (lr:0.0001000420872886621)
23340: accuracy:0.19 loss: 259.527 (lr:0.00010004187737743417)
23350: accuracy:0.18 loss: 276.516 (lr:0.00010004166851314286)
23360: accuracy:0.27 loss: 258.388 (lr:0.00010004146069056655)
23370: accuracy:0.29 loss: 260.145 (lr:0.00010004125390450967)
23380: accuracy:0.2 loss: 259.259 (lr:0.00010004104814980254)
23390: accuracy:0.21 loss: 254.789 (lr:0.0001000408434213013)
23400: accuracy:0.21 loss: 280.193 (lr:0.00010004063971388772)
23410: accuracy:0.26 loss: 261.475 (lr:0.0001000404370224691)
23420: accuracy:0.21 loss: 281.238 (lr:0.00010004023534197815)
23430: accuracy:0.17 loss: 275.288 (lr:0.00010004003466737284)
23440: accuracy:0.25 loss: 272.626 (lr:0.00010003983499363631)
23450: accuracy:0.2 loss: 259.381 (lr:0.00010003963631577669)
23460: accuracy:0.28 loss: 258.315 (lr:0.00010003943862882702)
23470: accuracy:0.2 loss: 263.949 (lr:0.00010003924192784513)
23480: accuracy:0.26 loss: 261.904 (lr:0.0001000390462079135)
23490: accuracy:0.26 loss: 249.785 (lr:0.00010003885146413907)
23500: accuracy:0.18 loss: 264.071 (lr:0.00010003865769165329)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
23500: ********* epoch 3 ********* test accuracy for all:0.193865 test loss: 276.458
23500: ********* epoch 3 ********* test accuracy for mode 0:0.0005 test loss: 393.03
23500: ********* epoch 3 ********* test accuracy for mode 1:0.189 test loss: 347.995
23500: ********* epoch 3 ********* test accuracy for mode 2:0.0545 test loss: 297.266
23500: ********* epoch 3 ********* test accuracy for mode 24:0.177 test loss: 282.639
23500: ********* epoch 3 ********* test accuracy for mode 25:0.267 test loss: 261.786
23500: ********* epoch 3 ********* test accuracy for mode 26:0.0195 test loss: 220.865
23500: ********* epoch 3 ********* test accuracy for mode 27:0.3685 test loss: 268.266
23500: ********* epoch 3 ********* test accuracy for mode 28:0.1705 test loss: 273.932
23500: ********* epoch 3 ********* test accuracy for mode 29:0.306 test loss: 278.857
23500: ********* epoch 3 ********* test accuracy for mode 30:0.1425 test loss: 278.748
23500: ********* epoch 3 ********* test accuracy for mode 31:0.176 test loss: 280.302
23500: ********* epoch 3 ********* test accuracy for mode 32:0.179 test loss: 272.042
23500: ********* epoch 3 ********* test accuracy for mode 33:0.1415 test loss: 281.783
23500: ********* epoch 3 ********* test accuracy for mode 34:0.1515 test loss: 277.594
23500: ********* epoch 3 ********* test accuracy for mode 35:0.001 test loss: 421.104
23500: ********* epoch 3 ********* test accuracy for mode 36:0.0295 test loss: 413.604
23510: accuracy:0.3 loss: 236.334 (lr:0.0001000384648856118)
23520: accuracy:0.2 loss: 270.79 (lr:0.00010003827304119446)
23530: accuracy:0.22 loss: 262.524 (lr:0.00010003808215360515)
23540: accuracy:0.19 loss: 270.016 (lr:0.00010003789221807166)
23550: accuracy:0.27 loss: 258.985 (lr:0.00010003770322984559)
23560: accuracy:0.31 loss: 249.512 (lr:0.00010003751518420223)
23570: accuracy:0.21 loss: 270.343 (lr:0.00010003732807644042)
23580: accuracy:0.29 loss: 249.968 (lr:0.00010003714190188249)
23590: accuracy:0.17 loss: 287.492 (lr:0.00010003695665587403)
23600: accuracy:0.25 loss: 266.414 (lr:0.00010003677233378388)
23610: accuracy:0.3 loss: 251.762 (lr:0.000100036588931004)
23620: accuracy:0.26 loss: 273.884 (lr:0.0001000364064429493)
23630: accuracy:0.25 loss: 263.818 (lr:0.00010003622486505757)
23640: accuracy:0.18 loss: 297.025 (lr:0.00010003604419278935)
23650: accuracy:0.24 loss: 241.073 (lr:0.00010003586442162784)
23660: accuracy:0.27 loss: 246.024 (lr:0.00010003568554707873)
23670: accuracy:0.22 loss: 269.806 (lr:0.00010003550756467014)
23680: accuracy:0.16 loss: 260.474 (lr:0.00010003533046995254)
23690: accuracy:0.17 loss: 277.629 (lr:0.00010003515425849851)
23700: accuracy:0.27 loss: 253.167 (lr:0.0001000349789259028)
23710: accuracy:0.18 loss: 260.993 (lr:0.00010003480446778203)
23720: accuracy:0.3 loss: 241.082 (lr:0.00010003463087977478)
23730: accuracy:0.22 loss: 258.829 (lr:0.00010003445815754134)
23740: accuracy:0.2 loss: 268.134 (lr:0.00010003428629676361)
23750: accuracy:0.28 loss: 252.028 (lr:0.00010003411529314509)
23760: accuracy:0.24 loss: 265.987 (lr:0.00010003394514241069)
23770: accuracy:0.28 loss: 262.628 (lr:0.0001000337758403066)
23780: accuracy:0.21 loss: 267.281 (lr:0.00010003360738260029)
23790: accuracy:0.26 loss: 250.875 (lr:0.00010003343976508029)
23800: accuracy:0.21 loss: 247.715 (lr:0.00010003327298355617)
23810: accuracy:0.24 loss: 264.882 (lr:0.00010003310703385836)
23820: accuracy:0.22 loss: 261.012 (lr:0.00010003294191183812)
23830: accuracy:0.3 loss: 261.879 (lr:0.0001000327776133674)
23840: accuracy:0.23 loss: 255.48 (lr:0.00010003261413433871)
23850: accuracy:0.17 loss: 261.036 (lr:0.00010003245147066509)
23860: accuracy:0.18 loss: 261.44 (lr:0.00010003228961827991)
23870: accuracy:0.28 loss: 242.437 (lr:0.00010003212857313689)
23880: accuracy:0.25 loss: 261.793 (lr:0.00010003196833120986)
23890: accuracy:0.16 loss: 271.905 (lr:0.00010003180888849277)
23900: accuracy:0.22 loss: 251.133 (lr:0.00010003165024099956)
23910: accuracy:0.21 loss: 254.09 (lr:0.00010003149238476402)
23920: accuracy:0.21 loss: 266.472 (lr:0.00010003133531583973)
23930: accuracy:0.27 loss: 266.712 (lr:0.00010003117903029998)
23940: accuracy:0.22 loss: 255.197 (lr:0.0001000310235242376)
23950: accuracy:0.23 loss: 264.119 (lr:0.00010003086879376495)
23960: accuracy:0.26 loss: 251.966 (lr:0.00010003071483501375)
23970: accuracy:0.23 loss: 245.84 (lr:0.00010003056164413502)
23980: accuracy:0.23 loss: 259.12 (lr:0.00010003040921729899)
23990: accuracy:0.25 loss: 255.749 (lr:0.00010003025755069498)
24000: accuracy:0.26 loss: 236.921 (lr:0.00010003010664053131)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
24000: ********* epoch 3 ********* test accuracy for all:0.194027 test loss: 274.764
24000: ********* epoch 3 ********* test accuracy for mode 0:0.0015 test loss: 395.905
24000: ********* epoch 3 ********* test accuracy for mode 1:0.151 test loss: 356.71
24000: ********* epoch 3 ********* test accuracy for mode 2:0.0545 test loss: 303.134
24000: ********* epoch 3 ********* test accuracy for mode 24:0.2265 test loss: 268.672
24000: ********* epoch 3 ********* test accuracy for mode 25:0.3415 test loss: 243.683
24000: ********* epoch 3 ********* test accuracy for mode 26:0.0185 test loss: 215.987
24000: ********* epoch 3 ********* test accuracy for mode 27:0.377 test loss: 254.152
24000: ********* epoch 3 ********* test accuracy for mode 28:0.188 test loss: 263.806
24000: ********* epoch 3 ********* test accuracy for mode 29:0.2915 test loss: 273.385
24000: ********* epoch 3 ********* test accuracy for mode 30:0.175 test loss: 273.962
24000: ********* epoch 3 ********* test accuracy for mode 31:0.0805 test loss: 285.828
24000: ********* epoch 3 ********* test accuracy for mode 32:0.248 test loss: 271.652
24000: ********* epoch 3 ********* test accuracy for mode 33:0.1445 test loss: 283.776
24000: ********* epoch 3 ********* test accuracy for mode 34:0.0985 test loss: 281.438
24000: ********* epoch 3 ********* test accuracy for mode 35:0.0005 test loss: 429.262
24000: ********* epoch 3 ********* test accuracy for mode 36:0.042 test loss: 420.315
24010: accuracy:0.23 loss: 253.745 (lr:0.00010002995648303522)
24020: accuracy:0.27 loss: 255.482 (lr:0.00010002980707445277)
24030: accuracy:0.2 loss: 256.975 (lr:0.00010002965841104873)
24040: accuracy:0.3 loss: 251.296 (lr:0.00010002951048910651)
24050: accuracy:0.25 loss: 257.948 (lr:0.00010002936330492807)
24060: accuracy:0.13 loss: 275.565 (lr:0.00010002921685483376)
24070: accuracy:0.21 loss: 249.294 (lr:0.00010002907113516235)
24080: accuracy:0.25 loss: 253.751 (lr:0.00010002892614227084)
24090: accuracy:0.21 loss: 247.985 (lr:0.0001000287818725344)
24100: accuracy:0.27 loss: 253.111 (lr:0.00010002863832234625)
24110: accuracy:0.23 loss: 260.981 (lr:0.00010002849548811766)
24120: accuracy:0.2 loss: 253.84 (lr:0.00010002835336627777)
24130: accuracy:0.21 loss: 267.543 (lr:0.0001000282119532735)
24140: accuracy:0.19 loss: 270.711 (lr:0.00010002807124556953)
24150: accuracy:0.27 loss: 252.627 (lr:0.00010002793123964816)
24160: accuracy:0.26 loss: 257.075 (lr:0.00010002779193200924)
24170: accuracy:0.23 loss: 269.89 (lr:0.00010002765331917007)
24180: accuracy:0.22 loss: 264.062 (lr:0.00010002751539766532)
24190: accuracy:0.23 loss: 260.708 (lr:0.00010002737816404693)
24200: accuracy:0.2 loss: 265.04 (lr:0.00010002724161488409)
24210: accuracy:0.23 loss: 272.055 (lr:0.00010002710574676303)
24220: accuracy:0.17 loss: 265.795 (lr:0.00010002697055628705)
24230: accuracy:0.28 loss: 261.481 (lr:0.00010002683604007638)
24240: accuracy:0.25 loss: 246.09 (lr:0.00010002670219476812)
24250: accuracy:0.27 loss: 243.579 (lr:0.00010002656901701612)
24260: accuracy:0.19 loss: 267.646 (lr:0.00010002643650349091)
24270: accuracy:0.21 loss: 265.477 (lr:0.00010002630465087969)
24280: accuracy:0.17 loss: 274.759 (lr:0.00010002617345588608)
24290: accuracy:0.21 loss: 271.552 (lr:0.00010002604291523026)
24300: accuracy:0.29 loss: 255.24 (lr:0.00010002591302564866)
24310: accuracy:0.17 loss: 246.359 (lr:0.00010002578378389406)
24320: accuracy:0.18 loss: 272.497 (lr:0.0001000256551867354)
24330: accuracy:0.22 loss: 252.674 (lr:0.00010002552723095774)
24340: accuracy:0.14 loss: 274.261 (lr:0.00010002539991336218)
24350: accuracy:0.31 loss: 263.4 (lr:0.00010002527323076579)
24360: accuracy:0.26 loss: 248.578 (lr:0.00010002514718000147)
24370: accuracy:0.31 loss: 250.031 (lr:0.00010002502175791797)
24380: accuracy:0.27 loss: 254.963 (lr:0.00010002489696137973)
24390: accuracy:0.3 loss: 254.633 (lr:0.0001000247727872668)
24400: accuracy:0.18 loss: 257.862 (lr:0.00010002464923247485)
24410: accuracy:0.26 loss: 266.975 (lr:0.000100024526293915)
24420: accuracy:0.31 loss: 254.63 (lr:0.00010002440396851377)
24430: accuracy:0.24 loss: 250.98 (lr:0.00010002428225321303)
24440: accuracy:0.2 loss: 259.904 (lr:0.00010002416114496988)
24450: accuracy:0.17 loss: 269.883 (lr:0.00010002404064075662)
24460: accuracy:0.28 loss: 243.104 (lr:0.00010002392073756062)
24470: accuracy:0.2 loss: 260.244 (lr:0.00010002380143238431)
24480: accuracy:0.24 loss: 264.225 (lr:0.00010002368272224504)
24490: accuracy:0.22 loss: 247.314 (lr:0.00010002356460417507)
24500: accuracy:0.22 loss: 258.6 (lr:0.00010002344707522144)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
24500: ********* epoch 3 ********* test accuracy for all:0.196108 test loss: 273.137
24500: ********* epoch 3 ********* test accuracy for mode 0:0.002 test loss: 386.754
24500: ********* epoch 3 ********* test accuracy for mode 1:0.1605 test loss: 352.438
24500: ********* epoch 3 ********* test accuracy for mode 2:0.0865 test loss: 297.903
24500: ********* epoch 3 ********* test accuracy for mode 24:0.238 test loss: 275.632
24500: ********* epoch 3 ********* test accuracy for mode 25:0.2585 test loss: 257.699
24500: ********* epoch 3 ********* test accuracy for mode 26:0.021 test loss: 219.759
24500: ********* epoch 3 ********* test accuracy for mode 27:0.335 test loss: 268.252
24500: ********* epoch 3 ********* test accuracy for mode 28:0.1645 test loss: 269.96
24500: ********* epoch 3 ********* test accuracy for mode 29:0.3205 test loss: 275.691
24500: ********* epoch 3 ********* test accuracy for mode 30:0.1605 test loss: 278.345
24500: ********* epoch 3 ********* test accuracy for mode 31:0.092 test loss: 284.069
24500: ********* epoch 3 ********* test accuracy for mode 32:0.244 test loss: 270.158
24500: ********* epoch 3 ********* test accuracy for mode 33:0.146 test loss: 283.033
24500: ********* epoch 3 ********* test accuracy for mode 34:0.063 test loss: 281.775
24500: ********* epoch 3 ********* test accuracy for mode 35:0.0005 test loss: 428.442
24500: ********* epoch 3 ********* test accuracy for mode 36:0.054 test loss: 405.903
24510: accuracy:0.28 loss: 249.466 (lr:0.0001000233301324459)
24520: accuracy:0.24 loss: 251.495 (lr:0.00010002321377292489)
24530: accuracy:0.25 loss: 235.518 (lr:0.00010002309799374941)
24540: accuracy:0.23 loss: 251.564 (lr:0.00010002298279202498)
24550: accuracy:0.27 loss: 264.819 (lr:0.00010002286816487155)
24560: accuracy:0.2 loss: 255.727 (lr:0.00010002275410942342)
24570: accuracy:0.25 loss: 236.529 (lr:0.00010002264062282922)
24580: accuracy:0.23 loss: 248.214 (lr:0.00010002252770225177)
24590: accuracy:0.19 loss: 269.04 (lr:0.00010002241534486805)
24600: accuracy:0.23 loss: 259.885 (lr:0.00010002230354786912)
24610: accuracy:0.28 loss: 254.191 (lr:0.00010002219230846004)
24620: accuracy:0.18 loss: 272.464 (lr:0.00010002208162385984)
24630: accuracy:0.23 loss: 266.072 (lr:0.00010002197149130137)
24640: accuracy:0.25 loss: 254.705 (lr:0.00010002186190803134)
24650: accuracy:0.25 loss: 255.307 (lr:0.00010002175287131015)
24660: accuracy:0.25 loss: 270.915 (lr:0.00010002164437841186)
24670: accuracy:0.24 loss: 261.353 (lr:0.00010002153642662417)
24680: accuracy:0.2 loss: 271.824 (lr:0.00010002142901324828)
24690: accuracy:0.26 loss: 259.885 (lr:0.00010002132213559882)
24700: accuracy:0.24 loss: 261.345 (lr:0.00010002121579100386)
24710: accuracy:0.22 loss: 268.292 (lr:0.00010002110997680479)
24720: accuracy:0.29 loss: 255.614 (lr:0.00010002100469035623)
24730: accuracy:0.15 loss: 274.794 (lr:0.00010002089992902603)
24740: accuracy:0.21 loss: 247.262 (lr:0.00010002079569019514)
24750: accuracy:0.26 loss: 260.243 (lr:0.00010002069197125759)
24760: accuracy:0.31 loss: 233.196 (lr:0.0001000205887696204)
24770: accuracy:0.11 loss: 289.195 (lr:0.00010002048608270351)
24780: accuracy:0.2 loss: 255.393 (lr:0.00010002038390793978)
24790: accuracy:0.28 loss: 244.599 (lr:0.00010002028224277479)
24800: accuracy:0.23 loss: 255.259 (lr:0.00010002018108466694)
24810: accuracy:0.27 loss: 260.767 (lr:0.00010002008043108724)
24820: accuracy:0.28 loss: 250.148 (lr:0.00010001998027951937)
24830: accuracy:0.36 loss: 259.594 (lr:0.00010001988062745954)
24840: accuracy:0.25 loss: 253.903 (lr:0.00010001978147241642)
24850: accuracy:0.34 loss: 247.723 (lr:0.00010001968281191114)
24860: accuracy:0.24 loss: 258.564 (lr:0.00010001958464347719)
24870: accuracy:0.24 loss: 248.999 (lr:0.00010001948696466035)
24880: accuracy:0.19 loss: 264.888 (lr:0.00010001938977301862)
24890: accuracy:0.27 loss: 247.975 (lr:0.00010001929306612225)
24900: accuracy:0.16 loss: 254.436 (lr:0.00010001919684155352)
24910: accuracy:0.19 loss: 261.385 (lr:0.00010001910109690684)
24920: accuracy:0.3 loss: 238.151 (lr:0.00010001900582978858)
24930: accuracy:0.25 loss: 246.447 (lr:0.00010001891103781705)
24940: accuracy:0.25 loss: 246.753 (lr:0.00010001881671862245)
24950: accuracy:0.35 loss: 251.727 (lr:0.00010001872286984679)
24960: accuracy:0.19 loss: 249.721 (lr:0.00010001862948914385)
24970: accuracy:0.18 loss: 264.043 (lr:0.00010001853657417912)
24980: accuracy:0.29 loss: 262.205 (lr:0.00010001844412262971)
24990: accuracy:0.28 loss: 261.627 (lr:0.00010001835213218432)
25000: accuracy:0.19 loss: 269.955 (lr:0.0001000182606005432)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
25000: ********* epoch 3 ********* test accuracy for all:0.193 test loss: 274.411
25000: ********* epoch 3 ********* test accuracy for mode 0:0.0005 test loss: 383.209
25000: ********* epoch 3 ********* test accuracy for mode 1:0.2135 test loss: 345.204
25000: ********* epoch 3 ********* test accuracy for mode 2:0.0995 test loss: 293.484
25000: ********* epoch 3 ********* test accuracy for mode 24:0.19 test loss: 285.947
25000: ********* epoch 3 ********* test accuracy for mode 25:0.3065 test loss: 263.629
25000: ********* epoch 3 ********* test accuracy for mode 26:0.03 test loss: 211.246
25000: ********* epoch 3 ********* test accuracy for mode 27:0.351 test loss: 270.29
25000: ********* epoch 3 ********* test accuracy for mode 28:0.1545 test loss: 271.507
25000: ********* epoch 3 ********* test accuracy for mode 29:0.3075 test loss: 277.303
25000: ********* epoch 3 ********* test accuracy for mode 30:0.1495 test loss: 277.497
25000: ********* epoch 3 ********* test accuracy for mode 31:0.1515 test loss: 279.354
25000: ********* epoch 3 ********* test accuracy for mode 32:0.1705 test loss: 270.016
25000: ********* epoch 3 ********* test accuracy for mode 33:0.199 test loss: 279.408
25000: ********* epoch 3 ********* test accuracy for mode 34:0.0495 test loss: 281.265
25000: ********* epoch 3 ********* test accuracy for mode 35:0.0005 test loss: 410.477
25000: ********* epoch 3 ********* test accuracy for mode 36:0.0215 test loss: 416.757
25010: accuracy:0.21 loss: 254.689 (lr:0.00010001816952541803)
25020: accuracy:0.26 loss: 238.149 (lr:0.00010001807890453195)
25030: accuracy:0.21 loss: 269.222 (lr:0.00010001798873561942)
25040: accuracy:0.22 loss: 262.808 (lr:0.00010001789901642622)
25050: accuracy:0.23 loss: 242.03 (lr:0.00010001780974470937)
25060: accuracy:0.26 loss: 257.319 (lr:0.00010001772091823706)
25070: accuracy:0.26 loss: 245.147 (lr:0.00010001763253478863)
25080: accuracy:0.25 loss: 240.808 (lr:0.00010001754459215448)
25090: accuracy:0.23 loss: 253.028 (lr:0.00010001745708813605)
25100: accuracy:0.23 loss: 265.15 (lr:0.00010001737002054574)
25110: accuracy:0.18 loss: 256.204 (lr:0.00010001728338720684)
25120: accuracy:0.32 loss: 245.532 (lr:0.00010001719718595352)
25130: accuracy:0.25 loss: 234.274 (lr:0.00010001711141463075)
25140: accuracy:0.17 loss: 272.617 (lr:0.00010001702607109425)
25150: accuracy:0.19 loss: 260.202 (lr:0.00010001694115321039)
25160: accuracy:0.25 loss: 252.899 (lr:0.00010001685665885625)
25170: accuracy:0.24 loss: 255.404 (lr:0.00010001677258591947)
25180: accuracy:0.23 loss: 251.128 (lr:0.0001000166889322982)
25190: accuracy:0.29 loss: 242.56 (lr:0.00010001660569590111)
25200: accuracy:0.27 loss: 257.387 (lr:0.00010001652287464729)
25210: accuracy:0.24 loss: 255.276 (lr:0.00010001644046646618)
25220: accuracy:0.22 loss: 259.652 (lr:0.00010001635846929761)
25230: accuracy:0.24 loss: 253.517 (lr:0.00010001627688109161)
25240: accuracy:0.21 loss: 271.341 (lr:0.00010001619569980849)
25250: accuracy:0.21 loss: 255.23 (lr:0.0001000161149234187)
25260: accuracy:0.24 loss: 264.401 (lr:0.00010001603454990284)
25270: accuracy:0.27 loss: 254.937 (lr:0.00010001595457725156)
25280: accuracy:0.3 loss: 239.268 (lr:0.00010001587500346555)
25290: accuracy:0.26 loss: 248.209 (lr:0.00010001579582655545)
25300: accuracy:0.2 loss: 259.514 (lr:0.00010001571704454184)
25310: accuracy:0.27 loss: 252.695 (lr:0.00010001563865545515)
25320: accuracy:0.23 loss: 255.918 (lr:0.00010001556065733567)
25330: accuracy:0.25 loss: 249.003 (lr:0.00010001548304823344)
25340: accuracy:0.28 loss: 245.88 (lr:0.00010001540582620821)
25350: accuracy:0.25 loss: 243.289 (lr:0.00010001532898932944)
25360: accuracy:0.18 loss: 251.766 (lr:0.0001000152525356762)
25370: accuracy:0.2 loss: 269.337 (lr:0.00010001517646333716)
25380: accuracy:0.19 loss: 257.472 (lr:0.00010001510077041049)
25390: accuracy:0.27 loss: 239.612 (lr:0.00010001502545500385)
25400: accuracy:0.2 loss: 277.24 (lr:0.00010001495051523439)
25410: accuracy:0.25 loss: 257.668 (lr:0.00010001487594922857)
25420: accuracy:0.27 loss: 240.462 (lr:0.00010001480175512226)
25430: accuracy:0.28 loss: 241.472 (lr:0.00010001472793106061)
25440: accuracy:0.19 loss: 268.87 (lr:0.00010001465447519799)
25450: accuracy:0.2 loss: 246.169 (lr:0.00010001458138569803)
25460: accuracy:0.24 loss: 257.085 (lr:0.00010001450866073346)
25470: accuracy:0.26 loss: 251.605 (lr:0.00010001443629848616)
25480: accuracy:0.17 loss: 255.717 (lr:0.00010001436429714708)
25490: accuracy:0.18 loss: 270.802 (lr:0.00010001429265491618)
25500: accuracy:0.21 loss: 258.116 (lr:0.00010001422137000239)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
25500: ********* epoch 3 ********* test accuracy for all:0.191243 test loss: 275.335
25500: ********* epoch 3 ********* test accuracy for mode 0:0.0 test loss: 392.387
25500: ********* epoch 3 ********* test accuracy for mode 1:0.177 test loss: 350.801
25500: ********* epoch 3 ********* test accuracy for mode 2:0.051 test loss: 304.563
25500: ********* epoch 3 ********* test accuracy for mode 24:0.188 test loss: 287.96
25500: ********* epoch 3 ********* test accuracy for mode 25:0.278 test loss: 264.118
25500: ********* epoch 3 ********* test accuracy for mode 26:0.0255 test loss: 214.878
25500: ********* epoch 3 ********* test accuracy for mode 27:0.3135 test loss: 279.024
25500: ********* epoch 3 ********* test accuracy for mode 28:0.161 test loss: 278.629
25500: ********* epoch 3 ********* test accuracy for mode 29:0.322 test loss: 286.545
25500: ********* epoch 3 ********* test accuracy for mode 30:0.0535 test loss: 293.516
25500: ********* epoch 3 ********* test accuracy for mode 31:0.207 test loss: 289.722
25500: ********* epoch 3 ********* test accuracy for mode 32:0.133 test loss: 280.839
25500: ********* epoch 3 ********* test accuracy for mode 33:0.204 test loss: 284.984
25500: ********* epoch 3 ********* test accuracy for mode 34:0.117 test loss: 283.375
25500: ********* epoch 3 ********* test accuracy for mode 35:0.0 test loss: 411.676
25500: ********* epoch 3 ********* test accuracy for mode 36:0.0155 test loss: 410.442
25510: accuracy:0.25 loss: 258.248 (lr:0.00010001415044062359)
25520: accuracy:0.24 loss: 252.035 (lr:0.00010001407986500656)
25530: accuracy:0.21 loss: 263.717 (lr:0.00010001400964138687)
25540: accuracy:0.19 loss: 273.162 (lr:0.00010001393976800896)
25550: accuracy:0.26 loss: 248.714 (lr:0.00010001387024312595)
25560: accuracy:0.23 loss: 257.212 (lr:0.00010001380106499977)
25570: accuracy:0.25 loss: 258.064 (lr:0.00010001373223190092)
25580: accuracy:0.27 loss: 254.243 (lr:0.00010001366374210858)
25590: accuracy:0.17 loss: 281.856 (lr:0.0001000135955939105)
25600: accuracy:0.28 loss: 249.71 (lr:0.00010001352778560299)
25610: accuracy:0.26 loss: 245.349 (lr:0.00010001346031549081)
25620: accuracy:0.21 loss: 266.499 (lr:0.00010001339318188723)
25630: accuracy:0.22 loss: 265.693 (lr:0.00010001332638311389)
25640: accuracy:0.22 loss: 258.516 (lr:0.00010001325991750083)
25650: accuracy:0.25 loss: 280.067 (lr:0.00010001319378338638)
25660: accuracy:0.18 loss: 257.714 (lr:0.00010001312797911722)
25670: accuracy:0.19 loss: 267.272 (lr:0.00010001306250304822)
25680: accuracy:0.19 loss: 252.989 (lr:0.00010001299735354246)
25690: accuracy:0.14 loss: 257.961 (lr:0.00010001293252897123)
25700: accuracy:0.24 loss: 248.522 (lr:0.00010001286802771389)
25710: accuracy:0.18 loss: 253.777 (lr:0.00010001280384815792)
25720: accuracy:0.27 loss: 249.671 (lr:0.00010001273998869882)
25730: accuracy:0.27 loss: 271.131 (lr:0.00010001267644774011)
25740: accuracy:0.27 loss: 247.601 (lr:0.00010001261322369324)
25750: accuracy:0.22 loss: 268.43 (lr:0.00010001255031497762)
25760: accuracy:0.21 loss: 273.641 (lr:0.00010001248772002053)
25770: accuracy:0.19 loss: 256.23 (lr:0.0001000124254372571)
25780: accuracy:0.24 loss: 238.083 (lr:0.00010001236346513023)
25790: accuracy:0.19 loss: 261.369 (lr:0.00010001230180209065)
25800: accuracy:0.19 loss: 256.099 (lr:0.00010001224044659675)
25810: accuracy:0.24 loss: 268.555 (lr:0.00010001217939711465)
25820: accuracy:0.21 loss: 273.899 (lr:0.00010001211865211812)
25830: accuracy:0.32 loss: 243.253 (lr:0.00010001205821008853)
25840: accuracy:0.3 loss: 265.256 (lr:0.00010001199806951481)
25850: accuracy:0.2 loss: 275.265 (lr:0.00010001193822889346)
25860: accuracy:0.34 loss: 243.953 (lr:0.00010001187868672846)
25870: accuracy:0.25 loss: 271.615 (lr:0.00010001181944153123)
25880: accuracy:0.28 loss: 246.426 (lr:0.00010001176049182067)
25890: accuracy:0.33 loss: 264.049 (lr:0.000100011701836123)
25900: accuracy:0.21 loss: 269.818 (lr:0.00010001164347297186)
25910: accuracy:0.28 loss: 244.344 (lr:0.00010001158540090814)
25920: accuracy:0.18 loss: 264.098 (lr:0.00010001152761848005)
25930: accuracy:0.29 loss: 262.265 (lr:0.00010001147012424303)
25940: accuracy:0.29 loss: 266.044 (lr:0.0001000114129167597)
25950: accuracy:0.21 loss: 242.375 (lr:0.00010001135599459989)
25960: accuracy:0.22 loss: 252.216 (lr:0.00010001129935634054)
25970: accuracy:0.24 loss: 256.717 (lr:0.00010001124300056568)
25980: accuracy:0.21 loss: 252.578 (lr:0.00010001118692586642)
25990: accuracy:0.17 loss: 276.718 (lr:0.00010001113113084089)
26000: accuracy:0.29 loss: 248.002 (lr:0.00010001107561409421)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
26000: ********* epoch 3 ********* test accuracy for all:0.196865 test loss: 274.463
26000: ********* epoch 3 ********* test accuracy for mode 0:0.0 test loss: 381.095
26000: ********* epoch 3 ********* test accuracy for mode 1:0.1985 test loss: 345.491
26000: ********* epoch 3 ********* test accuracy for mode 2:0.074 test loss: 295.036
26000: ********* epoch 3 ********* test accuracy for mode 24:0.2165 test loss: 280.278
26000: ********* epoch 3 ********* test accuracy for mode 25:0.2835 test loss: 262.499
26000: ********* epoch 3 ********* test accuracy for mode 26:0.025 test loss: 208.644
26000: ********* epoch 3 ********* test accuracy for mode 27:0.332 test loss: 274.296
26000: ********* epoch 3 ********* test accuracy for mode 28:0.2 test loss: 274.033
26000: ********* epoch 3 ********* test accuracy for mode 29:0.248 test loss: 287.598
26000: ********* epoch 3 ********* test accuracy for mode 30:0.174 test loss: 286.178
26000: ********* epoch 3 ********* test accuracy for mode 31:0.1605 test loss: 286.095
26000: ********* epoch 3 ********* test accuracy for mode 32:0.1345 test loss: 276.837
26000: ********* epoch 3 ********* test accuracy for mode 33:0.194 test loss: 280.812
26000: ********* epoch 3 ********* test accuracy for mode 34:0.177 test loss: 273.291
26000: ********* epoch 3 ********* test accuracy for mode 35:0.0 test loss: 416.234
26000: ********* epoch 3 ********* test accuracy for mode 36:0.017 test loss: 407.343
26010: accuracy:0.21 loss: 279.137 (lr:0.00010001102037423846)
26020: accuracy:0.18 loss: 256.466 (lr:0.00010001096540989264)
26030: accuracy:0.26 loss: 257.153 (lr:0.00010001091071968265)
26040: accuracy:0.25 loss: 258.704 (lr:0.0001000108563022412)
26050: accuracy:0.3 loss: 262.023 (lr:0.00010001080215620789)
26060: accuracy:0.29 loss: 244.602 (lr:0.00010001074828022904)
26070: accuracy:0.24 loss: 234.604 (lr:0.00010001069467295775)
26080: accuracy:0.24 loss: 258.808 (lr:0.00010001064133305384)
26090: accuracy:0.25 loss: 253.991 (lr:0.00010001058825918382)
26100: accuracy:0.19 loss: 263.961 (lr:0.00010001053545002083)
26110: accuracy:0.19 loss: 255.782 (lr:0.00010001048290424464)
26120: accuracy:0.18 loss: 261.886 (lr:0.0001000104306205416)
26130: accuracy:0.25 loss: 252.065 (lr:0.00010001037859760461)
26140: accuracy:0.28 loss: 241.47 (lr:0.00010001032683413311)
26150: accuracy:0.21 loss: 269.441 (lr:0.00010001027532883299)
26160: accuracy:0.26 loss: 275.826 (lr:0.00010001022408041664)
26170: accuracy:0.25 loss: 245.713 (lr:0.00010001017308760283)
26180: accuracy:0.2 loss: 251.274 (lr:0.00010001012234911673)
26190: accuracy:0.22 loss: 255.913 (lr:0.0001000100718636899)
26200: accuracy:0.15 loss: 258.532 (lr:0.00010001002163006017)
26210: accuracy:0.23 loss: 274.997 (lr:0.00010000997164697173)
26220: accuracy:0.25 loss: 255.576 (lr:0.00010000992191317496)
26230: accuracy:0.24 loss: 240.528 (lr:0.00010000987242742656)
26240: accuracy:0.26 loss: 249.999 (lr:0.00010000982318848935)
26250: accuracy:0.32 loss: 249.505 (lr:0.00010000977419513237)
26260: accuracy:0.21 loss: 252.792 (lr:0.00010000972544613076)
26270: accuracy:0.24 loss: 258.07 (lr:0.00010000967694026583)
26280: accuracy:0.18 loss: 260.688 (lr:0.0001000096286763249)
26290: accuracy:0.2 loss: 260.814 (lr:0.00010000958065310139)
26300: accuracy:0.24 loss: 253.082 (lr:0.0001000095328693947)
26310: accuracy:0.29 loss: 246.259 (lr:0.00010000948532401024)
26320: accuracy:0.19 loss: 266.204 (lr:0.00010000943801575938)
26330: accuracy:0.28 loss: 256.741 (lr:0.00010000939094345939)
26340: accuracy:0.26 loss: 270.05 (lr:0.00010000934410593348)
26350: accuracy:0.19 loss: 257.325 (lr:0.00010000929750201072)
26360: accuracy:0.38 loss: 250.773 (lr:0.00010000925113052599)
26370: accuracy:0.32 loss: 243.758 (lr:0.00010000920499031999)
26380: accuracy:0.18 loss: 271.235 (lr:0.00010000915908023924)
26390: accuracy:0.22 loss: 260.83 (lr:0.00010000911339913597)
26400: accuracy:0.28 loss: 242.08 (lr:0.00010000906794586815)
26410: accuracy:0.19 loss: 260.007 (lr:0.00010000902271929946)
26420: accuracy:0.25 loss: 244.9 (lr:0.00010000897771829922)
26430: accuracy:0.21 loss: 254.512 (lr:0.0001000089329417424)
26440: accuracy:0.2 loss: 269.019 (lr:0.00010000888838850959)
26450: accuracy:0.22 loss: 265.57 (lr:0.00010000884405748694)
26460: accuracy:0.28 loss: 257.62 (lr:0.00010000879994756622)
26470: accuracy:0.28 loss: 239.318 (lr:0.00010000875605764463)
26480: accuracy:0.22 loss: 247.948 (lr:0.00010000871238662493)
26490: accuracy:0.27 loss: 246.704 (lr:0.00010000866893341536)
26500: accuracy:0.19 loss: 271.62 (lr:0.00010000862569692957)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
26500: ********* epoch 3 ********* test accuracy for all:0.198703 test loss: 273.293
26500: ********* epoch 3 ********* test accuracy for mode 0:0.0005 test loss: 401.146
26500: ********* epoch 3 ********* test accuracy for mode 1:0.139 test loss: 359.354
26500: ********* epoch 3 ********* test accuracy for mode 2:0.0875 test loss: 298.479
26500: ********* epoch 3 ********* test accuracy for mode 24:0.1835 test loss: 279.818
26500: ********* epoch 3 ********* test accuracy for mode 25:0.3075 test loss: 254.942
26500: ********* epoch 3 ********* test accuracy for mode 26:0.018 test loss: 213.168
26500: ********* epoch 3 ********* test accuracy for mode 27:0.3485 test loss: 264.745
26500: ********* epoch 3 ********* test accuracy for mode 28:0.1745 test loss: 268.323
26500: ********* epoch 3 ********* test accuracy for mode 29:0.316 test loss: 275.535
26500: ********* epoch 3 ********* test accuracy for mode 30:0.197 test loss: 277.068
26500: ********* epoch 3 ********* test accuracy for mode 31:0.087 test loss: 285.318
26500: ********* epoch 3 ********* test accuracy for mode 32:0.231 test loss: 270.435
26500: ********* epoch 3 ********* test accuracy for mode 33:0.2 test loss: 278.844
26500: ********* epoch 3 ********* test accuracy for mode 34:0.1035 test loss: 278.022
26500: ********* epoch 3 ********* test accuracy for mode 35:0.0005 test loss: 419.747
26500: ********* epoch 3 ********* test accuracy for mode 36:0.0285 test loss: 421.708
26510: accuracy:0.22 loss: 267.994 (lr:0.00010000858267608666)
26520: accuracy:0.19 loss: 254.725 (lr:0.0001000085398698111)
26530: accuracy:0.29 loss: 241.602 (lr:0.00010000849727703271)
26540: accuracy:0.15 loss: 261.243 (lr:0.00010000845489668671)
26550: accuracy:0.21 loss: 269.915 (lr:0.00010000841272771356)
26560: accuracy:0.3 loss: 238.219 (lr:0.00010000837076905905)
26570: accuracy:0.24 loss: 259.972 (lr:0.00010000832901967419)
26580: accuracy:0.2 loss: 256.578 (lr:0.00010000828747851526)
26590: accuracy:0.25 loss: 250.778 (lr:0.00010000824614454372)
26600: accuracy:0.22 loss: 254.911 (lr:0.00010000820501672623)
26610: accuracy:0.18 loss: 260.249 (lr:0.00010000816409403458)
26620: accuracy:0.26 loss: 260.382 (lr:0.00010000812337544572)
26630: accuracy:0.24 loss: 273.725 (lr:0.00010000808285994165)
26640: accuracy:0.23 loss: 255.183 (lr:0.00010000804254650951)
26650: accuracy:0.2 loss: 246.43 (lr:0.00010000800243414145)
26660: accuracy:0.2 loss: 251.666 (lr:0.00010000796252183466)
26670: accuracy:0.26 loss: 247.029 (lr:0.00010000792280859133)
26680: accuracy:0.31 loss: 235.287 (lr:0.00010000788329341864)
26690: accuracy:0.21 loss: 264.624 (lr:0.00010000784397532868)
26700: accuracy:0.32 loss: 243.618 (lr:0.00010000780485333851)
26710: accuracy:0.24 loss: 252.862 (lr:0.0001000077659264701)
26720: accuracy:0.22 loss: 240.013 (lr:0.00010000772719375024)
26730: accuracy:0.22 loss: 258.087 (lr:0.00010000768865421062)
26740: accuracy:0.29 loss: 251.715 (lr:0.00010000765030688776)
26750: accuracy:0.22 loss: 240.261 (lr:0.00010000761215082299)
26760: accuracy:0.21 loss: 258.665 (lr:0.00010000757418506236)
26770: accuracy:0.23 loss: 259.377 (lr:0.00010000753640865677)
26780: accuracy:0.2 loss: 255.906 (lr:0.00010000749882066177)
26790: accuracy:0.22 loss: 253.814 (lr:0.0001000074614201377)
26800: accuracy:0.27 loss: 243.552 (lr:0.0001000074242061495)
26810: accuracy:0.2 loss: 284.47 (lr:0.00010000738717776686)
26820: accuracy:0.3 loss: 238.418 (lr:0.00010000735033406404)
26830: accuracy:0.21 loss: 277.176 (lr:0.00010000731367411996)
26840: accuracy:0.24 loss: 248.958 (lr:0.0001000072771970181)
26850: accuracy:0.25 loss: 259.94 (lr:0.00010000724090184656)
26860: accuracy:0.27 loss: 261.622 (lr:0.00010000720478769793)
26870: accuracy:0.27 loss: 249.822 (lr:0.00010000716885366938)
26880: accuracy:0.27 loss: 257.007 (lr:0.00010000713309886253)
26890: accuracy:0.26 loss: 250.474 (lr:0.00010000709752238354)
26900: accuracy:0.29 loss: 256.944 (lr:0.00010000706212334298)
26910: accuracy:0.27 loss: 248.105 (lr:0.00010000702690085586)
26920: accuracy:0.26 loss: 247.21 (lr:0.00010000699185404163)
26930: accuracy:0.21 loss: 249.297 (lr:0.0001000069569820241)
26940: accuracy:0.2 loss: 259.73 (lr:0.00010000692228393151)
26950: accuracy:0.22 loss: 252.182 (lr:0.00010000688775889636)
26960: accuracy:0.26 loss: 263.775 (lr:0.00010000685340605556)
26970: accuracy:0.27 loss: 256.614 (lr:0.00010000681922455025)
26980: accuracy:0.27 loss: 238.861 (lr:0.00010000678521352592)
26990: accuracy:0.17 loss: 270.527 (lr:0.00010000675137213227)
27000: accuracy:0.26 loss: 265.286 (lr:0.00010000671769952328)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
27000: ********* epoch 3 ********* test accuracy for all:0.198932 test loss: 271.708
27000: ********* epoch 3 ********* test accuracy for mode 0:0.0005 test loss: 389.025
27000: ********* epoch 3 ********* test accuracy for mode 1:0.148 test loss: 355.306
27000: ********* epoch 3 ********* test accuracy for mode 2:0.0875 test loss: 292.237
27000: ********* epoch 3 ********* test accuracy for mode 24:0.2025 test loss: 278.26
27000: ********* epoch 3 ********* test accuracy for mode 25:0.276 test loss: 255.713
27000: ********* epoch 3 ********* test accuracy for mode 26:0.021 test loss: 208.729
27000: ********* epoch 3 ********* test accuracy for mode 27:0.375 test loss: 258.634
27000: ********* epoch 3 ********* test accuracy for mode 28:0.1665 test loss: 261.432
27000: ********* epoch 3 ********* test accuracy for mode 29:0.3175 test loss: 268.319
27000: ********* epoch 3 ********* test accuracy for mode 30:0.0985 test loss: 274.451
27000: ********* epoch 3 ********* test accuracy for mode 31:0.249 test loss: 270.385
27000: ********* epoch 3 ********* test accuracy for mode 32:0.107 test loss: 264.276
27000: ********* epoch 3 ********* test accuracy for mode 33:0.2795 test loss: 270.417
27000: ********* epoch 3 ********* test accuracy for mode 34:0.0665 test loss: 273.703
27000: ********* epoch 3 ********* test accuracy for mode 35:0.0005 test loss: 417.836
27000: ********* epoch 3 ********* test accuracy for mode 36:0.0175 test loss: 420.737
27010: accuracy:0.31 loss: 239.457 (lr:0.00010000668419485713)
27020: accuracy:0.27 loss: 257.784 (lr:0.0001000066508572962)
27030: accuracy:0.27 loss: 264.229 (lr:0.00010000661768600706)
27040: accuracy:0.31 loss: 236.686 (lr:0.0001000065846801604)
27050: accuracy:0.21 loss: 275.09 (lr:0.0001000065518389311)
27060: accuracy:0.2 loss: 281.143 (lr:0.0001000065191614981)
27070: accuracy:0.36 loss: 231.979 (lr:0.00010000648664704447)
27080: accuracy:0.24 loss: 263.51 (lr:0.00010000645429475738)
27090: accuracy:0.24 loss: 246.612 (lr:0.00010000642210382797)
27100: accuracy:0.23 loss: 248.53 (lr:0.0001000063900734515)
27110: accuracy:0.24 loss: 248.642 (lr:0.0001000063582028272)
27120: accuracy:0.18 loss: 255.786 (lr:0.0001000063264911583)
27130: accuracy:0.26 loss: 246.707 (lr:0.00010000629493765202)
27140: accuracy:0.19 loss: 255.792 (lr:0.0001000062635415195)
27150: accuracy:0.18 loss: 251.678 (lr:0.00010000623230197584)
27160: accuracy:0.23 loss: 264.514 (lr:0.00010000620121824006)
27170: accuracy:0.25 loss: 255.61 (lr:0.00010000617028953505)
27180: accuracy:0.25 loss: 255.207 (lr:0.00010000613951508761)
27190: accuracy:0.17 loss: 259.313 (lr:0.00010000610889412837)
27200: accuracy:0.27 loss: 278.491 (lr:0.00010000607842589179)
27210: accuracy:0.26 loss: 244.984 (lr:0.00010000604810961618)
27220: accuracy:0.34 loss: 239.36 (lr:0.00010000601794454363)
27230: accuracy:0.18 loss: 271.01 (lr:0.00010000598792992)
27240: accuracy:0.24 loss: 245.073 (lr:0.00010000595806499493)
27250: accuracy:0.21 loss: 257.358 (lr:0.00010000592834902179)
27260: accuracy:0.22 loss: 258.694 (lr:0.0001000058987812577)
27270: accuracy:0.36 loss: 235.449 (lr:0.00010000586936096344)
27280: accuracy:0.19 loss: 260.393 (lr:0.00010000584008740351)
27290: accuracy:0.24 loss: 266.539 (lr:0.00010000581095984606)
27300: accuracy:0.21 loss: 256.322 (lr:0.00010000578197756292)
27310: accuracy:0.23 loss: 253.285 (lr:0.00010000575313982952)
27320: accuracy:0.26 loss: 254.413 (lr:0.00010000572444592491)
27330: accuracy:0.22 loss: 254.526 (lr:0.00010000569589513175)
27340: accuracy:0.28 loss: 247.157 (lr:0.00010000566748673627)
27350: accuracy:0.25 loss: 267.863 (lr:0.00010000563922002824)
27360: accuracy:0.26 loss: 268.883 (lr:0.00010000561109430102)
27370: accuracy:0.16 loss: 258.902 (lr:0.00010000558310885144)
27380: accuracy:0.24 loss: 251.219 (lr:0.00010000555526297987)
27390: accuracy:0.25 loss: 249.283 (lr:0.00010000552755599017)
27400: accuracy:0.23 loss: 261.744 (lr:0.00010000549998718965)
27410: accuracy:0.3 loss: 242.297 (lr:0.0001000054725558891)
27420: accuracy:0.28 loss: 234.53 (lr:0.00010000544526140274)
27430: accuracy:0.26 loss: 248.932 (lr:0.0001000054181030482)
27440: accuracy:0.16 loss: 257.931 (lr:0.0001000053910801465)
27450: accuracy:0.2 loss: 258.859 (lr:0.0001000053641920221)
27460: accuracy:0.22 loss: 252.67 (lr:0.00010000533743800277)
27470: accuracy:0.21 loss: 255.69 (lr:0.00010000531081741968)
27480: accuracy:0.21 loss: 260.123 (lr:0.00010000528432960729)
27490: accuracy:0.3 loss: 262.482 (lr:0.00010000525797390342)
27500: accuracy:0.22 loss: 254.598 (lr:0.00010000523174964918)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
27500: ********* epoch 3 ********* test accuracy for all:0.199784 test loss: 272.035
27500: ********* epoch 3 ********* test accuracy for mode 0:0.0 test loss: 390.424
27500: ********* epoch 3 ********* test accuracy for mode 1:0.1515 test loss: 352.948
27500: ********* epoch 3 ********* test accuracy for mode 2:0.087 test loss: 288.353
27500: ********* epoch 3 ********* test accuracy for mode 24:0.214 test loss: 282.408
27500: ********* epoch 3 ********* test accuracy for mode 25:0.2695 test loss: 263.814
27500: ********* epoch 3 ********* test accuracy for mode 26:0.02 test loss: 212.561
27500: ********* epoch 3 ********* test accuracy for mode 27:0.327 test loss: 270.568
27500: ********* epoch 3 ********* test accuracy for mode 28:0.17 test loss: 265.508
27500: ********* epoch 3 ********* test accuracy for mode 29:0.3335 test loss: 267.744
27500: ********* epoch 3 ********* test accuracy for mode 30:0.1375 test loss: 271.091
27500: ********* epoch 3 ********* test accuracy for mode 31:0.1735 test loss: 274.118
27500: ********* epoch 3 ********* test accuracy for mode 32:0.1945 test loss: 261.84
27500: ********* epoch 3 ********* test accuracy for mode 33:0.163 test loss: 272.896
27500: ********* epoch 3 ********* test accuracy for mode 34:0.1825 test loss: 269.1
27500: ********* epoch 3 ********* test accuracy for mode 35:0.0 test loss: 412.722
27500: ********* epoch 3 ********* test accuracy for mode 36:0.016 test loss: 415.661
27510: accuracy:0.25 loss: 256.848 (lr:0.00010000520565618894)
27520: accuracy:0.18 loss: 269.912 (lr:0.00010000517969287038)
27530: accuracy:0.22 loss: 263.764 (lr:0.00010000515385904442)
27540: accuracy:0.3 loss: 254.94 (lr:0.00010000512815406519)
27550: accuracy:0.2 loss: 244.026 (lr:0.00010000510257729009)
27560: accuracy:0.21 loss: 249.865 (lr:0.00010000507712807968)
27570: accuracy:0.22 loss: 268.758 (lr:0.00010000505180579775)
27580: accuracy:0.26 loss: 251.66 (lr:0.00010000502660981121)
27590: accuracy:0.2 loss: 254.212 (lr:0.00010000500153949019)
27600: accuracy:0.26 loss: 247.589 (lr:0.00010000497659420791)
27610: accuracy:0.17 loss: 256.52 (lr:0.00010000495177334075)
27620: accuracy:0.25 loss: 253.248 (lr:0.00010000492707626818)
27630: accuracy:0.27 loss: 248.305 (lr:0.00010000490250237278)
27640: accuracy:0.21 loss: 245.306 (lr:0.00010000487805104019)
27650: accuracy:0.17 loss: 268.408 (lr:0.00010000485372165912)
27660: accuracy:0.29 loss: 249.385 (lr:0.00010000482951362135)
27670: accuracy:0.31 loss: 229.847 (lr:0.00010000480542632168)
27680: accuracy:0.22 loss: 251.724 (lr:0.00010000478145915791)
27690: accuracy:0.27 loss: 232.471 (lr:0.00010000475761153087)
27700: accuracy:0.19 loss: 275.735 (lr:0.00010000473388284437)
27710: accuracy:0.25 loss: 257.576 (lr:0.00010000471027250519)
27720: accuracy:0.23 loss: 259.614 (lr:0.00010000468677992305)
27730: accuracy:0.22 loss: 240.221 (lr:0.00010000466340451067)
27740: accuracy:0.27 loss: 246.185 (lr:0.00010000464014568364)
27750: accuracy:0.26 loss: 250.435 (lr:0.00010000461700286049)
27760: accuracy:0.24 loss: 249.21 (lr:0.00010000459397546266)
27770: accuracy:0.29 loss: 251.301 (lr:0.00010000457106291446)
27780: accuracy:0.22 loss: 263.612 (lr:0.00010000454826464305)
27790: accuracy:0.21 loss: 246.234 (lr:0.00010000452558007851)
27800: accuracy:0.2 loss: 258.08 (lr:0.0001000045030086537)
27810: accuracy:0.31 loss: 229.188 (lr:0.00010000448054980435)
27820: accuracy:0.18 loss: 241.411 (lr:0.00010000445820296898)
27830: accuracy:0.26 loss: 252.935 (lr:0.00010000443596758891)
27840: accuracy:0.17 loss: 282.61 (lr:0.00010000441384310825)
27850: accuracy:0.29 loss: 252.039 (lr:0.0001000043918289739)
27860: accuracy:0.26 loss: 247.756 (lr:0.00010000436992463552)
27870: accuracy:0.31 loss: 240.668 (lr:0.00010000434812954547)
27880: accuracy:0.19 loss: 258.354 (lr:0.0001000043264431589)
27890: accuracy:0.21 loss: 262.442 (lr:0.00010000430486493362)
27900: accuracy:0.21 loss: 262.68 (lr:0.00010000428339433018)
27910: accuracy:0.21 loss: 248.884 (lr:0.00010000426203081184)
27920: accuracy:0.27 loss: 266.637 (lr:0.00010000424077384448)
27930: accuracy:0.23 loss: 250.405 (lr:0.00010000421962289669)
27940: accuracy:0.24 loss: 252.733 (lr:0.0001000041985774397)
27950: accuracy:0.22 loss: 254.459 (lr:0.00010000417763694736)
27960: accuracy:0.18 loss: 282.103 (lr:0.00010000415680089616)
27970: accuracy:0.21 loss: 243.35 (lr:0.0001000041360687652)
27980: accuracy:0.2 loss: 247.222 (lr:0.00010000411544003617)
27990: accuracy:0.3 loss: 252.619 (lr:0.00010000409491419335)
28000: accuracy:0.22 loss: 267.195 (lr:0.00010000407449072361)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
28000: ********* epoch 3 ********* test accuracy for all:0.196392 test loss: 272.665
28000: ********* epoch 3 ********* test accuracy for mode 0:0.0005 test loss: 390.111
28000: ********* epoch 3 ********* test accuracy for mode 1:0.1255 test loss: 355.797
28000: ********* epoch 3 ********* test accuracy for mode 2:0.0705 test loss: 290.566
28000: ********* epoch 3 ********* test accuracy for mode 24:0.217 test loss: 282.802
28000: ********* epoch 3 ********* test accuracy for mode 25:0.2895 test loss: 260.737
28000: ********* epoch 3 ********* test accuracy for mode 26:0.04 test loss: 213.005
28000: ********* epoch 3 ********* test accuracy for mode 27:0.2905 test loss: 274.998
28000: ********* epoch 3 ********* test accuracy for mode 28:0.191 test loss: 271.602
28000: ********* epoch 3 ********* test accuracy for mode 29:0.275 test loss: 280.202
28000: ********* epoch 3 ********* test accuracy for mode 30:0.162 test loss: 278.249
28000: ********* epoch 3 ********* test accuracy for mode 31:0.173 test loss: 281.446
28000: ********* epoch 3 ********* test accuracy for mode 32:0.176 test loss: 268.911
28000: ********* epoch 3 ********* test accuracy for mode 33:0.204 test loss: 277.137
28000: ********* epoch 3 ********* test accuracy for mode 34:0.102 test loss: 273.863
28000: ********* epoch 3 ********* test accuracy for mode 35:0.0 test loss: 406.834
28000: ********* epoch 3 ********* test accuracy for mode 36:0.026 test loss: 418.969
28010: accuracy:0.19 loss: 255.163 (lr:0.00010000405416911635)
28020: accuracy:0.2 loss: 284.869 (lr:0.00010000403394886352)
28030: accuracy:0.26 loss: 254.103 (lr:0.00010000401382945963)
28040: accuracy:0.24 loss: 237.229 (lr:0.00010000399381040169)
28050: accuracy:0.24 loss: 249.712 (lr:0.00010000397389118921)
28060: accuracy:0.19 loss: 271.331 (lr:0.00010000395407132422)
28070: accuracy:0.24 loss: 270.221 (lr:0.00010000393435031122)
28080: accuracy:0.23 loss: 241.452 (lr:0.00010000391472765717)
28090: accuracy:0.25 loss: 247.116 (lr:0.00010000389520287153)
28100: accuracy:0.25 loss: 254.114 (lr:0.00010000387577546616)
28110: accuracy:0.21 loss: 273.708 (lr:0.00010000385644495537)
28120: accuracy:0.22 loss: 256.829 (lr:0.00010000383721085591)
28130: accuracy:0.26 loss: 257.343 (lr:0.00010000381807268693)
28140: accuracy:0.26 loss: 257.737 (lr:0.00010000379902996997)
28150: accuracy:0.24 loss: 256.625 (lr:0.00010000378008222894)
28160: accuracy:0.22 loss: 258.263 (lr:0.00010000376122899017)
28170: accuracy:0.32 loss: 246.749 (lr:0.00010000374246978232)
28180: accuracy:0.32 loss: 241.003 (lr:0.0001000037238041364)
28190: accuracy:0.26 loss: 252.442 (lr:0.0001000037052315858)
28200: accuracy:0.27 loss: 261.205 (lr:0.00010000368675166617)
28210: accuracy:0.12 loss: 271.107 (lr:0.00010000366836391552)
28220: accuracy:0.25 loss: 257.857 (lr:0.00010000365006787416)
28230: accuracy:0.23 loss: 260.268 (lr:0.00010000363186308469)
28240: accuracy:0.29 loss: 231.44 (lr:0.00010000361374909199)
28250: accuracy:0.2 loss: 274.148 (lr:0.0001000035957254432)
28260: accuracy:0.3 loss: 239.815 (lr:0.00010000357779168773)
28270: accuracy:0.16 loss: 262.787 (lr:0.00010000355994737724)
28280: accuracy:0.31 loss: 242.76 (lr:0.00010000354219206563)
28290: accuracy:0.19 loss: 271.479 (lr:0.000100003524525309)
28300: accuracy:0.26 loss: 263.613 (lr:0.00010000350694666569)
28310: accuracy:0.21 loss: 246.17 (lr:0.00010000348945569621)
28320: accuracy:0.23 loss: 258.119 (lr:0.00010000347205196333)
28330: accuracy:0.26 loss: 260.673 (lr:0.00010000345473503192)
28340: accuracy:0.28 loss: 265.396 (lr:0.00010000343750446907)
28350: accuracy:0.3 loss: 235.685 (lr:0.00010000342035984399)
28360: accuracy:0.17 loss: 251.779 (lr:0.00010000340330072811)
28370: accuracy:0.26 loss: 238.692 (lr:0.00010000338632669492)
28380: accuracy:0.26 loss: 247.35 (lr:0.00010000336943732006)
28390: accuracy:0.19 loss: 255.478 (lr:0.00010000335263218132)
28400: accuracy:0.27 loss: 258.814 (lr:0.00010000333591085855)
28410: accuracy:0.2 loss: 275.405 (lr:0.00010000331927293373)
28420: accuracy:0.18 loss: 241.899 (lr:0.00010000330271799092)
28430: accuracy:0.15 loss: 261.7 (lr:0.00010000328624561621)
28440: accuracy:0.3 loss: 247.457 (lr:0.00010000326985539782)
28450: accuracy:0.22 loss: 259.178 (lr:0.00010000325354692599)
28460: accuracy:0.2 loss: 262.173 (lr:0.00010000323731979299)
28470: accuracy:0.27 loss: 245.836 (lr:0.00010000322117359318)
28480: accuracy:0.19 loss: 247.377 (lr:0.00010000320510792284)
28490: accuracy:0.16 loss: 254.257 (lr:0.00010000318912238039)
28500: accuracy:0.24 loss: 259.662 (lr:0.00010000317321656617)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
28500: ********* epoch 3 ********* test accuracy for all:0.201473 test loss: 272.678
28500: ********* epoch 3 ********* test accuracy for mode 0:0.0 test loss: 393.417
28500: ********* epoch 3 ********* test accuracy for mode 1:0.1195 test loss: 359.018
28500: ********* epoch 3 ********* test accuracy for mode 2:0.087 test loss: 288.549
28500: ********* epoch 3 ********* test accuracy for mode 24:0.218 test loss: 290.15
28500: ********* epoch 3 ********* test accuracy for mode 25:0.324 test loss: 266.044
28500: ********* epoch 3 ********* test accuracy for mode 26:0.0275 test loss: 210.527
28500: ********* epoch 3 ********* test accuracy for mode 27:0.335 test loss: 275.548
28500: ********* epoch 3 ********* test accuracy for mode 28:0.168 test loss: 275.165
28500: ********* epoch 3 ********* test accuracy for mode 29:0.292 test loss: 280.135
28500: ********* epoch 3 ********* test accuracy for mode 30:0.1085 test loss: 279.769
28500: ********* epoch 3 ********* test accuracy for mode 31:0.2075 test loss: 273.395
28500: ********* epoch 3 ********* test accuracy for mode 32:0.2045 test loss: 259.732
28500: ********* epoch 3 ********* test accuracy for mode 33:0.2545 test loss: 266.754
28500: ********* epoch 3 ********* test accuracy for mode 34:0.0475 test loss: 268.754
28500: ********* epoch 3 ********* test accuracy for mode 35:0.0 test loss: 423.062
28500: ********* epoch 3 ********* test accuracy for mode 36:0.0165 test loss: 446.742
28510: accuracy:0.32 loss: 216.902 (lr:0.00010000315739008252)
28520: accuracy:0.25 loss: 241.329 (lr:0.00010000314164253379)
28530: accuracy:0.24 loss: 261.616 (lr:0.00010000312597352627)
28540: accuracy:0.2 loss: 290.314 (lr:0.00010000311038266827)
28550: accuracy:0.23 loss: 263.852 (lr:0.00010000309486957)
28560: accuracy:0.23 loss: 261.9 (lr:0.00010000307943384362)
28570: accuracy:0.24 loss: 239.42 (lr:0.00010000306407510325)
28580: accuracy:0.22 loss: 270.159 (lr:0.00010000304879296492)
28590: accuracy:0.22 loss: 241.636 (lr:0.00010000303358704657)
28600: accuracy:0.25 loss: 257.18 (lr:0.00010000301845696805)
28610: accuracy:0.22 loss: 265.606 (lr:0.00010000300340235111)
28620: accuracy:0.26 loss: 249.575 (lr:0.0001000029884228194)
28630: accuracy:0.25 loss: 251.801 (lr:0.0001000029735179984)
28640: accuracy:0.27 loss: 264.328 (lr:0.00010000295868751552)
28650: accuracy:0.24 loss: 273.658 (lr:0.00010000294393099997)
28660: accuracy:0.22 loss: 260.136 (lr:0.00010000292924808286)
28670: accuracy:0.2 loss: 256.462 (lr:0.0001000029146383971)
28680: accuracy:0.25 loss: 250.666 (lr:0.00010000290010157744)
28690: accuracy:0.32 loss: 233.603 (lr:0.00010000288563726048)
28700: accuracy:0.28 loss: 244.597 (lr:0.0001000028712450846)
28710: accuracy:0.23 loss: 261.056 (lr:0.00010000285692469)
28720: accuracy:0.3 loss: 251.755 (lr:0.00010000284267571866)
28730: accuracy:0.27 loss: 264.646 (lr:0.00010000282849781436)
28740: accuracy:0.28 loss: 258.665 (lr:0.00010000281439062267)
28750: accuracy:0.24 loss: 248.177 (lr:0.00010000280035379087)
28760: accuracy:0.23 loss: 245.277 (lr:0.00010000278638696807)
28770: accuracy:0.37 loss: 245.21 (lr:0.0001000027724898051)
28780: accuracy:0.26 loss: 255.904 (lr:0.0001000027586619545)
28790: accuracy:0.28 loss: 245.606 (lr:0.0001000027449030706)
28800: accuracy:0.29 loss: 250.323 (lr:0.00010000273121280943)
28810: accuracy:0.17 loss: 271.441 (lr:0.00010000271759082871)
28820: accuracy:0.29 loss: 240.39 (lr:0.0001000027040367879)
28830: accuracy:0.2 loss: 256.378 (lr:0.00010000269055034817)
28840: accuracy:0.26 loss: 250.705 (lr:0.00010000267713117232)
28850: accuracy:0.22 loss: 265.364 (lr:0.00010000266377892489)
28860: accuracy:0.31 loss: 249.996 (lr:0.00010000265049327208)
28870: accuracy:0.29 loss: 233.562 (lr:0.00010000263727388173)
28880: accuracy:0.22 loss: 250.89 (lr:0.00010000262412042337)
28890: accuracy:0.28 loss: 258.791 (lr:0.00010000261103256817)
28900: accuracy:0.27 loss: 227.292 (lr:0.0001000025980099889)
28910: accuracy:0.2 loss: 244.782 (lr:0.00010000258505236002)
28920: accuracy:0.24 loss: 260.98 (lr:0.0001000025721593576)
28930: accuracy:0.26 loss: 251.251 (lr:0.00010000255933065927)
28940: accuracy:0.24 loss: 246.022 (lr:0.00010000254656594435)
28950: accuracy:0.21 loss: 255.425 (lr:0.00010000253386489372)
28960: accuracy:0.26 loss: 253.922 (lr:0.00010000252122718984)
28970: accuracy:0.21 loss: 241.15 (lr:0.00010000250865251678)
28980: accuracy:0.28 loss: 230.94 (lr:0.00010000249614056015)
28990: accuracy:0.22 loss: 248.528 (lr:0.00010000248369100716)
29000: accuracy:0.31 loss: 245.177 (lr:0.00010000247130354659)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
29000: ********* epoch 3 ********* test accuracy for all:0.203203 test loss: 269.831
29000: ********* epoch 3 ********* test accuracy for mode 0:0.0 test loss: 388.156
29000: ********* epoch 3 ********* test accuracy for mode 1:0.1535 test loss: 350.236
29000: ********* epoch 3 ********* test accuracy for mode 2:0.1125 test loss: 290.649
29000: ********* epoch 3 ********* test accuracy for mode 24:0.2095 test loss: 269.203
29000: ********* epoch 3 ********* test accuracy for mode 25:0.3455 test loss: 245.809
29000: ********* epoch 3 ********* test accuracy for mode 26:0.035 test loss: 207.574
29000: ********* epoch 3 ********* test accuracy for mode 27:0.2995 test loss: 263.068
29000: ********* epoch 3 ********* test accuracy for mode 28:0.2065 test loss: 256.611
29000: ********* epoch 3 ********* test accuracy for mode 29:0.318 test loss: 264.778
29000: ********* epoch 3 ********* test accuracy for mode 30:0.129 test loss: 272.927
29000: ********* epoch 3 ********* test accuracy for mode 31:0.186 test loss: 274.573
29000: ********* epoch 3 ********* test accuracy for mode 32:0.1605 test loss: 265.105
29000: ********* epoch 3 ********* test accuracy for mode 33:0.305 test loss: 270.428
29000: ********* epoch 3 ********* test accuracy for mode 34:0.0035 test loss: 278.344
29000: ********* epoch 3 ********* test accuracy for mode 35:0.0 test loss: 407.948
29000: ********* epoch 3 ********* test accuracy for mode 36:0.0675 test loss: 404.82
29010: accuracy:0.21 loss: 252.709 (lr:0.00010000245897786873)
29020: accuracy:0.22 loss: 254.621 (lr:0.00010000244671366544)
29030: accuracy:0.25 loss: 249.754 (lr:0.00010000243451063012)
29040: accuracy:0.2 loss: 262.813 (lr:0.00010000242236845771)
29050: accuracy:0.24 loss: 264.252 (lr:0.00010000241028684461)
29060: accuracy:0.21 loss: 245.977 (lr:0.00010000239826548883)
29070: accuracy:0.23 loss: 246.801 (lr:0.0001000023863040898)
29080: accuracy:0.16 loss: 271.583 (lr:0.0001000023744023485)
29090: accuracy:0.28 loss: 236.345 (lr:0.00010000236255996738)
29100: accuracy:0.24 loss: 254.44 (lr:0.00010000235077665038)
29110: accuracy:0.27 loss: 271.033 (lr:0.00010000233905210293)
29120: accuracy:0.26 loss: 251.62 (lr:0.0001000023273860319)
29130: accuracy:0.31 loss: 218.524 (lr:0.00010000231577814564)
29140: accuracy:0.22 loss: 246.195 (lr:0.00010000230422815395)
29150: accuracy:0.27 loss: 256.296 (lr:0.00010000229273576809)
29160: accuracy:0.26 loss: 241.982 (lr:0.00010000228130070073)
29170: accuracy:0.23 loss: 248.214 (lr:0.00010000226992266603)
29180: accuracy:0.24 loss: 264.301 (lr:0.0001000022586013795)
29190: accuracy:0.19 loss: 263.167 (lr:0.00010000224733655812)
29200: accuracy:0.3 loss: 225.405 (lr:0.00010000223612792027)
29210: accuracy:0.21 loss: 235.292 (lr:0.00010000222497518575)
29220: accuracy:0.2 loss: 274.321 (lr:0.00010000221387807571)
29230: accuracy:0.24 loss: 253.48 (lr:0.00010000220283631275)
29240: accuracy:0.23 loss: 251.537 (lr:0.00010000219184962081)
29250: accuracy:0.28 loss: 244.759 (lr:0.00010000218091772521)
29260: accuracy:0.31 loss: 253.055 (lr:0.00010000217004035267)
29270: accuracy:0.21 loss: 241.878 (lr:0.00010000215921723126)
29280: accuracy:0.28 loss: 256.359 (lr:0.00010000214844809039)
29290: accuracy:0.24 loss: 242.0 (lr:0.00010000213773266084)
29300: accuracy:0.26 loss: 251.206 (lr:0.00010000212707067471)
29310: accuracy:0.26 loss: 236.032 (lr:0.00010000211646186547)
29320: accuracy:0.14 loss: 273.922 (lr:0.00010000210590596787)
29330: accuracy:0.27 loss: 250.567 (lr:0.00010000209540271804)
29340: accuracy:0.28 loss: 258.748 (lr:0.00010000208495185338)
29350: accuracy:0.25 loss: 235.279 (lr:0.00010000207455311263)
29360: accuracy:0.28 loss: 231.439 (lr:0.00010000206420623582)
29370: accuracy:0.29 loss: 236.383 (lr:0.00010000205391096427)
29380: accuracy:0.23 loss: 253.148 (lr:0.0001000020436670406)
29390: accuracy:0.22 loss: 251.588 (lr:0.00010000203347420871)
29400: accuracy:0.22 loss: 252.444 (lr:0.00010000202333221379)
29410: accuracy:0.33 loss: 236.83 (lr:0.00010000201324080226)
29420: accuracy:0.26 loss: 246.397 (lr:0.00010000200319972187)
29430: accuracy:0.25 loss: 239.201 (lr:0.00010000199320872159)
29440: accuracy:0.23 loss: 252.303 (lr:0.00010000198326755162)
29450: accuracy:0.24 loss: 254.542 (lr:0.00010000197337596343)
29460: accuracy:0.22 loss: 255.852 (lr:0.00010000196353370975)
29470: accuracy:0.27 loss: 238.14 (lr:0.00010000195374054451)
29480: accuracy:0.26 loss: 241.733 (lr:0.0001000019439962229)
29490: accuracy:0.23 loss: 241.499 (lr:0.00010000193430050128)
29500: accuracy:0.22 loss: 261.618 (lr:0.0001000019246531373)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
29500: ********* epoch 4 ********* test accuracy for all:0.20077 test loss: 270.637
29500: ********* epoch 4 ********* test accuracy for mode 0:0.0 test loss: 389.13
29500: ********* epoch 4 ********* test accuracy for mode 1:0.1305 test loss: 351.511
29500: ********* epoch 4 ********* test accuracy for mode 2:0.0995 test loss: 294.366
29500: ********* epoch 4 ********* test accuracy for mode 24:0.214 test loss: 273.192
29500: ********* epoch 4 ********* test accuracy for mode 25:0.311 test loss: 250.268
29500: ********* epoch 4 ********* test accuracy for mode 26:0.0505 test loss: 205.795
29500: ********* epoch 4 ********* test accuracy for mode 27:0.305 test loss: 269.73
29500: ********* epoch 4 ********* test accuracy for mode 28:0.228 test loss: 263.082
29500: ********* epoch 4 ********* test accuracy for mode 29:0.285 test loss: 277.937
29500: ********* epoch 4 ********* test accuracy for mode 30:0.146 test loss: 281.097
29500: ********* epoch 4 ********* test accuracy for mode 31:0.14 test loss: 284.985
29500: ********* epoch 4 ********* test accuracy for mode 32:0.218 test loss: 269.566
29500: ********* epoch 4 ********* test accuracy for mode 33:0.2355 test loss: 277.927
29500: ********* epoch 4 ********* test accuracy for mode 34:0.0395 test loss: 279.246
29500: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 412.812
29500: ********* epoch 4 ********* test accuracy for mode 36:0.0315 test loss: 418.15
29510: accuracy:0.25 loss: 253.691 (lr:0.00010000191505388972)
29520: accuracy:0.23 loss: 231.414 (lr:0.0001000019055025186)
29530: accuracy:0.27 loss: 251.302 (lr:0.00010000189599878514)
29540: accuracy:0.25 loss: 263.441 (lr:0.00010000188654245175)
29550: accuracy:0.28 loss: 242.318 (lr:0.00010000187713328202)
29560: accuracy:0.26 loss: 256.745 (lr:0.00010000186777104071)
29570: accuracy:0.25 loss: 255.823 (lr:0.00010000185845549379)
29580: accuracy:0.39 loss: 228.054 (lr:0.00010000184918640835)
29590: accuracy:0.26 loss: 230.779 (lr:0.00010000183996355266)
29600: accuracy:0.21 loss: 253.121 (lr:0.00010000183078669614)
29610: accuracy:0.23 loss: 235.815 (lr:0.0001000018216556094)
29620: accuracy:0.27 loss: 258.892 (lr:0.00010000181257006415)
29630: accuracy:0.15 loss: 272.981 (lr:0.00010000180352983324)
29640: accuracy:0.23 loss: 247.64 (lr:0.00010000179453469068)
29650: accuracy:0.23 loss: 272.88 (lr:0.00010000178558441156)
29660: accuracy:0.19 loss: 242.895 (lr:0.00010000177667877215)
29670: accuracy:0.2 loss: 251.988 (lr:0.00010000176781754981)
29680: accuracy:0.2 loss: 269.55 (lr:0.000100001759000523)
29690: accuracy:0.17 loss: 269.679 (lr:0.00010000175022747129)
29700: accuracy:0.27 loss: 244.018 (lr:0.00010000174149817537)
29710: accuracy:0.28 loss: 235.295 (lr:0.00010000173281241697)
29720: accuracy:0.22 loss: 266.568 (lr:0.000100001724169979)
29730: accuracy:0.32 loss: 242.702 (lr:0.00010000171557064535)
29740: accuracy:0.29 loss: 259.943 (lr:0.00010000170701420106)
29750: accuracy:0.26 loss: 282.297 (lr:0.00010000169850043221)
29760: accuracy:0.15 loss: 256.249 (lr:0.00010000169002912597)
29770: accuracy:0.3 loss: 254.41 (lr:0.00010000168160007053)
29780: accuracy:0.18 loss: 259.958 (lr:0.00010000167321305519)
29790: accuracy:0.22 loss: 257.057 (lr:0.00010000166486787027)
29800: accuracy:0.27 loss: 248.358 (lr:0.00010000165656430712)
29810: accuracy:0.3 loss: 247.688 (lr:0.00010000164830215817)
29820: accuracy:0.31 loss: 258.456 (lr:0.00010000164008121685)
29830: accuracy:0.24 loss: 251.984 (lr:0.00010000163190127766)
29840: accuracy:0.25 loss: 250.707 (lr:0.00010000162376213608)
29850: accuracy:0.16 loss: 252.251 (lr:0.00010000161566358864)
29860: accuracy:0.23 loss: 247.965 (lr:0.00010000160760543288)
29870: accuracy:0.33 loss: 244.745 (lr:0.00010000159958746733)
29880: accuracy:0.26 loss: 257.295 (lr:0.00010000159160949156)
29890: accuracy:0.26 loss: 247.228 (lr:0.0001000015836713061)
29900: accuracy:0.23 loss: 242.634 (lr:0.00010000157577271251)
29910: accuracy:0.22 loss: 234.04 (lr:0.00010000156791351332)
29920: accuracy:0.26 loss: 243.846 (lr:0.00010000156009351205)
29930: accuracy:0.27 loss: 234.32 (lr:0.0001000015523125132)
29940: accuracy:0.27 loss: 261.983 (lr:0.00010000154457032223)
29950: accuracy:0.2 loss: 245.18 (lr:0.00010000153686674562)
29960: accuracy:0.21 loss: 268.1 (lr:0.00010000152920159075)
29970: accuracy:0.32 loss: 259.349 (lr:0.00010000152157466599)
29980: accuracy:0.19 loss: 272.956 (lr:0.00010000151398578069)
29990: accuracy:0.28 loss: 238.741 (lr:0.0001000015064347451)
30000: accuracy:0.25 loss: 244.348 (lr:0.00010000149892137047)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
30000: ********* epoch 4 ********* test accuracy for all:0.201932 test loss: 270.142
30000: ********* epoch 4 ********* test accuracy for mode 0:0.0 test loss: 397.228
30000: ********* epoch 4 ********* test accuracy for mode 1:0.1105 test loss: 361.467
30000: ********* epoch 4 ********* test accuracy for mode 2:0.1115 test loss: 292.197
30000: ********* epoch 4 ********* test accuracy for mode 24:0.215 test loss: 279.701
30000: ********* epoch 4 ********* test accuracy for mode 25:0.296 test loss: 259.878
30000: ********* epoch 4 ********* test accuracy for mode 26:0.063 test loss: 210.036
30000: ********* epoch 4 ********* test accuracy for mode 27:0.23 test loss: 279.978
30000: ********* epoch 4 ********* test accuracy for mode 28:0.2335 test loss: 266.42
30000: ********* epoch 4 ********* test accuracy for mode 29:0.2845 test loss: 275.239
30000: ********* epoch 4 ********* test accuracy for mode 30:0.215 test loss: 271.215
30000: ********* epoch 4 ********* test accuracy for mode 31:0.1695 test loss: 276.226
30000: ********* epoch 4 ********* test accuracy for mode 32:0.1865 test loss: 265.172
30000: ********* epoch 4 ********* test accuracy for mode 33:0.162 test loss: 276.297
30000: ********* epoch 4 ********* test accuracy for mode 34:0.073 test loss: 277.559
30000: ********* epoch 4 ********* test accuracy for mode 35:0.0005 test loss: 420.361
30000: ********* epoch 4 ********* test accuracy for mode 36:0.012 test loss: 406.13
30010: accuracy:0.19 loss: 245.773 (lr:0.00010000149144546894)
30020: accuracy:0.25 loss: 239.298 (lr:0.00010000148400685363)
30030: accuracy:0.27 loss: 273.26 (lr:0.00010000147660533858)
30040: accuracy:0.26 loss: 246.049 (lr:0.00010000146924073872)
30050: accuracy:0.21 loss: 245.836 (lr:0.00010000146191286997)
30060: accuracy:0.15 loss: 260.767 (lr:0.00010000145462154911)
30070: accuracy:0.29 loss: 250.144 (lr:0.00010000144736659386)
30080: accuracy:0.28 loss: 260.424 (lr:0.00010000144014782286)
30090: accuracy:0.18 loss: 249.307 (lr:0.00010000143296505563)
30100: accuracy:0.24 loss: 239.443 (lr:0.0001000014258181126)
30110: accuracy:0.22 loss: 257.179 (lr:0.00010000141870681509)
30120: accuracy:0.23 loss: 259.834 (lr:0.00010000141163098534)
30130: accuracy:0.25 loss: 249.09 (lr:0.00010000140459044643)
30140: accuracy:0.26 loss: 254.269 (lr:0.00010000139758502234)
30150: accuracy:0.34 loss: 243.652 (lr:0.00010000139061453797)
30160: accuracy:0.26 loss: 238.094 (lr:0.00010000138367881903)
30170: accuracy:0.24 loss: 248.814 (lr:0.00010000137677769213)
30180: accuracy:0.22 loss: 258.94 (lr:0.00010000136991098473)
30190: accuracy:0.25 loss: 245.53 (lr:0.00010000136307852519)
30200: accuracy:0.27 loss: 244.557 (lr:0.00010000135628014268)
30210: accuracy:0.28 loss: 238.68 (lr:0.00010000134951566726)
30220: accuracy:0.25 loss: 249.94 (lr:0.00010000134278492979)
30230: accuracy:0.23 loss: 240.399 (lr:0.00010000133608776201)
30240: accuracy:0.36 loss: 227.139 (lr:0.0001000013294239965)
30250: accuracy:0.25 loss: 263.446 (lr:0.00010000132279346666)
30260: accuracy:0.32 loss: 242.477 (lr:0.00010000131619600671)
30270: accuracy:0.18 loss: 276.21 (lr:0.00010000130963145174)
30280: accuracy:0.28 loss: 236.446 (lr:0.00010000130309963763)
30290: accuracy:0.26 loss: 236.373 (lr:0.00010000129660040107)
30300: accuracy:0.21 loss: 256.451 (lr:0.00010000129013357959)
30310: accuracy:0.28 loss: 241.516 (lr:0.00010000128369901151)
30320: accuracy:0.19 loss: 253.134 (lr:0.00010000127729653599)
30330: accuracy:0.33 loss: 224.749 (lr:0.00010000127092599294)
30340: accuracy:0.29 loss: 254.096 (lr:0.00010000126458722311)
30350: accuracy:0.21 loss: 255.044 (lr:0.00010000125828006802)
30360: accuracy:0.26 loss: 247.272 (lr:0.00010000125200437)
30370: accuracy:0.15 loss: 263.193 (lr:0.00010000124575997215)
30380: accuracy:0.26 loss: 248.131 (lr:0.00010000123954671837)
30390: accuracy:0.23 loss: 271.681 (lr:0.00010000123336445332)
30400: accuracy:0.19 loss: 261.112 (lr:0.00010000122721302245)
30410: accuracy:0.27 loss: 235.013 (lr:0.00010000122109227197)
30420: accuracy:0.24 loss: 242.265 (lr:0.00010000121500204885)
30430: accuracy:0.21 loss: 273.695 (lr:0.00010000120894220084)
30440: accuracy:0.28 loss: 249.876 (lr:0.00010000120291257646)
30450: accuracy:0.24 loss: 250.77 (lr:0.00010000119691302496)
30460: accuracy:0.21 loss: 251.67 (lr:0.00010000119094339634)
30470: accuracy:0.26 loss: 246.514 (lr:0.00010000118500354137)
30480: accuracy:0.26 loss: 244.139 (lr:0.00010000117909331156)
30490: accuracy:0.22 loss: 254.625 (lr:0.00010000117321255913)
30500: accuracy:0.3 loss: 241.448 (lr:0.00010000116736113708)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
30500: ********* epoch 4 ********* test accuracy for all:0.206851 test loss: 269.554
30500: ********* epoch 4 ********* test accuracy for mode 0:0.0005 test loss: 390.196
30500: ********* epoch 4 ********* test accuracy for mode 1:0.1365 test loss: 356.518
30500: ********* epoch 4 ********* test accuracy for mode 2:0.13 test loss: 285.911
30500: ********* epoch 4 ********* test accuracy for mode 24:0.205 test loss: 275.664
30500: ********* epoch 4 ********* test accuracy for mode 25:0.328 test loss: 251.896
30500: ********* epoch 4 ********* test accuracy for mode 26:0.0305 test loss: 209.807
30500: ********* epoch 4 ********* test accuracy for mode 27:0.27 test loss: 273.769
30500: ********* epoch 4 ********* test accuracy for mode 28:0.225 test loss: 268.414
30500: ********* epoch 4 ********* test accuracy for mode 29:0.2775 test loss: 277.995
30500: ********* epoch 4 ********* test accuracy for mode 30:0.17 test loss: 279.041
30500: ********* epoch 4 ********* test accuracy for mode 31:0.169 test loss: 278.98
30500: ********* epoch 4 ********* test accuracy for mode 32:0.162 test loss: 266.746
30500: ********* epoch 4 ********* test accuracy for mode 33:0.2405 test loss: 272.707
30500: ********* epoch 4 ********* test accuracy for mode 34:0.072 test loss: 273.511
30500: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 423.581
30500: ********* epoch 4 ********* test accuracy for mode 36:0.028 test loss: 410.651
30510: accuracy:0.26 loss: 253.126 (lr:0.00010000116153889913)
30520: accuracy:0.28 loss: 222.044 (lr:0.0001000011557456997)
30530: accuracy:0.22 loss: 258.598 (lr:0.00010000114998139397)
30540: accuracy:0.26 loss: 234.251 (lr:0.00010000114424583784)
30550: accuracy:0.25 loss: 259.038 (lr:0.00010000113853888792)
30560: accuracy:0.24 loss: 253.175 (lr:0.00010000113286040152)
30570: accuracy:0.17 loss: 249.335 (lr:0.0001000011272102367)
30580: accuracy:0.24 loss: 251.998 (lr:0.00010000112158825218)
30590: accuracy:0.26 loss: 253.337 (lr:0.00010000111599430744)
30600: accuracy:0.21 loss: 242.013 (lr:0.00010000111042826261)
30610: accuracy:0.19 loss: 262.139 (lr:0.00010000110488997855)
30620: accuracy:0.2 loss: 246.25 (lr:0.00010000109937931678)
30630: accuracy:0.23 loss: 250.772 (lr:0.00010000109389613957)
30640: accuracy:0.24 loss: 240.153 (lr:0.00010000108844030981)
30650: accuracy:0.2 loss: 245.369 (lr:0.00010000108301169112)
30660: accuracy:0.27 loss: 248.006 (lr:0.00010000107761014778)
30670: accuracy:0.26 loss: 254.486 (lr:0.00010000107223554474)
30680: accuracy:0.22 loss: 253.706 (lr:0.00010000106688774765)
30690: accuracy:0.29 loss: 240.726 (lr:0.0001000010615666228)
30700: accuracy:0.26 loss: 242.015 (lr:0.0001000010562720372)
30710: accuracy:0.24 loss: 241.913 (lr:0.00010000105100385842)
30720: accuracy:0.29 loss: 256.099 (lr:0.00010000104576195482)
30730: accuracy:0.23 loss: 246.432 (lr:0.0001000010405461953)
30740: accuracy:0.19 loss: 260.557 (lr:0.0001000010353564495)
30750: accuracy:0.28 loss: 262.028 (lr:0.00010000103019258767)
30760: accuracy:0.22 loss: 261.246 (lr:0.0001000010250544807)
30770: accuracy:0.26 loss: 247.564 (lr:0.00010000101994200015)
30780: accuracy:0.27 loss: 244.324 (lr:0.00010000101485501821)
30790: accuracy:0.28 loss: 256.979 (lr:0.00010000100979340768)
30800: accuracy:0.27 loss: 259.519 (lr:0.00010000100475704206)
30810: accuracy:0.27 loss: 253.693 (lr:0.0001000009997457954)
30820: accuracy:0.23 loss: 258.083 (lr:0.00010000099475954244)
30830: accuracy:0.19 loss: 249.506 (lr:0.00010000098979815853)
30840: accuracy:0.27 loss: 245.188 (lr:0.00010000098486151961)
30850: accuracy:0.24 loss: 257.683 (lr:0.0001000009799495023)
30860: accuracy:0.23 loss: 234.011 (lr:0.00010000097506198377)
30870: accuracy:0.21 loss: 249.653 (lr:0.00010000097019884183)
30880: accuracy:0.18 loss: 255.415 (lr:0.00010000096535995492)
30890: accuracy:0.27 loss: 237.506 (lr:0.00010000096054520206)
30900: accuracy:0.28 loss: 227.259 (lr:0.00010000095575446288)
30910: accuracy:0.19 loss: 260.638 (lr:0.00010000095098761761)
30920: accuracy:0.24 loss: 249.804 (lr:0.00010000094624454708)
30930: accuracy:0.25 loss: 242.348 (lr:0.00010000094152513271)
30940: accuracy:0.34 loss: 241.414 (lr:0.00010000093682925652)
30950: accuracy:0.19 loss: 257.934 (lr:0.00010000093215680111)
30960: accuracy:0.26 loss: 249.414 (lr:0.00010000092750764967)
30970: accuracy:0.18 loss: 266.171 (lr:0.00010000092288168597)
30980: accuracy:0.28 loss: 234.816 (lr:0.00010000091827879436)
30990: accuracy:0.27 loss: 243.072 (lr:0.00010000091369885975)
31000: accuracy:0.33 loss: 241.356 (lr:0.00010000090914176769)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
31000: ********* epoch 4 ********* test accuracy for all:0.201689 test loss: 269.348
31000: ********* epoch 4 ********* test accuracy for mode 0:0.0005 test loss: 399.679
31000: ********* epoch 4 ********* test accuracy for mode 1:0.1115 test loss: 364.013
31000: ********* epoch 4 ********* test accuracy for mode 2:0.099 test loss: 294.888
31000: ********* epoch 4 ********* test accuracy for mode 24:0.217 test loss: 268.695
31000: ********* epoch 4 ********* test accuracy for mode 25:0.355 test loss: 246.135
31000: ********* epoch 4 ********* test accuracy for mode 26:0.075 test loss: 202.317
31000: ********* epoch 4 ********* test accuracy for mode 27:0.2375 test loss: 273.357
31000: ********* epoch 4 ********* test accuracy for mode 28:0.2635 test loss: 260.518
31000: ********* epoch 4 ********* test accuracy for mode 29:0.298 test loss: 271.973
31000: ********* epoch 4 ********* test accuracy for mode 30:0.1095 test loss: 281.562
31000: ********* epoch 4 ********* test accuracy for mode 31:0.1845 test loss: 280.906
31000: ********* epoch 4 ********* test accuracy for mode 32:0.126 test loss: 271.612
31000: ********* epoch 4 ********* test accuracy for mode 33:0.244 test loss: 276.079
31000: ********* epoch 4 ********* test accuracy for mode 34:0.069 test loss: 275.613
31000: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 407.483
31000: ********* epoch 4 ********* test accuracy for mode 36:0.041 test loss: 397.387
31010: accuracy:0.28 loss: 260.159 (lr:0.00010000090460740421)
31020: accuracy:0.25 loss: 242.707 (lr:0.00010000090009565596)
31030: accuracy:0.24 loss: 231.255 (lr:0.00010000089560641014)
31040: accuracy:0.25 loss: 253.406 (lr:0.00010000089113955453)
31050: accuracy:0.23 loss: 250.939 (lr:0.00010000088669497747)
31060: accuracy:0.27 loss: 232.563 (lr:0.00010000088227256782)
31070: accuracy:0.21 loss: 250.753 (lr:0.00010000087787221503)
31080: accuracy:0.22 loss: 250.01 (lr:0.00010000087349380908)
31090: accuracy:0.27 loss: 249.356 (lr:0.00010000086913724054)
31100: accuracy:0.31 loss: 234.901 (lr:0.00010000086480240047)
31110: accuracy:0.23 loss: 245.345 (lr:0.0001000008604891805)
31120: accuracy:0.3 loss: 236.112 (lr:0.0001000008561974728)
31130: accuracy:0.24 loss: 235.894 (lr:0.0001000008519271701)
31140: accuracy:0.24 loss: 248.205 (lr:0.00010000084767816561)
31150: accuracy:0.24 loss: 238.127 (lr:0.00010000084345035312)
31160: accuracy:0.27 loss: 238.302 (lr:0.00010000083924362694)
31170: accuracy:0.36 loss: 231.225 (lr:0.00010000083505788188)
31180: accuracy:0.36 loss: 253.921 (lr:0.00010000083089301332)
31190: accuracy:0.27 loss: 234.632 (lr:0.00010000082674891713)
31200: accuracy:0.24 loss: 262.691 (lr:0.0001000008226254897)
31210: accuracy:0.18 loss: 274.322 (lr:0.00010000081852262795)
31220: accuracy:0.35 loss: 236.683 (lr:0.00010000081444022932)
31230: accuracy:0.26 loss: 251.562 (lr:0.00010000081037819173)
31240: accuracy:0.24 loss: 254.04 (lr:0.00010000080633641363)
31250: accuracy:0.19 loss: 260.209 (lr:0.00010000080231479399)
31260: accuracy:0.31 loss: 232.556 (lr:0.00010000079831323227)
31270: accuracy:0.25 loss: 232.468 (lr:0.0001000007943316284)
31280: accuracy:0.21 loss: 242.76 (lr:0.00010000079036988288)
31290: accuracy:0.27 loss: 242.727 (lr:0.00010000078642789665)
31300: accuracy:0.19 loss: 259.218 (lr:0.00010000078250557115)
31310: accuracy:0.25 loss: 242.389 (lr:0.00010000077860280833)
31320: accuracy:0.27 loss: 240.944 (lr:0.00010000077471951062)
31330: accuracy:0.17 loss: 263.781 (lr:0.00010000077085558095)
31340: accuracy:0.28 loss: 243.458 (lr:0.0001000007670109227)
31350: accuracy:0.28 loss: 254.99 (lr:0.00010000076318543976)
31360: accuracy:0.2 loss: 256.654 (lr:0.0001000007593790365)
31370: accuracy:0.28 loss: 250.822 (lr:0.00010000075559161775)
31380: accuracy:0.24 loss: 264.811 (lr:0.00010000075182308884)
31390: accuracy:0.2 loss: 259.514 (lr:0.00010000074807335554)
31400: accuracy:0.3 loss: 242.523 (lr:0.00010000074434232411)
31410: accuracy:0.26 loss: 252.074 (lr:0.00010000074062990128)
31420: accuracy:0.24 loss: 237.422 (lr:0.00010000073693599425)
31430: accuracy:0.25 loss: 257.09 (lr:0.00010000073326051064)
31440: accuracy:0.14 loss: 248.908 (lr:0.00010000072960335858)
31450: accuracy:0.25 loss: 229.589 (lr:0.00010000072596444666)
31460: accuracy:0.23 loss: 261.699 (lr:0.00010000072234368387)
31470: accuracy:0.28 loss: 255.926 (lr:0.00010000071874097971)
31480: accuracy:0.25 loss: 243.925 (lr:0.00010000071515624412)
31490: accuracy:0.23 loss: 264.399 (lr:0.00010000071158938748)
31500: accuracy:0.33 loss: 242.669 (lr:0.00010000070804032059)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
31500: ********* epoch 4 ********* test accuracy for all:0.203446 test loss: 268.771
31500: ********* epoch 4 ********* test accuracy for mode 0:0.0 test loss: 394.107
31500: ********* epoch 4 ********* test accuracy for mode 1:0.1065 test loss: 365.842
31500: ********* epoch 4 ********* test accuracy for mode 2:0.105 test loss: 293.492
31500: ********* epoch 4 ********* test accuracy for mode 24:0.204 test loss: 274.05
31500: ********* epoch 4 ********* test accuracy for mode 25:0.3725 test loss: 250.439
31500: ********* epoch 4 ********* test accuracy for mode 26:0.039 test loss: 204.915
31500: ********* epoch 4 ********* test accuracy for mode 27:0.2905 test loss: 269.698
31500: ********* epoch 4 ********* test accuracy for mode 28:0.2425 test loss: 263.385
31500: ********* epoch 4 ********* test accuracy for mode 29:0.296 test loss: 273.006
31500: ********* epoch 4 ********* test accuracy for mode 30:0.1265 test loss: 276.168
31500: ********* epoch 4 ********* test accuracy for mode 31:0.2455 test loss: 273.501
31500: ********* epoch 4 ********* test accuracy for mode 32:0.1265 test loss: 266.119
31500: ********* epoch 4 ********* test accuracy for mode 33:0.2105 test loss: 273.175
31500: ********* epoch 4 ********* test accuracy for mode 34:0.075 test loss: 274.239
31500: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 410.255
31500: ********* epoch 4 ********* test accuracy for mode 36:0.0215 test loss: 422.06
31510: accuracy:0.24 loss: 231.468 (lr:0.00010000070450895477)
31520: accuracy:0.27 loss: 272.964 (lr:0.0001000007009952017)
31530: accuracy:0.21 loss: 261.205 (lr:0.00010000069749897354)
31540: accuracy:0.19 loss: 258.38 (lr:0.0001000006940201829)
31550: accuracy:0.25 loss: 251.194 (lr:0.00010000069055874279)
31560: accuracy:0.2 loss: 260.458 (lr:0.00010000068711456669)
31570: accuracy:0.31 loss: 236.924 (lr:0.0001000006836875685)
31580: accuracy:0.27 loss: 245.236 (lr:0.00010000068027766252)
31590: accuracy:0.26 loss: 255.393 (lr:0.00010000067688476352)
31600: accuracy:0.33 loss: 238.337 (lr:0.00010000067350878668)
31610: accuracy:0.2 loss: 264.572 (lr:0.0001000006701496476)
31620: accuracy:0.29 loss: 242.294 (lr:0.00010000066680726228)
31630: accuracy:0.3 loss: 234.704 (lr:0.00010000066348154719)
31640: accuracy:0.21 loss: 245.872 (lr:0.00010000066017241916)
31650: accuracy:0.26 loss: 261.079 (lr:0.00010000065687979549)
31660: accuracy:0.21 loss: 253.579 (lr:0.00010000065360359385)
31670: accuracy:0.24 loss: 254.138 (lr:0.00010000065034373232)
31680: accuracy:0.29 loss: 237.59 (lr:0.00010000064710012943)
31690: accuracy:0.27 loss: 245.269 (lr:0.00010000064387270406)
31700: accuracy:0.29 loss: 254.512 (lr:0.00010000064066137556)
31710: accuracy:0.21 loss: 244.905 (lr:0.00010000063746606361)
31720: accuracy:0.37 loss: 228.957 (lr:0.00010000063428668836)
31730: accuracy:0.29 loss: 242.395 (lr:0.0001000006311231703)
31740: accuracy:0.24 loss: 250.496 (lr:0.00010000062797543036)
31750: accuracy:0.26 loss: 243.812 (lr:0.00010000062484338983)
31760: accuracy:0.24 loss: 255.372 (lr:0.00010000062172697042)
31770: accuracy:0.19 loss: 270.465 (lr:0.00010000061862609423)
31780: accuracy:0.29 loss: 254.763 (lr:0.00010000061554068371)
31790: accuracy:0.24 loss: 263.919 (lr:0.00010000061247066174)
31800: accuracy:0.26 loss: 233.887 (lr:0.00010000060941595157)
31810: accuracy:0.21 loss: 253.369 (lr:0.00010000060637647683)
31820: accuracy:0.3 loss: 245.915 (lr:0.00010000060335216153)
31830: accuracy:0.25 loss: 246.772 (lr:0.00010000060034293008)
31840: accuracy:0.2 loss: 246.38 (lr:0.00010000059734870722)
31850: accuracy:0.23 loss: 240.289 (lr:0.00010000059436941811)
31860: accuracy:0.22 loss: 254.706 (lr:0.00010000059140498827)
31870: accuracy:0.26 loss: 245.747 (lr:0.0001000005884553436)
31880: accuracy:0.2 loss: 260.794 (lr:0.00010000058552041032)
31890: accuracy:0.2 loss: 258.269 (lr:0.00010000058260011509)
31900: accuracy:0.29 loss: 243.452 (lr:0.00010000057969438489)
31910: accuracy:0.22 loss: 244.186 (lr:0.00010000057680314709)
31920: accuracy:0.28 loss: 243.186 (lr:0.00010000057392632939)
31930: accuracy:0.27 loss: 264.184 (lr:0.00010000057106385987)
31940: accuracy:0.29 loss: 242.767 (lr:0.000100000568215667)
31950: accuracy:0.21 loss: 253.473 (lr:0.00010000056538167953)
31960: accuracy:0.27 loss: 230.911 (lr:0.00010000056256182665)
31970: accuracy:0.21 loss: 259.0 (lr:0.00010000055975603783)
31980: accuracy:0.28 loss: 253.806 (lr:0.00010000055696424295)
31990: accuracy:0.21 loss: 244.455 (lr:0.00010000055418637219)
32000: accuracy:0.26 loss: 254.689 (lr:0.00010000055142235613)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
32000: ********* epoch 4 ********* test accuracy for all:0.206878 test loss: 268.489
32000: ********* epoch 4 ********* test accuracy for mode 0:0.0 test loss: 393.523
32000: ********* epoch 4 ********* test accuracy for mode 1:0.1225 test loss: 359.906
32000: ********* epoch 4 ********* test accuracy for mode 2:0.0605 test loss: 301.242
32000: ********* epoch 4 ********* test accuracy for mode 24:0.2665 test loss: 266.45
32000: ********* epoch 4 ********* test accuracy for mode 25:0.288 test loss: 254.383
32000: ********* epoch 4 ********* test accuracy for mode 26:0.0775 test loss: 203.268
32000: ********* epoch 4 ********* test accuracy for mode 27:0.265 test loss: 274.962
32000: ********* epoch 4 ********* test accuracy for mode 28:0.258 test loss: 265.783
32000: ********* epoch 4 ********* test accuracy for mode 29:0.2775 test loss: 277.577
32000: ********* epoch 4 ********* test accuracy for mode 30:0.1155 test loss: 280.281
32000: ********* epoch 4 ********* test accuracy for mode 31:0.178 test loss: 280.627
32000: ********* epoch 4 ********* test accuracy for mode 32:0.156 test loss: 268.706
32000: ********* epoch 4 ********* test accuracy for mode 33:0.2015 test loss: 273.177
32000: ********* epoch 4 ********* test accuracy for mode 34:0.1275 test loss: 271.119
32000: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 411.608
32000: ********* epoch 4 ********* test accuracy for mode 36:0.0265 test loss: 416.165
32010: accuracy:0.28 loss: 248.367 (lr:0.00010000054867212566)
32020: accuracy:0.2 loss: 261.64 (lr:0.00010000054593561202)
32030: accuracy:0.23 loss: 245.644 (lr:0.00010000054321274679)
32040: accuracy:0.27 loss: 246.669 (lr:0.00010000054050346191)
32050: accuracy:0.24 loss: 255.243 (lr:0.00010000053780768965)
32060: accuracy:0.27 loss: 240.087 (lr:0.0001000005351253626)
32070: accuracy:0.19 loss: 259.261 (lr:0.00010000053245641372)
32080: accuracy:0.24 loss: 260.151 (lr:0.00010000052980077628)
32090: accuracy:0.31 loss: 249.841 (lr:0.00010000052715838389)
32100: accuracy:0.16 loss: 254.437 (lr:0.00010000052452917048)
32110: accuracy:0.28 loss: 248.39 (lr:0.00010000052191307033)
32120: accuracy:0.33 loss: 237.169 (lr:0.00010000051931001803)
32130: accuracy:0.28 loss: 245.507 (lr:0.0001000005167199485)
32140: accuracy:0.26 loss: 235.04 (lr:0.00010000051414279701)
32150: accuracy:0.27 loss: 253.811 (lr:0.00010000051157849912)
32160: accuracy:0.19 loss: 229.924 (lr:0.0001000005090269907)
32170: accuracy:0.26 loss: 259.771 (lr:0.000100000506488208)
32180: accuracy:0.26 loss: 267.246 (lr:0.00010000050396208752)
32190: accuracy:0.32 loss: 238.839 (lr:0.00010000050144856612)
32200: accuracy:0.24 loss: 247.046 (lr:0.00010000049894758097)
32210: accuracy:0.18 loss: 263.443 (lr:0.00010000049645906952)
32220: accuracy:0.24 loss: 241.409 (lr:0.00010000049398296959)
32230: accuracy:0.22 loss: 241.253 (lr:0.00010000049151921925)
32240: accuracy:0.17 loss: 259.841 (lr:0.00010000048906775692)
32250: accuracy:0.22 loss: 280.06 (lr:0.0001000004866285213)
32260: accuracy:0.26 loss: 250.532 (lr:0.00010000048420145143)
32270: accuracy:0.22 loss: 240.281 (lr:0.0001000004817864866)
32280: accuracy:0.28 loss: 264.393 (lr:0.00010000047938356648)
32290: accuracy:0.19 loss: 253.574 (lr:0.00010000047699263097)
32300: accuracy:0.25 loss: 237.254 (lr:0.0001000004746136203)
32310: accuracy:0.19 loss: 280.463 (lr:0.00010000047224647499)
32320: accuracy:0.29 loss: 248.578 (lr:0.00010000046989113587)
32330: accuracy:0.29 loss: 239.12 (lr:0.00010000046754754406)
32340: accuracy:0.2 loss: 257.066 (lr:0.00010000046521564096)
32350: accuracy:0.24 loss: 247.242 (lr:0.00010000046289536827)
32360: accuracy:0.31 loss: 238.951 (lr:0.00010000046058666799)
32370: accuracy:0.29 loss: 241.327 (lr:0.00010000045828948239)
32380: accuracy:0.24 loss: 251.567 (lr:0.00010000045600375406)
32390: accuracy:0.27 loss: 235.337 (lr:0.00010000045372942585)
32400: accuracy:0.27 loss: 245.809 (lr:0.0001000004514664409)
32410: accuracy:0.23 loss: 263.291 (lr:0.00010000044921474262)
32420: accuracy:0.25 loss: 247.453 (lr:0.00010000044697427475)
32430: accuracy:0.28 loss: 249.525 (lr:0.00010000044474498126)
32440: accuracy:0.22 loss: 256.699 (lr:0.00010000044252680641)
32450: accuracy:0.21 loss: 253.572 (lr:0.00010000044031969476)
32460: accuracy:0.18 loss: 261.362 (lr:0.00010000043812359112)
32470: accuracy:0.24 loss: 266.256 (lr:0.00010000043593844058)
32480: accuracy:0.2 loss: 247.085 (lr:0.00010000043376418855)
32490: accuracy:0.28 loss: 251.218 (lr:0.00010000043160078063)
32500: accuracy:0.13 loss: 254.848 (lr:0.00010000042944816276)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
32500: ********* epoch 4 ********* test accuracy for all:0.205297 test loss: 269.19
32500: ********* epoch 4 ********* test accuracy for mode 0:0.0005 test loss: 397.375
32500: ********* epoch 4 ********* test accuracy for mode 1:0.101 test loss: 359.683
32500: ********* epoch 4 ********* test accuracy for mode 2:0.0955 test loss: 288.407
32500: ********* epoch 4 ********* test accuracy for mode 24:0.2235 test loss: 277.632
32500: ********* epoch 4 ********* test accuracy for mode 25:0.3305 test loss: 258.955
32500: ********* epoch 4 ********* test accuracy for mode 26:0.0665 test loss: 203.132
32500: ********* epoch 4 ********* test accuracy for mode 27:0.286 test loss: 273.374
32500: ********* epoch 4 ********* test accuracy for mode 28:0.225 test loss: 267.473
32500: ********* epoch 4 ********* test accuracy for mode 29:0.2805 test loss: 275.489
32500: ********* epoch 4 ********* test accuracy for mode 30:0.141 test loss: 275.042
32500: ********* epoch 4 ********* test accuracy for mode 31:0.167 test loss: 271.714
32500: ********* epoch 4 ********* test accuracy for mode 32:0.2655 test loss: 260.071
32500: ********* epoch 4 ********* test accuracy for mode 33:0.1145 test loss: 271.62
32500: ********* epoch 4 ********* test accuracy for mode 34:0.174 test loss: 266.434
32500: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 409.547
32500: ********* epoch 4 ********* test accuracy for mode 36:0.03 test loss: 414.293
32510: accuracy:0.3 loss: 248.904 (lr:0.00010000042730628112)
32520: accuracy:0.3 loss: 275.489 (lr:0.00010000042517508214)
32530: accuracy:0.34 loss: 243.646 (lr:0.00010000042305451257)
32540: accuracy:0.24 loss: 234.778 (lr:0.00010000042094451939)
32550: accuracy:0.27 loss: 239.386 (lr:0.00010000041884504983)
32560: accuracy:0.28 loss: 256.149 (lr:0.00010000041675605144)
32570: accuracy:0.24 loss: 257.791 (lr:0.00010000041467747196)
32580: accuracy:0.27 loss: 249.917 (lr:0.00010000041260925944)
32590: accuracy:0.24 loss: 266.852 (lr:0.00010000041055136217)
32600: accuracy:0.25 loss: 247.533 (lr:0.00010000040850372872)
32610: accuracy:0.3 loss: 237.63 (lr:0.00010000040646630787)
32620: accuracy:0.25 loss: 231.258 (lr:0.0001000004044390487)
32630: accuracy:0.3 loss: 234.268 (lr:0.00010000040242190052)
32640: accuracy:0.24 loss: 234.384 (lr:0.00010000040041481292)
32650: accuracy:0.25 loss: 261.549 (lr:0.00010000039841773571)
32660: accuracy:0.27 loss: 246.393 (lr:0.00010000039643061897)
32670: accuracy:0.22 loss: 257.283 (lr:0.00010000039445341301)
32680: accuracy:0.22 loss: 259.265 (lr:0.0001000003924860684)
32690: accuracy:0.28 loss: 250.678 (lr:0.00010000039052853597)
32700: accuracy:0.24 loss: 236.075 (lr:0.00010000038858076677)
32710: accuracy:0.28 loss: 224.584 (lr:0.00010000038664271211)
32720: accuracy:0.23 loss: 254.122 (lr:0.00010000038471432354)
32730: accuracy:0.27 loss: 245.785 (lr:0.00010000038279555284)
32740: accuracy:0.28 loss: 248.365 (lr:0.00010000038088635206)
32750: accuracy:0.22 loss: 247.202 (lr:0.00010000037898667346)
32760: accuracy:0.27 loss: 238.055 (lr:0.00010000037709646953)
32770: accuracy:0.25 loss: 249.673 (lr:0.00010000037521569305)
32780: accuracy:0.32 loss: 241.219 (lr:0.00010000037334429697)
32790: accuracy:0.26 loss: 244.095 (lr:0.00010000037148223452)
32800: accuracy:0.27 loss: 255.788 (lr:0.00010000036962945915)
32810: accuracy:0.24 loss: 238.686 (lr:0.00010000036778592452)
32820: accuracy:0.31 loss: 254.001 (lr:0.00010000036595158458)
32830: accuracy:0.27 loss: 275.405 (lr:0.00010000036412639343)
32840: accuracy:0.32 loss: 230.836 (lr:0.00010000036231030547)
32850: accuracy:0.28 loss: 242.796 (lr:0.00010000036050327528)
32860: accuracy:0.29 loss: 234.285 (lr:0.0001000003587052577)
32870: accuracy:0.2 loss: 257.881 (lr:0.00010000035691620776)
32880: accuracy:0.22 loss: 251.443 (lr:0.00010000035513608074)
32890: accuracy:0.29 loss: 252.131 (lr:0.00010000035336483215)
32900: accuracy:0.29 loss: 264.762 (lr:0.0001000003516024177)
32910: accuracy:0.23 loss: 258.886 (lr:0.00010000034984879333)
32920: accuracy:0.2 loss: 258.433 (lr:0.00010000034810391519)
32930: accuracy:0.26 loss: 259.121 (lr:0.00010000034636773967)
32940: accuracy:0.23 loss: 231.986 (lr:0.00010000034464022336)
32950: accuracy:0.23 loss: 241.942 (lr:0.00010000034292132308)
32960: accuracy:0.19 loss: 249.439 (lr:0.00010000034121099585)
32970: accuracy:0.32 loss: 219.069 (lr:0.0001000003395091989)
32980: accuracy:0.25 loss: 247.811 (lr:0.00010000033781588971)
32990: accuracy:0.24 loss: 280.355 (lr:0.00010000033613102593)
33000: accuracy:0.23 loss: 252.988 (lr:0.00010000033445456545)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
33000: ********* epoch 4 ********* test accuracy for all:0.206851 test loss: 266.402
33000: ********* epoch 4 ********* test accuracy for mode 0:0.0005 test loss: 395.168
33000: ********* epoch 4 ********* test accuracy for mode 1:0.102 test loss: 364.797
33000: ********* epoch 4 ********* test accuracy for mode 2:0.074 test loss: 290.884
33000: ********* epoch 4 ********* test accuracy for mode 24:0.2215 test loss: 269.451
33000: ********* epoch 4 ********* test accuracy for mode 25:0.334 test loss: 247.192
33000: ********* epoch 4 ********* test accuracy for mode 26:0.0525 test loss: 200.473
33000: ********* epoch 4 ********* test accuracy for mode 27:0.2855 test loss: 264.503
33000: ********* epoch 4 ********* test accuracy for mode 28:0.26 test loss: 257.225
33000: ********* epoch 4 ********* test accuracy for mode 29:0.281 test loss: 267.804
33000: ********* epoch 4 ********* test accuracy for mode 30:0.193 test loss: 267.721
33000: ********* epoch 4 ********* test accuracy for mode 31:0.1485 test loss: 275.587
33000: ********* epoch 4 ********* test accuracy for mode 32:0.188 test loss: 264.336
33000: ********* epoch 4 ********* test accuracy for mode 33:0.185 test loss: 269.924
33000: ********* epoch 4 ********* test accuracy for mode 34:0.1245 test loss: 269.617
33000: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 404.413
33000: ********* epoch 4 ********* test accuracy for mode 36:0.0575 test loss: 392.069
33010: accuracy:0.31 loss: 224.598 (lr:0.00010000033278646634)
33020: accuracy:0.23 loss: 257.172 (lr:0.00010000033112668692)
33030: accuracy:0.16 loss: 261.551 (lr:0.00010000032947518568)
33040: accuracy:0.34 loss: 244.993 (lr:0.00010000032783192134)
33050: accuracy:0.3 loss: 238.46 (lr:0.0001000003261968528)
33060: accuracy:0.28 loss: 233.757 (lr:0.00010000032456993921)
33070: accuracy:0.2 loss: 266.806 (lr:0.00010000032295113989)
33080: accuracy:0.29 loss: 234.709 (lr:0.00010000032134041435)
33090: accuracy:0.32 loss: 248.201 (lr:0.00010000031973772236)
33100: accuracy:0.26 loss: 264.741 (lr:0.00010000031814302381)
33110: accuracy:0.25 loss: 247.873 (lr:0.00010000031655627886)
33120: accuracy:0.18 loss: 256.059 (lr:0.00010000031497744783)
33130: accuracy:0.2 loss: 250.605 (lr:0.00010000031340649126)
33140: accuracy:0.28 loss: 252.327 (lr:0.00010000031184336986)
33150: accuracy:0.23 loss: 256.901 (lr:0.00010000031028804457)
33160: accuracy:0.27 loss: 266.289 (lr:0.00010000030874047648)
33170: accuracy:0.27 loss: 250.572 (lr:0.00010000030720062693)
33180: accuracy:0.31 loss: 244.638 (lr:0.00010000030566845741)
33190: accuracy:0.23 loss: 241.817 (lr:0.00010000030414392962)
33200: accuracy:0.2 loss: 255.016 (lr:0.00010000030262700545)
33210: accuracy:0.33 loss: 245.694 (lr:0.00010000030111764696)
33220: accuracy:0.28 loss: 253.762 (lr:0.00010000029961581643)
33230: accuracy:0.19 loss: 269.737 (lr:0.00010000029812147631)
33240: accuracy:0.33 loss: 230.875 (lr:0.00010000029663458925)
33250: accuracy:0.26 loss: 250.037 (lr:0.00010000029515511806)
33260: accuracy:0.25 loss: 252.038 (lr:0.00010000029368302577)
33270: accuracy:0.25 loss: 237.222 (lr:0.00010000029221827557)
33280: accuracy:0.25 loss: 251.87 (lr:0.00010000029076083084)
33290: accuracy:0.31 loss: 212.957 (lr:0.00010000028931065515)
33300: accuracy:0.33 loss: 232.602 (lr:0.00010000028786771223)
33310: accuracy:0.2 loss: 249.506 (lr:0.00010000028643196603)
33320: accuracy:0.25 loss: 240.923 (lr:0.00010000028500338064)
33330: accuracy:0.27 loss: 248.697 (lr:0.00010000028358192035)
33340: accuracy:0.26 loss: 255.443 (lr:0.00010000028216754961)
33350: accuracy:0.27 loss: 246.328 (lr:0.00010000028076023309)
33360: accuracy:0.33 loss: 236.523 (lr:0.0001000002793599356)
33370: accuracy:0.2 loss: 264.412 (lr:0.0001000002779666221)
33380: accuracy:0.26 loss: 240.743 (lr:0.00010000027658025778)
33390: accuracy:0.23 loss: 244.331 (lr:0.00010000027520080799)
33400: accuracy:0.35 loss: 233.498 (lr:0.00010000027382823823)
33410: accuracy:0.26 loss: 236.929 (lr:0.0001000002724625142)
33420: accuracy:0.33 loss: 237.08 (lr:0.00010000027110360174)
33430: accuracy:0.25 loss: 247.863 (lr:0.00010000026975146688)
33440: accuracy:0.19 loss: 263.65 (lr:0.00010000026840607584)
33450: accuracy:0.25 loss: 233.931 (lr:0.00010000026706739495)
33460: accuracy:0.29 loss: 251.401 (lr:0.00010000026573539076)
33470: accuracy:0.24 loss: 256.213 (lr:0.00010000026441002997)
33480: accuracy:0.29 loss: 240.849 (lr:0.00010000026309127944)
33490: accuracy:0.26 loss: 259.665 (lr:0.00010000026177910621)
33500: accuracy:0.27 loss: 235.362 (lr:0.00010000026047347747)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
33500: ********* epoch 4 ********* test accuracy for all:0.207892 test loss: 267.699
33500: ********* epoch 4 ********* test accuracy for mode 0:0.0005 test loss: 396.064
33500: ********* epoch 4 ********* test accuracy for mode 1:0.1025 test loss: 367.598
33500: ********* epoch 4 ********* test accuracy for mode 2:0.0925 test loss: 289.847
33500: ********* epoch 4 ********* test accuracy for mode 24:0.2225 test loss: 279.676
33500: ********* epoch 4 ********* test accuracy for mode 25:0.339 test loss: 255.507
33500: ********* epoch 4 ********* test accuracy for mode 26:0.033 test loss: 209.026
33500: ********* epoch 4 ********* test accuracy for mode 27:0.2915 test loss: 273.352
33500: ********* epoch 4 ********* test accuracy for mode 28:0.209 test loss: 265.224
33500: ********* epoch 4 ********* test accuracy for mode 29:0.3155 test loss: 270.695
33500: ********* epoch 4 ********* test accuracy for mode 30:0.138 test loss: 272.144
33500: ********* epoch 4 ********* test accuracy for mode 31:0.182 test loss: 273.019
33500: ********* epoch 4 ********* test accuracy for mode 32:0.2395 test loss: 261.764
33500: ********* epoch 4 ********* test accuracy for mode 33:0.1195 test loss: 271.794
33500: ********* epoch 4 ********* test accuracy for mode 34:0.1965 test loss: 266.712
33500: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 410.275
33500: ********* epoch 4 ********* test accuracy for mode 36:0.0235 test loss: 411.939
33510: accuracy:0.26 loss: 230.827 (lr:0.00010000025917436058)
33520: accuracy:0.27 loss: 243.148 (lr:0.00010000025788172306)
33530: accuracy:0.27 loss: 239.989 (lr:0.0001000002565955326)
33540: accuracy:0.29 loss: 241.132 (lr:0.00010000025531575705)
33550: accuracy:0.24 loss: 243.405 (lr:0.00010000025404236439)
33560: accuracy:0.22 loss: 245.305 (lr:0.00010000025277532283)
33570: accuracy:0.2 loss: 237.552 (lr:0.00010000025151460064)
33580: accuracy:0.29 loss: 243.75 (lr:0.00010000025026016633)
33590: accuracy:0.21 loss: 246.121 (lr:0.00010000024901198855)
33600: accuracy:0.26 loss: 269.344 (lr:0.00010000024777003607)
33610: accuracy:0.22 loss: 265.797 (lr:0.00010000024653427786)
33620: accuracy:0.28 loss: 233.329 (lr:0.00010000024530468302)
33630: accuracy:0.25 loss: 249.724 (lr:0.00010000024408122082)
33640: accuracy:0.26 loss: 246.427 (lr:0.00010000024286386065)
33650: accuracy:0.24 loss: 256.228 (lr:0.00010000024165257209)
33660: accuracy:0.32 loss: 230.837 (lr:0.00010000024044732486)
33670: accuracy:0.26 loss: 249.272 (lr:0.00010000023924808882)
33680: accuracy:0.23 loss: 246.753 (lr:0.000100000238054834)
33690: accuracy:0.23 loss: 266.723 (lr:0.00010000023686753056)
33700: accuracy:0.26 loss: 245.675 (lr:0.00010000023568614882)
33710: accuracy:0.2 loss: 242.083 (lr:0.00010000023451065926)
33720: accuracy:0.23 loss: 242.131 (lr:0.00010000023334103245)
33730: accuracy:0.2 loss: 268.695 (lr:0.0001000002321772392)
33740: accuracy:0.25 loss: 242.916 (lr:0.00010000023101925039)
33750: accuracy:0.19 loss: 260.749 (lr:0.00010000022986703707)
33760: accuracy:0.23 loss: 249.021 (lr:0.00010000022872057044)
33770: accuracy:0.25 loss: 236.694 (lr:0.00010000022757982184)
33780: accuracy:0.3 loss: 237.311 (lr:0.00010000022644476274)
33790: accuracy:0.25 loss: 256.667 (lr:0.00010000022531536477)
33800: accuracy:0.26 loss: 224.136 (lr:0.00010000022419159971)
33810: accuracy:0.26 loss: 232.37 (lr:0.00010000022307343945)
33820: accuracy:0.24 loss: 250.931 (lr:0.00010000022196085602)
33830: accuracy:0.18 loss: 250.569 (lr:0.00010000022085382163)
33840: accuracy:0.25 loss: 254.488 (lr:0.0001000002197523086)
33850: accuracy:0.27 loss: 237.877 (lr:0.00010000021865628938)
33860: accuracy:0.21 loss: 230.776 (lr:0.00010000021756573659)
33870: accuracy:0.24 loss: 236.605 (lr:0.00010000021648062296)
33880: accuracy:0.23 loss: 235.977 (lr:0.00010000021540092135)
33890: accuracy:0.16 loss: 234.356 (lr:0.00010000021432660477)
33900: accuracy:0.21 loss: 266.643 (lr:0.00010000021325764637)
33910: accuracy:0.26 loss: 260.235 (lr:0.00010000021219401941)
33920: accuracy:0.34 loss: 243.077 (lr:0.00010000021113569734)
33930: accuracy:0.31 loss: 232.277 (lr:0.00010000021008265364)
33940: accuracy:0.28 loss: 253.03 (lr:0.00010000020903486204)
33950: accuracy:0.26 loss: 230.643 (lr:0.00010000020799229632)
33960: accuracy:0.21 loss: 259.48 (lr:0.00010000020695493041)
33970: accuracy:0.23 loss: 246.799 (lr:0.00010000020592273839)
33980: accuracy:0.18 loss: 265.222 (lr:0.00010000020489569445)
33990: accuracy:0.27 loss: 231.769 (lr:0.0001000002038737729)
34000: accuracy:0.29 loss: 232.643 (lr:0.00010000020285694823)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
34000: ********* epoch 4 ********* test accuracy for all:0.207581 test loss: 267.967
34000: ********* epoch 4 ********* test accuracy for mode 0:0.0 test loss: 396.579
34000: ********* epoch 4 ********* test accuracy for mode 1:0.1065 test loss: 367.389
34000: ********* epoch 4 ********* test accuracy for mode 2:0.1045 test loss: 296.163
34000: ********* epoch 4 ********* test accuracy for mode 24:0.164 test loss: 275.763
34000: ********* epoch 4 ********* test accuracy for mode 25:0.317 test loss: 256.055
34000: ********* epoch 4 ********* test accuracy for mode 26:0.128 test loss: 201.214
34000: ********* epoch 4 ********* test accuracy for mode 27:0.214 test loss: 286.402
34000: ********* epoch 4 ********* test accuracy for mode 28:0.227 test loss: 272.487
34000: ********* epoch 4 ********* test accuracy for mode 29:0.278 test loss: 281.144
34000: ********* epoch 4 ********* test accuracy for mode 30:0.1955 test loss: 276.137
34000: ********* epoch 4 ********* test accuracy for mode 31:0.215 test loss: 281.181
34000: ********* epoch 4 ********* test accuracy for mode 32:0.16 test loss: 272.798
34000: ********* epoch 4 ********* test accuracy for mode 33:0.186 test loss: 277.757
34000: ********* epoch 4 ********* test accuracy for mode 34:0.168 test loss: 276.453
34000: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 390.919
34000: ********* epoch 4 ********* test accuracy for mode 36:0.0235 test loss: 391.137
34010: accuracy:0.26 loss: 249.246 (lr:0.00010000020184519498)
34020: accuracy:0.3 loss: 252.485 (lr:0.00010000020083848787)
34030: accuracy:0.26 loss: 248.983 (lr:0.00010000019983680173)
34040: accuracy:0.25 loss: 261.394 (lr:0.00010000019884011152)
34050: accuracy:0.24 loss: 253.302 (lr:0.00010000019784839232)
34060: accuracy:0.26 loss: 242.584 (lr:0.00010000019686161935)
34070: accuracy:0.22 loss: 249.305 (lr:0.00010000019587976794)
34080: accuracy:0.19 loss: 255.122 (lr:0.00010000019490281351)
34090: accuracy:0.2 loss: 259.117 (lr:0.00010000019393073168)
34100: accuracy:0.24 loss: 253.788 (lr:0.00010000019296349812)
34110: accuracy:0.21 loss: 269.951 (lr:0.00010000019200108866)
34120: accuracy:0.2 loss: 243.824 (lr:0.00010000019104347923)
34130: accuracy:0.21 loss: 245.893 (lr:0.0001000001900906459)
34140: accuracy:0.21 loss: 255.02 (lr:0.00010000018914256486)
34150: accuracy:0.23 loss: 261.345 (lr:0.00010000018819921238)
34160: accuracy:0.27 loss: 259.99 (lr:0.00010000018726056489)
34170: accuracy:0.32 loss: 239.624 (lr:0.00010000018632659892)
34180: accuracy:0.27 loss: 249.141 (lr:0.00010000018539729114)
34190: accuracy:0.21 loss: 259.493 (lr:0.00010000018447261828)
34200: accuracy:0.33 loss: 239.584 (lr:0.00010000018355255726)
34210: accuracy:0.34 loss: 241.026 (lr:0.00010000018263708507)
34220: accuracy:0.29 loss: 251.947 (lr:0.0001000001817261788)
34230: accuracy:0.24 loss: 249.11 (lr:0.00010000018081981571)
34240: accuracy:0.27 loss: 246.639 (lr:0.00010000017991797312)
34250: accuracy:0.26 loss: 247.033 (lr:0.00010000017902062847)
34260: accuracy:0.18 loss: 241.606 (lr:0.00010000017812775937)
34270: accuracy:0.3 loss: 249.156 (lr:0.00010000017723934346)
34280: accuracy:0.31 loss: 241.877 (lr:0.00010000017635535854)
34290: accuracy:0.2 loss: 253.355 (lr:0.00010000017547578252)
34300: accuracy:0.32 loss: 221.355 (lr:0.00010000017460059341)
34310: accuracy:0.26 loss: 251.455 (lr:0.00010000017372976932)
34320: accuracy:0.27 loss: 247.557 (lr:0.00010000017286328848)
34330: accuracy:0.3 loss: 266.813 (lr:0.00010000017200112923)
34340: accuracy:0.15 loss: 261.133 (lr:0.00010000017114327002)
34350: accuracy:0.17 loss: 261.124 (lr:0.0001000001702896894)
34360: accuracy:0.2 loss: 255.023 (lr:0.00010000016944036603)
34370: accuracy:0.26 loss: 243.886 (lr:0.00010000016859527868)
34380: accuracy:0.23 loss: 238.702 (lr:0.00010000016775440622)
34390: accuracy:0.22 loss: 265.23 (lr:0.00010000016691772762)
34400: accuracy:0.21 loss: 247.441 (lr:0.00010000016608522198)
34410: accuracy:0.23 loss: 244.38 (lr:0.00010000016525686848)
34420: accuracy:0.27 loss: 252.234 (lr:0.00010000016443264642)
34430: accuracy:0.21 loss: 256.681 (lr:0.00010000016361253517)
34440: accuracy:0.25 loss: 252.191 (lr:0.00010000016279651424)
34450: accuracy:0.26 loss: 243.807 (lr:0.00010000016198456325)
34460: accuracy:0.24 loss: 262.412 (lr:0.00010000016117666187)
34470: accuracy:0.26 loss: 259.018 (lr:0.00010000016037278991)
34480: accuracy:0.23 loss: 251.943 (lr:0.00010000015957292729)
34490: accuracy:0.23 loss: 253.575 (lr:0.000100000158777054)
34500: accuracy:0.26 loss: 245.498 (lr:0.00010000015798515013)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
34500: ********* epoch 4 ********* test accuracy for all:0.208811 test loss: 266.391
34500: ********* epoch 4 ********* test accuracy for mode 0:0.0 test loss: 401.105
34500: ********* epoch 4 ********* test accuracy for mode 1:0.095 test loss: 368.706
34500: ********* epoch 4 ********* test accuracy for mode 2:0.129 test loss: 281.459
34500: ********* epoch 4 ********* test accuracy for mode 24:0.1895 test loss: 278.165
34500: ********* epoch 4 ********* test accuracy for mode 25:0.3495 test loss: 252.807
34500: ********* epoch 4 ********* test accuracy for mode 26:0.0925 test loss: 203.609
34500: ********* epoch 4 ********* test accuracy for mode 27:0.264 test loss: 271.537
34500: ********* epoch 4 ********* test accuracy for mode 28:0.2195 test loss: 265.093
34500: ********* epoch 4 ********* test accuracy for mode 29:0.2465 test loss: 273.001
34500: ********* epoch 4 ********* test accuracy for mode 30:0.173 test loss: 267.565
34500: ********* epoch 4 ********* test accuracy for mode 31:0.228 test loss: 266.392
34500: ********* epoch 4 ********* test accuracy for mode 32:0.2425 test loss: 256.961
34500: ********* epoch 4 ********* test accuracy for mode 33:0.162 test loss: 269.083
34500: ********* epoch 4 ********* test accuracy for mode 34:0.07 test loss: 270.26
34500: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 405.791
34500: ********* epoch 4 ********* test accuracy for mode 36:0.0355 test loss: 414.638
34510: accuracy:0.21 loss: 259.476 (lr:0.00010000015719719591)
34520: accuracy:0.25 loss: 259.762 (lr:0.00010000015641317162)
34530: accuracy:0.3 loss: 247.209 (lr:0.00010000015563305767)
34540: accuracy:0.28 loss: 249.402 (lr:0.00010000015485683455)
34550: accuracy:0.27 loss: 247.481 (lr:0.00010000015408448288)
34560: accuracy:0.21 loss: 256.059 (lr:0.00010000015331598331)
34570: accuracy:0.32 loss: 249.35 (lr:0.00010000015255131665)
34580: accuracy:0.2 loss: 240.465 (lr:0.00010000015179046379)
34590: accuracy:0.31 loss: 239.69 (lr:0.00010000015103340569)
34600: accuracy:0.22 loss: 246.387 (lr:0.00010000015028012343)
34610: accuracy:0.27 loss: 272.354 (lr:0.0001000001495305982)
34620: accuracy:0.2 loss: 247.186 (lr:0.00010000014878481123)
34630: accuracy:0.28 loss: 238.595 (lr:0.00010000014804274388)
34640: accuracy:0.2 loss: 255.327 (lr:0.00010000014730437762)
34650: accuracy:0.28 loss: 241.748 (lr:0.00010000014656969397)
34660: accuracy:0.23 loss: 240.692 (lr:0.00010000014583867457)
34670: accuracy:0.25 loss: 251.239 (lr:0.00010000014511130115)
34680: accuracy:0.28 loss: 233.91 (lr:0.00010000014438755552)
34690: accuracy:0.26 loss: 233.767 (lr:0.00010000014366741957)
34700: accuracy:0.28 loss: 238.965 (lr:0.00010000014295087533)
34710: accuracy:0.26 loss: 263.778 (lr:0.00010000014223790486)
34720: accuracy:0.21 loss: 248.138 (lr:0.00010000014152849036)
34730: accuracy:0.32 loss: 227.741 (lr:0.00010000014082261407)
34740: accuracy:0.25 loss: 241.428 (lr:0.00010000014012025835)
34750: accuracy:0.19 loss: 264.936 (lr:0.00010000013942140565)
34760: accuracy:0.27 loss: 241.738 (lr:0.00010000013872603849)
34770: accuracy:0.17 loss: 256.434 (lr:0.00010000013803413948)
34780: accuracy:0.25 loss: 254.374 (lr:0.00010000013734569134)
34790: accuracy:0.24 loss: 253.544 (lr:0.00010000013666067684)
34800: accuracy:0.22 loss: 253.968 (lr:0.00010000013597907887)
34810: accuracy:0.28 loss: 263.123 (lr:0.0001000001353008804)
34820: accuracy:0.22 loss: 253.109 (lr:0.00010000013462606444)
34830: accuracy:0.25 loss: 247.517 (lr:0.00010000013395461413)
34840: accuracy:0.22 loss: 257.165 (lr:0.0001000001332865127)
34850: accuracy:0.23 loss: 274.623 (lr:0.00010000013262174345)
34860: accuracy:0.29 loss: 257.193 (lr:0.00010000013196028975)
34870: accuracy:0.27 loss: 226.67 (lr:0.00010000013130213506)
34880: accuracy:0.28 loss: 247.275 (lr:0.00010000013064726292)
34890: accuracy:0.27 loss: 268.608 (lr:0.00010000012999565698)
34900: accuracy:0.21 loss: 268.498 (lr:0.00010000012934730094)
34910: accuracy:0.19 loss: 253.398 (lr:0.00010000012870217859)
34920: accuracy:0.32 loss: 242.178 (lr:0.00010000012806027379)
34930: accuracy:0.3 loss: 232.559 (lr:0.00010000012742157052)
34940: accuracy:0.28 loss: 224.038 (lr:0.00010000012678605278)
34950: accuracy:0.28 loss: 249.637 (lr:0.0001000001261537047)
34960: accuracy:0.2 loss: 250.104 (lr:0.00010000012552451048)
34970: accuracy:0.31 loss: 248.06 (lr:0.00010000012489845436)
34980: accuracy:0.2 loss: 251.927 (lr:0.00010000012427552073)
34990: accuracy:0.23 loss: 249.833 (lr:0.00010000012365569398)
35000: accuracy:0.22 loss: 255.334 (lr:0.00010000012303895864)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
35000: ********* epoch 4 ********* test accuracy for all:0.208324 test loss: 267.765
35000: ********* epoch 4 ********* test accuracy for mode 0:0.0 test loss: 398.117
35000: ********* epoch 4 ********* test accuracy for mode 1:0.105 test loss: 361.005
35000: ********* epoch 4 ********* test accuracy for mode 2:0.108 test loss: 287.182
35000: ********* epoch 4 ********* test accuracy for mode 24:0.2115 test loss: 280.463
35000: ********* epoch 4 ********* test accuracy for mode 25:0.301 test loss: 260.261
35000: ********* epoch 4 ********* test accuracy for mode 26:0.134 test loss: 201.186
35000: ********* epoch 4 ********* test accuracy for mode 27:0.229 test loss: 282.759
35000: ********* epoch 4 ********* test accuracy for mode 28:0.212 test loss: 273.91
35000: ********* epoch 4 ********* test accuracy for mode 29:0.2905 test loss: 279.318
35000: ********* epoch 4 ********* test accuracy for mode 30:0.1565 test loss: 275.199
35000: ********* epoch 4 ********* test accuracy for mode 31:0.2475 test loss: 273.359
35000: ********* epoch 4 ********* test accuracy for mode 32:0.1405 test loss: 266.53
35000: ********* epoch 4 ********* test accuracy for mode 33:0.174 test loss: 273.881
35000: ********* epoch 4 ********* test accuracy for mode 34:0.1045 test loss: 271.569
35000: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 396.906
35000: ********* epoch 4 ********* test accuracy for mode 36:0.0195 test loss: 411.6
35010: accuracy:0.29 loss: 245.121 (lr:0.00010000012242529927)
35020: accuracy:0.28 loss: 238.263 (lr:0.00010000012181470054)
35030: accuracy:0.24 loss: 250.96 (lr:0.00010000012120714719)
35040: accuracy:0.26 loss: 235.817 (lr:0.00010000012060262402)
35050: accuracy:0.23 loss: 248.743 (lr:0.00010000012000111593)
35060: accuracy:0.15 loss: 270.344 (lr:0.00010000011940260786)
35070: accuracy:0.28 loss: 247.319 (lr:0.00010000011880708488)
35080: accuracy:0.28 loss: 234.66 (lr:0.00010000011821453207)
35090: accuracy:0.31 loss: 235.99 (lr:0.00010000011762493462)
35100: accuracy:0.22 loss: 266.965 (lr:0.00010000011703827781)
35110: accuracy:0.32 loss: 240.141 (lr:0.00010000011645454697)
35120: accuracy:0.28 loss: 257.434 (lr:0.00010000011587372749)
35130: accuracy:0.28 loss: 244.956 (lr:0.00010000011529580486)
35140: accuracy:0.23 loss: 237.648 (lr:0.00010000011472076464)
35150: accuracy:0.23 loss: 247.36 (lr:0.00010000011414859244)
35160: accuracy:0.2 loss: 251.511 (lr:0.00010000011357927396)
35170: accuracy:0.27 loss: 245.447 (lr:0.00010000011301279497)
35180: accuracy:0.26 loss: 248.926 (lr:0.0001000001124491413)
35190: accuracy:0.25 loss: 240.65 (lr:0.00010000011188829887)
35200: accuracy:0.23 loss: 255.789 (lr:0.00010000011133025366)
35210: accuracy:0.31 loss: 237.9 (lr:0.0001000001107749917)
35220: accuracy:0.28 loss: 232.114 (lr:0.00010000011022249911)
35230: accuracy:0.27 loss: 256.759 (lr:0.00010000010967276211)
35240: accuracy:0.28 loss: 246.013 (lr:0.00010000010912576693)
35250: accuracy:0.24 loss: 235.148 (lr:0.00010000010858149989)
35260: accuracy:0.26 loss: 245.588 (lr:0.00010000010803994741)
35270: accuracy:0.29 loss: 245.894 (lr:0.00010000010750109592)
35280: accuracy:0.27 loss: 246.474 (lr:0.00010000010696493197)
35290: accuracy:0.22 loss: 263.758 (lr:0.00010000010643144214)
35300: accuracy:0.15 loss: 251.944 (lr:0.00010000010590061311)
35310: accuracy:0.19 loss: 244.234 (lr:0.0001000001053724316)
35320: accuracy:0.23 loss: 239.548 (lr:0.00010000010484688441)
35330: accuracy:0.27 loss: 234.299 (lr:0.00010000010432395839)
35340: accuracy:0.34 loss: 241.151 (lr:0.00010000010380364048)
35350: accuracy:0.31 loss: 264.849 (lr:0.00010000010328591765)
35360: accuracy:0.17 loss: 257.242 (lr:0.00010000010277077699)
35370: accuracy:0.24 loss: 259.124 (lr:0.00010000010225820561)
35380: accuracy:0.31 loss: 236.337 (lr:0.00010000010174819067)
35390: accuracy:0.26 loss: 245.447 (lr:0.00010000010124071945)
35400: accuracy:0.24 loss: 260.578 (lr:0.00010000010073577926)
35410: accuracy:0.25 loss: 267.531 (lr:0.00010000010023335747)
35420: accuracy:0.29 loss: 251.563 (lr:0.00010000009973344151)
35430: accuracy:0.22 loss: 247.496 (lr:0.0001000000992360189)
35440: accuracy:0.22 loss: 250.179 (lr:0.00010000009874107718)
35450: accuracy:0.26 loss: 252.323 (lr:0.00010000009824860401)
35460: accuracy:0.24 loss: 241.836 (lr:0.00010000009775858705)
35470: accuracy:0.28 loss: 244.228 (lr:0.00010000009727101407)
35480: accuracy:0.27 loss: 240.886 (lr:0.00010000009678587286)
35490: accuracy:0.26 loss: 237.599 (lr:0.0001000000963031513)
35500: accuracy:0.26 loss: 238.517 (lr:0.00010000009582283734)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
35500: ********* epoch 4 ********* test accuracy for all:0.212081 test loss: 267.375
35500: ********* epoch 4 ********* test accuracy for mode 0:0.0 test loss: 410.196
35500: ********* epoch 4 ********* test accuracy for mode 1:0.075 test loss: 378.077
35500: ********* epoch 4 ********* test accuracy for mode 2:0.0935 test loss: 284.41
35500: ********* epoch 4 ********* test accuracy for mode 24:0.2285 test loss: 283.782
35500: ********* epoch 4 ********* test accuracy for mode 25:0.31 test loss: 260.689
35500: ********* epoch 4 ********* test accuracy for mode 26:0.1355 test loss: 202.26
35500: ********* epoch 4 ********* test accuracy for mode 27:0.249 test loss: 278.439
35500: ********* epoch 4 ********* test accuracy for mode 28:0.238 test loss: 268.985
35500: ********* epoch 4 ********* test accuracy for mode 29:0.284 test loss: 275.767
35500: ********* epoch 4 ********* test accuracy for mode 30:0.158 test loss: 269.757
35500: ********* epoch 4 ********* test accuracy for mode 31:0.232 test loss: 268.461
35500: ********* epoch 4 ********* test accuracy for mode 32:0.1815 test loss: 257.064
35500: ********* epoch 4 ********* test accuracy for mode 33:0.2095 test loss: 265.605
35500: ********* epoch 4 ********* test accuracy for mode 34:0.094 test loss: 266.687
35500: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 412.087
35500: ********* epoch 4 ********* test accuracy for mode 36:0.0195 test loss: 410.893
35510: accuracy:0.36 loss: 251.363 (lr:0.00010000009534491894)
35520: accuracy:0.23 loss: 257.389 (lr:0.00010000009486938418)
35530: accuracy:0.26 loss: 246.798 (lr:0.00010000009439622115)
35540: accuracy:0.2 loss: 253.769 (lr:0.00010000009392541803)
35550: accuracy:0.22 loss: 248.313 (lr:0.00010000009345696305)
35560: accuracy:0.23 loss: 248.213 (lr:0.00010000009299084451)
35570: accuracy:0.26 loss: 246.528 (lr:0.00010000009252705074)
35580: accuracy:0.21 loss: 243.227 (lr:0.00010000009206557014)
35590: accuracy:0.25 loss: 231.32 (lr:0.00010000009160639119)
35600: accuracy:0.24 loss: 247.157 (lr:0.0001000000911495024)
35610: accuracy:0.28 loss: 240.51 (lr:0.00010000009069489237)
35620: accuracy:0.28 loss: 247.612 (lr:0.00010000009024254971)
35630: accuracy:0.26 loss: 236.278 (lr:0.00010000008979246312)
35640: accuracy:0.27 loss: 239.389 (lr:0.00010000008934462133)
35650: accuracy:0.28 loss: 241.159 (lr:0.00010000008889901318)
35660: accuracy:0.22 loss: 270.836 (lr:0.0001000000884556275)
35670: accuracy:0.26 loss: 253.618 (lr:0.00010000008801445322)
35680: accuracy:0.27 loss: 239.151 (lr:0.0001000000875754793)
35690: accuracy:0.23 loss: 235.072 (lr:0.00010000008713869478)
35700: accuracy:0.29 loss: 237.757 (lr:0.00010000008670408872)
35710: accuracy:0.19 loss: 277.768 (lr:0.00010000008627165028)
35720: accuracy:0.24 loss: 235.775 (lr:0.00010000008584136863)
35730: accuracy:0.2 loss: 254.205 (lr:0.00010000008541323301)
35740: accuracy:0.22 loss: 241.256 (lr:0.00010000008498723274)
35750: accuracy:0.29 loss: 246.899 (lr:0.00010000008456335715)
35760: accuracy:0.29 loss: 232.521 (lr:0.00010000008414159565)
35770: accuracy:0.25 loss: 255.563 (lr:0.00010000008372193769)
35780: accuracy:0.35 loss: 230.122 (lr:0.00010000008330437278)
35790: accuracy:0.26 loss: 226.365 (lr:0.00010000008288889049)
35800: accuracy:0.27 loss: 242.02 (lr:0.00010000008247548042)
35810: accuracy:0.22 loss: 246.358 (lr:0.00010000008206413224)
35820: accuracy:0.26 loss: 259.449 (lr:0.00010000008165483568)
35830: accuracy:0.32 loss: 231.207 (lr:0.00010000008124758049)
35840: accuracy:0.29 loss: 243.614 (lr:0.00010000008084235648)
35850: accuracy:0.27 loss: 251.461 (lr:0.00010000008043915355)
35860: accuracy:0.21 loss: 252.298 (lr:0.0001000000800379616)
35870: accuracy:0.27 loss: 246.284 (lr:0.0001000000796387706)
35880: accuracy:0.26 loss: 258.29 (lr:0.00010000007924157057)
35890: accuracy:0.33 loss: 230.474 (lr:0.0001000000788463516)
35900: accuracy:0.22 loss: 233.904 (lr:0.00010000007845310377)
35910: accuracy:0.21 loss: 253.064 (lr:0.00010000007806181728)
35920: accuracy:0.25 loss: 245.436 (lr:0.00010000007767248234)
35930: accuracy:0.26 loss: 237.692 (lr:0.00010000007728508922)
35940: accuracy:0.27 loss: 237.468 (lr:0.00010000007689962823)
35950: accuracy:0.24 loss: 245.653 (lr:0.00010000007651608975)
35960: accuracy:0.35 loss: 242.522 (lr:0.00010000007613446415)
35970: accuracy:0.28 loss: 251.371 (lr:0.00010000007575474192)
35980: accuracy:0.25 loss: 251.838 (lr:0.00010000007537691358)
35990: accuracy:0.3 loss: 224.929 (lr:0.00010000007500096965)
36000: accuracy:0.21 loss: 274.388 (lr:0.00010000007462690076)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
36000: ********* epoch 4 ********* test accuracy for all:0.20673 test loss: 268.45
36000: ********* epoch 4 ********* test accuracy for mode 0:0.0 test loss: 397.651
36000: ********* epoch 4 ********* test accuracy for mode 1:0.103 test loss: 368.744
36000: ********* epoch 4 ********* test accuracy for mode 2:0.0885 test loss: 292.214
36000: ********* epoch 4 ********* test accuracy for mode 24:0.215 test loss: 275.486
36000: ********* epoch 4 ********* test accuracy for mode 25:0.2595 test loss: 260.693
36000: ********* epoch 4 ********* test accuracy for mode 26:0.1505 test loss: 206.648
36000: ********* epoch 4 ********* test accuracy for mode 27:0.1795 test loss: 289.968
36000: ********* epoch 4 ********* test accuracy for mode 28:0.291 test loss: 262.431
36000: ********* epoch 4 ********* test accuracy for mode 29:0.285 test loss: 272.808
36000: ********* epoch 4 ********* test accuracy for mode 30:0.1485 test loss: 271.798
36000: ********* epoch 4 ********* test accuracy for mode 31:0.247 test loss: 271.452
36000: ********* epoch 4 ********* test accuracy for mode 32:0.158 test loss: 262.948
36000: ********* epoch 4 ********* test accuracy for mode 33:0.222 test loss: 271.122
36000: ********* epoch 4 ********* test accuracy for mode 34:0.0845 test loss: 272.319
36000: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 405.451
36000: ********* epoch 4 ********* test accuracy for mode 36:0.024 test loss: 414.365
36010: accuracy:0.24 loss: 236.538 (lr:0.00010000007425469753)
36020: accuracy:0.25 loss: 244.43 (lr:0.00010000007388435068)
36030: accuracy:0.26 loss: 262.182 (lr:0.00010000007351585095)
36040: accuracy:0.22 loss: 259.935 (lr:0.00010000007314918912)
36050: accuracy:0.31 loss: 224.19 (lr:0.00010000007278435601)
36060: accuracy:0.2 loss: 242.007 (lr:0.00010000007242134251)
36070: accuracy:0.22 loss: 244.729 (lr:0.00010000007206013957)
36080: accuracy:0.2 loss: 260.045 (lr:0.00010000007170073813)
36090: accuracy:0.26 loss: 242.958 (lr:0.0001000000713431292)
36100: accuracy:0.28 loss: 252.428 (lr:0.00010000007098730386)
36110: accuracy:0.27 loss: 243.798 (lr:0.0001000000706332532)
36120: accuracy:0.16 loss: 253.151 (lr:0.00010000007028096839)
36130: accuracy:0.28 loss: 237.878 (lr:0.0001000000699304406)
36140: accuracy:0.24 loss: 246.54 (lr:0.00010000006958166106)
36150: accuracy:0.19 loss: 249.524 (lr:0.00010000006923462108)
36160: accuracy:0.28 loss: 236.043 (lr:0.00010000006888931197)
36170: accuracy:0.26 loss: 238.176 (lr:0.00010000006854572509)
36180: accuracy:0.29 loss: 251.784 (lr:0.00010000006820385186)
36190: accuracy:0.21 loss: 240.444 (lr:0.00010000006786368373)
36200: accuracy:0.24 loss: 245.241 (lr:0.00010000006752521219)
36210: accuracy:0.21 loss: 260.149 (lr:0.00010000006718842879)
36220: accuracy:0.24 loss: 245.012 (lr:0.00010000006685332511)
36230: accuracy:0.18 loss: 260.361 (lr:0.00010000006651989276)
36240: accuracy:0.35 loss: 237.782 (lr:0.00010000006618812341)
36250: accuracy:0.23 loss: 237.82 (lr:0.00010000006585800876)
36260: accuracy:0.25 loss: 246.908 (lr:0.00010000006552954058)
36270: accuracy:0.28 loss: 248.13 (lr:0.00010000006520271063)
36280: accuracy:0.28 loss: 241.763 (lr:0.00010000006487751076)
36290: accuracy:0.23 loss: 245.963 (lr:0.00010000006455393281)
36300: accuracy:0.26 loss: 238.102 (lr:0.00010000006423196873)
36310: accuracy:0.32 loss: 233.482 (lr:0.00010000006391161045)
36320: accuracy:0.25 loss: 244.96 (lr:0.00010000006359284997)
36330: accuracy:0.28 loss: 238.042 (lr:0.00010000006327567931)
36340: accuracy:0.19 loss: 239.563 (lr:0.00010000006296009054)
36350: accuracy:0.3 loss: 237.031 (lr:0.00010000006264607578)
36360: accuracy:0.36 loss: 235.043 (lr:0.00010000006233362717)
36370: accuracy:0.19 loss: 258.71 (lr:0.00010000006202273691)
36380: accuracy:0.34 loss: 236.62 (lr:0.00010000006171339721)
36390: accuracy:0.25 loss: 247.878 (lr:0.00010000006140560036)
36400: accuracy:0.3 loss: 238.452 (lr:0.00010000006109933866)
36410: accuracy:0.17 loss: 254.233 (lr:0.00010000006079460444)
36420: accuracy:0.16 loss: 262.803 (lr:0.00010000006049139007)
36430: accuracy:0.2 loss: 254.515 (lr:0.00010000006018968801)
36440: accuracy:0.29 loss: 247.022 (lr:0.00010000005988949068)
36450: accuracy:0.26 loss: 254.704 (lr:0.00010000005959079061)
36460: accuracy:0.22 loss: 245.386 (lr:0.0001000000592935803)
36470: accuracy:0.26 loss: 255.668 (lr:0.00010000005899785233)
36480: accuracy:0.26 loss: 251.42 (lr:0.00010000005870359932)
36490: accuracy:0.25 loss: 243.41 (lr:0.0001000000584108139)
36500: accuracy:0.26 loss: 238.812 (lr:0.00010000005811948875)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
36500: ********* epoch 4 ********* test accuracy for all:0.217311 test loss: 264.564
36500: ********* epoch 4 ********* test accuracy for mode 0:0.0005 test loss: 395.632
36500: ********* epoch 4 ********* test accuracy for mode 1:0.112 test loss: 365.556
36500: ********* epoch 4 ********* test accuracy for mode 2:0.0895 test loss: 289.71
36500: ********* epoch 4 ********* test accuracy for mode 24:0.2905 test loss: 259.974
36500: ********* epoch 4 ********* test accuracy for mode 25:0.2465 test loss: 249.991
36500: ********* epoch 4 ********* test accuracy for mode 26:0.219 test loss: 196.5
36500: ********* epoch 4 ********* test accuracy for mode 27:0.2585 test loss: 270.0
36500: ********* epoch 4 ********* test accuracy for mode 28:0.221 test loss: 264.084
36500: ********* epoch 4 ********* test accuracy for mode 29:0.303 test loss: 270.311
36500: ********* epoch 4 ********* test accuracy for mode 30:0.178 test loss: 271.994
36500: ********* epoch 4 ********* test accuracy for mode 31:0.16 test loss: 276.28
36500: ********* epoch 4 ********* test accuracy for mode 32:0.2385 test loss: 264.202
36500: ********* epoch 4 ********* test accuracy for mode 33:0.1585 test loss: 274.726
36500: ********* epoch 4 ********* test accuracy for mode 34:0.1455 test loss: 269.72
36500: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 396.358
36500: ********* epoch 4 ********* test accuracy for mode 36:0.0405 test loss: 404.827
36510: accuracy:0.2 loss: 258.351 (lr:0.00010000005782961659)
36520: accuracy:0.31 loss: 220.186 (lr:0.00010000005754119017)
36530: accuracy:0.25 loss: 256.524 (lr:0.00010000005725420229)
36540: accuracy:0.28 loss: 231.765 (lr:0.00010000005696864576)
36550: accuracy:0.29 loss: 242.46 (lr:0.00010000005668451345)
36560: accuracy:0.22 loss: 262.161 (lr:0.00010000005640179826)
36570: accuracy:0.14 loss: 258.429 (lr:0.00010000005612049312)
36580: accuracy:0.21 loss: 255.525 (lr:0.000100000055840591)
36590: accuracy:0.23 loss: 269.23 (lr:0.00010000005556208489)
36600: accuracy:0.39 loss: 226.699 (lr:0.00010000005528496784)
36610: accuracy:0.34 loss: 241.769 (lr:0.0001000000550092329)
36620: accuracy:0.31 loss: 238.312 (lr:0.00010000005473487321)
36630: accuracy:0.3 loss: 246.333 (lr:0.0001000000544618819)
36640: accuracy:0.24 loss: 237.356 (lr:0.00010000005419025212)
36650: accuracy:0.3 loss: 241.018 (lr:0.00010000005391997712)
36660: accuracy:0.33 loss: 236.776 (lr:0.0001000000536510501)
36670: accuracy:0.24 loss: 245.871 (lr:0.00010000005338346437)
36680: accuracy:0.21 loss: 252.295 (lr:0.00010000005311721324)
36690: accuracy:0.19 loss: 256.494 (lr:0.00010000005285229003)
36700: accuracy:0.37 loss: 213.73 (lr:0.00010000005258868813)
36710: accuracy:0.23 loss: 251.416 (lr:0.00010000005232640096)
36720: accuracy:0.31 loss: 240.785 (lr:0.00010000005206542195)
36730: accuracy:0.26 loss: 246.575 (lr:0.00010000005180574457)
36740: accuracy:0.27 loss: 238.525 (lr:0.00010000005154736234)
36750: accuracy:0.25 loss: 248.861 (lr:0.0001000000512902688)
36760: accuracy:0.22 loss: 233.056 (lr:0.00010000005103445752)
36770: accuracy:0.27 loss: 254.236 (lr:0.0001000000507799221)
36780: accuracy:0.21 loss: 245.226 (lr:0.00010000005052665617)
36790: accuracy:0.28 loss: 234.56 (lr:0.00010000005027465344)
36800: accuracy:0.28 loss: 249.731 (lr:0.00010000005002390755)
36810: accuracy:0.3 loss: 236.743 (lr:0.00010000004977441227)
36820: accuracy:0.25 loss: 230.396 (lr:0.00010000004952616135)
36830: accuracy:0.33 loss: 221.225 (lr:0.0001000000492791486)
36840: accuracy:0.22 loss: 249.107 (lr:0.00010000004903336781)
36850: accuracy:0.2 loss: 246.557 (lr:0.00010000004878881288)
36860: accuracy:0.26 loss: 248.565 (lr:0.00010000004854547765)
36870: accuracy:0.27 loss: 255.181 (lr:0.00010000004830335607)
36880: accuracy:0.17 loss: 255.563 (lr:0.00010000004806244208)
36890: accuracy:0.21 loss: 241.93 (lr:0.00010000004782272965)
36900: accuracy:0.25 loss: 243.907 (lr:0.00010000004758421279)
36910: accuracy:0.24 loss: 238.066 (lr:0.00010000004734688555)
36920: accuracy:0.22 loss: 251.215 (lr:0.00010000004711074196)
36930: accuracy:0.21 loss: 259.193 (lr:0.00010000004687577616)
36940: accuracy:0.28 loss: 233.993 (lr:0.00010000004664198225)
36950: accuracy:0.29 loss: 252.902 (lr:0.00010000004640935439)
36960: accuracy:0.26 loss: 236.332 (lr:0.00010000004617788677)
36970: accuracy:0.22 loss: 258.012 (lr:0.0001000000459475736)
36980: accuracy:0.28 loss: 244.105 (lr:0.00010000004571840913)
36990: accuracy:0.24 loss: 231.292 (lr:0.0001000000454903876)
37000: accuracy:0.36 loss: 229.939 (lr:0.00010000004526350335)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
37000: ********* epoch 4 ********* test accuracy for all:0.211851 test loss: 266.712
37000: ********* epoch 4 ********* test accuracy for mode 0:0.0 test loss: 399.033
37000: ********* epoch 4 ********* test accuracy for mode 1:0.0975 test loss: 367.994
37000: ********* epoch 4 ********* test accuracy for mode 2:0.075 test loss: 287.926
37000: ********* epoch 4 ********* test accuracy for mode 24:0.2205 test loss: 271.876
37000: ********* epoch 4 ********* test accuracy for mode 25:0.37 test loss: 250.918
37000: ********* epoch 4 ********* test accuracy for mode 26:0.089 test loss: 199.744
37000: ********* epoch 4 ********* test accuracy for mode 27:0.288 test loss: 269.805
37000: ********* epoch 4 ********* test accuracy for mode 28:0.221 test loss: 264.019
37000: ********* epoch 4 ********* test accuracy for mode 29:0.3105 test loss: 268.797
37000: ********* epoch 4 ********* test accuracy for mode 30:0.1675 test loss: 267.194
37000: ********* epoch 4 ********* test accuracy for mode 31:0.1985 test loss: 269.152
37000: ********* epoch 4 ********* test accuracy for mode 32:0.256 test loss: 257.267
37000: ********* epoch 4 ********* test accuracy for mode 33:0.146 test loss: 271.279
37000: ********* epoch 4 ********* test accuracy for mode 34:0.115 test loss: 267.999
37000: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 402.051
37000: ********* epoch 4 ********* test accuracy for mode 36:0.0245 test loss: 413.715
37010: accuracy:0.26 loss: 248.691 (lr:0.00010000004503775069)
37020: accuracy:0.22 loss: 251.082 (lr:0.00010000004481312396)
37030: accuracy:0.2 loss: 245.599 (lr:0.00010000004458961758)
37040: accuracy:0.24 loss: 244.687 (lr:0.00010000004436722594)
37050: accuracy:0.24 loss: 237.324 (lr:0.00010000004414594347)
37060: accuracy:0.28 loss: 233.606 (lr:0.00010000004392576466)
37070: accuracy:0.26 loss: 238.196 (lr:0.00010000004370668399)
37080: accuracy:0.27 loss: 231.311 (lr:0.000100000043488696)
37090: accuracy:0.3 loss: 262.365 (lr:0.00010000004327179522)
37100: accuracy:0.23 loss: 244.305 (lr:0.00010000004305597624)
37110: accuracy:0.21 loss: 248.121 (lr:0.00010000004284123366)
37120: accuracy:0.29 loss: 229.494 (lr:0.00010000004262756212)
37130: accuracy:0.22 loss: 244.039 (lr:0.00010000004241495626)
37140: accuracy:0.28 loss: 253.111 (lr:0.00010000004220341079)
37150: accuracy:0.24 loss: 243.65 (lr:0.0001000000419929204)
37160: accuracy:0.28 loss: 234.339 (lr:0.00010000004178347984)
37170: accuracy:0.29 loss: 245.031 (lr:0.00010000004157508386)
37180: accuracy:0.27 loss: 236.047 (lr:0.00010000004136772727)
37190: accuracy:0.34 loss: 225.032 (lr:0.00010000004116140487)
37200: accuracy:0.27 loss: 253.756 (lr:0.0001000000409561115)
37210: accuracy:0.22 loss: 252.621 (lr:0.00010000004075184204)
37220: accuracy:0.31 loss: 225.769 (lr:0.00010000004054859139)
37230: accuracy:0.24 loss: 231.929 (lr:0.00010000004034635444)
37240: accuracy:0.25 loss: 251.222 (lr:0.00010000004014512616)
37250: accuracy:0.26 loss: 239.947 (lr:0.0001000000399449015)
37260: accuracy:0.22 loss: 236.491 (lr:0.00010000003974567548)
37270: accuracy:0.22 loss: 239.132 (lr:0.0001000000395474431)
37280: accuracy:0.35 loss: 226.991 (lr:0.0001000000393501994)
37290: accuracy:0.24 loss: 237.729 (lr:0.00010000003915393947)
37300: accuracy:0.25 loss: 233.441 (lr:0.00010000003895865838)
37310: accuracy:0.24 loss: 235.356 (lr:0.00010000003876435126)
37320: accuracy:0.24 loss: 254.445 (lr:0.00010000003857101325)
37330: accuracy:0.22 loss: 245.837 (lr:0.00010000003837863952)
37340: accuracy:0.23 loss: 244.368 (lr:0.00010000003818722525)
37350: accuracy:0.3 loss: 239.456 (lr:0.00010000003799676568)
37360: accuracy:0.22 loss: 233.824 (lr:0.00010000003780725602)
37370: accuracy:0.22 loss: 239.956 (lr:0.00010000003761869153)
37380: accuracy:0.28 loss: 252.275 (lr:0.00010000003743106753)
37390: accuracy:0.25 loss: 270.119 (lr:0.0001000000372443793)
37400: accuracy:0.25 loss: 250.346 (lr:0.00010000003705862218)
37410: accuracy:0.33 loss: 243.856 (lr:0.00010000003687379154)
37420: accuracy:0.28 loss: 228.275 (lr:0.00010000003668988273)
37430: accuracy:0.25 loss: 242.633 (lr:0.00010000003650689118)
37440: accuracy:0.24 loss: 244.941 (lr:0.0001000000363248123)
37450: accuracy:0.32 loss: 224.933 (lr:0.00010000003614364154)
37460: accuracy:0.25 loss: 248.256 (lr:0.00010000003596337437)
37470: accuracy:0.31 loss: 249.512 (lr:0.0001000000357840063)
37480: accuracy:0.28 loss: 245.639 (lr:0.00010000003560553282)
37490: accuracy:0.23 loss: 246.007 (lr:0.00010000003542794949)
37500: accuracy:0.25 loss: 264.989 (lr:0.00010000003525125186)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
37500: ********* epoch 4 ********* test accuracy for all:0.211514 test loss: 267.138
37500: ********* epoch 4 ********* test accuracy for mode 0:0.0 test loss: 400.833
37500: ********* epoch 4 ********* test accuracy for mode 1:0.104 test loss: 368.445
37500: ********* epoch 4 ********* test accuracy for mode 2:0.068 test loss: 294.722
37500: ********* epoch 4 ********* test accuracy for mode 24:0.2265 test loss: 273.947
37500: ********* epoch 4 ********* test accuracy for mode 25:0.372 test loss: 250.759
37500: ********* epoch 4 ********* test accuracy for mode 26:0.054 test loss: 201.266
37500: ********* epoch 4 ********* test accuracy for mode 27:0.2715 test loss: 279.572
37500: ********* epoch 4 ********* test accuracy for mode 28:0.246 test loss: 269.178
37500: ********* epoch 4 ********* test accuracy for mode 29:0.259 test loss: 280.288
37500: ********* epoch 4 ********* test accuracy for mode 30:0.213 test loss: 276.532
37500: ********* epoch 4 ********* test accuracy for mode 31:0.15 test loss: 285.508
37500: ********* epoch 4 ********* test accuracy for mode 32:0.201 test loss: 271.849
37500: ********* epoch 4 ********* test accuracy for mode 33:0.1985 test loss: 277.382
37500: ********* epoch 4 ********* test accuracy for mode 34:0.1285 test loss: 273.5
37500: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 401.654
37500: ********* epoch 4 ********* test accuracy for mode 36:0.02 test loss: 404.387
37510: accuracy:0.32 loss: 230.347 (lr:0.00010000003507543551)
37520: accuracy:0.22 loss: 236.457 (lr:0.00010000003490049603)
37530: accuracy:0.31 loss: 237.602 (lr:0.00010000003472642908)
37540: accuracy:0.27 loss: 250.371 (lr:0.0001000000345532303)
37550: accuracy:0.24 loss: 270.752 (lr:0.00010000003438089534)
37560: accuracy:0.27 loss: 251.675 (lr:0.00010000003420941992)
37570: accuracy:0.3 loss: 220.922 (lr:0.00010000003403879972)
37580: accuracy:0.26 loss: 236.987 (lr:0.0001000000338690305)
37590: accuracy:0.29 loss: 243.273 (lr:0.000100000033700108)
37600: accuracy:0.32 loss: 230.685 (lr:0.00010000003353202802)
37610: accuracy:0.28 loss: 238.684 (lr:0.00010000003336478632)
37620: accuracy:0.31 loss: 234.008 (lr:0.00010000003319837876)
37630: accuracy:0.26 loss: 246.831 (lr:0.00010000003303280115)
37640: accuracy:0.21 loss: 255.586 (lr:0.00010000003286804938)
37650: accuracy:0.19 loss: 249.458 (lr:0.0001000000327041193)
37660: accuracy:0.29 loss: 222.766 (lr:0.00010000003254100681)
37670: accuracy:0.23 loss: 238.973 (lr:0.00010000003237870787)
37680: accuracy:0.22 loss: 268.968 (lr:0.00010000003221721839)
37690: accuracy:0.3 loss: 240.843 (lr:0.00010000003205653434)
37700: accuracy:0.31 loss: 233.477 (lr:0.0001000000318966517)
37710: accuracy:0.29 loss: 247.036 (lr:0.00010000003173756649)
37720: accuracy:0.33 loss: 222.023 (lr:0.00010000003157927472)
37730: accuracy:0.31 loss: 227.433 (lr:0.00010000003142177243)
37740: accuracy:0.21 loss: 252.774 (lr:0.0001000000312650557)
37750: accuracy:0.33 loss: 219.612 (lr:0.00010000003110912057)
37760: accuracy:0.3 loss: 226.3 (lr:0.00010000003095396319)
37770: accuracy:0.31 loss: 231.75 (lr:0.00010000003079957965)
37780: accuracy:0.28 loss: 244.626 (lr:0.0001000000306459661)
37790: accuracy:0.31 loss: 238.414 (lr:0.00010000003049311871)
37800: accuracy:0.24 loss: 231.867 (lr:0.00010000003034103365)
37810: accuracy:0.27 loss: 252.393 (lr:0.00010000003018970712)
37820: accuracy:0.23 loss: 236.755 (lr:0.00010000003003913531)
37830: accuracy:0.31 loss: 241.471 (lr:0.00010000002988931451)
37840: accuracy:0.24 loss: 262.466 (lr:0.00010000002974024093)
37850: accuracy:0.24 loss: 240.213 (lr:0.00010000002959191086)
37860: accuracy:0.28 loss: 243.084 (lr:0.00010000002944432059)
37870: accuracy:0.26 loss: 230.89 (lr:0.00010000002929746642)
37880: accuracy:0.28 loss: 250.271 (lr:0.0001000000291513447)
37890: accuracy:0.25 loss: 234.227 (lr:0.00010000002900595177)
37900: accuracy:0.22 loss: 255.126 (lr:0.00010000002886128397)
37910: accuracy:0.24 loss: 247.437 (lr:0.00010000002871733772)
37920: accuracy:0.35 loss: 234.711 (lr:0.0001000000285741094)
37930: accuracy:0.27 loss: 231.862 (lr:0.00010000002843159543)
37940: accuracy:0.25 loss: 244.657 (lr:0.00010000002828979227)
37950: accuracy:0.25 loss: 256.832 (lr:0.00010000002814869634)
37960: accuracy:0.2 loss: 247.686 (lr:0.00010000002800830412)
37970: accuracy:0.25 loss: 245.411 (lr:0.00010000002786861213)
37980: accuracy:0.36 loss: 253.066 (lr:0.00010000002772961685)
37990: accuracy:0.22 loss: 249.469 (lr:0.0001000000275913148)
38000: accuracy:0.13 loss: 244.622 (lr:0.00010000002745370255)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
38000: ********* epoch 4 ********* test accuracy for all:0.211622 test loss: 265.958
38000: ********* epoch 4 ********* test accuracy for mode 0:0.0 test loss: 395.985
38000: ********* epoch 4 ********* test accuracy for mode 1:0.107 test loss: 362.543
38000: ********* epoch 4 ********* test accuracy for mode 2:0.089 test loss: 289.75
38000: ********* epoch 4 ********* test accuracy for mode 24:0.229 test loss: 278.652
38000: ********* epoch 4 ********* test accuracy for mode 25:0.317 test loss: 258.445
38000: ********* epoch 4 ********* test accuracy for mode 26:0.0805 test loss: 198.952
38000: ********* epoch 4 ********* test accuracy for mode 27:0.2865 test loss: 269.115
38000: ********* epoch 4 ********* test accuracy for mode 28:0.2855 test loss: 255.541
38000: ********* epoch 4 ********* test accuracy for mode 29:0.321 test loss: 269.026
38000: ********* epoch 4 ********* test accuracy for mode 30:0.1185 test loss: 272.219
38000: ********* epoch 4 ********* test accuracy for mode 31:0.176 test loss: 274.25
38000: ********* epoch 4 ********* test accuracy for mode 32:0.249 test loss: 259.673
38000: ********* epoch 4 ********* test accuracy for mode 33:0.2045 test loss: 269.506
38000: ********* epoch 4 ********* test accuracy for mode 34:0.1295 test loss: 268.331
38000: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 404.008
38000: ********* epoch 4 ********* test accuracy for mode 36:0.019 test loss: 412.919
38010: accuracy:0.29 loss: 252.795 (lr:0.00010000002731677664)
38020: accuracy:0.21 loss: 259.377 (lr:0.00010000002718053364)
38030: accuracy:0.28 loss: 241.897 (lr:0.00010000002704497016)
38040: accuracy:0.25 loss: 244.223 (lr:0.00010000002691008281)
38050: accuracy:0.22 loss: 252.867 (lr:0.00010000002677586822)
38060: accuracy:0.28 loss: 245.502 (lr:0.00010000002664232302)
38070: accuracy:0.46 loss: 218.352 (lr:0.00010000002650944388)
38080: accuracy:0.3 loss: 232.341 (lr:0.00010000002637722747)
38090: accuracy:0.33 loss: 217.616 (lr:0.0001000000262456705)
38100: accuracy:0.27 loss: 241.967 (lr:0.00010000002611476968)
38110: accuracy:0.3 loss: 241.506 (lr:0.00010000002598452172)
38120: accuracy:0.27 loss: 245.316 (lr:0.00010000002585492338)
38130: accuracy:0.2 loss: 237.871 (lr:0.00010000002572597141)
38140: accuracy:0.25 loss: 246.237 (lr:0.00010000002559766258)
38150: accuracy:0.27 loss: 227.137 (lr:0.00010000002546999371)
38160: accuracy:0.27 loss: 240.356 (lr:0.0001000000253429616)
38170: accuracy:0.27 loss: 239.562 (lr:0.00010000002521656304)
38180: accuracy:0.25 loss: 238.647 (lr:0.00010000002509079491)
38190: accuracy:0.35 loss: 236.391 (lr:0.00010000002496565405)
38200: accuracy:0.32 loss: 257.382 (lr:0.00010000002484113733)
38210: accuracy:0.27 loss: 237.014 (lr:0.00010000002471724165)
38220: accuracy:0.29 loss: 242.753 (lr:0.00010000002459396389)
38230: accuracy:0.24 loss: 267.663 (lr:0.00010000002447130098)
38240: accuracy:0.31 loss: 237.607 (lr:0.00010000002434924985)
38250: accuracy:0.3 loss: 234.207 (lr:0.00010000002422780747)
38260: accuracy:0.3 loss: 258.216 (lr:0.00010000002410697076)
38270: accuracy:0.28 loss: 238.774 (lr:0.00010000002398673676)
38280: accuracy:0.27 loss: 248.962 (lr:0.0001000000238671024)
38290: accuracy:0.22 loss: 248.028 (lr:0.00010000002374806473)
38300: accuracy:0.28 loss: 237.115 (lr:0.00010000002362962077)
38310: accuracy:0.25 loss: 235.156 (lr:0.00010000002351176754)
38320: accuracy:0.26 loss: 237.581 (lr:0.0001000000233945021)
38330: accuracy:0.3 loss: 242.648 (lr:0.00010000002327782154)
38340: accuracy:0.3 loss: 245.084 (lr:0.00010000002316172292)
38350: accuracy:0.28 loss: 230.355 (lr:0.00010000002304620335)
38360: accuracy:0.34 loss: 243.042 (lr:0.00010000002293125994)
38370: accuracy:0.22 loss: 258.535 (lr:0.0001000000228168898)
38380: accuracy:0.25 loss: 226.742 (lr:0.00010000002270309008)
38390: accuracy:0.33 loss: 225.875 (lr:0.00010000002258985795)
38400: accuracy:0.2 loss: 259.665 (lr:0.00010000002247719056)
38410: accuracy:0.28 loss: 241.793 (lr:0.0001000000223650851)
38420: accuracy:0.22 loss: 251.925 (lr:0.00010000002225353878)
38430: accuracy:0.21 loss: 244.637 (lr:0.0001000000221425488)
38440: accuracy:0.29 loss: 233.514 (lr:0.00010000002203211237)
38450: accuracy:0.24 loss: 241.039 (lr:0.00010000002192222675)
38460: accuracy:0.29 loss: 245.183 (lr:0.00010000002181288919)
38470: accuracy:0.17 loss: 264.327 (lr:0.00010000002170409695)
38480: accuracy:0.22 loss: 228.322 (lr:0.00010000002159584732)
38490: accuracy:0.26 loss: 229.932 (lr:0.00010000002148813758)
38500: accuracy:0.28 loss: 225.745 (lr:0.00010000002138096505)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
38500: ********* epoch 4 ********* test accuracy for all:0.215568 test loss: 266.779
38500: ********* epoch 4 ********* test accuracy for mode 0:0.0005 test loss: 412.401
38500: ********* epoch 4 ********* test accuracy for mode 1:0.094 test loss: 374.698
38500: ********* epoch 4 ********* test accuracy for mode 2:0.0975 test loss: 287.166
38500: ********* epoch 4 ********* test accuracy for mode 24:0.2455 test loss: 272.883
38500: ********* epoch 4 ********* test accuracy for mode 25:0.318 test loss: 253.018
38500: ********* epoch 4 ********* test accuracy for mode 26:0.098 test loss: 194.967
38500: ********* epoch 4 ********* test accuracy for mode 27:0.2645 test loss: 271.388
38500: ********* epoch 4 ********* test accuracy for mode 28:0.28 test loss: 256.164
38500: ********* epoch 4 ********* test accuracy for mode 29:0.2925 test loss: 268.922
38500: ********* epoch 4 ********* test accuracy for mode 30:0.206 test loss: 265.788
38500: ********* epoch 4 ********* test accuracy for mode 31:0.1955 test loss: 270.396
38500: ********* epoch 4 ********* test accuracy for mode 32:0.186 test loss: 259.014
38500: ********* epoch 4 ********* test accuracy for mode 33:0.248 test loss: 265.706
38500: ********* epoch 4 ********* test accuracy for mode 34:0.0755 test loss: 267.55
38500: ********* epoch 4 ********* test accuracy for mode 35:0.0 test loss: 415.369
38500: ********* epoch 4 ********* test accuracy for mode 36:0.0105 test loss: 450.357
38510: accuracy:0.25 loss: 263.213 (lr:0.00010000002127432703)
38520: accuracy:0.28 loss: 221.401 (lr:0.00010000002116822088)
38530: accuracy:0.35 loss: 217.383 (lr:0.00010000002106264394)
38540: accuracy:0.29 loss: 246.766 (lr:0.00010000002095759358)
38550: accuracy:0.33 loss: 225.828 (lr:0.00010000002085306713)
38560: accuracy:0.34 loss: 228.339 (lr:0.00010000002074906203)
38570: accuracy:0.24 loss: 260.399 (lr:0.00010000002064557565)
38580: accuracy:0.33 loss: 246.793 (lr:0.00010000002054260541)
38590: accuracy:0.26 loss: 247.17 (lr:0.00010000002044014874)
38600: accuracy:0.27 loss: 242.152 (lr:0.00010000002033820308)
38610: accuracy:0.27 loss: 236.315 (lr:0.00010000002023676587)
38620: accuracy:0.25 loss: 254.352 (lr:0.00010000002013583457)
38630: accuracy:0.36 loss: 222.354 (lr:0.00010000002003540667)
38640: accuracy:0.29 loss: 226.05 (lr:0.00010000001993547968)
38650: accuracy:0.3 loss: 216.851 (lr:0.00010000001983605105)
38660: accuracy:0.3 loss: 231.738 (lr:0.00010000001973711833)
38670: accuracy:0.19 loss: 248.311 (lr:0.00010000001963867905)
38680: accuracy:0.26 loss: 255.233 (lr:0.00010000001954073072)
38690: accuracy:0.26 loss: 229.722 (lr:0.00010000001944327092)
38700: accuracy:0.22 loss: 243.689 (lr:0.0001000000193462972)
38710: accuracy:0.25 loss: 246.158 (lr:0.00010000001924980714)
38720: accuracy:0.34 loss: 225.06 (lr:0.00010000001915379833)
38730: accuracy:0.24 loss: 242.345 (lr:0.00010000001905826837)
38740: accuracy:0.26 loss: 237.592 (lr:0.00010000001896321486)
38750: accuracy:0.26 loss: 245.498 (lr:0.00010000001886863543)
38760: accuracy:0.24 loss: 253.285 (lr:0.00010000001877452771)
38770: accuracy:0.32 loss: 232.486 (lr:0.00010000001868088937)
38780: accuracy:0.19 loss: 242.352 (lr:0.00010000001858771804)
38790: accuracy:0.28 loss: 236.902 (lr:0.00010000001849501141)
38800: accuracy:0.17 loss: 251.89 (lr:0.00010000001840276716)
38810: accuracy:0.3 loss: 242.549 (lr:0.00010000001831098297)
38820: accuracy:0.21 loss: 250.188 (lr:0.00010000001821965657)
38830: accuracy:0.24 loss: 225.286 (lr:0.00010000001812878565)
38840: accuracy:0.31 loss: 242.123 (lr:0.00010000001803836795)
38850: accuracy:0.3 loss: 215.081 (lr:0.00010000001794840122)
38860: accuracy:0.2 loss: 246.216 (lr:0.00010000001785888319)
38870: accuracy:0.3 loss: 247.099 (lr:0.00010000001776981164)
38880: accuracy:0.27 loss: 242.255 (lr:0.00010000001768118433)
38890: accuracy:0.21 loss: 249.355 (lr:0.00010000001759299906)
38900: accuracy:0.25 loss: 257.446 (lr:0.00010000001750525361)
38910: accuracy:0.29 loss: 235.49 (lr:0.0001000000174179458)
38920: accuracy:0.26 loss: 237.923 (lr:0.00010000001733107343)
38930: accuracy:0.19 loss: 255.521 (lr:0.00010000001724463434)
38940: accuracy:0.31 loss: 232.315 (lr:0.00010000001715862637)
38950: accuracy:0.32 loss: 225.18 (lr:0.00010000001707304737)
38960: accuracy:0.27 loss: 239.726 (lr:0.00010000001698789519)
38970: accuracy:0.24 loss: 234.932 (lr:0.0001000000169031677)
38980: accuracy:0.28 loss: 242.02 (lr:0.0001000000168188628)
38990: accuracy:0.28 loss: 226.106 (lr:0.00010000001673497837)
39000: accuracy:0.2 loss: 256.331 (lr:0.00010000001665151231)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
39000: ********* epoch 5 ********* test accuracy for all:0.215054 test loss: 264.784
39000: ********* epoch 5 ********* test accuracy for mode 0:0.0 test loss: 406.789
39000: ********* epoch 5 ********* test accuracy for mode 1:0.1085 test loss: 366.804
39000: ********* epoch 5 ********* test accuracy for mode 2:0.102 test loss: 286.081
39000: ********* epoch 5 ********* test accuracy for mode 24:0.2605 test loss: 260.632
39000: ********* epoch 5 ********* test accuracy for mode 25:0.2945 test loss: 243.837
39000: ********* epoch 5 ********* test accuracy for mode 26:0.0735 test loss: 201.531
39000: ********* epoch 5 ********* test accuracy for mode 27:0.2695 test loss: 269.201
39000: ********* epoch 5 ********* test accuracy for mode 28:0.258 test loss: 257.503
39000: ********* epoch 5 ********* test accuracy for mode 29:0.293 test loss: 263.897
39000: ********* epoch 5 ********* test accuracy for mode 30:0.186 test loss: 264.901
39000: ********* epoch 5 ********* test accuracy for mode 31:0.18 test loss: 268.829
39000: ********* epoch 5 ********* test accuracy for mode 32:0.2045 test loss: 257.698
39000: ********* epoch 5 ********* test accuracy for mode 33:0.225 test loss: 264.094
39000: ********* epoch 5 ********* test accuracy for mode 34:0.135 test loss: 263.551
39000: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 403.654
39000: ********* epoch 5 ********* test accuracy for mode 36:0.0245 test loss: 421.815
39010: accuracy:0.27 loss: 243.794 (lr:0.00010000001656846256)
39020: accuracy:0.32 loss: 240.097 (lr:0.000100000016485827)
39030: accuracy:0.23 loss: 234.462 (lr:0.0001000000164036036)
39040: accuracy:0.18 loss: 248.605 (lr:0.00010000001632179028)
39050: accuracy:0.3 loss: 228.082 (lr:0.00010000001624038502)
39060: accuracy:0.3 loss: 238.439 (lr:0.00010000001615938576)
39070: accuracy:0.3 loss: 239.697 (lr:0.00010000001607879048)
39080: accuracy:0.27 loss: 249.112 (lr:0.00010000001599859719)
39090: accuracy:0.32 loss: 250.09 (lr:0.00010000001591880385)
39100: accuracy:0.31 loss: 238.063 (lr:0.00010000001583940848)
39110: accuracy:0.24 loss: 250.67 (lr:0.0001000000157604091)
39120: accuracy:0.27 loss: 245.013 (lr:0.00010000001568180373)
39130: accuracy:0.23 loss: 234.253 (lr:0.0001000000156035904)
39140: accuracy:0.4 loss: 225.039 (lr:0.00010000001552576719)
39150: accuracy:0.26 loss: 233.499 (lr:0.0001000000154483321)
39160: accuracy:0.2 loss: 246.562 (lr:0.00010000001537128322)
39170: accuracy:0.3 loss: 236.405 (lr:0.00010000001529461862)
39180: accuracy:0.24 loss: 248.388 (lr:0.00010000001521833639)
39190: accuracy:0.27 loss: 240.82 (lr:0.00010000001514243462)
39200: accuracy:0.35 loss: 225.064 (lr:0.00010000001506691141)
39210: accuracy:0.27 loss: 253.357 (lr:0.00010000001499176489)
39220: accuracy:0.29 loss: 235.311 (lr:0.00010000001491699314)
39230: accuracy:0.28 loss: 230.26 (lr:0.00010000001484259432)
39240: accuracy:0.25 loss: 268.761 (lr:0.00010000001476856658)
39250: accuracy:0.24 loss: 250.33 (lr:0.00010000001469490804)
39260: accuracy:0.26 loss: 246.826 (lr:0.00010000001462161688)
39270: accuracy:0.16 loss: 276.287 (lr:0.00010000001454869126)
39280: accuracy:0.3 loss: 245.318 (lr:0.00010000001447612937)
39290: accuracy:0.29 loss: 230.527 (lr:0.00010000001440392938)
39300: accuracy:0.23 loss: 231.669 (lr:0.00010000001433208948)
39310: accuracy:0.19 loss: 244.993 (lr:0.00010000001426060788)
39320: accuracy:0.28 loss: 227.717 (lr:0.0001000000141894828)
39330: accuracy:0.24 loss: 227.753 (lr:0.00010000001411871246)
39340: accuracy:0.33 loss: 222.857 (lr:0.00010000001404829508)
39350: accuracy:0.26 loss: 243.493 (lr:0.00010000001397822893)
39360: accuracy:0.33 loss: 235.224 (lr:0.00010000001390851222)
39370: accuracy:0.23 loss: 245.964 (lr:0.00010000001383914323)
39380: accuracy:0.21 loss: 245.649 (lr:0.00010000001377012021)
39390: accuracy:0.31 loss: 233.612 (lr:0.00010000001370144145)
39400: accuracy:0.25 loss: 236.089 (lr:0.00010000001363310523)
39410: accuracy:0.25 loss: 231.481 (lr:0.00010000001356510983)
39420: accuracy:0.2 loss: 244.653 (lr:0.00010000001349745355)
39430: accuracy:0.26 loss: 237.115 (lr:0.00010000001343013474)
39440: accuracy:0.26 loss: 231.85 (lr:0.00010000001336315165)
39450: accuracy:0.31 loss: 222.792 (lr:0.00010000001329650266)
39460: accuracy:0.36 loss: 234.432 (lr:0.00010000001323018608)
39470: accuracy:0.27 loss: 250.852 (lr:0.00010000001316420024)
39480: accuracy:0.24 loss: 252.793 (lr:0.00010000001309854352)
39490: accuracy:0.28 loss: 217.422 (lr:0.00010000001303321426)
39500: accuracy:0.26 loss: 220.469 (lr:0.00010000001296821083)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
39500: ********* epoch 5 ********* test accuracy for all:0.215784 test loss: 264.582
39500: ********* epoch 5 ********* test accuracy for mode 0:0.0 test loss: 408.577
39500: ********* epoch 5 ********* test accuracy for mode 1:0.1085 test loss: 371.352
39500: ********* epoch 5 ********* test accuracy for mode 2:0.102 test loss: 289.535
39500: ********* epoch 5 ********* test accuracy for mode 24:0.2445 test loss: 272.188
39500: ********* epoch 5 ********* test accuracy for mode 25:0.3035 test loss: 254.893
39500: ********* epoch 5 ********* test accuracy for mode 26:0.1125 test loss: 197.512
39500: ********* epoch 5 ********* test accuracy for mode 27:0.282 test loss: 270.859
39500: ********* epoch 5 ********* test accuracy for mode 28:0.2585 test loss: 259.814
39500: ********* epoch 5 ********* test accuracy for mode 29:0.2865 test loss: 268.267
39500: ********* epoch 5 ********* test accuracy for mode 30:0.1885 test loss: 266.321
39500: ********* epoch 5 ********* test accuracy for mode 31:0.1995 test loss: 271.034
39500: ********* epoch 5 ********* test accuracy for mode 32:0.1865 test loss: 260.708
39500: ********* epoch 5 ********* test accuracy for mode 33:0.216 test loss: 268.055
39500: ********* epoch 5 ********* test accuracy for mode 34:0.1 test loss: 268.781
39500: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 404.606
39500: ********* epoch 5 ********* test accuracy for mode 36:0.0195 test loss: 428.227
39510: accuracy:0.33 loss: 259.268 (lr:0.00010000001290353161)
39520: accuracy:0.21 loss: 252.059 (lr:0.00010000001283917499)
39530: accuracy:0.28 loss: 246.526 (lr:0.00010000001277513934)
39540: accuracy:0.33 loss: 230.226 (lr:0.00010000001271142305)
39550: accuracy:0.31 loss: 242.812 (lr:0.00010000001264802457)
39560: accuracy:0.29 loss: 231.4 (lr:0.00010000001258494229)
39570: accuracy:0.29 loss: 221.341 (lr:0.00010000001252217463)
39580: accuracy:0.27 loss: 250.332 (lr:0.00010000001245972001)
39590: accuracy:0.29 loss: 248.85 (lr:0.00010000001239757691)
39600: accuracy:0.3 loss: 241.056 (lr:0.00010000001233574373)
39610: accuracy:0.29 loss: 231.488 (lr:0.00010000001227421895)
39620: accuracy:0.21 loss: 242.224 (lr:0.00010000001221300103)
39630: accuracy:0.21 loss: 234.849 (lr:0.00010000001215208844)
39640: accuracy:0.19 loss: 244.26 (lr:0.00010000001209147964)
39650: accuracy:0.31 loss: 251.771 (lr:0.00010000001203117313)
39660: accuracy:0.33 loss: 226.336 (lr:0.0001000000119711674)
39670: accuracy:0.29 loss: 239.13 (lr:0.00010000001191146096)
39680: accuracy:0.23 loss: 233.525 (lr:0.0001000000118520523)
39690: accuracy:0.26 loss: 236.44 (lr:0.00010000001179293995)
39700: accuracy:0.21 loss: 249.387 (lr:0.00010000001173412241)
39710: accuracy:0.34 loss: 229.303 (lr:0.00010000001167559822)
39720: accuracy:0.24 loss: 234.429 (lr:0.00010000001161736594)
39730: accuracy:0.27 loss: 249.362 (lr:0.00010000001155942409)
39740: accuracy:0.3 loss: 242.066 (lr:0.00010000001150177122)
39750: accuracy:0.31 loss: 219.137 (lr:0.0001000000114444059)
39760: accuracy:0.19 loss: 251.912 (lr:0.00010000001138732669)
39770: accuracy:0.25 loss: 246.179 (lr:0.00010000001133053215)
39780: accuracy:0.26 loss: 241.941 (lr:0.00010000001127402089)
39790: accuracy:0.21 loss: 245.345 (lr:0.00010000001121779147)
39800: accuracy:0.21 loss: 243.859 (lr:0.0001000000111618425)
39810: accuracy:0.26 loss: 244.331 (lr:0.00010000001110617259)
39820: accuracy:0.26 loss: 246.552 (lr:0.00010000001105078032)
39830: accuracy:0.26 loss: 239.861 (lr:0.00010000001099566432)
39840: accuracy:0.32 loss: 233.47 (lr:0.00010000001094082322)
39850: accuracy:0.21 loss: 224.669 (lr:0.00010000001088625563)
39860: accuracy:0.31 loss: 227.345 (lr:0.00010000001083196021)
39870: accuracy:0.26 loss: 240.341 (lr:0.00010000001077793558)
39880: accuracy:0.27 loss: 249.389 (lr:0.0001000000107241804)
39890: accuracy:0.19 loss: 243.788 (lr:0.00010000001067069332)
39900: accuracy:0.24 loss: 236.198 (lr:0.00010000001061747302)
39910: accuracy:0.28 loss: 252.16 (lr:0.00010000001056451815)
39920: accuracy:0.26 loss: 242.753 (lr:0.0001000000105118274)
39930: accuracy:0.24 loss: 234.123 (lr:0.00010000001045939945)
39940: accuracy:0.24 loss: 243.837 (lr:0.00010000001040723297)
39950: accuracy:0.27 loss: 258.147 (lr:0.00010000001035532668)
39960: accuracy:0.32 loss: 239.103 (lr:0.00010000001030367927)
39970: accuracy:0.21 loss: 238.273 (lr:0.00010000001025228946)
39980: accuracy:0.26 loss: 250.653 (lr:0.00010000001020115595)
39990: accuracy:0.29 loss: 230.85 (lr:0.00010000001015027747)
40000: accuracy:0.32 loss: 218.705 (lr:0.00010000001009965275)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
40000: ********* epoch 5 ********* test accuracy for all:0.215459 test loss: 265.706
40000: ********* epoch 5 ********* test accuracy for mode 0:0.001 test loss: 397.26
40000: ********* epoch 5 ********* test accuracy for mode 1:0.1115 test loss: 366.306
40000: ********* epoch 5 ********* test accuracy for mode 2:0.0935 test loss: 280.681
40000: ********* epoch 5 ********* test accuracy for mode 24:0.255 test loss: 273.499
40000: ********* epoch 5 ********* test accuracy for mode 25:0.275 test loss: 258.404
40000: ********* epoch 5 ********* test accuracy for mode 26:0.245 test loss: 193.592
40000: ********* epoch 5 ********* test accuracy for mode 27:0.203 test loss: 280.482
40000: ********* epoch 5 ********* test accuracy for mode 28:0.23 test loss: 266.809
40000: ********* epoch 5 ********* test accuracy for mode 29:0.266 test loss: 270.08
40000: ********* epoch 5 ********* test accuracy for mode 30:0.219 test loss: 262.047
40000: ********* epoch 5 ********* test accuracy for mode 31:0.173 test loss: 264.012
40000: ********* epoch 5 ********* test accuracy for mode 32:0.3005 test loss: 250.464
40000: ********* epoch 5 ********* test accuracy for mode 33:0.128 test loss: 265.739
40000: ********* epoch 5 ********* test accuracy for mode 34:0.192 test loss: 261.152
40000: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 390.624
40000: ********* epoch 5 ********* test accuracy for mode 36:0.0255 test loss: 393.215
40010: accuracy:0.27 loss: 243.768 (lr:0.00010000001004928053)
40020: accuracy:0.3 loss: 246.752 (lr:0.00010000000999915953)
40030: accuracy:0.28 loss: 237.707 (lr:0.00010000000994928851)
40040: accuracy:0.3 loss: 237.561 (lr:0.00010000000989966623)
40050: accuracy:0.21 loss: 251.855 (lr:0.00010000000985029145)
40060: accuracy:0.23 loss: 229.795 (lr:0.00010000000980116291)
40070: accuracy:0.21 loss: 247.005 (lr:0.0001000000097522794)
40080: accuracy:0.28 loss: 238.813 (lr:0.00010000000970363971)
40090: accuracy:0.31 loss: 242.075 (lr:0.00010000000965524261)
40100: accuracy:0.22 loss: 241.153 (lr:0.00010000000960708687)
40110: accuracy:0.22 loss: 238.399 (lr:0.00010000000955917133)
40120: accuracy:0.25 loss: 239.086 (lr:0.00010000000951149476)
40130: accuracy:0.14 loss: 246.671 (lr:0.00010000000946405598)
40140: accuracy:0.26 loss: 245.522 (lr:0.00010000000941685382)
40150: accuracy:0.23 loss: 251.764 (lr:0.00010000000936988706)
40160: accuracy:0.29 loss: 243.711 (lr:0.00010000000932315456)
40170: accuracy:0.27 loss: 239.556 (lr:0.00010000000927665512)
40180: accuracy:0.25 loss: 230.98 (lr:0.00010000000923038762)
40190: accuracy:0.26 loss: 231.466 (lr:0.00010000000918435086)
40200: accuracy:0.32 loss: 242.471 (lr:0.00010000000913854373)
40210: accuracy:0.27 loss: 235.723 (lr:0.00010000000909296505)
40220: accuracy:0.27 loss: 235.911 (lr:0.0001000000090476137)
40230: accuracy:0.25 loss: 250.61 (lr:0.00010000000900248854)
40240: accuracy:0.32 loss: 231.423 (lr:0.00010000000895758843)
40250: accuracy:0.25 loss: 243.247 (lr:0.00010000000891291227)
40260: accuracy:0.22 loss: 243.745 (lr:0.00010000000886845894)
40270: accuracy:0.31 loss: 252.823 (lr:0.00010000000882422731)
40280: accuracy:0.3 loss: 240.15 (lr:0.00010000000878021629)
40290: accuracy:0.35 loss: 227.971 (lr:0.00010000000873642478)
40300: accuracy:0.25 loss: 252.958 (lr:0.00010000000869285169)
40310: accuracy:0.28 loss: 229.543 (lr:0.0001000000086494959)
40320: accuracy:0.23 loss: 236.196 (lr:0.00010000000860635637)
40330: accuracy:0.22 loss: 238.128 (lr:0.00010000000856343199)
40340: accuracy:0.27 loss: 235.384 (lr:0.00010000000852072169)
40350: accuracy:0.26 loss: 234.017 (lr:0.00010000000847822441)
40360: accuracy:0.25 loss: 243.332 (lr:0.00010000000843593909)
40370: accuracy:0.26 loss: 238.748 (lr:0.00010000000839386467)
40380: accuracy:0.34 loss: 244.059 (lr:0.0001000000083520001)
40390: accuracy:0.36 loss: 216.389 (lr:0.00010000000831034432)
40400: accuracy:0.26 loss: 234.374 (lr:0.0001000000082688963)
40410: accuracy:0.21 loss: 243.64 (lr:0.00010000000822765501)
40420: accuracy:0.32 loss: 232.184 (lr:0.00010000000818661941)
40430: accuracy:0.32 loss: 238.66 (lr:0.00010000000814578848)
40440: accuracy:0.21 loss: 246.331 (lr:0.00010000000810516119)
40450: accuracy:0.25 loss: 250.581 (lr:0.00010000000806473653)
40460: accuracy:0.33 loss: 222.186 (lr:0.00010000000802451349)
40470: accuracy:0.25 loss: 237.72 (lr:0.00010000000798449106)
40480: accuracy:0.26 loss: 247.888 (lr:0.00010000000794466824)
40490: accuracy:0.3 loss: 227.908 (lr:0.00010000000790504404)
40500: accuracy:0.34 loss: 240.168 (lr:0.00010000000786561748)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
40500: ********* epoch 5 ********* test accuracy for all:0.219054 test loss: 264.414
40500: ********* epoch 5 ********* test accuracy for mode 0:0.0015 test loss: 408.398
40500: ********* epoch 5 ********* test accuracy for mode 1:0.0995 test loss: 374.688
40500: ********* epoch 5 ********* test accuracy for mode 2:0.046 test loss: 284.904
40500: ********* epoch 5 ********* test accuracy for mode 24:0.2235 test loss: 278.766
40500: ********* epoch 5 ********* test accuracy for mode 25:0.392 test loss: 251.534
40500: ********* epoch 5 ********* test accuracy for mode 26:0.108 test loss: 194.574
40500: ********* epoch 5 ********* test accuracy for mode 27:0.2575 test loss: 272.285
40500: ********* epoch 5 ********* test accuracy for mode 28:0.302 test loss: 258.898
40500: ********* epoch 5 ********* test accuracy for mode 29:0.258 test loss: 268.591
40500: ********* epoch 5 ********* test accuracy for mode 30:0.211 test loss: 266.854
40500: ********* epoch 5 ********* test accuracy for mode 31:0.1885 test loss: 267.192
40500: ********* epoch 5 ********* test accuracy for mode 32:0.245 test loss: 253.827
40500: ********* epoch 5 ********* test accuracy for mode 33:0.1375 test loss: 265.087
40500: ********* epoch 5 ********* test accuracy for mode 34:0.2445 test loss: 257.0
40500: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 409.446
40500: ********* epoch 5 ********* test accuracy for mode 36:0.0165 test loss: 421.221
40510: accuracy:0.3 loss: 233.149 (lr:0.00010000000782638755)
40520: accuracy:0.26 loss: 237.983 (lr:0.00010000000778735327)
40530: accuracy:0.33 loss: 221.624 (lr:0.00010000000774851368)
40540: accuracy:0.39 loss: 233.9 (lr:0.00010000000770986781)
40550: accuracy:0.3 loss: 240.44 (lr:0.00010000000767141468)
40560: accuracy:0.19 loss: 252.158 (lr:0.00010000000763315335)
40570: accuracy:0.29 loss: 251.051 (lr:0.00010000000759508284)
40580: accuracy:0.36 loss: 233.471 (lr:0.0001000000075572022)
40590: accuracy:0.2 loss: 256.478 (lr:0.0001000000075195105)
40600: accuracy:0.36 loss: 227.971 (lr:0.00010000000748200679)
40610: accuracy:0.3 loss: 234.619 (lr:0.00010000000744469012)
40620: accuracy:0.3 loss: 232.794 (lr:0.00010000000740755957)
40630: accuracy:0.3 loss: 242.253 (lr:0.00010000000737061421)
40640: accuracy:0.3 loss: 232.808 (lr:0.00010000000733385312)
40650: accuracy:0.23 loss: 248.836 (lr:0.00010000000729727538)
40660: accuracy:0.34 loss: 240.84 (lr:0.00010000000726088007)
40670: accuracy:0.28 loss: 232.482 (lr:0.00010000000722466628)
40680: accuracy:0.27 loss: 241.792 (lr:0.0001000000071886331)
40690: accuracy:0.31 loss: 226.699 (lr:0.00010000000715277965)
40700: accuracy:0.23 loss: 255.129 (lr:0.000100000007117105)
40710: accuracy:0.27 loss: 239.3 (lr:0.0001000000070816083)
40720: accuracy:0.21 loss: 246.146 (lr:0.00010000000704628863)
40730: accuracy:0.32 loss: 228.852 (lr:0.00010000000701114511)
40740: accuracy:0.25 loss: 235.723 (lr:0.00010000000697617688)
40750: accuracy:0.17 loss: 250.937 (lr:0.00010000000694138306)
40760: accuracy:0.38 loss: 222.62 (lr:0.00010000000690676276)
40770: accuracy:0.22 loss: 243.556 (lr:0.00010000000687231514)
40780: accuracy:0.22 loss: 224.227 (lr:0.00010000000683803934)
40790: accuracy:0.26 loss: 243.833 (lr:0.00010000000680393447)
40800: accuracy:0.25 loss: 248.108 (lr:0.0001000000067699997)
40810: accuracy:0.3 loss: 223.901 (lr:0.00010000000673623419)
40820: accuracy:0.29 loss: 239.099 (lr:0.00010000000670263708)
40830: accuracy:0.28 loss: 246.091 (lr:0.00010000000666920754)
40840: accuracy:0.31 loss: 244.8 (lr:0.00010000000663594473)
40850: accuracy:0.25 loss: 234.255 (lr:0.00010000000660284782)
40860: accuracy:0.33 loss: 238.541 (lr:0.00010000000656991598)
40870: accuracy:0.3 loss: 229.667 (lr:0.00010000000653714838)
40880: accuracy:0.25 loss: 232.679 (lr:0.00010000000650454422)
40890: accuracy:0.18 loss: 247.817 (lr:0.00010000000647210267)
40900: accuracy:0.28 loss: 241.721 (lr:0.00010000000643982292)
40910: accuracy:0.24 loss: 245.308 (lr:0.00010000000640770417)
40920: accuracy:0.26 loss: 233.447 (lr:0.00010000000637574561)
40930: accuracy:0.31 loss: 230.616 (lr:0.00010000000634394645)
40940: accuracy:0.3 loss: 236.823 (lr:0.00010000000631230588)
40950: accuracy:0.27 loss: 240.414 (lr:0.00010000000628082313)
40960: accuracy:0.24 loss: 259.272 (lr:0.00010000000624949738)
40970: accuracy:0.28 loss: 228.146 (lr:0.00010000000621832789)
40980: accuracy:0.25 loss: 236.264 (lr:0.00010000000618731385)
40990: accuracy:0.21 loss: 233.198 (lr:0.0001000000061564545)
41000: accuracy:0.25 loss: 241.799 (lr:0.00010000000612574906)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
41000: ********* epoch 5 ********* test accuracy for all:0.217676 test loss: 264.388
41000: ********* epoch 5 ********* test accuracy for mode 0:0.0005 test loss: 410.001
41000: ********* epoch 5 ********* test accuracy for mode 1:0.0845 test loss: 379.221
41000: ********* epoch 5 ********* test accuracy for mode 2:0.069 test loss: 284.681
41000: ********* epoch 5 ********* test accuracy for mode 24:0.2445 test loss: 267.951
41000: ********* epoch 5 ********* test accuracy for mode 25:0.346 test loss: 248.548
41000: ********* epoch 5 ********* test accuracy for mode 26:0.0965 test loss: 197.413
41000: ********* epoch 5 ********* test accuracy for mode 27:0.245 test loss: 269.727
41000: ********* epoch 5 ********* test accuracy for mode 28:0.2925 test loss: 252.969
41000: ********* epoch 5 ********* test accuracy for mode 29:0.278 test loss: 257.567
41000: ********* epoch 5 ********* test accuracy for mode 30:0.238 test loss: 257.977
41000: ********* epoch 5 ********* test accuracy for mode 31:0.184 test loss: 265.653
41000: ********* epoch 5 ********* test accuracy for mode 32:0.198 test loss: 254.581
41000: ********* epoch 5 ********* test accuracy for mode 33:0.163 test loss: 266.394
41000: ********* epoch 5 ********* test accuracy for mode 34:0.1835 test loss: 261.497
41000: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 428.782
41000: ********* epoch 5 ********* test accuracy for mode 36:0.046 test loss: 433.683
41010: accuracy:0.19 loss: 244.428 (lr:0.00010000000609519675)
41020: accuracy:0.31 loss: 225.034 (lr:0.00010000000606479682)
41030: accuracy:0.22 loss: 230.784 (lr:0.00010000000603454853)
41040: accuracy:0.26 loss: 247.659 (lr:0.00010000000600445109)
41050: accuracy:0.26 loss: 240.426 (lr:0.00010000000597450376)
41060: accuracy:0.31 loss: 220.184 (lr:0.0001000000059447058)
41070: accuracy:0.35 loss: 235.088 (lr:0.00010000000591505647)
41080: accuracy:0.33 loss: 208.792 (lr:0.000100000005885555)
41090: accuracy:0.25 loss: 230.659 (lr:0.00010000000585620066)
41100: accuracy:0.24 loss: 238.815 (lr:0.00010000000582699274)
41110: accuracy:0.26 loss: 242.541 (lr:0.0001000000057979305)
41120: accuracy:0.3 loss: 234.213 (lr:0.0001000000057690132)
41130: accuracy:0.29 loss: 240.228 (lr:0.00010000000574024013)
41140: accuracy:0.27 loss: 241.333 (lr:0.00010000000571161055)
41150: accuracy:0.26 loss: 243.786 (lr:0.00010000000568312378)
41160: accuracy:0.32 loss: 242.189 (lr:0.00010000000565477909)
41170: accuracy:0.31 loss: 267.703 (lr:0.00010000000562657575)
41180: accuracy:0.36 loss: 225.322 (lr:0.00010000000559851309)
41190: accuracy:0.27 loss: 241.203 (lr:0.0001000000055705904)
41200: accuracy:0.31 loss: 225.532 (lr:0.00010000000554280695)
41210: accuracy:0.29 loss: 236.312 (lr:0.00010000000551516209)
41220: accuracy:0.31 loss: 210.762 (lr:0.00010000000548765511)
41230: accuracy:0.38 loss: 229.406 (lr:0.0001000000054602853)
41240: accuracy:0.21 loss: 254.333 (lr:0.00010000000543305202)
41250: accuracy:0.25 loss: 249.412 (lr:0.00010000000540595457)
41260: accuracy:0.3 loss: 247.353 (lr:0.00010000000537899225)
41270: accuracy:0.21 loss: 248.185 (lr:0.00010000000535216442)
41280: accuracy:0.25 loss: 237.7 (lr:0.00010000000532547039)
41290: accuracy:0.27 loss: 259.249 (lr:0.0001000000052989095)
41300: accuracy:0.2 loss: 232.432 (lr:0.00010000000527248106)
41310: accuracy:0.27 loss: 241.226 (lr:0.00010000000524618446)
41320: accuracy:0.26 loss: 221.15 (lr:0.000100000005220019)
41330: accuracy:0.26 loss: 237.739 (lr:0.00010000000519398406)
41340: accuracy:0.26 loss: 236.279 (lr:0.00010000000516807896)
41350: accuracy:0.28 loss: 238.553 (lr:0.00010000000514230305)
41360: accuracy:0.25 loss: 254.241 (lr:0.00010000000511665571)
41370: accuracy:0.32 loss: 227.277 (lr:0.00010000000509113628)
41380: accuracy:0.24 loss: 245.81 (lr:0.00010000000506574413)
41390: accuracy:0.17 loss: 244.5 (lr:0.00010000000504047863)
41400: accuracy:0.33 loss: 229.93 (lr:0.00010000000501533913)
41410: accuracy:0.4 loss: 224.945 (lr:0.00010000000499032503)
41420: accuracy:0.3 loss: 250.473 (lr:0.00010000000496543567)
41430: accuracy:0.29 loss: 240.561 (lr:0.00010000000494067046)
41440: accuracy:0.24 loss: 226.523 (lr:0.00010000000491602877)
41450: accuracy:0.33 loss: 230.274 (lr:0.00010000000489150997)
41460: accuracy:0.28 loss: 230.456 (lr:0.00010000000486711346)
41470: accuracy:0.33 loss: 250.86 (lr:0.00010000000484283863)
41480: accuracy:0.27 loss: 236.952 (lr:0.00010000000481868487)
41490: accuracy:0.26 loss: 256.432 (lr:0.00010000000479465158)
41500: accuracy:0.26 loss: 224.939 (lr:0.00010000000477073816)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
41500: ********* epoch 5 ********* test accuracy for all:0.213905 test loss: 264.371
41500: ********* epoch 5 ********* test accuracy for mode 0:0.0015 test loss: 406.299
41500: ********* epoch 5 ********* test accuracy for mode 1:0.0895 test loss: 378.698
41500: ********* epoch 5 ********* test accuracy for mode 2:0.09 test loss: 282.174
41500: ********* epoch 5 ********* test accuracy for mode 24:0.2475 test loss: 276.559
41500: ********* epoch 5 ********* test accuracy for mode 25:0.3105 test loss: 257.583
41500: ********* epoch 5 ********* test accuracy for mode 26:0.095 test loss: 198.55
41500: ********* epoch 5 ********* test accuracy for mode 27:0.2965 test loss: 277.852
41500: ********* epoch 5 ********* test accuracy for mode 28:0.178 test loss: 276.111
41500: ********* epoch 5 ********* test accuracy for mode 29:0.268 test loss: 278.095
41500: ********* epoch 5 ********* test accuracy for mode 30:0.1735 test loss: 274.84
41500: ********* epoch 5 ********* test accuracy for mode 31:0.248 test loss: 274.217
41500: ********* epoch 5 ********* test accuracy for mode 32:0.082 test loss: 268.14
41500: ********* epoch 5 ********* test accuracy for mode 33:0.251 test loss: 266.393
41500: ********* epoch 5 ********* test accuracy for mode 34:0.168 test loss: 262.588
41500: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 404.119
41500: ********* epoch 5 ********* test accuracy for mode 36:0.02 test loss: 409.047
41510: accuracy:0.32 loss: 237.434 (lr:0.000100000004746944)
41520: accuracy:0.32 loss: 237.348 (lr:0.00010000000472326852)
41530: accuracy:0.22 loss: 238.975 (lr:0.00010000000469971112)
41540: accuracy:0.33 loss: 237.797 (lr:0.00010000000467627122)
41550: accuracy:0.3 loss: 228.8 (lr:0.00010000000465294821)
41560: accuracy:0.28 loss: 231.874 (lr:0.00010000000462974154)
41570: accuracy:0.25 loss: 237.0 (lr:0.00010000000460665061)
41580: accuracy:0.42 loss: 208.18 (lr:0.00010000000458367483)
41590: accuracy:0.24 loss: 233.556 (lr:0.00010000000456081366)
41600: accuracy:0.26 loss: 242.617 (lr:0.00010000000453806651)
41610: accuracy:0.19 loss: 259.208 (lr:0.0001000000045154328)
41620: accuracy:0.17 loss: 251.756 (lr:0.000100000004492912)
41630: accuracy:0.25 loss: 237.296 (lr:0.00010000000447050351)
41640: accuracy:0.26 loss: 245.727 (lr:0.00010000000444820678)
41650: accuracy:0.3 loss: 224.291 (lr:0.00010000000442602125)
41660: accuracy:0.26 loss: 240.435 (lr:0.00010000000440394638)
41670: accuracy:0.26 loss: 245.848 (lr:0.0001000000043819816)
41680: accuracy:0.22 loss: 236.733 (lr:0.00010000000436012637)
41690: accuracy:0.29 loss: 233.336 (lr:0.00010000000433838016)
41700: accuracy:0.25 loss: 238.121 (lr:0.0001000000043167424)
41710: accuracy:0.23 loss: 257.54 (lr:0.00010000000429521256)
41720: accuracy:0.38 loss: 222.645 (lr:0.0001000000042737901)
41730: accuracy:0.26 loss: 233.232 (lr:0.00010000000425247448)
41740: accuracy:0.35 loss: 225.302 (lr:0.00010000000423126518)
41750: accuracy:0.26 loss: 248.21 (lr:0.00010000000421016164)
41760: accuracy:0.34 loss: 226.043 (lr:0.00010000000418916338)
41770: accuracy:0.25 loss: 240.046 (lr:0.00010000000416826985)
41780: accuracy:0.2 loss: 247.479 (lr:0.00010000000414748051)
41790: accuracy:0.32 loss: 234.16 (lr:0.00010000000412679486)
41800: accuracy:0.33 loss: 236.764 (lr:0.00010000000410621239)
41810: accuracy:0.29 loss: 230.026 (lr:0.00010000000408573257)
41820: accuracy:0.32 loss: 236.825 (lr:0.0001000000040653549)
41830: accuracy:0.27 loss: 234.634 (lr:0.00010000000404507885)
41840: accuracy:0.35 loss: 226.486 (lr:0.00010000000402490394)
41850: accuracy:0.31 loss: 228.316 (lr:0.00010000000400482964)
41860: accuracy:0.28 loss: 222.397 (lr:0.00010000000398485547)
41870: accuracy:0.16 loss: 250.324 (lr:0.00010000000396498092)
41880: accuracy:0.26 loss: 245.668 (lr:0.0001000000039452055)
41890: accuracy:0.21 loss: 258.673 (lr:0.0001000000039255287)
41900: accuracy:0.29 loss: 238.126 (lr:0.00010000000390595004)
41910: accuracy:0.28 loss: 241.499 (lr:0.00010000000388646903)
41920: accuracy:0.18 loss: 254.968 (lr:0.00010000000386708519)
41930: accuracy:0.27 loss: 230.863 (lr:0.00010000000384779802)
41940: accuracy:0.27 loss: 239.397 (lr:0.00010000000382860706)
41950: accuracy:0.31 loss: 243.307 (lr:0.00010000000380951179)
41960: accuracy:0.21 loss: 238.845 (lr:0.00010000000379051177)
41970: accuracy:0.27 loss: 232.203 (lr:0.00010000000377160653)
41980: accuracy:0.3 loss: 229.566 (lr:0.00010000000375279555)
41990: accuracy:0.23 loss: 240.891 (lr:0.00010000000373407841)
42000: accuracy:0.25 loss: 216.838 (lr:0.00010000000371545461)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
42000: ********* epoch 5 ********* test accuracy for all:0.219824 test loss: 263.538
42000: ********* epoch 5 ********* test accuracy for mode 0:0.0015 test loss: 397.145
42000: ********* epoch 5 ********* test accuracy for mode 1:0.114 test loss: 364.786
42000: ********* epoch 5 ********* test accuracy for mode 2:0.046 test loss: 290.795
42000: ********* epoch 5 ********* test accuracy for mode 24:0.232 test loss: 271.574
42000: ********* epoch 5 ********* test accuracy for mode 25:0.301 test loss: 251.01
42000: ********* epoch 5 ********* test accuracy for mode 26:0.3105 test loss: 184.413
42000: ********* epoch 5 ********* test accuracy for mode 27:0.249 test loss: 269.745
42000: ********* epoch 5 ********* test accuracy for mode 28:0.2715 test loss: 257.656
42000: ********* epoch 5 ********* test accuracy for mode 29:0.313 test loss: 261.946
42000: ********* epoch 5 ********* test accuracy for mode 30:0.1345 test loss: 265.176
42000: ********* epoch 5 ********* test accuracy for mode 31:0.242 test loss: 266.988
42000: ********* epoch 5 ********* test accuracy for mode 32:0.1495 test loss: 262.476
42000: ********* epoch 5 ********* test accuracy for mode 33:0.169 test loss: 271.19
42000: ********* epoch 5 ********* test accuracy for mode 34:0.2025 test loss: 265.863
42000: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 389.645
42000: ********* epoch 5 ********* test accuracy for mode 36:0.03 test loss: 403.928
42010: accuracy:0.26 loss: 220.982 (lr:0.00010000000369692371)
42020: accuracy:0.24 loss: 242.105 (lr:0.00010000000367848523)
42030: accuracy:0.28 loss: 244.603 (lr:0.0001000000036601387)
42040: accuracy:0.26 loss: 245.892 (lr:0.00010000000364188369)
42050: accuracy:0.25 loss: 239.309 (lr:0.00010000000362371971)
42060: accuracy:0.31 loss: 254.508 (lr:0.00010000000360564633)
42070: accuracy:0.28 loss: 224.211 (lr:0.0001000000035876631)
42080: accuracy:0.33 loss: 235.852 (lr:0.00010000000356976955)
42090: accuracy:0.31 loss: 235.551 (lr:0.00010000000355196526)
42100: accuracy:0.26 loss: 239.548 (lr:0.00010000000353424976)
42110: accuracy:0.23 loss: 239.606 (lr:0.00010000000351662261)
42120: accuracy:0.28 loss: 243.597 (lr:0.00010000000349908338)
42130: accuracy:0.2 loss: 243.366 (lr:0.00010000000348163163)
42140: accuracy:0.23 loss: 247.455 (lr:0.00010000000346426692)
42150: accuracy:0.28 loss: 241.132 (lr:0.00010000000344698882)
42160: accuracy:0.25 loss: 240.069 (lr:0.00010000000342979688)
42170: accuracy:0.22 loss: 251.946 (lr:0.00010000000341269071)
42180: accuracy:0.22 loss: 247.654 (lr:0.00010000000339566984)
42190: accuracy:0.22 loss: 251.776 (lr:0.00010000000337873386)
42200: accuracy:0.23 loss: 260.359 (lr:0.00010000000336188236)
42210: accuracy:0.31 loss: 219.118 (lr:0.00010000000334511491)
42220: accuracy:0.24 loss: 252.196 (lr:0.00010000000332843107)
42230: accuracy:0.25 loss: 235.812 (lr:0.00010000000331183046)
42240: accuracy:0.24 loss: 240.169 (lr:0.00010000000329531264)
42250: accuracy:0.26 loss: 230.043 (lr:0.00010000000327887719)
42260: accuracy:0.33 loss: 241.764 (lr:0.00010000000326252372)
42270: accuracy:0.25 loss: 235.435 (lr:0.00010000000324625181)
42280: accuracy:0.29 loss: 244.819 (lr:0.00010000000323006107)
42290: accuracy:0.23 loss: 241.627 (lr:0.00010000000321395107)
42300: accuracy:0.23 loss: 241.154 (lr:0.00010000000319792142)
42310: accuracy:0.29 loss: 235.04 (lr:0.00010000000318197173)
42320: accuracy:0.29 loss: 243.229 (lr:0.00010000000316610157)
42330: accuracy:0.23 loss: 253.444 (lr:0.00010000000315031057)
42340: accuracy:0.27 loss: 243.676 (lr:0.00010000000313459834)
42350: accuracy:0.33 loss: 233.248 (lr:0.00010000000311896446)
42360: accuracy:0.23 loss: 242.094 (lr:0.00010000000310340857)
42370: accuracy:0.14 loss: 261.465 (lr:0.00010000000308793025)
42380: accuracy:0.27 loss: 242.798 (lr:0.00010000000307252913)
42390: accuracy:0.29 loss: 227.962 (lr:0.00010000000305720483)
42400: accuracy:0.31 loss: 238.381 (lr:0.00010000000304195695)
42410: accuracy:0.2 loss: 246.672 (lr:0.00010000000302678513)
42420: accuracy:0.28 loss: 243.984 (lr:0.00010000000301168898)
42430: accuracy:0.28 loss: 254.373 (lr:0.00010000000299666812)
42440: accuracy:0.27 loss: 231.916 (lr:0.00010000000298172217)
42450: accuracy:0.22 loss: 253.674 (lr:0.00010000000296685077)
42460: accuracy:0.29 loss: 237.918 (lr:0.00010000000295205354)
42470: accuracy:0.28 loss: 231.866 (lr:0.00010000000293733011)
42480: accuracy:0.26 loss: 254.814 (lr:0.00010000000292268011)
42490: accuracy:0.37 loss: 208.631 (lr:0.00010000000290810319)
42500: accuracy:0.25 loss: 240.503 (lr:0.00010000000289359897)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
42500: ********* epoch 5 ********* test accuracy for all:0.220108 test loss: 262.217
42500: ********* epoch 5 ********* test accuracy for mode 0:0.0015 test loss: 393.179
42500: ********* epoch 5 ********* test accuracy for mode 1:0.12 test loss: 361.339
42500: ********* epoch 5 ********* test accuracy for mode 2:0.0665 test loss: 285.352
42500: ********* epoch 5 ********* test accuracy for mode 24:0.234 test loss: 266.447
42500: ********* epoch 5 ********* test accuracy for mode 25:0.339 test loss: 247.901
42500: ********* epoch 5 ********* test accuracy for mode 26:0.1445 test loss: 195.751
42500: ********* epoch 5 ********* test accuracy for mode 27:0.215 test loss: 272.908
42500: ********* epoch 5 ********* test accuracy for mode 28:0.306 test loss: 255.647
42500: ********* epoch 5 ********* test accuracy for mode 29:0.275 test loss: 264.159
42500: ********* epoch 5 ********* test accuracy for mode 30:0.2015 test loss: 265.288
42500: ********* epoch 5 ********* test accuracy for mode 31:0.1735 test loss: 271.271
42500: ********* epoch 5 ********* test accuracy for mode 32:0.2425 test loss: 259.009
42500: ********* epoch 5 ********* test accuracy for mode 33:0.143 test loss: 270.433
42500: ********* epoch 5 ********* test accuracy for mode 34:0.2275 test loss: 262.685
42500: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 399.415
42500: ********* epoch 5 ********* test accuracy for mode 36:0.037 test loss: 395.703
42510: accuracy:0.25 loss: 221.46 (lr:0.00010000000287916708)
42520: accuracy:0.23 loss: 251.675 (lr:0.00010000000286480718)
42530: accuracy:0.17 loss: 249.888 (lr:0.00010000000285051888)
42540: accuracy:0.24 loss: 247.221 (lr:0.00010000000283630186)
42550: accuracy:0.19 loss: 262.351 (lr:0.00010000000282215575)
42560: accuracy:0.22 loss: 232.114 (lr:0.00010000000280808019)
42570: accuracy:0.3 loss: 205.341 (lr:0.00010000000279407483)
42580: accuracy:0.27 loss: 238.841 (lr:0.00010000000278013932)
42590: accuracy:0.21 loss: 247.39 (lr:0.00010000000276627333)
42600: accuracy:0.2 loss: 230.899 (lr:0.00010000000275247647)
42610: accuracy:0.25 loss: 252.995 (lr:0.00010000000273874844)
42620: accuracy:0.24 loss: 250.282 (lr:0.00010000000272508888)
42630: accuracy:0.22 loss: 254.12 (lr:0.00010000000271149744)
42640: accuracy:0.24 loss: 228.744 (lr:0.0001000000026979738)
42650: accuracy:0.23 loss: 236.356 (lr:0.0001000000026845176)
42660: accuracy:0.28 loss: 235.596 (lr:0.0001000000026711285)
42670: accuracy:0.28 loss: 247.114 (lr:0.00010000000265780619)
42680: accuracy:0.29 loss: 247.114 (lr:0.00010000000264455033)
42690: accuracy:0.27 loss: 244.776 (lr:0.00010000000263136059)
42700: accuracy:0.27 loss: 253.251 (lr:0.00010000000261823662)
42710: accuracy:0.23 loss: 241.843 (lr:0.00010000000260517811)
42720: accuracy:0.25 loss: 241.403 (lr:0.00010000000259218473)
42730: accuracy:0.27 loss: 240.361 (lr:0.00010000000257925615)
42740: accuracy:0.34 loss: 221.99 (lr:0.00010000000256639206)
42750: accuracy:0.28 loss: 236.946 (lr:0.00010000000255359212)
42760: accuracy:0.22 loss: 240.906 (lr:0.00010000000254085603)
42770: accuracy:0.31 loss: 223.985 (lr:0.00010000000252818346)
42780: accuracy:0.25 loss: 244.896 (lr:0.00010000000251557408)
42790: accuracy:0.28 loss: 229.886 (lr:0.00010000000250302762)
42800: accuracy:0.31 loss: 231.934 (lr:0.0001000000024905437)
42810: accuracy:0.25 loss: 255.008 (lr:0.00010000000247812207)
42820: accuracy:0.19 loss: 243.979 (lr:0.00010000000246576238)
42830: accuracy:0.26 loss: 253.001 (lr:0.00010000000245346434)
42840: accuracy:0.29 loss: 230.343 (lr:0.00010000000244122764)
42850: accuracy:0.32 loss: 225.835 (lr:0.00010000000242905197)
42860: accuracy:0.32 loss: 236.31 (lr:0.00010000000241693702)
42870: accuracy:0.25 loss: 239.961 (lr:0.00010000000240488249)
42880: accuracy:0.19 loss: 255.055 (lr:0.0001000000023928881)
42890: accuracy:0.29 loss: 237.834 (lr:0.00010000000238095351)
42900: accuracy:0.31 loss: 235.385 (lr:0.00010000000236907846)
42910: accuracy:0.23 loss: 236.475 (lr:0.00010000000235726264)
42920: accuracy:0.33 loss: 238.365 (lr:0.00010000000234550574)
42930: accuracy:0.26 loss: 254.357 (lr:0.00010000000233380748)
42940: accuracy:0.22 loss: 247.441 (lr:0.00010000000232216757)
42950: accuracy:0.29 loss: 230.225 (lr:0.0001000000023105857)
42960: accuracy:0.25 loss: 227.928 (lr:0.00010000000229906161)
42970: accuracy:0.23 loss: 231.754 (lr:0.00010000000228759499)
42980: accuracy:0.28 loss: 244.16 (lr:0.00010000000227618557)
42990: accuracy:0.25 loss: 236.258 (lr:0.00010000000226483305)
43000: accuracy:0.31 loss: 235.194 (lr:0.00010000000225353714)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
43000: ********* epoch 5 ********* test accuracy for all:0.219689 test loss: 264.399
43000: ********* epoch 5 ********* test accuracy for mode 0:0.0005 test loss: 410.634
43000: ********* epoch 5 ********* test accuracy for mode 1:0.091 test loss: 374.339
43000: ********* epoch 5 ********* test accuracy for mode 2:0.056 test loss: 283.821
43000: ********* epoch 5 ********* test accuracy for mode 24:0.2185 test loss: 273.637
43000: ********* epoch 5 ********* test accuracy for mode 25:0.3095 test loss: 255.425
43000: ********* epoch 5 ********* test accuracy for mode 26:0.2005 test loss: 194.685
43000: ********* epoch 5 ********* test accuracy for mode 27:0.2205 test loss: 277.893
43000: ********* epoch 5 ********* test accuracy for mode 28:0.301 test loss: 262.661
43000: ********* epoch 5 ********* test accuracy for mode 29:0.2715 test loss: 272.869
43000: ********* epoch 5 ********* test accuracy for mode 30:0.11 test loss: 274.584
43000: ********* epoch 5 ********* test accuracy for mode 31:0.243 test loss: 270.195
43000: ********* epoch 5 ********* test accuracy for mode 32:0.16 test loss: 263.647
43000: ********* epoch 5 ********* test accuracy for mode 33:0.2275 test loss: 268.56
43000: ********* epoch 5 ********* test accuracy for mode 34:0.144 test loss: 263.111
43000: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 399.097
43000: ********* epoch 5 ********* test accuracy for mode 36:0.028 test loss: 408.778
43010: accuracy:0.19 loss: 244.138 (lr:0.00010000000224229758)
43020: accuracy:0.22 loss: 244.657 (lr:0.00010000000223111407)
43030: accuracy:0.32 loss: 236.548 (lr:0.00010000000221998634)
43040: accuracy:0.28 loss: 218.092 (lr:0.00010000000220891411)
43050: accuracy:0.19 loss: 245.322 (lr:0.00010000000219789712)
43060: accuracy:0.25 loss: 256.166 (lr:0.00010000000218693506)
43070: accuracy:0.26 loss: 251.607 (lr:0.00010000000217602767)
43080: accuracy:0.26 loss: 233.934 (lr:0.00010000000216517469)
43090: accuracy:0.33 loss: 244.277 (lr:0.00010000000215437583)
43100: accuracy:0.26 loss: 232.46 (lr:0.00010000000214363083)
43110: accuracy:0.3 loss: 222.275 (lr:0.00010000000213293943)
43120: accuracy:0.29 loss: 238.691 (lr:0.00010000000212230135)
43130: accuracy:0.3 loss: 231.927 (lr:0.00010000000211171634)
43140: accuracy:0.37 loss: 223.409 (lr:0.0001000000021011841)
43150: accuracy:0.24 loss: 249.614 (lr:0.0001000000020907044)
43160: accuracy:0.24 loss: 242.908 (lr:0.00010000000208027697)
43170: accuracy:0.21 loss: 232.747 (lr:0.00010000000206990155)
43180: accuracy:0.26 loss: 241.972 (lr:0.00010000000205957787)
43190: accuracy:0.26 loss: 233.639 (lr:0.00010000000204930568)
43200: accuracy:0.3 loss: 233.714 (lr:0.00010000000203908473)
43210: accuracy:0.3 loss: 258.159 (lr:0.00010000000202891475)
43220: accuracy:0.33 loss: 220.401 (lr:0.0001000000020187955)
43230: accuracy:0.3 loss: 234.983 (lr:0.00010000000200872671)
43240: accuracy:0.31 loss: 236.928 (lr:0.00010000000199870814)
43250: accuracy:0.23 loss: 254.18 (lr:0.00010000000198873954)
43260: accuracy:0.25 loss: 254.859 (lr:0.00010000000197882066)
43270: accuracy:0.18 loss: 265.393 (lr:0.00010000000196895125)
43280: accuracy:0.24 loss: 249.177 (lr:0.00010000000195913108)
43290: accuracy:0.25 loss: 264.283 (lr:0.00010000000194935987)
43300: accuracy:0.29 loss: 232.006 (lr:0.00010000000193963739)
43310: accuracy:0.24 loss: 244.015 (lr:0.00010000000192996341)
43320: accuracy:0.36 loss: 232.039 (lr:0.00010000000192033767)
43330: accuracy:0.23 loss: 248.612 (lr:0.00010000000191075995)
43340: accuracy:0.24 loss: 261.583 (lr:0.00010000000190123)
43350: accuracy:0.27 loss: 242.938 (lr:0.00010000000189174757)
43360: accuracy:0.25 loss: 240.702 (lr:0.00010000000188231244)
43370: accuracy:0.23 loss: 230.996 (lr:0.00010000000187292437)
43380: accuracy:0.24 loss: 243.458 (lr:0.00010000000186358312)
43390: accuracy:0.19 loss: 245.083 (lr:0.00010000000185428847)
43400: accuracy:0.22 loss: 231.474 (lr:0.00010000000184504016)
43410: accuracy:0.28 loss: 233.333 (lr:0.00010000000183583799)
43420: accuracy:0.3 loss: 245.234 (lr:0.0001000000018266817)
43430: accuracy:0.33 loss: 237.514 (lr:0.0001000000018175711)
43440: accuracy:0.26 loss: 234.196 (lr:0.00010000000180850592)
43450: accuracy:0.28 loss: 249.919 (lr:0.00010000000179948595)
43460: accuracy:0.29 loss: 235.641 (lr:0.00010000000179051098)
43470: accuracy:0.3 loss: 227.353 (lr:0.00010000000178158077)
43480: accuracy:0.27 loss: 233.384 (lr:0.0001000000017726951)
43490: accuracy:0.3 loss: 259.234 (lr:0.00010000000176385374)
43500: accuracy:0.25 loss: 239.321 (lr:0.00010000000175505649)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
43500: ********* epoch 5 ********* test accuracy for all:0.219784 test loss: 262.844
43500: ********* epoch 5 ********* test accuracy for mode 0:0.001 test loss: 403.497
43500: ********* epoch 5 ********* test accuracy for mode 1:0.096 test loss: 372.147
43500: ********* epoch 5 ********* test accuracy for mode 2:0.0355 test loss: 290.124
43500: ********* epoch 5 ********* test accuracy for mode 24:0.243 test loss: 267.566
43500: ********* epoch 5 ********* test accuracy for mode 25:0.261 test loss: 251.806
43500: ********* epoch 5 ********* test accuracy for mode 26:0.361 test loss: 185.658
43500: ********* epoch 5 ********* test accuracy for mode 27:0.2425 test loss: 270.103
43500: ********* epoch 5 ********* test accuracy for mode 28:0.2755 test loss: 256.394
43500: ********* epoch 5 ********* test accuracy for mode 29:0.3165 test loss: 260.141
43500: ********* epoch 5 ********* test accuracy for mode 30:0.139 test loss: 266.789
43500: ********* epoch 5 ********* test accuracy for mode 31:0.2155 test loss: 266.811
43500: ********* epoch 5 ********* test accuracy for mode 32:0.2055 test loss: 257.378
43500: ********* epoch 5 ********* test accuracy for mode 33:0.1875 test loss: 268.623
43500: ********* epoch 5 ********* test accuracy for mode 34:0.1635 test loss: 262.977
43500: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 401.091
43500: ********* epoch 5 ********* test accuracy for mode 36:0.0295 test loss: 399.385
43510: accuracy:0.34 loss: 247.142 (lr:0.00010000000174630311)
43520: accuracy:0.32 loss: 227.883 (lr:0.00010000000173759339)
43530: accuracy:0.15 loss: 257.113 (lr:0.0001000000017289271)
43540: accuracy:0.3 loss: 238.937 (lr:0.00010000000172030404)
43550: accuracy:0.38 loss: 226.987 (lr:0.00010000000171172399)
43560: accuracy:0.29 loss: 241.308 (lr:0.00010000000170318674)
43570: accuracy:0.33 loss: 230.223 (lr:0.00010000000169469205)
43580: accuracy:0.25 loss: 253.685 (lr:0.00010000000168623973)
43590: accuracy:0.34 loss: 226.212 (lr:0.00010000000167782959)
43600: accuracy:0.3 loss: 246.095 (lr:0.00010000000166946138)
43610: accuracy:0.27 loss: 244.276 (lr:0.0001000000016611349)
43620: accuracy:0.31 loss: 240.363 (lr:0.00010000000165284995)
43630: accuracy:0.22 loss: 242.295 (lr:0.00010000000164460633)
43640: accuracy:0.23 loss: 253.281 (lr:0.00010000000163640383)
43650: accuracy:0.27 loss: 252.064 (lr:0.00010000000162824222)
43660: accuracy:0.29 loss: 230.92 (lr:0.00010000000162012133)
43670: accuracy:0.31 loss: 242.228 (lr:0.00010000000161204095)
43680: accuracy:0.29 loss: 231.344 (lr:0.00010000000160400086)
43690: accuracy:0.23 loss: 234.603 (lr:0.00010000000159600087)
43700: accuracy:0.31 loss: 226.439 (lr:0.00010000000158804078)
43710: accuracy:0.3 loss: 255.755 (lr:0.0001000000015801204)
43720: accuracy:0.3 loss: 227.998 (lr:0.00010000000157223951)
43730: accuracy:0.24 loss: 240.233 (lr:0.00010000000156439794)
43740: accuracy:0.34 loss: 229.838 (lr:0.00010000000155659547)
43750: accuracy:0.25 loss: 248.819 (lr:0.00010000000154883192)
43760: accuracy:0.26 loss: 238.711 (lr:0.00010000000154110709)
43770: accuracy:0.17 loss: 246.967 (lr:0.00010000000153342079)
43780: accuracy:0.26 loss: 240.012 (lr:0.00010000000152577281)
43790: accuracy:0.25 loss: 249.809 (lr:0.00010000000151816299)
43800: accuracy:0.23 loss: 238.096 (lr:0.00010000000151059112)
43810: accuracy:0.24 loss: 248.198 (lr:0.00010000000150305702)
43820: accuracy:0.2 loss: 234.987 (lr:0.00010000000149556049)
43830: accuracy:0.31 loss: 243.961 (lr:0.00010000000148810135)
43840: accuracy:0.27 loss: 246.901 (lr:0.00010000000148067941)
43850: accuracy:0.31 loss: 223.777 (lr:0.0001000000014732945)
43860: accuracy:0.33 loss: 235.748 (lr:0.0001000000014659464)
43870: accuracy:0.32 loss: 225.012 (lr:0.00010000000145863496)
43880: accuracy:0.28 loss: 230.49 (lr:0.00010000000145135999)
43890: accuracy:0.27 loss: 237.956 (lr:0.0001000000014441213)
43900: accuracy:0.3 loss: 233.741 (lr:0.00010000000143691872)
43910: accuracy:0.3 loss: 233.727 (lr:0.00010000000142975206)
43920: accuracy:0.33 loss: 229.015 (lr:0.00010000000142262114)
43930: accuracy:0.32 loss: 242.679 (lr:0.0001000000014155258)
43940: accuracy:0.23 loss: 242.502 (lr:0.00010000000140846582)
43950: accuracy:0.27 loss: 245.159 (lr:0.00010000000140144107)
43960: accuracy:0.25 loss: 243.841 (lr:0.00010000000139445136)
43970: accuracy:0.2 loss: 258.34 (lr:0.0001000000013874965)
43980: accuracy:0.3 loss: 251.388 (lr:0.00010000000138057634)
43990: accuracy:0.25 loss: 251.948 (lr:0.00010000000137369068)
44000: accuracy:0.24 loss: 232.487 (lr:0.00010000000136683937)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
44000: ********* epoch 5 ********* test accuracy for all:0.219649 test loss: 263.856
44000: ********* epoch 5 ********* test accuracy for mode 0:0.0005 test loss: 415.588
44000: ********* epoch 5 ********* test accuracy for mode 1:0.079 test loss: 381.289
44000: ********* epoch 5 ********* test accuracy for mode 2:0.0735 test loss: 283.639
44000: ********* epoch 5 ********* test accuracy for mode 24:0.183 test loss: 282.545
44000: ********* epoch 5 ********* test accuracy for mode 25:0.3535 test loss: 251.691
44000: ********* epoch 5 ********* test accuracy for mode 26:0.1805 test loss: 191.242
44000: ********* epoch 5 ********* test accuracy for mode 27:0.2615 test loss: 271.822
44000: ********* epoch 5 ********* test accuracy for mode 28:0.256 test loss: 261.322
44000: ********* epoch 5 ********* test accuracy for mode 29:0.3005 test loss: 266.177
44000: ********* epoch 5 ********* test accuracy for mode 30:0.185 test loss: 266.764
44000: ********* epoch 5 ********* test accuracy for mode 31:0.1825 test loss: 272.057
44000: ********* epoch 5 ********* test accuracy for mode 32:0.2045 test loss: 260.948
44000: ********* epoch 5 ********* test accuracy for mode 33:0.1955 test loss: 269.021
44000: ********* epoch 5 ********* test accuracy for mode 34:0.163 test loss: 263.031
44000: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 397.088
44000: ********* epoch 5 ********* test accuracy for mode 36:0.0335 test loss: 414.819
44010: accuracy:0.29 loss: 229.232 (lr:0.00010000000136002223)
44020: accuracy:0.24 loss: 231.82 (lr:0.00010000000135323909)
44030: accuracy:0.23 loss: 231.483 (lr:0.00010000000134648978)
44040: accuracy:0.33 loss: 233.961 (lr:0.00010000000133977414)
44050: accuracy:0.32 loss: 229.979 (lr:0.00010000000133309198)
44060: accuracy:0.24 loss: 228.644 (lr:0.00010000000132644316)
44070: accuracy:0.29 loss: 228.727 (lr:0.0001000000013198275)
44080: accuracy:0.27 loss: 221.058 (lr:0.00010000000131324483)
44090: accuracy:0.2 loss: 257.042 (lr:0.00010000000130669499)
44100: accuracy:0.34 loss: 221.302 (lr:0.00010000000130017783)
44110: accuracy:0.2 loss: 239.396 (lr:0.00010000000129369316)
44120: accuracy:0.22 loss: 262.863 (lr:0.00010000000128724084)
44130: accuracy:0.21 loss: 252.987 (lr:0.0001000000012808207)
44140: accuracy:0.28 loss: 231.203 (lr:0.00010000000127443258)
44150: accuracy:0.28 loss: 231.812 (lr:0.00010000000126807632)
44160: accuracy:0.24 loss: 264.207 (lr:0.00010000000126175176)
44170: accuracy:0.21 loss: 248.467 (lr:0.00010000000125545875)
44180: accuracy:0.29 loss: 235.067 (lr:0.00010000000124919712)
44190: accuracy:0.3 loss: 230.821 (lr:0.00010000000124296673)
44200: accuracy:0.33 loss: 233.007 (lr:0.00010000000123676741)
44210: accuracy:0.26 loss: 238.432 (lr:0.000100000001230599)
44220: accuracy:0.28 loss: 235.058 (lr:0.00010000000122446136)
44230: accuracy:0.31 loss: 227.904 (lr:0.00010000000121835433)
44240: accuracy:0.27 loss: 249.555 (lr:0.00010000000121227777)
44250: accuracy:0.19 loss: 235.551 (lr:0.00010000000120623152)
44260: accuracy:0.23 loss: 245.07 (lr:0.0001000000012002154)
44270: accuracy:0.28 loss: 252.15 (lr:0.0001000000011942293)
44280: accuracy:0.26 loss: 232.467 (lr:0.00010000000118827306)
44290: accuracy:0.39 loss: 215.678 (lr:0.00010000000118234653)
44300: accuracy:0.18 loss: 255.7 (lr:0.00010000000117644955)
44310: accuracy:0.33 loss: 214.845 (lr:0.00010000000117058199)
44320: accuracy:0.27 loss: 237.519 (lr:0.00010000000116474368)
44330: accuracy:0.29 loss: 225.615 (lr:0.0001000000011589345)
44340: accuracy:0.26 loss: 233.762 (lr:0.00010000000115315429)
44350: accuracy:0.25 loss: 240.972 (lr:0.00010000000114740291)
44360: accuracy:0.24 loss: 237.823 (lr:0.0001000000011416802)
44370: accuracy:0.31 loss: 216.35 (lr:0.00010000000113598606)
44380: accuracy:0.27 loss: 247.326 (lr:0.0001000000011303203)
44390: accuracy:0.28 loss: 222.424 (lr:0.0001000000011246828)
44400: accuracy:0.32 loss: 226.572 (lr:0.00010000000111907343)
44410: accuracy:0.25 loss: 249.182 (lr:0.00010000000111349202)
44420: accuracy:0.22 loss: 248.641 (lr:0.00010000000110793847)
44430: accuracy:0.25 loss: 249.641 (lr:0.0001000000011024126)
44440: accuracy:0.27 loss: 238.188 (lr:0.00010000000109691429)
44450: accuracy:0.25 loss: 235.661 (lr:0.0001000000010914434)
44460: accuracy:0.25 loss: 234.389 (lr:0.00010000000108599981)
44470: accuracy:0.31 loss: 242.444 (lr:0.00010000000108058337)
44480: accuracy:0.25 loss: 252.982 (lr:0.00010000000107519393)
44490: accuracy:0.31 loss: 237.924 (lr:0.00010000000106983138)
44500: accuracy:0.22 loss: 253.066 (lr:0.00010000000106449557)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
44500: ********* epoch 5 ********* test accuracy for all:0.221243 test loss: 263.814
44500: ********* epoch 5 ********* test accuracy for mode 0:0.001 test loss: 407.659
44500: ********* epoch 5 ********* test accuracy for mode 1:0.097 test loss: 373.901
44500: ********* epoch 5 ********* test accuracy for mode 2:0.0545 test loss: 281.142
44500: ********* epoch 5 ********* test accuracy for mode 24:0.234 test loss: 274.482
44500: ********* epoch 5 ********* test accuracy for mode 25:0.3515 test loss: 255.211
44500: ********* epoch 5 ********* test accuracy for mode 26:0.136 test loss: 189.687
44500: ********* epoch 5 ********* test accuracy for mode 27:0.278 test loss: 268.797
44500: ********* epoch 5 ********* test accuracy for mode 28:0.252 test loss: 259.141
44500: ********* epoch 5 ********* test accuracy for mode 29:0.303 test loss: 260.594
44500: ********* epoch 5 ********* test accuracy for mode 30:0.243 test loss: 259.785
44500: ********* epoch 5 ********* test accuracy for mode 31:0.1835 test loss: 266.718
44500: ********* epoch 5 ********* test accuracy for mode 32:0.196 test loss: 256.148
44500: ********* epoch 5 ********* test accuracy for mode 33:0.2215 test loss: 264.68
44500: ********* epoch 5 ********* test accuracy for mode 34:0.1015 test loss: 263.075
44500: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 410.91
44500: ********* epoch 5 ********* test accuracy for mode 36:0.029 test loss: 427.656
44510: accuracy:0.21 loss: 256.512 (lr:0.00010000000105918638)
44520: accuracy:0.28 loss: 224.952 (lr:0.00010000000105390366)
44530: accuracy:0.27 loss: 225.325 (lr:0.0001000000010486473)
44540: accuracy:0.28 loss: 236.958 (lr:0.00010000000104341715)
44550: accuracy:0.4 loss: 229.216 (lr:0.00010000000103821309)
44560: accuracy:0.29 loss: 231.019 (lr:0.00010000000103303498)
44570: accuracy:0.25 loss: 245.427 (lr:0.00010000000102788269)
44580: accuracy:0.34 loss: 230.058 (lr:0.0001000000010227561)
44590: accuracy:0.27 loss: 252.286 (lr:0.00010000000101765508)
44600: accuracy:0.21 loss: 237.125 (lr:0.00010000000101257951)
44610: accuracy:0.27 loss: 239.552 (lr:0.00010000000100752926)
44620: accuracy:0.29 loss: 238.663 (lr:0.00010000000100250418)
44630: accuracy:0.31 loss: 237.503 (lr:0.00010000000099750417)
44640: accuracy:0.34 loss: 222.138 (lr:0.00010000000099252909)
44650: accuracy:0.29 loss: 222.625 (lr:0.00010000000098757884)
44660: accuracy:0.31 loss: 221.522 (lr:0.00010000000098265327)
44670: accuracy:0.36 loss: 212.751 (lr:0.00010000000097775227)
44680: accuracy:0.3 loss: 217.906 (lr:0.0001000000009728757)
44690: accuracy:0.19 loss: 255.676 (lr:0.00010000000096802346)
44700: accuracy:0.24 loss: 246.351 (lr:0.00010000000096319543)
44710: accuracy:0.31 loss: 243.235 (lr:0.00010000000095839147)
44720: accuracy:0.27 loss: 258.685 (lr:0.00010000000095361148)
44730: accuracy:0.21 loss: 255.335 (lr:0.00010000000094885531)
44740: accuracy:0.25 loss: 248.083 (lr:0.00010000000094412288)
44750: accuracy:0.33 loss: 215.192 (lr:0.00010000000093941405)
44760: accuracy:0.34 loss: 250.883 (lr:0.0001000000009347287)
44770: accuracy:0.19 loss: 248.925 (lr:0.00010000000093006672)
44780: accuracy:0.22 loss: 254.533 (lr:0.00010000000092542799)
44790: accuracy:0.29 loss: 240.792 (lr:0.00010000000092081241)
44800: accuracy:0.25 loss: 222.598 (lr:0.00010000000091621984)
44810: accuracy:0.3 loss: 247.151 (lr:0.00010000000091165017)
44820: accuracy:0.3 loss: 240.935 (lr:0.0001000000009071033)
44830: accuracy:0.25 loss: 241.282 (lr:0.0001000000009025791)
44840: accuracy:0.28 loss: 240.388 (lr:0.00010000000089807746)
44850: accuracy:0.33 loss: 237.249 (lr:0.00010000000089359828)
44860: accuracy:0.27 loss: 234.713 (lr:0.00010000000088914144)
44870: accuracy:0.24 loss: 245.776 (lr:0.00010000000088470684)
44880: accuracy:0.3 loss: 232.998 (lr:0.00010000000088029434)
44890: accuracy:0.31 loss: 239.864 (lr:0.00010000000087590385)
44900: accuracy:0.23 loss: 263.372 (lr:0.00010000000087153526)
44910: accuracy:0.32 loss: 233.414 (lr:0.00010000000086718846)
44920: accuracy:0.24 loss: 238.922 (lr:0.00010000000086286335)
44930: accuracy:0.27 loss: 236.603 (lr:0.0001000000008585598)
44940: accuracy:0.29 loss: 236.092 (lr:0.00010000000085427771)
44950: accuracy:0.27 loss: 235.563 (lr:0.00010000000085001697)
44960: accuracy:0.3 loss: 223.923 (lr:0.0001000000008457775)
44970: accuracy:0.3 loss: 231.389 (lr:0.00010000000084155917)
44980: accuracy:0.27 loss: 236.776 (lr:0.00010000000083736188)
44990: accuracy:0.28 loss: 257.691 (lr:0.00010000000083318552)
45000: accuracy:0.3 loss: 241.95 (lr:0.00010000000082902999)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
45000: ********* epoch 5 ********* test accuracy for all:0.223351 test loss: 263.317
45000: ********* epoch 5 ********* test accuracy for mode 0:0.001 test loss: 404.885
45000: ********* epoch 5 ********* test accuracy for mode 1:0.099 test loss: 372.402
45000: ********* epoch 5 ********* test accuracy for mode 2:0.077 test loss: 284.794
45000: ********* epoch 5 ********* test accuracy for mode 24:0.2295 test loss: 274.451
45000: ********* epoch 5 ********* test accuracy for mode 25:0.311 test loss: 253.96
45000: ********* epoch 5 ********* test accuracy for mode 26:0.3005 test loss: 189.745
45000: ********* epoch 5 ********* test accuracy for mode 27:0.202 test loss: 281.728
45000: ********* epoch 5 ********* test accuracy for mode 28:0.2775 test loss: 267.21
45000: ********* epoch 5 ********* test accuracy for mode 29:0.2845 test loss: 273.779
45000: ********* epoch 5 ********* test accuracy for mode 30:0.1455 test loss: 276.475
45000: ********* epoch 5 ********* test accuracy for mode 31:0.225 test loss: 272.003
45000: ********* epoch 5 ********* test accuracy for mode 32:0.1945 test loss: 263.82
45000: ********* epoch 5 ********* test accuracy for mode 33:0.2005 test loss: 270.409
45000: ********* epoch 5 ********* test accuracy for mode 34:0.083 test loss: 267.333
45000: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 395.85
45000: ********* epoch 5 ********* test accuracy for mode 36:0.0195 test loss: 402.811
45010: accuracy:0.31 loss: 257.693 (lr:0.00010000000082489518)
45020: accuracy:0.25 loss: 250.952 (lr:0.000100000000820781)
45030: accuracy:0.2 loss: 245.243 (lr:0.00010000000081668734)
45040: accuracy:0.32 loss: 234.933 (lr:0.00010000000081261409)
45050: accuracy:0.34 loss: 241.164 (lr:0.00010000000080856116)
45060: accuracy:0.3 loss: 230.041 (lr:0.00010000000080452845)
45070: accuracy:0.19 loss: 251.179 (lr:0.00010000000080051584)
45080: accuracy:0.21 loss: 244.534 (lr:0.00010000000079652325)
45090: accuracy:0.23 loss: 243.829 (lr:0.00010000000079255059)
45100: accuracy:0.28 loss: 233.398 (lr:0.00010000000078859772)
45110: accuracy:0.27 loss: 232.788 (lr:0.00010000000078466457)
45120: accuracy:0.24 loss: 235.686 (lr:0.00010000000078075104)
45130: accuracy:0.21 loss: 256.264 (lr:0.00010000000077685703)
45140: accuracy:0.28 loss: 225.69 (lr:0.00010000000077298243)
45150: accuracy:0.31 loss: 222.419 (lr:0.00010000000076912717)
45160: accuracy:0.32 loss: 230.071 (lr:0.00010000000076529113)
45170: accuracy:0.35 loss: 209.095 (lr:0.00010000000076147422)
45180: accuracy:0.26 loss: 266.463 (lr:0.00010000000075767636)
45190: accuracy:0.27 loss: 254.505 (lr:0.00010000000075389744)
45200: accuracy:0.24 loss: 237.344 (lr:0.00010000000075013736)
45210: accuracy:0.32 loss: 245.247 (lr:0.00010000000074639603)
45220: accuracy:0.19 loss: 252.191 (lr:0.00010000000074267336)
45230: accuracy:0.27 loss: 260.978 (lr:0.00010000000073896926)
45240: accuracy:0.29 loss: 235.226 (lr:0.00010000000073528364)
45250: accuracy:0.22 loss: 222.259 (lr:0.00010000000073161639)
45260: accuracy:0.31 loss: 257.257 (lr:0.00010000000072796744)
45270: accuracy:0.21 loss: 253.647 (lr:0.00010000000072433669)
45280: accuracy:0.24 loss: 236.041 (lr:0.00010000000072072405)
45290: accuracy:0.17 loss: 241.313 (lr:0.00010000000071712942)
45300: accuracy:0.2 loss: 269.81 (lr:0.00010000000071355273)
45310: accuracy:0.28 loss: 235.023 (lr:0.00010000000070999386)
45320: accuracy:0.2 loss: 250.186 (lr:0.00010000000070645275)
45330: accuracy:0.25 loss: 234.933 (lr:0.00010000000070292931)
45340: accuracy:0.28 loss: 229.646 (lr:0.00010000000069942343)
45350: accuracy:0.3 loss: 217.749 (lr:0.00010000000069593504)
45360: accuracy:0.3 loss: 237.21 (lr:0.00010000000069246405)
45370: accuracy:0.24 loss: 240.912 (lr:0.00010000000068901038)
45380: accuracy:0.34 loss: 246.357 (lr:0.00010000000068557392)
45390: accuracy:0.26 loss: 230.824 (lr:0.0001000000006821546)
45400: accuracy:0.27 loss: 230.502 (lr:0.00010000000067875235)
45410: accuracy:0.25 loss: 242.647 (lr:0.00010000000067536706)
45420: accuracy:0.26 loss: 253.986 (lr:0.00010000000067199865)
45430: accuracy:0.22 loss: 234.086 (lr:0.00010000000066864704)
45440: accuracy:0.34 loss: 221.375 (lr:0.00010000000066531214)
45450: accuracy:0.19 loss: 247.215 (lr:0.00010000000066199389)
45460: accuracy:0.3 loss: 230.316 (lr:0.00010000000065869218)
45470: accuracy:0.26 loss: 217.189 (lr:0.00010000000065540694)
45480: accuracy:0.27 loss: 255.079 (lr:0.00010000000065213808)
45490: accuracy:0.29 loss: 229.966 (lr:0.00010000000064888553)
45500: accuracy:0.33 loss: 233.087 (lr:0.0001000000006456492)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
45500: ********* epoch 5 ********* test accuracy for all:0.223743 test loss: 262.733
45500: ********* epoch 5 ********* test accuracy for mode 0:0.001 test loss: 411.762
45500: ********* epoch 5 ********* test accuracy for mode 1:0.0875 test loss: 380.172
45500: ********* epoch 5 ********* test accuracy for mode 2:0.0735 test loss: 282.31
45500: ********* epoch 5 ********* test accuracy for mode 24:0.244 test loss: 272.883
45500: ********* epoch 5 ********* test accuracy for mode 25:0.256 test loss: 258.08
45500: ********* epoch 5 ********* test accuracy for mode 26:0.259 test loss: 193.672
45500: ********* epoch 5 ********* test accuracy for mode 27:0.216 test loss: 280.733
45500: ********* epoch 5 ********* test accuracy for mode 28:0.274 test loss: 266.967
45500: ********* epoch 5 ********* test accuracy for mode 29:0.245 test loss: 273.49
45500: ********* epoch 5 ********* test accuracy for mode 30:0.226 test loss: 268.021
45500: ********* epoch 5 ********* test accuracy for mode 31:0.2125 test loss: 269.447
45500: ********* epoch 5 ********* test accuracy for mode 32:0.1975 test loss: 261.562
45500: ********* epoch 5 ********* test accuracy for mode 33:0.174 test loss: 268.839
45500: ********* epoch 5 ********* test accuracy for mode 34:0.1545 test loss: 264.207
45500: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 395.771
45500: ********* epoch 5 ********* test accuracy for mode 36:0.0145 test loss: 408.832
45510: accuracy:0.25 loss: 222.038 (lr:0.00010000000064242901)
45520: accuracy:0.25 loss: 232.724 (lr:0.00010000000063922488)
45530: accuracy:0.33 loss: 229.405 (lr:0.00010000000063603673)
45540: accuracy:0.3 loss: 234.046 (lr:0.00010000000063286449)
45550: accuracy:0.22 loss: 245.465 (lr:0.00010000000062970807)
45560: accuracy:0.31 loss: 221.337 (lr:0.00010000000062656739)
45570: accuracy:0.31 loss: 235.858 (lr:0.00010000000062344237)
45580: accuracy:0.22 loss: 242.367 (lr:0.00010000000062033293)
45590: accuracy:0.27 loss: 241.541 (lr:0.00010000000061723901)
45600: accuracy:0.25 loss: 236.712 (lr:0.00010000000061416051)
45610: accuracy:0.26 loss: 242.415 (lr:0.00010000000061109739)
45620: accuracy:0.19 loss: 255.44 (lr:0.00010000000060804952)
45630: accuracy:0.26 loss: 224.787 (lr:0.00010000000060501687)
45640: accuracy:0.33 loss: 234.681 (lr:0.00010000000060199933)
45650: accuracy:0.29 loss: 236.602 (lr:0.00010000000059899685)
45660: accuracy:0.24 loss: 247.574 (lr:0.00010000000059600933)
45670: accuracy:0.32 loss: 235.522 (lr:0.00010000000059303672)
45680: accuracy:0.28 loss: 234.504 (lr:0.00010000000059007895)
45690: accuracy:0.28 loss: 230.302 (lr:0.00010000000058713591)
45700: accuracy:0.29 loss: 234.044 (lr:0.00010000000058420756)
45710: accuracy:0.21 loss: 260.223 (lr:0.00010000000058129381)
45720: accuracy:0.24 loss: 250.587 (lr:0.0001000000005783946)
45730: accuracy:0.33 loss: 238.669 (lr:0.00010000000057550985)
45740: accuracy:0.24 loss: 244.195 (lr:0.00010000000057263947)
45750: accuracy:0.29 loss: 235.148 (lr:0.00010000000056978343)
45760: accuracy:0.23 loss: 232.856 (lr:0.00010000000056694161)
45770: accuracy:0.28 loss: 233.13 (lr:0.00010000000056411399)
45780: accuracy:0.3 loss: 230.864 (lr:0.00010000000056130045)
45790: accuracy:0.35 loss: 222.373 (lr:0.00010000000055850095)
45800: accuracy:0.3 loss: 233.406 (lr:0.00010000000055571542)
45810: accuracy:0.23 loss: 247.393 (lr:0.00010000000055294378)
45820: accuracy:0.24 loss: 255.209 (lr:0.00010000000055018596)
45830: accuracy:0.25 loss: 244.262 (lr:0.0001000000005474419)
45840: accuracy:0.18 loss: 252.468 (lr:0.00010000000054471152)
45850: accuracy:0.28 loss: 241.34 (lr:0.00010000000054199476)
45860: accuracy:0.36 loss: 220.762 (lr:0.00010000000053929154)
45870: accuracy:0.32 loss: 235.852 (lr:0.00010000000053660181)
45880: accuracy:0.27 loss: 218.799 (lr:0.0001000000005339255)
45890: accuracy:0.29 loss: 236.851 (lr:0.00010000000053126254)
45900: accuracy:0.27 loss: 254.948 (lr:0.00010000000052861286)
45910: accuracy:0.28 loss: 245.285 (lr:0.00010000000052597639)
45920: accuracy:0.3 loss: 238.559 (lr:0.00010000000052335308)
45930: accuracy:0.3 loss: 239.791 (lr:0.00010000000052074284)
45940: accuracy:0.2 loss: 245.413 (lr:0.00010000000051814563)
45950: accuracy:0.28 loss: 231.646 (lr:0.00010000000051556137)
45960: accuracy:0.33 loss: 238.019 (lr:0.00010000000051298999)
45970: accuracy:0.35 loss: 227.34 (lr:0.00010000000051043144)
45980: accuracy:0.25 loss: 258.347 (lr:0.00010000000050788565)
45990: accuracy:0.2 loss: 250.521 (lr:0.00010000000050535256)
46000: accuracy:0.2 loss: 259.045 (lr:0.0001000000005028321)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
46000: ********* epoch 5 ********* test accuracy for all:0.226554 test loss: 261.351
46000: ********* epoch 5 ********* test accuracy for mode 0:0.0 test loss: 398.918
46000: ********* epoch 5 ********* test accuracy for mode 1:0.1015 test loss: 373.111
46000: ********* epoch 5 ********* test accuracy for mode 2:0.0775 test loss: 286.117
46000: ********* epoch 5 ********* test accuracy for mode 24:0.2315 test loss: 271.199
46000: ********* epoch 5 ********* test accuracy for mode 25:0.2425 test loss: 257.073
46000: ********* epoch 5 ********* test accuracy for mode 26:0.4705 test loss: 183.101
46000: ********* epoch 5 ********* test accuracy for mode 27:0.199 test loss: 280.325
46000: ********* epoch 5 ********* test accuracy for mode 28:0.272 test loss: 265.124
46000: ********* epoch 5 ********* test accuracy for mode 29:0.2665 test loss: 268.426
46000: ********* epoch 5 ********* test accuracy for mode 30:0.227 test loss: 264.005
46000: ********* epoch 5 ********* test accuracy for mode 31:0.185 test loss: 266.691
46000: ********* epoch 5 ********* test accuracy for mode 32:0.2075 test loss: 259.176
46000: ********* epoch 5 ********* test accuracy for mode 33:0.251 test loss: 264.979
46000: ********* epoch 5 ********* test accuracy for mode 34:0.0575 test loss: 269.695
46000: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 397.376
46000: ********* epoch 5 ********* test accuracy for mode 36:0.0245 test loss: 410.05
46010: accuracy:0.31 loss: 234.52 (lr:0.00010000000050032422)
46020: accuracy:0.3 loss: 236.682 (lr:0.00010000000049782885)
46030: accuracy:0.27 loss: 252.302 (lr:0.00010000000049534592)
46040: accuracy:0.27 loss: 254.827 (lr:0.00010000000049287536)
46050: accuracy:0.22 loss: 247.579 (lr:0.00010000000049041713)
46060: accuracy:0.31 loss: 240.244 (lr:0.00010000000048797117)
46070: accuracy:0.26 loss: 230.301 (lr:0.00010000000048553741)
46080: accuracy:0.3 loss: 245.924 (lr:0.00010000000048311578)
46090: accuracy:0.33 loss: 233.69 (lr:0.00010000000048070623)
46100: accuracy:0.31 loss: 229.814 (lr:0.0001000000004783087)
46110: accuracy:0.28 loss: 246.551 (lr:0.00010000000047592313)
46120: accuracy:0.19 loss: 231.924 (lr:0.00010000000047354944)
46130: accuracy:0.33 loss: 230.516 (lr:0.0001000000004711876)
46140: accuracy:0.29 loss: 238.802 (lr:0.00010000000046883755)
46150: accuracy:0.3 loss: 220.397 (lr:0.00010000000046649921)
46160: accuracy:0.25 loss: 247.297 (lr:0.00010000000046417254)
46170: accuracy:0.28 loss: 229.989 (lr:0.00010000000046185747)
46180: accuracy:0.23 loss: 233.301 (lr:0.00010000000045955395)
46190: accuracy:0.31 loss: 219.866 (lr:0.0001000000004572619)
46200: accuracy:0.26 loss: 229.462 (lr:0.0001000000004549813)
46210: accuracy:0.26 loss: 232.287 (lr:0.00010000000045271208)
46220: accuracy:0.27 loss: 243.004 (lr:0.00010000000045045417)
46230: accuracy:0.28 loss: 228.062 (lr:0.00010000000044820752)
46240: accuracy:0.28 loss: 250.116 (lr:0.00010000000044597207)
46250: accuracy:0.32 loss: 229.203 (lr:0.00010000000044374777)
46260: accuracy:0.31 loss: 239.211 (lr:0.00010000000044153458)
46270: accuracy:0.31 loss: 218.177 (lr:0.00010000000043933241)
46280: accuracy:0.29 loss: 239.209 (lr:0.00010000000043714123)
46290: accuracy:0.21 loss: 244.303 (lr:0.00010000000043496098)
46300: accuracy:0.22 loss: 254.812 (lr:0.00010000000043279161)
46310: accuracy:0.28 loss: 242.823 (lr:0.00010000000043063305)
46320: accuracy:0.17 loss: 241.059 (lr:0.00010000000042848526)
46330: accuracy:0.31 loss: 244.255 (lr:0.00010000000042634818)
46340: accuracy:0.24 loss: 237.76 (lr:0.00010000000042422175)
46350: accuracy:0.27 loss: 234.609 (lr:0.00010000000042210594)
46360: accuracy:0.23 loss: 248.879 (lr:0.00010000000042000068)
46370: accuracy:0.31 loss: 228.249 (lr:0.00010000000041790592)
46380: accuracy:0.3 loss: 244.925 (lr:0.00010000000041582161)
46390: accuracy:0.28 loss: 235.323 (lr:0.00010000000041374768)
46400: accuracy:0.2 loss: 242.547 (lr:0.0001000000004116841)
46410: accuracy:0.32 loss: 243.496 (lr:0.00010000000040963083)
46420: accuracy:0.29 loss: 237.435 (lr:0.00010000000040758779)
46430: accuracy:0.29 loss: 239.292 (lr:0.00010000000040555493)
46440: accuracy:0.26 loss: 227.947 (lr:0.00010000000040353222)
46450: accuracy:0.33 loss: 248.743 (lr:0.00010000000040151959)
46460: accuracy:0.25 loss: 244.735 (lr:0.00010000000039951701)
46470: accuracy:0.31 loss: 238.516 (lr:0.00010000000039752441)
46480: accuracy:0.26 loss: 237.504 (lr:0.00010000000039554174)
46490: accuracy:0.34 loss: 236.006 (lr:0.00010000000039356897)
46500: accuracy:0.22 loss: 266.601 (lr:0.00010000000039160604)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
46500: ********* epoch 5 ********* test accuracy for all:0.225527 test loss: 262.824
46500: ********* epoch 5 ********* test accuracy for mode 0:0.0015 test loss: 398.098
46500: ********* epoch 5 ********* test accuracy for mode 1:0.0965 test loss: 369.432
46500: ********* epoch 5 ********* test accuracy for mode 2:0.079 test loss: 279.335
46500: ********* epoch 5 ********* test accuracy for mode 24:0.2055 test loss: 279.536
46500: ********* epoch 5 ********* test accuracy for mode 25:0.302 test loss: 257.254
46500: ********* epoch 5 ********* test accuracy for mode 26:0.3125 test loss: 187.118
46500: ********* epoch 5 ********* test accuracy for mode 27:0.2685 test loss: 274.456
46500: ********* epoch 5 ********* test accuracy for mode 28:0.2405 test loss: 267.333
46500: ********* epoch 5 ********* test accuracy for mode 29:0.2785 test loss: 269.03
46500: ********* epoch 5 ********* test accuracy for mode 30:0.226 test loss: 263.591
46500: ********* epoch 5 ********* test accuracy for mode 31:0.183 test loss: 265.839
46500: ********* epoch 5 ********* test accuracy for mode 32:0.2245 test loss: 256.784
46500: ********* epoch 5 ********* test accuracy for mode 33:0.161 test loss: 267.809
46500: ********* epoch 5 ********* test accuracy for mode 34:0.1395 test loss: 264.505
46500: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 401.931
46500: ********* epoch 5 ********* test accuracy for mode 36:0.0205 test loss: 424.813
46510: accuracy:0.27 loss: 230.43 (lr:0.0001000000003896529)
46520: accuracy:0.26 loss: 245.313 (lr:0.0001000000003877095)
46530: accuracy:0.34 loss: 224.235 (lr:0.00010000000038577578)
46540: accuracy:0.32 loss: 237.043 (lr:0.00010000000038385171)
46550: accuracy:0.3 loss: 223.741 (lr:0.00010000000038193726)
46560: accuracy:0.34 loss: 227.797 (lr:0.00010000000038003233)
46570: accuracy:0.28 loss: 224.51 (lr:0.00010000000037813691)
46580: accuracy:0.24 loss: 251.302 (lr:0.00010000000037625094)
46590: accuracy:0.24 loss: 237.49 (lr:0.00010000000037437439)
46600: accuracy:0.29 loss: 228.678 (lr:0.00010000000037250719)
46610: accuracy:0.21 loss: 242.128 (lr:0.0001000000003706493)
46620: accuracy:0.3 loss: 239.399 (lr:0.00010000000036880068)
46630: accuracy:0.24 loss: 244.043 (lr:0.00010000000036696128)
46640: accuracy:0.24 loss: 235.691 (lr:0.00010000000036513105)
46650: accuracy:0.22 loss: 237.832 (lr:0.00010000000036330996)
46660: accuracy:0.29 loss: 215.887 (lr:0.00010000000036149793)
46670: accuracy:0.32 loss: 210.311 (lr:0.00010000000035969496)
46680: accuracy:0.27 loss: 229.603 (lr:0.00010000000035790097)
46690: accuracy:0.3 loss: 242.482 (lr:0.00010000000035611594)
46700: accuracy:0.23 loss: 252.471 (lr:0.0001000000003543398)
46710: accuracy:0.3 loss: 228.369 (lr:0.00010000000035257252)
46720: accuracy:0.3 loss: 252.265 (lr:0.00010000000035081405)
46730: accuracy:0.24 loss: 238.78 (lr:0.00010000000034906437)
46740: accuracy:0.31 loss: 223.449 (lr:0.0001000000003473234)
46750: accuracy:0.26 loss: 242.533 (lr:0.00010000000034559111)
46760: accuracy:0.29 loss: 232.166 (lr:0.00010000000034386748)
46770: accuracy:0.33 loss: 236.715 (lr:0.00010000000034215243)
46780: accuracy:0.3 loss: 241.412 (lr:0.00010000000034044594)
46790: accuracy:0.27 loss: 230.905 (lr:0.00010000000033874796)
46800: accuracy:0.22 loss: 241.684 (lr:0.00010000000033705844)
46810: accuracy:0.29 loss: 234.966 (lr:0.00010000000033537736)
46820: accuracy:0.4 loss: 209.482 (lr:0.00010000000033370465)
46830: accuracy:0.32 loss: 212.397 (lr:0.0001000000003320403)
46840: accuracy:0.29 loss: 236.93 (lr:0.00010000000033038424)
46850: accuracy:0.31 loss: 248.886 (lr:0.00010000000032873645)
46860: accuracy:0.33 loss: 230.225 (lr:0.00010000000032709686)
46870: accuracy:0.27 loss: 233.585 (lr:0.00010000000032546546)
46880: accuracy:0.29 loss: 237.126 (lr:0.0001000000003238422)
46890: accuracy:0.22 loss: 250.274 (lr:0.00010000000032222702)
46900: accuracy:0.35 loss: 243.62 (lr:0.0001000000003206199)
46910: accuracy:0.27 loss: 225.476 (lr:0.00010000000031902082)
46920: accuracy:0.26 loss: 248.196 (lr:0.00010000000031742968)
46930: accuracy:0.26 loss: 255.657 (lr:0.0001000000003158465)
46940: accuracy:0.26 loss: 249.177 (lr:0.00010000000031427121)
46950: accuracy:0.2 loss: 256.219 (lr:0.00010000000031270378)
46960: accuracy:0.36 loss: 239.959 (lr:0.00010000000031114415)
46970: accuracy:0.22 loss: 238.623 (lr:0.00010000000030959232)
46980: accuracy:0.22 loss: 234.758 (lr:0.00010000000030804823)
46990: accuracy:0.3 loss: 222.641 (lr:0.00010000000030651182)
47000: accuracy:0.26 loss: 232.296 (lr:0.0001000000003049831)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
47000: ********* epoch 5 ********* test accuracy for all:0.223568 test loss: 261.402
47000: ********* epoch 5 ********* test accuracy for mode 0:0.002 test loss: 407.19
47000: ********* epoch 5 ********* test accuracy for mode 1:0.0865 test loss: 376.674
47000: ********* epoch 5 ********* test accuracy for mode 2:0.044 test loss: 283.419
47000: ********* epoch 5 ********* test accuracy for mode 24:0.2215 test loss: 274.831
47000: ********* epoch 5 ********* test accuracy for mode 25:0.331 test loss: 251.67
47000: ********* epoch 5 ********* test accuracy for mode 26:0.127 test loss: 191.825
47000: ********* epoch 5 ********* test accuracy for mode 27:0.2975 test loss: 264.673
47000: ********* epoch 5 ********* test accuracy for mode 28:0.279 test loss: 256.561
47000: ********* epoch 5 ********* test accuracy for mode 29:0.273 test loss: 264.438
47000: ********* epoch 5 ********* test accuracy for mode 30:0.2145 test loss: 260.46
47000: ********* epoch 5 ********* test accuracy for mode 31:0.1695 test loss: 266.756
47000: ********* epoch 5 ********* test accuracy for mode 32:0.179 test loss: 257.91
47000: ********* epoch 5 ********* test accuracy for mode 33:0.2945 test loss: 258.764
47000: ********* epoch 5 ********* test accuracy for mode 34:0.1115 test loss: 261.896
47000: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 402.686
47000: ********* epoch 5 ********* test accuracy for mode 36:0.0265 test loss: 409.461
47010: accuracy:0.27 loss: 221.28 (lr:0.00010000000030346199)
47020: accuracy:0.26 loss: 229.575 (lr:0.00010000000030194845)
47030: accuracy:0.18 loss: 245.051 (lr:0.00010000000030044248)
47040: accuracy:0.22 loss: 233.712 (lr:0.00010000000029894402)
47050: accuracy:0.33 loss: 220.009 (lr:0.00010000000029745303)
47060: accuracy:0.28 loss: 242.188 (lr:0.00010000000029596948)
47070: accuracy:0.3 loss: 220.486 (lr:0.00010000000029449333)
47080: accuracy:0.29 loss: 209.828 (lr:0.00010000000029302453)
47090: accuracy:0.22 loss: 239.191 (lr:0.00010000000029156307)
47100: accuracy:0.31 loss: 227.541 (lr:0.00010000000029010888)
47110: accuracy:0.32 loss: 239.952 (lr:0.00010000000028866196)
47120: accuracy:0.28 loss: 213.08 (lr:0.00010000000028722226)
47130: accuracy:0.25 loss: 232.875 (lr:0.00010000000028578973)
47140: accuracy:0.28 loss: 244.332 (lr:0.00010000000028436435)
47150: accuracy:0.27 loss: 238.346 (lr:0.00010000000028294608)
47160: accuracy:0.28 loss: 224.766 (lr:0.00010000000028153488)
47170: accuracy:0.29 loss: 237.463 (lr:0.00010000000028013071)
47180: accuracy:0.33 loss: 222.137 (lr:0.00010000000027873356)
47190: accuracy:0.28 loss: 235.777 (lr:0.00010000000027734337)
47200: accuracy:0.2 loss: 266.548 (lr:0.00010000000027596011)
47210: accuracy:0.26 loss: 250.45 (lr:0.00010000000027458376)
47220: accuracy:0.21 loss: 247.588 (lr:0.00010000000027321426)
47230: accuracy:0.26 loss: 252.453 (lr:0.0001000000002718516)
47240: accuracy:0.3 loss: 224.819 (lr:0.00010000000027049573)
47250: accuracy:0.23 loss: 266.494 (lr:0.00010000000026914663)
47260: accuracy:0.18 loss: 236.193 (lr:0.00010000000026780426)
47270: accuracy:0.32 loss: 227.808 (lr:0.00010000000026646857)
47280: accuracy:0.26 loss: 220.649 (lr:0.00010000000026513956)
47290: accuracy:0.23 loss: 233.155 (lr:0.00010000000026381717)
47300: accuracy:0.3 loss: 221.156 (lr:0.00010000000026250138)
47310: accuracy:0.29 loss: 229.298 (lr:0.00010000000026119216)
47320: accuracy:0.2 loss: 253.737 (lr:0.00010000000025988945)
47330: accuracy:0.23 loss: 232.725 (lr:0.00010000000025859324)
47340: accuracy:0.24 loss: 262.004 (lr:0.0001000000002573035)
47350: accuracy:0.26 loss: 245.584 (lr:0.0001000000002560202)
47360: accuracy:0.21 loss: 234.792 (lr:0.0001000000002547433)
47370: accuracy:0.26 loss: 246.134 (lr:0.00010000000025347276)
47380: accuracy:0.3 loss: 229.86 (lr:0.00010000000025220855)
47390: accuracy:0.31 loss: 228.709 (lr:0.00010000000025095066)
47400: accuracy:0.35 loss: 219.67 (lr:0.00010000000024969904)
47410: accuracy:0.32 loss: 231.851 (lr:0.00010000000024845366)
47420: accuracy:0.3 loss: 229.285 (lr:0.00010000000024721449)
47430: accuracy:0.26 loss: 243.654 (lr:0.0001000000002459815)
47440: accuracy:0.22 loss: 253.58 (lr:0.00010000000024475466)
47450: accuracy:0.37 loss: 241.267 (lr:0.00010000000024353394)
47460: accuracy:0.4 loss: 205.839 (lr:0.00010000000024231931)
47470: accuracy:0.24 loss: 246.138 (lr:0.00010000000024111074)
47480: accuracy:0.31 loss: 242.024 (lr:0.0001000000002399082)
47490: accuracy:0.32 loss: 222.789 (lr:0.00010000000023871166)
47500: accuracy:0.31 loss: 233.475 (lr:0.00010000000023752107)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
47500: ********* epoch 5 ********* test accuracy for all:0.22823 test loss: 261.678
47500: ********* epoch 5 ********* test accuracy for mode 0:0.0015 test loss: 404.322
47500: ********* epoch 5 ********* test accuracy for mode 1:0.0925 test loss: 379.31
47500: ********* epoch 5 ********* test accuracy for mode 2:0.05 test loss: 283.041
47500: ********* epoch 5 ********* test accuracy for mode 24:0.2275 test loss: 271.009
47500: ********* epoch 5 ********* test accuracy for mode 25:0.276 test loss: 248.732
47500: ********* epoch 5 ********* test accuracy for mode 26:0.3985 test loss: 183.024
47500: ********* epoch 5 ********* test accuracy for mode 27:0.218 test loss: 275.521
47500: ********* epoch 5 ********* test accuracy for mode 28:0.265 test loss: 258.785
47500: ********* epoch 5 ********* test accuracy for mode 29:0.274 test loss: 264.235
47500: ********* epoch 5 ********* test accuracy for mode 30:0.248 test loss: 257.322
47500: ********* epoch 5 ********* test accuracy for mode 31:0.2225 test loss: 263.438
47500: ********* epoch 5 ********* test accuracy for mode 32:0.1725 test loss: 258.108
47500: ********* epoch 5 ********* test accuracy for mode 33:0.206 test loss: 264.14
47500: ********* epoch 5 ********* test accuracy for mode 34:0.1285 test loss: 263.059
47500: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 405.041
47500: ********* epoch 5 ********* test accuracy for mode 36:0.027 test loss: 408.655
47510: accuracy:0.26 loss: 225.622 (lr:0.00010000000023633643)
47520: accuracy:0.36 loss: 222.171 (lr:0.0001000000002351577)
47530: accuracy:0.31 loss: 224.61 (lr:0.00010000000023398485)
47540: accuracy:0.3 loss: 220.376 (lr:0.00010000000023281784)
47550: accuracy:0.17 loss: 247.684 (lr:0.00010000000023165666)
47560: accuracy:0.28 loss: 243.178 (lr:0.00010000000023050126)
47570: accuracy:0.25 loss: 231.458 (lr:0.00010000000022935163)
47580: accuracy:0.31 loss: 216.304 (lr:0.00010000000022820774)
47590: accuracy:0.34 loss: 230.439 (lr:0.00010000000022706955)
47600: accuracy:0.27 loss: 242.082 (lr:0.00010000000022593703)
47610: accuracy:0.28 loss: 240.35 (lr:0.00010000000022481017)
47620: accuracy:0.27 loss: 239.654 (lr:0.00010000000022368892)
47630: accuracy:0.27 loss: 230.283 (lr:0.00010000000022257327)
47640: accuracy:0.27 loss: 234.383 (lr:0.00010000000022146318)
47650: accuracy:0.25 loss: 224.908 (lr:0.00010000000022035862)
47660: accuracy:0.26 loss: 238.345 (lr:0.00010000000021925958)
47670: accuracy:0.27 loss: 255.894 (lr:0.00010000000021816603)
47680: accuracy:0.25 loss: 255.295 (lr:0.00010000000021707792)
47690: accuracy:0.25 loss: 248.502 (lr:0.00010000000021599524)
47700: accuracy:0.26 loss: 243.598 (lr:0.00010000000021491796)
47710: accuracy:0.22 loss: 238.59 (lr:0.00010000000021384605)
47720: accuracy:0.32 loss: 235.7 (lr:0.00010000000021277948)
47730: accuracy:0.34 loss: 213.897 (lr:0.00010000000021171825)
47740: accuracy:0.26 loss: 244.003 (lr:0.00010000000021066229)
47750: accuracy:0.27 loss: 240.418 (lr:0.00010000000020961162)
47760: accuracy:0.24 loss: 242.949 (lr:0.00010000000020856617)
47770: accuracy:0.26 loss: 228.026 (lr:0.00010000000020752594)
47780: accuracy:0.24 loss: 235.643 (lr:0.0001000000002064909)
47790: accuracy:0.2 loss: 254.072 (lr:0.00010000000020546102)
47800: accuracy:0.23 loss: 241.404 (lr:0.00010000000020443629)
47810: accuracy:0.25 loss: 254.015 (lr:0.00010000000020341665)
47820: accuracy:0.28 loss: 241.62 (lr:0.0001000000002024021)
47830: accuracy:0.25 loss: 231.819 (lr:0.00010000000020139262)
47840: accuracy:0.29 loss: 250.245 (lr:0.00010000000020038817)
47850: accuracy:0.31 loss: 236.94 (lr:0.00010000000019938873)
47860: accuracy:0.24 loss: 239.158 (lr:0.00010000000019839427)
47870: accuracy:0.32 loss: 220.974 (lr:0.00010000000019740479)
47880: accuracy:0.26 loss: 248.859 (lr:0.00010000000019642022)
47890: accuracy:0.25 loss: 251.255 (lr:0.00010000000019544057)
47900: accuracy:0.28 loss: 259.623 (lr:0.00010000000019446581)
47910: accuracy:0.23 loss: 218.085 (lr:0.0001000000001934959)
47920: accuracy:0.19 loss: 230.892 (lr:0.00010000000019253084)
47930: accuracy:0.3 loss: 234.772 (lr:0.00010000000019157059)
47940: accuracy:0.29 loss: 232.955 (lr:0.00010000000019061512)
47950: accuracy:0.27 loss: 246.444 (lr:0.00010000000018966442)
47960: accuracy:0.29 loss: 240.263 (lr:0.00010000000018871847)
47970: accuracy:0.34 loss: 220.128 (lr:0.00010000000018777723)
47980: accuracy:0.2 loss: 233.618 (lr:0.00010000000018684069)
47990: accuracy:0.27 loss: 242.2 (lr:0.00010000000018590882)
48000: accuracy:0.32 loss: 243.239 (lr:0.00010000000018498159)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
48000: ********* epoch 5 ********* test accuracy for all:0.226149 test loss: 262.698
48000: ********* epoch 5 ********* test accuracy for mode 0:0.001 test loss: 421.413
48000: ********* epoch 5 ********* test accuracy for mode 1:0.069 test loss: 391.023
48000: ********* epoch 5 ********* test accuracy for mode 2:0.0745 test loss: 275.415
48000: ********* epoch 5 ********* test accuracy for mode 24:0.213 test loss: 277.565
48000: ********* epoch 5 ********* test accuracy for mode 25:0.3465 test loss: 251.991
48000: ********* epoch 5 ********* test accuracy for mode 26:0.212 test loss: 187.009
48000: ********* epoch 5 ********* test accuracy for mode 27:0.3025 test loss: 271.024
48000: ********* epoch 5 ********* test accuracy for mode 28:0.282 test loss: 261.378
48000: ********* epoch 5 ********* test accuracy for mode 29:0.2485 test loss: 269.687
48000: ********* epoch 5 ********* test accuracy for mode 30:0.1995 test loss: 267.241
48000: ********* epoch 5 ********* test accuracy for mode 31:0.188 test loss: 263.104
48000: ********* epoch 5 ********* test accuracy for mode 32:0.2095 test loss: 252.275
48000: ********* epoch 5 ********* test accuracy for mode 33:0.2675 test loss: 258.565
48000: ********* epoch 5 ********* test accuracy for mode 34:0.026 test loss: 262.826
48000: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 419.226
48000: ********* epoch 5 ********* test accuracy for mode 36:0.033 test loss: 433.495
48010: accuracy:0.25 loss: 226.856 (lr:0.000100000000184059)
48020: accuracy:0.33 loss: 225.531 (lr:0.000100000000183141)
48030: accuracy:0.25 loss: 262.279 (lr:0.00010000000018222758)
48040: accuracy:0.29 loss: 233.35 (lr:0.00010000000018131871)
48050: accuracy:0.21 loss: 254.472 (lr:0.00010000000018041439)
48060: accuracy:0.22 loss: 241.433 (lr:0.00010000000017951457)
48070: accuracy:0.22 loss: 247.321 (lr:0.00010000000017861924)
48080: accuracy:0.35 loss: 224.579 (lr:0.00010000000017772836)
48090: accuracy:0.36 loss: 233.108 (lr:0.00010000000017684194)
48100: accuracy:0.28 loss: 241.549 (lr:0.00010000000017595993)
48110: accuracy:0.3 loss: 240.909 (lr:0.00010000000017508234)
48120: accuracy:0.28 loss: 246.344 (lr:0.00010000000017420911)
48130: accuracy:0.27 loss: 253.517 (lr:0.00010000000017334024)
48140: accuracy:0.25 loss: 233.397 (lr:0.0001000000001724757)
48150: accuracy:0.28 loss: 232.317 (lr:0.00010000000017161547)
48160: accuracy:0.33 loss: 263.057 (lr:0.00010000000017075954)
48170: accuracy:0.21 loss: 257.176 (lr:0.00010000000016990788)
48180: accuracy:0.32 loss: 237.347 (lr:0.00010000000016906045)
48190: accuracy:0.36 loss: 232.206 (lr:0.00010000000016821727)
48200: accuracy:0.26 loss: 242.793 (lr:0.00010000000016737827)
48210: accuracy:0.3 loss: 232.736 (lr:0.00010000000016654347)
48220: accuracy:0.24 loss: 233.505 (lr:0.00010000000016571283)
48230: accuracy:0.25 loss: 240.912 (lr:0.00010000000016488634)
48240: accuracy:0.3 loss: 222.596 (lr:0.00010000000016406396)
48250: accuracy:0.26 loss: 211.994 (lr:0.00010000000016324568)
48260: accuracy:0.27 loss: 242.039 (lr:0.0001000000001624315)
48270: accuracy:0.29 loss: 245.204 (lr:0.00010000000016162137)
48280: accuracy:0.3 loss: 251.933 (lr:0.00010000000016081528)
48290: accuracy:0.33 loss: 237.498 (lr:0.0001000000001600132)
48300: accuracy:0.25 loss: 244.351 (lr:0.00010000000015921513)
48310: accuracy:0.27 loss: 223.843 (lr:0.00010000000015842105)
48320: accuracy:0.3 loss: 229.061 (lr:0.00010000000015763093)
48330: accuracy:0.29 loss: 230.592 (lr:0.00010000000015684473)
48340: accuracy:0.3 loss: 224.19 (lr:0.00010000000015606246)
48350: accuracy:0.22 loss: 232.474 (lr:0.0001000000001552841)
48360: accuracy:0.31 loss: 220.858 (lr:0.00010000000015450962)
48370: accuracy:0.29 loss: 237.978 (lr:0.000100000000153739)
48380: accuracy:0.28 loss: 226.923 (lr:0.00010000000015297222)
48390: accuracy:0.27 loss: 237.392 (lr:0.00010000000015220926)
48400: accuracy:0.24 loss: 237.328 (lr:0.00010000000015145012)
48410: accuracy:0.34 loss: 228.856 (lr:0.00010000000015069477)
48420: accuracy:0.33 loss: 221.544 (lr:0.00010000000014994317)
48430: accuracy:0.3 loss: 240.316 (lr:0.00010000000014919533)
48440: accuracy:0.21 loss: 256.84 (lr:0.00010000000014845122)
48450: accuracy:0.29 loss: 239.762 (lr:0.0001000000001477108)
48460: accuracy:0.22 loss: 241.124 (lr:0.0001000000001469741)
48470: accuracy:0.29 loss: 222.115 (lr:0.00010000000014624106)
48480: accuracy:0.27 loss: 256.504 (lr:0.00010000000014551167)
48490: accuracy:0.36 loss: 218.404 (lr:0.00010000000014478593)
48500: accuracy:0.3 loss: 221.189 (lr:0.00010000000014406382)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
48500: ********* epoch 5 ********* test accuracy for all:0.226514 test loss: 261.971
48500: ********* epoch 5 ********* test accuracy for mode 0:0.0 test loss: 402.323
48500: ********* epoch 5 ********* test accuracy for mode 1:0.1075 test loss: 371.07
48500: ********* epoch 5 ********* test accuracy for mode 2:0.0445 test loss: 285.199
48500: ********* epoch 5 ********* test accuracy for mode 24:0.2065 test loss: 278.039
48500: ********* epoch 5 ********* test accuracy for mode 25:0.2585 test loss: 256.384
48500: ********* epoch 5 ********* test accuracy for mode 26:0.288 test loss: 187.92
48500: ********* epoch 5 ********* test accuracy for mode 27:0.28 test loss: 274.565
48500: ********* epoch 5 ********* test accuracy for mode 28:0.2485 test loss: 265.634
48500: ********* epoch 5 ********* test accuracy for mode 29:0.2925 test loss: 270.087
48500: ********* epoch 5 ********* test accuracy for mode 30:0.2095 test loss: 270.189
48500: ********* epoch 5 ********* test accuracy for mode 31:0.1955 test loss: 270.868
48500: ********* epoch 5 ********* test accuracy for mode 32:0.143 test loss: 264.333
48500: ********* epoch 5 ********* test accuracy for mode 33:0.2435 test loss: 266.985
48500: ********* epoch 5 ********* test accuracy for mode 34:0.0735 test loss: 267.294
48500: ********* epoch 5 ********* test accuracy for mode 35:0.0 test loss: 411.359
48500: ********* epoch 5 ********* test accuracy for mode 36:0.02 test loss: 437.662
48510: accuracy:0.32 loss: 233.575 (lr:0.00010000000014334529)
48520: accuracy:0.26 loss: 259.085 (lr:0.00010000000014263035)
48530: accuracy:0.3 loss: 255.012 (lr:0.00010000000014191898)
48540: accuracy:0.26 loss: 235.869 (lr:0.00010000000014121116)
48550: accuracy:0.25 loss: 217.155 (lr:0.00010000000014050686)
48560: accuracy:0.36 loss: 213.727 (lr:0.00010000000013980609)
48570: accuracy:0.29 loss: 219.511 (lr:0.0001000000001391088)
48580: accuracy:0.2 loss: 237.826 (lr:0.00010000000013841499)
48590: accuracy:0.3 loss: 228.452 (lr:0.00010000000013772465)
48600: accuracy:0.21 loss: 253.824 (lr:0.00010000000013703774)
48610: accuracy:0.23 loss: 240.098 (lr:0.00010000000013635426)
48620: accuracy:0.25 loss: 236.001 (lr:0.00010000000013567419)
48630: accuracy:0.29 loss: 237.298 (lr:0.00010000000013499751)
48640: accuracy:0.2 loss: 264.807 (lr:0.00010000000013432421)
48650: accuracy:0.26 loss: 235.095 (lr:0.00010000000013365427)
48660: accuracy:0.33 loss: 228.198 (lr:0.00010000000013298766)
48670: accuracy:0.33 loss: 214.789 (lr:0.00010000000013232439)
48680: accuracy:0.32 loss: 220.559 (lr:0.00010000000013166442)
48690: accuracy:0.26 loss: 224.999 (lr:0.00010000000013100773)
48700: accuracy:0.26 loss: 239.686 (lr:0.00010000000013035434)
48710: accuracy:0.33 loss: 228.795 (lr:0.00010000000012970418)
48720: accuracy:0.32 loss: 224.288 (lr:0.00010000000012905728)
48730: accuracy:0.31 loss: 249.183 (lr:0.0001000000001284136)
48740: accuracy:0.22 loss: 229.571 (lr:0.00010000000012777314)
48750: accuracy:0.3 loss: 212.602 (lr:0.00010000000012713587)
48760: accuracy:0.37 loss: 227.508 (lr:0.00010000000012650177)
48770: accuracy:0.28 loss: 240.813 (lr:0.00010000000012587085)
48780: accuracy:0.33 loss: 218.044 (lr:0.00010000000012524307)
48790: accuracy:0.34 loss: 230.979 (lr:0.0001000000001246184)
48800: accuracy:0.27 loss: 232.967 (lr:0.00010000000012399687)
48810: accuracy:0.26 loss: 240.007 (lr:0.00010000000012337843)
48820: accuracy:0.21 loss: 242.269 (lr:0.00010000000012276308)
48830: accuracy:0.25 loss: 231.241 (lr:0.0001000000001221508)
48840: accuracy:0.27 loss: 242.248 (lr:0.00010000000012154158)
48850: accuracy:0.19 loss: 233.185 (lr:0.00010000000012093538)
48860: accuracy:0.22 loss: 251.136 (lr:0.00010000000012033222)
48870: accuracy:0.2 loss: 250.837 (lr:0.00010000000011973206)
48880: accuracy:0.33 loss: 225.539 (lr:0.00010000000011913489)
48890: accuracy:0.28 loss: 227.768 (lr:0.0001000000001185407)
48900: accuracy:0.3 loss: 225.947 (lr:0.00010000000011794948)
48910: accuracy:0.25 loss: 234.15 (lr:0.0001000000001173612)
48920: accuracy:0.23 loss: 244.09 (lr:0.00010000000011677586)
48930: accuracy:0.33 loss: 230.834 (lr:0.00010000000011619344)
48940: accuracy:0.29 loss: 228.369 (lr:0.00010000000011561392)
48950: accuracy:0.28 loss: 244.259 (lr:0.0001000000001150373)
48960: accuracy:0.4 loss: 226.795 (lr:0.00010000000011446354)
48970: accuracy:0.19 loss: 239.789 (lr:0.00010000000011389265)
48980: accuracy:0.37 loss: 220.43 (lr:0.00010000000011332461)
48990: accuracy:0.26 loss: 223.213 (lr:0.0001000000001127594)
49000: accuracy:0.34 loss: 219.481 (lr:0.00010000000011219701)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
49000: ********* epoch 6 ********* test accuracy for all:0.224811 test loss: 261.664
49000: ********* epoch 6 ********* test accuracy for mode 0:0.0 test loss: 401.696
49000: ********* epoch 6 ********* test accuracy for mode 1:0.107 test loss: 371.366
49000: ********* epoch 6 ********* test accuracy for mode 2:0.081 test loss: 282.331
49000: ********* epoch 6 ********* test accuracy for mode 24:0.2185 test loss: 277.278
49000: ********* epoch 6 ********* test accuracy for mode 25:0.3275 test loss: 246.652
49000: ********* epoch 6 ********* test accuracy for mode 26:0.313 test loss: 180.192
49000: ********* epoch 6 ********* test accuracy for mode 27:0.2175 test loss: 279.76
49000: ********* epoch 6 ********* test accuracy for mode 28:0.2615 test loss: 264.858
49000: ********* epoch 6 ********* test accuracy for mode 29:0.245 test loss: 270.632
49000: ********* epoch 6 ********* test accuracy for mode 30:0.209 test loss: 265.735
49000: ********* epoch 6 ********* test accuracy for mode 31:0.1675 test loss: 265.843
49000: ********* epoch 6 ********* test accuracy for mode 32:0.234 test loss: 253.453
49000: ********* epoch 6 ********* test accuracy for mode 33:0.221 test loss: 262.778
49000: ********* epoch 6 ********* test accuracy for mode 34:0.111 test loss: 262.479
49000: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 410.981
49000: ********* epoch 6 ********* test accuracy for mode 36:0.018 test loss: 428.502
49010: accuracy:0.22 loss: 231.505 (lr:0.00010000000011163743)
49020: accuracy:0.35 loss: 220.557 (lr:0.00010000000011108064)
49030: accuracy:0.24 loss: 241.89 (lr:0.00010000000011052661)
49040: accuracy:0.22 loss: 239.042 (lr:0.00010000000010997536)
49050: accuracy:0.29 loss: 229.381 (lr:0.00010000000010942686)
49060: accuracy:0.22 loss: 246.328 (lr:0.00010000000010888109)
49070: accuracy:0.33 loss: 213.903 (lr:0.00010000000010833804)
49080: accuracy:0.3 loss: 222.538 (lr:0.0001000000001077977)
49090: accuracy:0.25 loss: 242.599 (lr:0.00010000000010726006)
49100: accuracy:0.3 loss: 221.716 (lr:0.0001000000001067251)
49110: accuracy:0.29 loss: 225.404 (lr:0.00010000000010619281)
49120: accuracy:0.26 loss: 243.445 (lr:0.00010000000010566316)
49130: accuracy:0.26 loss: 235.827 (lr:0.00010000000010513617)
49140: accuracy:0.26 loss: 244.268 (lr:0.0001000000001046118)
49150: accuracy:0.22 loss: 231.567 (lr:0.00010000000010409005)
49160: accuracy:0.2 loss: 260.273 (lr:0.0001000000001035709)
49170: accuracy:0.23 loss: 232.305 (lr:0.00010000000010305433)
49180: accuracy:0.31 loss: 235.223 (lr:0.00010000000010254035)
49190: accuracy:0.24 loss: 239.41 (lr:0.00010000000010202893)
49200: accuracy:0.26 loss: 232.342 (lr:0.00010000000010152006)
49210: accuracy:0.29 loss: 242.863 (lr:0.00010000000010101373)
49220: accuracy:0.27 loss: 227.699 (lr:0.00010000000010050991)
49230: accuracy:0.19 loss: 252.395 (lr:0.00010000000010000862)
49240: accuracy:0.23 loss: 245.539 (lr:0.00010000000009950983)
49250: accuracy:0.36 loss: 225.765 (lr:0.00010000000009901352)
49260: accuracy:0.33 loss: 225.584 (lr:0.00010000000009851968)
49270: accuracy:0.28 loss: 238.332 (lr:0.00010000000009802832)
49280: accuracy:0.33 loss: 237.986 (lr:0.0001000000000975394)
49290: accuracy:0.3 loss: 237.403 (lr:0.00010000000009705292)
49300: accuracy:0.26 loss: 239.856 (lr:0.00010000000009656886)
49310: accuracy:0.27 loss: 235.867 (lr:0.00010000000009608722)
49320: accuracy:0.2 loss: 246.513 (lr:0.00010000000009560799)
49330: accuracy:0.29 loss: 220.626 (lr:0.00010000000009513114)
49340: accuracy:0.29 loss: 220.229 (lr:0.00010000000009465667)
49350: accuracy:0.23 loss: 235.218 (lr:0.00010000000009418457)
49360: accuracy:0.24 loss: 240.029 (lr:0.00010000000009371482)
49370: accuracy:0.29 loss: 257.53 (lr:0.00010000000009324742)
49380: accuracy:0.31 loss: 225.115 (lr:0.00010000000009278234)
49390: accuracy:0.29 loss: 225.739 (lr:0.00010000000009231959)
49400: accuracy:0.29 loss: 231.453 (lr:0.00010000000009185914)
49410: accuracy:0.32 loss: 223.741 (lr:0.000100000000091401)
49420: accuracy:0.27 loss: 227.184 (lr:0.00010000000009094513)
49430: accuracy:0.2 loss: 246.018 (lr:0.00010000000009049154)
49440: accuracy:0.24 loss: 219.096 (lr:0.00010000000009004022)
49450: accuracy:0.25 loss: 236.644 (lr:0.00010000000008959114)
49460: accuracy:0.28 loss: 229.132 (lr:0.0001000000000891443)
49470: accuracy:0.29 loss: 251.07 (lr:0.00010000000008869968)
49480: accuracy:0.32 loss: 219.105 (lr:0.0001000000000882573)
49490: accuracy:0.32 loss: 214.247 (lr:0.00010000000008781711)
49500: accuracy:0.23 loss: 237.439 (lr:0.00010000000008737912)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
49500: ********* epoch 6 ********* test accuracy for all:0.22527 test loss: 261.869
49500: ********* epoch 6 ********* test accuracy for mode 0:0.0005 test loss: 402.188
49500: ********* epoch 6 ********* test accuracy for mode 1:0.1035 test loss: 378.12
49500: ********* epoch 6 ********* test accuracy for mode 2:0.076 test loss: 283.997
49500: ********* epoch 6 ********* test accuracy for mode 24:0.231 test loss: 273.786
49500: ********* epoch 6 ********* test accuracy for mode 25:0.2675 test loss: 255.34
49500: ********* epoch 6 ********* test accuracy for mode 26:0.3195 test loss: 188.881
49500: ********* epoch 6 ********* test accuracy for mode 27:0.2525 test loss: 279.123
49500: ********* epoch 6 ********* test accuracy for mode 28:0.2325 test loss: 269.689
49500: ********* epoch 6 ********* test accuracy for mode 29:0.275 test loss: 272.18
49500: ********* epoch 6 ********* test accuracy for mode 30:0.183 test loss: 270.749
49500: ********* epoch 6 ********* test accuracy for mode 31:0.2525 test loss: 266.434
49500: ********* epoch 6 ********* test accuracy for mode 32:0.143 test loss: 261.556
49500: ********* epoch 6 ********* test accuracy for mode 33:0.247 test loss: 268.697
49500: ********* epoch 6 ********* test accuracy for mode 34:0.065 test loss: 271.074
49500: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 404.604
49500: ********* epoch 6 ********* test accuracy for mode 36:0.0285 test loss: 420.021
49510: accuracy:0.3 loss: 225.331 (lr:0.00010000000008694332)
49520: accuracy:0.26 loss: 219.225 (lr:0.00010000000008650969)
49530: accuracy:0.36 loss: 231.327 (lr:0.00010000000008607822)
49540: accuracy:0.19 loss: 237.313 (lr:0.0001000000000856489)
49550: accuracy:0.29 loss: 236.743 (lr:0.00010000000008522172)
49560: accuracy:0.32 loss: 222.379 (lr:0.00010000000008479668)
49570: accuracy:0.3 loss: 232.197 (lr:0.00010000000008437376)
49580: accuracy:0.25 loss: 224.977 (lr:0.00010000000008395294)
49590: accuracy:0.27 loss: 237.737 (lr:0.00010000000008353422)
49600: accuracy:0.28 loss: 244.857 (lr:0.00010000000008311759)
49610: accuracy:0.28 loss: 230.604 (lr:0.00010000000008270304)
49620: accuracy:0.28 loss: 233.948 (lr:0.00010000000008229056)
49630: accuracy:0.21 loss: 252.43 (lr:0.00010000000008188013)
49640: accuracy:0.25 loss: 240.787 (lr:0.00010000000008147175)
49650: accuracy:0.21 loss: 249.328 (lr:0.00010000000008106541)
49660: accuracy:0.25 loss: 222.182 (lr:0.0001000000000806611)
49670: accuracy:0.32 loss: 243.135 (lr:0.0001000000000802588)
49680: accuracy:0.28 loss: 243.94 (lr:0.0001000000000798585)
49690: accuracy:0.34 loss: 222.171 (lr:0.0001000000000794602)
49700: accuracy:0.29 loss: 247.644 (lr:0.0001000000000790639)
49710: accuracy:0.28 loss: 237.51 (lr:0.00010000000007866957)
49720: accuracy:0.32 loss: 238.109 (lr:0.0001000000000782772)
49730: accuracy:0.24 loss: 228.531 (lr:0.00010000000007788678)
49740: accuracy:0.34 loss: 223.928 (lr:0.00010000000007749833)
49750: accuracy:0.34 loss: 229.442 (lr:0.00010000000007711181)
49760: accuracy:0.17 loss: 239.201 (lr:0.0001000000000767272)
49770: accuracy:0.26 loss: 239.203 (lr:0.00010000000007634453)
49780: accuracy:0.24 loss: 255.356 (lr:0.00010000000007596376)
49790: accuracy:0.27 loss: 242.574 (lr:0.00010000000007558489)
49800: accuracy:0.25 loss: 245.326 (lr:0.00010000000007520791)
49810: accuracy:0.2 loss: 237.826 (lr:0.0001000000000748328)
49820: accuracy:0.3 loss: 221.318 (lr:0.00010000000007445958)
49830: accuracy:0.24 loss: 246.196 (lr:0.00010000000007408821)
49840: accuracy:0.26 loss: 218.486 (lr:0.00010000000007371869)
49850: accuracy:0.27 loss: 237.633 (lr:0.00010000000007335101)
49860: accuracy:0.19 loss: 252.89 (lr:0.00010000000007298517)
49870: accuracy:0.38 loss: 235.746 (lr:0.00010000000007262117)
49880: accuracy:0.31 loss: 242.825 (lr:0.00010000000007225896)
49890: accuracy:0.27 loss: 233.487 (lr:0.00010000000007189857)
49900: accuracy:0.35 loss: 238.514 (lr:0.00010000000007153997)
49910: accuracy:0.22 loss: 238.87 (lr:0.00010000000007118316)
49920: accuracy:0.3 loss: 230.264 (lr:0.00010000000007082814)
49930: accuracy:0.39 loss: 215.424 (lr:0.00010000000007047488)
49940: accuracy:0.27 loss: 235.637 (lr:0.00010000000007012338)
49950: accuracy:0.27 loss: 240.922 (lr:0.00010000000006977365)
49960: accuracy:0.3 loss: 237.457 (lr:0.00010000000006942564)
49970: accuracy:0.27 loss: 227.967 (lr:0.00010000000006907939)
49980: accuracy:0.29 loss: 238.101 (lr:0.00010000000006873486)
49990: accuracy:0.33 loss: 226.552 (lr:0.00010000000006839203)
50000: accuracy:0.25 loss: 255.009 (lr:0.00010000000006805093)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
50000: ********* epoch 6 ********* test accuracy for all:0.226824 test loss: 262.545
50000: ********* epoch 6 ********* test accuracy for mode 0:0.0 test loss: 401.3
50000: ********* epoch 6 ********* test accuracy for mode 1:0.103 test loss: 374.864
50000: ********* epoch 6 ********* test accuracy for mode 2:0.0365 test loss: 287.619
50000: ********* epoch 6 ********* test accuracy for mode 24:0.2125 test loss: 279.475
50000: ********* epoch 6 ********* test accuracy for mode 25:0.2975 test loss: 256.009
50000: ********* epoch 6 ********* test accuracy for mode 26:0.292 test loss: 187.131
50000: ********* epoch 6 ********* test accuracy for mode 27:0.2645 test loss: 276.803
50000: ********* epoch 6 ********* test accuracy for mode 28:0.264 test loss: 263.858
50000: ********* epoch 6 ********* test accuracy for mode 29:0.2785 test loss: 270.0
50000: ********* epoch 6 ********* test accuracy for mode 30:0.222 test loss: 264.078
50000: ********* epoch 6 ********* test accuracy for mode 31:0.2215 test loss: 268.598
50000: ********* epoch 6 ********* test accuracy for mode 32:0.185 test loss: 260.759
50000: ********* epoch 6 ********* test accuracy for mode 33:0.152 test loss: 270.143
50000: ********* epoch 6 ********* test accuracy for mode 34:0.24 test loss: 260.275
50000: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 399.301
50000: ********* epoch 6 ********* test accuracy for mode 36:0.0245 test loss: 411.168
50010: accuracy:0.3 loss: 260.783 (lr:0.00010000000006771152)
50020: accuracy:0.33 loss: 245.758 (lr:0.0001000000000673738)
50030: accuracy:0.2 loss: 241.627 (lr:0.00010000000006703778)
50040: accuracy:0.26 loss: 252.649 (lr:0.00010000000006670343)
50050: accuracy:0.3 loss: 229.315 (lr:0.00010000000006637074)
50060: accuracy:0.28 loss: 243.681 (lr:0.00010000000006603972)
50070: accuracy:0.29 loss: 225.741 (lr:0.00010000000006571034)
50080: accuracy:0.31 loss: 233.451 (lr:0.00010000000006538261)
50090: accuracy:0.26 loss: 228.008 (lr:0.00010000000006505651)
50100: accuracy:0.25 loss: 245.116 (lr:0.00010000000006473205)
50110: accuracy:0.19 loss: 247.817 (lr:0.00010000000006440919)
50120: accuracy:0.21 loss: 248.458 (lr:0.00010000000006408795)
50130: accuracy:0.27 loss: 233.183 (lr:0.00010000000006376832)
50140: accuracy:0.27 loss: 230.142 (lr:0.00010000000006345027)
50150: accuracy:0.32 loss: 220.707 (lr:0.0001000000000631338)
50160: accuracy:0.25 loss: 220.113 (lr:0.00010000000006281892)
50170: accuracy:0.25 loss: 244.724 (lr:0.00010000000006250562)
50180: accuracy:0.26 loss: 218.171 (lr:0.00010000000006219387)
50190: accuracy:0.28 loss: 222.706 (lr:0.00010000000006188368)
50200: accuracy:0.34 loss: 212.328 (lr:0.00010000000006157503)
50210: accuracy:0.31 loss: 214.474 (lr:0.00010000000006126792)
50220: accuracy:0.31 loss: 238.436 (lr:0.00010000000006096235)
50230: accuracy:0.26 loss: 221.076 (lr:0.0001000000000606583)
50240: accuracy:0.26 loss: 233.007 (lr:0.00010000000006035576)
50250: accuracy:0.2 loss: 238.349 (lr:0.00010000000006005474)
50260: accuracy:0.36 loss: 240.06 (lr:0.00010000000005975521)
50270: accuracy:0.24 loss: 239.886 (lr:0.00010000000005945718)
50280: accuracy:0.22 loss: 276.111 (lr:0.00010000000005916063)
50290: accuracy:0.26 loss: 230.05 (lr:0.00010000000005886557)
50300: accuracy:0.3 loss: 227.649 (lr:0.00010000000005857198)
50310: accuracy:0.3 loss: 237.069 (lr:0.00010000000005827986)
50320: accuracy:0.29 loss: 238.454 (lr:0.00010000000005798918)
50330: accuracy:0.25 loss: 237.129 (lr:0.00010000000005769996)
50340: accuracy:0.29 loss: 242.157 (lr:0.00010000000005741218)
50350: accuracy:0.32 loss: 238.719 (lr:0.00010000000005712583)
50360: accuracy:0.31 loss: 233.343 (lr:0.00010000000005684092)
50370: accuracy:0.21 loss: 249.535 (lr:0.00010000000005655742)
50380: accuracy:0.28 loss: 218.156 (lr:0.00010000000005627534)
50390: accuracy:0.33 loss: 233.684 (lr:0.00010000000005599467)
50400: accuracy:0.17 loss: 247.133 (lr:0.00010000000005571539)
50410: accuracy:0.31 loss: 236.269 (lr:0.00010000000005543751)
50420: accuracy:0.28 loss: 237.318 (lr:0.00010000000005516101)
50430: accuracy:0.29 loss: 224.745 (lr:0.0001000000000548859)
50440: accuracy:0.26 loss: 224.658 (lr:0.00010000000005461215)
50450: accuracy:0.31 loss: 234.003 (lr:0.00010000000005433977)
50460: accuracy:0.32 loss: 233.161 (lr:0.00010000000005406875)
50470: accuracy:0.27 loss: 232.09 (lr:0.00010000000005379908)
50480: accuracy:0.23 loss: 234.193 (lr:0.00010000000005353075)
50490: accuracy:0.3 loss: 238.359 (lr:0.00010000000005326377)
50500: accuracy:0.24 loss: 249.542 (lr:0.00010000000005299812)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
50500: ********* epoch 6 ********* test accuracy for all:0.226081 test loss: 261.273
50500: ********* epoch 6 ********* test accuracy for mode 0:0.0015 test loss: 399.401
50500: ********* epoch 6 ********* test accuracy for mode 1:0.097 test loss: 376.216
50500: ********* epoch 6 ********* test accuracy for mode 2:0.0355 test loss: 287.629
50500: ********* epoch 6 ********* test accuracy for mode 24:0.25 test loss: 266.988
50500: ********* epoch 6 ********* test accuracy for mode 25:0.319 test loss: 250.863
50500: ********* epoch 6 ********* test accuracy for mode 26:0.2955 test loss: 187.612
50500: ********* epoch 6 ********* test accuracy for mode 27:0.2595 test loss: 277.122
50500: ********* epoch 6 ********* test accuracy for mode 28:0.251 test loss: 262.721
50500: ********* epoch 6 ********* test accuracy for mode 29:0.254 test loss: 266.152
50500: ********* epoch 6 ********* test accuracy for mode 30:0.2435 test loss: 260.473
50500: ********* epoch 6 ********* test accuracy for mode 31:0.1805 test loss: 265.358
50500: ********* epoch 6 ********* test accuracy for mode 32:0.199 test loss: 256.482
50500: ********* epoch 6 ********* test accuracy for mode 33:0.2495 test loss: 263.809
50500: ********* epoch 6 ********* test accuracy for mode 34:0.1235 test loss: 264.972
50500: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 407.725
50500: ********* epoch 6 ********* test accuracy for mode 36:0.0265 test loss: 405.105
50510: accuracy:0.33 loss: 223.675 (lr:0.0001000000000527338)
50520: accuracy:0.34 loss: 214.863 (lr:0.00010000000005247078)
50530: accuracy:0.26 loss: 244.861 (lr:0.00010000000005220908)
50540: accuracy:0.27 loss: 255.213 (lr:0.00010000000005194868)
50550: accuracy:0.26 loss: 228.277 (lr:0.00010000000005168959)
50560: accuracy:0.31 loss: 225.522 (lr:0.00010000000005143179)
50570: accuracy:0.22 loss: 237.696 (lr:0.00010000000005117527)
50580: accuracy:0.23 loss: 235.653 (lr:0.00010000000005092003)
50590: accuracy:0.28 loss: 230.077 (lr:0.00010000000005066607)
50600: accuracy:0.25 loss: 236.515 (lr:0.00010000000005041337)
50610: accuracy:0.25 loss: 229.567 (lr:0.00010000000005016193)
50620: accuracy:0.35 loss: 229.9 (lr:0.00010000000004991175)
50630: accuracy:0.29 loss: 228.413 (lr:0.00010000000004966281)
50640: accuracy:0.34 loss: 229.026 (lr:0.00010000000004941512)
50650: accuracy:0.32 loss: 226.629 (lr:0.00010000000004916865)
50660: accuracy:0.32 loss: 223.942 (lr:0.00010000000004892344)
50670: accuracy:0.25 loss: 230.83 (lr:0.00010000000004867942)
50680: accuracy:0.29 loss: 214.051 (lr:0.00010000000004843663)
50690: accuracy:0.26 loss: 248.942 (lr:0.00010000000004819505)
50700: accuracy:0.26 loss: 223.878 (lr:0.00010000000004795469)
50710: accuracy:0.32 loss: 229.911 (lr:0.00010000000004771551)
50720: accuracy:0.32 loss: 229.286 (lr:0.00010000000004747753)
50730: accuracy:0.37 loss: 209.495 (lr:0.00010000000004724073)
50740: accuracy:0.3 loss: 233.313 (lr:0.00010000000004700512)
50750: accuracy:0.33 loss: 227.636 (lr:0.00010000000004677067)
50760: accuracy:0.23 loss: 246.797 (lr:0.0001000000000465374)
50770: accuracy:0.33 loss: 216.504 (lr:0.0001000000000463053)
50780: accuracy:0.31 loss: 251.237 (lr:0.00010000000004607436)
50790: accuracy:0.34 loss: 218.351 (lr:0.00010000000004584456)
50800: accuracy:0.25 loss: 239.157 (lr:0.0001000000000456159)
50810: accuracy:0.22 loss: 239.432 (lr:0.0001000000000453884)
50820: accuracy:0.28 loss: 222.116 (lr:0.00010000000004516201)
50830: accuracy:0.29 loss: 241.018 (lr:0.00010000000004493677)
50840: accuracy:0.32 loss: 220.477 (lr:0.00010000000004471265)
50850: accuracy:0.28 loss: 224.171 (lr:0.00010000000004448964)
50860: accuracy:0.28 loss: 234.348 (lr:0.00010000000004426775)
50870: accuracy:0.23 loss: 238.133 (lr:0.00010000000004404696)
50880: accuracy:0.19 loss: 246.181 (lr:0.00010000000004382728)
50890: accuracy:0.25 loss: 237.762 (lr:0.00010000000004360869)
50900: accuracy:0.33 loss: 234.521 (lr:0.00010000000004339119)
50910: accuracy:0.3 loss: 234.501 (lr:0.00010000000004317478)
50920: accuracy:0.32 loss: 235.956 (lr:0.00010000000004295944)
50930: accuracy:0.23 loss: 231.534 (lr:0.00010000000004274518)
50940: accuracy:0.25 loss: 231.53 (lr:0.00010000000004253198)
50950: accuracy:0.3 loss: 219.67 (lr:0.00010000000004231986)
50960: accuracy:0.31 loss: 240.963 (lr:0.00010000000004210879)
50970: accuracy:0.25 loss: 239.557 (lr:0.00010000000004189877)
50980: accuracy:0.33 loss: 221.883 (lr:0.0001000000000416898)
50990: accuracy:0.27 loss: 240.15 (lr:0.00010000000004148186)
51000: accuracy:0.3 loss: 234.761 (lr:0.00010000000004127497)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
51000: ********* epoch 6 ********* test accuracy for all:0.226635 test loss: 261.688
51000: ********* epoch 6 ********* test accuracy for mode 0:0.0015 test loss: 405.888
51000: ********* epoch 6 ********* test accuracy for mode 1:0.0965 test loss: 375.549
51000: ********* epoch 6 ********* test accuracy for mode 2:0.083 test loss: 275.724
51000: ********* epoch 6 ********* test accuracy for mode 24:0.2235 test loss: 264.173
51000: ********* epoch 6 ********* test accuracy for mode 25:0.3425 test loss: 241.594
51000: ********* epoch 6 ********* test accuracy for mode 26:0.321 test loss: 179.656
51000: ********* epoch 6 ********* test accuracy for mode 27:0.28 test loss: 262.381
51000: ********* epoch 6 ********* test accuracy for mode 28:0.267 test loss: 253.863
51000: ********* epoch 6 ********* test accuracy for mode 29:0.266 test loss: 261.841
51000: ********* epoch 6 ********* test accuracy for mode 30:0.199 test loss: 261.78
51000: ********* epoch 6 ********* test accuracy for mode 31:0.183 test loss: 262.952
51000: ********* epoch 6 ********* test accuracy for mode 32:0.2025 test loss: 253.496
51000: ********* epoch 6 ********* test accuracy for mode 33:0.2585 test loss: 259.972
51000: ********* epoch 6 ********* test accuracy for mode 34:0.071 test loss: 261.829
51000: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 404.584
51000: ********* epoch 6 ********* test accuracy for mode 36:0.0465 test loss: 424.781
51010: accuracy:0.31 loss: 227.544 (lr:0.00010000000004106912)
51020: accuracy:0.22 loss: 236.554 (lr:0.00010000000004086429)
51030: accuracy:0.32 loss: 239.319 (lr:0.00010000000004066047)
51040: accuracy:0.27 loss: 238.129 (lr:0.00010000000004045767)
51050: accuracy:0.31 loss: 251.418 (lr:0.00010000000004025589)
51060: accuracy:0.31 loss: 230.795 (lr:0.00010000000004005512)
51070: accuracy:0.25 loss: 220.336 (lr:0.00010000000003985534)
51080: accuracy:0.26 loss: 226.355 (lr:0.00010000000003965656)
51090: accuracy:0.3 loss: 221.258 (lr:0.00010000000003945877)
51100: accuracy:0.32 loss: 229.997 (lr:0.00010000000003926197)
51110: accuracy:0.29 loss: 213.994 (lr:0.00010000000003906615)
51120: accuracy:0.24 loss: 240.578 (lr:0.00010000000003887131)
51130: accuracy:0.24 loss: 238.716 (lr:0.00010000000003867744)
51140: accuracy:0.29 loss: 219.96 (lr:0.00010000000003848453)
51150: accuracy:0.35 loss: 222.09 (lr:0.00010000000003829259)
51160: accuracy:0.27 loss: 226.874 (lr:0.0001000000000381016)
51170: accuracy:0.29 loss: 242.391 (lr:0.00010000000003791157)
51180: accuracy:0.28 loss: 219.861 (lr:0.00010000000003772249)
51190: accuracy:0.26 loss: 224.183 (lr:0.00010000000003753435)
51200: accuracy:0.26 loss: 227.013 (lr:0.00010000000003734714)
51210: accuracy:0.27 loss: 236.019 (lr:0.00010000000003716087)
51220: accuracy:0.28 loss: 248.525 (lr:0.00010000000003697553)
51230: accuracy:0.19 loss: 261.594 (lr:0.00010000000003679112)
51240: accuracy:0.3 loss: 223.519 (lr:0.00010000000003660762)
51250: accuracy:0.37 loss: 212.009 (lr:0.00010000000003642504)
51260: accuracy:0.28 loss: 234.439 (lr:0.00010000000003624337)
51270: accuracy:0.33 loss: 234.766 (lr:0.0001000000000360626)
51280: accuracy:0.34 loss: 233.258 (lr:0.00010000000003588275)
51290: accuracy:0.31 loss: 225.664 (lr:0.00010000000003570377)
51300: accuracy:0.27 loss: 231.016 (lr:0.0001000000000355257)
51310: accuracy:0.24 loss: 234.588 (lr:0.00010000000003534852)
51320: accuracy:0.29 loss: 229.883 (lr:0.00010000000003517221)
51330: accuracy:0.32 loss: 258.17 (lr:0.00010000000003499679)
51340: accuracy:0.28 loss: 231.246 (lr:0.00010000000003482225)
51350: accuracy:0.29 loss: 250.245 (lr:0.00010000000003464857)
51360: accuracy:0.31 loss: 237.453 (lr:0.00010000000003447576)
51370: accuracy:0.29 loss: 242.535 (lr:0.00010000000003430381)
51380: accuracy:0.25 loss: 231.52 (lr:0.00010000000003413272)
51390: accuracy:0.26 loss: 230.819 (lr:0.00010000000003396249)
51400: accuracy:0.25 loss: 225.103 (lr:0.0001000000000337931)
51410: accuracy:0.26 loss: 237.996 (lr:0.00010000000003362456)
51420: accuracy:0.29 loss: 233.488 (lr:0.00010000000003345684)
51430: accuracy:0.22 loss: 265.328 (lr:0.00010000000003328999)
51440: accuracy:0.31 loss: 221.399 (lr:0.00010000000003312394)
51450: accuracy:0.36 loss: 201.285 (lr:0.00010000000003295873)
51460: accuracy:0.24 loss: 223.414 (lr:0.00010000000003279436)
51470: accuracy:0.23 loss: 240.474 (lr:0.00010000000003263079)
51480: accuracy:0.24 loss: 233.864 (lr:0.00010000000003246805)
51490: accuracy:0.24 loss: 231.847 (lr:0.00010000000003230611)
51500: accuracy:0.27 loss: 228.944 (lr:0.00010000000003214499)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
51500: ********* epoch 6 ********* test accuracy for all:0.228189 test loss: 262.633
51500: ********* epoch 6 ********* test accuracy for mode 0:0.0035 test loss: 408.524
51500: ********* epoch 6 ********* test accuracy for mode 1:0.0925 test loss: 380.284
51500: ********* epoch 6 ********* test accuracy for mode 2:0.0335 test loss: 282.84
51500: ********* epoch 6 ********* test accuracy for mode 24:0.23 test loss: 274.474
51500: ********* epoch 6 ********* test accuracy for mode 25:0.3355 test loss: 248.468
51500: ********* epoch 6 ********* test accuracy for mode 26:0.3315 test loss: 179.742
51500: ********* epoch 6 ********* test accuracy for mode 27:0.2945 test loss: 266.593
51500: ********* epoch 6 ********* test accuracy for mode 28:0.2315 test loss: 261.633
51500: ********* epoch 6 ********* test accuracy for mode 29:0.3045 test loss: 266.001
51500: ********* epoch 6 ********* test accuracy for mode 30:0.202 test loss: 263.717
51500: ********* epoch 6 ********* test accuracy for mode 31:0.203 test loss: 267.819
51500: ********* epoch 6 ********* test accuracy for mode 32:0.204 test loss: 255.66
51500: ********* epoch 6 ********* test accuracy for mode 33:0.22 test loss: 263.528
51500: ********* epoch 6 ********* test accuracy for mode 34:0.147 test loss: 260.724
51500: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 413.151
51500: ********* epoch 6 ********* test accuracy for mode 36:0.0205 test loss: 428.516
51510: accuracy:0.22 loss: 233.084 (lr:0.00010000000003198466)
51520: accuracy:0.31 loss: 229.105 (lr:0.00010000000003182513)
51530: accuracy:0.31 loss: 230.407 (lr:0.0001000000000316664)
51540: accuracy:0.3 loss: 242.776 (lr:0.00010000000003150848)
51550: accuracy:0.23 loss: 233.308 (lr:0.00010000000003135132)
51560: accuracy:0.25 loss: 238.873 (lr:0.00010000000003119495)
51570: accuracy:0.25 loss: 240.715 (lr:0.00010000000003103937)
51580: accuracy:0.26 loss: 238.885 (lr:0.00010000000003088456)
51590: accuracy:0.2 loss: 246.438 (lr:0.00010000000003073052)
51600: accuracy:0.31 loss: 231.344 (lr:0.00010000000003057726)
51610: accuracy:0.35 loss: 208.993 (lr:0.00010000000003042475)
51620: accuracy:0.21 loss: 259.098 (lr:0.000100000000030273)
51630: accuracy:0.25 loss: 229.531 (lr:0.00010000000003012201)
51640: accuracy:0.34 loss: 229.35 (lr:0.00010000000002997178)
51650: accuracy:0.23 loss: 250.525 (lr:0.0001000000000298223)
51660: accuracy:0.23 loss: 239.101 (lr:0.00010000000002967356)
51670: accuracy:0.21 loss: 240.314 (lr:0.00010000000002952557)
51680: accuracy:0.22 loss: 254.688 (lr:0.0001000000000293783)
51690: accuracy:0.27 loss: 244.384 (lr:0.00010000000002923178)
51700: accuracy:0.27 loss: 246.582 (lr:0.00010000000002908599)
51710: accuracy:0.2 loss: 249.33 (lr:0.00010000000002894093)
51720: accuracy:0.27 loss: 238.483 (lr:0.00010000000002879658)
51730: accuracy:0.18 loss: 242.64 (lr:0.00010000000002865295)
51740: accuracy:0.39 loss: 224.224 (lr:0.00010000000002851005)
51750: accuracy:0.33 loss: 215.599 (lr:0.00010000000002836786)
51760: accuracy:0.19 loss: 249.477 (lr:0.00010000000002822637)
51770: accuracy:0.18 loss: 243.498 (lr:0.00010000000002808558)
51780: accuracy:0.25 loss: 225.009 (lr:0.0001000000000279455)
51790: accuracy:0.28 loss: 232.586 (lr:0.00010000000002780613)
51800: accuracy:0.24 loss: 238.426 (lr:0.00010000000002766745)
51810: accuracy:0.28 loss: 237.969 (lr:0.00010000000002752946)
51820: accuracy:0.24 loss: 243.314 (lr:0.00010000000002739216)
51830: accuracy:0.25 loss: 246.648 (lr:0.00010000000002725553)
51840: accuracy:0.35 loss: 228.402 (lr:0.00010000000002711959)
51850: accuracy:0.24 loss: 241.487 (lr:0.00010000000002698433)
51860: accuracy:0.38 loss: 215.026 (lr:0.00010000000002684974)
51870: accuracy:0.26 loss: 242.293 (lr:0.00010000000002671583)
51880: accuracy:0.34 loss: 232.075 (lr:0.0001000000000265826)
51890: accuracy:0.23 loss: 223.642 (lr:0.00010000000002645001)
51900: accuracy:0.32 loss: 224.264 (lr:0.00010000000002631809)
51910: accuracy:0.32 loss: 237.321 (lr:0.00010000000002618682)
51920: accuracy:0.25 loss: 221.738 (lr:0.00010000000002605622)
51930: accuracy:0.19 loss: 248.682 (lr:0.00010000000002592626)
51940: accuracy:0.2 loss: 228.812 (lr:0.00010000000002579696)
51950: accuracy:0.3 loss: 246.977 (lr:0.00010000000002566829)
51960: accuracy:0.22 loss: 249.51 (lr:0.00010000000002554027)
51970: accuracy:0.36 loss: 215.303 (lr:0.00010000000002541289)
51980: accuracy:0.29 loss: 231.035 (lr:0.00010000000002528615)
51990: accuracy:0.28 loss: 242.557 (lr:0.00010000000002516003)
52000: accuracy:0.3 loss: 226.57 (lr:0.00010000000002503454)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
52000: ********* epoch 6 ********* test accuracy for all:0.229149 test loss: 260.761
52000: ********* epoch 6 ********* test accuracy for mode 0:0.0015 test loss: 404.1
52000: ********* epoch 6 ********* test accuracy for mode 1:0.094 test loss: 381.016
52000: ********* epoch 6 ********* test accuracy for mode 2:0.041 test loss: 276.895
52000: ********* epoch 6 ********* test accuracy for mode 24:0.2255 test loss: 272.055
52000: ********* epoch 6 ********* test accuracy for mode 25:0.285 test loss: 256.574
52000: ********* epoch 6 ********* test accuracy for mode 26:0.426 test loss: 181.341
52000: ********* epoch 6 ********* test accuracy for mode 27:0.203 test loss: 281.269
52000: ********* epoch 6 ********* test accuracy for mode 28:0.2965 test loss: 261.725
52000: ********* epoch 6 ********* test accuracy for mode 29:0.2885 test loss: 266.681
52000: ********* epoch 6 ********* test accuracy for mode 30:0.2075 test loss: 262.748
52000: ********* epoch 6 ********* test accuracy for mode 31:0.2005 test loss: 263.95
52000: ********* epoch 6 ********* test accuracy for mode 32:0.1615 test loss: 256.18
52000: ********* epoch 6 ********* test accuracy for mode 33:0.2525 test loss: 259.058
52000: ********* epoch 6 ********* test accuracy for mode 34:0.1285 test loss: 258.532
52000: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 390.707
52000: ********* epoch 6 ********* test accuracy for mode 36:0.017 test loss: 415.903
52010: accuracy:0.12 loss: 245.599 (lr:0.00010000000002490969)
52020: accuracy:0.27 loss: 238.631 (lr:0.00010000000002478545)
52030: accuracy:0.3 loss: 225.049 (lr:0.00010000000002466182)
52040: accuracy:0.33 loss: 231.653 (lr:0.00010000000002453882)
52050: accuracy:0.27 loss: 232.204 (lr:0.00010000000002441644)
52060: accuracy:0.23 loss: 239.922 (lr:0.00010000000002429466)
52070: accuracy:0.31 loss: 227.662 (lr:0.00010000000002417348)
52080: accuracy:0.27 loss: 246.381 (lr:0.00010000000002405292)
52090: accuracy:0.29 loss: 240.414 (lr:0.00010000000002393295)
52100: accuracy:0.27 loss: 234.297 (lr:0.0001000000000238136)
52110: accuracy:0.22 loss: 246.638 (lr:0.00010000000002369482)
52120: accuracy:0.28 loss: 234.052 (lr:0.00010000000002357665)
52130: accuracy:0.33 loss: 221.206 (lr:0.00010000000002345905)
52140: accuracy:0.29 loss: 229.394 (lr:0.00010000000002334205)
52150: accuracy:0.28 loss: 239.962 (lr:0.00010000000002322563)
52160: accuracy:0.22 loss: 228.601 (lr:0.00010000000002310979)
52170: accuracy:0.34 loss: 226.914 (lr:0.00010000000002299454)
52180: accuracy:0.25 loss: 236.298 (lr:0.00010000000002287984)
52190: accuracy:0.25 loss: 218.441 (lr:0.00010000000002276573)
52200: accuracy:0.32 loss: 220.739 (lr:0.00010000000002265219)
52210: accuracy:0.17 loss: 261.117 (lr:0.00010000000002253921)
52220: accuracy:0.26 loss: 234.622 (lr:0.0001000000000224268)
52230: accuracy:0.28 loss: 231.346 (lr:0.00010000000002231495)
52240: accuracy:0.4 loss: 207.154 (lr:0.00010000000002220365)
52250: accuracy:0.28 loss: 239.789 (lr:0.0001000000000220929)
52260: accuracy:0.23 loss: 237.434 (lr:0.00010000000002198272)
52270: accuracy:0.33 loss: 236.838 (lr:0.00010000000002187308)
52280: accuracy:0.33 loss: 230.692 (lr:0.00010000000002176398)
52290: accuracy:0.24 loss: 236.387 (lr:0.00010000000002165544)
52300: accuracy:0.22 loss: 258.044 (lr:0.00010000000002154743)
52310: accuracy:0.32 loss: 226.504 (lr:0.00010000000002143997)
52320: accuracy:0.26 loss: 247.612 (lr:0.00010000000002133302)
52330: accuracy:0.27 loss: 244.031 (lr:0.00010000000002122664)
52340: accuracy:0.23 loss: 221.959 (lr:0.00010000000002112076)
52350: accuracy:0.22 loss: 240.375 (lr:0.00010000000002101542)
52360: accuracy:0.26 loss: 266.905 (lr:0.0001000000000209106)
52370: accuracy:0.31 loss: 239.296 (lr:0.00010000000002080632)
52380: accuracy:0.32 loss: 248.831 (lr:0.00010000000002070255)
52390: accuracy:0.3 loss: 236.958 (lr:0.00010000000002059929)
52400: accuracy:0.28 loss: 225.991 (lr:0.00010000000002049655)
52410: accuracy:0.27 loss: 232.226 (lr:0.00010000000002039432)
52420: accuracy:0.27 loss: 234.889 (lr:0.00010000000002029261)
52430: accuracy:0.29 loss: 230.341 (lr:0.0001000000000201914)
52440: accuracy:0.28 loss: 236.48 (lr:0.00010000000002009069)
52450: accuracy:0.3 loss: 237.141 (lr:0.00010000000001999048)
52460: accuracy:0.33 loss: 232.87 (lr:0.00010000000001989079)
52470: accuracy:0.28 loss: 223.187 (lr:0.00010000000001979157)
52480: accuracy:0.29 loss: 239.428 (lr:0.00010000000001969287)
52490: accuracy:0.32 loss: 224.032 (lr:0.00010000000001959466)
52500: accuracy:0.3 loss: 216.313 (lr:0.00010000000001949693)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
52500: ********* epoch 6 ********* test accuracy for all:0.22473 test loss: 261.684
52500: ********* epoch 6 ********* test accuracy for mode 0:0.0005 test loss: 404.385
52500: ********* epoch 6 ********* test accuracy for mode 1:0.094 test loss: 373.927
52500: ********* epoch 6 ********* test accuracy for mode 2:0.069 test loss: 277.454
52500: ********* epoch 6 ********* test accuracy for mode 24:0.209 test loss: 263.383
52500: ********* epoch 6 ********* test accuracy for mode 25:0.356 test loss: 240.616
52500: ********* epoch 6 ********* test accuracy for mode 26:0.298 test loss: 182.509
52500: ********* epoch 6 ********* test accuracy for mode 27:0.263 test loss: 261.153
52500: ********* epoch 6 ********* test accuracy for mode 28:0.2605 test loss: 248.551
52500: ********* epoch 6 ********* test accuracy for mode 29:0.301 test loss: 252.314
52500: ********* epoch 6 ********* test accuracy for mode 30:0.232 test loss: 245.589
52500: ********* epoch 6 ********* test accuracy for mode 31:0.2845 test loss: 246.648
52500: ********* epoch 6 ********* test accuracy for mode 32:0.1445 test loss: 247.31
52500: ********* epoch 6 ********* test accuracy for mode 33:0.2725 test loss: 253.702
52500: ********* epoch 6 ********* test accuracy for mode 34:0.048 test loss: 262.92
52500: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 393.965
52500: ********* epoch 6 ********* test accuracy for mode 36:0.028 test loss: 424.319
52510: accuracy:0.24 loss: 251.641 (lr:0.00010000000001939967)
52520: accuracy:0.23 loss: 237.572 (lr:0.00010000000001930292)
52530: accuracy:0.29 loss: 227.542 (lr:0.00010000000001920665)
52540: accuracy:0.23 loss: 227.009 (lr:0.00010000000001911086)
52550: accuracy:0.26 loss: 234.728 (lr:0.00010000000001901554)
52560: accuracy:0.3 loss: 224.935 (lr:0.0001000000000189207)
52570: accuracy:0.32 loss: 221.319 (lr:0.00010000000001882634)
52580: accuracy:0.41 loss: 214.429 (lr:0.00010000000001873243)
52590: accuracy:0.22 loss: 239.306 (lr:0.00010000000001863901)
52600: accuracy:0.25 loss: 244.968 (lr:0.00010000000001854604)
52610: accuracy:0.24 loss: 244.051 (lr:0.00010000000001845355)
52620: accuracy:0.28 loss: 234.84 (lr:0.00010000000001836151)
52630: accuracy:0.24 loss: 237.189 (lr:0.00010000000001826994)
52640: accuracy:0.32 loss: 237.213 (lr:0.00010000000001817881)
52650: accuracy:0.35 loss: 224.587 (lr:0.00010000000001808814)
52660: accuracy:0.23 loss: 242.475 (lr:0.00010000000001799792)
52670: accuracy:0.18 loss: 252.211 (lr:0.00010000000001790817)
52680: accuracy:0.22 loss: 237.965 (lr:0.00010000000001781884)
52690: accuracy:0.28 loss: 243.426 (lr:0.00010000000001772998)
52700: accuracy:0.3 loss: 247.186 (lr:0.00010000000001764155)
52710: accuracy:0.26 loss: 227.798 (lr:0.00010000000001755356)
52720: accuracy:0.25 loss: 230.292 (lr:0.00010000000001746601)
52730: accuracy:0.2 loss: 254.843 (lr:0.0001000000000173789)
52740: accuracy:0.27 loss: 241.357 (lr:0.00010000000001729222)
52750: accuracy:0.24 loss: 241.774 (lr:0.00010000000001720597)
52760: accuracy:0.23 loss: 257.78 (lr:0.00010000000001712015)
52770: accuracy:0.34 loss: 217.235 (lr:0.00010000000001703477)
52780: accuracy:0.23 loss: 257.172 (lr:0.00010000000001694981)
52790: accuracy:0.31 loss: 217.832 (lr:0.00010000000001686527)
52800: accuracy:0.32 loss: 211.478 (lr:0.00010000000001678115)
52810: accuracy:0.31 loss: 228.109 (lr:0.00010000000001669746)
52820: accuracy:0.31 loss: 231.933 (lr:0.00010000000001661418)
52830: accuracy:0.28 loss: 227.671 (lr:0.00010000000001653132)
52840: accuracy:0.3 loss: 234.614 (lr:0.00010000000001644887)
52850: accuracy:0.29 loss: 229.232 (lr:0.00010000000001636682)
52860: accuracy:0.3 loss: 232.643 (lr:0.0001000000000162852)
52870: accuracy:0.21 loss: 227.173 (lr:0.00010000000001620398)
52880: accuracy:0.29 loss: 232.546 (lr:0.00010000000001612316)
52890: accuracy:0.28 loss: 228.626 (lr:0.00010000000001604274)
52900: accuracy:0.35 loss: 210.344 (lr:0.00010000000001596273)
52910: accuracy:0.29 loss: 234.638 (lr:0.00010000000001588312)
52920: accuracy:0.26 loss: 223.919 (lr:0.0001000000000158039)
52930: accuracy:0.32 loss: 220.457 (lr:0.00010000000001572507)
52940: accuracy:0.24 loss: 226.057 (lr:0.00010000000001564664)
52950: accuracy:0.26 loss: 218.608 (lr:0.0001000000000155686)
52960: accuracy:0.34 loss: 211.01 (lr:0.00010000000001549096)
52970: accuracy:0.27 loss: 237.702 (lr:0.0001000000000154137)
52980: accuracy:0.31 loss: 241.256 (lr:0.00010000000001533682)
52990: accuracy:0.21 loss: 242.879 (lr:0.00010000000001526033)
53000: accuracy:0.37 loss: 230.895 (lr:0.00010000000001518422)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
53000: ********* epoch 6 ********* test accuracy for all:0.227595 test loss: 261.53
53000: ********* epoch 6 ********* test accuracy for mode 0:0.0015 test loss: 408.176
53000: ********* epoch 6 ********* test accuracy for mode 1:0.0915 test loss: 380.545
53000: ********* epoch 6 ********* test accuracy for mode 2:0.061 test loss: 285.655
53000: ********* epoch 6 ********* test accuracy for mode 24:0.229 test loss: 273.889
53000: ********* epoch 6 ********* test accuracy for mode 25:0.3375 test loss: 246.478
53000: ********* epoch 6 ********* test accuracy for mode 26:0.2555 test loss: 185.089
53000: ********* epoch 6 ********* test accuracy for mode 27:0.279 test loss: 271.95
53000: ********* epoch 6 ********* test accuracy for mode 28:0.254 test loss: 262.45
53000: ********* epoch 6 ********* test accuracy for mode 29:0.3 test loss: 269.608
53000: ********* epoch 6 ********* test accuracy for mode 30:0.2095 test loss: 267.156
53000: ********* epoch 6 ********* test accuracy for mode 31:0.2015 test loss: 271.153
53000: ********* epoch 6 ********* test accuracy for mode 32:0.153 test loss: 262.451
53000: ********* epoch 6 ********* test accuracy for mode 33:0.2955 test loss: 262.651
53000: ********* epoch 6 ********* test accuracy for mode 34:0.0465 test loss: 267.756
53000: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 405.597
53000: ********* epoch 6 ********* test accuracy for mode 36:0.02 test loss: 422.182
53010: accuracy:0.29 loss: 238.754 (lr:0.00010000000001510848)
53020: accuracy:0.32 loss: 236.184 (lr:0.00010000000001503313)
53030: accuracy:0.27 loss: 228.88 (lr:0.00010000000001495816)
53040: accuracy:0.3 loss: 233.118 (lr:0.00010000000001488355)
53050: accuracy:0.27 loss: 238.484 (lr:0.00010000000001480933)
53060: accuracy:0.3 loss: 212.17 (lr:0.00010000000001473545)
53070: accuracy:0.29 loss: 233.549 (lr:0.00010000000001466197)
53080: accuracy:0.34 loss: 205.62 (lr:0.00010000000001458884)
53090: accuracy:0.3 loss: 229.548 (lr:0.00010000000001451608)
53100: accuracy:0.19 loss: 245.707 (lr:0.00010000000001444368)
53110: accuracy:0.29 loss: 227.727 (lr:0.00010000000001437163)
53120: accuracy:0.28 loss: 219.571 (lr:0.00010000000001429995)
53130: accuracy:0.31 loss: 236.698 (lr:0.00010000000001422864)
53140: accuracy:0.37 loss: 226.992 (lr:0.00010000000001415767)
53150: accuracy:0.36 loss: 218.42 (lr:0.00010000000001408706)
53160: accuracy:0.33 loss: 237.835 (lr:0.0001000000000140168)
53170: accuracy:0.32 loss: 213.215 (lr:0.0001000000000139469)
53180: accuracy:0.33 loss: 229.302 (lr:0.00010000000001387733)
53190: accuracy:0.28 loss: 244.629 (lr:0.00010000000001380812)
53200: accuracy:0.28 loss: 252.393 (lr:0.00010000000001373925)
53210: accuracy:0.21 loss: 237.579 (lr:0.00010000000001367072)
53220: accuracy:0.27 loss: 249.681 (lr:0.00010000000001360254)
53230: accuracy:0.31 loss: 233.01 (lr:0.0001000000000135347)
53240: accuracy:0.35 loss: 234.26 (lr:0.00010000000001346719)
53250: accuracy:0.32 loss: 243.674 (lr:0.00010000000001340003)
53260: accuracy:0.28 loss: 221.853 (lr:0.0001000000000133332)
53270: accuracy:0.29 loss: 221.548 (lr:0.0001000000000132667)
53280: accuracy:0.34 loss: 229.8 (lr:0.00010000000001320053)
53290: accuracy:0.19 loss: 254.886 (lr:0.0001000000000131347)
53300: accuracy:0.28 loss: 230.476 (lr:0.00010000000001306918)
53310: accuracy:0.26 loss: 229.1 (lr:0.000100000000013004)
53320: accuracy:0.24 loss: 244.05 (lr:0.00010000000001293914)
53330: accuracy:0.27 loss: 243.118 (lr:0.00010000000001287461)
53340: accuracy:0.28 loss: 226.466 (lr:0.0001000000000128104)
53350: accuracy:0.28 loss: 256.445 (lr:0.0001000000000127465)
53360: accuracy:0.32 loss: 228.556 (lr:0.00010000000001268292)
53370: accuracy:0.26 loss: 216.093 (lr:0.00010000000001261967)
53380: accuracy:0.2 loss: 242.93 (lr:0.00010000000001255673)
53390: accuracy:0.33 loss: 229.784 (lr:0.0001000000000124941)
53400: accuracy:0.24 loss: 245.444 (lr:0.00010000000001243179)
53410: accuracy:0.29 loss: 242.224 (lr:0.00010000000001236979)
53420: accuracy:0.3 loss: 246.213 (lr:0.00010000000001230808)
53430: accuracy:0.31 loss: 230.52 (lr:0.0001000000000122467)
53440: accuracy:0.27 loss: 238.491 (lr:0.00010000000001218562)
53450: accuracy:0.2 loss: 228.504 (lr:0.00010000000001212484)
53460: accuracy:0.4 loss: 219.098 (lr:0.00010000000001206437)
53470: accuracy:0.27 loss: 245.107 (lr:0.0001000000000120042)
53480: accuracy:0.27 loss: 235.002 (lr:0.00010000000001194433)
53490: accuracy:0.24 loss: 254.642 (lr:0.00010000000001188476)
53500: accuracy:0.26 loss: 236.375 (lr:0.00010000000001182548)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
53500: ********* epoch 6 ********* test accuracy for all:0.226189 test loss: 262.008
53500: ********* epoch 6 ********* test accuracy for mode 0:0.002 test loss: 410.931
53500: ********* epoch 6 ********* test accuracy for mode 1:0.0855 test loss: 384.595
53500: ********* epoch 6 ********* test accuracy for mode 2:0.0615 test loss: 280.701
53500: ********* epoch 6 ********* test accuracy for mode 24:0.2285 test loss: 276.503
53500: ********* epoch 6 ********* test accuracy for mode 25:0.2855 test loss: 258.369
53500: ********* epoch 6 ********* test accuracy for mode 26:0.3465 test loss: 188.398
53500: ********* epoch 6 ********* test accuracy for mode 27:0.205 test loss: 281.376
53500: ********* epoch 6 ********* test accuracy for mode 28:0.2575 test loss: 260.009
53500: ********* epoch 6 ********* test accuracy for mode 29:0.291 test loss: 263.867
53500: ********* epoch 6 ********* test accuracy for mode 30:0.2 test loss: 261.189
53500: ********* epoch 6 ********* test accuracy for mode 31:0.2345 test loss: 260.012
53500: ********* epoch 6 ********* test accuracy for mode 32:0.217 test loss: 250.708
53500: ********* epoch 6 ********* test accuracy for mode 33:0.235 test loss: 258.876
53500: ********* epoch 6 ********* test accuracy for mode 34:0.0625 test loss: 262.28
53500: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 396.071
53500: ********* epoch 6 ********* test accuracy for mode 36:0.0215 test loss: 421.21
53510: accuracy:0.24 loss: 247.912 (lr:0.0001000000000117665)
53520: accuracy:0.26 loss: 224.248 (lr:0.00010000000001170782)
53530: accuracy:0.26 loss: 234.297 (lr:0.00010000000001164942)
53540: accuracy:0.2 loss: 241.356 (lr:0.00010000000001159132)
53550: accuracy:0.31 loss: 239.829 (lr:0.0001000000000115335)
53560: accuracy:0.24 loss: 245.757 (lr:0.00010000000001147599)
53570: accuracy:0.31 loss: 229.093 (lr:0.00010000000001141875)
53580: accuracy:0.23 loss: 225.566 (lr:0.00010000000001136179)
53590: accuracy:0.2 loss: 239.226 (lr:0.00010000000001130513)
53600: accuracy:0.26 loss: 239.539 (lr:0.00010000000001124875)
53610: accuracy:0.31 loss: 235.275 (lr:0.00010000000001119264)
53620: accuracy:0.25 loss: 251.695 (lr:0.00010000000001113682)
53630: accuracy:0.31 loss: 220.078 (lr:0.00010000000001108127)
53640: accuracy:0.32 loss: 239.97 (lr:0.000100000000011026)
53650: accuracy:0.26 loss: 230.148 (lr:0.00010000000001097102)
53660: accuracy:0.26 loss: 219.305 (lr:0.0001000000000109163)
53670: accuracy:0.24 loss: 222.667 (lr:0.00010000000001086185)
53680: accuracy:0.3 loss: 228.458 (lr:0.00010000000001080767)
53690: accuracy:0.32 loss: 239.693 (lr:0.00010000000001075377)
53700: accuracy:0.38 loss: 219.393 (lr:0.00010000000001070015)
53710: accuracy:0.32 loss: 219.944 (lr:0.00010000000001064678)
53720: accuracy:0.3 loss: 228.617 (lr:0.00010000000001059368)
53730: accuracy:0.25 loss: 274.412 (lr:0.00010000000001054084)
53740: accuracy:0.25 loss: 231.345 (lr:0.00010000000001048826)
53750: accuracy:0.31 loss: 231.31 (lr:0.00010000000001043595)
53760: accuracy:0.37 loss: 226.039 (lr:0.0001000000000103839)
53770: accuracy:0.4 loss: 234.231 (lr:0.00010000000001033211)
53780: accuracy:0.28 loss: 232.294 (lr:0.00010000000001028059)
53790: accuracy:0.32 loss: 224.651 (lr:0.0001000000000102293)
53800: accuracy:0.26 loss: 241.276 (lr:0.00010000000001017829)
53810: accuracy:0.27 loss: 233.208 (lr:0.00010000000001012752)
53820: accuracy:0.3 loss: 225.553 (lr:0.00010000000001007701)
53830: accuracy:0.38 loss: 214.674 (lr:0.00010000000001002675)
53840: accuracy:0.23 loss: 239.383 (lr:0.00010000000000997674)
53850: accuracy:0.31 loss: 232.99 (lr:0.00010000000000992699)
53860: accuracy:0.26 loss: 245.877 (lr:0.00010000000000987748)
53870: accuracy:0.29 loss: 222.074 (lr:0.00010000000000982822)
53880: accuracy:0.33 loss: 213.342 (lr:0.0001000000000097792)
53890: accuracy:0.25 loss: 229.315 (lr:0.00010000000000973042)
53900: accuracy:0.26 loss: 222.174 (lr:0.00010000000000968189)
53910: accuracy:0.3 loss: 221.621 (lr:0.0001000000000096336)
53920: accuracy:0.21 loss: 271.107 (lr:0.00010000000000958554)
53930: accuracy:0.35 loss: 212.409 (lr:0.00010000000000953774)
53940: accuracy:0.26 loss: 240.455 (lr:0.00010000000000949018)
53950: accuracy:0.34 loss: 223.374 (lr:0.00010000000000944284)
53960: accuracy:0.29 loss: 240.748 (lr:0.00010000000000939574)
53970: accuracy:0.25 loss: 236.681 (lr:0.00010000000000934888)
53980: accuracy:0.26 loss: 228.523 (lr:0.00010000000000930226)
53990: accuracy:0.37 loss: 224.465 (lr:0.00010000000000925587)
54000: accuracy:0.29 loss: 241.64 (lr:0.00010000000000920969)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
54000: ********* epoch 6 ********* test accuracy for all:0.232041 test loss: 260.525
54000: ********* epoch 6 ********* test accuracy for mode 0:0.002 test loss: 406.144
54000: ********* epoch 6 ********* test accuracy for mode 1:0.0895 test loss: 377.61
54000: ********* epoch 6 ********* test accuracy for mode 2:0.0385 test loss: 285.026
54000: ********* epoch 6 ********* test accuracy for mode 24:0.216 test loss: 269.684
54000: ********* epoch 6 ********* test accuracy for mode 25:0.302 test loss: 249.763
54000: ********* epoch 6 ********* test accuracy for mode 26:0.4105 test loss: 177.489
54000: ********* epoch 6 ********* test accuracy for mode 27:0.22 test loss: 275.292
54000: ********* epoch 6 ********* test accuracy for mode 28:0.2715 test loss: 262.136
54000: ********* epoch 6 ********* test accuracy for mode 29:0.3 test loss: 268.765
54000: ********* epoch 6 ********* test accuracy for mode 30:0.1835 test loss: 269.779
54000: ********* epoch 6 ********* test accuracy for mode 31:0.215 test loss: 268.881
54000: ********* epoch 6 ********* test accuracy for mode 32:0.169 test loss: 259.894
54000: ********* epoch 6 ********* test accuracy for mode 33:0.22 test loss: 264.982
54000: ********* epoch 6 ********* test accuracy for mode 34:0.098 test loss: 263.426
54000: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 399.643
54000: ********* epoch 6 ********* test accuracy for mode 36:0.0305 test loss: 406.045
54010: accuracy:0.28 loss: 223.168 (lr:0.00010000000000916376)
54020: accuracy:0.33 loss: 230.952 (lr:0.00010000000000911806)
54030: accuracy:0.21 loss: 247.694 (lr:0.00010000000000907258)
54040: accuracy:0.27 loss: 226.939 (lr:0.00010000000000902733)
54050: accuracy:0.31 loss: 233.023 (lr:0.00010000000000898231)
54060: accuracy:0.35 loss: 229.776 (lr:0.0001000000000089375)
54070: accuracy:0.27 loss: 241.95 (lr:0.00010000000000889293)
54080: accuracy:0.26 loss: 220.737 (lr:0.00010000000000884859)
54090: accuracy:0.3 loss: 228.424 (lr:0.00010000000000880444)
54100: accuracy:0.28 loss: 222.794 (lr:0.00010000000000876053)
54110: accuracy:0.24 loss: 227.334 (lr:0.00010000000000871684)
54120: accuracy:0.22 loss: 235.326 (lr:0.00010000000000867336)
54130: accuracy:0.25 loss: 242.205 (lr:0.0001000000000086301)
54140: accuracy:0.3 loss: 232.656 (lr:0.00010000000000858706)
54150: accuracy:0.36 loss: 243.887 (lr:0.00010000000000854424)
54160: accuracy:0.26 loss: 237.778 (lr:0.00010000000000850163)
54170: accuracy:0.29 loss: 234.507 (lr:0.00010000000000845922)
54180: accuracy:0.36 loss: 228.45 (lr:0.00010000000000841703)
54190: accuracy:0.25 loss: 234.687 (lr:0.00010000000000837505)
54200: accuracy:0.3 loss: 235.632 (lr:0.00010000000000833328)
54210: accuracy:0.33 loss: 224.518 (lr:0.00010000000000829171)
54220: accuracy:0.29 loss: 235.559 (lr:0.00010000000000825036)
54230: accuracy:0.27 loss: 241.655 (lr:0.00010000000000820922)
54240: accuracy:0.24 loss: 234.639 (lr:0.00010000000000816826)
54250: accuracy:0.3 loss: 223.6 (lr:0.00010000000000812752)
54260: accuracy:0.35 loss: 231.806 (lr:0.00010000000000808699)
54270: accuracy:0.35 loss: 223.922 (lr:0.00010000000000804666)
54280: accuracy:0.32 loss: 231.008 (lr:0.00010000000000800653)
54290: accuracy:0.31 loss: 197.626 (lr:0.00010000000000796659)
54300: accuracy:0.24 loss: 241.549 (lr:0.00010000000000792686)
54310: accuracy:0.19 loss: 244.059 (lr:0.00010000000000788732)
54320: accuracy:0.31 loss: 244.753 (lr:0.00010000000000784799)
54330: accuracy:0.27 loss: 242.76 (lr:0.00010000000000780885)
54340: accuracy:0.22 loss: 250.919 (lr:0.0001000000000077699)
54350: accuracy:0.3 loss: 227.89 (lr:0.00010000000000773114)
54360: accuracy:0.34 loss: 220.633 (lr:0.00010000000000769258)
54370: accuracy:0.29 loss: 241.353 (lr:0.00010000000000765421)
54380: accuracy:0.25 loss: 239.006 (lr:0.00010000000000761604)
54390: accuracy:0.25 loss: 241.901 (lr:0.00010000000000757806)
54400: accuracy:0.3 loss: 222.202 (lr:0.00010000000000754026)
54410: accuracy:0.25 loss: 240.727 (lr:0.00010000000000750266)
54420: accuracy:0.31 loss: 239.584 (lr:0.00010000000000746524)
54430: accuracy:0.28 loss: 251.211 (lr:0.000100000000007428)
54440: accuracy:0.25 loss: 244.633 (lr:0.00010000000000739096)
54450: accuracy:0.23 loss: 227.019 (lr:0.0001000000000073541)
54460: accuracy:0.29 loss: 236.219 (lr:0.00010000000000731741)
54470: accuracy:0.3 loss: 240.859 (lr:0.00010000000000728092)
54480: accuracy:0.25 loss: 246.755 (lr:0.0001000000000072446)
54490: accuracy:0.26 loss: 219.906 (lr:0.00010000000000720847)
54500: accuracy:0.24 loss: 249.787 (lr:0.00010000000000717252)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
54500: ********* epoch 6 ********* test accuracy for all:0.23277 test loss: 260.081
54500: ********* epoch 6 ********* test accuracy for mode 0:0.001 test loss: 421.558
54500: ********* epoch 6 ********* test accuracy for mode 1:0.065 test loss: 390.754
54500: ********* epoch 6 ********* test accuracy for mode 2:0.0525 test loss: 274.622
54500: ********* epoch 6 ********* test accuracy for mode 24:0.2175 test loss: 273.476
54500: ********* epoch 6 ********* test accuracy for mode 25:0.288 test loss: 252.304
54500: ********* epoch 6 ********* test accuracy for mode 26:0.358 test loss: 177.924
54500: ********* epoch 6 ********* test accuracy for mode 27:0.294 test loss: 261.834
54500: ********* epoch 6 ********* test accuracy for mode 28:0.2705 test loss: 252.443
54500: ********* epoch 6 ********* test accuracy for mode 29:0.2825 test loss: 257.119
54500: ********* epoch 6 ********* test accuracy for mode 30:0.215 test loss: 258.256
54500: ********* epoch 6 ********* test accuracy for mode 31:0.1655 test loss: 261.935
54500: ********* epoch 6 ********* test accuracy for mode 32:0.262 test loss: 246.446
54500: ********* epoch 6 ********* test accuracy for mode 33:0.227 test loss: 255.292
54500: ********* epoch 6 ********* test accuracy for mode 34:0.1415 test loss: 254.767
54500: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 412.105
54500: ********* epoch 6 ********* test accuracy for mode 36:0.021 test loss: 425.006
54510: accuracy:0.26 loss: 227.679 (lr:0.00010000000000713675)
54520: accuracy:0.29 loss: 230.838 (lr:0.00010000000000710115)
54530: accuracy:0.33 loss: 228.009 (lr:0.00010000000000706574)
54540: accuracy:0.32 loss: 232.38 (lr:0.0001000000000070305)
54550: accuracy:0.23 loss: 241.946 (lr:0.00010000000000699543)
54560: accuracy:0.23 loss: 236.684 (lr:0.00010000000000696054)
54570: accuracy:0.28 loss: 215.05 (lr:0.00010000000000692582)
54580: accuracy:0.28 loss: 247.395 (lr:0.00010000000000689128)
54590: accuracy:0.29 loss: 230.084 (lr:0.0001000000000068569)
54600: accuracy:0.27 loss: 227.876 (lr:0.00010000000000682271)
54610: accuracy:0.29 loss: 240.119 (lr:0.00010000000000678868)
54620: accuracy:0.25 loss: 238.756 (lr:0.00010000000000675483)
54630: accuracy:0.22 loss: 240.443 (lr:0.00010000000000672114)
54640: accuracy:0.3 loss: 232.387 (lr:0.00010000000000668761)
54650: accuracy:0.3 loss: 236.337 (lr:0.00010000000000665425)
54660: accuracy:0.38 loss: 228.351 (lr:0.00010000000000662106)
54670: accuracy:0.31 loss: 215.977 (lr:0.00010000000000658805)
54680: accuracy:0.25 loss: 259.674 (lr:0.00010000000000655519)
54690: accuracy:0.28 loss: 221.332 (lr:0.0001000000000065225)
54700: accuracy:0.26 loss: 212.518 (lr:0.00010000000000648997)
54710: accuracy:0.22 loss: 236.789 (lr:0.0001000000000064576)
54720: accuracy:0.2 loss: 240.624 (lr:0.0001000000000064254)
54730: accuracy:0.32 loss: 240.017 (lr:0.00010000000000639334)
54740: accuracy:0.34 loss: 222.887 (lr:0.00010000000000636145)
54750: accuracy:0.35 loss: 233.5 (lr:0.00010000000000632973)
54760: accuracy:0.25 loss: 227.033 (lr:0.00010000000000629816)
54770: accuracy:0.29 loss: 240.431 (lr:0.00010000000000626675)
54780: accuracy:0.27 loss: 241.067 (lr:0.0001000000000062355)
54790: accuracy:0.35 loss: 218.662 (lr:0.00010000000000620439)
54800: accuracy:0.28 loss: 226.598 (lr:0.00010000000000617345)
54810: accuracy:0.32 loss: 242.018 (lr:0.00010000000000614266)
54820: accuracy:0.3 loss: 225.611 (lr:0.00010000000000611202)
54830: accuracy:0.25 loss: 237.419 (lr:0.00010000000000608154)
54840: accuracy:0.27 loss: 228.097 (lr:0.00010000000000605121)
54850: accuracy:0.22 loss: 252.758 (lr:0.00010000000000602103)
54860: accuracy:0.33 loss: 222.683 (lr:0.000100000000005991)
54870: accuracy:0.3 loss: 221.722 (lr:0.00010000000000596111)
54880: accuracy:0.26 loss: 242.359 (lr:0.00010000000000593138)
54890: accuracy:0.22 loss: 235.095 (lr:0.0001000000000059018)
54900: accuracy:0.3 loss: 254.83 (lr:0.00010000000000587237)
54910: accuracy:0.29 loss: 232.587 (lr:0.00010000000000584307)
54920: accuracy:0.24 loss: 241.823 (lr:0.00010000000000581393)
54930: accuracy:0.29 loss: 228.828 (lr:0.00010000000000578494)
54940: accuracy:0.28 loss: 231.766 (lr:0.00010000000000575609)
54950: accuracy:0.32 loss: 233.665 (lr:0.00010000000000572737)
54960: accuracy:0.27 loss: 225.354 (lr:0.00010000000000569882)
54970: accuracy:0.25 loss: 234.188 (lr:0.00010000000000567038)
54980: accuracy:0.29 loss: 232.444 (lr:0.0001000000000056421)
54990: accuracy:0.27 loss: 234.4 (lr:0.00010000000000561396)
55000: accuracy:0.23 loss: 246.395 (lr:0.00010000000000558596)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
55000: ********* epoch 6 ********* test accuracy for all:0.229473 test loss: 259.719
55000: ********* epoch 6 ********* test accuracy for mode 0:0.003 test loss: 407.142
55000: ********* epoch 6 ********* test accuracy for mode 1:0.084 test loss: 379.814
55000: ********* epoch 6 ********* test accuracy for mode 2:0.081 test loss: 282.139
55000: ********* epoch 6 ********* test accuracy for mode 24:0.2515 test loss: 259.81
55000: ********* epoch 6 ********* test accuracy for mode 25:0.3255 test loss: 239.617
55000: ********* epoch 6 ********* test accuracy for mode 26:0.3385 test loss: 179.305
55000: ********* epoch 6 ********* test accuracy for mode 27:0.2105 test loss: 270.028
55000: ********* epoch 6 ********* test accuracy for mode 28:0.2765 test loss: 253.95
55000: ********* epoch 6 ********* test accuracy for mode 29:0.3125 test loss: 254.651
55000: ********* epoch 6 ********* test accuracy for mode 30:0.203 test loss: 262.176
55000: ********* epoch 6 ********* test accuracy for mode 31:0.1845 test loss: 263.974
55000: ********* epoch 6 ********* test accuracy for mode 32:0.2295 test loss: 256.34
55000: ********* epoch 6 ********* test accuracy for mode 33:0.1985 test loss: 267.398
55000: ********* epoch 6 ********* test accuracy for mode 34:0.087 test loss: 268.377
55000: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 401.874
55000: ********* epoch 6 ********* test accuracy for mode 36:0.0495 test loss: 395.413
55010: accuracy:0.37 loss: 221.728 (lr:0.0001000000000055581)
55020: accuracy:0.38 loss: 220.417 (lr:0.00010000000000553038)
55030: accuracy:0.31 loss: 247.769 (lr:0.0001000000000055028)
55040: accuracy:0.34 loss: 215.18 (lr:0.00010000000000547536)
55050: accuracy:0.21 loss: 227.281 (lr:0.00010000000000544805)
55060: accuracy:0.11 loss: 281.29 (lr:0.00010000000000542088)
55070: accuracy:0.26 loss: 242.384 (lr:0.00010000000000539384)
55080: accuracy:0.24 loss: 255.581 (lr:0.00010000000000536694)
55090: accuracy:0.27 loss: 234.938 (lr:0.00010000000000534017)
55100: accuracy:0.29 loss: 240.759 (lr:0.00010000000000531353)
55110: accuracy:0.27 loss: 246.378 (lr:0.00010000000000528704)
55120: accuracy:0.32 loss: 220.374 (lr:0.00010000000000526066)
55130: accuracy:0.23 loss: 276.372 (lr:0.00010000000000523442)
55140: accuracy:0.31 loss: 248.585 (lr:0.00010000000000520832)
55150: accuracy:0.27 loss: 224.514 (lr:0.00010000000000518234)
55160: accuracy:0.37 loss: 236.143 (lr:0.0001000000000051565)
55170: accuracy:0.23 loss: 207.964 (lr:0.00010000000000513077)
55180: accuracy:0.31 loss: 224.108 (lr:0.00010000000000510519)
55190: accuracy:0.28 loss: 247.74 (lr:0.00010000000000507972)
55200: accuracy:0.37 loss: 233.946 (lr:0.00010000000000505439)
55210: accuracy:0.33 loss: 211.089 (lr:0.00010000000000502918)
55220: accuracy:0.22 loss: 255.215 (lr:0.0001000000000050041)
55230: accuracy:0.24 loss: 225.764 (lr:0.00010000000000497914)
55240: accuracy:0.26 loss: 252.223 (lr:0.00010000000000495431)
55250: accuracy:0.35 loss: 219.192 (lr:0.0001000000000049296)
55260: accuracy:0.37 loss: 210.356 (lr:0.00010000000000490502)
55270: accuracy:0.24 loss: 224.96 (lr:0.00010000000000488054)
55280: accuracy:0.37 loss: 230.464 (lr:0.0001000000000048562)
55290: accuracy:0.28 loss: 238.197 (lr:0.00010000000000483198)
55300: accuracy:0.27 loss: 224.231 (lr:0.00010000000000480789)
55310: accuracy:0.17 loss: 243.747 (lr:0.00010000000000478391)
55320: accuracy:0.32 loss: 223.57 (lr:0.00010000000000476005)
55330: accuracy:0.33 loss: 225.374 (lr:0.0001000000000047363)
55340: accuracy:0.22 loss: 224.4 (lr:0.00010000000000471268)
55350: accuracy:0.23 loss: 240.315 (lr:0.00010000000000468918)
55360: accuracy:0.31 loss: 235.726 (lr:0.00010000000000466579)
55370: accuracy:0.25 loss: 258.021 (lr:0.00010000000000464252)
55380: accuracy:0.34 loss: 215.685 (lr:0.00010000000000461937)
55390: accuracy:0.34 loss: 248.669 (lr:0.00010000000000459633)
55400: accuracy:0.28 loss: 239.495 (lr:0.0001000000000045734)
55410: accuracy:0.24 loss: 270.629 (lr:0.00010000000000455059)
55420: accuracy:0.32 loss: 241.206 (lr:0.00010000000000452789)
55430: accuracy:0.19 loss: 254.554 (lr:0.00010000000000450531)
55440: accuracy:0.3 loss: 231.901 (lr:0.00010000000000448284)
55450: accuracy:0.32 loss: 241.897 (lr:0.00010000000000446048)
55460: accuracy:0.27 loss: 236.099 (lr:0.00010000000000443824)
55470: accuracy:0.26 loss: 236.709 (lr:0.0001000000000044161)
55480: accuracy:0.23 loss: 232.006 (lr:0.00010000000000439407)
55490: accuracy:0.27 loss: 215.726 (lr:0.00010000000000437216)
55500: accuracy:0.26 loss: 237.005 (lr:0.00010000000000435035)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
55500: ********* epoch 6 ********* test accuracy for all:0.232514 test loss: 259.779
55500: ********* epoch 6 ********* test accuracy for mode 0:0.0025 test loss: 404.69
55500: ********* epoch 6 ********* test accuracy for mode 1:0.092 test loss: 373.783
55500: ********* epoch 6 ********* test accuracy for mode 2:0.079 test loss: 280.35
55500: ********* epoch 6 ********* test accuracy for mode 24:0.204 test loss: 268.539
55500: ********* epoch 6 ********* test accuracy for mode 25:0.3235 test loss: 243.704
55500: ********* epoch 6 ********* test accuracy for mode 26:0.3945 test loss: 174.816
55500: ********* epoch 6 ********* test accuracy for mode 27:0.2035 test loss: 274.85
55500: ********* epoch 6 ********* test accuracy for mode 28:0.268 test loss: 258.545
55500: ********* epoch 6 ********* test accuracy for mode 29:0.2855 test loss: 258.699
55500: ********* epoch 6 ********* test accuracy for mode 30:0.228 test loss: 261.378
55500: ********* epoch 6 ********* test accuracy for mode 31:0.2235 test loss: 263.97
55500: ********* epoch 6 ********* test accuracy for mode 32:0.17 test loss: 259.014
55500: ********* epoch 6 ********* test accuracy for mode 33:0.24 test loss: 263.616
55500: ********* epoch 6 ********* test accuracy for mode 34:0.099 test loss: 263.593
55500: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 398.073
55500: ********* epoch 6 ********* test accuracy for mode 36:0.038 test loss: 409.299
55510: accuracy:0.34 loss: 215.623 (lr:0.00010000000000432865)
55520: accuracy:0.25 loss: 214.557 (lr:0.00010000000000430707)
55530: accuracy:0.34 loss: 225.69 (lr:0.00010000000000428558)
55540: accuracy:0.3 loss: 234.59 (lr:0.00010000000000426421)
55550: accuracy:0.33 loss: 213.449 (lr:0.00010000000000424295)
55560: accuracy:0.29 loss: 235.99 (lr:0.00010000000000422178)
55570: accuracy:0.32 loss: 230.971 (lr:0.00010000000000420073)
55580: accuracy:0.31 loss: 229.09 (lr:0.00010000000000417978)
55590: accuracy:0.22 loss: 258.643 (lr:0.00010000000000415892)
55600: accuracy:0.32 loss: 235.266 (lr:0.00010000000000413819)
55610: accuracy:0.22 loss: 238.995 (lr:0.00010000000000411755)
55620: accuracy:0.29 loss: 231.719 (lr:0.00010000000000409702)
55630: accuracy:0.29 loss: 237.716 (lr:0.00010000000000407658)
55640: accuracy:0.26 loss: 234.015 (lr:0.00010000000000405625)
55650: accuracy:0.3 loss: 215.659 (lr:0.00010000000000403602)
55660: accuracy:0.33 loss: 242.079 (lr:0.00010000000000401589)
55670: accuracy:0.31 loss: 226.625 (lr:0.00010000000000399586)
55680: accuracy:0.24 loss: 238.298 (lr:0.00010000000000397592)
55690: accuracy:0.3 loss: 223.67 (lr:0.0001000000000039561)
55700: accuracy:0.29 loss: 240.626 (lr:0.00010000000000393636)
55710: accuracy:0.31 loss: 217.451 (lr:0.00010000000000391673)
55720: accuracy:0.29 loss: 245.045 (lr:0.0001000000000038972)
55730: accuracy:0.23 loss: 245.049 (lr:0.00010000000000387776)
55740: accuracy:0.34 loss: 197.989 (lr:0.00010000000000385842)
55750: accuracy:0.19 loss: 245.639 (lr:0.00010000000000383918)
55760: accuracy:0.23 loss: 225.927 (lr:0.00010000000000382003)
55770: accuracy:0.23 loss: 247.285 (lr:0.00010000000000380097)
55780: accuracy:0.22 loss: 247.494 (lr:0.00010000000000378201)
55790: accuracy:0.31 loss: 238.058 (lr:0.00010000000000376315)
55800: accuracy:0.31 loss: 226.211 (lr:0.00010000000000374439)
55810: accuracy:0.3 loss: 218.712 (lr:0.00010000000000372572)
55820: accuracy:0.34 loss: 224.139 (lr:0.00010000000000370712)
55830: accuracy:0.28 loss: 221.337 (lr:0.00010000000000368864)
55840: accuracy:0.24 loss: 237.93 (lr:0.00010000000000367025)
55850: accuracy:0.32 loss: 213.246 (lr:0.00010000000000365194)
55860: accuracy:0.31 loss: 213.126 (lr:0.00010000000000363372)
55870: accuracy:0.24 loss: 234.44 (lr:0.0001000000000036156)
55880: accuracy:0.34 loss: 219.166 (lr:0.00010000000000359756)
55890: accuracy:0.24 loss: 256.281 (lr:0.00010000000000357962)
55900: accuracy:0.28 loss: 219.214 (lr:0.00010000000000356177)
55910: accuracy:0.35 loss: 221.189 (lr:0.000100000000003544)
55920: accuracy:0.29 loss: 230.625 (lr:0.00010000000000352633)
55930: accuracy:0.26 loss: 224.528 (lr:0.00010000000000350874)
55940: accuracy:0.26 loss: 237.217 (lr:0.00010000000000349124)
55950: accuracy:0.25 loss: 222.893 (lr:0.00010000000000347383)
55960: accuracy:0.31 loss: 223.591 (lr:0.00010000000000345651)
55970: accuracy:0.25 loss: 222.241 (lr:0.00010000000000343927)
55980: accuracy:0.37 loss: 205.18 (lr:0.00010000000000342211)
55990: accuracy:0.33 loss: 219.603 (lr:0.00010000000000340505)
56000: accuracy:0.26 loss: 233.452 (lr:0.00010000000000338806)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
56000: ********* epoch 6 ********* test accuracy for all:0.230459 test loss: 258.948
56000: ********* epoch 6 ********* test accuracy for mode 0:0.0005 test loss: 408.993
56000: ********* epoch 6 ********* test accuracy for mode 1:0.0965 test loss: 373.987
56000: ********* epoch 6 ********* test accuracy for mode 2:0.04 test loss: 283.943
56000: ********* epoch 6 ********* test accuracy for mode 24:0.236 test loss: 263.717
56000: ********* epoch 6 ********* test accuracy for mode 25:0.361 test loss: 237.819
56000: ********* epoch 6 ********* test accuracy for mode 26:0.271 test loss: 182.214
56000: ********* epoch 6 ********* test accuracy for mode 27:0.248 test loss: 266.55
56000: ********* epoch 6 ********* test accuracy for mode 28:0.2645 test loss: 250.413
56000: ********* epoch 6 ********* test accuracy for mode 29:0.262 test loss: 258.602
56000: ********* epoch 6 ********* test accuracy for mode 30:0.2525 test loss: 255.567
56000: ********* epoch 6 ********* test accuracy for mode 31:0.1715 test loss: 263.604
56000: ********* epoch 6 ********* test accuracy for mode 32:0.2615 test loss: 251.124
56000: ********* epoch 6 ********* test accuracy for mode 33:0.24 test loss: 260.718
56000: ********* epoch 6 ********* test accuracy for mode 34:0.0895 test loss: 266.501
56000: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 396.918
56000: ********* epoch 6 ********* test accuracy for mode 36:0.049 test loss: 401.436
56010: accuracy:0.36 loss: 231.987 (lr:0.00010000000000337117)
56020: accuracy:0.35 loss: 238.886 (lr:0.00010000000000335435)
56030: accuracy:0.31 loss: 238.219 (lr:0.00010000000000333761)
56040: accuracy:0.33 loss: 219.742 (lr:0.00010000000000332097)
56050: accuracy:0.25 loss: 228.577 (lr:0.00010000000000330441)
56060: accuracy:0.29 loss: 231.751 (lr:0.00010000000000328793)
56070: accuracy:0.35 loss: 219.796 (lr:0.00010000000000327153)
56080: accuracy:0.32 loss: 231.534 (lr:0.00010000000000325521)
56090: accuracy:0.26 loss: 232.794 (lr:0.00010000000000323898)
56100: accuracy:0.32 loss: 218.482 (lr:0.00010000000000322282)
56110: accuracy:0.28 loss: 231.67 (lr:0.00010000000000320675)
56120: accuracy:0.32 loss: 228.094 (lr:0.00010000000000319076)
56130: accuracy:0.26 loss: 229.041 (lr:0.00010000000000317485)
56140: accuracy:0.32 loss: 222.441 (lr:0.000100000000003159)
56150: accuracy:0.32 loss: 238.077 (lr:0.00010000000000314326)
56160: accuracy:0.25 loss: 232.948 (lr:0.00010000000000312758)
56170: accuracy:0.22 loss: 239.352 (lr:0.00010000000000311198)
56180: accuracy:0.31 loss: 240.934 (lr:0.00010000000000309646)
56190: accuracy:0.27 loss: 226.874 (lr:0.00010000000000308101)
56200: accuracy:0.37 loss: 219.523 (lr:0.00010000000000306564)
56210: accuracy:0.26 loss: 266.132 (lr:0.00010000000000305035)
56220: accuracy:0.3 loss: 232.031 (lr:0.00010000000000303515)
56230: accuracy:0.31 loss: 221.852 (lr:0.00010000000000302001)
56240: accuracy:0.23 loss: 245.221 (lr:0.00010000000000300494)
56250: accuracy:0.28 loss: 233.857 (lr:0.00010000000000298995)
56260: accuracy:0.24 loss: 236.177 (lr:0.00010000000000297504)
56270: accuracy:0.29 loss: 234.581 (lr:0.0001000000000029602)
56280: accuracy:0.23 loss: 252.717 (lr:0.00010000000000294544)
56290: accuracy:0.3 loss: 231.852 (lr:0.00010000000000293075)
56300: accuracy:0.33 loss: 249.836 (lr:0.00010000000000291613)
56310: accuracy:0.25 loss: 253.021 (lr:0.00010000000000290159)
56320: accuracy:0.2 loss: 249.879 (lr:0.00010000000000288711)
56330: accuracy:0.2 loss: 225.99 (lr:0.00010000000000287272)
56340: accuracy:0.21 loss: 241.469 (lr:0.00010000000000285838)
56350: accuracy:0.27 loss: 232.049 (lr:0.00010000000000284414)
56360: accuracy:0.3 loss: 241.028 (lr:0.00010000000000282995)
56370: accuracy:0.15 loss: 265.271 (lr:0.00010000000000281583)
56380: accuracy:0.31 loss: 221.291 (lr:0.00010000000000280179)
56390: accuracy:0.3 loss: 223.368 (lr:0.00010000000000278781)
56400: accuracy:0.33 loss: 231.47 (lr:0.00010000000000277391)
56410: accuracy:0.34 loss: 238.012 (lr:0.00010000000000276007)
56420: accuracy:0.28 loss: 249.786 (lr:0.00010000000000274632)
56430: accuracy:0.24 loss: 239.917 (lr:0.00010000000000273261)
56440: accuracy:0.25 loss: 253.023 (lr:0.00010000000000271898)
56450: accuracy:0.3 loss: 230.867 (lr:0.00010000000000270543)
56460: accuracy:0.33 loss: 228.749 (lr:0.00010000000000269193)
56470: accuracy:0.32 loss: 222.257 (lr:0.0001000000000026785)
56480: accuracy:0.22 loss: 247.366 (lr:0.00010000000000266515)
56490: accuracy:0.34 loss: 214.088 (lr:0.00010000000000265185)
56500: accuracy:0.3 loss: 241.829 (lr:0.00010000000000263863)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
56500: ********* epoch 6 ********* test accuracy for all:0.233297 test loss: 259.795
56500: ********* epoch 6 ********* test accuracy for mode 0:0.0005 test loss: 422.983
56500: ********* epoch 6 ********* test accuracy for mode 1:0.067 test loss: 389.406
56500: ********* epoch 6 ********* test accuracy for mode 2:0.0585 test loss: 269.973
56500: ********* epoch 6 ********* test accuracy for mode 24:0.247 test loss: 268.479
56500: ********* epoch 6 ********* test accuracy for mode 25:0.314 test loss: 243.367
56500: ********* epoch 6 ********* test accuracy for mode 26:0.2485 test loss: 187.876
56500: ********* epoch 6 ********* test accuracy for mode 27:0.24 test loss: 268.909
56500: ********* epoch 6 ********* test accuracy for mode 28:0.274 test loss: 256.115
56500: ********* epoch 6 ********* test accuracy for mode 29:0.276 test loss: 258.879
56500: ********* epoch 6 ********* test accuracy for mode 30:0.2485 test loss: 258.387
56500: ********* epoch 6 ********* test accuracy for mode 31:0.1665 test loss: 262.455
56500: ********* epoch 6 ********* test accuracy for mode 32:0.233 test loss: 248.538
56500: ********* epoch 6 ********* test accuracy for mode 33:0.258 test loss: 255.415
56500: ********* epoch 6 ********* test accuracy for mode 34:0.161 test loss: 253.823
56500: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 418.555
56500: ********* epoch 6 ********* test accuracy for mode 36:0.0315 test loss: 447.131
56510: accuracy:0.34 loss: 214.193 (lr:0.00010000000000262547)
56520: accuracy:0.26 loss: 225.996 (lr:0.00010000000000261238)
56530: accuracy:0.3 loss: 231.791 (lr:0.00010000000000259934)
56540: accuracy:0.32 loss: 214.717 (lr:0.00010000000000258638)
56550: accuracy:0.29 loss: 223.827 (lr:0.00010000000000257348)
56560: accuracy:0.31 loss: 239.889 (lr:0.00010000000000256065)
56570: accuracy:0.36 loss: 221.451 (lr:0.00010000000000254787)
56580: accuracy:0.27 loss: 231.826 (lr:0.00010000000000253517)
56590: accuracy:0.32 loss: 216.499 (lr:0.00010000000000252252)
56600: accuracy:0.37 loss: 222.613 (lr:0.00010000000000250993)
56610: accuracy:0.34 loss: 233.017 (lr:0.00010000000000249742)
56620: accuracy:0.39 loss: 226.259 (lr:0.00010000000000248497)
56630: accuracy:0.29 loss: 235.783 (lr:0.00010000000000247257)
56640: accuracy:0.24 loss: 230.688 (lr:0.00010000000000246024)
56650: accuracy:0.29 loss: 221.802 (lr:0.00010000000000244797)
56660: accuracy:0.3 loss: 244.059 (lr:0.00010000000000243576)
56670: accuracy:0.22 loss: 230.717 (lr:0.00010000000000242362)
56680: accuracy:0.36 loss: 235.324 (lr:0.00010000000000241153)
56690: accuracy:0.3 loss: 217.277 (lr:0.0001000000000023995)
56700: accuracy:0.26 loss: 244.385 (lr:0.00010000000000238753)
56710: accuracy:0.29 loss: 231.481 (lr:0.00010000000000237561)
56720: accuracy:0.29 loss: 236.328 (lr:0.00010000000000236377)
56730: accuracy:0.36 loss: 233.449 (lr:0.00010000000000235198)
56740: accuracy:0.32 loss: 226.48 (lr:0.00010000000000234026)
56750: accuracy:0.26 loss: 221.351 (lr:0.00010000000000232857)
56760: accuracy:0.25 loss: 244.264 (lr:0.00010000000000231697)
56770: accuracy:0.19 loss: 236.381 (lr:0.00010000000000230541)
56780: accuracy:0.27 loss: 218.531 (lr:0.0001000000000022939)
56790: accuracy:0.29 loss: 245.466 (lr:0.00010000000000228247)
56800: accuracy:0.31 loss: 234.485 (lr:0.00010000000000227108)
56810: accuracy:0.23 loss: 241.741 (lr:0.00010000000000225975)
56820: accuracy:0.25 loss: 244.157 (lr:0.00010000000000224849)
56830: accuracy:0.23 loss: 254.956 (lr:0.00010000000000223727)
56840: accuracy:0.3 loss: 227.218 (lr:0.00010000000000222612)
56850: accuracy:0.32 loss: 241.4 (lr:0.00010000000000221502)
56860: accuracy:0.29 loss: 204.914 (lr:0.00010000000000220397)
56870: accuracy:0.29 loss: 224.901 (lr:0.00010000000000219298)
56880: accuracy:0.33 loss: 243.472 (lr:0.00010000000000218204)
56890: accuracy:0.31 loss: 227.596 (lr:0.00010000000000217115)
56900: accuracy:0.29 loss: 244.809 (lr:0.00010000000000216032)
56910: accuracy:0.21 loss: 223.597 (lr:0.00010000000000214954)
56920: accuracy:0.32 loss: 225.947 (lr:0.00010000000000213882)
56930: accuracy:0.28 loss: 232.198 (lr:0.00010000000000212816)
56940: accuracy:0.26 loss: 235.293 (lr:0.00010000000000211755)
56950: accuracy:0.29 loss: 236.455 (lr:0.00010000000000210699)
56960: accuracy:0.26 loss: 263.226 (lr:0.00010000000000209647)
56970: accuracy:0.28 loss: 226.853 (lr:0.00010000000000208602)
56980: accuracy:0.35 loss: 218.452 (lr:0.00010000000000207561)
56990: accuracy:0.3 loss: 234.383 (lr:0.00010000000000206526)
57000: accuracy:0.35 loss: 220.805 (lr:0.00010000000000205496)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
57000: ********* epoch 6 ********* test accuracy for all:0.230757 test loss: 260.91
57000: ********* epoch 6 ********* test accuracy for mode 0:0.001 test loss: 406.993
57000: ********* epoch 6 ********* test accuracy for mode 1:0.0805 test loss: 379.204
57000: ********* epoch 6 ********* test accuracy for mode 2:0.038 test loss: 282.657
57000: ********* epoch 6 ********* test accuracy for mode 24:0.218 test loss: 267.476
57000: ********* epoch 6 ********* test accuracy for mode 25:0.291 test loss: 249.183
57000: ********* epoch 6 ********* test accuracy for mode 26:0.338 test loss: 175.858
57000: ********* epoch 6 ********* test accuracy for mode 27:0.3135 test loss: 255.257
57000: ********* epoch 6 ********* test accuracy for mode 28:0.2785 test loss: 253.305
57000: ********* epoch 6 ********* test accuracy for mode 29:0.282 test loss: 261.735
57000: ********* epoch 6 ********* test accuracy for mode 30:0.228 test loss: 260.228
57000: ********* epoch 6 ********* test accuracy for mode 31:0.2245 test loss: 261.954
57000: ********* epoch 6 ********* test accuracy for mode 32:0.162 test loss: 259.433
57000: ********* epoch 6 ********* test accuracy for mode 33:0.2195 test loss: 265.838
57000: ********* epoch 6 ********* test accuracy for mode 34:0.1295 test loss: 264.329
57000: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 401.789
57000: ********* epoch 6 ********* test accuracy for mode 36:0.022 test loss: 438.915
57010: accuracy:0.23 loss: 241.693 (lr:0.00010000000000204472)
57020: accuracy:0.28 loss: 233.555 (lr:0.00010000000000203452)
57030: accuracy:0.31 loss: 238.082 (lr:0.00010000000000202437)
57040: accuracy:0.34 loss: 208.956 (lr:0.00010000000000201428)
57050: accuracy:0.29 loss: 239.114 (lr:0.00010000000000200423)
57060: accuracy:0.21 loss: 236.553 (lr:0.00010000000000199423)
57070: accuracy:0.33 loss: 225.382 (lr:0.00010000000000198428)
57080: accuracy:0.27 loss: 233.818 (lr:0.00010000000000197439)
57090: accuracy:0.23 loss: 243.617 (lr:0.00010000000000196454)
57100: accuracy:0.27 loss: 256.38 (lr:0.00010000000000195474)
57110: accuracy:0.3 loss: 236.179 (lr:0.000100000000001945)
57120: accuracy:0.26 loss: 244.839 (lr:0.00010000000000193529)
57130: accuracy:0.33 loss: 241.897 (lr:0.00010000000000192564)
57140: accuracy:0.3 loss: 226.134 (lr:0.00010000000000191603)
57150: accuracy:0.33 loss: 210.496 (lr:0.00010000000000190648)
57160: accuracy:0.23 loss: 229.062 (lr:0.00010000000000189697)
57170: accuracy:0.25 loss: 234.253 (lr:0.0001000000000018875)
57180: accuracy:0.34 loss: 218.35 (lr:0.0001000000000018781)
57190: accuracy:0.29 loss: 223.605 (lr:0.00010000000000186874)
57200: accuracy:0.25 loss: 251.467 (lr:0.00010000000000185941)
57210: accuracy:0.28 loss: 213.296 (lr:0.00010000000000185014)
57220: accuracy:0.25 loss: 238.937 (lr:0.00010000000000184091)
57230: accuracy:0.22 loss: 249.649 (lr:0.00010000000000183172)
57240: accuracy:0.34 loss: 213.762 (lr:0.00010000000000182259)
57250: accuracy:0.23 loss: 247.509 (lr:0.0001000000000018135)
57260: accuracy:0.28 loss: 229.42 (lr:0.00010000000000180446)
57270: accuracy:0.18 loss: 231.99 (lr:0.00010000000000179546)
57280: accuracy:0.26 loss: 242.121 (lr:0.0001000000000017865)
57290: accuracy:0.25 loss: 241.932 (lr:0.0001000000000017776)
57300: accuracy:0.31 loss: 225.917 (lr:0.00010000000000176873)
57310: accuracy:0.24 loss: 240.51 (lr:0.00010000000000175991)
57320: accuracy:0.27 loss: 234.148 (lr:0.00010000000000175113)
57330: accuracy:0.18 loss: 267.254 (lr:0.0001000000000017424)
57340: accuracy:0.28 loss: 243.878 (lr:0.0001000000000017337)
57350: accuracy:0.31 loss: 235.28 (lr:0.00010000000000172505)
57360: accuracy:0.3 loss: 228.76 (lr:0.00010000000000171645)
57370: accuracy:0.25 loss: 230.236 (lr:0.0001000000000017079)
57380: accuracy:0.29 loss: 239.409 (lr:0.00010000000000169937)
57390: accuracy:0.29 loss: 225.391 (lr:0.0001000000000016909)
57400: accuracy:0.22 loss: 238.834 (lr:0.00010000000000168247)
57410: accuracy:0.27 loss: 220.999 (lr:0.00010000000000167407)
57420: accuracy:0.25 loss: 232.01 (lr:0.00010000000000166572)
57430: accuracy:0.34 loss: 217.648 (lr:0.00010000000000165741)
57440: accuracy:0.2 loss: 246.216 (lr:0.00010000000000164914)
57450: accuracy:0.34 loss: 216.909 (lr:0.00010000000000164092)
57460: accuracy:0.29 loss: 225.862 (lr:0.00010000000000163275)
57470: accuracy:0.33 loss: 222.005 (lr:0.0001000000000016246)
57480: accuracy:0.4 loss: 226.243 (lr:0.0001000000000016165)
57490: accuracy:0.33 loss: 239.608 (lr:0.00010000000000160843)
57500: accuracy:0.32 loss: 238.454 (lr:0.00010000000000160041)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
57500: ********* epoch 6 ********* test accuracy for all:0.234946 test loss: 258.127
57500: ********* epoch 6 ********* test accuracy for mode 0:0.002 test loss: 414.858
57500: ********* epoch 6 ********* test accuracy for mode 1:0.062 test loss: 391.809
57500: ********* epoch 6 ********* test accuracy for mode 2:0.077 test loss: 279.158
57500: ********* epoch 6 ********* test accuracy for mode 24:0.216 test loss: 267.328
57500: ********* epoch 6 ********* test accuracy for mode 25:0.3285 test loss: 238.844
57500: ********* epoch 6 ********* test accuracy for mode 26:0.314 test loss: 177.45
57500: ********* epoch 6 ********* test accuracy for mode 27:0.2975 test loss: 251.86
57500: ********* epoch 6 ********* test accuracy for mode 28:0.2685 test loss: 249.594
57500: ********* epoch 6 ********* test accuracy for mode 29:0.252 test loss: 255.9
57500: ********* epoch 6 ********* test accuracy for mode 30:0.298 test loss: 250.541
57500: ********* epoch 6 ********* test accuracy for mode 31:0.1695 test loss: 259.647
57500: ********* epoch 6 ********* test accuracy for mode 32:0.188 test loss: 253.962
57500: ********* epoch 6 ********* test accuracy for mode 33:0.2535 test loss: 261.024
57500: ********* epoch 6 ********* test accuracy for mode 34:0.0675 test loss: 263.532
57500: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 401.555
57500: ********* epoch 6 ********* test accuracy for mode 36:0.058 test loss: 413.212
57510: accuracy:0.34 loss: 231.715 (lr:0.00010000000000159243)
57520: accuracy:0.36 loss: 213.562 (lr:0.00010000000000158448)
57530: accuracy:0.26 loss: 242.385 (lr:0.00010000000000157658)
57540: accuracy:0.25 loss: 236.154 (lr:0.00010000000000156872)
57550: accuracy:0.29 loss: 232.121 (lr:0.00010000000000156089)
57560: accuracy:0.21 loss: 236.283 (lr:0.00010000000000155311)
57570: accuracy:0.21 loss: 240.992 (lr:0.00010000000000154536)
57580: accuracy:0.4 loss: 213.927 (lr:0.00010000000000153766)
57590: accuracy:0.32 loss: 222.15 (lr:0.00010000000000152999)
57600: accuracy:0.3 loss: 236.117 (lr:0.00010000000000152236)
57610: accuracy:0.27 loss: 253.998 (lr:0.00010000000000151476)
57620: accuracy:0.29 loss: 246.84 (lr:0.00010000000000150721)
57630: accuracy:0.29 loss: 231.678 (lr:0.00010000000000149969)
57640: accuracy:0.28 loss: 240.082 (lr:0.0001000000000014922)
57650: accuracy:0.26 loss: 222.973 (lr:0.00010000000000148477)
57660: accuracy:0.27 loss: 227.032 (lr:0.00010000000000147737)
57670: accuracy:0.26 loss: 220.462 (lr:0.00010000000000146999)
57680: accuracy:0.41 loss: 209.528 (lr:0.00010000000000146266)
57690: accuracy:0.28 loss: 219.02 (lr:0.00010000000000145537)
57700: accuracy:0.21 loss: 253.79 (lr:0.0001000000000014481)
57710: accuracy:0.26 loss: 223.509 (lr:0.00010000000000144088)
57720: accuracy:0.33 loss: 221.875 (lr:0.0001000000000014337)
57730: accuracy:0.26 loss: 241.924 (lr:0.00010000000000142656)
57740: accuracy:0.24 loss: 258.352 (lr:0.00010000000000141944)
57750: accuracy:0.26 loss: 236.167 (lr:0.00010000000000141235)
57760: accuracy:0.28 loss: 240.115 (lr:0.00010000000000140531)
57770: accuracy:0.24 loss: 239.884 (lr:0.0001000000000013983)
57780: accuracy:0.39 loss: 230.944 (lr:0.00010000000000139133)
57790: accuracy:0.29 loss: 235.72 (lr:0.0001000000000013844)
57800: accuracy:0.3 loss: 232.914 (lr:0.00010000000000137748)
57810: accuracy:0.32 loss: 229.506 (lr:0.00010000000000137061)
57820: accuracy:0.34 loss: 224.107 (lr:0.00010000000000136378)
57830: accuracy:0.27 loss: 232.897 (lr:0.00010000000000135698)
57840: accuracy:0.29 loss: 223.227 (lr:0.00010000000000135022)
57850: accuracy:0.27 loss: 232.815 (lr:0.00010000000000134348)
57860: accuracy:0.25 loss: 245.945 (lr:0.00010000000000133677)
57870: accuracy:0.31 loss: 246.866 (lr:0.0001000000000013301)
57880: accuracy:0.4 loss: 218.495 (lr:0.00010000000000132348)
57890: accuracy:0.26 loss: 242.026 (lr:0.00010000000000131688)
57900: accuracy:0.23 loss: 240.495 (lr:0.0001000000000013103)
57910: accuracy:0.27 loss: 253.023 (lr:0.00010000000000130377)
57920: accuracy:0.23 loss: 242.214 (lr:0.00010000000000129727)
57930: accuracy:0.22 loss: 236.792 (lr:0.0001000000000012908)
57940: accuracy:0.3 loss: 245.567 (lr:0.00010000000000128436)
57950: accuracy:0.24 loss: 234.827 (lr:0.00010000000000127795)
57960: accuracy:0.27 loss: 230.237 (lr:0.00010000000000127158)
57970: accuracy:0.28 loss: 231.126 (lr:0.00010000000000126524)
57980: accuracy:0.29 loss: 237.567 (lr:0.00010000000000125893)
57990: accuracy:0.26 loss: 238.515 (lr:0.00010000000000125265)
58000: accuracy:0.3 loss: 220.887 (lr:0.0001000000000012464)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
58000: ********* epoch 6 ********* test accuracy for all:0.235514 test loss: 259.286
58000: ********* epoch 6 ********* test accuracy for mode 0:0.0005 test loss: 417.54
58000: ********* epoch 6 ********* test accuracy for mode 1:0.0615 test loss: 390.012
58000: ********* epoch 6 ********* test accuracy for mode 2:0.0475 test loss: 279.075
58000: ********* epoch 6 ********* test accuracy for mode 24:0.2235 test loss: 270.522
58000: ********* epoch 6 ********* test accuracy for mode 25:0.327 test loss: 244.668
58000: ********* epoch 6 ********* test accuracy for mode 26:0.3605 test loss: 176.202
58000: ********* epoch 6 ********* test accuracy for mode 27:0.2865 test loss: 262.157
58000: ********* epoch 6 ********* test accuracy for mode 28:0.257 test loss: 257.0
58000: ********* epoch 6 ********* test accuracy for mode 29:0.268 test loss: 261.72
58000: ********* epoch 6 ********* test accuracy for mode 30:0.2715 test loss: 255.044
58000: ********* epoch 6 ********* test accuracy for mode 31:0.2225 test loss: 257.733
58000: ********* epoch 6 ********* test accuracy for mode 32:0.1865 test loss: 251.452
58000: ********* epoch 6 ********* test accuracy for mode 33:0.2665 test loss: 257.326
58000: ********* epoch 6 ********* test accuracy for mode 34:0.0795 test loss: 261.452
58000: ********* epoch 6 ********* test accuracy for mode 35:0.0 test loss: 413.454
58000: ********* epoch 6 ********* test accuracy for mode 36:0.0315 test loss: 448.233
58010: accuracy:0.28 loss: 228.34 (lr:0.00010000000000124018)
58020: accuracy:0.25 loss: 235.316 (lr:0.000100000000001234)
58030: accuracy:0.26 loss: 243.166 (lr:0.00010000000000122785)
58040: accuracy:0.35 loss: 210.222 (lr:0.00010000000000122172)
58050: accuracy:0.26 loss: 218.458 (lr:0.00010000000000121563)
58060: accuracy:0.37 loss: 233.778 (lr:0.00010000000000120957)
58070: accuracy:0.31 loss: 230.103 (lr:0.00010000000000120354)
58080: accuracy:0.27 loss: 223.835 (lr:0.00010000000000119753)
58090: accuracy:0.24 loss: 233.248 (lr:0.00010000000000119156)
58100: accuracy:0.35 loss: 212.641 (lr:0.00010000000000118561)
58110: accuracy:0.25 loss: 245.824 (lr:0.0001000000000011797)
58120: accuracy:0.32 loss: 231.514 (lr:0.00010000000000117382)
58130: accuracy:0.26 loss: 232.48 (lr:0.00010000000000116796)
58140: accuracy:0.35 loss: 239.531 (lr:0.00010000000000116213)
58150: accuracy:0.28 loss: 232.497 (lr:0.00010000000000115635)
58160: accuracy:0.29 loss: 215.05 (lr:0.00010000000000115057)
58170: accuracy:0.23 loss: 242.772 (lr:0.00010000000000114484)
58180: accuracy:0.24 loss: 231.963 (lr:0.00010000000000113912)
58190: accuracy:0.35 loss: 222.597 (lr:0.00010000000000113344)
58200: accuracy:0.19 loss: 230.543 (lr:0.00010000000000112779)
58210: accuracy:0.32 loss: 223.216 (lr:0.00010000000000112217)
58220: accuracy:0.21 loss: 233.711 (lr:0.00010000000000111657)
58230: accuracy:0.23 loss: 230.229 (lr:0.000100000000001111)
58240: accuracy:0.31 loss: 230.802 (lr:0.00010000000000110546)
58250: accuracy:0.27 loss: 238.088 (lr:0.00010000000000109994)
58260: accuracy:0.28 loss: 224.093 (lr:0.00010000000000109447)
58270: accuracy:0.35 loss: 242.831 (lr:0.000100000000001089)
58280: accuracy:0.26 loss: 244.186 (lr:0.00010000000000108357)
58290: accuracy:0.29 loss: 233.733 (lr:0.00010000000000107816)
58300: accuracy:0.38 loss: 196.878 (lr:0.00010000000000107278)
58310: accuracy:0.25 loss: 231.585 (lr:0.00010000000000106744)
58320: accuracy:0.28 loss: 227.233 (lr:0.00010000000000106212)
58330: accuracy:0.24 loss: 246.784 (lr:0.00010000000000105682)
58340: accuracy:0.32 loss: 230.669 (lr:0.00010000000000105155)
58350: accuracy:0.34 loss: 202.934 (lr:0.0001000000000010463)
58360: accuracy:0.24 loss: 251.223 (lr:0.00010000000000104108)
58370: accuracy:0.36 loss: 222.068 (lr:0.00010000000000103589)
58380: accuracy:0.29 loss: 230.752 (lr:0.00010000000000103073)
58390: accuracy:0.27 loss: 236.53 (lr:0.00010000000000102558)
58400: accuracy:0.22 loss: 243.965 (lr:0.00010000000000102047)
58410: accuracy:0.28 loss: 236.669 (lr:0.00010000000000101537)
58420: accuracy:0.35 loss: 233.318 (lr:0.00010000000000101032)
58430: accuracy:0.35 loss: 215.506 (lr:0.00010000000000100528)
58440: accuracy:0.27 loss: 230.658 (lr:0.00010000000000100026)
58450: accuracy:0.26 loss: 231.315 (lr:0.00010000000000099528)
58460: accuracy:0.33 loss: 232.356 (lr:0.00010000000000099032)
58470: accuracy:0.32 loss: 229.362 (lr:0.00010000000000098537)
58480: accuracy:0.31 loss: 215.897 (lr:0.00010000000000098045)
58490: accuracy:0.34 loss: 220.001 (lr:0.00010000000000097557)
58500: accuracy:0.25 loss: 237.814 (lr:0.0001000000000009707)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
58500: ********* epoch 7 ********* test accuracy for all:0.234014 test loss: 259.392
58500: ********* epoch 7 ********* test accuracy for mode 0:0.001 test loss: 413.362
58500: ********* epoch 7 ********* test accuracy for mode 1:0.0775 test loss: 386.846
58500: ********* epoch 7 ********* test accuracy for mode 2:0.0365 test loss: 280.66
58500: ********* epoch 7 ********* test accuracy for mode 24:0.227 test loss: 270.471
58500: ********* epoch 7 ********* test accuracy for mode 25:0.3185 test loss: 244.793
58500: ********* epoch 7 ********* test accuracy for mode 26:0.3475 test loss: 180.843
58500: ********* epoch 7 ********* test accuracy for mode 27:0.2055 test loss: 272.903
58500: ********* epoch 7 ********* test accuracy for mode 28:0.2665 test loss: 259.386
58500: ********* epoch 7 ********* test accuracy for mode 29:0.298 test loss: 260.324
58500: ********* epoch 7 ********* test accuracy for mode 30:0.1925 test loss: 260.49
58500: ********* epoch 7 ********* test accuracy for mode 31:0.2775 test loss: 253.442
58500: ********* epoch 7 ********* test accuracy for mode 32:0.1575 test loss: 252.354
58500: ********* epoch 7 ********* test accuracy for mode 33:0.268 test loss: 256.336
58500: ********* epoch 7 ********* test accuracy for mode 34:0.126 test loss: 258.866
58500: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 403.455
58500: ********* epoch 7 ********* test accuracy for mode 36:0.0475 test loss: 430.118
58510: accuracy:0.27 loss: 238.297 (lr:0.00010000000000096585)
58520: accuracy:0.27 loss: 232.769 (lr:0.00010000000000096104)
58530: accuracy:0.2 loss: 265.652 (lr:0.00010000000000095624)
58540: accuracy:0.34 loss: 214.535 (lr:0.00010000000000095147)
58550: accuracy:0.19 loss: 260.64 (lr:0.00010000000000094673)
58560: accuracy:0.34 loss: 225.418 (lr:0.00010000000000094201)
58570: accuracy:0.3 loss: 224.085 (lr:0.00010000000000093731)
58580: accuracy:0.35 loss: 216.367 (lr:0.00010000000000093264)
58590: accuracy:0.27 loss: 236.776 (lr:0.00010000000000092799)
58600: accuracy:0.2 loss: 252.896 (lr:0.00010000000000092335)
58610: accuracy:0.31 loss: 230.731 (lr:0.00010000000000091876)
58620: accuracy:0.26 loss: 228.237 (lr:0.00010000000000091418)
58630: accuracy:0.29 loss: 227.888 (lr:0.00010000000000090961)
58640: accuracy:0.32 loss: 228.281 (lr:0.00010000000000090507)
58650: accuracy:0.21 loss: 252.863 (lr:0.00010000000000090056)
58660: accuracy:0.39 loss: 218.158 (lr:0.00010000000000089607)
58670: accuracy:0.35 loss: 230.457 (lr:0.0001000000000008916)
58680: accuracy:0.3 loss: 232.123 (lr:0.00010000000000088715)
58690: accuracy:0.27 loss: 238.392 (lr:0.00010000000000088272)
58700: accuracy:0.23 loss: 261.006 (lr:0.00010000000000087833)
58710: accuracy:0.29 loss: 223.638 (lr:0.00010000000000087394)
58720: accuracy:0.31 loss: 218.372 (lr:0.00010000000000086959)
58730: accuracy:0.25 loss: 235.414 (lr:0.00010000000000086525)
58740: accuracy:0.27 loss: 228.154 (lr:0.00010000000000086093)
58750: accuracy:0.3 loss: 228.922 (lr:0.00010000000000085663)
58760: accuracy:0.25 loss: 240.075 (lr:0.00010000000000085236)
58770: accuracy:0.33 loss: 237.726 (lr:0.00010000000000084812)
58780: accuracy:0.27 loss: 235.177 (lr:0.00010000000000084388)
58790: accuracy:0.27 loss: 238.326 (lr:0.00010000000000083968)
58800: accuracy:0.37 loss: 247.361 (lr:0.00010000000000083549)
58810: accuracy:0.32 loss: 235.27 (lr:0.00010000000000083132)
58820: accuracy:0.31 loss: 223.781 (lr:0.00010000000000082717)
58830: accuracy:0.32 loss: 231.237 (lr:0.00010000000000082305)
58840: accuracy:0.3 loss: 233.433 (lr:0.00010000000000081894)
58850: accuracy:0.29 loss: 212.182 (lr:0.00010000000000081486)
58860: accuracy:0.25 loss: 246.574 (lr:0.0001000000000008108)
58870: accuracy:0.31 loss: 230.145 (lr:0.00010000000000080676)
58880: accuracy:0.25 loss: 244.879 (lr:0.00010000000000080273)
58890: accuracy:0.31 loss: 228.085 (lr:0.00010000000000079872)
58900: accuracy:0.37 loss: 222.997 (lr:0.00010000000000079474)
58910: accuracy:0.18 loss: 237.827 (lr:0.00010000000000079078)
58920: accuracy:0.28 loss: 233.644 (lr:0.00010000000000078684)
58930: accuracy:0.32 loss: 218.087 (lr:0.00010000000000078291)
58940: accuracy:0.27 loss: 228.697 (lr:0.000100000000000779)
58950: accuracy:0.22 loss: 237.911 (lr:0.00010000000000077511)
58960: accuracy:0.26 loss: 222.645 (lr:0.00010000000000077125)
58970: accuracy:0.4 loss: 204.184 (lr:0.0001000000000007674)
58980: accuracy:0.35 loss: 216.441 (lr:0.00010000000000076358)
58990: accuracy:0.31 loss: 229.038 (lr:0.00010000000000075977)
59000: accuracy:0.3 loss: 222.951 (lr:0.00010000000000075598)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
59000: ********* epoch 7 ********* test accuracy for all:0.233932 test loss: 259.771
59000: ********* epoch 7 ********* test accuracy for mode 0:0.001 test loss: 416.481
59000: ********* epoch 7 ********* test accuracy for mode 1:0.0735 test loss: 388.388
59000: ********* epoch 7 ********* test accuracy for mode 2:0.061 test loss: 285.743
59000: ********* epoch 7 ********* test accuracy for mode 24:0.2055 test loss: 263.307
59000: ********* epoch 7 ********* test accuracy for mode 25:0.3145 test loss: 237.77
59000: ********* epoch 7 ********* test accuracy for mode 26:0.368 test loss: 176.181
59000: ********* epoch 7 ********* test accuracy for mode 27:0.2735 test loss: 260.327
59000: ********* epoch 7 ********* test accuracy for mode 28:0.2845 test loss: 250.99
59000: ********* epoch 7 ********* test accuracy for mode 29:0.3 test loss: 257.111
59000: ********* epoch 7 ********* test accuracy for mode 30:0.222 test loss: 256.1
59000: ********* epoch 7 ********* test accuracy for mode 31:0.19 test loss: 261.876
59000: ********* epoch 7 ********* test accuracy for mode 32:0.248 test loss: 251.473
59000: ********* epoch 7 ********* test accuracy for mode 33:0.2205 test loss: 261.449
59000: ********* epoch 7 ********* test accuracy for mode 34:0.0775 test loss: 265.619
59000: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 408.639
59000: ********* epoch 7 ********* test accuracy for mode 36:0.0195 test loss: 444.511
59010: accuracy:0.28 loss: 221.509 (lr:0.00010000000000075221)
59020: accuracy:0.28 loss: 241.895 (lr:0.00010000000000074846)
59030: accuracy:0.3 loss: 224.515 (lr:0.00010000000000074473)
59040: accuracy:0.28 loss: 226.586 (lr:0.00010000000000074102)
59050: accuracy:0.35 loss: 212.637 (lr:0.00010000000000073732)
59060: accuracy:0.3 loss: 231.177 (lr:0.00010000000000073364)
59070: accuracy:0.29 loss: 227.848 (lr:0.00010000000000072998)
59080: accuracy:0.27 loss: 246.453 (lr:0.00010000000000072634)
59090: accuracy:0.26 loss: 225.896 (lr:0.00010000000000072272)
59100: accuracy:0.36 loss: 220.926 (lr:0.00010000000000071912)
59110: accuracy:0.32 loss: 216.816 (lr:0.00010000000000071552)
59120: accuracy:0.28 loss: 261.097 (lr:0.00010000000000071196)
59130: accuracy:0.3 loss: 245.267 (lr:0.00010000000000070841)
59140: accuracy:0.35 loss: 239.192 (lr:0.00010000000000070487)
59150: accuracy:0.37 loss: 210.669 (lr:0.00010000000000070136)
59160: accuracy:0.27 loss: 236.066 (lr:0.00010000000000069787)
59170: accuracy:0.28 loss: 247.471 (lr:0.00010000000000069438)
59180: accuracy:0.27 loss: 221.497 (lr:0.00010000000000069091)
59190: accuracy:0.27 loss: 221.875 (lr:0.00010000000000068747)
59200: accuracy:0.31 loss: 249.669 (lr:0.00010000000000068404)
59210: accuracy:0.27 loss: 225.192 (lr:0.00010000000000068063)
59220: accuracy:0.35 loss: 230.006 (lr:0.00010000000000067724)
59230: accuracy:0.3 loss: 221.361 (lr:0.00010000000000067386)
59240: accuracy:0.27 loss: 229.898 (lr:0.0001000000000006705)
59250: accuracy:0.3 loss: 224.662 (lr:0.00010000000000066716)
59260: accuracy:0.3 loss: 227.612 (lr:0.00010000000000066382)
59270: accuracy:0.35 loss: 217.762 (lr:0.00010000000000066051)
59280: accuracy:0.27 loss: 250.667 (lr:0.00010000000000065722)
59290: accuracy:0.25 loss: 211.27 (lr:0.00010000000000065394)
59300: accuracy:0.24 loss: 234.921 (lr:0.00010000000000065068)
59310: accuracy:0.28 loss: 224.757 (lr:0.00010000000000064744)
59320: accuracy:0.2 loss: 242.683 (lr:0.00010000000000064421)
59330: accuracy:0.23 loss: 235.047 (lr:0.000100000000000641)
59340: accuracy:0.26 loss: 230.777 (lr:0.0001000000000006378)
59350: accuracy:0.37 loss: 243.514 (lr:0.00010000000000063462)
59360: accuracy:0.23 loss: 221.039 (lr:0.00010000000000063144)
59370: accuracy:0.24 loss: 234.394 (lr:0.0001000000000006283)
59380: accuracy:0.33 loss: 208.385 (lr:0.00010000000000062517)
59390: accuracy:0.23 loss: 234.73 (lr:0.00010000000000062205)
59400: accuracy:0.31 loss: 230.663 (lr:0.00010000000000061895)
59410: accuracy:0.2 loss: 240.921 (lr:0.00010000000000061586)
59420: accuracy:0.33 loss: 228.459 (lr:0.00010000000000061278)
59430: accuracy:0.32 loss: 217.828 (lr:0.00010000000000060973)
59440: accuracy:0.24 loss: 250.349 (lr:0.0001000000000006067)
59450: accuracy:0.32 loss: 233.359 (lr:0.00010000000000060366)
59460: accuracy:0.25 loss: 242.174 (lr:0.00010000000000060065)
59470: accuracy:0.4 loss: 232.267 (lr:0.00010000000000059766)
59480: accuracy:0.28 loss: 233.016 (lr:0.00010000000000059468)
59490: accuracy:0.3 loss: 220.672 (lr:0.00010000000000059171)
59500: accuracy:0.33 loss: 227.399 (lr:0.00010000000000058877)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
59500: ********* epoch 7 ********* test accuracy for all:0.233986 test loss: 259.5
59500: ********* epoch 7 ********* test accuracy for mode 0:0.0015 test loss: 419.915
59500: ********* epoch 7 ********* test accuracy for mode 1:0.074 test loss: 391.994
59500: ********* epoch 7 ********* test accuracy for mode 2:0.0675 test loss: 274.31
59500: ********* epoch 7 ********* test accuracy for mode 24:0.183 test loss: 280.043
59500: ********* epoch 7 ********* test accuracy for mode 25:0.311 test loss: 247.043
59500: ********* epoch 7 ********* test accuracy for mode 26:0.3295 test loss: 179.775
59500: ********* epoch 7 ********* test accuracy for mode 27:0.267 test loss: 261.43
59500: ********* epoch 7 ********* test accuracy for mode 28:0.2655 test loss: 256.067
59500: ********* epoch 7 ********* test accuracy for mode 29:0.322 test loss: 255.014
59500: ********* epoch 7 ********* test accuracy for mode 30:0.2125 test loss: 257.951
59500: ********* epoch 7 ********* test accuracy for mode 31:0.224 test loss: 258.832
59500: ********* epoch 7 ********* test accuracy for mode 32:0.175 test loss: 254.982
59500: ********* epoch 7 ********* test accuracy for mode 33:0.267 test loss: 258.114
59500: ********* epoch 7 ********* test accuracy for mode 34:0.081 test loss: 262.222
59500: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 410.738
59500: ********* epoch 7 ********* test accuracy for mode 36:0.043 test loss: 432.033
59510: accuracy:0.3 loss: 230.625 (lr:0.00010000000000058583)
59520: accuracy:0.25 loss: 271.299 (lr:0.0001000000000005829)
59530: accuracy:0.22 loss: 266.953 (lr:0.00010000000000058)
59540: accuracy:0.25 loss: 234.677 (lr:0.0001000000000005771)
59550: accuracy:0.25 loss: 224.991 (lr:0.00010000000000057423)
59560: accuracy:0.35 loss: 210.657 (lr:0.00010000000000057137)
59570: accuracy:0.32 loss: 224.684 (lr:0.0001000000000005685)
59580: accuracy:0.3 loss: 239.738 (lr:0.00010000000000056567)
59590: accuracy:0.31 loss: 215.729 (lr:0.00010000000000056285)
59600: accuracy:0.25 loss: 220.807 (lr:0.00010000000000056005)
59610: accuracy:0.36 loss: 216.136 (lr:0.00010000000000055726)
59620: accuracy:0.29 loss: 225.784 (lr:0.00010000000000055448)
59630: accuracy:0.32 loss: 215.069 (lr:0.00010000000000055171)
59640: accuracy:0.23 loss: 241.029 (lr:0.00010000000000054896)
59650: accuracy:0.29 loss: 250.58 (lr:0.00010000000000054623)
59660: accuracy:0.32 loss: 236.972 (lr:0.00010000000000054349)
59670: accuracy:0.29 loss: 235.407 (lr:0.00010000000000054078)
59680: accuracy:0.28 loss: 221.964 (lr:0.00010000000000053808)
59690: accuracy:0.33 loss: 237.666 (lr:0.0001000000000005354)
59700: accuracy:0.24 loss: 226.511 (lr:0.00010000000000053273)
59710: accuracy:0.25 loss: 234.491 (lr:0.00010000000000053007)
59720: accuracy:0.3 loss: 232.832 (lr:0.00010000000000052743)
59730: accuracy:0.24 loss: 240.013 (lr:0.0001000000000005248)
59740: accuracy:0.38 loss: 224.28 (lr:0.00010000000000052218)
59750: accuracy:0.34 loss: 220.263 (lr:0.00010000000000051958)
59760: accuracy:0.27 loss: 234.088 (lr:0.00010000000000051699)
59770: accuracy:0.31 loss: 224.23 (lr:0.0001000000000005144)
59780: accuracy:0.28 loss: 223.639 (lr:0.00010000000000051184)
59790: accuracy:0.23 loss: 241.975 (lr:0.0001000000000005093)
59800: accuracy:0.25 loss: 224.922 (lr:0.00010000000000050675)
59810: accuracy:0.26 loss: 236.155 (lr:0.00010000000000050423)
59820: accuracy:0.33 loss: 229.174 (lr:0.0001000000000005017)
59830: accuracy:0.34 loss: 231.471 (lr:0.00010000000000049921)
59840: accuracy:0.32 loss: 226.588 (lr:0.00010000000000049672)
59850: accuracy:0.26 loss: 248.486 (lr:0.00010000000000049424)
59860: accuracy:0.29 loss: 220.748 (lr:0.00010000000000049177)
59870: accuracy:0.41 loss: 222.372 (lr:0.00010000000000048932)
59880: accuracy:0.31 loss: 218.852 (lr:0.00010000000000048688)
59890: accuracy:0.25 loss: 248.003 (lr:0.00010000000000048445)
59900: accuracy:0.29 loss: 248.568 (lr:0.00010000000000048204)
59910: accuracy:0.21 loss: 244.535 (lr:0.00010000000000047963)
59920: accuracy:0.33 loss: 222.872 (lr:0.00010000000000047724)
59930: accuracy:0.28 loss: 237.819 (lr:0.00010000000000047486)
59940: accuracy:0.3 loss: 235.609 (lr:0.00010000000000047249)
59950: accuracy:0.31 loss: 208.57 (lr:0.00010000000000047014)
59960: accuracy:0.24 loss: 236.425 (lr:0.0001000000000004678)
59970: accuracy:0.3 loss: 224.323 (lr:0.00010000000000046545)
59980: accuracy:0.19 loss: 264.096 (lr:0.00010000000000046314)
59990: accuracy:0.38 loss: 212.944 (lr:0.00010000000000046083)
60000: accuracy:0.28 loss: 215.401 (lr:0.00010000000000045853)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
60000: ********* epoch 7 ********* test accuracy for all:0.233392 test loss: 259.607
60000: ********* epoch 7 ********* test accuracy for mode 0:0.0015 test loss: 430.233
60000: ********* epoch 7 ********* test accuracy for mode 1:0.0635 test loss: 399.509
60000: ********* epoch 7 ********* test accuracy for mode 2:0.0505 test loss: 279.26
60000: ********* epoch 7 ********* test accuracy for mode 24:0.199 test loss: 272.842
60000: ********* epoch 7 ********* test accuracy for mode 25:0.3725 test loss: 240.675
60000: ********* epoch 7 ********* test accuracy for mode 26:0.2515 test loss: 181.191
60000: ********* epoch 7 ********* test accuracy for mode 27:0.298 test loss: 261.138
60000: ********* epoch 7 ********* test accuracy for mode 28:0.2485 test loss: 260.148
60000: ********* epoch 7 ********* test accuracy for mode 29:0.281 test loss: 263.033
60000: ********* epoch 7 ********* test accuracy for mode 30:0.198 test loss: 259.972
60000: ********* epoch 7 ********* test accuracy for mode 31:0.255 test loss: 256.611
60000: ********* epoch 7 ********* test accuracy for mode 32:0.1895 test loss: 250.815
60000: ********* epoch 7 ********* test accuracy for mode 33:0.2465 test loss: 256.015
60000: ********* epoch 7 ********* test accuracy for mode 34:0.161 test loss: 255.081
60000: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 409.031
60000: ********* epoch 7 ********* test accuracy for mode 36:0.033 test loss: 443.878
60010: accuracy:0.27 loss: 224.526 (lr:0.00010000000000045624)
60020: accuracy:0.28 loss: 235.373 (lr:0.00010000000000045396)
60030: accuracy:0.35 loss: 220.483 (lr:0.0001000000000004517)
60040: accuracy:0.34 loss: 220.092 (lr:0.00010000000000044945)
60050: accuracy:0.25 loss: 237.571 (lr:0.00010000000000044721)
60060: accuracy:0.27 loss: 242.155 (lr:0.00010000000000044497)
60070: accuracy:0.36 loss: 231.278 (lr:0.00010000000000044275)
60080: accuracy:0.31 loss: 237.74 (lr:0.00010000000000044054)
60090: accuracy:0.18 loss: 250.897 (lr:0.00010000000000043835)
60100: accuracy:0.32 loss: 221.607 (lr:0.00010000000000043617)
60110: accuracy:0.28 loss: 247.275 (lr:0.00010000000000043398)
60120: accuracy:0.31 loss: 231.121 (lr:0.00010000000000043183)
60130: accuracy:0.28 loss: 234.138 (lr:0.00010000000000042967)
60140: accuracy:0.33 loss: 223.511 (lr:0.00010000000000042753)
60150: accuracy:0.25 loss: 236.729 (lr:0.00010000000000042539)
60160: accuracy:0.24 loss: 275.307 (lr:0.00010000000000042328)
60170: accuracy:0.29 loss: 227.152 (lr:0.00010000000000042116)
60180: accuracy:0.27 loss: 224.5 (lr:0.00010000000000041906)
60190: accuracy:0.31 loss: 216.631 (lr:0.00010000000000041698)
60200: accuracy:0.28 loss: 225.703 (lr:0.00010000000000041489)
60210: accuracy:0.28 loss: 234.855 (lr:0.00010000000000041283)
60220: accuracy:0.39 loss: 220.827 (lr:0.00010000000000041077)
60230: accuracy:0.31 loss: 226.118 (lr:0.00010000000000040872)
60240: accuracy:0.26 loss: 234.016 (lr:0.00010000000000040668)
60250: accuracy:0.25 loss: 240.732 (lr:0.00010000000000040466)
60260: accuracy:0.33 loss: 230.156 (lr:0.00010000000000040264)
60270: accuracy:0.3 loss: 233.96 (lr:0.00010000000000040062)
60280: accuracy:0.25 loss: 236.171 (lr:0.00010000000000039863)
60290: accuracy:0.34 loss: 219.682 (lr:0.00010000000000039663)
60300: accuracy:0.34 loss: 215.391 (lr:0.00010000000000039465)
60310: accuracy:0.29 loss: 232.894 (lr:0.00010000000000039269)
60320: accuracy:0.33 loss: 223.772 (lr:0.00010000000000039074)
60330: accuracy:0.24 loss: 235.83 (lr:0.00010000000000038879)
60340: accuracy:0.3 loss: 240.629 (lr:0.00010000000000038685)
60350: accuracy:0.33 loss: 208.154 (lr:0.00010000000000038491)
60360: accuracy:0.32 loss: 222.294 (lr:0.000100000000000383)
60370: accuracy:0.29 loss: 229.098 (lr:0.00010000000000038109)
60380: accuracy:0.32 loss: 233.036 (lr:0.00010000000000037919)
60390: accuracy:0.33 loss: 224.316 (lr:0.0001000000000003773)
60400: accuracy:0.28 loss: 232.132 (lr:0.00010000000000037541)
60410: accuracy:0.26 loss: 236.788 (lr:0.00010000000000037354)
60420: accuracy:0.26 loss: 226.788 (lr:0.00010000000000037168)
60430: accuracy:0.34 loss: 228.872 (lr:0.00010000000000036983)
60440: accuracy:0.22 loss: 234.152 (lr:0.00010000000000036798)
60450: accuracy:0.32 loss: 223.24 (lr:0.00010000000000036614)
60460: accuracy:0.32 loss: 233.447 (lr:0.00010000000000036432)
60470: accuracy:0.33 loss: 226.854 (lr:0.0001000000000003625)
60480: accuracy:0.28 loss: 233.272 (lr:0.00010000000000036069)
60490: accuracy:0.3 loss: 238.213 (lr:0.00010000000000035889)
60500: accuracy:0.34 loss: 226.609 (lr:0.0001000000000003571)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
60500: ********* epoch 7 ********* test accuracy for all:0.236662 test loss: 257.887
60500: ********* epoch 7 ********* test accuracy for mode 0:0.001 test loss: 408.173
60500: ********* epoch 7 ********* test accuracy for mode 1:0.0885 test loss: 382.957
60500: ********* epoch 7 ********* test accuracy for mode 2:0.026 test loss: 280.241
60500: ********* epoch 7 ********* test accuracy for mode 24:0.2365 test loss: 263.098
60500: ********* epoch 7 ********* test accuracy for mode 25:0.3205 test loss: 241.349
60500: ********* epoch 7 ********* test accuracy for mode 26:0.3145 test loss: 178.078
60500: ********* epoch 7 ********* test accuracy for mode 27:0.283 test loss: 255.944
60500: ********* epoch 7 ********* test accuracy for mode 28:0.3155 test loss: 246.627
60500: ********* epoch 7 ********* test accuracy for mode 29:0.2925 test loss: 255.454
60500: ********* epoch 7 ********* test accuracy for mode 30:0.2155 test loss: 256.848
60500: ********* epoch 7 ********* test accuracy for mode 31:0.2245 test loss: 258.672
60500: ********* epoch 7 ********* test accuracy for mode 32:0.1905 test loss: 252.059
60500: ********* epoch 7 ********* test accuracy for mode 33:0.2385 test loss: 256.589
60500: ********* epoch 7 ********* test accuracy for mode 34:0.147 test loss: 256.021
60500: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 406.029
60500: ********* epoch 7 ********* test accuracy for mode 36:0.0285 test loss: 423.489
60510: accuracy:0.26 loss: 237.445 (lr:0.00010000000000035532)
60520: accuracy:0.28 loss: 237.02 (lr:0.00010000000000035355)
60530: accuracy:0.26 loss: 232.202 (lr:0.00010000000000035179)
60540: accuracy:0.33 loss: 234.116 (lr:0.00010000000000035003)
60550: accuracy:0.29 loss: 228.788 (lr:0.00010000000000034829)
60560: accuracy:0.27 loss: 240.712 (lr:0.00010000000000034654)
60570: accuracy:0.3 loss: 217.315 (lr:0.00010000000000034482)
60580: accuracy:0.33 loss: 229.319 (lr:0.0001000000000003431)
60590: accuracy:0.25 loss: 238.029 (lr:0.00010000000000034139)
60600: accuracy:0.37 loss: 214.485 (lr:0.00010000000000033969)
60610: accuracy:0.29 loss: 233.367 (lr:0.00010000000000033799)
60620: accuracy:0.24 loss: 227.914 (lr:0.00010000000000033631)
60630: accuracy:0.27 loss: 244.892 (lr:0.00010000000000033463)
60640: accuracy:0.31 loss: 230.835 (lr:0.00010000000000033296)
60650: accuracy:0.27 loss: 222.191 (lr:0.0001000000000003313)
60660: accuracy:0.31 loss: 239.775 (lr:0.00010000000000032964)
60670: accuracy:0.28 loss: 236.111 (lr:0.000100000000000328)
60680: accuracy:0.29 loss: 235.724 (lr:0.00010000000000032636)
60690: accuracy:0.31 loss: 217.253 (lr:0.00010000000000032474)
60700: accuracy:0.33 loss: 249.711 (lr:0.00010000000000032312)
60710: accuracy:0.33 loss: 228.051 (lr:0.00010000000000032151)
60720: accuracy:0.22 loss: 225.644 (lr:0.00010000000000031991)
60730: accuracy:0.32 loss: 240.124 (lr:0.00010000000000031831)
60740: accuracy:0.31 loss: 229.604 (lr:0.00010000000000031673)
60750: accuracy:0.26 loss: 255.823 (lr:0.00010000000000031514)
60760: accuracy:0.27 loss: 232.263 (lr:0.00010000000000031357)
60770: accuracy:0.3 loss: 243.865 (lr:0.00010000000000031201)
60780: accuracy:0.32 loss: 216.982 (lr:0.00010000000000031045)
60790: accuracy:0.31 loss: 223.954 (lr:0.00010000000000030891)
60800: accuracy:0.28 loss: 230.721 (lr:0.00010000000000030736)
60810: accuracy:0.31 loss: 209.725 (lr:0.00010000000000030583)
60820: accuracy:0.31 loss: 233.047 (lr:0.0001000000000003043)
60830: accuracy:0.35 loss: 212.92 (lr:0.00010000000000030278)
60840: accuracy:0.3 loss: 235.871 (lr:0.00010000000000030128)
60850: accuracy:0.24 loss: 256.757 (lr:0.00010000000000029977)
60860: accuracy:0.32 loss: 221.53 (lr:0.00010000000000029828)
60870: accuracy:0.34 loss: 212.257 (lr:0.00010000000000029679)
60880: accuracy:0.24 loss: 238.653 (lr:0.00010000000000029531)
60890: accuracy:0.32 loss: 209.829 (lr:0.00010000000000029384)
60900: accuracy:0.31 loss: 231.798 (lr:0.00010000000000029237)
60910: accuracy:0.32 loss: 216.908 (lr:0.00010000000000029091)
60920: accuracy:0.22 loss: 234.747 (lr:0.00010000000000028946)
60930: accuracy:0.29 loss: 229.547 (lr:0.00010000000000028802)
60940: accuracy:0.31 loss: 218.742 (lr:0.00010000000000028659)
60950: accuracy:0.3 loss: 221.574 (lr:0.00010000000000028515)
60960: accuracy:0.37 loss: 223.38 (lr:0.00010000000000028373)
60970: accuracy:0.43 loss: 207.518 (lr:0.00010000000000028232)
60980: accuracy:0.24 loss: 220.748 (lr:0.00010000000000028091)
60990: accuracy:0.33 loss: 219.889 (lr:0.00010000000000027951)
61000: accuracy:0.27 loss: 228.947 (lr:0.00010000000000027812)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
61000: ********* epoch 7 ********* test accuracy for all:0.232297 test loss: 259.724
61000: ********* epoch 7 ********* test accuracy for mode 0:0.0 test loss: 426.604
61000: ********* epoch 7 ********* test accuracy for mode 1:0.066 test loss: 395.307
61000: ********* epoch 7 ********* test accuracy for mode 2:0.0805 test loss: 272.233
61000: ********* epoch 7 ********* test accuracy for mode 24:0.25 test loss: 266.393
61000: ********* epoch 7 ********* test accuracy for mode 25:0.3505 test loss: 241.771
61000: ********* epoch 7 ********* test accuracy for mode 26:0.276 test loss: 183.776
61000: ********* epoch 7 ********* test accuracy for mode 27:0.232 test loss: 273.009
61000: ********* epoch 7 ********* test accuracy for mode 28:0.259 test loss: 264.517
61000: ********* epoch 7 ********* test accuracy for mode 29:0.297 test loss: 265.474
61000: ********* epoch 7 ********* test accuracy for mode 30:0.211 test loss: 263.546
61000: ********* epoch 7 ********* test accuracy for mode 31:0.1795 test loss: 263.118
61000: ********* epoch 7 ********* test accuracy for mode 32:0.211 test loss: 251.955
61000: ********* epoch 7 ********* test accuracy for mode 33:0.254 test loss: 256.884
61000: ********* epoch 7 ********* test accuracy for mode 34:0.124 test loss: 256.32
61000: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 413.341
61000: ********* epoch 7 ********* test accuracy for mode 36:0.025 test loss: 448.895
61010: accuracy:0.28 loss: 241.213 (lr:0.00010000000000027672)
61020: accuracy:0.29 loss: 229.456 (lr:0.00010000000000027535)
61030: accuracy:0.36 loss: 222.711 (lr:0.00010000000000027397)
61040: accuracy:0.26 loss: 241.668 (lr:0.0001000000000002726)
61050: accuracy:0.31 loss: 218.633 (lr:0.00010000000000027125)
61060: accuracy:0.31 loss: 209.982 (lr:0.00010000000000026989)
61070: accuracy:0.26 loss: 228.846 (lr:0.00010000000000026855)
61080: accuracy:0.27 loss: 228.405 (lr:0.0001000000000002672)
61090: accuracy:0.2 loss: 224.321 (lr:0.00010000000000026588)
61100: accuracy:0.32 loss: 225.626 (lr:0.00010000000000026455)
61110: accuracy:0.24 loss: 226.238 (lr:0.00010000000000026324)
61120: accuracy:0.23 loss: 246.1 (lr:0.00010000000000026192)
61130: accuracy:0.22 loss: 248.105 (lr:0.0001000000000002606)
61140: accuracy:0.34 loss: 211.771 (lr:0.0001000000000002593)
61150: accuracy:0.27 loss: 225.345 (lr:0.00010000000000025802)
61160: accuracy:0.32 loss: 229.3 (lr:0.00010000000000025673)
61170: accuracy:0.25 loss: 236.17 (lr:0.00010000000000025546)
61180: accuracy:0.26 loss: 229.425 (lr:0.00010000000000025418)
61190: accuracy:0.25 loss: 242.944 (lr:0.00010000000000025291)
61200: accuracy:0.29 loss: 232.023 (lr:0.00010000000000025165)
61210: accuracy:0.25 loss: 233.9 (lr:0.00010000000000025039)
61220: accuracy:0.24 loss: 245.853 (lr:0.00010000000000024914)
61230: accuracy:0.22 loss: 248.696 (lr:0.00010000000000024791)
61240: accuracy:0.26 loss: 230.05 (lr:0.00010000000000024666)
61250: accuracy:0.32 loss: 242.867 (lr:0.00010000000000024544)
61260: accuracy:0.35 loss: 220.706 (lr:0.00010000000000024421)
61270: accuracy:0.32 loss: 218.535 (lr:0.00010000000000024299)
61280: accuracy:0.27 loss: 223.577 (lr:0.00010000000000024178)
61290: accuracy:0.3 loss: 235.847 (lr:0.00010000000000024058)
61300: accuracy:0.25 loss: 236.878 (lr:0.00010000000000023937)
61310: accuracy:0.33 loss: 221.009 (lr:0.00010000000000023818)
61320: accuracy:0.3 loss: 226.638 (lr:0.000100000000000237)
61330: accuracy:0.24 loss: 235.665 (lr:0.0001000000000002358)
61340: accuracy:0.32 loss: 205.407 (lr:0.00010000000000023464)
61350: accuracy:0.37 loss: 220.144 (lr:0.00010000000000023346)
61360: accuracy:0.31 loss: 221.351 (lr:0.0001000000000002323)
61370: accuracy:0.24 loss: 218.173 (lr:0.00010000000000023114)
61380: accuracy:0.33 loss: 204.744 (lr:0.00010000000000022999)
61390: accuracy:0.26 loss: 217.231 (lr:0.00010000000000022884)
61400: accuracy:0.37 loss: 209.945 (lr:0.0001000000000002277)
61410: accuracy:0.29 loss: 231.776 (lr:0.00010000000000022656)
61420: accuracy:0.3 loss: 235.114 (lr:0.00010000000000022544)
61430: accuracy:0.34 loss: 207.32 (lr:0.00010000000000022431)
61440: accuracy:0.27 loss: 224.31 (lr:0.00010000000000022319)
61450: accuracy:0.27 loss: 218.101 (lr:0.00010000000000022208)
61460: accuracy:0.32 loss: 221.12 (lr:0.00010000000000022097)
61470: accuracy:0.27 loss: 230.358 (lr:0.00010000000000021987)
61480: accuracy:0.28 loss: 224.871 (lr:0.00010000000000021877)
61490: accuracy:0.39 loss: 215.73 (lr:0.00010000000000021769)
61500: accuracy:0.3 loss: 221.788 (lr:0.0001000000000002166)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
61500: ********* epoch 7 ********* test accuracy for all:0.239568 test loss: 259.229
61500: ********* epoch 7 ********* test accuracy for mode 0:0.0035 test loss: 415.08
61500: ********* epoch 7 ********* test accuracy for mode 1:0.0755 test loss: 388.96
61500: ********* epoch 7 ********* test accuracy for mode 2:0.094 test loss: 272.544
61500: ********* epoch 7 ********* test accuracy for mode 24:0.2245 test loss: 268.493
61500: ********* epoch 7 ********* test accuracy for mode 25:0.367 test loss: 237.586
61500: ********* epoch 7 ********* test accuracy for mode 26:0.3165 test loss: 176.8
61500: ********* epoch 7 ********* test accuracy for mode 27:0.2385 test loss: 264.342
61500: ********* epoch 7 ********* test accuracy for mode 28:0.283 test loss: 255.622
61500: ********* epoch 7 ********* test accuracy for mode 29:0.294 test loss: 260.527
61500: ********* epoch 7 ********* test accuracy for mode 30:0.213 test loss: 260.479
61500: ********* epoch 7 ********* test accuracy for mode 31:0.1875 test loss: 260.166
61500: ********* epoch 7 ********* test accuracy for mode 32:0.2225 test loss: 249.978
61500: ********* epoch 7 ********* test accuracy for mode 33:0.2645 test loss: 256.001
61500: ********* epoch 7 ********* test accuracy for mode 34:0.08 test loss: 259.333
61500: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 408.587
61500: ********* epoch 7 ********* test accuracy for mode 36:0.091 test loss: 420.798
61510: accuracy:0.28 loss: 233.826 (lr:0.00010000000000021552)
61520: accuracy:0.28 loss: 231.096 (lr:0.00010000000000021445)
61530: accuracy:0.34 loss: 213.644 (lr:0.00010000000000021338)
61540: accuracy:0.29 loss: 227.835 (lr:0.0001000000000002123)
61550: accuracy:0.21 loss: 239.873 (lr:0.00010000000000021125)
61560: accuracy:0.27 loss: 222.654 (lr:0.00010000000000021019)
61570: accuracy:0.29 loss: 227.491 (lr:0.00010000000000020915)
61580: accuracy:0.29 loss: 215.392 (lr:0.0001000000000002081)
61590: accuracy:0.23 loss: 231.345 (lr:0.00010000000000020706)
61600: accuracy:0.38 loss: 237.73 (lr:0.00010000000000020603)
61610: accuracy:0.28 loss: 227.784 (lr:0.000100000000000205)
61620: accuracy:0.32 loss: 230.888 (lr:0.00010000000000020398)
61630: accuracy:0.28 loss: 234.634 (lr:0.00010000000000020297)
61640: accuracy:0.27 loss: 236.073 (lr:0.00010000000000020195)
61650: accuracy:0.27 loss: 230.27 (lr:0.00010000000000020095)
61660: accuracy:0.27 loss: 219.314 (lr:0.00010000000000019995)
61670: accuracy:0.25 loss: 226.191 (lr:0.00010000000000019894)
61680: accuracy:0.24 loss: 229.54 (lr:0.00010000000000019795)
61690: accuracy:0.29 loss: 217.7 (lr:0.00010000000000019696)
61700: accuracy:0.24 loss: 239.203 (lr:0.00010000000000019599)
61710: accuracy:0.25 loss: 244.605 (lr:0.00010000000000019501)
61720: accuracy:0.25 loss: 224.98 (lr:0.00010000000000019404)
61730: accuracy:0.19 loss: 252.756 (lr:0.00010000000000019306)
61740: accuracy:0.22 loss: 228.552 (lr:0.0001000000000001921)
61750: accuracy:0.34 loss: 221.161 (lr:0.00010000000000019115)
61760: accuracy:0.24 loss: 232.076 (lr:0.00010000000000019019)
61770: accuracy:0.34 loss: 233.5 (lr:0.00010000000000018924)
61780: accuracy:0.31 loss: 231.866 (lr:0.0001000000000001883)
61790: accuracy:0.32 loss: 229.701 (lr:0.00010000000000018735)
61800: accuracy:0.32 loss: 225.683 (lr:0.00010000000000018642)
61810: accuracy:0.3 loss: 225.552 (lr:0.0001000000000001855)
61820: accuracy:0.33 loss: 214.501 (lr:0.00010000000000018458)
61830: accuracy:0.42 loss: 201.019 (lr:0.00010000000000018366)
61840: accuracy:0.28 loss: 239.379 (lr:0.00010000000000018273)
61850: accuracy:0.35 loss: 236.881 (lr:0.00010000000000018183)
61860: accuracy:0.22 loss: 239.214 (lr:0.00010000000000018092)
61870: accuracy:0.34 loss: 219.555 (lr:0.00010000000000018001)
61880: accuracy:0.27 loss: 243.614 (lr:0.00010000000000017911)
61890: accuracy:0.42 loss: 212.658 (lr:0.00010000000000017822)
61900: accuracy:0.32 loss: 225.387 (lr:0.00010000000000017734)
61910: accuracy:0.28 loss: 233.48 (lr:0.00010000000000017645)
61920: accuracy:0.28 loss: 235.755 (lr:0.00010000000000017556)
61930: accuracy:0.3 loss: 223.701 (lr:0.0001000000000001747)
61940: accuracy:0.39 loss: 205.338 (lr:0.00010000000000017383)
61950: accuracy:0.27 loss: 220.428 (lr:0.00010000000000017296)
61960: accuracy:0.3 loss: 225.731 (lr:0.0001000000000001721)
61970: accuracy:0.3 loss: 234.932 (lr:0.00010000000000017124)
61980: accuracy:0.35 loss: 221.145 (lr:0.00010000000000017039)
61990: accuracy:0.28 loss: 224.352 (lr:0.00010000000000016953)
62000: accuracy:0.33 loss: 219.553 (lr:0.00010000000000016868)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
62000: ********* epoch 7 ********* test accuracy for all:0.238135 test loss: 256.9
62000: ********* epoch 7 ********* test accuracy for mode 0:0.0015 test loss: 420.999
62000: ********* epoch 7 ********* test accuracy for mode 1:0.064 test loss: 395.675
62000: ********* epoch 7 ********* test accuracy for mode 2:0.0675 test loss: 274.689
62000: ********* epoch 7 ********* test accuracy for mode 24:0.2335 test loss: 259.713
62000: ********* epoch 7 ********* test accuracy for mode 25:0.387 test loss: 227.975
62000: ********* epoch 7 ********* test accuracy for mode 26:0.274 test loss: 176.04
62000: ********* epoch 7 ********* test accuracy for mode 27:0.291 test loss: 249.179
62000: ********* epoch 7 ********* test accuracy for mode 28:0.293 test loss: 244.057
62000: ********* epoch 7 ********* test accuracy for mode 29:0.2865 test loss: 256.189
62000: ********* epoch 7 ********* test accuracy for mode 30:0.18 test loss: 256.692
62000: ********* epoch 7 ********* test accuracy for mode 31:0.26 test loss: 255.117
62000: ********* epoch 7 ********* test accuracy for mode 32:0.148 test loss: 254.63
62000: ********* epoch 7 ********* test accuracy for mode 33:0.243 test loss: 260.083
62000: ********* epoch 7 ********* test accuracy for mode 34:0.1175 test loss: 261.572
62000: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 410.7
62000: ********* epoch 7 ********* test accuracy for mode 36:0.038 test loss: 431.816
62010: accuracy:0.23 loss: 243.619 (lr:0.00010000000000016784)
62020: accuracy:0.28 loss: 226.282 (lr:0.00010000000000016701)
62030: accuracy:0.24 loss: 238.374 (lr:0.00010000000000016617)
62040: accuracy:0.33 loss: 214.625 (lr:0.00010000000000016535)
62050: accuracy:0.23 loss: 247.584 (lr:0.00010000000000016452)
62060: accuracy:0.27 loss: 221.542 (lr:0.0001000000000001637)
62070: accuracy:0.3 loss: 224.273 (lr:0.00010000000000016288)
62080: accuracy:0.28 loss: 223.429 (lr:0.00010000000000016207)
62090: accuracy:0.37 loss: 195.796 (lr:0.00010000000000016127)
62100: accuracy:0.36 loss: 221.471 (lr:0.00010000000000016045)
62110: accuracy:0.29 loss: 243.417 (lr:0.00010000000000015965)
62120: accuracy:0.26 loss: 223.912 (lr:0.00010000000000015887)
62130: accuracy:0.2 loss: 260.587 (lr:0.00010000000000015807)
62140: accuracy:0.27 loss: 242.437 (lr:0.00010000000000015728)
62150: accuracy:0.32 loss: 216.001 (lr:0.0001000000000001565)
62160: accuracy:0.21 loss: 238.769 (lr:0.00010000000000015572)
62170: accuracy:0.29 loss: 232.283 (lr:0.00010000000000015494)
62180: accuracy:0.28 loss: 225.551 (lr:0.00010000000000015416)
62190: accuracy:0.32 loss: 234.03 (lr:0.0001000000000001534)
62200: accuracy:0.3 loss: 230.956 (lr:0.00010000000000015263)
62210: accuracy:0.22 loss: 249.592 (lr:0.00010000000000015187)
62220: accuracy:0.2 loss: 235.636 (lr:0.00010000000000015112)
62230: accuracy:0.26 loss: 232.346 (lr:0.00010000000000015036)
62240: accuracy:0.37 loss: 199.112 (lr:0.00010000000000014961)
62250: accuracy:0.28 loss: 217.959 (lr:0.00010000000000014887)
62260: accuracy:0.27 loss: 227.807 (lr:0.00010000000000014812)
62270: accuracy:0.24 loss: 229.031 (lr:0.00010000000000014739)
62280: accuracy:0.3 loss: 241.903 (lr:0.00010000000000014664)
62290: accuracy:0.24 loss: 220.978 (lr:0.00010000000000014591)
62300: accuracy:0.29 loss: 215.373 (lr:0.00010000000000014519)
62310: accuracy:0.22 loss: 243.142 (lr:0.00010000000000014446)
62320: accuracy:0.3 loss: 232.929 (lr:0.00010000000000014374)
62330: accuracy:0.29 loss: 223.917 (lr:0.00010000000000014302)
62340: accuracy:0.29 loss: 253.782 (lr:0.00010000000000014232)
62350: accuracy:0.27 loss: 240.139 (lr:0.0001000000000001416)
62360: accuracy:0.24 loss: 235.207 (lr:0.0001000000000001409)
62370: accuracy:0.32 loss: 229.112 (lr:0.00010000000000014019)
62380: accuracy:0.29 loss: 234.946 (lr:0.0001000000000001395)
62390: accuracy:0.27 loss: 220.791 (lr:0.0001000000000001388)
62400: accuracy:0.31 loss: 223.068 (lr:0.0001000000000001381)
62410: accuracy:0.33 loss: 224.614 (lr:0.00010000000000013741)
62420: accuracy:0.29 loss: 233.684 (lr:0.00010000000000013674)
62430: accuracy:0.33 loss: 215.842 (lr:0.00010000000000013606)
62440: accuracy:0.29 loss: 213.891 (lr:0.00010000000000013538)
62450: accuracy:0.36 loss: 207.356 (lr:0.0001000000000001347)
62460: accuracy:0.33 loss: 233.324 (lr:0.00010000000000013403)
62470: accuracy:0.41 loss: 218.847 (lr:0.00010000000000013336)
62480: accuracy:0.26 loss: 206.956 (lr:0.0001000000000001327)
62490: accuracy:0.25 loss: 233.415 (lr:0.00010000000000013203)
62500: accuracy:0.32 loss: 208.343 (lr:0.00010000000000013137)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
62500: ********* epoch 7 ********* test accuracy for all:0.23677 test loss: 259.15
62500: ********* epoch 7 ********* test accuracy for mode 0:0.0025 test loss: 416.472
62500: ********* epoch 7 ********* test accuracy for mode 1:0.0695 test loss: 392.385
62500: ********* epoch 7 ********* test accuracy for mode 2:0.0725 test loss: 273.013
62500: ********* epoch 7 ********* test accuracy for mode 24:0.208 test loss: 269.349
62500: ********* epoch 7 ********* test accuracy for mode 25:0.3065 test loss: 241.679
62500: ********* epoch 7 ********* test accuracy for mode 26:0.3755 test loss: 173.835
62500: ********* epoch 7 ********* test accuracy for mode 27:0.2585 test loss: 261.503
62500: ********* epoch 7 ********* test accuracy for mode 28:0.303 test loss: 252.638
62500: ********* epoch 7 ********* test accuracy for mode 29:0.2485 test loss: 264.082
62500: ********* epoch 7 ********* test accuracy for mode 30:0.219 test loss: 257.973
62500: ********* epoch 7 ********* test accuracy for mode 31:0.239 test loss: 257.548
62500: ********* epoch 7 ********* test accuracy for mode 32:0.1585 test loss: 253.299
62500: ********* epoch 7 ********* test accuracy for mode 33:0.2445 test loss: 258.231
62500: ********* epoch 7 ********* test accuracy for mode 34:0.1355 test loss: 258.389
62500: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 406.302
62500: ********* epoch 7 ********* test accuracy for mode 36:0.0515 test loss: 421.383
62510: accuracy:0.3 loss: 234.91 (lr:0.00010000000000013072)
62520: accuracy:0.34 loss: 212.842 (lr:0.00010000000000013007)
62530: accuracy:0.19 loss: 232.859 (lr:0.00010000000000012942)
62540: accuracy:0.3 loss: 230.782 (lr:0.00010000000000012877)
62550: accuracy:0.34 loss: 223.07 (lr:0.00010000000000012813)
62560: accuracy:0.27 loss: 234.202 (lr:0.0001000000000001275)
62570: accuracy:0.34 loss: 206.748 (lr:0.00010000000000012686)
62580: accuracy:0.29 loss: 237.317 (lr:0.00010000000000012622)
62590: accuracy:0.32 loss: 228.075 (lr:0.0001000000000001256)
62600: accuracy:0.36 loss: 207.948 (lr:0.00010000000000012497)
62610: accuracy:0.3 loss: 221.023 (lr:0.00010000000000012435)
62620: accuracy:0.25 loss: 216.226 (lr:0.00010000000000012373)
62630: accuracy:0.29 loss: 233.352 (lr:0.0001000000000001231)
62640: accuracy:0.24 loss: 235.201 (lr:0.00010000000000012249)
62650: accuracy:0.35 loss: 207.382 (lr:0.00010000000000012188)
62660: accuracy:0.28 loss: 244.665 (lr:0.00010000000000012127)
62670: accuracy:0.32 loss: 227.549 (lr:0.00010000000000012066)
62680: accuracy:0.24 loss: 224.759 (lr:0.00010000000000012007)
62690: accuracy:0.21 loss: 242.588 (lr:0.00010000000000011947)
62700: accuracy:0.24 loss: 243.815 (lr:0.00010000000000011887)
62710: accuracy:0.27 loss: 239.051 (lr:0.00010000000000011828)
62720: accuracy:0.32 loss: 241.048 (lr:0.0001000000000001177)
62730: accuracy:0.31 loss: 231.503 (lr:0.0001000000000001171)
62740: accuracy:0.3 loss: 221.818 (lr:0.00010000000000011652)
62750: accuracy:0.21 loss: 248.296 (lr:0.00010000000000011593)
62760: accuracy:0.36 loss: 216.549 (lr:0.00010000000000011536)
62770: accuracy:0.25 loss: 249.202 (lr:0.00010000000000011478)
62780: accuracy:0.32 loss: 222.366 (lr:0.00010000000000011421)
62790: accuracy:0.33 loss: 230.574 (lr:0.00010000000000011364)
62800: accuracy:0.42 loss: 211.791 (lr:0.00010000000000011307)
62810: accuracy:0.23 loss: 232.237 (lr:0.00010000000000011252)
62820: accuracy:0.31 loss: 243.499 (lr:0.00010000000000011195)
62830: accuracy:0.29 loss: 244.578 (lr:0.00010000000000011139)
62840: accuracy:0.29 loss: 241.938 (lr:0.00010000000000011084)
62850: accuracy:0.3 loss: 228.74 (lr:0.00010000000000011028)
62860: accuracy:0.27 loss: 243.288 (lr:0.00010000000000010974)
62870: accuracy:0.31 loss: 216.147 (lr:0.00010000000000010918)
62880: accuracy:0.33 loss: 216.32 (lr:0.00010000000000010864)
62890: accuracy:0.31 loss: 213.851 (lr:0.0001000000000001081)
62900: accuracy:0.3 loss: 240.664 (lr:0.00010000000000010756)
62910: accuracy:0.33 loss: 233.304 (lr:0.00010000000000010703)
62920: accuracy:0.35 loss: 224.919 (lr:0.00010000000000010649)
62930: accuracy:0.26 loss: 225.577 (lr:0.00010000000000010596)
62940: accuracy:0.27 loss: 229.845 (lr:0.00010000000000010543)
62950: accuracy:0.33 loss: 226.045 (lr:0.0001000000000001049)
62960: accuracy:0.33 loss: 224.146 (lr:0.00010000000000010439)
62970: accuracy:0.34 loss: 234.995 (lr:0.00010000000000010386)
62980: accuracy:0.3 loss: 220.54 (lr:0.00010000000000010334)
62990: accuracy:0.26 loss: 227.306 (lr:0.00010000000000010283)
63000: accuracy:0.31 loss: 217.773 (lr:0.00010000000000010231)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
63000: ********* epoch 7 ********* test accuracy for all:0.235554 test loss: 259.121
63000: ********* epoch 7 ********* test accuracy for mode 0:0.004 test loss: 412.689
63000: ********* epoch 7 ********* test accuracy for mode 1:0.07 test loss: 397.739
63000: ********* epoch 7 ********* test accuracy for mode 2:0.056 test loss: 275.463
63000: ********* epoch 7 ********* test accuracy for mode 24:0.2485 test loss: 268.391
63000: ********* epoch 7 ********* test accuracy for mode 25:0.2245 test loss: 248.627
63000: ********* epoch 7 ********* test accuracy for mode 26:0.48 test loss: 172.879
63000: ********* epoch 7 ********* test accuracy for mode 27:0.2145 test loss: 273.367
63000: ********* epoch 7 ********* test accuracy for mode 28:0.259 test loss: 264.357
63000: ********* epoch 7 ********* test accuracy for mode 29:0.277 test loss: 263.638
63000: ********* epoch 7 ********* test accuracy for mode 30:0.2535 test loss: 260.538
63000: ********* epoch 7 ********* test accuracy for mode 31:0.16 test loss: 264.898
63000: ********* epoch 7 ********* test accuracy for mode 32:0.225 test loss: 250.775
63000: ********* epoch 7 ********* test accuracy for mode 33:0.2575 test loss: 256.798
63000: ********* epoch 7 ********* test accuracy for mode 34:0.083 test loss: 260.49
63000: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 411.499
63000: ********* epoch 7 ********* test accuracy for mode 36:0.054 test loss: 424.508
63010: accuracy:0.29 loss: 228.69 (lr:0.00010000000000010181)
63020: accuracy:0.24 loss: 247.924 (lr:0.0001000000000001013)
63030: accuracy:0.34 loss: 207.258 (lr:0.0001000000000001008)
63040: accuracy:0.3 loss: 228.827 (lr:0.0001000000000001003)
63050: accuracy:0.25 loss: 223.355 (lr:0.00010000000000009979)
63060: accuracy:0.26 loss: 243.75 (lr:0.00010000000000009929)
63070: accuracy:0.4 loss: 209.644 (lr:0.0001000000000000988)
63080: accuracy:0.24 loss: 225.614 (lr:0.0001000000000000983)
63090: accuracy:0.25 loss: 216.553 (lr:0.00010000000000009781)
63100: accuracy:0.28 loss: 221.546 (lr:0.00010000000000009733)
63110: accuracy:0.33 loss: 228.897 (lr:0.00010000000000009684)
63120: accuracy:0.3 loss: 228.439 (lr:0.00010000000000009636)
63130: accuracy:0.23 loss: 235.354 (lr:0.00010000000000009588)
63140: accuracy:0.23 loss: 243.056 (lr:0.0001000000000000954)
63150: accuracy:0.34 loss: 211.683 (lr:0.00010000000000009493)
63160: accuracy:0.23 loss: 246.286 (lr:0.00010000000000009445)
63170: accuracy:0.23 loss: 221.511 (lr:0.00010000000000009398)
63180: accuracy:0.34 loss: 207.243 (lr:0.0001000000000000935)
63190: accuracy:0.3 loss: 242.119 (lr:0.00010000000000009304)
63200: accuracy:0.28 loss: 224.189 (lr:0.00010000000000009258)
63210: accuracy:0.24 loss: 255.542 (lr:0.00010000000000009212)
63220: accuracy:0.31 loss: 223.86 (lr:0.00010000000000009166)
63230: accuracy:0.37 loss: 212.698 (lr:0.0001000000000000912)
63240: accuracy:0.3 loss: 221.034 (lr:0.00010000000000009075)
63250: accuracy:0.28 loss: 224.033 (lr:0.00010000000000009029)
63260: accuracy:0.24 loss: 228.499 (lr:0.00010000000000008984)
63270: accuracy:0.21 loss: 239.163 (lr:0.0001000000000000894)
63280: accuracy:0.31 loss: 220.803 (lr:0.00010000000000008895)
63290: accuracy:0.25 loss: 229.668 (lr:0.0001000000000000885)
63300: accuracy:0.31 loss: 240.308 (lr:0.00010000000000008807)
63310: accuracy:0.28 loss: 231.81 (lr:0.00010000000000008762)
63320: accuracy:0.24 loss: 233.469 (lr:0.00010000000000008719)
63330: accuracy:0.39 loss: 209.08 (lr:0.00010000000000008675)
63340: accuracy:0.34 loss: 238.494 (lr:0.00010000000000008632)
63350: accuracy:0.25 loss: 226.052 (lr:0.00010000000000008589)
63360: accuracy:0.35 loss: 214.647 (lr:0.00010000000000008547)
63370: accuracy:0.29 loss: 220.428 (lr:0.00010000000000008503)
63380: accuracy:0.22 loss: 250.856 (lr:0.00010000000000008461)
63390: accuracy:0.29 loss: 228.42 (lr:0.00010000000000008419)
63400: accuracy:0.32 loss: 216.861 (lr:0.00010000000000008377)
63410: accuracy:0.37 loss: 200.089 (lr:0.00010000000000008335)
63420: accuracy:0.3 loss: 221.709 (lr:0.00010000000000008293)
63430: accuracy:0.27 loss: 229.978 (lr:0.00010000000000008253)
63440: accuracy:0.42 loss: 226.072 (lr:0.0001000000000000821)
63450: accuracy:0.33 loss: 231.094 (lr:0.0001000000000000817)
63460: accuracy:0.3 loss: 221.421 (lr:0.00010000000000008129)
63470: accuracy:0.25 loss: 235.585 (lr:0.00010000000000008089)
63480: accuracy:0.28 loss: 230.325 (lr:0.00010000000000008048)
63490: accuracy:0.26 loss: 233.521 (lr:0.00010000000000008009)
63500: accuracy:0.29 loss: 237.634 (lr:0.00010000000000007968)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
63500: ********* epoch 7 ********* test accuracy for all:0.237297 test loss: 259.228
63500: ********* epoch 7 ********* test accuracy for mode 0:0.0025 test loss: 415.977
63500: ********* epoch 7 ********* test accuracy for mode 1:0.0705 test loss: 389.219
63500: ********* epoch 7 ********* test accuracy for mode 2:0.0455 test loss: 279.816
63500: ********* epoch 7 ********* test accuracy for mode 24:0.2575 test loss: 267.383
63500: ********* epoch 7 ********* test accuracy for mode 25:0.247 test loss: 246.521
63500: ********* epoch 7 ********* test accuracy for mode 26:0.425 test loss: 173.192
63500: ********* epoch 7 ********* test accuracy for mode 27:0.2495 test loss: 265.418
63500: ********* epoch 7 ********* test accuracy for mode 28:0.2865 test loss: 254.974
63500: ********* epoch 7 ********* test accuracy for mode 29:0.2635 test loss: 265.051
63500: ********* epoch 7 ********* test accuracy for mode 30:0.2515 test loss: 257.681
63500: ********* epoch 7 ********* test accuracy for mode 31:0.2055 test loss: 262.676
63500: ********* epoch 7 ********* test accuracy for mode 32:0.203 test loss: 255.448
63500: ********* epoch 7 ********* test accuracy for mode 33:0.21 test loss: 261.114
63500: ********* epoch 7 ********* test accuracy for mode 34:0.1585 test loss: 259.044
63500: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 412.771
63500: ********* epoch 7 ********* test accuracy for mode 36:0.0315 test loss: 422.107
63510: accuracy:0.27 loss: 250.426 (lr:0.00010000000000007929)
63520: accuracy:0.31 loss: 217.286 (lr:0.0001000000000000789)
63530: accuracy:0.17 loss: 247.814 (lr:0.0001000000000000785)
63540: accuracy:0.3 loss: 240.475 (lr:0.00010000000000007811)
63550: accuracy:0.28 loss: 237.193 (lr:0.00010000000000007771)
63560: accuracy:0.29 loss: 257.445 (lr:0.00010000000000007734)
63570: accuracy:0.38 loss: 220.893 (lr:0.00010000000000007694)
63580: accuracy:0.31 loss: 238.432 (lr:0.00010000000000007656)
63590: accuracy:0.27 loss: 227.054 (lr:0.00010000000000007618)
63600: accuracy:0.28 loss: 231.122 (lr:0.0001000000000000758)
63610: accuracy:0.3 loss: 229.687 (lr:0.00010000000000007542)
63620: accuracy:0.26 loss: 228.122 (lr:0.00010000000000007505)
63630: accuracy:0.25 loss: 235.06 (lr:0.00010000000000007467)
63640: accuracy:0.21 loss: 236.512 (lr:0.0001000000000000743)
63650: accuracy:0.29 loss: 223.392 (lr:0.00010000000000007392)
63660: accuracy:0.3 loss: 229.574 (lr:0.00010000000000007355)
63670: accuracy:0.23 loss: 260.693 (lr:0.00010000000000007319)
63680: accuracy:0.22 loss: 246.984 (lr:0.00010000000000007282)
63690: accuracy:0.18 loss: 259.273 (lr:0.00010000000000007246)
63700: accuracy:0.26 loss: 235.247 (lr:0.0001000000000000721)
63710: accuracy:0.29 loss: 225.517 (lr:0.00010000000000007174)
63720: accuracy:0.27 loss: 240.0 (lr:0.00010000000000007139)
63730: accuracy:0.29 loss: 231.147 (lr:0.00010000000000007103)
63740: accuracy:0.37 loss: 222.789 (lr:0.00010000000000007067)
63750: accuracy:0.26 loss: 236.256 (lr:0.00010000000000007032)
63760: accuracy:0.24 loss: 243.262 (lr:0.00010000000000006998)
63770: accuracy:0.24 loss: 238.87 (lr:0.00010000000000006962)
63780: accuracy:0.28 loss: 241.903 (lr:0.00010000000000006927)
63790: accuracy:0.26 loss: 236.621 (lr:0.00010000000000006893)
63800: accuracy:0.3 loss: 227.553 (lr:0.00010000000000006858)
63810: accuracy:0.31 loss: 232.469 (lr:0.00010000000000006824)
63820: accuracy:0.2 loss: 243.316 (lr:0.0001000000000000679)
63830: accuracy:0.23 loss: 243.577 (lr:0.00010000000000006756)
63840: accuracy:0.36 loss: 209.909 (lr:0.00010000000000006723)
63850: accuracy:0.32 loss: 227.695 (lr:0.00010000000000006689)
63860: accuracy:0.29 loss: 234.761 (lr:0.00010000000000006656)
63870: accuracy:0.34 loss: 219.194 (lr:0.00010000000000006622)
63880: accuracy:0.35 loss: 216.193 (lr:0.0001000000000000659)
63890: accuracy:0.33 loss: 215.103 (lr:0.00010000000000006557)
63900: accuracy:0.29 loss: 219.67 (lr:0.00010000000000006525)
63910: accuracy:0.28 loss: 234.723 (lr:0.00010000000000006492)
63920: accuracy:0.29 loss: 231.984 (lr:0.0001000000000000646)
63930: accuracy:0.3 loss: 225.445 (lr:0.00010000000000006427)
63940: accuracy:0.25 loss: 225.81 (lr:0.00010000000000006395)
63950: accuracy:0.25 loss: 219.886 (lr:0.00010000000000006363)
63960: accuracy:0.37 loss: 223.97 (lr:0.00010000000000006331)
63970: accuracy:0.32 loss: 218.209 (lr:0.000100000000000063)
63980: accuracy:0.3 loss: 228.598 (lr:0.00010000000000006269)
63990: accuracy:0.23 loss: 257.003 (lr:0.00010000000000006237)
64000: accuracy:0.31 loss: 225.335 (lr:0.00010000000000006206)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
64000: ********* epoch 7 ********* test accuracy for all:0.234635 test loss: 258.896
64000: ********* epoch 7 ********* test accuracy for mode 0:0.0055 test loss: 410.118
64000: ********* epoch 7 ********* test accuracy for mode 1:0.0855 test loss: 386.108
64000: ********* epoch 7 ********* test accuracy for mode 2:0.035 test loss: 281.42
64000: ********* epoch 7 ********* test accuracy for mode 24:0.2495 test loss: 271.263
64000: ********* epoch 7 ********* test accuracy for mode 25:0.2915 test loss: 248.012
64000: ********* epoch 7 ********* test accuracy for mode 26:0.405 test loss: 176.596
64000: ********* epoch 7 ********* test accuracy for mode 27:0.256 test loss: 273.845
64000: ********* epoch 7 ********* test accuracy for mode 28:0.235 test loss: 267.659
64000: ********* epoch 7 ********* test accuracy for mode 29:0.265 test loss: 269.527
64000: ********* epoch 7 ********* test accuracy for mode 30:0.261 test loss: 265.276
64000: ********* epoch 7 ********* test accuracy for mode 31:0.184 test loss: 268.972
64000: ********* epoch 7 ********* test accuracy for mode 32:0.147 test loss: 261.092
64000: ********* epoch 7 ********* test accuracy for mode 33:0.2635 test loss: 261.663
64000: ********* epoch 7 ********* test accuracy for mode 34:0.13 test loss: 261.34
64000: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 396.406
64000: ********* epoch 7 ********* test accuracy for mode 36:0.085 test loss: 396.007
64010: accuracy:0.24 loss: 226.345 (lr:0.00010000000000006175)
64020: accuracy:0.17 loss: 251.778 (lr:0.00010000000000006144)
64030: accuracy:0.37 loss: 217.47 (lr:0.00010000000000006114)
64040: accuracy:0.26 loss: 228.615 (lr:0.00010000000000006083)
64050: accuracy:0.19 loss: 240.884 (lr:0.00010000000000006053)
64060: accuracy:0.32 loss: 212.38 (lr:0.00010000000000006022)
64070: accuracy:0.27 loss: 224.861 (lr:0.00010000000000005992)
64080: accuracy:0.29 loss: 239.754 (lr:0.00010000000000005962)
64090: accuracy:0.29 loss: 226.785 (lr:0.00010000000000005932)
64100: accuracy:0.25 loss: 232.653 (lr:0.00010000000000005903)
64110: accuracy:0.22 loss: 243.921 (lr:0.00010000000000005874)
64120: accuracy:0.31 loss: 239.492 (lr:0.00010000000000005844)
64130: accuracy:0.29 loss: 220.861 (lr:0.00010000000000005816)
64140: accuracy:0.28 loss: 235.591 (lr:0.00010000000000005786)
64150: accuracy:0.28 loss: 218.222 (lr:0.00010000000000005758)
64160: accuracy:0.31 loss: 222.363 (lr:0.00010000000000005729)
64170: accuracy:0.22 loss: 250.478 (lr:0.000100000000000057)
64180: accuracy:0.36 loss: 217.695 (lr:0.00010000000000005672)
64190: accuracy:0.29 loss: 233.121 (lr:0.00010000000000005644)
64200: accuracy:0.24 loss: 243.601 (lr:0.00010000000000005615)
64210: accuracy:0.29 loss: 224.923 (lr:0.00010000000000005587)
64220: accuracy:0.3 loss: 212.32 (lr:0.0001000000000000556)
64230: accuracy:0.27 loss: 239.058 (lr:0.00010000000000005531)
64240: accuracy:0.3 loss: 218.932 (lr:0.00010000000000005504)
64250: accuracy:0.32 loss: 217.408 (lr:0.00010000000000005477)
64260: accuracy:0.29 loss: 234.135 (lr:0.0001000000000000545)
64270: accuracy:0.23 loss: 240.872 (lr:0.00010000000000005423)
64280: accuracy:0.27 loss: 228.542 (lr:0.00010000000000005396)
64290: accuracy:0.27 loss: 237.38 (lr:0.00010000000000005369)
64300: accuracy:0.3 loss: 248.047 (lr:0.00010000000000005342)
64310: accuracy:0.32 loss: 226.633 (lr:0.00010000000000005314)
64320: accuracy:0.25 loss: 240.778 (lr:0.00010000000000005289)
64330: accuracy:0.28 loss: 214.841 (lr:0.00010000000000005262)
64340: accuracy:0.3 loss: 229.047 (lr:0.00010000000000005236)
64350: accuracy:0.33 loss: 224.577 (lr:0.0001000000000000521)
64360: accuracy:0.33 loss: 230.479 (lr:0.00010000000000005184)
64370: accuracy:0.25 loss: 228.206 (lr:0.00010000000000005157)
64380: accuracy:0.27 loss: 230.723 (lr:0.00010000000000005131)
64390: accuracy:0.28 loss: 228.793 (lr:0.00010000000000005107)
64400: accuracy:0.25 loss: 239.374 (lr:0.00010000000000005081)
64410: accuracy:0.32 loss: 229.945 (lr:0.00010000000000005056)
64420: accuracy:0.3 loss: 221.263 (lr:0.00010000000000005031)
64430: accuracy:0.26 loss: 246.176 (lr:0.00010000000000005005)
64440: accuracy:0.32 loss: 221.584 (lr:0.00010000000000004981)
64450: accuracy:0.38 loss: 231.776 (lr:0.00010000000000004955)
64460: accuracy:0.29 loss: 226.14 (lr:0.00010000000000004931)
64470: accuracy:0.31 loss: 236.482 (lr:0.00010000000000004906)
64480: accuracy:0.32 loss: 233.277 (lr:0.00010000000000004882)
64490: accuracy:0.22 loss: 244.247 (lr:0.00010000000000004858)
64500: accuracy:0.29 loss: 232.501 (lr:0.00010000000000004833)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
64500: ********* epoch 7 ********* test accuracy for all:0.237135 test loss: 257.625
64500: ********* epoch 7 ********* test accuracy for mode 0:0.01 test loss: 408.131
64500: ********* epoch 7 ********* test accuracy for mode 1:0.0735 test loss: 393.493
64500: ********* epoch 7 ********* test accuracy for mode 2:0.0255 test loss: 283.502
64500: ********* epoch 7 ********* test accuracy for mode 24:0.2675 test loss: 257.122
64500: ********* epoch 7 ********* test accuracy for mode 25:0.303 test loss: 235.015
64500: ********* epoch 7 ********* test accuracy for mode 26:0.3885 test loss: 172.539
64500: ********* epoch 7 ********* test accuracy for mode 27:0.259 test loss: 256.551
64500: ********* epoch 7 ********* test accuracy for mode 28:0.2915 test loss: 248.213
64500: ********* epoch 7 ********* test accuracy for mode 29:0.256 test loss: 254.258
64500: ********* epoch 7 ********* test accuracy for mode 30:0.2835 test loss: 249.372
64500: ********* epoch 7 ********* test accuracy for mode 31:0.206 test loss: 255.055
64500: ********* epoch 7 ********* test accuracy for mode 32:0.1635 test loss: 250.509
64500: ********* epoch 7 ********* test accuracy for mode 33:0.27 test loss: 255.319
64500: ********* epoch 7 ********* test accuracy for mode 34:0.0685 test loss: 259.636
64500: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 397.005
64500: ********* epoch 7 ********* test accuracy for mode 36:0.071 test loss: 423.307
64510: accuracy:0.28 loss: 224.601 (lr:0.00010000000000004809)
64520: accuracy:0.31 loss: 238.037 (lr:0.00010000000000004785)
64530: accuracy:0.34 loss: 214.838 (lr:0.00010000000000004761)
64540: accuracy:0.32 loss: 222.428 (lr:0.00010000000000004737)
64550: accuracy:0.3 loss: 232.255 (lr:0.00010000000000004714)
64560: accuracy:0.26 loss: 228.904 (lr:0.00010000000000004691)
64570: accuracy:0.32 loss: 210.877 (lr:0.00010000000000004667)
64580: accuracy:0.34 loss: 213.137 (lr:0.00010000000000004644)
64590: accuracy:0.34 loss: 208.93 (lr:0.0001000000000000462)
64600: accuracy:0.25 loss: 238.315 (lr:0.00010000000000004597)
64610: accuracy:0.29 loss: 228.963 (lr:0.00010000000000004574)
64620: accuracy:0.29 loss: 224.794 (lr:0.00010000000000004551)
64630: accuracy:0.27 loss: 225.394 (lr:0.0001000000000000453)
64640: accuracy:0.3 loss: 212.396 (lr:0.00010000000000004507)
64650: accuracy:0.3 loss: 234.28 (lr:0.00010000000000004484)
64660: accuracy:0.27 loss: 228.974 (lr:0.00010000000000004462)
64670: accuracy:0.34 loss: 208.681 (lr:0.00010000000000004439)
64680: accuracy:0.22 loss: 253.847 (lr:0.00010000000000004417)
64690: accuracy:0.32 loss: 219.817 (lr:0.00010000000000004396)
64700: accuracy:0.32 loss: 219.156 (lr:0.00010000000000004374)
64710: accuracy:0.27 loss: 248.114 (lr:0.00010000000000004352)
64720: accuracy:0.3 loss: 240.259 (lr:0.0001000000000000433)
64730: accuracy:0.33 loss: 218.889 (lr:0.00010000000000004309)
64740: accuracy:0.37 loss: 243.599 (lr:0.00010000000000004287)
64750: accuracy:0.29 loss: 226.017 (lr:0.00010000000000004265)
64760: accuracy:0.31 loss: 226.41 (lr:0.00010000000000004244)
64770: accuracy:0.28 loss: 234.147 (lr:0.00010000000000004223)
64780: accuracy:0.3 loss: 234.902 (lr:0.00010000000000004202)
64790: accuracy:0.3 loss: 215.18 (lr:0.00010000000000004181)
64800: accuracy:0.31 loss: 227.938 (lr:0.0001000000000000416)
64810: accuracy:0.28 loss: 243.864 (lr:0.0001000000000000414)
64820: accuracy:0.22 loss: 241.212 (lr:0.00010000000000004119)
64830: accuracy:0.34 loss: 209.808 (lr:0.00010000000000004099)
64840: accuracy:0.27 loss: 228.419 (lr:0.00010000000000004077)
64850: accuracy:0.3 loss: 219.571 (lr:0.00010000000000004057)
64860: accuracy:0.3 loss: 231.707 (lr:0.00010000000000004038)
64870: accuracy:0.27 loss: 227.026 (lr:0.00010000000000004017)
64880: accuracy:0.31 loss: 220.911 (lr:0.00010000000000003997)
64890: accuracy:0.27 loss: 227.049 (lr:0.00010000000000003977)
64900: accuracy:0.29 loss: 207.091 (lr:0.00010000000000003958)
64910: accuracy:0.23 loss: 241.878 (lr:0.00010000000000003937)
64920: accuracy:0.31 loss: 205.193 (lr:0.00010000000000003919)
64930: accuracy:0.29 loss: 200.659 (lr:0.00010000000000003898)
64940: accuracy:0.24 loss: 235.126 (lr:0.00010000000000003879)
64950: accuracy:0.33 loss: 228.523 (lr:0.00010000000000003859)
64960: accuracy:0.28 loss: 256.303 (lr:0.0001000000000000384)
64970: accuracy:0.23 loss: 238.723 (lr:0.00010000000000003821)
64980: accuracy:0.22 loss: 250.257 (lr:0.00010000000000003802)
64990: accuracy:0.28 loss: 231.842 (lr:0.00010000000000003783)
65000: accuracy:0.34 loss: 219.566 (lr:0.00010000000000003764)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
65000: ********* epoch 7 ********* test accuracy for all:0.238243 test loss: 257.802
65000: ********* epoch 7 ********* test accuracy for mode 0:0.0025 test loss: 423.361
65000: ********* epoch 7 ********* test accuracy for mode 1:0.06 test loss: 402.987
65000: ********* epoch 7 ********* test accuracy for mode 2:0.0245 test loss: 276.99
65000: ********* epoch 7 ********* test accuracy for mode 24:0.255 test loss: 268.162
65000: ********* epoch 7 ********* test accuracy for mode 25:0.2675 test loss: 244.844
65000: ********* epoch 7 ********* test accuracy for mode 26:0.4355 test loss: 171.529
65000: ********* epoch 7 ********* test accuracy for mode 27:0.2865 test loss: 257.813
65000: ********* epoch 7 ********* test accuracy for mode 28:0.2785 test loss: 255.85
65000: ********* epoch 7 ********* test accuracy for mode 29:0.2955 test loss: 262.439
65000: ********* epoch 7 ********* test accuracy for mode 30:0.1905 test loss: 267.562
65000: ********* epoch 7 ********* test accuracy for mode 31:0.203 test loss: 266.779
65000: ********* epoch 7 ********* test accuracy for mode 32:0.14 test loss: 258.043
65000: ********* epoch 7 ********* test accuracy for mode 33:0.2915 test loss: 257.759
65000: ********* epoch 7 ********* test accuracy for mode 34:0.1075 test loss: 259.061
65000: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 401.118
65000: ********* epoch 7 ********* test accuracy for mode 36:0.0605 test loss: 416.223
65010: accuracy:0.31 loss: 235.507 (lr:0.00010000000000003745)
65020: accuracy:0.38 loss: 218.387 (lr:0.00010000000000003727)
65030: accuracy:0.33 loss: 229.043 (lr:0.00010000000000003708)
65040: accuracy:0.32 loss: 221.769 (lr:0.0001000000000000369)
65050: accuracy:0.23 loss: 247.427 (lr:0.00010000000000003672)
65060: accuracy:0.34 loss: 232.547 (lr:0.00010000000000003653)
65070: accuracy:0.36 loss: 210.108 (lr:0.00010000000000003635)
65080: accuracy:0.29 loss: 221.045 (lr:0.00010000000000003616)
65090: accuracy:0.29 loss: 212.657 (lr:0.00010000000000003599)
65100: accuracy:0.28 loss: 228.326 (lr:0.00010000000000003581)
65110: accuracy:0.38 loss: 214.568 (lr:0.00010000000000003563)
65120: accuracy:0.29 loss: 235.294 (lr:0.00010000000000003544)
65130: accuracy:0.17 loss: 242.964 (lr:0.00010000000000003527)
65140: accuracy:0.38 loss: 230.968 (lr:0.00010000000000003509)
65150: accuracy:0.33 loss: 221.716 (lr:0.00010000000000003493)
65160: accuracy:0.25 loss: 225.554 (lr:0.00010000000000003475)
65170: accuracy:0.37 loss: 212.415 (lr:0.00010000000000003458)
65180: accuracy:0.27 loss: 236.897 (lr:0.0001000000000000344)
65190: accuracy:0.26 loss: 226.566 (lr:0.00010000000000003422)
65200: accuracy:0.31 loss: 221.565 (lr:0.00010000000000003406)
65210: accuracy:0.36 loss: 219.436 (lr:0.00010000000000003389)
65220: accuracy:0.19 loss: 245.645 (lr:0.00010000000000003372)
65230: accuracy:0.32 loss: 226.683 (lr:0.00010000000000003355)
65240: accuracy:0.27 loss: 235.654 (lr:0.00010000000000003338)
65250: accuracy:0.34 loss: 211.592 (lr:0.00010000000000003322)
65260: accuracy:0.24 loss: 228.749 (lr:0.00010000000000003306)
65270: accuracy:0.31 loss: 220.056 (lr:0.00010000000000003288)
65280: accuracy:0.33 loss: 222.838 (lr:0.00010000000000003272)
65290: accuracy:0.28 loss: 227.739 (lr:0.00010000000000003256)
65300: accuracy:0.26 loss: 234.038 (lr:0.0001000000000000324)
65310: accuracy:0.26 loss: 238.373 (lr:0.00010000000000003223)
65320: accuracy:0.24 loss: 237.36 (lr:0.00010000000000003208)
65330: accuracy:0.27 loss: 248.975 (lr:0.00010000000000003192)
65340: accuracy:0.33 loss: 231.265 (lr:0.00010000000000003176)
65350: accuracy:0.31 loss: 226.874 (lr:0.0001000000000000316)
65360: accuracy:0.29 loss: 226.782 (lr:0.00010000000000003145)
65370: accuracy:0.26 loss: 251.867 (lr:0.00010000000000003128)
65380: accuracy:0.31 loss: 237.012 (lr:0.00010000000000003113)
65390: accuracy:0.32 loss: 234.322 (lr:0.00010000000000003097)
65400: accuracy:0.27 loss: 238.22 (lr:0.00010000000000003082)
65410: accuracy:0.31 loss: 235.561 (lr:0.00010000000000003066)
65420: accuracy:0.37 loss: 242.602 (lr:0.00010000000000003051)
65430: accuracy:0.35 loss: 229.224 (lr:0.00010000000000003036)
65440: accuracy:0.27 loss: 241.244 (lr:0.00010000000000003021)
65450: accuracy:0.36 loss: 235.142 (lr:0.00010000000000003006)
65460: accuracy:0.39 loss: 216.571 (lr:0.00010000000000002992)
65470: accuracy:0.26 loss: 226.944 (lr:0.00010000000000002977)
65480: accuracy:0.38 loss: 214.608 (lr:0.00010000000000002962)
65490: accuracy:0.34 loss: 239.199 (lr:0.00010000000000002947)
65500: accuracy:0.3 loss: 232.617 (lr:0.00010000000000002932)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
65500: ********* epoch 7 ********* test accuracy for all:0.236541 test loss: 258.952
65500: ********* epoch 7 ********* test accuracy for mode 0:0.0015 test loss: 426.225
65500: ********* epoch 7 ********* test accuracy for mode 1:0.058 test loss: 406.057
65500: ********* epoch 7 ********* test accuracy for mode 2:0.038 test loss: 275.213
65500: ********* epoch 7 ********* test accuracy for mode 24:0.231 test loss: 272.886
65500: ********* epoch 7 ********* test accuracy for mode 25:0.3065 test loss: 245.846
65500: ********* epoch 7 ********* test accuracy for mode 26:0.322 test loss: 182.153
65500: ********* epoch 7 ********* test accuracy for mode 27:0.2225 test loss: 276.41
65500: ********* epoch 7 ********* test accuracy for mode 28:0.277 test loss: 261.112
65500: ********* epoch 7 ********* test accuracy for mode 29:0.2315 test loss: 268.551
65500: ********* epoch 7 ********* test accuracy for mode 30:0.2535 test loss: 259.891
65500: ********* epoch 7 ********* test accuracy for mode 31:0.224 test loss: 260.562
65500: ********* epoch 7 ********* test accuracy for mode 32:0.152 test loss: 254.293
65500: ********* epoch 7 ********* test accuracy for mode 33:0.2585 test loss: 256.388
65500: ********* epoch 7 ********* test accuracy for mode 34:0.106 test loss: 257.969
65500: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 407.671
65500: ********* epoch 7 ********* test accuracy for mode 36:0.038 test loss: 434.899
65510: accuracy:0.24 loss: 223.6 (lr:0.00010000000000002917)
65520: accuracy:0.26 loss: 239.53 (lr:0.00010000000000002902)
65530: accuracy:0.27 loss: 248.335 (lr:0.00010000000000002889)
65540: accuracy:0.35 loss: 211.064 (lr:0.00010000000000002874)
65550: accuracy:0.28 loss: 220.167 (lr:0.00010000000000002859)
65560: accuracy:0.27 loss: 214.329 (lr:0.00010000000000002845)
65570: accuracy:0.3 loss: 213.71 (lr:0.0001000000000000283)
65580: accuracy:0.27 loss: 222.319 (lr:0.00010000000000002817)
65590: accuracy:0.32 loss: 229.36 (lr:0.00010000000000002803)
65600: accuracy:0.29 loss: 221.891 (lr:0.00010000000000002788)
65610: accuracy:0.21 loss: 244.375 (lr:0.00010000000000002775)
65620: accuracy:0.36 loss: 235.559 (lr:0.00010000000000002761)
65630: accuracy:0.21 loss: 232.268 (lr:0.00010000000000002748)
65640: accuracy:0.28 loss: 228.763 (lr:0.00010000000000002734)
65650: accuracy:0.23 loss: 239.587 (lr:0.0001000000000000272)
65660: accuracy:0.23 loss: 234.809 (lr:0.00010000000000002707)
65670: accuracy:0.3 loss: 222.347 (lr:0.00010000000000002693)
65680: accuracy:0.27 loss: 237.268 (lr:0.0001000000000000268)
65690: accuracy:0.31 loss: 215.479 (lr:0.00010000000000002666)
65700: accuracy:0.26 loss: 223.941 (lr:0.00010000000000002653)
65710: accuracy:0.28 loss: 232.295 (lr:0.00010000000000002639)
65720: accuracy:0.34 loss: 219.341 (lr:0.00010000000000002627)
65730: accuracy:0.3 loss: 240.056 (lr:0.00010000000000002613)
65740: accuracy:0.25 loss: 230.183 (lr:0.000100000000000026)
65750: accuracy:0.3 loss: 230.7 (lr:0.00010000000000002588)
65760: accuracy:0.37 loss: 228.99 (lr:0.00010000000000002574)
65770: accuracy:0.37 loss: 208.975 (lr:0.00010000000000002562)
65780: accuracy:0.33 loss: 235.955 (lr:0.00010000000000002548)
65790: accuracy:0.28 loss: 222.779 (lr:0.00010000000000002536)
65800: accuracy:0.35 loss: 212.363 (lr:0.00010000000000002524)
65810: accuracy:0.29 loss: 233.869 (lr:0.0001000000000000251)
65820: accuracy:0.32 loss: 218.051 (lr:0.00010000000000002498)
65830: accuracy:0.29 loss: 240.43 (lr:0.00010000000000002486)
65840: accuracy:0.26 loss: 239.193 (lr:0.00010000000000002474)
65850: accuracy:0.3 loss: 236.42 (lr:0.00010000000000002462)
65860: accuracy:0.26 loss: 232.249 (lr:0.0001000000000000245)
65870: accuracy:0.35 loss: 211.203 (lr:0.00010000000000002437)
65880: accuracy:0.29 loss: 221.055 (lr:0.00010000000000002425)
65890: accuracy:0.23 loss: 239.379 (lr:0.00010000000000002413)
65900: accuracy:0.29 loss: 221.535 (lr:0.000100000000000024)
65910: accuracy:0.2 loss: 233.989 (lr:0.00010000000000002388)
65920: accuracy:0.29 loss: 230.443 (lr:0.00010000000000002376)
65930: accuracy:0.36 loss: 220.653 (lr:0.00010000000000002364)
65940: accuracy:0.34 loss: 229.374 (lr:0.00010000000000002353)
65950: accuracy:0.27 loss: 237.108 (lr:0.00010000000000002341)
65960: accuracy:0.23 loss: 239.938 (lr:0.00010000000000002329)
65970: accuracy:0.28 loss: 240.815 (lr:0.00010000000000002318)
65980: accuracy:0.31 loss: 226.263 (lr:0.00010000000000002306)
65990: accuracy:0.27 loss: 234.491 (lr:0.00010000000000002295)
66000: accuracy:0.28 loss: 230.885 (lr:0.00010000000000002283)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
66000: ********* epoch 7 ********* test accuracy for all:0.237257 test loss: 258.384
66000: ********* epoch 7 ********* test accuracy for mode 0:0.0045 test loss: 429.426
66000: ********* epoch 7 ********* test accuracy for mode 1:0.057 test loss: 406.727
66000: ********* epoch 7 ********* test accuracy for mode 2:0.0445 test loss: 275.055
66000: ********* epoch 7 ********* test accuracy for mode 24:0.193 test loss: 274.84
66000: ********* epoch 7 ********* test accuracy for mode 25:0.296 test loss: 247.39
66000: ********* epoch 7 ********* test accuracy for mode 26:0.3815 test loss: 173.52
66000: ********* epoch 7 ********* test accuracy for mode 27:0.186 test loss: 278.356
66000: ********* epoch 7 ********* test accuracy for mode 28:0.2965 test loss: 255.979
66000: ********* epoch 7 ********* test accuracy for mode 29:0.2825 test loss: 258.7
66000: ********* epoch 7 ********* test accuracy for mode 30:0.2375 test loss: 253.453
66000: ********* epoch 7 ********* test accuracy for mode 31:0.2325 test loss: 253.4
66000: ********* epoch 7 ********* test accuracy for mode 32:0.228 test loss: 244.718
66000: ********* epoch 7 ********* test accuracy for mode 33:0.2045 test loss: 256.175
66000: ********* epoch 7 ********* test accuracy for mode 34:0.06 test loss: 259.196
66000: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 409.378
66000: ********* epoch 7 ********* test accuracy for mode 36:0.0535 test loss: 427.337
66010: accuracy:0.38 loss: 202.053 (lr:0.00010000000000002272)
66020: accuracy:0.19 loss: 267.23 (lr:0.00010000000000002261)
66030: accuracy:0.29 loss: 230.216 (lr:0.00010000000000002249)
66040: accuracy:0.38 loss: 209.273 (lr:0.00010000000000002238)
66050: accuracy:0.3 loss: 225.729 (lr:0.00010000000000002227)
66060: accuracy:0.24 loss: 242.531 (lr:0.00010000000000002216)
66070: accuracy:0.18 loss: 249.954 (lr:0.00010000000000002205)
66080: accuracy:0.33 loss: 217.57 (lr:0.00010000000000002193)
66090: accuracy:0.32 loss: 227.201 (lr:0.00010000000000002182)
66100: accuracy:0.32 loss: 224.33 (lr:0.00010000000000002172)
66110: accuracy:0.28 loss: 207.972 (lr:0.00010000000000002161)
66120: accuracy:0.39 loss: 209.881 (lr:0.0001000000000000215)
66130: accuracy:0.27 loss: 226.473 (lr:0.00010000000000002139)
66140: accuracy:0.3 loss: 237.399 (lr:0.0001000000000000213)
66150: accuracy:0.3 loss: 212.678 (lr:0.00010000000000002119)
66160: accuracy:0.29 loss: 229.795 (lr:0.00010000000000002108)
66170: accuracy:0.3 loss: 233.601 (lr:0.00010000000000002097)
66180: accuracy:0.3 loss: 223.818 (lr:0.00010000000000002086)
66190: accuracy:0.29 loss: 237.727 (lr:0.00010000000000002077)
66200: accuracy:0.35 loss: 220.065 (lr:0.00010000000000002066)
66210: accuracy:0.33 loss: 221.879 (lr:0.00010000000000002056)
66220: accuracy:0.23 loss: 250.334 (lr:0.00010000000000002046)
66230: accuracy:0.35 loss: 211.506 (lr:0.00010000000000002035)
66240: accuracy:0.32 loss: 220.9 (lr:0.00010000000000002025)
66250: accuracy:0.24 loss: 232.027 (lr:0.00010000000000002016)
66260: accuracy:0.27 loss: 238.704 (lr:0.00010000000000002005)
66270: accuracy:0.21 loss: 250.995 (lr:0.00010000000000001995)
66280: accuracy:0.34 loss: 227.505 (lr:0.00010000000000001985)
66290: accuracy:0.28 loss: 238.824 (lr:0.00010000000000001975)
66300: accuracy:0.27 loss: 224.528 (lr:0.00010000000000001966)
66310: accuracy:0.32 loss: 214.885 (lr:0.00010000000000001956)
66320: accuracy:0.33 loss: 236.386 (lr:0.00010000000000001945)
66330: accuracy:0.28 loss: 216.063 (lr:0.00010000000000001936)
66340: accuracy:0.35 loss: 224.032 (lr:0.00010000000000001926)
66350: accuracy:0.23 loss: 228.111 (lr:0.00010000000000001917)
66360: accuracy:0.26 loss: 243.589 (lr:0.00010000000000001907)
66370: accuracy:0.33 loss: 209.109 (lr:0.00010000000000001898)
66380: accuracy:0.3 loss: 232.095 (lr:0.00010000000000001888)
66390: accuracy:0.25 loss: 224.993 (lr:0.00010000000000001879)
66400: accuracy:0.33 loss: 213.207 (lr:0.0001000000000000187)
66410: accuracy:0.34 loss: 223.513 (lr:0.0001000000000000186)
66420: accuracy:0.26 loss: 230.976 (lr:0.0001000000000000185)
66430: accuracy:0.23 loss: 230.303 (lr:0.00010000000000001842)
66440: accuracy:0.25 loss: 225.913 (lr:0.00010000000000001833)
66450: accuracy:0.31 loss: 231.274 (lr:0.00010000000000001823)
66460: accuracy:0.3 loss: 215.799 (lr:0.00010000000000001814)
66470: accuracy:0.24 loss: 226.283 (lr:0.00010000000000001806)
66480: accuracy:0.26 loss: 237.569 (lr:0.00010000000000001796)
66490: accuracy:0.35 loss: 215.576 (lr:0.00010000000000001787)
66500: accuracy:0.21 loss: 230.835 (lr:0.00010000000000001779)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
66500: ********* epoch 7 ********* test accuracy for all:0.236351 test loss: 258.446
66500: ********* epoch 7 ********* test accuracy for mode 0:0.0005 test loss: 429.352
66500: ********* epoch 7 ********* test accuracy for mode 1:0.0545 test loss: 403.072
66500: ********* epoch 7 ********* test accuracy for mode 2:0.031 test loss: 278.115
66500: ********* epoch 7 ********* test accuracy for mode 24:0.2305 test loss: 259.185
66500: ********* epoch 7 ********* test accuracy for mode 25:0.3035 test loss: 237.491
66500: ********* epoch 7 ********* test accuracy for mode 26:0.3535 test loss: 178.015
66500: ********* epoch 7 ********* test accuracy for mode 27:0.219 test loss: 268.669
66500: ********* epoch 7 ********* test accuracy for mode 28:0.276 test loss: 260.26
66500: ********* epoch 7 ********* test accuracy for mode 29:0.2745 test loss: 261.584
66500: ********* epoch 7 ********* test accuracy for mode 30:0.225 test loss: 258.954
66500: ********* epoch 7 ********* test accuracy for mode 31:0.2435 test loss: 256.862
66500: ********* epoch 7 ********* test accuracy for mode 32:0.1395 test loss: 255.439
66500: ********* epoch 7 ********* test accuracy for mode 33:0.2235 test loss: 257.656
66500: ********* epoch 7 ********* test accuracy for mode 34:0.152 test loss: 254.378
66500: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 407.806
66500: ********* epoch 7 ********* test accuracy for mode 36:0.0975 test loss: 418.19
66510: accuracy:0.35 loss: 221.302 (lr:0.00010000000000001769)
66520: accuracy:0.34 loss: 214.103 (lr:0.00010000000000001761)
66530: accuracy:0.26 loss: 236.736 (lr:0.00010000000000001751)
66540: accuracy:0.3 loss: 237.607 (lr:0.00010000000000001743)
66550: accuracy:0.29 loss: 232.88 (lr:0.00010000000000001734)
66560: accuracy:0.29 loss: 229.677 (lr:0.00010000000000001726)
66570: accuracy:0.3 loss: 234.915 (lr:0.00010000000000001718)
66580: accuracy:0.29 loss: 221.913 (lr:0.00010000000000001708)
66590: accuracy:0.32 loss: 216.335 (lr:0.000100000000000017)
66600: accuracy:0.27 loss: 243.861 (lr:0.00010000000000001692)
66610: accuracy:0.18 loss: 247.515 (lr:0.00010000000000001684)
66620: accuracy:0.33 loss: 221.316 (lr:0.00010000000000001674)
66630: accuracy:0.24 loss: 234.272 (lr:0.00010000000000001666)
66640: accuracy:0.26 loss: 229.664 (lr:0.00010000000000001658)
66650: accuracy:0.26 loss: 235.487 (lr:0.0001000000000000165)
66660: accuracy:0.26 loss: 242.358 (lr:0.00010000000000001642)
66670: accuracy:0.43 loss: 228.201 (lr:0.00010000000000001634)
66680: accuracy:0.32 loss: 231.379 (lr:0.00010000000000001625)
66690: accuracy:0.27 loss: 236.909 (lr:0.00010000000000001617)
66700: accuracy:0.38 loss: 207.822 (lr:0.00010000000000001609)
66710: accuracy:0.24 loss: 236.883 (lr:0.00010000000000001601)
66720: accuracy:0.3 loss: 231.01 (lr:0.00010000000000001593)
66730: accuracy:0.32 loss: 212.84 (lr:0.00010000000000001585)
66740: accuracy:0.37 loss: 211.086 (lr:0.00010000000000001578)
66750: accuracy:0.27 loss: 241.341 (lr:0.0001000000000000157)
66760: accuracy:0.29 loss: 228.969 (lr:0.00010000000000001562)
66770: accuracy:0.33 loss: 204.785 (lr:0.00010000000000001554)
66780: accuracy:0.27 loss: 236.109 (lr:0.00010000000000001545)
66790: accuracy:0.31 loss: 227.235 (lr:0.00010000000000001539)
66800: accuracy:0.27 loss: 245.993 (lr:0.0001000000000000153)
66810: accuracy:0.28 loss: 233.489 (lr:0.00010000000000001522)
66820: accuracy:0.23 loss: 233.934 (lr:0.00010000000000001516)
66830: accuracy:0.26 loss: 239.635 (lr:0.00010000000000001508)
66840: accuracy:0.29 loss: 206.714 (lr:0.00010000000000001501)
66850: accuracy:0.31 loss: 210.708 (lr:0.00010000000000001493)
66860: accuracy:0.29 loss: 237.314 (lr:0.00010000000000001486)
66870: accuracy:0.31 loss: 233.257 (lr:0.00010000000000001478)
66880: accuracy:0.3 loss: 219.353 (lr:0.00010000000000001471)
66890: accuracy:0.35 loss: 219.058 (lr:0.00010000000000001463)
66900: accuracy:0.19 loss: 251.824 (lr:0.00010000000000001456)
66910: accuracy:0.26 loss: 215.058 (lr:0.00010000000000001449)
66920: accuracy:0.31 loss: 231.369 (lr:0.00010000000000001441)
66930: accuracy:0.27 loss: 245.109 (lr:0.00010000000000001434)
66940: accuracy:0.28 loss: 229.482 (lr:0.00010000000000001428)
66950: accuracy:0.23 loss: 224.872 (lr:0.00010000000000001421)
66960: accuracy:0.32 loss: 202.646 (lr:0.00010000000000001413)
66970: accuracy:0.31 loss: 214.009 (lr:0.00010000000000001406)
66980: accuracy:0.29 loss: 229.149 (lr:0.00010000000000001399)
66990: accuracy:0.27 loss: 229.029 (lr:0.00010000000000001392)
67000: accuracy:0.27 loss: 227.946 (lr:0.00010000000000001386)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
67000: ********* epoch 7 ********* test accuracy for all:0.238946 test loss: 258.53
67000: ********* epoch 7 ********* test accuracy for mode 0:0.0015 test loss: 433.373
67000: ********* epoch 7 ********* test accuracy for mode 1:0.057 test loss: 406.901
67000: ********* epoch 7 ********* test accuracy for mode 2:0.048 test loss: 276.043
67000: ********* epoch 7 ********* test accuracy for mode 24:0.2335 test loss: 265.838
67000: ********* epoch 7 ********* test accuracy for mode 25:0.28 test loss: 243.482
67000: ********* epoch 7 ********* test accuracy for mode 26:0.389 test loss: 175.039
67000: ********* epoch 7 ********* test accuracy for mode 27:0.2645 test loss: 259.963
67000: ********* epoch 7 ********* test accuracy for mode 28:0.3115 test loss: 248.621
67000: ********* epoch 7 ********* test accuracy for mode 29:0.3015 test loss: 253.075
67000: ********* epoch 7 ********* test accuracy for mode 30:0.225 test loss: 254.21
67000: ********* epoch 7 ********* test accuracy for mode 31:0.236 test loss: 254.966
67000: ********* epoch 7 ********* test accuracy for mode 32:0.163 test loss: 251.54
67000: ********* epoch 7 ********* test accuracy for mode 33:0.2625 test loss: 255.69
67000: ********* epoch 7 ********* test accuracy for mode 34:0.106 test loss: 257.429
67000: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 419.103
67000: ********* epoch 7 ********* test accuracy for mode 36:0.033 test loss: 455.726
67010: accuracy:0.29 loss: 222.97 (lr:0.00010000000000001379)
67020: accuracy:0.29 loss: 218.158 (lr:0.00010000000000001372)
67030: accuracy:0.23 loss: 243.931 (lr:0.00010000000000001364)
67040: accuracy:0.37 loss: 207.663 (lr:0.00010000000000001357)
67050: accuracy:0.29 loss: 238.312 (lr:0.0001000000000000135)
67060: accuracy:0.27 loss: 218.972 (lr:0.00010000000000001344)
67070: accuracy:0.26 loss: 243.334 (lr:0.00010000000000001338)
67080: accuracy:0.3 loss: 221.767 (lr:0.00010000000000001331)
67090: accuracy:0.25 loss: 228.858 (lr:0.00010000000000001325)
67100: accuracy:0.32 loss: 221.969 (lr:0.00010000000000001318)
67110: accuracy:0.25 loss: 228.565 (lr:0.00010000000000001311)
67120: accuracy:0.32 loss: 230.672 (lr:0.00010000000000001304)
67130: accuracy:0.35 loss: 213.128 (lr:0.00010000000000001297)
67140: accuracy:0.34 loss: 199.915 (lr:0.00010000000000001292)
67150: accuracy:0.31 loss: 218.784 (lr:0.00010000000000001285)
67160: accuracy:0.35 loss: 203.714 (lr:0.00010000000000001278)
67170: accuracy:0.3 loss: 214.276 (lr:0.00010000000000001272)
67180: accuracy:0.3 loss: 249.083 (lr:0.00010000000000001266)
67190: accuracy:0.29 loss: 235.666 (lr:0.0001000000000000126)
67200: accuracy:0.3 loss: 220.42 (lr:0.00010000000000001253)
67210: accuracy:0.28 loss: 233.112 (lr:0.00010000000000001247)
67220: accuracy:0.35 loss: 208.405 (lr:0.0001000000000000124)
67230: accuracy:0.33 loss: 212.741 (lr:0.00010000000000001235)
67240: accuracy:0.21 loss: 237.933 (lr:0.00010000000000001228)
67250: accuracy:0.34 loss: 202.676 (lr:0.00010000000000001223)
67260: accuracy:0.34 loss: 222.471 (lr:0.00010000000000001216)
67270: accuracy:0.27 loss: 232.708 (lr:0.00010000000000001211)
67280: accuracy:0.28 loss: 228.956 (lr:0.00010000000000001204)
67290: accuracy:0.3 loss: 229.667 (lr:0.00010000000000001199)
67300: accuracy:0.37 loss: 215.362 (lr:0.00010000000000001192)
67310: accuracy:0.39 loss: 222.498 (lr:0.00010000000000001186)
67320: accuracy:0.36 loss: 219.018 (lr:0.00010000000000001181)
67330: accuracy:0.35 loss: 226.467 (lr:0.00010000000000001174)
67340: accuracy:0.34 loss: 210.366 (lr:0.00010000000000001169)
67350: accuracy:0.31 loss: 216.357 (lr:0.00010000000000001163)
67360: accuracy:0.37 loss: 209.467 (lr:0.00010000000000001157)
67370: accuracy:0.3 loss: 232.124 (lr:0.00010000000000001151)
67380: accuracy:0.33 loss: 226.79 (lr:0.00010000000000001146)
67390: accuracy:0.28 loss: 247.795 (lr:0.0001000000000000114)
67400: accuracy:0.31 loss: 240.533 (lr:0.00010000000000001133)
67410: accuracy:0.31 loss: 226.125 (lr:0.00010000000000001128)
67420: accuracy:0.26 loss: 246.642 (lr:0.00010000000000001123)
67430: accuracy:0.4 loss: 195.305 (lr:0.00010000000000001117)
67440: accuracy:0.3 loss: 237.379 (lr:0.00010000000000001112)
67450: accuracy:0.22 loss: 232.363 (lr:0.00010000000000001106)
67460: accuracy:0.27 loss: 233.685 (lr:0.00010000000000001101)
67470: accuracy:0.28 loss: 239.499 (lr:0.00010000000000001096)
67480: accuracy:0.33 loss: 214.637 (lr:0.0001000000000000109)
67490: accuracy:0.28 loss: 226.759 (lr:0.00010000000000001085)
67500: accuracy:0.27 loss: 215.051 (lr:0.00010000000000001079)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
67500: ********* epoch 7 ********* test accuracy for all:0.242284 test loss: 257.257
67500: ********* epoch 7 ********* test accuracy for mode 0:0.004 test loss: 415.089
67500: ********* epoch 7 ********* test accuracy for mode 1:0.072 test loss: 388.186
67500: ********* epoch 7 ********* test accuracy for mode 2:0.058 test loss: 272.09
67500: ********* epoch 7 ********* test accuracy for mode 24:0.2235 test loss: 269.722
67500: ********* epoch 7 ********* test accuracy for mode 25:0.25 test loss: 248.656
67500: ********* epoch 7 ********* test accuracy for mode 26:0.4725 test loss: 169.387
67500: ********* epoch 7 ********* test accuracy for mode 27:0.238 test loss: 266.162
67500: ********* epoch 7 ********* test accuracy for mode 28:0.284 test loss: 254.176
67500: ********* epoch 7 ********* test accuracy for mode 29:0.291 test loss: 258.33
67500: ********* epoch 7 ********* test accuracy for mode 30:0.242 test loss: 258.799
67500: ********* epoch 7 ********* test accuracy for mode 31:0.1745 test loss: 266.158
67500: ********* epoch 7 ********* test accuracy for mode 32:0.1895 test loss: 258.66
67500: ********* epoch 7 ********* test accuracy for mode 33:0.1965 test loss: 263.57
67500: ********* epoch 7 ********* test accuracy for mode 34:0.1965 test loss: 254.89
67500: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 405.747
67500: ********* epoch 7 ********* test accuracy for mode 36:0.0535 test loss: 424.407
67510: accuracy:0.29 loss: 220.822 (lr:0.00010000000000001074)
67520: accuracy:0.34 loss: 207.963 (lr:0.00010000000000001068)
67530: accuracy:0.37 loss: 217.398 (lr:0.00010000000000001063)
67540: accuracy:0.31 loss: 217.033 (lr:0.00010000000000001058)
67550: accuracy:0.3 loss: 225.397 (lr:0.00010000000000001052)
67560: accuracy:0.2 loss: 230.611 (lr:0.00010000000000001047)
67570: accuracy:0.32 loss: 231.098 (lr:0.00010000000000001041)
67580: accuracy:0.29 loss: 240.147 (lr:0.00010000000000001036)
67590: accuracy:0.35 loss: 204.569 (lr:0.00010000000000001032)
67600: accuracy:0.25 loss: 231.751 (lr:0.00010000000000001026)
67610: accuracy:0.35 loss: 227.156 (lr:0.00010000000000001021)
67620: accuracy:0.31 loss: 208.478 (lr:0.00010000000000001016)
67630: accuracy:0.21 loss: 261.678 (lr:0.00010000000000001011)
67640: accuracy:0.34 loss: 205.346 (lr:0.00010000000000001006)
67650: accuracy:0.35 loss: 225.064 (lr:0.00010000000000001)
67660: accuracy:0.33 loss: 216.131 (lr:0.00010000000000000997)
67670: accuracy:0.32 loss: 217.762 (lr:0.00010000000000000991)
67680: accuracy:0.24 loss: 231.964 (lr:0.00010000000000000986)
67690: accuracy:0.31 loss: 231.847 (lr:0.00010000000000000982)
67700: accuracy:0.26 loss: 243.043 (lr:0.00010000000000000976)
67710: accuracy:0.26 loss: 232.871 (lr:0.00010000000000000971)
67720: accuracy:0.26 loss: 236.842 (lr:0.00010000000000000967)
67730: accuracy:0.34 loss: 223.263 (lr:0.00010000000000000961)
67740: accuracy:0.4 loss: 213.399 (lr:0.00010000000000000957)
67750: accuracy:0.32 loss: 213.462 (lr:0.00010000000000000952)
67760: accuracy:0.27 loss: 241.728 (lr:0.00010000000000000948)
67770: accuracy:0.26 loss: 234.37 (lr:0.00010000000000000942)
67780: accuracy:0.33 loss: 239.737 (lr:0.00010000000000000938)
67790: accuracy:0.24 loss: 232.053 (lr:0.00010000000000000933)
67800: accuracy:0.34 loss: 225.659 (lr:0.00010000000000000929)
67810: accuracy:0.33 loss: 220.048 (lr:0.00010000000000000923)
67820: accuracy:0.4 loss: 196.742 (lr:0.0001000000000000092)
67830: accuracy:0.28 loss: 232.839 (lr:0.00010000000000000915)
67840: accuracy:0.37 loss: 207.727 (lr:0.0001000000000000091)
67850: accuracy:0.32 loss: 229.429 (lr:0.00010000000000000906)
67860: accuracy:0.27 loss: 230.637 (lr:0.00010000000000000902)
67870: accuracy:0.24 loss: 229.813 (lr:0.00010000000000000896)
67880: accuracy:0.36 loss: 214.05 (lr:0.00010000000000000892)
67890: accuracy:0.34 loss: 220.916 (lr:0.00010000000000000888)
67900: accuracy:0.23 loss: 237.066 (lr:0.00010000000000000883)
67910: accuracy:0.32 loss: 211.591 (lr:0.00010000000000000879)
67920: accuracy:0.34 loss: 217.28 (lr:0.00010000000000000875)
67930: accuracy:0.29 loss: 222.321 (lr:0.0001000000000000087)
67940: accuracy:0.27 loss: 245.512 (lr:0.00010000000000000866)
67950: accuracy:0.3 loss: 230.264 (lr:0.00010000000000000861)
67960: accuracy:0.31 loss: 241.089 (lr:0.00010000000000000857)
67970: accuracy:0.26 loss: 244.123 (lr:0.00010000000000000853)
67980: accuracy:0.31 loss: 244.131 (lr:0.00010000000000000849)
67990: accuracy:0.38 loss: 221.312 (lr:0.00010000000000000845)
68000: accuracy:0.29 loss: 206.842 (lr:0.00010000000000000841)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
68000: ********* epoch 7 ********* test accuracy for all:0.239432 test loss: 257.364
68000: ********* epoch 7 ********* test accuracy for mode 0:0.0035 test loss: 428.712
68000: ********* epoch 7 ********* test accuracy for mode 1:0.059 test loss: 398.246
68000: ********* epoch 7 ********* test accuracy for mode 2:0.0595 test loss: 269.997
68000: ********* epoch 7 ********* test accuracy for mode 24:0.194 test loss: 270.635
68000: ********* epoch 7 ********* test accuracy for mode 25:0.328 test loss: 240.386
68000: ********* epoch 7 ********* test accuracy for mode 26:0.338 test loss: 174.881
68000: ********* epoch 7 ********* test accuracy for mode 27:0.2425 test loss: 258.489
68000: ********* epoch 7 ********* test accuracy for mode 28:0.29 test loss: 245.058
68000: ********* epoch 7 ********* test accuracy for mode 29:0.2855 test loss: 248.25
68000: ********* epoch 7 ********* test accuracy for mode 30:0.284 test loss: 243.828
68000: ********* epoch 7 ********* test accuracy for mode 31:0.181 test loss: 251.541
68000: ********* epoch 7 ********* test accuracy for mode 32:0.2355 test loss: 244.325
68000: ********* epoch 7 ********* test accuracy for mode 33:0.217 test loss: 252.685
68000: ********* epoch 7 ********* test accuracy for mode 34:0.1465 test loss: 252.89
68000: ********* epoch 7 ********* test accuracy for mode 35:0.0 test loss: 421.321
68000: ********* epoch 7 ********* test accuracy for mode 36:0.0555 test loss: 438.011
68010: accuracy:0.28 loss: 248.695 (lr:0.00010000000000000837)
68020: accuracy:0.27 loss: 215.174 (lr:0.00010000000000000833)
68030: accuracy:0.23 loss: 242.398 (lr:0.00010000000000000827)
68040: accuracy:0.28 loss: 235.692 (lr:0.00010000000000000823)
68050: accuracy:0.25 loss: 235.398 (lr:0.00010000000000000819)
68060: accuracy:0.36 loss: 210.583 (lr:0.00010000000000000815)
68070: accuracy:0.29 loss: 234.729 (lr:0.00010000000000000811)
68080: accuracy:0.28 loss: 245.888 (lr:0.00010000000000000807)
68090: accuracy:0.27 loss: 226.893 (lr:0.00010000000000000803)
68100: accuracy:0.31 loss: 217.187 (lr:0.00010000000000000799)
68110: accuracy:0.27 loss: 217.865 (lr:0.00010000000000000796)
68120: accuracy:0.38 loss: 206.565 (lr:0.00010000000000000792)
68130: accuracy:0.3 loss: 236.247 (lr:0.00010000000000000788)
68140: accuracy:0.34 loss: 230.898 (lr:0.00010000000000000784)
68150: accuracy:0.29 loss: 223.787 (lr:0.0001000000000000078)
68160: accuracy:0.31 loss: 216.466 (lr:0.00010000000000000776)
68170: accuracy:0.29 loss: 204.704 (lr:0.00010000000000000772)
68180: accuracy:0.28 loss: 220.502 (lr:0.00010000000000000768)
68190: accuracy:0.34 loss: 213.629 (lr:0.00010000000000000765)
68200: accuracy:0.19 loss: 252.807 (lr:0.00010000000000000761)
68210: accuracy:0.24 loss: 242.201 (lr:0.00010000000000000757)
68220: accuracy:0.28 loss: 240.296 (lr:0.00010000000000000753)
68230: accuracy:0.33 loss: 231.478 (lr:0.00010000000000000749)
68240: accuracy:0.26 loss: 232.116 (lr:0.00010000000000000746)
68250: accuracy:0.33 loss: 220.892 (lr:0.00010000000000000742)
68260: accuracy:0.31 loss: 215.029 (lr:0.00010000000000000738)
68270: accuracy:0.36 loss: 210.601 (lr:0.00010000000000000734)
68280: accuracy:0.27 loss: 221.368 (lr:0.00010000000000000731)
68290: accuracy:0.33 loss: 233.333 (lr:0.00010000000000000727)
68300: accuracy:0.22 loss: 239.575 (lr:0.00010000000000000723)
68310: accuracy:0.29 loss: 234.388 (lr:0.0001000000000000072)
68320: accuracy:0.28 loss: 233.721 (lr:0.00010000000000000716)
68330: accuracy:0.26 loss: 223.273 (lr:0.00010000000000000712)
68340: accuracy:0.19 loss: 253.012 (lr:0.00010000000000000709)
68350: accuracy:0.32 loss: 227.031 (lr:0.00010000000000000705)
68360: accuracy:0.26 loss: 224.316 (lr:0.00010000000000000703)
68370: accuracy:0.31 loss: 223.446 (lr:0.00010000000000000698)
68380: accuracy:0.3 loss: 221.993 (lr:0.00010000000000000694)
68390: accuracy:0.26 loss: 227.935 (lr:0.00010000000000000692)
68400: accuracy:0.31 loss: 216.819 (lr:0.00010000000000000688)
68410: accuracy:0.3 loss: 226.87 (lr:0.00010000000000000685)
68420: accuracy:0.32 loss: 208.355 (lr:0.00010000000000000681)
68430: accuracy:0.37 loss: 212.654 (lr:0.00010000000000000678)
68440: accuracy:0.23 loss: 233.465 (lr:0.00010000000000000674)
68450: accuracy:0.28 loss: 245.295 (lr:0.00010000000000000671)
68460: accuracy:0.25 loss: 224.036 (lr:0.00010000000000000667)
68470: accuracy:0.33 loss: 207.294 (lr:0.00010000000000000665)
68480: accuracy:0.31 loss: 238.786 (lr:0.0001000000000000066)
68490: accuracy:0.31 loss: 233.028 (lr:0.00010000000000000658)
68500: accuracy:0.31 loss: 227.023 (lr:0.00010000000000000655)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
68500: ********* epoch 8 ********* test accuracy for all:0.24227 test loss: 257.572
68500: ********* epoch 8 ********* test accuracy for mode 0:0.002 test loss: 425.803
68500: ********* epoch 8 ********* test accuracy for mode 1:0.0615 test loss: 396.895
68500: ********* epoch 8 ********* test accuracy for mode 2:0.1225 test loss: 269.702
68500: ********* epoch 8 ********* test accuracy for mode 24:0.2205 test loss: 265.128
68500: ********* epoch 8 ********* test accuracy for mode 25:0.27 test loss: 245.411
68500: ********* epoch 8 ********* test accuracy for mode 26:0.458 test loss: 166.858
68500: ********* epoch 8 ********* test accuracy for mode 27:0.2565 test loss: 260.441
68500: ********* epoch 8 ********* test accuracy for mode 28:0.2935 test loss: 250.531
68500: ********* epoch 8 ********* test accuracy for mode 29:0.2875 test loss: 256.427
68500: ********* epoch 8 ********* test accuracy for mode 30:0.25 test loss: 253.285
68500: ********* epoch 8 ********* test accuracy for mode 31:0.1745 test loss: 257.434
68500: ********* epoch 8 ********* test accuracy for mode 32:0.238 test loss: 248.046
68500: ********* epoch 8 ********* test accuracy for mode 33:0.2205 test loss: 259.637
68500: ********* epoch 8 ********* test accuracy for mode 34:0.0815 test loss: 261.253
68500: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 413.091
68500: ********* epoch 8 ********* test accuracy for mode 36:0.104 test loss: 425.679
68510: accuracy:0.33 loss: 212.753 (lr:0.00010000000000000651)
68520: accuracy:0.36 loss: 211.4 (lr:0.00010000000000000648)
68530: accuracy:0.35 loss: 216.424 (lr:0.00010000000000000644)
68540: accuracy:0.28 loss: 225.148 (lr:0.00010000000000000642)
68550: accuracy:0.29 loss: 236.136 (lr:0.00010000000000000639)
68560: accuracy:0.28 loss: 246.241 (lr:0.00010000000000000635)
68570: accuracy:0.26 loss: 227.71 (lr:0.00010000000000000632)
68580: accuracy:0.31 loss: 220.582 (lr:0.00010000000000000629)
68590: accuracy:0.26 loss: 231.951 (lr:0.00010000000000000625)
68600: accuracy:0.31 loss: 212.048 (lr:0.00010000000000000623)
68610: accuracy:0.28 loss: 223.618 (lr:0.0001000000000000062)
68620: accuracy:0.22 loss: 245.294 (lr:0.00010000000000000616)
68630: accuracy:0.22 loss: 219.548 (lr:0.00010000000000000613)
68640: accuracy:0.28 loss: 213.755 (lr:0.0001000000000000061)
68650: accuracy:0.33 loss: 218.279 (lr:0.00010000000000000608)
68660: accuracy:0.25 loss: 240.5 (lr:0.00010000000000000604)
68670: accuracy:0.24 loss: 234.61 (lr:0.00010000000000000601)
68680: accuracy:0.3 loss: 207.25 (lr:0.00010000000000000598)
68690: accuracy:0.33 loss: 227.228 (lr:0.00010000000000000595)
68700: accuracy:0.25 loss: 237.915 (lr:0.00010000000000000593)
68710: accuracy:0.34 loss: 227.699 (lr:0.00010000000000000589)
68720: accuracy:0.28 loss: 224.407 (lr:0.00010000000000000586)
68730: accuracy:0.38 loss: 221.669 (lr:0.00010000000000000583)
68740: accuracy:0.3 loss: 221.748 (lr:0.0001000000000000058)
68750: accuracy:0.34 loss: 213.216 (lr:0.00010000000000000578)
68760: accuracy:0.24 loss: 267.535 (lr:0.00010000000000000575)
68770: accuracy:0.28 loss: 231.554 (lr:0.00010000000000000572)
68780: accuracy:0.37 loss: 188.412 (lr:0.0001000000000000057)
68790: accuracy:0.28 loss: 216.534 (lr:0.00010000000000000566)
68800: accuracy:0.31 loss: 230.312 (lr:0.00010000000000000563)
68810: accuracy:0.29 loss: 236.435 (lr:0.0001000000000000056)
68820: accuracy:0.29 loss: 219.685 (lr:0.00010000000000000557)
68830: accuracy:0.33 loss: 229.031 (lr:0.00010000000000000555)
68840: accuracy:0.32 loss: 225.992 (lr:0.00010000000000000552)
68850: accuracy:0.29 loss: 224.88 (lr:0.0001000000000000055)
68860: accuracy:0.42 loss: 196.961 (lr:0.00010000000000000547)
68870: accuracy:0.26 loss: 232.477 (lr:0.00010000000000000544)
68880: accuracy:0.31 loss: 233.312 (lr:0.00010000000000000541)
68890: accuracy:0.37 loss: 218.949 (lr:0.00010000000000000539)
68900: accuracy:0.26 loss: 243.049 (lr:0.00010000000000000536)
68910: accuracy:0.26 loss: 254.954 (lr:0.00010000000000000533)
68920: accuracy:0.31 loss: 232.442 (lr:0.0001000000000000053)
68930: accuracy:0.32 loss: 229.062 (lr:0.00010000000000000528)
68940: accuracy:0.29 loss: 217.82 (lr:0.00010000000000000525)
68950: accuracy:0.3 loss: 229.699 (lr:0.00010000000000000522)
68960: accuracy:0.25 loss: 235.035 (lr:0.0001000000000000052)
68970: accuracy:0.34 loss: 215.72 (lr:0.00010000000000000518)
68980: accuracy:0.33 loss: 227.208 (lr:0.00010000000000000515)
68990: accuracy:0.29 loss: 230.384 (lr:0.00010000000000000513)
69000: accuracy:0.3 loss: 237.264 (lr:0.0001000000000000051)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
69000: ********* epoch 8 ********* test accuracy for all:0.242068 test loss: 258.798
69000: ********* epoch 8 ********* test accuracy for mode 0:0.0035 test loss: 425.185
69000: ********* epoch 8 ********* test accuracy for mode 1:0.0565 test loss: 401.469
69000: ********* epoch 8 ********* test accuracy for mode 2:0.0835 test loss: 267.641
69000: ********* epoch 8 ********* test accuracy for mode 24:0.207 test loss: 275.162
69000: ********* epoch 8 ********* test accuracy for mode 25:0.2835 test loss: 249.585
69000: ********* epoch 8 ********* test accuracy for mode 26:0.4255 test loss: 173.265
69000: ********* epoch 8 ********* test accuracy for mode 27:0.267 test loss: 264.21
69000: ********* epoch 8 ********* test accuracy for mode 28:0.254 test loss: 256.189
69000: ********* epoch 8 ********* test accuracy for mode 29:0.3015 test loss: 256.137
69000: ********* epoch 8 ********* test accuracy for mode 30:0.241 test loss: 252.614
69000: ********* epoch 8 ********* test accuracy for mode 31:0.1705 test loss: 254.96
69000: ********* epoch 8 ********* test accuracy for mode 32:0.276 test loss: 239.858
69000: ********* epoch 8 ********* test accuracy for mode 33:0.263 test loss: 248.21
69000: ********* epoch 8 ********* test accuracy for mode 34:0.131 test loss: 250.647
69000: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 411.574
69000: ********* epoch 8 ********* test accuracy for mode 36:0.0235 test loss: 473.79
69010: accuracy:0.24 loss: 219.113 (lr:0.00010000000000000507)
69020: accuracy:0.25 loss: 229.959 (lr:0.00010000000000000505)
69030: accuracy:0.31 loss: 215.623 (lr:0.00010000000000000502)
69040: accuracy:0.27 loss: 224.846 (lr:0.00010000000000000499)
69050: accuracy:0.29 loss: 209.192 (lr:0.00010000000000000498)
69060: accuracy:0.26 loss: 239.288 (lr:0.00010000000000000495)
69070: accuracy:0.38 loss: 222.27 (lr:0.00010000000000000492)
69080: accuracy:0.21 loss: 236.779 (lr:0.0001000000000000049)
69090: accuracy:0.34 loss: 230.235 (lr:0.00010000000000000487)
69100: accuracy:0.35 loss: 225.276 (lr:0.00010000000000000486)
69110: accuracy:0.32 loss: 233.793 (lr:0.00010000000000000483)
69120: accuracy:0.29 loss: 222.689 (lr:0.0001000000000000048)
69130: accuracy:0.3 loss: 234.784 (lr:0.00010000000000000478)
69140: accuracy:0.37 loss: 225.987 (lr:0.00010000000000000475)
69150: accuracy:0.34 loss: 221.002 (lr:0.00010000000000000473)
69160: accuracy:0.36 loss: 215.534 (lr:0.00010000000000000471)
69170: accuracy:0.23 loss: 233.255 (lr:0.00010000000000000468)
69180: accuracy:0.37 loss: 231.283 (lr:0.00010000000000000467)
69190: accuracy:0.32 loss: 242.466 (lr:0.00010000000000000464)
69200: accuracy:0.33 loss: 214.815 (lr:0.00010000000000000461)
69210: accuracy:0.33 loss: 221.292 (lr:0.00010000000000000459)
69220: accuracy:0.35 loss: 212.296 (lr:0.00010000000000000457)
69230: accuracy:0.25 loss: 242.584 (lr:0.00010000000000000454)
69240: accuracy:0.27 loss: 237.6 (lr:0.00010000000000000452)
69250: accuracy:0.25 loss: 232.242 (lr:0.0001000000000000045)
69260: accuracy:0.31 loss: 210.197 (lr:0.00010000000000000448)
69270: accuracy:0.31 loss: 210.892 (lr:0.00010000000000000445)
69280: accuracy:0.25 loss: 230.408 (lr:0.00010000000000000444)
69290: accuracy:0.35 loss: 216.547 (lr:0.00010000000000000441)
69300: accuracy:0.33 loss: 213.921 (lr:0.00010000000000000438)
69310: accuracy:0.28 loss: 213.794 (lr:0.00010000000000000437)
69320: accuracy:0.27 loss: 248.374 (lr:0.00010000000000000434)
69330: accuracy:0.2 loss: 254.26 (lr:0.00010000000000000433)
69340: accuracy:0.33 loss: 209.681 (lr:0.0001000000000000043)
69350: accuracy:0.38 loss: 217.159 (lr:0.00010000000000000429)
69360: accuracy:0.27 loss: 222.858 (lr:0.00010000000000000426)
69370: accuracy:0.28 loss: 212.442 (lr:0.00010000000000000423)
69380: accuracy:0.33 loss: 220.538 (lr:0.00010000000000000422)
69390: accuracy:0.35 loss: 211.882 (lr:0.00010000000000000419)
69400: accuracy:0.3 loss: 231.365 (lr:0.00010000000000000418)
69410: accuracy:0.41 loss: 232.663 (lr:0.00010000000000000415)
69420: accuracy:0.28 loss: 230.352 (lr:0.00010000000000000414)
69430: accuracy:0.28 loss: 211.344 (lr:0.00010000000000000411)
69440: accuracy:0.34 loss: 207.091 (lr:0.0001000000000000041)
69450: accuracy:0.39 loss: 200.789 (lr:0.00010000000000000407)
69460: accuracy:0.22 loss: 231.611 (lr:0.00010000000000000406)
69470: accuracy:0.31 loss: 203.334 (lr:0.00010000000000000403)
69480: accuracy:0.28 loss: 232.825 (lr:0.00010000000000000402)
69490: accuracy:0.25 loss: 235.377 (lr:0.00010000000000000399)
69500: accuracy:0.29 loss: 238.764 (lr:0.00010000000000000398)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
69500: ********* epoch 8 ********* test accuracy for all:0.244486 test loss: 256.704
69500: ********* epoch 8 ********* test accuracy for mode 0:0.0015 test loss: 420.653
69500: ********* epoch 8 ********* test accuracy for mode 1:0.072 test loss: 396.484
69500: ********* epoch 8 ********* test accuracy for mode 2:0.0355 test loss: 277.936
69500: ********* epoch 8 ********* test accuracy for mode 24:0.2505 test loss: 259.219
69500: ********* epoch 8 ********* test accuracy for mode 25:0.282 test loss: 240.682
69500: ********* epoch 8 ********* test accuracy for mode 26:0.43 test loss: 170.934
69500: ********* epoch 8 ********* test accuracy for mode 27:0.267 test loss: 263.561
69500: ********* epoch 8 ********* test accuracy for mode 28:0.2785 test loss: 254.655
69500: ********* epoch 8 ********* test accuracy for mode 29:0.2555 test loss: 263.623
69500: ********* epoch 8 ********* test accuracy for mode 30:0.268 test loss: 256.396
69500: ********* epoch 8 ********* test accuracy for mode 31:0.195 test loss: 260.434
69500: ********* epoch 8 ********* test accuracy for mode 32:0.2215 test loss: 252.626
69500: ********* epoch 8 ********* test accuracy for mode 33:0.227 test loss: 257.705
69500: ********* epoch 8 ********* test accuracy for mode 34:0.138 test loss: 255.954
69500: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 418.043
69500: ********* epoch 8 ********* test accuracy for mode 36:0.0485 test loss: 432.87
69510: accuracy:0.32 loss: 217.466 (lr:0.00010000000000000395)
69520: accuracy:0.32 loss: 224.328 (lr:0.00010000000000000394)
69530: accuracy:0.21 loss: 241.704 (lr:0.00010000000000000391)
69540: accuracy:0.33 loss: 227.223 (lr:0.0001000000000000039)
69550: accuracy:0.34 loss: 208.352 (lr:0.00010000000000000387)
69560: accuracy:0.28 loss: 242.445 (lr:0.00010000000000000385)
69570: accuracy:0.34 loss: 243.318 (lr:0.00010000000000000384)
69580: accuracy:0.21 loss: 237.121 (lr:0.00010000000000000381)
69590: accuracy:0.24 loss: 234.862 (lr:0.0001000000000000038)
69600: accuracy:0.33 loss: 207.924 (lr:0.00010000000000000377)
69610: accuracy:0.38 loss: 204.168 (lr:0.00010000000000000376)
69620: accuracy:0.3 loss: 231.768 (lr:0.00010000000000000375)
69630: accuracy:0.31 loss: 242.641 (lr:0.00010000000000000372)
69640: accuracy:0.26 loss: 229.133 (lr:0.0001000000000000037)
69650: accuracy:0.36 loss: 215.512 (lr:0.00010000000000000369)
69660: accuracy:0.22 loss: 242.643 (lr:0.00010000000000000366)
69670: accuracy:0.28 loss: 244.558 (lr:0.00010000000000000365)
69680: accuracy:0.25 loss: 232.19 (lr:0.00010000000000000364)
69690: accuracy:0.37 loss: 215.146 (lr:0.00010000000000000361)
69700: accuracy:0.29 loss: 241.69 (lr:0.0001000000000000036)
69710: accuracy:0.3 loss: 227.578 (lr:0.00010000000000000358)
69720: accuracy:0.22 loss: 230.164 (lr:0.00010000000000000356)
69730: accuracy:0.24 loss: 234.683 (lr:0.00010000000000000354)
69740: accuracy:0.24 loss: 235.439 (lr:0.00010000000000000353)
69750: accuracy:0.34 loss: 208.886 (lr:0.0001000000000000035)
69760: accuracy:0.33 loss: 237.457 (lr:0.00010000000000000349)
69770: accuracy:0.26 loss: 219.49 (lr:0.00010000000000000347)
69780: accuracy:0.2 loss: 237.063 (lr:0.00010000000000000345)
69790: accuracy:0.25 loss: 237.977 (lr:0.00010000000000000343)
69800: accuracy:0.27 loss: 243.795 (lr:0.00010000000000000342)
69810: accuracy:0.28 loss: 215.465 (lr:0.0001000000000000034)
69820: accuracy:0.3 loss: 221.036 (lr:0.00010000000000000338)
69830: accuracy:0.28 loss: 217.488 (lr:0.00010000000000000337)
69840: accuracy:0.25 loss: 240.288 (lr:0.00010000000000000335)
69850: accuracy:0.32 loss: 209.592 (lr:0.00010000000000000334)
69860: accuracy:0.24 loss: 243.499 (lr:0.00010000000000000331)
69870: accuracy:0.33 loss: 210.121 (lr:0.0001000000000000033)
69880: accuracy:0.28 loss: 224.977 (lr:0.00010000000000000328)
69890: accuracy:0.3 loss: 230.772 (lr:0.00010000000000000327)
69900: accuracy:0.29 loss: 218.209 (lr:0.00010000000000000326)
69910: accuracy:0.36 loss: 205.798 (lr:0.00010000000000000323)
69920: accuracy:0.32 loss: 218.737 (lr:0.00010000000000000322)
69930: accuracy:0.23 loss: 237.017 (lr:0.0001000000000000032)
69940: accuracy:0.23 loss: 250.241 (lr:0.00010000000000000319)
69950: accuracy:0.28 loss: 227.042 (lr:0.00010000000000000318)
69960: accuracy:0.3 loss: 243.851 (lr:0.00010000000000000316)
69970: accuracy:0.24 loss: 233.623 (lr:0.00010000000000000314)
69980: accuracy:0.3 loss: 218.953 (lr:0.00010000000000000312)
69990: accuracy:0.35 loss: 226.885 (lr:0.00010000000000000311)
70000: accuracy:0.26 loss: 236.776 (lr:0.0001000000000000031)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
70000: ********* epoch 8 ********* test accuracy for all:0.237095 test loss: 258.371
70000: ********* epoch 8 ********* test accuracy for mode 0:0.0045 test loss: 407.95
70000: ********* epoch 8 ********* test accuracy for mode 1:0.073 test loss: 388.202
70000: ********* epoch 8 ********* test accuracy for mode 2:0.042 test loss: 277.83
70000: ********* epoch 8 ********* test accuracy for mode 24:0.1825 test loss: 273.947
70000: ********* epoch 8 ********* test accuracy for mode 25:0.2675 test loss: 247.643
70000: ********* epoch 8 ********* test accuracy for mode 26:0.4195 test loss: 175.913
70000: ********* epoch 8 ********* test accuracy for mode 27:0.229 test loss: 274.701
70000: ********* epoch 8 ********* test accuracy for mode 28:0.24 test loss: 264.456
70000: ********* epoch 8 ********* test accuracy for mode 29:0.253 test loss: 266.175
70000: ********* epoch 8 ********* test accuracy for mode 30:0.2715 test loss: 253.158
70000: ********* epoch 8 ********* test accuracy for mode 31:0.2035 test loss: 258.758
70000: ********* epoch 8 ********* test accuracy for mode 32:0.215 test loss: 250.29
70000: ********* epoch 8 ********* test accuracy for mode 33:0.239 test loss: 254.552
70000: ********* epoch 8 ********* test accuracy for mode 34:0.145 test loss: 255.132
70000: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 400.384
70000: ********* epoch 8 ********* test accuracy for mode 36:0.034 test loss: 422.86
70010: accuracy:0.31 loss: 226.915 (lr:0.00010000000000000308)
70020: accuracy:0.45 loss: 191.85 (lr:0.00010000000000000307)
70030: accuracy:0.32 loss: 237.128 (lr:0.00010000000000000305)
70040: accuracy:0.36 loss: 226.067 (lr:0.00010000000000000303)
70050: accuracy:0.37 loss: 213.772 (lr:0.00010000000000000301)
70060: accuracy:0.34 loss: 227.413 (lr:0.000100000000000003)
70070: accuracy:0.38 loss: 217.756 (lr:0.00010000000000000299)
70080: accuracy:0.27 loss: 235.683 (lr:0.00010000000000000297)
70090: accuracy:0.32 loss: 246.79 (lr:0.00010000000000000296)
70100: accuracy:0.3 loss: 232.617 (lr:0.00010000000000000295)
70110: accuracy:0.3 loss: 221.127 (lr:0.00010000000000000293)
70120: accuracy:0.31 loss: 225.886 (lr:0.00010000000000000292)
70130: accuracy:0.26 loss: 208.054 (lr:0.0001000000000000029)
70140: accuracy:0.31 loss: 224.056 (lr:0.00010000000000000289)
70150: accuracy:0.29 loss: 223.355 (lr:0.00010000000000000286)
70160: accuracy:0.27 loss: 248.186 (lr:0.00010000000000000285)
70170: accuracy:0.23 loss: 248.611 (lr:0.00010000000000000284)
70180: accuracy:0.29 loss: 220.004 (lr:0.00010000000000000282)
70190: accuracy:0.24 loss: 228.85 (lr:0.00010000000000000281)
70200: accuracy:0.3 loss: 213.378 (lr:0.0001000000000000028)
70210: accuracy:0.37 loss: 202.484 (lr:0.00010000000000000278)
70220: accuracy:0.25 loss: 256.44 (lr:0.00010000000000000277)
70230: accuracy:0.26 loss: 238.183 (lr:0.00010000000000000276)
70240: accuracy:0.25 loss: 227.972 (lr:0.00010000000000000274)
70250: accuracy:0.28 loss: 222.016 (lr:0.00010000000000000273)
70260: accuracy:0.32 loss: 233.978 (lr:0.00010000000000000272)
70270: accuracy:0.3 loss: 206.867 (lr:0.0001000000000000027)
70280: accuracy:0.39 loss: 218.27 (lr:0.00010000000000000269)
70290: accuracy:0.26 loss: 219.053 (lr:0.00010000000000000267)
70300: accuracy:0.22 loss: 244.003 (lr:0.00010000000000000266)
70310: accuracy:0.23 loss: 221.1 (lr:0.00010000000000000265)
70320: accuracy:0.27 loss: 235.837 (lr:0.00010000000000000263)
70330: accuracy:0.28 loss: 231.8 (lr:0.00010000000000000262)
70340: accuracy:0.28 loss: 237.254 (lr:0.00010000000000000261)
70350: accuracy:0.28 loss: 234.005 (lr:0.0001000000000000026)
70360: accuracy:0.38 loss: 210.007 (lr:0.00010000000000000258)
70370: accuracy:0.39 loss: 215.404 (lr:0.00010000000000000257)
70380: accuracy:0.3 loss: 230.988 (lr:0.00010000000000000257)
70390: accuracy:0.42 loss: 204.853 (lr:0.00010000000000000255)
70400: accuracy:0.34 loss: 235.933 (lr:0.00010000000000000254)
70410: accuracy:0.31 loss: 220.768 (lr:0.00010000000000000253)
70420: accuracy:0.2 loss: 245.51 (lr:0.00010000000000000251)
70430: accuracy:0.27 loss: 233.483 (lr:0.0001000000000000025)
70440: accuracy:0.25 loss: 232.224 (lr:0.00010000000000000248)
70450: accuracy:0.34 loss: 241.329 (lr:0.00010000000000000247)
70460: accuracy:0.32 loss: 225.816 (lr:0.00010000000000000246)
70470: accuracy:0.39 loss: 224.198 (lr:0.00010000000000000244)
70480: accuracy:0.26 loss: 213.184 (lr:0.00010000000000000243)
70490: accuracy:0.28 loss: 234.001 (lr:0.00010000000000000242)
70500: accuracy:0.25 loss: 238.942 (lr:0.00010000000000000242)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
70500: ********* epoch 8 ********* test accuracy for all:0.242784 test loss: 256.393
70500: ********* epoch 8 ********* test accuracy for mode 0:0.0005 test loss: 413.164
70500: ********* epoch 8 ********* test accuracy for mode 1:0.0655 test loss: 394.465
70500: ********* epoch 8 ********* test accuracy for mode 2:0.0485 test loss: 276.21
70500: ********* epoch 8 ********* test accuracy for mode 24:0.1985 test loss: 271.084
70500: ********* epoch 8 ********* test accuracy for mode 25:0.3335 test loss: 238.531
70500: ********* epoch 8 ********* test accuracy for mode 26:0.389 test loss: 170.914
70500: ********* epoch 8 ********* test accuracy for mode 27:0.242 test loss: 263.856
70500: ********* epoch 8 ********* test accuracy for mode 28:0.249 test loss: 254.337
70500: ********* epoch 8 ********* test accuracy for mode 29:0.3075 test loss: 253.455
70500: ********* epoch 8 ********* test accuracy for mode 30:0.237 test loss: 248.805
70500: ********* epoch 8 ********* test accuracy for mode 31:0.2225 test loss: 252.021
70500: ********* epoch 8 ********* test accuracy for mode 32:0.254 test loss: 244.088
70500: ********* epoch 8 ********* test accuracy for mode 33:0.229 test loss: 255.389
70500: ********* epoch 8 ********* test accuracy for mode 34:0.089 test loss: 260.076
70500: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 405.123
70500: ********* epoch 8 ********* test accuracy for mode 36:0.0735 test loss: 412.271
70510: accuracy:0.34 loss: 213.734 (lr:0.0001000000000000024)
70520: accuracy:0.35 loss: 215.682 (lr:0.00010000000000000239)
70530: accuracy:0.27 loss: 237.218 (lr:0.00010000000000000238)
70540: accuracy:0.3 loss: 226.516 (lr:0.00010000000000000236)
70550: accuracy:0.32 loss: 213.45 (lr:0.00010000000000000235)
70560: accuracy:0.23 loss: 246.093 (lr:0.00010000000000000234)
70570: accuracy:0.25 loss: 234.287 (lr:0.00010000000000000232)
70580: accuracy:0.3 loss: 232.789 (lr:0.00010000000000000232)
70590: accuracy:0.29 loss: 228.919 (lr:0.00010000000000000231)
70600: accuracy:0.31 loss: 206.093 (lr:0.0001000000000000023)
70610: accuracy:0.27 loss: 235.691 (lr:0.00010000000000000228)
70620: accuracy:0.33 loss: 201.626 (lr:0.00010000000000000227)
70630: accuracy:0.27 loss: 236.582 (lr:0.00010000000000000225)
70640: accuracy:0.29 loss: 217.874 (lr:0.00010000000000000225)
70650: accuracy:0.3 loss: 234.051 (lr:0.00010000000000000224)
70660: accuracy:0.34 loss: 215.699 (lr:0.00010000000000000223)
70670: accuracy:0.3 loss: 222.027 (lr:0.00010000000000000221)
70680: accuracy:0.32 loss: 205.299 (lr:0.0001000000000000022)
70690: accuracy:0.32 loss: 215.988 (lr:0.00010000000000000219)
70700: accuracy:0.32 loss: 233.659 (lr:0.00010000000000000219)
70710: accuracy:0.3 loss: 233.327 (lr:0.00010000000000000217)
70720: accuracy:0.31 loss: 217.24 (lr:0.00010000000000000216)
70730: accuracy:0.27 loss: 234.734 (lr:0.00010000000000000215)
70740: accuracy:0.35 loss: 216.262 (lr:0.00010000000000000213)
70750: accuracy:0.28 loss: 222.788 (lr:0.00010000000000000213)
70760: accuracy:0.22 loss: 237.252 (lr:0.00010000000000000212)
70770: accuracy:0.27 loss: 222.658 (lr:0.0001000000000000021)
70780: accuracy:0.31 loss: 215.432 (lr:0.00010000000000000209)
70790: accuracy:0.31 loss: 228.908 (lr:0.00010000000000000209)
70800: accuracy:0.27 loss: 225.712 (lr:0.00010000000000000208)
70810: accuracy:0.24 loss: 221.681 (lr:0.00010000000000000206)
70820: accuracy:0.36 loss: 204.055 (lr:0.00010000000000000205)
70830: accuracy:0.35 loss: 209.034 (lr:0.00010000000000000205)
70840: accuracy:0.25 loss: 242.55 (lr:0.00010000000000000204)
70850: accuracy:0.31 loss: 218.77 (lr:0.00010000000000000202)
70860: accuracy:0.38 loss: 216.178 (lr:0.00010000000000000201)
70870: accuracy:0.35 loss: 215.143 (lr:0.00010000000000000201)
70880: accuracy:0.24 loss: 228.097 (lr:0.000100000000000002)
70890: accuracy:0.31 loss: 232.562 (lr:0.00010000000000000198)
70900: accuracy:0.29 loss: 240.804 (lr:0.00010000000000000197)
70910: accuracy:0.26 loss: 215.581 (lr:0.00010000000000000197)
70920: accuracy:0.35 loss: 217.969 (lr:0.00010000000000000196)
70930: accuracy:0.29 loss: 250.701 (lr:0.00010000000000000194)
70940: accuracy:0.27 loss: 235.65 (lr:0.00010000000000000193)
70950: accuracy:0.38 loss: 220.032 (lr:0.00010000000000000193)
70960: accuracy:0.34 loss: 229.12 (lr:0.00010000000000000192)
70970: accuracy:0.25 loss: 219.303 (lr:0.0001000000000000019)
70980: accuracy:0.3 loss: 215.237 (lr:0.0001000000000000019)
70990: accuracy:0.27 loss: 244.17 (lr:0.00010000000000000189)
71000: accuracy:0.32 loss: 233.267 (lr:0.00010000000000000188)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
71000: ********* epoch 8 ********* test accuracy for all:0.242014 test loss: 257.127
71000: ********* epoch 8 ********* test accuracy for mode 0:0.001 test loss: 426.397
71000: ********* epoch 8 ********* test accuracy for mode 1:0.0635 test loss: 400.39
71000: ********* epoch 8 ********* test accuracy for mode 2:0.0385 test loss: 278.656
71000: ********* epoch 8 ********* test accuracy for mode 24:0.214 test loss: 268.575
71000: ********* epoch 8 ********* test accuracy for mode 25:0.31 test loss: 238.84
71000: ********* epoch 8 ********* test accuracy for mode 26:0.44 test loss: 166.568
71000: ********* epoch 8 ********* test accuracy for mode 27:0.284 test loss: 253.549
71000: ********* epoch 8 ********* test accuracy for mode 28:0.2685 test loss: 250.033
71000: ********* epoch 8 ********* test accuracy for mode 29:0.2935 test loss: 254.166
71000: ********* epoch 8 ********* test accuracy for mode 30:0.2585 test loss: 249.321
71000: ********* epoch 8 ********* test accuracy for mode 31:0.2095 test loss: 253.387
71000: ********* epoch 8 ********* test accuracy for mode 32:0.225 test loss: 246.411
71000: ********* epoch 8 ********* test accuracy for mode 33:0.2155 test loss: 254.166
71000: ********* epoch 8 ********* test accuracy for mode 34:0.1595 test loss: 254.1
71000: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 416.814
71000: ********* epoch 8 ********* test accuracy for mode 36:0.0255 test loss: 459.531
71010: accuracy:0.29 loss: 214.337 (lr:0.00010000000000000188)
71020: accuracy:0.28 loss: 225.229 (lr:0.00010000000000000186)
71030: accuracy:0.28 loss: 214.58 (lr:0.00010000000000000185)
71040: accuracy:0.35 loss: 206.041 (lr:0.00010000000000000185)
71050: accuracy:0.23 loss: 238.164 (lr:0.00010000000000000183)
71060: accuracy:0.28 loss: 238.195 (lr:0.00010000000000000182)
71070: accuracy:0.36 loss: 236.178 (lr:0.00010000000000000182)
71080: accuracy:0.33 loss: 218.572 (lr:0.00010000000000000181)
71090: accuracy:0.39 loss: 207.366 (lr:0.0001000000000000018)
71100: accuracy:0.33 loss: 233.424 (lr:0.0001000000000000018)
71110: accuracy:0.28 loss: 229.371 (lr:0.00010000000000000178)
71120: accuracy:0.26 loss: 234.047 (lr:0.00010000000000000177)
71130: accuracy:0.29 loss: 208.729 (lr:0.00010000000000000177)
71140: accuracy:0.3 loss: 247.566 (lr:0.00010000000000000175)
71150: accuracy:0.3 loss: 210.852 (lr:0.00010000000000000174)
71160: accuracy:0.28 loss: 222.494 (lr:0.00010000000000000174)
71170: accuracy:0.27 loss: 225.517 (lr:0.00010000000000000173)
71180: accuracy:0.3 loss: 231.143 (lr:0.00010000000000000171)
71190: accuracy:0.34 loss: 210.258 (lr:0.00010000000000000171)
71200: accuracy:0.31 loss: 228.133 (lr:0.0001000000000000017)
71210: accuracy:0.35 loss: 236.377 (lr:0.00010000000000000169)
71220: accuracy:0.32 loss: 246.574 (lr:0.00010000000000000169)
71230: accuracy:0.29 loss: 230.111 (lr:0.00010000000000000167)
71240: accuracy:0.28 loss: 207.787 (lr:0.00010000000000000167)
71250: accuracy:0.33 loss: 225.393 (lr:0.00010000000000000166)
71260: accuracy:0.36 loss: 222.014 (lr:0.00010000000000000164)
71270: accuracy:0.3 loss: 230.753 (lr:0.00010000000000000164)
71280: accuracy:0.27 loss: 219.926 (lr:0.00010000000000000163)
71290: accuracy:0.27 loss: 223.67 (lr:0.00010000000000000163)
71300: accuracy:0.24 loss: 226.55 (lr:0.00010000000000000162)
71310: accuracy:0.32 loss: 207.246 (lr:0.0001000000000000016)
71320: accuracy:0.31 loss: 218.523 (lr:0.0001000000000000016)
71330: accuracy:0.35 loss: 217.838 (lr:0.00010000000000000159)
71340: accuracy:0.32 loss: 224.991 (lr:0.00010000000000000159)
71350: accuracy:0.32 loss: 222.325 (lr:0.00010000000000000158)
71360: accuracy:0.32 loss: 215.102 (lr:0.00010000000000000156)
71370: accuracy:0.35 loss: 234.329 (lr:0.00010000000000000156)
71380: accuracy:0.33 loss: 216.292 (lr:0.00010000000000000155)
71390: accuracy:0.31 loss: 226.042 (lr:0.00010000000000000155)
71400: accuracy:0.34 loss: 231.657 (lr:0.00010000000000000154)
71410: accuracy:0.32 loss: 221.958 (lr:0.00010000000000000154)
71420: accuracy:0.29 loss: 222.595 (lr:0.00010000000000000152)
71430: accuracy:0.31 loss: 229.15 (lr:0.00010000000000000152)
71440: accuracy:0.36 loss: 203.925 (lr:0.00010000000000000151)
71450: accuracy:0.26 loss: 220.747 (lr:0.0001000000000000015)
71460: accuracy:0.27 loss: 234.665 (lr:0.0001000000000000015)
71470: accuracy:0.35 loss: 231.26 (lr:0.00010000000000000148)
71480: accuracy:0.3 loss: 227.767 (lr:0.00010000000000000148)
71490: accuracy:0.34 loss: 222.881 (lr:0.00010000000000000147)
71500: accuracy:0.19 loss: 244.927 (lr:0.00010000000000000147)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
71500: ********* epoch 8 ********* test accuracy for all:0.240095 test loss: 258.594
71500: ********* epoch 8 ********* test accuracy for mode 0:0.003 test loss: 419.205
71500: ********* epoch 8 ********* test accuracy for mode 1:0.068 test loss: 397.29
71500: ********* epoch 8 ********* test accuracy for mode 2:0.0295 test loss: 283.977
71500: ********* epoch 8 ********* test accuracy for mode 24:0.217 test loss: 271.589
71500: ********* epoch 8 ********* test accuracy for mode 25:0.3105 test loss: 239.101
71500: ********* epoch 8 ********* test accuracy for mode 26:0.4715 test loss: 166.805
71500: ********* epoch 8 ********* test accuracy for mode 27:0.2025 test loss: 276.666
71500: ********* epoch 8 ********* test accuracy for mode 28:0.265 test loss: 261.737
71500: ********* epoch 8 ********* test accuracy for mode 29:0.2525 test loss: 266.231
71500: ********* epoch 8 ********* test accuracy for mode 30:0.2575 test loss: 256.782
71500: ********* epoch 8 ********* test accuracy for mode 31:0.205 test loss: 259.016
71500: ********* epoch 8 ********* test accuracy for mode 32:0.2555 test loss: 246.732
71500: ********* epoch 8 ********* test accuracy for mode 33:0.2345 test loss: 257.215
71500: ********* epoch 8 ********* test accuracy for mode 34:0.108 test loss: 262.343
71500: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 409.104
71500: ********* epoch 8 ********* test accuracy for mode 36:0.027 test loss: 453.806
71510: accuracy:0.27 loss: 227.65 (lr:0.00010000000000000145)
71520: accuracy:0.27 loss: 236.816 (lr:0.00010000000000000145)
71530: accuracy:0.35 loss: 215.383 (lr:0.00010000000000000144)
71540: accuracy:0.33 loss: 212.949 (lr:0.00010000000000000144)
71550: accuracy:0.23 loss: 224.19 (lr:0.00010000000000000143)
71560: accuracy:0.29 loss: 237.908 (lr:0.00010000000000000143)
71570: accuracy:0.25 loss: 236.663 (lr:0.00010000000000000141)
71580: accuracy:0.25 loss: 227.618 (lr:0.0001000000000000014)
71590: accuracy:0.35 loss: 212.224 (lr:0.0001000000000000014)
71600: accuracy:0.31 loss: 228.436 (lr:0.00010000000000000139)
71610: accuracy:0.39 loss: 208.314 (lr:0.00010000000000000139)
71620: accuracy:0.29 loss: 235.136 (lr:0.00010000000000000137)
71630: accuracy:0.32 loss: 218.219 (lr:0.00010000000000000137)
71640: accuracy:0.29 loss: 220.758 (lr:0.00010000000000000136)
71650: accuracy:0.36 loss: 235.916 (lr:0.00010000000000000136)
71660: accuracy:0.24 loss: 234.328 (lr:0.00010000000000000135)
71670: accuracy:0.35 loss: 215.546 (lr:0.00010000000000000135)
71680: accuracy:0.28 loss: 235.536 (lr:0.00010000000000000133)
71690: accuracy:0.32 loss: 207.351 (lr:0.00010000000000000133)
71700: accuracy:0.26 loss: 235.717 (lr:0.00010000000000000132)
71710: accuracy:0.24 loss: 219.243 (lr:0.00010000000000000132)
71720: accuracy:0.28 loss: 216.664 (lr:0.0001000000000000013)
71730: accuracy:0.3 loss: 210.443 (lr:0.0001000000000000013)
71740: accuracy:0.35 loss: 210.098 (lr:0.0001000000000000013)
71750: accuracy:0.22 loss: 230.049 (lr:0.00010000000000000129)
71760: accuracy:0.29 loss: 246.583 (lr:0.00010000000000000129)
71770: accuracy:0.33 loss: 216.219 (lr:0.00010000000000000128)
71780: accuracy:0.22 loss: 215.099 (lr:0.00010000000000000128)
71790: accuracy:0.27 loss: 220.251 (lr:0.00010000000000000127)
71800: accuracy:0.25 loss: 219.923 (lr:0.00010000000000000127)
71810: accuracy:0.27 loss: 230.757 (lr:0.00010000000000000125)
71820: accuracy:0.3 loss: 233.023 (lr:0.00010000000000000125)
71830: accuracy:0.26 loss: 259.628 (lr:0.00010000000000000124)
71840: accuracy:0.31 loss: 230.481 (lr:0.00010000000000000124)
71850: accuracy:0.31 loss: 228.744 (lr:0.00010000000000000122)
71860: accuracy:0.34 loss: 216.92 (lr:0.00010000000000000122)
71870: accuracy:0.32 loss: 210.099 (lr:0.00010000000000000121)
71880: accuracy:0.27 loss: 218.97 (lr:0.00010000000000000121)
71890: accuracy:0.3 loss: 223.144 (lr:0.00010000000000000121)
71900: accuracy:0.34 loss: 222.886 (lr:0.0001000000000000012)
71910: accuracy:0.31 loss: 225.268 (lr:0.0001000000000000012)
71920: accuracy:0.32 loss: 221.823 (lr:0.00010000000000000118)
71930: accuracy:0.34 loss: 204.223 (lr:0.00010000000000000118)
71940: accuracy:0.21 loss: 216.3 (lr:0.00010000000000000117)
71950: accuracy:0.23 loss: 225.898 (lr:0.00010000000000000117)
71960: accuracy:0.37 loss: 219.161 (lr:0.00010000000000000117)
71970: accuracy:0.37 loss: 234.803 (lr:0.00010000000000000116)
71980: accuracy:0.34 loss: 213.759 (lr:0.00010000000000000116)
71990: accuracy:0.28 loss: 229.587 (lr:0.00010000000000000114)
72000: accuracy:0.22 loss: 224.524 (lr:0.00010000000000000114)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
72000: ********* epoch 8 ********* test accuracy for all:0.241324 test loss: 257.062
72000: ********* epoch 8 ********* test accuracy for mode 0:0.0015 test loss: 421.986
72000: ********* epoch 8 ********* test accuracy for mode 1:0.065 test loss: 393.089
72000: ********* epoch 8 ********* test accuracy for mode 2:0.03 test loss: 278.095
72000: ********* epoch 8 ********* test accuracy for mode 24:0.2435 test loss: 265.418
72000: ********* epoch 8 ********* test accuracy for mode 25:0.289 test loss: 244.03
72000: ********* epoch 8 ********* test accuracy for mode 26:0.411 test loss: 169.667
72000: ********* epoch 8 ********* test accuracy for mode 27:0.246 test loss: 264.822
72000: ********* epoch 8 ********* test accuracy for mode 28:0.32 test loss: 251.488
72000: ********* epoch 8 ********* test accuracy for mode 29:0.2425 test loss: 264.801
72000: ********* epoch 8 ********* test accuracy for mode 30:0.265 test loss: 255.491
72000: ********* epoch 8 ********* test accuracy for mode 31:0.199 test loss: 258.986
72000: ********* epoch 8 ********* test accuracy for mode 32:0.223 test loss: 248.575
72000: ********* epoch 8 ********* test accuracy for mode 33:0.2425 test loss: 256.08
72000: ********* epoch 8 ********* test accuracy for mode 34:0.1415 test loss: 257.342
72000: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 410.276
72000: ********* epoch 8 ********* test accuracy for mode 36:0.0455 test loss: 428.765
72010: accuracy:0.28 loss: 232.761 (lr:0.00010000000000000113)
72020: accuracy:0.33 loss: 224.801 (lr:0.00010000000000000113)
72030: accuracy:0.38 loss: 212.104 (lr:0.00010000000000000113)
72040: accuracy:0.31 loss: 218.829 (lr:0.00010000000000000112)
72050: accuracy:0.4 loss: 222.264 (lr:0.00010000000000000112)
72060: accuracy:0.39 loss: 219.565 (lr:0.0001000000000000011)
72070: accuracy:0.41 loss: 211.418 (lr:0.0001000000000000011)
72080: accuracy:0.26 loss: 237.949 (lr:0.0001000000000000011)
72090: accuracy:0.3 loss: 224.869 (lr:0.00010000000000000109)
72100: accuracy:0.33 loss: 218.801 (lr:0.00010000000000000109)
72110: accuracy:0.24 loss: 227.559 (lr:0.00010000000000000108)
72120: accuracy:0.38 loss: 218.075 (lr:0.00010000000000000108)
72130: accuracy:0.34 loss: 233.433 (lr:0.00010000000000000108)
72140: accuracy:0.34 loss: 219.818 (lr:0.00010000000000000106)
72150: accuracy:0.34 loss: 224.009 (lr:0.00010000000000000106)
72160: accuracy:0.26 loss: 246.4 (lr:0.00010000000000000105)
72170: accuracy:0.36 loss: 218.383 (lr:0.00010000000000000105)
72180: accuracy:0.24 loss: 219.905 (lr:0.00010000000000000105)
72190: accuracy:0.31 loss: 215.608 (lr:0.00010000000000000103)
72200: accuracy:0.28 loss: 224.735 (lr:0.00010000000000000103)
72210: accuracy:0.26 loss: 234.713 (lr:0.00010000000000000103)
72220: accuracy:0.26 loss: 215.783 (lr:0.00010000000000000102)
72230: accuracy:0.31 loss: 223.693 (lr:0.00010000000000000102)
72240: accuracy:0.36 loss: 209.662 (lr:0.00010000000000000101)
72250: accuracy:0.32 loss: 220.118 (lr:0.00010000000000000101)
72260: accuracy:0.26 loss: 210.175 (lr:0.00010000000000000101)
72270: accuracy:0.38 loss: 207.062 (lr:0.000100000000000001)
72280: accuracy:0.35 loss: 206.467 (lr:0.000100000000000001)
72290: accuracy:0.27 loss: 236.265 (lr:0.000100000000000001)
72300: accuracy:0.23 loss: 229.197 (lr:0.00010000000000000098)
72310: accuracy:0.29 loss: 212.551 (lr:0.00010000000000000098)
72320: accuracy:0.28 loss: 236.889 (lr:0.00010000000000000097)
72330: accuracy:0.25 loss: 219.585 (lr:0.00010000000000000097)
72340: accuracy:0.26 loss: 215.463 (lr:0.00010000000000000097)
72350: accuracy:0.25 loss: 233.514 (lr:0.00010000000000000095)
72360: accuracy:0.41 loss: 210.906 (lr:0.00010000000000000095)
72370: accuracy:0.3 loss: 209.071 (lr:0.00010000000000000095)
72380: accuracy:0.24 loss: 241.349 (lr:0.00010000000000000094)
72390: accuracy:0.29 loss: 226.481 (lr:0.00010000000000000094)
72400: accuracy:0.29 loss: 233.888 (lr:0.00010000000000000094)
72410: accuracy:0.35 loss: 211.672 (lr:0.00010000000000000093)
72420: accuracy:0.33 loss: 226.582 (lr:0.00010000000000000093)
72430: accuracy:0.3 loss: 229.04 (lr:0.00010000000000000093)
72440: accuracy:0.34 loss: 220.036 (lr:0.00010000000000000091)
72450: accuracy:0.25 loss: 238.934 (lr:0.00010000000000000091)
72460: accuracy:0.33 loss: 221.483 (lr:0.00010000000000000091)
72470: accuracy:0.31 loss: 218.291 (lr:0.0001000000000000009)
72480: accuracy:0.32 loss: 220.91 (lr:0.0001000000000000009)
72490: accuracy:0.25 loss: 241.823 (lr:0.0001000000000000009)
72500: accuracy:0.24 loss: 251.069 (lr:0.00010000000000000089)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
72500: ********* epoch 8 ********* test accuracy for all:0.241892 test loss: 257.129
72500: ********* epoch 8 ********* test accuracy for mode 0:0.0045 test loss: 414.19
72500: ********* epoch 8 ********* test accuracy for mode 1:0.0645 test loss: 393.141
72500: ********* epoch 8 ********* test accuracy for mode 2:0.0345 test loss: 280.285
72500: ********* epoch 8 ********* test accuracy for mode 24:0.227 test loss: 264.548
72500: ********* epoch 8 ********* test accuracy for mode 25:0.2975 test loss: 235.098
72500: ********* epoch 8 ********* test accuracy for mode 26:0.4835 test loss: 163.761
72500: ********* epoch 8 ********* test accuracy for mode 27:0.237 test loss: 256.383
72500: ********* epoch 8 ********* test accuracy for mode 28:0.2805 test loss: 245.659
72500: ********* epoch 8 ********* test accuracy for mode 29:0.304 test loss: 250.536
72500: ********* epoch 8 ********* test accuracy for mode 30:0.273 test loss: 247.671
72500: ********* epoch 8 ********* test accuracy for mode 31:0.1635 test loss: 260.593
72500: ********* epoch 8 ********* test accuracy for mode 32:0.2415 test loss: 249.583
72500: ********* epoch 8 ********* test accuracy for mode 33:0.254 test loss: 256.325
72500: ********* epoch 8 ********* test accuracy for mode 34:0.109 test loss: 260.925
72500: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 412.439
72500: ********* epoch 8 ********* test accuracy for mode 36:0.064 test loss: 422.91
72510: accuracy:0.33 loss: 219.627 (lr:0.00010000000000000089)
72520: accuracy:0.26 loss: 227.833 (lr:0.00010000000000000089)
72530: accuracy:0.33 loss: 218.064 (lr:0.00010000000000000087)
72540: accuracy:0.28 loss: 212.922 (lr:0.00010000000000000087)
72550: accuracy:0.29 loss: 236.578 (lr:0.00010000000000000087)
72560: accuracy:0.23 loss: 226.386 (lr:0.00010000000000000086)
72570: accuracy:0.22 loss: 250.393 (lr:0.00010000000000000086)
72580: accuracy:0.31 loss: 219.469 (lr:0.00010000000000000086)
72590: accuracy:0.37 loss: 210.015 (lr:0.00010000000000000085)
72600: accuracy:0.29 loss: 229.263 (lr:0.00010000000000000085)
72610: accuracy:0.4 loss: 200.831 (lr:0.00010000000000000085)
72620: accuracy:0.28 loss: 233.641 (lr:0.00010000000000000085)
72630: accuracy:0.34 loss: 224.576 (lr:0.00010000000000000083)
72640: accuracy:0.36 loss: 225.896 (lr:0.00010000000000000083)
72650: accuracy:0.21 loss: 249.985 (lr:0.00010000000000000083)
72660: accuracy:0.31 loss: 234.504 (lr:0.00010000000000000082)
72670: accuracy:0.25 loss: 236.241 (lr:0.00010000000000000082)
72680: accuracy:0.28 loss: 220.118 (lr:0.00010000000000000082)
72690: accuracy:0.32 loss: 215.441 (lr:0.0001000000000000008)
72700: accuracy:0.26 loss: 211.207 (lr:0.0001000000000000008)
72710: accuracy:0.3 loss: 227.832 (lr:0.0001000000000000008)
72720: accuracy:0.3 loss: 220.254 (lr:0.0001000000000000008)
72730: accuracy:0.27 loss: 222.23 (lr:0.00010000000000000079)
72740: accuracy:0.23 loss: 222.572 (lr:0.00010000000000000079)
72750: accuracy:0.25 loss: 215.231 (lr:0.00010000000000000079)
72760: accuracy:0.31 loss: 239.62 (lr:0.00010000000000000078)
72770: accuracy:0.3 loss: 213.375 (lr:0.00010000000000000078)
72780: accuracy:0.38 loss: 222.182 (lr:0.00010000000000000078)
72790: accuracy:0.28 loss: 215.853 (lr:0.00010000000000000076)
72800: accuracy:0.34 loss: 223.316 (lr:0.00010000000000000076)
72810: accuracy:0.42 loss: 219.28 (lr:0.00010000000000000076)
72820: accuracy:0.28 loss: 254.213 (lr:0.00010000000000000076)
72830: accuracy:0.28 loss: 221.559 (lr:0.00010000000000000075)
72840: accuracy:0.31 loss: 238.556 (lr:0.00010000000000000075)
72850: accuracy:0.36 loss: 227.652 (lr:0.00010000000000000075)
72860: accuracy:0.34 loss: 201.478 (lr:0.00010000000000000075)
72870: accuracy:0.25 loss: 239.547 (lr:0.00010000000000000074)
72880: accuracy:0.36 loss: 224.339 (lr:0.00010000000000000074)
72890: accuracy:0.32 loss: 216.737 (lr:0.00010000000000000074)
72900: accuracy:0.29 loss: 204.045 (lr:0.00010000000000000072)
72910: accuracy:0.23 loss: 222.581 (lr:0.00010000000000000072)
72920: accuracy:0.31 loss: 222.118 (lr:0.00010000000000000072)
72930: accuracy:0.27 loss: 210.147 (lr:0.00010000000000000072)
72940: accuracy:0.3 loss: 235.528 (lr:0.00010000000000000071)
72950: accuracy:0.29 loss: 216.463 (lr:0.00010000000000000071)
72960: accuracy:0.38 loss: 232.637 (lr:0.00010000000000000071)
72970: accuracy:0.33 loss: 226.701 (lr:0.00010000000000000071)
72980: accuracy:0.29 loss: 236.45 (lr:0.0001000000000000007)
72990: accuracy:0.27 loss: 224.592 (lr:0.0001000000000000007)
73000: accuracy:0.39 loss: 211.791 (lr:0.0001000000000000007)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
73000: ********* epoch 8 ********* test accuracy for all:0.240662 test loss: 257.136
73000: ********* epoch 8 ********* test accuracy for mode 0:0.0035 test loss: 420.001
73000: ********* epoch 8 ********* test accuracy for mode 1:0.051 test loss: 398.129
73000: ********* epoch 8 ********* test accuracy for mode 2:0.059 test loss: 275.082
73000: ********* epoch 8 ********* test accuracy for mode 24:0.2335 test loss: 269.204
73000: ********* epoch 8 ********* test accuracy for mode 25:0.2635 test loss: 242.294
73000: ********* epoch 8 ********* test accuracy for mode 26:0.453 test loss: 161.869
73000: ********* epoch 8 ********* test accuracy for mode 27:0.265 test loss: 248.182
73000: ********* epoch 8 ********* test accuracy for mode 28:0.3135 test loss: 240.518
73000: ********* epoch 8 ********* test accuracy for mode 29:0.284 test loss: 244.158
73000: ********* epoch 8 ********* test accuracy for mode 30:0.296 test loss: 240.103
73000: ********* epoch 8 ********* test accuracy for mode 31:0.1945 test loss: 249.865
73000: ********* epoch 8 ********* test accuracy for mode 32:0.201 test loss: 245.901
73000: ********* epoch 8 ********* test accuracy for mode 33:0.264 test loss: 251.454
73000: ********* epoch 8 ********* test accuracy for mode 34:0.116 test loss: 257.907
73000: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 409.53
73000: ********* epoch 8 ********* test accuracy for mode 36:0.096 test loss: 420.734
73010: accuracy:0.31 loss: 209.665 (lr:0.0001000000000000007)
73020: accuracy:0.24 loss: 229.333 (lr:0.00010000000000000068)
73030: accuracy:0.32 loss: 206.931 (lr:0.00010000000000000068)
73040: accuracy:0.3 loss: 247.98 (lr:0.00010000000000000068)
73050: accuracy:0.33 loss: 226.369 (lr:0.00010000000000000068)
73060: accuracy:0.26 loss: 226.65 (lr:0.00010000000000000067)
73070: accuracy:0.21 loss: 226.884 (lr:0.00010000000000000067)
73080: accuracy:0.32 loss: 206.975 (lr:0.00010000000000000067)
73090: accuracy:0.33 loss: 213.282 (lr:0.00010000000000000067)
73100: accuracy:0.28 loss: 241.876 (lr:0.00010000000000000066)
73110: accuracy:0.41 loss: 200.12 (lr:0.00010000000000000066)
73120: accuracy:0.35 loss: 221.611 (lr:0.00010000000000000066)
73130: accuracy:0.33 loss: 198.163 (lr:0.00010000000000000066)
73140: accuracy:0.3 loss: 218.496 (lr:0.00010000000000000064)
73150: accuracy:0.27 loss: 242.084 (lr:0.00010000000000000064)
73160: accuracy:0.23 loss: 229.631 (lr:0.00010000000000000064)
73170: accuracy:0.26 loss: 254.39 (lr:0.00010000000000000064)
73180: accuracy:0.28 loss: 213.909 (lr:0.00010000000000000063)
73190: accuracy:0.31 loss: 231.926 (lr:0.00010000000000000063)
73200: accuracy:0.32 loss: 217.625 (lr:0.00010000000000000063)
73210: accuracy:0.3 loss: 222.441 (lr:0.00010000000000000063)
73220: accuracy:0.32 loss: 225.609 (lr:0.00010000000000000063)
73230: accuracy:0.31 loss: 228.673 (lr:0.00010000000000000061)
73240: accuracy:0.29 loss: 209.679 (lr:0.00010000000000000061)
73250: accuracy:0.31 loss: 231.126 (lr:0.00010000000000000061)
73260: accuracy:0.37 loss: 227.582 (lr:0.00010000000000000061)
73270: accuracy:0.32 loss: 226.437 (lr:0.0001000000000000006)
73280: accuracy:0.28 loss: 252.164 (lr:0.0001000000000000006)
73290: accuracy:0.32 loss: 236.424 (lr:0.0001000000000000006)
73300: accuracy:0.28 loss: 246.567 (lr:0.0001000000000000006)
73310: accuracy:0.35 loss: 230.857 (lr:0.0001000000000000006)
73320: accuracy:0.24 loss: 220.59 (lr:0.00010000000000000059)
73330: accuracy:0.25 loss: 240.131 (lr:0.00010000000000000059)
73340: accuracy:0.36 loss: 211.831 (lr:0.00010000000000000059)
73350: accuracy:0.33 loss: 225.414 (lr:0.00010000000000000059)
73360: accuracy:0.33 loss: 224.058 (lr:0.00010000000000000057)
73370: accuracy:0.3 loss: 229.881 (lr:0.00010000000000000057)
73380: accuracy:0.23 loss: 239.782 (lr:0.00010000000000000057)
73390: accuracy:0.3 loss: 232.995 (lr:0.00010000000000000057)
73400: accuracy:0.26 loss: 245.911 (lr:0.00010000000000000057)
73410: accuracy:0.36 loss: 204.874 (lr:0.00010000000000000056)
73420: accuracy:0.3 loss: 226.331 (lr:0.00010000000000000056)
73430: accuracy:0.33 loss: 221.666 (lr:0.00010000000000000056)
73440: accuracy:0.36 loss: 222.712 (lr:0.00010000000000000056)
73450: accuracy:0.22 loss: 222.948 (lr:0.00010000000000000056)
73460: accuracy:0.29 loss: 235.546 (lr:0.00010000000000000055)
73470: accuracy:0.27 loss: 234.562 (lr:0.00010000000000000055)
73480: accuracy:0.26 loss: 230.99 (lr:0.00010000000000000055)
73490: accuracy:0.27 loss: 221.408 (lr:0.00010000000000000055)
73500: accuracy:0.25 loss: 234.671 (lr:0.00010000000000000055)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
73500: ********* epoch 8 ********* test accuracy for all:0.241595 test loss: 256.994
73500: ********* epoch 8 ********* test accuracy for mode 0:0.0055 test loss: 415.962
73500: ********* epoch 8 ********* test accuracy for mode 1:0.0645 test loss: 396.044
73500: ********* epoch 8 ********* test accuracy for mode 2:0.066 test loss: 277.48
73500: ********* epoch 8 ********* test accuracy for mode 24:0.2145 test loss: 270.428
73500: ********* epoch 8 ********* test accuracy for mode 25:0.2915 test loss: 244.437
73500: ********* epoch 8 ********* test accuracy for mode 26:0.4185 test loss: 175.19
73500: ********* epoch 8 ********* test accuracy for mode 27:0.191 test loss: 277.36
73500: ********* epoch 8 ********* test accuracy for mode 28:0.282 test loss: 253.386
73500: ********* epoch 8 ********* test accuracy for mode 29:0.289 test loss: 256.817
73500: ********* epoch 8 ********* test accuracy for mode 30:0.251 test loss: 250.557
73500: ********* epoch 8 ********* test accuracy for mode 31:0.223 test loss: 254.903
73500: ********* epoch 8 ********* test accuracy for mode 32:0.2225 test loss: 246.247
73500: ********* epoch 8 ********* test accuracy for mode 33:0.271 test loss: 252.182
73500: ********* epoch 8 ********* test accuracy for mode 34:0.1025 test loss: 258.891
73500: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 411.306
73500: ********* epoch 8 ********* test accuracy for mode 36:0.038 test loss: 435.503
73510: accuracy:0.28 loss: 236.462 (lr:0.00010000000000000053)
73520: accuracy:0.34 loss: 201.979 (lr:0.00010000000000000053)
73530: accuracy:0.33 loss: 234.007 (lr:0.00010000000000000053)
73540: accuracy:0.31 loss: 201.609 (lr:0.00010000000000000053)
73550: accuracy:0.3 loss: 226.848 (lr:0.00010000000000000053)
73560: accuracy:0.27 loss: 233.863 (lr:0.00010000000000000052)
73570: accuracy:0.3 loss: 222.423 (lr:0.00010000000000000052)
73580: accuracy:0.29 loss: 232.232 (lr:0.00010000000000000052)
73590: accuracy:0.35 loss: 206.834 (lr:0.00010000000000000052)
73600: accuracy:0.35 loss: 211.378 (lr:0.00010000000000000052)
73610: accuracy:0.28 loss: 229.972 (lr:0.0001000000000000005)
73620: accuracy:0.29 loss: 234.779 (lr:0.0001000000000000005)
73630: accuracy:0.24 loss: 226.325 (lr:0.0001000000000000005)
73640: accuracy:0.31 loss: 242.112 (lr:0.0001000000000000005)
73650: accuracy:0.28 loss: 233.913 (lr:0.0001000000000000005)
73660: accuracy:0.27 loss: 242.165 (lr:0.0001000000000000005)
73670: accuracy:0.28 loss: 219.046 (lr:0.00010000000000000049)
73680: accuracy:0.28 loss: 216.705 (lr:0.00010000000000000049)
73690: accuracy:0.32 loss: 227.836 (lr:0.00010000000000000049)
73700: accuracy:0.33 loss: 240.478 (lr:0.00010000000000000049)
73710: accuracy:0.29 loss: 221.953 (lr:0.00010000000000000049)
73720: accuracy:0.2 loss: 230.307 (lr:0.00010000000000000048)
73730: accuracy:0.26 loss: 219.515 (lr:0.00010000000000000048)
73740: accuracy:0.39 loss: 202.58 (lr:0.00010000000000000048)
73750: accuracy:0.35 loss: 209.956 (lr:0.00010000000000000048)
73760: accuracy:0.28 loss: 232.553 (lr:0.00010000000000000048)
73770: accuracy:0.3 loss: 220.363 (lr:0.00010000000000000048)
73780: accuracy:0.28 loss: 233.949 (lr:0.00010000000000000047)
73790: accuracy:0.25 loss: 239.119 (lr:0.00010000000000000047)
73800: accuracy:0.36 loss: 212.9 (lr:0.00010000000000000047)
73810: accuracy:0.28 loss: 234.223 (lr:0.00010000000000000047)
73820: accuracy:0.34 loss: 211.905 (lr:0.00010000000000000047)
73830: accuracy:0.23 loss: 244.084 (lr:0.00010000000000000047)
73840: accuracy:0.24 loss: 247.14 (lr:0.00010000000000000045)
73850: accuracy:0.3 loss: 218.124 (lr:0.00010000000000000045)
73860: accuracy:0.35 loss: 201.195 (lr:0.00010000000000000045)
73870: accuracy:0.22 loss: 240.64 (lr:0.00010000000000000045)
73880: accuracy:0.22 loss: 218.089 (lr:0.00010000000000000045)
73890: accuracy:0.34 loss: 218.205 (lr:0.00010000000000000045)
73900: accuracy:0.37 loss: 226.551 (lr:0.00010000000000000044)
73910: accuracy:0.32 loss: 224.696 (lr:0.00010000000000000044)
73920: accuracy:0.19 loss: 229.48 (lr:0.00010000000000000044)
73930: accuracy:0.29 loss: 217.369 (lr:0.00010000000000000044)
73940: accuracy:0.34 loss: 220.224 (lr:0.00010000000000000044)
73950: accuracy:0.33 loss: 221.52 (lr:0.00010000000000000044)
73960: accuracy:0.19 loss: 225.328 (lr:0.00010000000000000042)
73970: accuracy:0.34 loss: 229.4 (lr:0.00010000000000000042)
73980: accuracy:0.27 loss: 219.776 (lr:0.00010000000000000042)
73990: accuracy:0.31 loss: 219.686 (lr:0.00010000000000000042)
74000: accuracy:0.22 loss: 246.195 (lr:0.00010000000000000042)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
74000: ********* epoch 8 ********* test accuracy for all:0.245905 test loss: 255.052
74000: ********* epoch 8 ********* test accuracy for mode 0:0.0065 test loss: 415.781
74000: ********* epoch 8 ********* test accuracy for mode 1:0.0595 test loss: 392.876
74000: ********* epoch 8 ********* test accuracy for mode 2:0.0425 test loss: 274.418
74000: ********* epoch 8 ********* test accuracy for mode 24:0.2525 test loss: 265.143
74000: ********* epoch 8 ********* test accuracy for mode 25:0.274 test loss: 243.093
74000: ********* epoch 8 ********* test accuracy for mode 26:0.384 test loss: 173.317
74000: ********* epoch 8 ********* test accuracy for mode 27:0.254 test loss: 255.599
74000: ********* epoch 8 ********* test accuracy for mode 28:0.319 test loss: 244.854
74000: ********* epoch 8 ********* test accuracy for mode 29:0.2745 test loss: 251.764
74000: ********* epoch 8 ********* test accuracy for mode 30:0.2725 test loss: 244.072
74000: ********* epoch 8 ********* test accuracy for mode 31:0.1995 test loss: 250.576
74000: ********* epoch 8 ********* test accuracy for mode 32:0.252 test loss: 242.031
74000: ********* epoch 8 ********* test accuracy for mode 33:0.2415 test loss: 250.388
74000: ********* epoch 8 ********* test accuracy for mode 34:0.125 test loss: 254.0
74000: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 408.723
74000: ********* epoch 8 ********* test accuracy for mode 36:0.113 test loss: 409.743
74010: accuracy:0.28 loss: 234.949 (lr:0.00010000000000000042)
74020: accuracy:0.27 loss: 223.833 (lr:0.00010000000000000042)
74030: accuracy:0.23 loss: 238.703 (lr:0.00010000000000000041)
74040: accuracy:0.31 loss: 216.236 (lr:0.00010000000000000041)
74050: accuracy:0.31 loss: 232.02 (lr:0.00010000000000000041)
74060: accuracy:0.25 loss: 227.711 (lr:0.00010000000000000041)
74070: accuracy:0.24 loss: 231.04 (lr:0.00010000000000000041)
74080: accuracy:0.29 loss: 233.201 (lr:0.00010000000000000041)
74090: accuracy:0.28 loss: 232.106 (lr:0.0001000000000000004)
74100: accuracy:0.3 loss: 225.854 (lr:0.0001000000000000004)
74110: accuracy:0.25 loss: 234.456 (lr:0.0001000000000000004)
74120: accuracy:0.41 loss: 213.281 (lr:0.0001000000000000004)
74130: accuracy:0.28 loss: 220.138 (lr:0.0001000000000000004)
74140: accuracy:0.31 loss: 232.248 (lr:0.0001000000000000004)
74150: accuracy:0.24 loss: 221.776 (lr:0.0001000000000000004)
74160: accuracy:0.25 loss: 227.538 (lr:0.00010000000000000038)
74170: accuracy:0.33 loss: 222.647 (lr:0.00010000000000000038)
74180: accuracy:0.37 loss: 216.882 (lr:0.00010000000000000038)
74190: accuracy:0.32 loss: 244.967 (lr:0.00010000000000000038)
74200: accuracy:0.31 loss: 218.633 (lr:0.00010000000000000038)
74210: accuracy:0.28 loss: 234.949 (lr:0.00010000000000000038)
74220: accuracy:0.25 loss: 227.072 (lr:0.00010000000000000038)
74230: accuracy:0.38 loss: 217.184 (lr:0.00010000000000000038)
74240: accuracy:0.31 loss: 212.519 (lr:0.00010000000000000037)
74250: accuracy:0.35 loss: 210.408 (lr:0.00010000000000000037)
74260: accuracy:0.27 loss: 227.271 (lr:0.00010000000000000037)
74270: accuracy:0.32 loss: 227.061 (lr:0.00010000000000000037)
74280: accuracy:0.35 loss: 207.408 (lr:0.00010000000000000037)
74290: accuracy:0.33 loss: 221.651 (lr:0.00010000000000000037)
74300: accuracy:0.39 loss: 214.788 (lr:0.00010000000000000037)
74310: accuracy:0.31 loss: 219.933 (lr:0.00010000000000000036)
74320: accuracy:0.34 loss: 219.018 (lr:0.00010000000000000036)
74330: accuracy:0.24 loss: 234.497 (lr:0.00010000000000000036)
74340: accuracy:0.34 loss: 213.743 (lr:0.00010000000000000036)
74350: accuracy:0.25 loss: 229.628 (lr:0.00010000000000000036)
74360: accuracy:0.28 loss: 230.47 (lr:0.00010000000000000036)
74370: accuracy:0.25 loss: 230.126 (lr:0.00010000000000000036)
74380: accuracy:0.31 loss: 234.163 (lr:0.00010000000000000036)
74390: accuracy:0.45 loss: 196.749 (lr:0.00010000000000000034)
74400: accuracy:0.27 loss: 231.888 (lr:0.00010000000000000034)
74410: accuracy:0.28 loss: 256.04 (lr:0.00010000000000000034)
74420: accuracy:0.33 loss: 231.207 (lr:0.00010000000000000034)
74430: accuracy:0.33 loss: 224.01 (lr:0.00010000000000000034)
74440: accuracy:0.34 loss: 233.787 (lr:0.00010000000000000034)
74450: accuracy:0.24 loss: 233.054 (lr:0.00010000000000000034)
74460: accuracy:0.28 loss: 226.483 (lr:0.00010000000000000034)
74470: accuracy:0.3 loss: 239.765 (lr:0.00010000000000000033)
74480: accuracy:0.39 loss: 219.141 (lr:0.00010000000000000033)
74490: accuracy:0.34 loss: 210.987 (lr:0.00010000000000000033)
74500: accuracy:0.29 loss: 236.848 (lr:0.00010000000000000033)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
74500: ********* epoch 8 ********* test accuracy for all:0.241662 test loss: 255.515
74500: ********* epoch 8 ********* test accuracy for mode 0:0.006 test loss: 409.494
74500: ********* epoch 8 ********* test accuracy for mode 1:0.07 test loss: 386.912
74500: ********* epoch 8 ********* test accuracy for mode 2:0.0385 test loss: 280.312
74500: ********* epoch 8 ********* test accuracy for mode 24:0.2495 test loss: 259.517
74500: ********* epoch 8 ********* test accuracy for mode 25:0.248 test loss: 245.539
74500: ********* epoch 8 ********* test accuracy for mode 26:0.3985 test loss: 172.047
74500: ********* epoch 8 ********* test accuracy for mode 27:0.273 test loss: 255.429
74500: ********* epoch 8 ********* test accuracy for mode 28:0.293 test loss: 250.439
74500: ********* epoch 8 ********* test accuracy for mode 29:0.2895 test loss: 259.819
74500: ********* epoch 8 ********* test accuracy for mode 30:0.248 test loss: 259.082
74500: ********* epoch 8 ********* test accuracy for mode 31:0.156 test loss: 269.423
74500: ********* epoch 8 ********* test accuracy for mode 32:0.228 test loss: 256.361
74500: ********* epoch 8 ********* test accuracy for mode 33:0.203 test loss: 262.972
74500: ********* epoch 8 ********* test accuracy for mode 34:0.1575 test loss: 258.973
74500: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 394.776
74500: ********* epoch 8 ********* test accuracy for mode 36:0.054 test loss: 410.529
74510: accuracy:0.36 loss: 225.1 (lr:0.00010000000000000033)
74520: accuracy:0.23 loss: 235.683 (lr:0.00010000000000000033)
74530: accuracy:0.29 loss: 222.067 (lr:0.00010000000000000033)
74540: accuracy:0.36 loss: 208.029 (lr:0.00010000000000000033)
74550: accuracy:0.36 loss: 219.939 (lr:0.00010000000000000032)
74560: accuracy:0.3 loss: 213.746 (lr:0.00010000000000000032)
74570: accuracy:0.33 loss: 221.331 (lr:0.00010000000000000032)
74580: accuracy:0.24 loss: 211.107 (lr:0.00010000000000000032)
74590: accuracy:0.27 loss: 234.134 (lr:0.00010000000000000032)
74600: accuracy:0.31 loss: 217.844 (lr:0.00010000000000000032)
74610: accuracy:0.33 loss: 211.991 (lr:0.00010000000000000032)
74620: accuracy:0.29 loss: 220.52 (lr:0.00010000000000000032)
74630: accuracy:0.28 loss: 233.961 (lr:0.00010000000000000032)
74640: accuracy:0.15 loss: 261.632 (lr:0.0001000000000000003)
74650: accuracy:0.33 loss: 216.338 (lr:0.0001000000000000003)
74660: accuracy:0.27 loss: 218.614 (lr:0.0001000000000000003)
74670: accuracy:0.29 loss: 244.039 (lr:0.0001000000000000003)
74680: accuracy:0.27 loss: 228.33 (lr:0.0001000000000000003)
74690: accuracy:0.3 loss: 219.517 (lr:0.0001000000000000003)
74700: accuracy:0.32 loss: 224.638 (lr:0.0001000000000000003)
74710: accuracy:0.27 loss: 218.513 (lr:0.0001000000000000003)
74720: accuracy:0.29 loss: 233.088 (lr:0.0001000000000000003)
74730: accuracy:0.28 loss: 235.419 (lr:0.00010000000000000029)
74740: accuracy:0.29 loss: 236.129 (lr:0.00010000000000000029)
74750: accuracy:0.33 loss: 214.232 (lr:0.00010000000000000029)
74760: accuracy:0.34 loss: 221.197 (lr:0.00010000000000000029)
74770: accuracy:0.29 loss: 210.57 (lr:0.00010000000000000029)
74780: accuracy:0.33 loss: 197.038 (lr:0.00010000000000000029)
74790: accuracy:0.33 loss: 216.05 (lr:0.00010000000000000029)
74800: accuracy:0.28 loss: 230.862 (lr:0.00010000000000000029)
74810: accuracy:0.26 loss: 221.274 (lr:0.00010000000000000029)
74820: accuracy:0.32 loss: 207.638 (lr:0.00010000000000000028)
74830: accuracy:0.21 loss: 227.649 (lr:0.00010000000000000028)
74840: accuracy:0.33 loss: 209.056 (lr:0.00010000000000000028)
74850: accuracy:0.32 loss: 239.774 (lr:0.00010000000000000028)
74860: accuracy:0.27 loss: 250.054 (lr:0.00010000000000000028)
74870: accuracy:0.3 loss: 219.271 (lr:0.00010000000000000028)
74880: accuracy:0.24 loss: 225.02 (lr:0.00010000000000000028)
74890: accuracy:0.39 loss: 207.35 (lr:0.00010000000000000028)
74900: accuracy:0.33 loss: 219.815 (lr:0.00010000000000000028)
74910: accuracy:0.31 loss: 235.035 (lr:0.00010000000000000028)
74920: accuracy:0.29 loss: 232.995 (lr:0.00010000000000000026)
74930: accuracy:0.28 loss: 225.512 (lr:0.00010000000000000026)
74940: accuracy:0.25 loss: 238.988 (lr:0.00010000000000000026)
74950: accuracy:0.33 loss: 222.361 (lr:0.00010000000000000026)
74960: accuracy:0.31 loss: 239.81 (lr:0.00010000000000000026)
74970: accuracy:0.32 loss: 226.975 (lr:0.00010000000000000026)
74980: accuracy:0.27 loss: 221.501 (lr:0.00010000000000000026)
74990: accuracy:0.34 loss: 236.4 (lr:0.00010000000000000026)
75000: accuracy:0.44 loss: 200.451 (lr:0.00010000000000000026)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
75000: ********* epoch 8 ********* test accuracy for all:0.241257 test loss: 258.242
75000: ********* epoch 8 ********* test accuracy for mode 0:0.0025 test loss: 425.701
75000: ********* epoch 8 ********* test accuracy for mode 1:0.056 test loss: 403.826
75000: ********* epoch 8 ********* test accuracy for mode 2:0.052 test loss: 269.145
75000: ********* epoch 8 ********* test accuracy for mode 24:0.211 test loss: 274.879
75000: ********* epoch 8 ********* test accuracy for mode 25:0.3095 test loss: 244.21
75000: ********* epoch 8 ********* test accuracy for mode 26:0.337 test loss: 178.574
75000: ********* epoch 8 ********* test accuracy for mode 27:0.268 test loss: 267.659
75000: ********* epoch 8 ********* test accuracy for mode 28:0.232 test loss: 267.256
75000: ********* epoch 8 ********* test accuracy for mode 29:0.2815 test loss: 267.429
75000: ********* epoch 8 ********* test accuracy for mode 30:0.2145 test loss: 262.266
75000: ********* epoch 8 ********* test accuracy for mode 31:0.197 test loss: 259.281
75000: ********* epoch 8 ********* test accuracy for mode 32:0.232 test loss: 249.091
75000: ********* epoch 8 ********* test accuracy for mode 33:0.2335 test loss: 251.751
75000: ********* epoch 8 ********* test accuracy for mode 34:0.1925 test loss: 247.134
75000: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 416.524
75000: ********* epoch 8 ********* test accuracy for mode 36:0.0455 test loss: 453.099
75010: accuracy:0.3 loss: 227.456 (lr:0.00010000000000000026)
75020: accuracy:0.24 loss: 250.108 (lr:0.00010000000000000026)
75030: accuracy:0.22 loss: 225.195 (lr:0.00010000000000000025)
75040: accuracy:0.25 loss: 238.497 (lr:0.00010000000000000025)
75050: accuracy:0.32 loss: 250.702 (lr:0.00010000000000000025)
75060: accuracy:0.29 loss: 225.139 (lr:0.00010000000000000025)
75070: accuracy:0.34 loss: 217.646 (lr:0.00010000000000000025)
75080: accuracy:0.31 loss: 255.472 (lr:0.00010000000000000025)
75090: accuracy:0.26 loss: 235.319 (lr:0.00010000000000000025)
75100: accuracy:0.34 loss: 210.882 (lr:0.00010000000000000025)
75110: accuracy:0.27 loss: 220.705 (lr:0.00010000000000000025)
75120: accuracy:0.25 loss: 231.673 (lr:0.00010000000000000025)
75130: accuracy:0.31 loss: 232.798 (lr:0.00010000000000000025)
75140: accuracy:0.33 loss: 230.48 (lr:0.00010000000000000024)
75150: accuracy:0.32 loss: 230.597 (lr:0.00010000000000000024)
75160: accuracy:0.29 loss: 221.942 (lr:0.00010000000000000024)
75170: accuracy:0.32 loss: 212.872 (lr:0.00010000000000000024)
75180: accuracy:0.29 loss: 229.342 (lr:0.00010000000000000024)
75190: accuracy:0.33 loss: 223.596 (lr:0.00010000000000000024)
75200: accuracy:0.26 loss: 242.146 (lr:0.00010000000000000024)
75210: accuracy:0.27 loss: 239.244 (lr:0.00010000000000000024)
75220: accuracy:0.29 loss: 235.48 (lr:0.00010000000000000024)
75230: accuracy:0.34 loss: 223.071 (lr:0.00010000000000000024)
75240: accuracy:0.37 loss: 227.104 (lr:0.00010000000000000024)
75250: accuracy:0.31 loss: 232.922 (lr:0.00010000000000000024)
75260: accuracy:0.32 loss: 228.996 (lr:0.00010000000000000022)
75270: accuracy:0.32 loss: 220.352 (lr:0.00010000000000000022)
75280: accuracy:0.26 loss: 233.944 (lr:0.00010000000000000022)
75290: accuracy:0.32 loss: 225.247 (lr:0.00010000000000000022)
75300: accuracy:0.3 loss: 218.146 (lr:0.00010000000000000022)
75310: accuracy:0.31 loss: 227.658 (lr:0.00010000000000000022)
75320: accuracy:0.3 loss: 210.782 (lr:0.00010000000000000022)
75330: accuracy:0.3 loss: 226.425 (lr:0.00010000000000000022)
75340: accuracy:0.35 loss: 230.207 (lr:0.00010000000000000022)
75350: accuracy:0.36 loss: 217.601 (lr:0.00010000000000000022)
75360: accuracy:0.4 loss: 216.672 (lr:0.00010000000000000022)
75370: accuracy:0.32 loss: 238.799 (lr:0.00010000000000000022)
75380: accuracy:0.45 loss: 210.725 (lr:0.00010000000000000021)
75390: accuracy:0.33 loss: 212.828 (lr:0.00010000000000000021)
75400: accuracy:0.29 loss: 230.169 (lr:0.00010000000000000021)
75410: accuracy:0.31 loss: 231.229 (lr:0.00010000000000000021)
75420: accuracy:0.21 loss: 232.65 (lr:0.00010000000000000021)
75430: accuracy:0.24 loss: 210.472 (lr:0.00010000000000000021)
75440: accuracy:0.32 loss: 226.724 (lr:0.00010000000000000021)
75450: accuracy:0.22 loss: 248.232 (lr:0.00010000000000000021)
75460: accuracy:0.31 loss: 226.902 (lr:0.00010000000000000021)
75470: accuracy:0.25 loss: 208.991 (lr:0.00010000000000000021)
75480: accuracy:0.34 loss: 210.215 (lr:0.00010000000000000021)
75490: accuracy:0.3 loss: 223.463 (lr:0.00010000000000000021)
75500: accuracy:0.29 loss: 215.48 (lr:0.00010000000000000021)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
75500: ********* epoch 8 ********* test accuracy for all:0.240108 test loss: 258.071
75500: ********* epoch 8 ********* test accuracy for mode 0:0.004 test loss: 425.87
75500: ********* epoch 8 ********* test accuracy for mode 1:0.0625 test loss: 402.797
75500: ********* epoch 8 ********* test accuracy for mode 2:0.0725 test loss: 272.723
75500: ********* epoch 8 ********* test accuracy for mode 24:0.25 test loss: 266.973
75500: ********* epoch 8 ********* test accuracy for mode 25:0.2575 test loss: 247.622
75500: ********* epoch 8 ********* test accuracy for mode 26:0.402 test loss: 173.275
75500: ********* epoch 8 ********* test accuracy for mode 27:0.261 test loss: 261.668
75500: ********* epoch 8 ********* test accuracy for mode 28:0.3215 test loss: 249.664
75500: ********* epoch 8 ********* test accuracy for mode 29:0.2595 test loss: 260.339
75500: ********* epoch 8 ********* test accuracy for mode 30:0.245 test loss: 255.635
75500: ********* epoch 8 ********* test accuracy for mode 31:0.1825 test loss: 256.214
75500: ********* epoch 8 ********* test accuracy for mode 32:0.2625 test loss: 245.492
75500: ********* epoch 8 ********* test accuracy for mode 33:0.2135 test loss: 253.484
75500: ********* epoch 8 ********* test accuracy for mode 34:0.17 test loss: 251.266
75500: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 414.906
75500: ********* epoch 8 ********* test accuracy for mode 36:0.0575 test loss: 433.739
75510: accuracy:0.33 loss: 227.368 (lr:0.00010000000000000021)
75520: accuracy:0.27 loss: 223.444 (lr:0.0001000000000000002)
75530: accuracy:0.33 loss: 229.887 (lr:0.0001000000000000002)
75540: accuracy:0.25 loss: 248.763 (lr:0.0001000000000000002)
75550: accuracy:0.31 loss: 222.875 (lr:0.0001000000000000002)
75560: accuracy:0.16 loss: 247.487 (lr:0.0001000000000000002)
75570: accuracy:0.28 loss: 228.419 (lr:0.0001000000000000002)
75580: accuracy:0.24 loss: 243.172 (lr:0.0001000000000000002)
75590: accuracy:0.29 loss: 216.836 (lr:0.0001000000000000002)
75600: accuracy:0.35 loss: 219.489 (lr:0.0001000000000000002)
75610: accuracy:0.3 loss: 225.656 (lr:0.0001000000000000002)
75620: accuracy:0.33 loss: 210.807 (lr:0.0001000000000000002)
75630: accuracy:0.16 loss: 249.421 (lr:0.0001000000000000002)
75640: accuracy:0.36 loss: 207.607 (lr:0.0001000000000000002)
75650: accuracy:0.19 loss: 225.765 (lr:0.0001000000000000002)
75660: accuracy:0.3 loss: 220.352 (lr:0.00010000000000000018)
75670: accuracy:0.29 loss: 233.154 (lr:0.00010000000000000018)
75680: accuracy:0.29 loss: 218.714 (lr:0.00010000000000000018)
75690: accuracy:0.31 loss: 223.162 (lr:0.00010000000000000018)
75700: accuracy:0.26 loss: 236.846 (lr:0.00010000000000000018)
75710: accuracy:0.36 loss: 231.342 (lr:0.00010000000000000018)
75720: accuracy:0.38 loss: 210.281 (lr:0.00010000000000000018)
75730: accuracy:0.34 loss: 232.474 (lr:0.00010000000000000018)
75740: accuracy:0.42 loss: 189.409 (lr:0.00010000000000000018)
75750: accuracy:0.36 loss: 215.57 (lr:0.00010000000000000018)
75760: accuracy:0.28 loss: 229.443 (lr:0.00010000000000000018)
75770: accuracy:0.36 loss: 223.878 (lr:0.00010000000000000018)
75780: accuracy:0.36 loss: 205.308 (lr:0.00010000000000000018)
75790: accuracy:0.33 loss: 229.432 (lr:0.00010000000000000018)
75800: accuracy:0.32 loss: 239.906 (lr:0.00010000000000000018)
75810: accuracy:0.26 loss: 252.331 (lr:0.00010000000000000017)
75820: accuracy:0.31 loss: 226.754 (lr:0.00010000000000000017)
75830: accuracy:0.29 loss: 220.314 (lr:0.00010000000000000017)
75840: accuracy:0.23 loss: 222.078 (lr:0.00010000000000000017)
75850: accuracy:0.39 loss: 208.995 (lr:0.00010000000000000017)
75860: accuracy:0.24 loss: 225.771 (lr:0.00010000000000000017)
75870: accuracy:0.32 loss: 219.6 (lr:0.00010000000000000017)
75880: accuracy:0.34 loss: 220.658 (lr:0.00010000000000000017)
75890: accuracy:0.3 loss: 233.388 (lr:0.00010000000000000017)
75900: accuracy:0.31 loss: 230.053 (lr:0.00010000000000000017)
75910: accuracy:0.27 loss: 241.61 (lr:0.00010000000000000017)
75920: accuracy:0.35 loss: 205.205 (lr:0.00010000000000000017)
75930: accuracy:0.31 loss: 229.102 (lr:0.00010000000000000017)
75940: accuracy:0.31 loss: 221.211 (lr:0.00010000000000000017)
75950: accuracy:0.27 loss: 226.25 (lr:0.00010000000000000017)
75960: accuracy:0.26 loss: 218.488 (lr:0.00010000000000000017)
75970: accuracy:0.37 loss: 206.517 (lr:0.00010000000000000017)
75980: accuracy:0.31 loss: 220.619 (lr:0.00010000000000000015)
75990: accuracy:0.23 loss: 235.313 (lr:0.00010000000000000015)
76000: accuracy:0.22 loss: 237.459 (lr:0.00010000000000000015)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
76000: ********* epoch 8 ********* test accuracy for all:0.242068 test loss: 256.705
76000: ********* epoch 8 ********* test accuracy for mode 0:0.0055 test loss: 423.329
76000: ********* epoch 8 ********* test accuracy for mode 1:0.0555 test loss: 402.286
76000: ********* epoch 8 ********* test accuracy for mode 2:0.0465 test loss: 275.114
76000: ********* epoch 8 ********* test accuracy for mode 24:0.2395 test loss: 265.188
76000: ********* epoch 8 ********* test accuracy for mode 25:0.2555 test loss: 252.276
76000: ********* epoch 8 ********* test accuracy for mode 26:0.3705 test loss: 182.951
76000: ********* epoch 8 ********* test accuracy for mode 27:0.2235 test loss: 277.854
76000: ********* epoch 8 ********* test accuracy for mode 28:0.276 test loss: 258.772
76000: ********* epoch 8 ********* test accuracy for mode 29:0.273 test loss: 257.275
76000: ********* epoch 8 ********* test accuracy for mode 30:0.245 test loss: 251.524
76000: ********* epoch 8 ********* test accuracy for mode 31:0.2205 test loss: 250.827
76000: ********* epoch 8 ********* test accuracy for mode 32:0.246 test loss: 239.93
76000: ********* epoch 8 ********* test accuracy for mode 33:0.2435 test loss: 248.798
76000: ********* epoch 8 ********* test accuracy for mode 34:0.1255 test loss: 251.605
76000: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 402.33
76000: ********* epoch 8 ********* test accuracy for mode 36:0.0475 test loss: 440.001
76010: accuracy:0.29 loss: 233.006 (lr:0.00010000000000000015)
76020: accuracy:0.3 loss: 223.721 (lr:0.00010000000000000015)
76030: accuracy:0.3 loss: 222.376 (lr:0.00010000000000000015)
76040: accuracy:0.24 loss: 241.86 (lr:0.00010000000000000015)
76050: accuracy:0.36 loss: 226.495 (lr:0.00010000000000000015)
76060: accuracy:0.3 loss: 221.424 (lr:0.00010000000000000015)
76070: accuracy:0.29 loss: 217.548 (lr:0.00010000000000000015)
76080: accuracy:0.32 loss: 197.82 (lr:0.00010000000000000015)
76090: accuracy:0.3 loss: 222.169 (lr:0.00010000000000000015)
76100: accuracy:0.27 loss: 238.543 (lr:0.00010000000000000015)
76110: accuracy:0.3 loss: 247.591 (lr:0.00010000000000000015)
76120: accuracy:0.28 loss: 234.519 (lr:0.00010000000000000015)
76130: accuracy:0.31 loss: 218.922 (lr:0.00010000000000000015)
76140: accuracy:0.24 loss: 244.512 (lr:0.00010000000000000015)
76150: accuracy:0.27 loss: 226.608 (lr:0.00010000000000000015)
76160: accuracy:0.25 loss: 238.486 (lr:0.00010000000000000014)
76170: accuracy:0.33 loss: 208.992 (lr:0.00010000000000000014)
76180: accuracy:0.18 loss: 254.455 (lr:0.00010000000000000014)
76190: accuracy:0.24 loss: 227.584 (lr:0.00010000000000000014)
76200: accuracy:0.35 loss: 212.781 (lr:0.00010000000000000014)
76210: accuracy:0.26 loss: 232.231 (lr:0.00010000000000000014)
76220: accuracy:0.33 loss: 197.261 (lr:0.00010000000000000014)
76230: accuracy:0.31 loss: 218.991 (lr:0.00010000000000000014)
76240: accuracy:0.26 loss: 210.409 (lr:0.00010000000000000014)
76250: accuracy:0.27 loss: 247.063 (lr:0.00010000000000000014)
76260: accuracy:0.3 loss: 226.585 (lr:0.00010000000000000014)
76270: accuracy:0.31 loss: 227.656 (lr:0.00010000000000000014)
76280: accuracy:0.31 loss: 209.036 (lr:0.00010000000000000014)
76290: accuracy:0.17 loss: 249.775 (lr:0.00010000000000000014)
76300: accuracy:0.25 loss: 236.78 (lr:0.00010000000000000014)
76310: accuracy:0.25 loss: 229.199 (lr:0.00010000000000000014)
76320: accuracy:0.26 loss: 248.083 (lr:0.00010000000000000014)
76330: accuracy:0.33 loss: 217.576 (lr:0.00010000000000000014)
76340: accuracy:0.28 loss: 246.302 (lr:0.00010000000000000014)
76350: accuracy:0.3 loss: 223.951 (lr:0.00010000000000000014)
76360: accuracy:0.37 loss: 201.172 (lr:0.00010000000000000013)
76370: accuracy:0.36 loss: 220.255 (lr:0.00010000000000000013)
76380: accuracy:0.35 loss: 200.769 (lr:0.00010000000000000013)
76390: accuracy:0.35 loss: 235.445 (lr:0.00010000000000000013)
76400: accuracy:0.28 loss: 235.458 (lr:0.00010000000000000013)
76410: accuracy:0.32 loss: 218.811 (lr:0.00010000000000000013)
76420: accuracy:0.28 loss: 230.616 (lr:0.00010000000000000013)
76430: accuracy:0.28 loss: 226.335 (lr:0.00010000000000000013)
76440: accuracy:0.3 loss: 222.597 (lr:0.00010000000000000013)
76450: accuracy:0.32 loss: 235.019 (lr:0.00010000000000000013)
76460: accuracy:0.24 loss: 240.699 (lr:0.00010000000000000013)
76470: accuracy:0.3 loss: 228.56 (lr:0.00010000000000000013)
76480: accuracy:0.28 loss: 218.985 (lr:0.00010000000000000013)
76490: accuracy:0.22 loss: 245.109 (lr:0.00010000000000000013)
76500: accuracy:0.35 loss: 218.619 (lr:0.00010000000000000013)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
76500: ********* epoch 8 ********* test accuracy for all:0.243351 test loss: 259.177
76500: ********* epoch 8 ********* test accuracy for mode 0:0.005 test loss: 422.51
76500: ********* epoch 8 ********* test accuracy for mode 1:0.0545 test loss: 397.625
76500: ********* epoch 8 ********* test accuracy for mode 2:0.064 test loss: 260.294
76500: ********* epoch 8 ********* test accuracy for mode 24:0.2125 test loss: 280.002
76500: ********* epoch 8 ********* test accuracy for mode 25:0.2645 test loss: 256.155
76500: ********* epoch 8 ********* test accuracy for mode 26:0.4325 test loss: 174.79
76500: ********* epoch 8 ********* test accuracy for mode 27:0.2535 test loss: 269.865
76500: ********* epoch 8 ********* test accuracy for mode 28:0.264 test loss: 259.432
76500: ********* epoch 8 ********* test accuracy for mode 29:0.2965 test loss: 258.028
76500: ********* epoch 8 ********* test accuracy for mode 30:0.249 test loss: 252.074
76500: ********* epoch 8 ********* test accuracy for mode 31:0.196 test loss: 252.468
76500: ********* epoch 8 ********* test accuracy for mode 32:0.253 test loss: 235.938
76500: ********* epoch 8 ********* test accuracy for mode 33:0.2575 test loss: 242.842
76500: ********* epoch 8 ********* test accuracy for mode 34:0.1505 test loss: 243.709
76500: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 421.511
76500: ********* epoch 8 ********* test accuracy for mode 36:0.0435 test loss: 453.633
76510: accuracy:0.32 loss: 207.8 (lr:0.00010000000000000013)
76520: accuracy:0.33 loss: 209.697 (lr:0.00010000000000000013)
76530: accuracy:0.29 loss: 233.141 (lr:0.00010000000000000013)
76540: accuracy:0.31 loss: 223.686 (lr:0.00010000000000000013)
76550: accuracy:0.38 loss: 214.798 (lr:0.00010000000000000013)
76560: accuracy:0.28 loss: 218.956 (lr:0.00010000000000000013)
76570: accuracy:0.3 loss: 242.31 (lr:0.00010000000000000013)
76580: accuracy:0.29 loss: 227.758 (lr:0.00010000000000000011)
76590: accuracy:0.34 loss: 216.874 (lr:0.00010000000000000011)
76600: accuracy:0.31 loss: 227.287 (lr:0.00010000000000000011)
76610: accuracy:0.36 loss: 225.966 (lr:0.00010000000000000011)
76620: accuracy:0.27 loss: 227.337 (lr:0.00010000000000000011)
76630: accuracy:0.22 loss: 232.516 (lr:0.00010000000000000011)
76640: accuracy:0.35 loss: 244.821 (lr:0.00010000000000000011)
76650: accuracy:0.3 loss: 226.656 (lr:0.00010000000000000011)
76660: accuracy:0.35 loss: 210.953 (lr:0.00010000000000000011)
76670: accuracy:0.31 loss: 223.947 (lr:0.00010000000000000011)
76680: accuracy:0.32 loss: 217.855 (lr:0.00010000000000000011)
76690: accuracy:0.26 loss: 226.2 (lr:0.00010000000000000011)
76700: accuracy:0.34 loss: 222.285 (lr:0.00010000000000000011)
76710: accuracy:0.33 loss: 216.834 (lr:0.00010000000000000011)
76720: accuracy:0.33 loss: 231.143 (lr:0.00010000000000000011)
76730: accuracy:0.3 loss: 246.8 (lr:0.00010000000000000011)
76740: accuracy:0.31 loss: 235.102 (lr:0.00010000000000000011)
76750: accuracy:0.32 loss: 218.352 (lr:0.00010000000000000011)
76760: accuracy:0.28 loss: 217.845 (lr:0.00010000000000000011)
76770: accuracy:0.32 loss: 220.507 (lr:0.00010000000000000011)
76780: accuracy:0.26 loss: 225.199 (lr:0.00010000000000000011)
76790: accuracy:0.28 loss: 242.344 (lr:0.00010000000000000011)
76800: accuracy:0.35 loss: 218.112 (lr:0.00010000000000000011)
76810: accuracy:0.38 loss: 205.734 (lr:0.00010000000000000011)
76820: accuracy:0.25 loss: 228.861 (lr:0.00010000000000000011)
76830: accuracy:0.26 loss: 222.481 (lr:0.0001000000000000001)
76840: accuracy:0.3 loss: 228.62 (lr:0.0001000000000000001)
76850: accuracy:0.31 loss: 233.439 (lr:0.0001000000000000001)
76860: accuracy:0.26 loss: 232.764 (lr:0.0001000000000000001)
76870: accuracy:0.25 loss: 231.066 (lr:0.0001000000000000001)
76880: accuracy:0.34 loss: 192.992 (lr:0.0001000000000000001)
76890: accuracy:0.38 loss: 217.287 (lr:0.0001000000000000001)
76900: accuracy:0.32 loss: 226.292 (lr:0.0001000000000000001)
76910: accuracy:0.24 loss: 241.892 (lr:0.0001000000000000001)
76920: accuracy:0.24 loss: 235.682 (lr:0.0001000000000000001)
76930: accuracy:0.25 loss: 250.512 (lr:0.0001000000000000001)
76940: accuracy:0.28 loss: 237.42 (lr:0.0001000000000000001)
76950: accuracy:0.29 loss: 233.815 (lr:0.0001000000000000001)
76960: accuracy:0.26 loss: 235.117 (lr:0.0001000000000000001)
76970: accuracy:0.38 loss: 204.092 (lr:0.0001000000000000001)
76980: accuracy:0.35 loss: 213.944 (lr:0.0001000000000000001)
76990: accuracy:0.31 loss: 218.886 (lr:0.0001000000000000001)
77000: accuracy:0.33 loss: 217.648 (lr:0.0001000000000000001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
77000: ********* epoch 8 ********* test accuracy for all:0.245797 test loss: 255.551
77000: ********* epoch 8 ********* test accuracy for mode 0:0.006 test loss: 421.09
77000: ********* epoch 8 ********* test accuracy for mode 1:0.0615 test loss: 395.969
77000: ********* epoch 8 ********* test accuracy for mode 2:0.052 test loss: 278.741
77000: ********* epoch 8 ********* test accuracy for mode 24:0.269 test loss: 254.717
77000: ********* epoch 8 ********* test accuracy for mode 25:0.2665 test loss: 234.695
77000: ********* epoch 8 ********* test accuracy for mode 26:0.4585 test loss: 165.525
77000: ********* epoch 8 ********* test accuracy for mode 27:0.2215 test loss: 262.534
77000: ********* epoch 8 ********* test accuracy for mode 28:0.2815 test loss: 251.311
77000: ********* epoch 8 ********* test accuracy for mode 29:0.316 test loss: 255.727
77000: ********* epoch 8 ********* test accuracy for mode 30:0.231 test loss: 256.901
77000: ********* epoch 8 ********* test accuracy for mode 31:0.2085 test loss: 261.669
77000: ********* epoch 8 ********* test accuracy for mode 32:0.1915 test loss: 256.09
77000: ********* epoch 8 ********* test accuracy for mode 33:0.2405 test loss: 261.582
77000: ********* epoch 8 ********* test accuracy for mode 34:0.094 test loss: 264.706
77000: ********* epoch 8 ********* test accuracy for mode 35:0.0005 test loss: 415.273
77000: ********* epoch 8 ********* test accuracy for mode 36:0.0605 test loss: 434.588
77010: accuracy:0.32 loss: 214.628 (lr:0.0001000000000000001)
77020: accuracy:0.26 loss: 239.256 (lr:0.0001000000000000001)
77030: accuracy:0.26 loss: 227.514 (lr:0.0001000000000000001)
77040: accuracy:0.28 loss: 223.366 (lr:0.0001000000000000001)
77050: accuracy:0.26 loss: 226.392 (lr:0.0001000000000000001)
77060: accuracy:0.3 loss: 219.992 (lr:0.0001000000000000001)
77070: accuracy:0.24 loss: 234.339 (lr:0.0001000000000000001)
77080: accuracy:0.3 loss: 234.836 (lr:0.0001000000000000001)
77090: accuracy:0.27 loss: 233.081 (lr:0.0001000000000000001)
77100: accuracy:0.31 loss: 218.208 (lr:0.0001000000000000001)
77110: accuracy:0.27 loss: 219.89 (lr:0.0001000000000000001)
77120: accuracy:0.38 loss: 223.56 (lr:0.00010000000000000009)
77130: accuracy:0.33 loss: 232.862 (lr:0.00010000000000000009)
77140: accuracy:0.33 loss: 207.816 (lr:0.00010000000000000009)
77150: accuracy:0.32 loss: 214.5 (lr:0.00010000000000000009)
77160: accuracy:0.41 loss: 212.012 (lr:0.00010000000000000009)
77170: accuracy:0.38 loss: 200.135 (lr:0.00010000000000000009)
77180: accuracy:0.31 loss: 220.039 (lr:0.00010000000000000009)
77190: accuracy:0.31 loss: 218.56 (lr:0.00010000000000000009)
77200: accuracy:0.23 loss: 224.557 (lr:0.00010000000000000009)
77210: accuracy:0.27 loss: 218.371 (lr:0.00010000000000000009)
77220: accuracy:0.4 loss: 227.772 (lr:0.00010000000000000009)
77230: accuracy:0.28 loss: 224.182 (lr:0.00010000000000000009)
77240: accuracy:0.35 loss: 223.617 (lr:0.00010000000000000009)
77250: accuracy:0.29 loss: 239.39 (lr:0.00010000000000000009)
77260: accuracy:0.22 loss: 236.275 (lr:0.00010000000000000009)
77270: accuracy:0.31 loss: 252.317 (lr:0.00010000000000000009)
77280: accuracy:0.33 loss: 208.734 (lr:0.00010000000000000009)
77290: accuracy:0.34 loss: 217.76 (lr:0.00010000000000000009)
77300: accuracy:0.35 loss: 211.559 (lr:0.00010000000000000009)
77310: accuracy:0.24 loss: 224.258 (lr:0.00010000000000000009)
77320: accuracy:0.37 loss: 234.891 (lr:0.00010000000000000009)
77330: accuracy:0.31 loss: 234.776 (lr:0.00010000000000000009)
77340: accuracy:0.34 loss: 209.601 (lr:0.00010000000000000009)
77350: accuracy:0.35 loss: 214.626 (lr:0.00010000000000000009)
77360: accuracy:0.33 loss: 202.243 (lr:0.00010000000000000009)
77370: accuracy:0.27 loss: 222.072 (lr:0.00010000000000000009)
77380: accuracy:0.34 loss: 203.595 (lr:0.00010000000000000009)
77390: accuracy:0.36 loss: 212.031 (lr:0.00010000000000000009)
77400: accuracy:0.34 loss: 207.06 (lr:0.00010000000000000009)
77410: accuracy:0.38 loss: 209.512 (lr:0.00010000000000000009)
77420: accuracy:0.34 loss: 227.185 (lr:0.00010000000000000009)
77430: accuracy:0.27 loss: 215.115 (lr:0.00010000000000000009)
77440: accuracy:0.26 loss: 215.302 (lr:0.00010000000000000009)
77450: accuracy:0.3 loss: 212.405 (lr:0.00010000000000000007)
77460: accuracy:0.33 loss: 225.794 (lr:0.00010000000000000007)
77470: accuracy:0.31 loss: 223.133 (lr:0.00010000000000000007)
77480: accuracy:0.35 loss: 214.655 (lr:0.00010000000000000007)
77490: accuracy:0.25 loss: 257.682 (lr:0.00010000000000000007)
77500: accuracy:0.3 loss: 219.12 (lr:0.00010000000000000007)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
77500: ********* epoch 8 ********* test accuracy for all:0.244108 test loss: 255.493
77500: ********* epoch 8 ********* test accuracy for mode 0:0.0055 test loss: 417.491
77500: ********* epoch 8 ********* test accuracy for mode 1:0.0665 test loss: 396.056
77500: ********* epoch 8 ********* test accuracy for mode 2:0.0385 test loss: 278.629
77500: ********* epoch 8 ********* test accuracy for mode 24:0.244 test loss: 259.854
77500: ********* epoch 8 ********* test accuracy for mode 25:0.312 test loss: 238.717
77500: ********* epoch 8 ********* test accuracy for mode 26:0.415 test loss: 168.746
77500: ********* epoch 8 ********* test accuracy for mode 27:0.2115 test loss: 275.163
77500: ********* epoch 8 ********* test accuracy for mode 28:0.28 test loss: 255.493
77500: ********* epoch 8 ********* test accuracy for mode 29:0.2765 test loss: 259.785
77500: ********* epoch 8 ********* test accuracy for mode 30:0.228 test loss: 255.496
77500: ********* epoch 8 ********* test accuracy for mode 31:0.219 test loss: 256.539
77500: ********* epoch 8 ********* test accuracy for mode 32:0.188 test loss: 254.179
77500: ********* epoch 8 ********* test accuracy for mode 33:0.247 test loss: 258.641
77500: ********* epoch 8 ********* test accuracy for mode 34:0.145 test loss: 260.465
77500: ********* epoch 8 ********* test accuracy for mode 35:0.0 test loss: 403.025
77500: ********* epoch 8 ********* test accuracy for mode 36:0.0445 test loss: 417.273
77510: accuracy:0.4 loss: 203.119 (lr:0.00010000000000000007)
77520: accuracy:0.33 loss: 228.863 (lr:0.00010000000000000007)
77530: accuracy:0.36 loss: 197.103 (lr:0.00010000000000000007)
77540: accuracy:0.35 loss: 213.714 (lr:0.00010000000000000007)
77550: accuracy:0.27 loss: 240.258 (lr:0.00010000000000000007)
77560: accuracy:0.25 loss: 232.365 (lr:0.00010000000000000007)
77570: accuracy:0.33 loss: 208.959 (lr:0.00010000000000000007)
77580: accuracy:0.25 loss: 230.035 (lr:0.00010000000000000007)
77590: accuracy:0.29 loss: 216.326 (lr:0.00010000000000000007)
77600: accuracy:0.35 loss: 215.163 (lr:0.00010000000000000007)
77610: accuracy:0.33 loss: 218.016 (lr:0.00010000000000000007)
77620: accuracy:0.31 loss: 245.345 (lr:0.00010000000000000007)
77630: accuracy:0.31 loss: 211.513 (lr:0.00010000000000000007)
77640: accuracy:0.41 loss: 211.572 (lr:0.00010000000000000007)
77650: accuracy:0.38 loss: 202.986 (lr:0.00010000000000000007)
77660: accuracy:0.3 loss: 229.964 (lr:0.00010000000000000007)
77670: accuracy:0.3 loss: 195.764 (lr:0.00010000000000000007)
77680: accuracy:0.32 loss: 217.85 (lr:0.00010000000000000007)
77690: accuracy:0.33 loss: 235.215 (lr:0.00010000000000000007)
77700: accuracy:0.3 loss: 231.882 (lr:0.00010000000000000007)
77710: accuracy:0.27 loss: 219.987 (lr:0.00010000000000000007)
77720: accuracy:0.3 loss: 223.602 (lr:0.00010000000000000007)
77730: accuracy:0.31 loss: 220.04 (lr:0.00010000000000000007)
77740: accuracy:0.34 loss: 202.35 (lr:0.00010000000000000007)
77750: accuracy:0.37 loss: 212.165 (lr:0.00010000000000000007)
77760: accuracy:0.28 loss: 247.776 (lr:0.00010000000000000007)
77770: accuracy:0.28 loss: 229.695 (lr:0.00010000000000000007)
77780: accuracy:0.29 loss: 216.469 (lr:0.00010000000000000007)
77790: accuracy:0.26 loss: 228.41 (lr:0.00010000000000000007)
77800: accuracy:0.29 loss: 222.255 (lr:0.00010000000000000007)
77810: accuracy:0.24 loss: 238.019 (lr:0.00010000000000000007)
77820: accuracy:0.35 loss: 214.755 (lr:0.00010000000000000007)
77830: accuracy:0.33 loss: 204.226 (lr:0.00010000000000000007)
77840: accuracy:0.32 loss: 226.937 (lr:0.00010000000000000007)
77850: accuracy:0.34 loss: 238.314 (lr:0.00010000000000000007)
77860: accuracy:0.31 loss: 235.956 (lr:0.00010000000000000006)
77870: accuracy:0.36 loss: 215.108 (lr:0.00010000000000000006)
77880: accuracy:0.25 loss: 221.815 (lr:0.00010000000000000006)
77890: accuracy:0.28 loss: 243.248 (lr:0.00010000000000000006)
77900: accuracy:0.35 loss: 221.886 (lr:0.00010000000000000006)
77910: accuracy:0.32 loss: 222.587 (lr:0.00010000000000000006)
77920: accuracy:0.31 loss: 217.598 (lr:0.00010000000000000006)
77930: accuracy:0.23 loss: 249.508 (lr:0.00010000000000000006)
77940: accuracy:0.33 loss: 227.341 (lr:0.00010000000000000006)
77950: accuracy:0.24 loss: 222.314 (lr:0.00010000000000000006)
77960: accuracy:0.31 loss: 242.159 (lr:0.00010000000000000006)
77970: accuracy:0.33 loss: 215.815 (lr:0.00010000000000000006)
77980: accuracy:0.34 loss: 194.326 (lr:0.00010000000000000006)
77990: accuracy:0.34 loss: 205.295 (lr:0.00010000000000000006)
78000: accuracy:0.17 loss: 228.511 (lr:0.00010000000000000006)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
78000: ********* epoch 9 ********* test accuracy for all:0.242757 test loss: 256.453
78000: ********* epoch 9 ********* test accuracy for mode 0:0.005 test loss: 425.859
78000: ********* epoch 9 ********* test accuracy for mode 1:0.0555 test loss: 400.909
78000: ********* epoch 9 ********* test accuracy for mode 2:0.024 test loss: 279.925
78000: ********* epoch 9 ********* test accuracy for mode 24:0.271 test loss: 259.564
78000: ********* epoch 9 ********* test accuracy for mode 25:0.265 test loss: 248.982
78000: ********* epoch 9 ********* test accuracy for mode 26:0.411 test loss: 175.458
78000: ********* epoch 9 ********* test accuracy for mode 27:0.212 test loss: 273.008
78000: ********* epoch 9 ********* test accuracy for mode 28:0.297 test loss: 254.499
78000: ********* epoch 9 ********* test accuracy for mode 29:0.277 test loss: 260.402
78000: ********* epoch 9 ********* test accuracy for mode 30:0.262 test loss: 254.597
78000: ********* epoch 9 ********* test accuracy for mode 31:0.1835 test loss: 259.529
78000: ********* epoch 9 ********* test accuracy for mode 32:0.212 test loss: 251.685
78000: ********* epoch 9 ********* test accuracy for mode 33:0.2275 test loss: 258.67
78000: ********* epoch 9 ********* test accuracy for mode 34:0.115 test loss: 259.5
78000: ********* epoch 9 ********* test accuracy for mode 35:0.0 test loss: 411.871
78000: ********* epoch 9 ********* test accuracy for mode 36:0.067 test loss: 427.463
78010: accuracy:0.31 loss: 226.256 (lr:0.00010000000000000006)
78020: accuracy:0.27 loss: 226.993 (lr:0.00010000000000000006)
78030: accuracy:0.26 loss: 222.988 (lr:0.00010000000000000006)
78040: accuracy:0.26 loss: 220.166 (lr:0.00010000000000000006)
78050: accuracy:0.3 loss: 216.378 (lr:0.00010000000000000006)
78060: accuracy:0.3 loss: 217.861 (lr:0.00010000000000000006)
78070: accuracy:0.28 loss: 206.826 (lr:0.00010000000000000006)
78080: accuracy:0.29 loss: 218.909 (lr:0.00010000000000000006)
78090: accuracy:0.29 loss: 227.866 (lr:0.00010000000000000006)
78100: accuracy:0.35 loss: 196.638 (lr:0.00010000000000000006)
78110: accuracy:0.41 loss: 221.46 (lr:0.00010000000000000006)
78120: accuracy:0.3 loss: 208.479 (lr:0.00010000000000000006)
78130: accuracy:0.28 loss: 207.813 (lr:0.00010000000000000006)
78140: accuracy:0.3 loss: 248.576 (lr:0.00010000000000000006)
78150: accuracy:0.31 loss: 232.21 (lr:0.00010000000000000006)
78160: accuracy:0.27 loss: 233.815 (lr:0.00010000000000000006)
78170: accuracy:0.27 loss: 227.046 (lr:0.00010000000000000006)
78180: accuracy:0.29 loss: 226.008 (lr:0.00010000000000000006)
78190: accuracy:0.26 loss: 227.361 (lr:0.00010000000000000006)
78200: accuracy:0.31 loss: 224.916 (lr:0.00010000000000000006)
78210: accuracy:0.32 loss: 222.305 (lr:0.00010000000000000006)
78220: accuracy:0.19 loss: 250.036 (lr:0.00010000000000000006)
78230: accuracy:0.2 loss: 222.593 (lr:0.00010000000000000006)
78240: accuracy:0.31 loss: 222.974 (lr:0.00010000000000000006)
78250: accuracy:0.35 loss: 217.236 (lr:0.00010000000000000006)
78260: accuracy:0.28 loss: 243.305 (lr:0.00010000000000000006)
78270: accuracy:0.38 loss: 204.126 (lr:0.00010000000000000006)
78280: accuracy:0.36 loss: 209.954 (lr:0.00010000000000000006)
78290: accuracy:0.29 loss: 217.111 (lr:0.00010000000000000006)
78300: accuracy:0.32 loss: 232.274 (lr:0.00010000000000000006)
78310: accuracy:0.41 loss: 208.888 (lr:0.00010000000000000006)
78320: accuracy:0.4 loss: 212.944 (lr:0.00010000000000000006)
78330: accuracy:0.26 loss: 250.573 (lr:0.00010000000000000006)
78340: accuracy:0.22 loss: 231.766 (lr:0.00010000000000000006)
78350: accuracy:0.23 loss: 220.215 (lr:0.00010000000000000006)
78360: accuracy:0.22 loss: 228.387 (lr:0.00010000000000000005)
78370: accuracy:0.32 loss: 229.745 (lr:0.00010000000000000005)
78380: accuracy:0.35 loss: 217.538 (lr:0.00010000000000000005)
78390: accuracy:0.37 loss: 216.476 (lr:0.00010000000000000005)
78400: accuracy:0.29 loss: 236.138 (lr:0.00010000000000000005)
78410: accuracy:0.27 loss: 232.685 (lr:0.00010000000000000005)
78420: accuracy:0.32 loss: 208.856 (lr:0.00010000000000000005)
78430: accuracy:0.24 loss: 242.837 (lr:0.00010000000000000005)
78440: accuracy:0.31 loss: 219.374 (lr:0.00010000000000000005)
78450: accuracy:0.33 loss: 203.68 (lr:0.00010000000000000005)
78460: accuracy:0.36 loss: 219.172 (lr:0.00010000000000000005)
78470: accuracy:0.25 loss: 236.919 (lr:0.00010000000000000005)
78480: accuracy:0.25 loss: 231.75 (lr:0.00010000000000000005)
78490: accuracy:0.25 loss: 214.734 (lr:0.00010000000000000005)
78500: accuracy:0.28 loss: 220.043 (lr:0.00010000000000000005)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
78500: ********* epoch 9 ********* test accuracy for all:0.24527 test loss: 256.342
78500: ********* epoch 9 ********* test accuracy for mode 0:0.006 test loss: 422.768
78500: ********* epoch 9 ********* test accuracy for mode 1:0.0555 test loss: 399.568
78500: ********* epoch 9 ********* test accuracy for mode 2:0.022 test loss: 279.7
78500: ********* epoch 9 ********* test accuracy for mode 24:0.219 test loss: 265.592
78500: ********* epoch 9 ********* test accuracy for mode 25:0.3425 test loss: 236.654
78500: ********* epoch 9 ********* test accuracy for mode 26:0.3965 test loss: 167.495
78500: ********* epoch 9 ********* test accuracy for mode 27:0.273 test loss: 257.419
78500: ********* epoch 9 ********* test accuracy for mode 28:0.309 test loss: 250.19
78500: ********* epoch 9 ********* test accuracy for mode 29:0.319 test loss: 258.576
78500: ********* epoch 9 ********* test accuracy for mode 30:0.182 test loss: 262.641
78500: ********* epoch 9 ********* test accuracy for mode 31:0.1885 test loss: 264.839
78500: ********* epoch 9 ********* test accuracy for mode 32:0.248 test loss: 251.096
78500: ********* epoch 9 ********* test accuracy for mode 33:0.2 test loss: 261.238
78500: ********* epoch 9 ********* test accuracy for mode 34:0.18 test loss: 258.158
78500: ********* epoch 9 ********* test accuracy for mode 35:0.0 test loss: 406.705
78500: ********* epoch 9 ********* test accuracy for mode 36:0.0615 test loss: 430.133
78510: accuracy:0.3 loss: 200.154 (lr:0.00010000000000000005)
78520: accuracy:0.31 loss: 223.672 (lr:0.00010000000000000005)
78530: accuracy:0.32 loss: 207.369 (lr:0.00010000000000000005)
78540: accuracy:0.24 loss: 227.424 (lr:0.00010000000000000005)
78550: accuracy:0.23 loss: 211.919 (lr:0.00010000000000000005)
78560: accuracy:0.28 loss: 224.755 (lr:0.00010000000000000005)
78570: accuracy:0.31 loss: 222.281 (lr:0.00010000000000000005)
78580: accuracy:0.3 loss: 242.468 (lr:0.00010000000000000005)
78590: accuracy:0.3 loss: 222.183 (lr:0.00010000000000000005)
78600: accuracy:0.26 loss: 243.019 (lr:0.00010000000000000005)
78610: accuracy:0.28 loss: 236.913 (lr:0.00010000000000000005)
78620: accuracy:0.34 loss: 214.656 (lr:0.00010000000000000005)
78630: accuracy:0.32 loss: 226.784 (lr:0.00010000000000000005)
78640: accuracy:0.24 loss: 233.317 (lr:0.00010000000000000005)
78650: accuracy:0.28 loss: 223.073 (lr:0.00010000000000000005)
78660: accuracy:0.36 loss: 209.199 (lr:0.00010000000000000005)
78670: accuracy:0.35 loss: 216.806 (lr:0.00010000000000000005)
78680: accuracy:0.33 loss: 224.011 (lr:0.00010000000000000005)
78690: accuracy:0.29 loss: 232.593 (lr:0.00010000000000000005)
78700: accuracy:0.38 loss: 207.089 (lr:0.00010000000000000005)
78710: accuracy:0.29 loss: 211.581 (lr:0.00010000000000000005)
78720: accuracy:0.3 loss: 249.041 (lr:0.00010000000000000005)
78730: accuracy:0.3 loss: 219.428 (lr:0.00010000000000000005)
78740: accuracy:0.36 loss: 234.363 (lr:0.00010000000000000005)
78750: accuracy:0.35 loss: 217.776 (lr:0.00010000000000000005)
78760: accuracy:0.24 loss: 236.338 (lr:0.00010000000000000005)
78770: accuracy:0.33 loss: 226.369 (lr:0.00010000000000000005)
78780: accuracy:0.29 loss: 210.651 (lr:0.00010000000000000005)
78790: accuracy:0.32 loss: 236.5 (lr:0.00010000000000000005)
78800: accuracy:0.3 loss: 230.298 (lr:0.00010000000000000005)
78810: accuracy:0.37 loss: 231.343 (lr:0.00010000000000000005)
78820: accuracy:0.34 loss: 215.764 (lr:0.00010000000000000005)
78830: accuracy:0.29 loss: 217.556 (lr:0.00010000000000000005)
78840: accuracy:0.29 loss: 231.122 (lr:0.00010000000000000005)
78850: accuracy:0.28 loss: 227.356 (lr:0.00010000000000000005)
78860: accuracy:0.31 loss: 227.186 (lr:0.00010000000000000005)
78870: accuracy:0.34 loss: 203.876 (lr:0.00010000000000000005)
78880: accuracy:0.32 loss: 241.665 (lr:0.00010000000000000005)
78890: accuracy:0.3 loss: 220.455 (lr:0.00010000000000000005)
78900: accuracy:0.29 loss: 217.032 (lr:0.00010000000000000005)
78910: accuracy:0.27 loss: 231.778 (lr:0.00010000000000000005)
78920: accuracy:0.3 loss: 222.47 (lr:0.00010000000000000005)
78930: accuracy:0.3 loss: 231.961 (lr:0.00010000000000000005)
78940: accuracy:0.27 loss: 236.392 (lr:0.00010000000000000005)
78950: accuracy:0.32 loss: 219.452 (lr:0.00010000000000000005)
78960: accuracy:0.23 loss: 231.439 (lr:0.00010000000000000005)
78970: accuracy:0.18 loss: 237.843 (lr:0.00010000000000000005)
78980: accuracy:0.38 loss: 213.895 (lr:0.00010000000000000005)
78990: accuracy:0.36 loss: 213.394 (lr:0.00010000000000000005)
79000: accuracy:0.3 loss: 220.372 (lr:0.00010000000000000005)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
79000: ********* epoch 9 ********* test accuracy for all:0.244743 test loss: 257.097
79000: ********* epoch 9 ********* test accuracy for mode 0:0.0035 test loss: 433.785
79000: ********* epoch 9 ********* test accuracy for mode 1:0.048 test loss: 401.931
79000: ********* epoch 9 ********* test accuracy for mode 2:0.022 test loss: 276.707
79000: ********* epoch 9 ********* test accuracy for mode 24:0.2215 test loss: 270.071
79000: ********* epoch 9 ********* test accuracy for mode 25:0.306 test loss: 243.895
79000: ********* epoch 9 ********* test accuracy for mode 26:0.405 test loss: 172.054
79000: ********* epoch 9 ********* test accuracy for mode 27:0.258 test loss: 267.032
79000: ********* epoch 9 ********* test accuracy for mode 28:0.2925 test loss: 252.805
79000: ********* epoch 9 ********* test accuracy for mode 29:0.254 test loss: 262.88
79000: ********* epoch 9 ********* test accuracy for mode 30:0.252 test loss: 252.046
79000: ********* epoch 9 ********* test accuracy for mode 31:0.2305 test loss: 255.03
79000: ********* epoch 9 ********* test accuracy for mode 32:0.282 test loss: 243.431
79000: ********* epoch 9 ********* test accuracy for mode 33:0.123 test loss: 259.068
79000: ********* epoch 9 ********* test accuracy for mode 34:0.2725 test loss: 248.525
79000: ********* epoch 9 ********* test accuracy for mode 35:0.0 test loss: 420.382
79000: ********* epoch 9 ********* test accuracy for mode 36:0.043 test loss: 439.584
79010: accuracy:0.4 loss: 210.617 (lr:0.00010000000000000005)
79020: accuracy:0.36 loss: 231.221 (lr:0.00010000000000000005)
79030: accuracy:0.27 loss: 224.725 (lr:0.00010000000000000003)
79040: accuracy:0.37 loss: 199.245 (lr:0.00010000000000000003)
79050: accuracy:0.34 loss: 229.278 (lr:0.00010000000000000003)
79060: accuracy:0.33 loss: 229.931 (lr:0.00010000000000000003)
79070: accuracy:0.34 loss: 223.309 (lr:0.00010000000000000003)
79080: accuracy:0.28 loss: 222.298 (lr:0.00010000000000000003)
79090: accuracy:0.26 loss: 233.523 (lr:0.00010000000000000003)
79100: accuracy:0.33 loss: 213.296 (lr:0.00010000000000000003)
79110: accuracy:0.36 loss: 222.91 (lr:0.00010000000000000003)
79120: accuracy:0.39 loss: 212.276 (lr:0.00010000000000000003)
79130: accuracy:0.26 loss: 217.541 (lr:0.00010000000000000003)
79140: accuracy:0.32 loss: 228.915 (lr:0.00010000000000000003)
79150: accuracy:0.34 loss: 213.943 (lr:0.00010000000000000003)
79160: accuracy:0.25 loss: 219.413 (lr:0.00010000000000000003)
79170: accuracy:0.33 loss: 215.237 (lr:0.00010000000000000003)
79180: accuracy:0.31 loss: 227.528 (lr:0.00010000000000000003)
79190: accuracy:0.28 loss: 210.039 (lr:0.00010000000000000003)
79200: accuracy:0.29 loss: 232.58 (lr:0.00010000000000000003)
79210: accuracy:0.39 loss: 212.979 (lr:0.00010000000000000003)
79220: accuracy:0.38 loss: 201.883 (lr:0.00010000000000000003)
79230: accuracy:0.28 loss: 227.24 (lr:0.00010000000000000003)
79240: accuracy:0.3 loss: 214.756 (lr:0.00010000000000000003)
79250: accuracy:0.24 loss: 228.323 (lr:0.00010000000000000003)
79260: accuracy:0.31 loss: 211.459 (lr:0.00010000000000000003)
79270: accuracy:0.32 loss: 215.424 (lr:0.00010000000000000003)
79280: accuracy:0.35 loss: 216.856 (lr:0.00010000000000000003)
79290: accuracy:0.25 loss: 229.212 (lr:0.00010000000000000003)
79300: accuracy:0.32 loss: 225.554 (lr:0.00010000000000000003)
79310: accuracy:0.33 loss: 221.411 (lr:0.00010000000000000003)
79320: accuracy:0.33 loss: 213.941 (lr:0.00010000000000000003)
79330: accuracy:0.3 loss: 239.509 (lr:0.00010000000000000003)
79340: accuracy:0.28 loss: 250.34 (lr:0.00010000000000000003)
79350: accuracy:0.43 loss: 196.838 (lr:0.00010000000000000003)
79360: accuracy:0.28 loss: 226.177 (lr:0.00010000000000000003)
79370: accuracy:0.3 loss: 224.042 (lr:0.00010000000000000003)
79380: accuracy:0.44 loss: 208.691 (lr:0.00010000000000000003)
79390: accuracy:0.3 loss: 208.491 (lr:0.00010000000000000003)
79400: accuracy:0.3 loss: 233.401 (lr:0.00010000000000000003)
79410: accuracy:0.3 loss: 211.126 (lr:0.00010000000000000003)
79420: accuracy:0.38 loss: 206.75 (lr:0.00010000000000000003)
79430: accuracy:0.26 loss: 236.056 (lr:0.00010000000000000003)
79440: accuracy:0.34 loss: 211.669 (lr:0.00010000000000000003)
79450: accuracy:0.33 loss: 215.777 (lr:0.00010000000000000003)
79460: accuracy:0.3 loss: 218.026 (lr:0.00010000000000000003)
79470: accuracy:0.3 loss: 202.652 (lr:0.00010000000000000003)
79480: accuracy:0.38 loss: 205.031 (lr:0.00010000000000000003)
79490: accuracy:0.3 loss: 228.386 (lr:0.00010000000000000003)
79500: accuracy:0.33 loss: 232.653 (lr:0.00010000000000000003)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
79500: ********* epoch 9 ********* test accuracy for all:0.24627 test loss: 257.119
79500: ********* epoch 9 ********* test accuracy for mode 0:0.0065 test loss: 438.579
79500: ********* epoch 9 ********* test accuracy for mode 1:0.049 test loss: 409.411
79500: ********* epoch 9 ********* test accuracy for mode 2:0.0115 test loss: 273.281
79500: ********* epoch 9 ********* test accuracy for mode 24:0.205 test loss: 273.523
79500: ********* epoch 9 ********* test accuracy for mode 25:0.301 test loss: 242.762
79500: ********* epoch 9 ********* test accuracy for mode 26:0.3995 test loss: 171.825
79500: ********* epoch 9 ********* test accuracy for mode 27:0.295 test loss: 251.369
79500: ********* epoch 9 ********* test accuracy for mode 28:0.26 test loss: 245.86
79500: ********* epoch 9 ********* test accuracy for mode 29:0.306 test loss: 244.438
79500: ********* epoch 9 ********* test accuracy for mode 30:0.2525 test loss: 241.248
79500: ********* epoch 9 ********* test accuracy for mode 31:0.213 test loss: 244.748
79500: ********* epoch 9 ********* test accuracy for mode 32:0.239 test loss: 235.8
79500: ********* epoch 9 ********* test accuracy for mode 33:0.308 test loss: 241.134
79500: ********* epoch 9 ********* test accuracy for mode 34:0.116 test loss: 249.597
79500: ********* epoch 9 ********* test accuracy for mode 35:0.0005 test loss: 428.71
79500: ********* epoch 9 ********* test accuracy for mode 36:0.093 test loss: 447.068
79510: accuracy:0.21 loss: 245.509 (lr:0.00010000000000000003)
79520: accuracy:0.24 loss: 247.145 (lr:0.00010000000000000003)
79530: accuracy:0.33 loss: 225.499 (lr:0.00010000000000000003)
79540: accuracy:0.29 loss: 246.415 (lr:0.00010000000000000003)
79550: accuracy:0.3 loss: 216.553 (lr:0.00010000000000000003)
79560: accuracy:0.37 loss: 214.935 (lr:0.00010000000000000003)
79570: accuracy:0.38 loss: 224.021 (lr:0.00010000000000000003)
79580: accuracy:0.28 loss: 218.727 (lr:0.00010000000000000003)
79590: accuracy:0.36 loss: 228.669 (lr:0.00010000000000000003)
79600: accuracy:0.32 loss: 222.438 (lr:0.00010000000000000003)
79610: accuracy:0.3 loss: 212.962 (lr:0.00010000000000000003)
79620: accuracy:0.28 loss: 227.974 (lr:0.00010000000000000003)
79630: accuracy:0.27 loss: 222.35 (lr:0.00010000000000000003)
79640: accuracy:0.34 loss: 233.317 (lr:0.00010000000000000003)
79650: accuracy:0.35 loss: 219.262 (lr:0.00010000000000000003)
79660: accuracy:0.26 loss: 233.413 (lr:0.00010000000000000003)
79670: accuracy:0.32 loss: 213.301 (lr:0.00010000000000000003)
79680: accuracy:0.32 loss: 219.559 (lr:0.00010000000000000003)
79690: accuracy:0.22 loss: 253.599 (lr:0.00010000000000000003)
79700: accuracy:0.3 loss: 234.171 (lr:0.00010000000000000003)
79710: accuracy:0.27 loss: 225.279 (lr:0.00010000000000000003)
79720: accuracy:0.3 loss: 216.541 (lr:0.00010000000000000003)
79730: accuracy:0.33 loss: 213.931 (lr:0.00010000000000000003)
79740: accuracy:0.33 loss: 209.649 (lr:0.00010000000000000003)
79750: accuracy:0.34 loss: 216.914 (lr:0.00010000000000000003)
79760: accuracy:0.29 loss: 229.519 (lr:0.00010000000000000003)
79770: accuracy:0.34 loss: 209.678 (lr:0.00010000000000000003)
79780: accuracy:0.37 loss: 212.226 (lr:0.00010000000000000003)
79790: accuracy:0.34 loss: 216.502 (lr:0.00010000000000000003)
79800: accuracy:0.29 loss: 239.682 (lr:0.00010000000000000003)
79810: accuracy:0.35 loss: 226.508 (lr:0.00010000000000000003)
79820: accuracy:0.22 loss: 228.624 (lr:0.00010000000000000003)
79830: accuracy:0.37 loss: 220.903 (lr:0.00010000000000000003)
79840: accuracy:0.25 loss: 238.039 (lr:0.00010000000000000003)
79850: accuracy:0.26 loss: 229.754 (lr:0.00010000000000000003)
79860: accuracy:0.36 loss: 223.349 (lr:0.00010000000000000003)
79870: accuracy:0.28 loss: 231.072 (lr:0.00010000000000000003)
79880: accuracy:0.27 loss: 225.537 (lr:0.00010000000000000003)
79890: accuracy:0.29 loss: 226.699 (lr:0.00010000000000000003)
79900: accuracy:0.44 loss: 212.697 (lr:0.00010000000000000003)
79910: accuracy:0.36 loss: 240.957 (lr:0.00010000000000000003)
79920: accuracy:0.3 loss: 231.924 (lr:0.00010000000000000003)
79930: accuracy:0.39 loss: 213.483 (lr:0.00010000000000000003)
79940: accuracy:0.32 loss: 224.239 (lr:0.00010000000000000003)
79950: accuracy:0.29 loss: 220.941 (lr:0.00010000000000000003)
79960: accuracy:0.31 loss: 213.908 (lr:0.00010000000000000003)
79970: accuracy:0.27 loss: 222.626 (lr:0.00010000000000000003)
79980: accuracy:0.38 loss: 214.755 (lr:0.00010000000000000003)
79990: accuracy:0.34 loss: 212.18 (lr:0.00010000000000000003)
80000: accuracy:0.31 loss: 216.68 (lr:0.00010000000000000003)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
80000: ********* epoch 9 ********* test accuracy for all:0.245068 test loss: 257.303
80000: ********* epoch 9 ********* test accuracy for mode 0:0.008 test loss: 425.119
80000: ********* epoch 9 ********* test accuracy for mode 1:0.0575 test loss: 401.667
80000: ********* epoch 9 ********* test accuracy for mode 2:0.0265 test loss: 276.326
80000: ********* epoch 9 ********* test accuracy for mode 24:0.2225 test loss: 268.26
80000: ********* epoch 9 ********* test accuracy for mode 25:0.2825 test loss: 245.11
80000: ********* epoch 9 ********* test accuracy for mode 26:0.45 test loss: 161.561
80000: ********* epoch 9 ********* test accuracy for mode 27:0.2875 test loss: 252.947
80000: ********* epoch 9 ********* test accuracy for mode 28:0.2805 test loss: 252.009
80000: ********* epoch 9 ********* test accuracy for mode 29:0.2695 test loss: 257.184
80000: ********* epoch 9 ********* test accuracy for mode 30:0.257 test loss: 249.811
80000: ********* epoch 9 ********* test accuracy for mode 31:0.224 test loss: 255.98
80000: ********* epoch 9 ********* test accuracy for mode 32:0.203 test loss: 248.103
80000: ********* epoch 9 ********* test accuracy for mode 33:0.2045 test loss: 257.876
80000: ********* epoch 9 ********* test accuracy for mode 34:0.1495 test loss: 255.902
80000: ********* epoch 9 ********* test accuracy for mode 35:0.0 test loss: 426.106
80000: ********* epoch 9 ********* test accuracy for mode 36:0.0535 test loss: 454.681
80010: accuracy:0.28 loss: 232.566 (lr:0.00010000000000000003)
80020: accuracy:0.28 loss: 228.349 (lr:0.00010000000000000003)
80030: accuracy:0.36 loss: 208.684 (lr:0.00010000000000000003)
80040: accuracy:0.28 loss: 236.55 (lr:0.00010000000000000003)
80050: accuracy:0.31 loss: 227.414 (lr:0.00010000000000000002)
80060: accuracy:0.38 loss: 226.962 (lr:0.00010000000000000002)
80070: accuracy:0.27 loss: 223.762 (lr:0.00010000000000000002)
80080: accuracy:0.24 loss: 203.307 (lr:0.00010000000000000002)
80090: accuracy:0.33 loss: 208.724 (lr:0.00010000000000000002)
80100: accuracy:0.27 loss: 215.417 (lr:0.00010000000000000002)
80110: accuracy:0.31 loss: 206.152 (lr:0.00010000000000000002)
80120: accuracy:0.35 loss: 208.748 (lr:0.00010000000000000002)
80130: accuracy:0.3 loss: 210.867 (lr:0.00010000000000000002)
80140: accuracy:0.24 loss: 250.148 (lr:0.00010000000000000002)
80150: accuracy:0.3 loss: 223.716 (lr:0.00010000000000000002)
80160: accuracy:0.25 loss: 222.169 (lr:0.00010000000000000002)
80170: accuracy:0.29 loss: 208.569 (lr:0.00010000000000000002)
80180: accuracy:0.29 loss: 232.813 (lr:0.00010000000000000002)
80190: accuracy:0.25 loss: 248.125 (lr:0.00010000000000000002)
80200: accuracy:0.24 loss: 211.887 (lr:0.00010000000000000002)
80210: accuracy:0.32 loss: 216.753 (lr:0.00010000000000000002)
80220: accuracy:0.34 loss: 223.373 (lr:0.00010000000000000002)
80230: accuracy:0.33 loss: 245.199 (lr:0.00010000000000000002)
80240: accuracy:0.28 loss: 226.61 (lr:0.00010000000000000002)
80250: accuracy:0.35 loss: 219.095 (lr:0.00010000000000000002)
80260: accuracy:0.31 loss: 218.129 (lr:0.00010000000000000002)
80270: accuracy:0.28 loss: 225.761 (lr:0.00010000000000000002)
80280: accuracy:0.28 loss: 237.197 (lr:0.00010000000000000002)
80290: accuracy:0.33 loss: 210.782 (lr:0.00010000000000000002)
80300: accuracy:0.36 loss: 212.058 (lr:0.00010000000000000002)
80310: accuracy:0.32 loss: 219.697 (lr:0.00010000000000000002)
80320: accuracy:0.36 loss: 208.318 (lr:0.00010000000000000002)
80330: accuracy:0.36 loss: 224.92 (lr:0.00010000000000000002)
80340: accuracy:0.32 loss: 214.82 (lr:0.00010000000000000002)
80350: accuracy:0.33 loss: 221.055 (lr:0.00010000000000000002)
80360: accuracy:0.27 loss: 237.268 (lr:0.00010000000000000002)
80370: accuracy:0.33 loss: 209.635 (lr:0.00010000000000000002)
80380: accuracy:0.29 loss: 229.382 (lr:0.00010000000000000002)
80390: accuracy:0.36 loss: 190.645 (lr:0.00010000000000000002)
80400: accuracy:0.32 loss: 235.216 (lr:0.00010000000000000002)
80410: accuracy:0.33 loss: 216.07 (lr:0.00010000000000000002)
80420: accuracy:0.32 loss: 223.174 (lr:0.00010000000000000002)
80430: accuracy:0.35 loss: 206.482 (lr:0.00010000000000000002)
80440: accuracy:0.3 loss: 213.614 (lr:0.00010000000000000002)
80450: accuracy:0.33 loss: 226.691 (lr:0.00010000000000000002)
80460: accuracy:0.31 loss: 217.291 (lr:0.00010000000000000002)
80470: accuracy:0.2 loss: 238.078 (lr:0.00010000000000000002)
80480: accuracy:0.23 loss: 233.393 (lr:0.00010000000000000002)
80490: accuracy:0.34 loss: 225.097 (lr:0.00010000000000000002)
80500: accuracy:0.36 loss: 215.432 (lr:0.00010000000000000002)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
80500: ********* epoch 9 ********* test accuracy for all:0.242689 test loss: 256.176
80500: ********* epoch 9 ********* test accuracy for mode 0:0.011 test loss: 426.209
80500: ********* epoch 9 ********* test accuracy for mode 1:0.049 test loss: 407.532
80500: ********* epoch 9 ********* test accuracy for mode 2:0.016 test loss: 274.153
80500: ********* epoch 9 ********* test accuracy for mode 24:0.2065 test loss: 274.186
80500: ********* epoch 9 ********* test accuracy for mode 25:0.3345 test loss: 240.192
80500: ********* epoch 9 ********* test accuracy for mode 26:0.3615 test loss: 172.996
80500: ********* epoch 9 ********* test accuracy for mode 27:0.257 test loss: 258.298
80500: ********* epoch 9 ********* test accuracy for mode 28:0.299 test loss: 246.37
80500: ********* epoch 9 ********* test accuracy for mode 29:0.254 test loss: 253.184
80500: ********* epoch 9 ********* test accuracy for mode 30:0.2825 test loss: 246.719
80500: ********* epoch 9 ********* test accuracy for mode 31:0.221 test loss: 252.446
80500: ********* epoch 9 ********* test accuracy for mode 32:0.1865 test loss: 246.875
80500: ********* epoch 9 ********* test accuracy for mode 33:0.273 test loss: 248.504
80500: ********* epoch 9 ********* test accuracy for mode 34:0.156 test loss: 252.627
80500: ********* epoch 9 ********* test accuracy for mode 35:0.001 test loss: 424.575
80500: ********* epoch 9 ********* test accuracy for mode 36:0.05 test loss: 437.815
80510: accuracy:0.33 loss: 218.783 (lr:0.00010000000000000002)
80520: accuracy:0.32 loss: 212.438 (lr:0.00010000000000000002)
80530: accuracy:0.27 loss: 211.223 (lr:0.00010000000000000002)
80540: accuracy:0.31 loss: 227.675 (lr:0.00010000000000000002)
80550: accuracy:0.35 loss: 217.759 (lr:0.00010000000000000002)
80560: accuracy:0.32 loss: 226.829 (lr:0.00010000000000000002)
80570: accuracy:0.29 loss: 224.947 (lr:0.00010000000000000002)
80580: accuracy:0.25 loss: 237.44 (lr:0.00010000000000000002)
80590: accuracy:0.37 loss: 211.764 (lr:0.00010000000000000002)
80600: accuracy:0.24 loss: 240.721 (lr:0.00010000000000000002)
80610: accuracy:0.31 loss: 231.687 (lr:0.00010000000000000002)
80620: accuracy:0.3 loss: 213.127 (lr:0.00010000000000000002)
80630: accuracy:0.36 loss: 208.651 (lr:0.00010000000000000002)
80640: accuracy:0.29 loss: 230.219 (lr:0.00010000000000000002)
80650: accuracy:0.36 loss: 219.131 (lr:0.00010000000000000002)
80660: accuracy:0.32 loss: 215.617 (lr:0.00010000000000000002)
80670: accuracy:0.22 loss: 236.193 (lr:0.00010000000000000002)
80680: accuracy:0.3 loss: 223.67 (lr:0.00010000000000000002)
80690: accuracy:0.32 loss: 220.371 (lr:0.00010000000000000002)
80700: accuracy:0.26 loss: 237.339 (lr:0.00010000000000000002)
80710: accuracy:0.32 loss: 224.641 (lr:0.00010000000000000002)
80720: accuracy:0.31 loss: 212.874 (lr:0.00010000000000000002)
80730: accuracy:0.26 loss: 216.295 (lr:0.00010000000000000002)
80740: accuracy:0.29 loss: 236.12 (lr:0.00010000000000000002)
80750: accuracy:0.28 loss: 227.09 (lr:0.00010000000000000002)
80760: accuracy:0.29 loss: 221.146 (lr:0.00010000000000000002)
80770: accuracy:0.32 loss: 211.921 (lr:0.00010000000000000002)
80780: accuracy:0.33 loss: 236.925 (lr:0.00010000000000000002)
80790: accuracy:0.34 loss: 198.313 (lr:0.00010000000000000002)
80800: accuracy:0.28 loss: 222.335 (lr:0.00010000000000000002)
80810: accuracy:0.37 loss: 225.803 (lr:0.00010000000000000002)
80820: accuracy:0.3 loss: 204.155 (lr:0.00010000000000000002)
80830: accuracy:0.29 loss: 230.213 (lr:0.00010000000000000002)
80840: accuracy:0.32 loss: 237.424 (lr:0.00010000000000000002)
80850: accuracy:0.28 loss: 227.178 (lr:0.00010000000000000002)
80860: accuracy:0.34 loss: 210.278 (lr:0.00010000000000000002)
80870: accuracy:0.29 loss: 219.119 (lr:0.00010000000000000002)
80880: accuracy:0.32 loss: 210.927 (lr:0.00010000000000000002)
80890: accuracy:0.35 loss: 205.069 (lr:0.00010000000000000002)
80900: accuracy:0.3 loss: 220.899 (lr:0.00010000000000000002)
80910: accuracy:0.3 loss: 233.212 (lr:0.00010000000000000002)
80920: accuracy:0.33 loss: 208.894 (lr:0.00010000000000000002)
80930: accuracy:0.39 loss: 209.457 (lr:0.00010000000000000002)
80940: accuracy:0.3 loss: 230.135 (lr:0.00010000000000000002)
80950: accuracy:0.21 loss: 254.07 (lr:0.00010000000000000002)
80960: accuracy:0.29 loss: 222.548 (lr:0.00010000000000000002)
80970: accuracy:0.32 loss: 230.462 (lr:0.00010000000000000002)
80980: accuracy:0.35 loss: 221.391 (lr:0.00010000000000000002)
80990: accuracy:0.35 loss: 215.665 (lr:0.00010000000000000002)
81000: accuracy:0.37 loss: 206.838 (lr:0.00010000000000000002)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
81000: ********* epoch 9 ********* test accuracy for all:0.242554 test loss: 256.581
81000: ********* epoch 9 ********* test accuracy for mode 0:0.0075 test loss: 416.782
81000: ********* epoch 9 ********* test accuracy for mode 1:0.063 test loss: 394.544
81000: ********* epoch 9 ********* test accuracy for mode 2:0.0345 test loss: 272.433
81000: ********* epoch 9 ********* test accuracy for mode 24:0.2265 test loss: 271.99
81000: ********* epoch 9 ********* test accuracy for mode 25:0.2655 test loss: 248.61
81000: ********* epoch 9 ********* test accuracy for mode 26:0.425 test loss: 166.821
81000: ********* epoch 9 ********* test accuracy for mode 27:0.2325 test loss: 266.921
81000: ********* epoch 9 ********* test accuracy for mode 28:0.2605 test loss: 254.455
81000: ********* epoch 9 ********* test accuracy for mode 29:0.305 test loss: 252.946
81000: ********* epoch 9 ********* test accuracy for mode 30:0.257 test loss: 251.361
81000: ********* epoch 9 ********* test accuracy for mode 31:0.214 test loss: 255.091
81000: ********* epoch 9 ********* test accuracy for mode 32:0.204 test loss: 246.316
81000: ********* epoch 9 ********* test accuracy for mode 33:0.2625 test loss: 251.408
81000: ********* epoch 9 ********* test accuracy for mode 34:0.134 test loss: 254.601
81000: ********* epoch 9 ********* test accuracy for mode 35:0.011 test loss: 411.281
81000: ********* epoch 9 ********* test accuracy for mode 36:0.05 test loss: 427.067
81010: accuracy:0.32 loss: 222.493 (lr:0.00010000000000000002)
81020: accuracy:0.42 loss: 186.183 (lr:0.00010000000000000002)
81030: accuracy:0.24 loss: 219.758 (lr:0.00010000000000000002)
81040: accuracy:0.34 loss: 209.984 (lr:0.00010000000000000002)
81050: accuracy:0.32 loss: 220.263 (lr:0.00010000000000000002)
81060: accuracy:0.45 loss: 186.069 (lr:0.00010000000000000002)
81070: accuracy:0.3 loss: 223.405 (lr:0.00010000000000000002)
81080: accuracy:0.32 loss: 215.776 (lr:0.00010000000000000002)
81090: accuracy:0.3 loss: 189.267 (lr:0.00010000000000000002)
81100: accuracy:0.38 loss: 217.925 (lr:0.00010000000000000002)
81110: accuracy:0.38 loss: 221.537 (lr:0.00010000000000000002)
81120: accuracy:0.27 loss: 245.311 (lr:0.00010000000000000002)
81130: accuracy:0.27 loss: 215.452 (lr:0.00010000000000000002)
81140: accuracy:0.24 loss: 243.667 (lr:0.00010000000000000002)
81150: accuracy:0.35 loss: 207.639 (lr:0.00010000000000000002)
81160: accuracy:0.39 loss: 211.105 (lr:0.00010000000000000002)
81170: accuracy:0.29 loss: 237.316 (lr:0.00010000000000000002)
81180: accuracy:0.27 loss: 231.398 (lr:0.00010000000000000002)
81190: accuracy:0.32 loss: 224.474 (lr:0.00010000000000000002)
81200: accuracy:0.25 loss: 234.717 (lr:0.00010000000000000002)
81210: accuracy:0.28 loss: 211.078 (lr:0.00010000000000000002)
81220: accuracy:0.28 loss: 227.866 (lr:0.00010000000000000002)
81230: accuracy:0.28 loss: 227.987 (lr:0.00010000000000000002)
81240: accuracy:0.4 loss: 202.197 (lr:0.00010000000000000002)
81250: accuracy:0.32 loss: 217.015 (lr:0.00010000000000000002)
81260: accuracy:0.28 loss: 207.106 (lr:0.00010000000000000002)
81270: accuracy:0.31 loss: 223.127 (lr:0.00010000000000000002)
81280: accuracy:0.29 loss: 216.359 (lr:0.00010000000000000002)
81290: accuracy:0.35 loss: 219.335 (lr:0.00010000000000000002)
81300: accuracy:0.31 loss: 226.025 (lr:0.00010000000000000002)
81310: accuracy:0.33 loss: 252.345 (lr:0.00010000000000000002)
81320: accuracy:0.28 loss: 230.312 (lr:0.00010000000000000002)
81330: accuracy:0.31 loss: 218.836 (lr:0.00010000000000000002)
81340: accuracy:0.3 loss: 211.519 (lr:0.00010000000000000002)
81350: accuracy:0.34 loss: 198.814 (lr:0.00010000000000000002)
81360: accuracy:0.23 loss: 232.188 (lr:0.00010000000000000002)
81370: accuracy:0.27 loss: 230.371 (lr:0.00010000000000000002)
81380: accuracy:0.31 loss: 222.053 (lr:0.00010000000000000002)
81390: accuracy:0.28 loss: 223.067 (lr:0.00010000000000000002)
81400: accuracy:0.32 loss: 195.281 (lr:0.00010000000000000002)
81410: accuracy:0.4 loss: 205.382 (lr:0.00010000000000000002)
81420: accuracy:0.37 loss: 225.179 (lr:0.00010000000000000002)
81430: accuracy:0.31 loss: 215.851 (lr:0.00010000000000000002)
81440: accuracy:0.29 loss: 235.673 (lr:0.00010000000000000002)
81450: accuracy:0.38 loss: 212.501 (lr:0.00010000000000000002)
81460: accuracy:0.27 loss: 212.179 (lr:0.00010000000000000002)
81470: accuracy:0.3 loss: 213.051 (lr:0.00010000000000000002)
81480: accuracy:0.29 loss: 228.89 (lr:0.00010000000000000002)
81490: accuracy:0.31 loss: 219.336 (lr:0.00010000000000000002)
81500: accuracy:0.43 loss: 215.698 (lr:0.00010000000000000002)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
81500: ********* epoch 9 ********* test accuracy for all:0.243959 test loss: 257.211
81500: ********* epoch 9 ********* test accuracy for mode 0:0.013 test loss: 418.841
81500: ********* epoch 9 ********* test accuracy for mode 1:0.0545 test loss: 402.877
81500: ********* epoch 9 ********* test accuracy for mode 2:0.05 test loss: 273.937
81500: ********* epoch 9 ********* test accuracy for mode 24:0.2365 test loss: 268.352
81500: ********* epoch 9 ********* test accuracy for mode 25:0.267 test loss: 253.372
81500: ********* epoch 9 ********* test accuracy for mode 26:0.4365 test loss: 167.196
81500: ********* epoch 9 ********* test accuracy for mode 27:0.2215 test loss: 274.113
81500: ********* epoch 9 ********* test accuracy for mode 28:0.299 test loss: 256.304
81500: ********* epoch 9 ********* test accuracy for mode 29:0.2865 test loss: 262.857
81500: ********* epoch 9 ********* test accuracy for mode 30:0.198 test loss: 261.133
81500: ********* epoch 9 ********* test accuracy for mode 31:0.2215 test loss: 259.083
81500: ********* epoch 9 ********* test accuracy for mode 32:0.212 test loss: 248.379
81500: ********* epoch 9 ********* test accuracy for mode 33:0.254 test loss: 253.295
81500: ********* epoch 9 ********* test accuracy for mode 34:0.141 test loss: 256.166
81500: ********* epoch 9 ********* test accuracy for mode 35:0.013 test loss: 421.555
81500: ********* epoch 9 ********* test accuracy for mode 36:0.035 test loss: 443.962
81510: accuracy:0.37 loss: 215.503 (lr:0.00010000000000000002)
81520: accuracy:0.27 loss: 227.575 (lr:0.00010000000000000002)
81530: accuracy:0.37 loss: 215.797 (lr:0.00010000000000000002)
81540: accuracy:0.22 loss: 220.617 (lr:0.00010000000000000002)
81550: accuracy:0.34 loss: 214.305 (lr:0.00010000000000000002)
81560: accuracy:0.33 loss: 198.683 (lr:0.00010000000000000002)
81570: accuracy:0.25 loss: 226.646 (lr:0.00010000000000000002)
81580: accuracy:0.27 loss: 243.929 (lr:0.00010000000000000002)
81590: accuracy:0.23 loss: 237.626 (lr:0.00010000000000000002)
81600: accuracy:0.34 loss: 211.459 (lr:0.00010000000000000002)
81610: accuracy:0.35 loss: 210.1 (lr:0.00010000000000000002)
81620: accuracy:0.21 loss: 251.987 (lr:0.00010000000000000002)
81630: accuracy:0.24 loss: 245.456 (lr:0.00010000000000000002)
81640: accuracy:0.36 loss: 216.959 (lr:0.00010000000000000002)
81650: accuracy:0.32 loss: 213.51 (lr:0.00010000000000000002)
81660: accuracy:0.34 loss: 224.301 (lr:0.00010000000000000002)
81670: accuracy:0.22 loss: 244.614 (lr:0.00010000000000000002)
81680: accuracy:0.32 loss: 217.848 (lr:0.00010000000000000002)
81690: accuracy:0.34 loss: 214.21 (lr:0.00010000000000000002)
81700: accuracy:0.41 loss: 210.76 (lr:0.00010000000000000002)
81710: accuracy:0.24 loss: 234.923 (lr:0.00010000000000000002)
81720: accuracy:0.29 loss: 227.023 (lr:0.00010000000000000002)
81730: accuracy:0.3 loss: 230.404 (lr:0.00010000000000000002)
81740: accuracy:0.37 loss: 200.478 (lr:0.00010000000000000002)
81750: accuracy:0.27 loss: 219.457 (lr:0.00010000000000000002)
81760: accuracy:0.27 loss: 218.605 (lr:0.00010000000000000002)
81770: accuracy:0.2 loss: 249.541 (lr:0.00010000000000000002)
81780: accuracy:0.31 loss: 213.793 (lr:0.00010000000000000002)
81790: accuracy:0.27 loss: 240.984 (lr:0.00010000000000000002)
81800: accuracy:0.35 loss: 232.911 (lr:0.00010000000000000002)
81810: accuracy:0.23 loss: 224.4 (lr:0.00010000000000000002)
81820: accuracy:0.31 loss: 221.903 (lr:0.00010000000000000002)
81830: accuracy:0.3 loss: 231.061 (lr:0.00010000000000000002)
81840: accuracy:0.31 loss: 213.173 (lr:0.00010000000000000002)
81850: accuracy:0.34 loss: 230.076 (lr:0.00010000000000000002)
81860: accuracy:0.32 loss: 218.321 (lr:0.00010000000000000002)
81870: accuracy:0.3 loss: 219.575 (lr:0.00010000000000000002)
81880: accuracy:0.32 loss: 217.564 (lr:0.00010000000000000002)
81890: accuracy:0.25 loss: 247.041 (lr:0.00010000000000000002)
81900: accuracy:0.31 loss: 217.88 (lr:0.00010000000000000002)
81910: accuracy:0.26 loss: 229.854 (lr:0.00010000000000000002)
81920: accuracy:0.35 loss: 225.726 (lr:0.00010000000000000002)
81930: accuracy:0.28 loss: 229.153 (lr:0.00010000000000000002)
81940: accuracy:0.35 loss: 217.673 (lr:0.00010000000000000002)
81950: accuracy:0.32 loss: 223.632 (lr:0.00010000000000000002)
81960: accuracy:0.37 loss: 208.707 (lr:0.00010000000000000002)
81970: accuracy:0.3 loss: 227.594 (lr:0.00010000000000000002)
81980: accuracy:0.3 loss: 229.272 (lr:0.00010000000000000002)
81990: accuracy:0.31 loss: 211.711 (lr:0.00010000000000000002)
82000: accuracy:0.26 loss: 230.754 (lr:0.00010000000000000002)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
82000: ********* epoch 9 ********* test accuracy for all:0.246311 test loss: 256.562
82000: ********* epoch 9 ********* test accuracy for mode 0:0.0065 test loss: 426.953
82000: ********* epoch 9 ********* test accuracy for mode 1:0.0525 test loss: 405.877
82000: ********* epoch 9 ********* test accuracy for mode 2:0.044 test loss: 273.759
82000: ********* epoch 9 ********* test accuracy for mode 24:0.2595 test loss: 267.53
82000: ********* epoch 9 ********* test accuracy for mode 25:0.2835 test loss: 245.636
82000: ********* epoch 9 ********* test accuracy for mode 26:0.411 test loss: 170.459
82000: ********* epoch 9 ********* test accuracy for mode 27:0.2305 test loss: 268.237
82000: ********* epoch 9 ********* test accuracy for mode 28:0.2985 test loss: 252.58
82000: ********* epoch 9 ********* test accuracy for mode 29:0.2555 test loss: 258.366
82000: ********* epoch 9 ********* test accuracy for mode 30:0.285 test loss: 249.596
82000: ********* epoch 9 ********* test accuracy for mode 31:0.2135 test loss: 255.763
82000: ********* epoch 9 ********* test accuracy for mode 32:0.1465 test loss: 250.104
82000: ********* epoch 9 ********* test accuracy for mode 33:0.3445 test loss: 246.849
82000: ********* epoch 9 ********* test accuracy for mode 34:0.085 test loss: 257.305
82000: ********* epoch 9 ********* test accuracy for mode 35:0.0045 test loss: 416.736
82000: ********* epoch 9 ********* test accuracy for mode 36:0.0695 test loss: 446.838
82010: accuracy:0.36 loss: 217.005 (lr:0.00010000000000000002)
82020: accuracy:0.32 loss: 229.075 (lr:0.00010000000000000002)
82030: accuracy:0.32 loss: 219.288 (lr:0.00010000000000000002)
82040: accuracy:0.32 loss: 219.733 (lr:0.00010000000000000002)
82050: accuracy:0.3 loss: 223.288 (lr:0.00010000000000000002)
82060: accuracy:0.26 loss: 225.119 (lr:0.00010000000000000002)
82070: accuracy:0.45 loss: 210.561 (lr:0.00010000000000000002)
82080: accuracy:0.46 loss: 202.869 (lr:0.00010000000000000002)
82090: accuracy:0.26 loss: 243.63 (lr:0.00010000000000000002)
82100: accuracy:0.35 loss: 209.504 (lr:0.00010000000000000002)
82110: accuracy:0.28 loss: 225.551 (lr:0.00010000000000000002)
82120: accuracy:0.36 loss: 210.221 (lr:0.00010000000000000002)
82130: accuracy:0.3 loss: 212.348 (lr:0.00010000000000000002)
82140: accuracy:0.28 loss: 221.471 (lr:0.00010000000000000002)
82150: accuracy:0.3 loss: 228.834 (lr:0.00010000000000000002)
82160: accuracy:0.39 loss: 206.637 (lr:0.00010000000000000002)
82170: accuracy:0.31 loss: 230.595 (lr:0.00010000000000000002)
82180: accuracy:0.35 loss: 229.093 (lr:0.00010000000000000002)
82190: accuracy:0.3 loss: 236.627 (lr:0.00010000000000000002)
82200: accuracy:0.22 loss: 232.812 (lr:0.00010000000000000002)
82210: accuracy:0.3 loss: 232.676 (lr:0.00010000000000000002)
82220: accuracy:0.27 loss: 219.474 (lr:0.00010000000000000002)
82230: accuracy:0.33 loss: 220.63 (lr:0.00010000000000000002)
82240: accuracy:0.32 loss: 211.837 (lr:0.00010000000000000002)
82250: accuracy:0.31 loss: 217.492 (lr:0.0001)
82260: accuracy:0.26 loss: 238.865 (lr:0.0001)
82270: accuracy:0.36 loss: 226.009 (lr:0.0001)
82280: accuracy:0.27 loss: 207.953 (lr:0.0001)
82290: accuracy:0.29 loss: 227.345 (lr:0.0001)
82300: accuracy:0.32 loss: 208.671 (lr:0.0001)
82310: accuracy:0.34 loss: 217.088 (lr:0.0001)
82320: accuracy:0.22 loss: 247.539 (lr:0.0001)
82330: accuracy:0.33 loss: 226.463 (lr:0.0001)
82340: accuracy:0.32 loss: 216.972 (lr:0.0001)
82350: accuracy:0.34 loss: 206.964 (lr:0.0001)
82360: accuracy:0.29 loss: 230.449 (lr:0.0001)
82370: accuracy:0.27 loss: 228.002 (lr:0.0001)
82380: accuracy:0.32 loss: 232.305 (lr:0.0001)
82390: accuracy:0.28 loss: 229.808 (lr:0.0001)
82400: accuracy:0.34 loss: 201.041 (lr:0.0001)
82410: accuracy:0.38 loss: 214.814 (lr:0.0001)
82420: accuracy:0.31 loss: 232.995 (lr:0.0001)
82430: accuracy:0.26 loss: 239.174 (lr:0.0001)
82440: accuracy:0.34 loss: 217.456 (lr:0.0001)
82450: accuracy:0.28 loss: 210.253 (lr:0.0001)
82460: accuracy:0.38 loss: 213.255 (lr:0.0001)
82470: accuracy:0.33 loss: 217.93 (lr:0.0001)
82480: accuracy:0.3 loss: 222.833 (lr:0.0001)
82490: accuracy:0.33 loss: 222.009 (lr:0.0001)
82500: accuracy:0.33 loss: 219.027 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
82500: ********* epoch 9 ********* test accuracy for all:0.241905 test loss: 256.78
82500: ********* epoch 9 ********* test accuracy for mode 0:0.007 test loss: 419.772
82500: ********* epoch 9 ********* test accuracy for mode 1:0.0595 test loss: 400.938
82500: ********* epoch 9 ********* test accuracy for mode 2:0.053 test loss: 271.921
82500: ********* epoch 9 ********* test accuracy for mode 24:0.2445 test loss: 260.539
82500: ********* epoch 9 ********* test accuracy for mode 25:0.298 test loss: 237.344
82500: ********* epoch 9 ********* test accuracy for mode 26:0.405 test loss: 166.759
82500: ********* epoch 9 ********* test accuracy for mode 27:0.2635 test loss: 258.198
82500: ********* epoch 9 ********* test accuracy for mode 28:0.266 test loss: 254.055
82500: ********* epoch 9 ********* test accuracy for mode 29:0.304 test loss: 255.659
82500: ********* epoch 9 ********* test accuracy for mode 30:0.195 test loss: 258.024
82500: ********* epoch 9 ********* test accuracy for mode 31:0.2315 test loss: 258.761
82500: ********* epoch 9 ********* test accuracy for mode 32:0.2 test loss: 251.862
82500: ********* epoch 9 ********* test accuracy for mode 33:0.264 test loss: 254.708
82500: ********* epoch 9 ********* test accuracy for mode 34:0.1215 test loss: 259.028
82500: ********* epoch 9 ********* test accuracy for mode 35:0.0095 test loss: 405.749
82500: ********* epoch 9 ********* test accuracy for mode 36:0.087 test loss: 417.452
82510: accuracy:0.35 loss: 221.753 (lr:0.0001)
82520: accuracy:0.32 loss: 215.714 (lr:0.0001)
82530: accuracy:0.23 loss: 232.961 (lr:0.0001)
82540: accuracy:0.36 loss: 219.658 (lr:0.0001)
82550: accuracy:0.29 loss: 214.114 (lr:0.0001)
82560: accuracy:0.27 loss: 228.958 (lr:0.0001)
82570: accuracy:0.38 loss: 215.89 (lr:0.0001)
82580: accuracy:0.35 loss: 195.319 (lr:0.0001)
82590: accuracy:0.33 loss: 234.978 (lr:0.0001)
82600: accuracy:0.33 loss: 221.665 (lr:0.0001)
82610: accuracy:0.28 loss: 217.885 (lr:0.0001)
82620: accuracy:0.4 loss: 193.366 (lr:0.0001)
82630: accuracy:0.3 loss: 225.804 (lr:0.0001)
82640: accuracy:0.21 loss: 236.083 (lr:0.0001)
82650: accuracy:0.17 loss: 234.275 (lr:0.0001)
82660: accuracy:0.25 loss: 231.099 (lr:0.0001)
82670: accuracy:0.28 loss: 238.312 (lr:0.0001)
82680: accuracy:0.33 loss: 242.947 (lr:0.0001)
82690: accuracy:0.26 loss: 211.509 (lr:0.0001)
82700: accuracy:0.27 loss: 229.775 (lr:0.0001)
82710: accuracy:0.26 loss: 210.268 (lr:0.0001)
82720: accuracy:0.35 loss: 222.057 (lr:0.0001)
82730: accuracy:0.33 loss: 221.934 (lr:0.0001)
82740: accuracy:0.33 loss: 211.791 (lr:0.0001)
82750: accuracy:0.3 loss: 213.849 (lr:0.0001)
82760: accuracy:0.33 loss: 234.853 (lr:0.0001)
82770: accuracy:0.38 loss: 219.716 (lr:0.0001)
82780: accuracy:0.34 loss: 212.911 (lr:0.0001)
82790: accuracy:0.29 loss: 235.664 (lr:0.0001)
82800: accuracy:0.35 loss: 211.512 (lr:0.0001)
82810: accuracy:0.31 loss: 225.761 (lr:0.0001)
82820: accuracy:0.22 loss: 239.479 (lr:0.0001)
82830: accuracy:0.33 loss: 225.494 (lr:0.0001)
82840: accuracy:0.36 loss: 216.139 (lr:0.0001)
82850: accuracy:0.29 loss: 240.064 (lr:0.0001)
82860: accuracy:0.28 loss: 219.535 (lr:0.0001)
82870: accuracy:0.36 loss: 219.042 (lr:0.0001)
82880: accuracy:0.34 loss: 213.998 (lr:0.0001)
82890: accuracy:0.25 loss: 222.384 (lr:0.0001)
82900: accuracy:0.24 loss: 236.405 (lr:0.0001)
82910: accuracy:0.38 loss: 200.215 (lr:0.0001)
82920: accuracy:0.24 loss: 231.095 (lr:0.0001)
82930: accuracy:0.35 loss: 221.86 (lr:0.0001)
82940: accuracy:0.35 loss: 198.5 (lr:0.0001)
82950: accuracy:0.28 loss: 225.526 (lr:0.0001)
82960: accuracy:0.28 loss: 227.34 (lr:0.0001)
82970: accuracy:0.21 loss: 242.036 (lr:0.0001)
82980: accuracy:0.29 loss: 237.218 (lr:0.0001)
82990: accuracy:0.39 loss: 220.639 (lr:0.0001)
83000: accuracy:0.3 loss: 218.603 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
83000: ********* epoch 9 ********* test accuracy for all:0.244784 test loss: 255.699
83000: ********* epoch 9 ********* test accuracy for mode 0:0.006 test loss: 426.979
83000: ********* epoch 9 ********* test accuracy for mode 1:0.044 test loss: 404.074
83000: ********* epoch 9 ********* test accuracy for mode 2:0.0395 test loss: 275.183
83000: ********* epoch 9 ********* test accuracy for mode 24:0.241 test loss: 261.844
83000: ********* epoch 9 ********* test accuracy for mode 25:0.2935 test loss: 237.925
83000: ********* epoch 9 ********* test accuracy for mode 26:0.4325 test loss: 166.119
83000: ********* epoch 9 ********* test accuracy for mode 27:0.241 test loss: 262.042
83000: ********* epoch 9 ********* test accuracy for mode 28:0.2995 test loss: 250.028
83000: ********* epoch 9 ********* test accuracy for mode 29:0.285 test loss: 256.926
83000: ********* epoch 9 ********* test accuracy for mode 30:0.2405 test loss: 253.604
83000: ********* epoch 9 ********* test accuracy for mode 31:0.177 test loss: 258.71
83000: ********* epoch 9 ********* test accuracy for mode 32:0.2555 test loss: 245.14
83000: ********* epoch 9 ********* test accuracy for mode 33:0.2195 test loss: 254.335
83000: ********* epoch 9 ********* test accuracy for mode 34:0.1685 test loss: 253.6
83000: ********* epoch 9 ********* test accuracy for mode 35:0.001 test loss: 413.01
83000: ********* epoch 9 ********* test accuracy for mode 36:0.0625 test loss: 448.667
83010: accuracy:0.36 loss: 218.931 (lr:0.0001)
83020: accuracy:0.33 loss: 216.614 (lr:0.0001)
83030: accuracy:0.37 loss: 212.03 (lr:0.0001)
83040: accuracy:0.22 loss: 236.305 (lr:0.0001)
83050: accuracy:0.33 loss: 222.117 (lr:0.0001)
83060: accuracy:0.44 loss: 210.644 (lr:0.0001)
83070: accuracy:0.41 loss: 193.366 (lr:0.0001)
83080: accuracy:0.27 loss: 222.879 (lr:0.0001)
83090: accuracy:0.31 loss: 204.857 (lr:0.0001)
83100: accuracy:0.28 loss: 222.733 (lr:0.0001)
83110: accuracy:0.24 loss: 222.438 (lr:0.0001)
83120: accuracy:0.34 loss: 227.149 (lr:0.0001)
83130: accuracy:0.38 loss: 206.671 (lr:0.0001)
83140: accuracy:0.28 loss: 249.195 (lr:0.0001)
83150: accuracy:0.39 loss: 210.091 (lr:0.0001)
83160: accuracy:0.3 loss: 215.4 (lr:0.0001)
83170: accuracy:0.22 loss: 235.687 (lr:0.0001)
83180: accuracy:0.34 loss: 224.309 (lr:0.0001)
83190: accuracy:0.32 loss: 219.328 (lr:0.0001)
83200: accuracy:0.27 loss: 223.513 (lr:0.0001)
83210: accuracy:0.35 loss: 215.016 (lr:0.0001)
83220: accuracy:0.29 loss: 235.119 (lr:0.0001)
83230: accuracy:0.28 loss: 221.039 (lr:0.0001)
83240: accuracy:0.35 loss: 233.32 (lr:0.0001)
83250: accuracy:0.31 loss: 225.467 (lr:0.0001)
83260: accuracy:0.34 loss: 224.33 (lr:0.0001)
83270: accuracy:0.39 loss: 206.533 (lr:0.0001)
83280: accuracy:0.31 loss: 215.516 (lr:0.0001)
83290: accuracy:0.36 loss: 225.444 (lr:0.0001)
83300: accuracy:0.28 loss: 226.371 (lr:0.0001)
83310: accuracy:0.28 loss: 231.559 (lr:0.0001)
83320: accuracy:0.37 loss: 210.866 (lr:0.0001)
83330: accuracy:0.24 loss: 253.902 (lr:0.0001)
83340: accuracy:0.27 loss: 241.016 (lr:0.0001)
83350: accuracy:0.34 loss: 206.968 (lr:0.0001)
83360: accuracy:0.31 loss: 229.371 (lr:0.0001)
83370: accuracy:0.32 loss: 219.623 (lr:0.0001)
83380: accuracy:0.28 loss: 221.65 (lr:0.0001)
83390: accuracy:0.3 loss: 230.36 (lr:0.0001)
83400: accuracy:0.35 loss: 223.556 (lr:0.0001)
83410: accuracy:0.37 loss: 212.204 (lr:0.0001)
83420: accuracy:0.25 loss: 220.149 (lr:0.0001)
83430: accuracy:0.35 loss: 214.896 (lr:0.0001)
83440: accuracy:0.27 loss: 227.753 (lr:0.0001)
83450: accuracy:0.29 loss: 228.562 (lr:0.0001)
83460: accuracy:0.32 loss: 225.114 (lr:0.0001)
83470: accuracy:0.28 loss: 226.849 (lr:0.0001)
83480: accuracy:0.27 loss: 213.408 (lr:0.0001)
83490: accuracy:0.26 loss: 229.583 (lr:0.0001)
83500: accuracy:0.26 loss: 250.045 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
83500: ********* epoch 9 ********* test accuracy for all:0.245068 test loss: 256.661
83500: ********* epoch 9 ********* test accuracy for mode 0:0.0035 test loss: 428.251
83500: ********* epoch 9 ********* test accuracy for mode 1:0.0455 test loss: 408.058
83500: ********* epoch 9 ********* test accuracy for mode 2:0.0365 test loss: 272.601
83500: ********* epoch 9 ********* test accuracy for mode 24:0.2365 test loss: 271.657
83500: ********* epoch 9 ********* test accuracy for mode 25:0.2855 test loss: 249.575
83500: ********* epoch 9 ********* test accuracy for mode 26:0.407 test loss: 166.918
83500: ********* epoch 9 ********* test accuracy for mode 27:0.277 test loss: 260.472
83500: ********* epoch 9 ********* test accuracy for mode 28:0.3125 test loss: 248.528
83500: ********* epoch 9 ********* test accuracy for mode 29:0.2475 test loss: 258.53
83500: ********* epoch 9 ********* test accuracy for mode 30:0.259 test loss: 247.871
83500: ********* epoch 9 ********* test accuracy for mode 31:0.224 test loss: 250.972
83500: ********* epoch 9 ********* test accuracy for mode 32:0.218 test loss: 245.791
83500: ********* epoch 9 ********* test accuracy for mode 33:0.2315 test loss: 252.262
83500: ********* epoch 9 ********* test accuracy for mode 34:0.168 test loss: 251.179
83500: ********* epoch 9 ********* test accuracy for mode 35:0.0005 test loss: 422.716
83500: ********* epoch 9 ********* test accuracy for mode 36:0.042 test loss: 457.997
83510: accuracy:0.36 loss: 227.943 (lr:0.0001)
83520: accuracy:0.32 loss: 214.337 (lr:0.0001)
83530: accuracy:0.3 loss: 220.2 (lr:0.0001)
83540: accuracy:0.3 loss: 221.573 (lr:0.0001)
83550: accuracy:0.25 loss: 227.132 (lr:0.0001)
83560: accuracy:0.31 loss: 226.268 (lr:0.0001)
83570: accuracy:0.3 loss: 233.577 (lr:0.0001)
83580: accuracy:0.31 loss: 216.392 (lr:0.0001)
83590: accuracy:0.37 loss: 237.221 (lr:0.0001)
83600: accuracy:0.35 loss: 211.55 (lr:0.0001)
83610: accuracy:0.37 loss: 214.284 (lr:0.0001)
83620: accuracy:0.31 loss: 225.761 (lr:0.0001)
83630: accuracy:0.32 loss: 229.496 (lr:0.0001)
83640: accuracy:0.3 loss: 220.665 (lr:0.0001)
83650: accuracy:0.31 loss: 230.887 (lr:0.0001)
83660: accuracy:0.27 loss: 214.842 (lr:0.0001)
83670: accuracy:0.27 loss: 231.183 (lr:0.0001)
83680: accuracy:0.33 loss: 224.91 (lr:0.0001)
83690: accuracy:0.38 loss: 208.841 (lr:0.0001)
83700: accuracy:0.34 loss: 216.467 (lr:0.0001)
83710: accuracy:0.37 loss: 211.501 (lr:0.0001)
83720: accuracy:0.38 loss: 202.31 (lr:0.0001)
83730: accuracy:0.33 loss: 213.615 (lr:0.0001)
83740: accuracy:0.31 loss: 221.011 (lr:0.0001)
83750: accuracy:0.45 loss: 192.542 (lr:0.0001)
83760: accuracy:0.4 loss: 212.214 (lr:0.0001)
83770: accuracy:0.28 loss: 219.483 (lr:0.0001)
83780: accuracy:0.26 loss: 218.548 (lr:0.0001)
83790: accuracy:0.29 loss: 220.031 (lr:0.0001)
83800: accuracy:0.28 loss: 217.18 (lr:0.0001)
83810: accuracy:0.31 loss: 211.16 (lr:0.0001)
83820: accuracy:0.36 loss: 214.68 (lr:0.0001)
83830: accuracy:0.31 loss: 200.08 (lr:0.0001)
83840: accuracy:0.33 loss: 210.205 (lr:0.0001)
83850: accuracy:0.33 loss: 218.419 (lr:0.0001)
83860: accuracy:0.29 loss: 244.583 (lr:0.0001)
83870: accuracy:0.37 loss: 218.208 (lr:0.0001)
83880: accuracy:0.34 loss: 214.034 (lr:0.0001)
83890: accuracy:0.31 loss: 206.969 (lr:0.0001)
83900: accuracy:0.32 loss: 222.517 (lr:0.0001)
83910: accuracy:0.34 loss: 208.248 (lr:0.0001)
83920: accuracy:0.36 loss: 216.262 (lr:0.0001)
83930: accuracy:0.33 loss: 213.028 (lr:0.0001)
83940: accuracy:0.3 loss: 217.396 (lr:0.0001)
83950: accuracy:0.35 loss: 206.466 (lr:0.0001)
83960: accuracy:0.31 loss: 221.274 (lr:0.0001)
83970: accuracy:0.2 loss: 249.712 (lr:0.0001)
83980: accuracy:0.34 loss: 214.382 (lr:0.0001)
83990: accuracy:0.3 loss: 214.372 (lr:0.0001)
84000: accuracy:0.19 loss: 244.04 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
84000: ********* epoch 9 ********* test accuracy for all:0.241851 test loss: 257.644
84000: ********* epoch 9 ********* test accuracy for mode 0:0.0045 test loss: 431.872
84000: ********* epoch 9 ********* test accuracy for mode 1:0.0405 test loss: 412.349
84000: ********* epoch 9 ********* test accuracy for mode 2:0.0285 test loss: 272.752
84000: ********* epoch 9 ********* test accuracy for mode 24:0.238 test loss: 267.664
84000: ********* epoch 9 ********* test accuracy for mode 25:0.3025 test loss: 245.698
84000: ********* epoch 9 ********* test accuracy for mode 26:0.308 test loss: 181.314
84000: ********* epoch 9 ********* test accuracy for mode 27:0.2395 test loss: 270.026
84000: ********* epoch 9 ********* test accuracy for mode 28:0.296 test loss: 255.694
84000: ********* epoch 9 ********* test accuracy for mode 29:0.2415 test loss: 262.943
84000: ********* epoch 9 ********* test accuracy for mode 30:0.2805 test loss: 249.81
84000: ********* epoch 9 ********* test accuracy for mode 31:0.1835 test loss: 257.853
84000: ********* epoch 9 ********* test accuracy for mode 32:0.2445 test loss: 242.763
84000: ********* epoch 9 ********* test accuracy for mode 33:0.224 test loss: 249.379
84000: ********* epoch 9 ********* test accuracy for mode 34:0.2015 test loss: 246.87
84000: ********* epoch 9 ********* test accuracy for mode 35:0.002 test loss: 409.953
84000: ********* epoch 9 ********* test accuracy for mode 36:0.0605 test loss: 442.87
84010: accuracy:0.22 loss: 239.06 (lr:0.0001)
84020: accuracy:0.33 loss: 223.323 (lr:0.0001)
84030: accuracy:0.3 loss: 218.797 (lr:0.0001)
84040: accuracy:0.35 loss: 225.519 (lr:0.0001)
84050: accuracy:0.33 loss: 228.39 (lr:0.0001)
84060: accuracy:0.37 loss: 211.142 (lr:0.0001)
84070: accuracy:0.35 loss: 202.544 (lr:0.0001)
84080: accuracy:0.31 loss: 246.691 (lr:0.0001)
84090: accuracy:0.28 loss: 230.559 (lr:0.0001)
84100: accuracy:0.34 loss: 228.441 (lr:0.0001)
84110: accuracy:0.28 loss: 218.26 (lr:0.0001)
84120: accuracy:0.22 loss: 230.911 (lr:0.0001)
84130: accuracy:0.33 loss: 207.323 (lr:0.0001)
84140: accuracy:0.27 loss: 223.078 (lr:0.0001)
84150: accuracy:0.32 loss: 236.651 (lr:0.0001)
84160: accuracy:0.28 loss: 224.766 (lr:0.0001)
84170: accuracy:0.38 loss: 214.603 (lr:0.0001)
84180: accuracy:0.25 loss: 210.59 (lr:0.0001)
84190: accuracy:0.38 loss: 204.613 (lr:0.0001)
84200: accuracy:0.34 loss: 205.94 (lr:0.0001)
84210: accuracy:0.3 loss: 235.166 (lr:0.0001)
84220: accuracy:0.29 loss: 228.895 (lr:0.0001)
84230: accuracy:0.36 loss: 228.386 (lr:0.0001)
84240: accuracy:0.28 loss: 242.3 (lr:0.0001)
84250: accuracy:0.26 loss: 225.443 (lr:0.0001)
84260: accuracy:0.22 loss: 229.993 (lr:0.0001)
84270: accuracy:0.31 loss: 242.202 (lr:0.0001)
84280: accuracy:0.24 loss: 232.019 (lr:0.0001)
84290: accuracy:0.39 loss: 210.311 (lr:0.0001)
84300: accuracy:0.26 loss: 254.109 (lr:0.0001)
84310: accuracy:0.39 loss: 217.77 (lr:0.0001)
84320: accuracy:0.36 loss: 230.8 (lr:0.0001)
84330: accuracy:0.28 loss: 219.57 (lr:0.0001)
84340: accuracy:0.34 loss: 226.185 (lr:0.0001)
84350: accuracy:0.36 loss: 215.264 (lr:0.0001)
84360: accuracy:0.36 loss: 197.033 (lr:0.0001)
84370: accuracy:0.28 loss: 218.945 (lr:0.0001)
84380: accuracy:0.27 loss: 243.425 (lr:0.0001)
84390: accuracy:0.28 loss: 217.78 (lr:0.0001)
84400: accuracy:0.39 loss: 205.339 (lr:0.0001)
84410: accuracy:0.31 loss: 225.627 (lr:0.0001)
84420: accuracy:0.37 loss: 216.65 (lr:0.0001)
84430: accuracy:0.3 loss: 218.711 (lr:0.0001)
84440: accuracy:0.28 loss: 232.805 (lr:0.0001)
84450: accuracy:0.35 loss: 218.52 (lr:0.0001)
84460: accuracy:0.31 loss: 223.122 (lr:0.0001)
84470: accuracy:0.3 loss: 219.677 (lr:0.0001)
84480: accuracy:0.35 loss: 204.081 (lr:0.0001)
84490: accuracy:0.35 loss: 217.836 (lr:0.0001)
84500: accuracy:0.34 loss: 229.475 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
84500: ********* epoch 9 ********* test accuracy for all:0.242351 test loss: 257.807
84500: ********* epoch 9 ********* test accuracy for mode 0:0.0055 test loss: 432.747
84500: ********* epoch 9 ********* test accuracy for mode 1:0.0435 test loss: 418.378
84500: ********* epoch 9 ********* test accuracy for mode 2:0.055 test loss: 268.748
84500: ********* epoch 9 ********* test accuracy for mode 24:0.263 test loss: 262.248
84500: ********* epoch 9 ********* test accuracy for mode 25:0.3315 test loss: 242.383
84500: ********* epoch 9 ********* test accuracy for mode 26:0.363 test loss: 170.625
84500: ********* epoch 9 ********* test accuracy for mode 27:0.246 test loss: 267.388
84500: ********* epoch 9 ********* test accuracy for mode 28:0.287 test loss: 261.839
84500: ********* epoch 9 ********* test accuracy for mode 29:0.234 test loss: 267.816
84500: ********* epoch 9 ********* test accuracy for mode 30:0.239 test loss: 255.437
84500: ********* epoch 9 ********* test accuracy for mode 31:0.1935 test loss: 256.162
84500: ********* epoch 9 ********* test accuracy for mode 32:0.2435 test loss: 242.444
84500: ********* epoch 9 ********* test accuracy for mode 33:0.262 test loss: 247.478
84500: ********* epoch 9 ********* test accuracy for mode 34:0.143 test loss: 250.44
84500: ********* epoch 9 ********* test accuracy for mode 35:0.0 test loss: 417.798
84500: ********* epoch 9 ********* test accuracy for mode 36:0.0495 test loss: 445.463
84510: accuracy:0.34 loss: 200.871 (lr:0.0001)
84520: accuracy:0.33 loss: 224.3 (lr:0.0001)
84530: accuracy:0.32 loss: 233.177 (lr:0.0001)
84540: accuracy:0.36 loss: 203.814 (lr:0.0001)
84550: accuracy:0.34 loss: 210.365 (lr:0.0001)
84560: accuracy:0.35 loss: 208.458 (lr:0.0001)
84570: accuracy:0.3 loss: 227.092 (lr:0.0001)
84580: accuracy:0.33 loss: 222.378 (lr:0.0001)
84590: accuracy:0.31 loss: 205.992 (lr:0.0001)
84600: accuracy:0.28 loss: 230.626 (lr:0.0001)
84610: accuracy:0.31 loss: 223.965 (lr:0.0001)
84620: accuracy:0.31 loss: 212.554 (lr:0.0001)
84630: accuracy:0.31 loss: 228.561 (lr:0.0001)
84640: accuracy:0.27 loss: 234.296 (lr:0.0001)
84650: accuracy:0.34 loss: 198.973 (lr:0.0001)
84660: accuracy:0.35 loss: 209.489 (lr:0.0001)
84670: accuracy:0.32 loss: 208.574 (lr:0.0001)
84680: accuracy:0.37 loss: 223.132 (lr:0.0001)
84690: accuracy:0.3 loss: 219.794 (lr:0.0001)
84700: accuracy:0.35 loss: 219.757 (lr:0.0001)
84710: accuracy:0.35 loss: 202.746 (lr:0.0001)
84720: accuracy:0.26 loss: 230.512 (lr:0.0001)
84730: accuracy:0.27 loss: 220.063 (lr:0.0001)
84740: accuracy:0.32 loss: 205.192 (lr:0.0001)
84750: accuracy:0.34 loss: 240.8 (lr:0.0001)
84760: accuracy:0.25 loss: 244.713 (lr:0.0001)
84770: accuracy:0.24 loss: 226.439 (lr:0.0001)
84780: accuracy:0.3 loss: 227.667 (lr:0.0001)
84790: accuracy:0.29 loss: 231.419 (lr:0.0001)
84800: accuracy:0.29 loss: 219.181 (lr:0.0001)
84810: accuracy:0.29 loss: 216.813 (lr:0.0001)
84820: accuracy:0.42 loss: 183.249 (lr:0.0001)
84830: accuracy:0.26 loss: 225.859 (lr:0.0001)
84840: accuracy:0.3 loss: 203.066 (lr:0.0001)
84850: accuracy:0.32 loss: 218.168 (lr:0.0001)
84860: accuracy:0.35 loss: 211.96 (lr:0.0001)
84870: accuracy:0.28 loss: 220.421 (lr:0.0001)
84880: accuracy:0.29 loss: 238.705 (lr:0.0001)
84890: accuracy:0.28 loss: 219.715 (lr:0.0001)
84900: accuracy:0.3 loss: 222.819 (lr:0.0001)
84910: accuracy:0.33 loss: 236.117 (lr:0.0001)
84920: accuracy:0.36 loss: 216.426 (lr:0.0001)
84930: accuracy:0.32 loss: 231.609 (lr:0.0001)
84940: accuracy:0.25 loss: 229.786 (lr:0.0001)
84950: accuracy:0.3 loss: 236.929 (lr:0.0001)
84960: accuracy:0.3 loss: 226.876 (lr:0.0001)
84970: accuracy:0.28 loss: 231.869 (lr:0.0001)
84980: accuracy:0.33 loss: 211.769 (lr:0.0001)
84990: accuracy:0.36 loss: 216.429 (lr:0.0001)
85000: accuracy:0.27 loss: 223.298 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
85000: ********* epoch 9 ********* test accuracy for all:0.245149 test loss: 255.982
85000: ********* epoch 9 ********* test accuracy for mode 0:0.0105 test loss: 418.716
85000: ********* epoch 9 ********* test accuracy for mode 1:0.0505 test loss: 407.374
85000: ********* epoch 9 ********* test accuracy for mode 2:0.056 test loss: 265.557
85000: ********* epoch 9 ********* test accuracy for mode 24:0.2115 test loss: 276.313
85000: ********* epoch 9 ********* test accuracy for mode 25:0.27 test loss: 256.275
85000: ********* epoch 9 ********* test accuracy for mode 26:0.492 test loss: 165.851
85000: ********* epoch 9 ********* test accuracy for mode 27:0.2305 test loss: 269.053
85000: ********* epoch 9 ********* test accuracy for mode 28:0.2905 test loss: 252.567
85000: ********* epoch 9 ********* test accuracy for mode 29:0.2665 test loss: 256.733
85000: ********* epoch 9 ********* test accuracy for mode 30:0.251 test loss: 248.075
85000: ********* epoch 9 ********* test accuracy for mode 31:0.194 test loss: 247.556
85000: ********* epoch 9 ********* test accuracy for mode 32:0.2655 test loss: 237.071
85000: ********* epoch 9 ********* test accuracy for mode 33:0.239 test loss: 246.906
85000: ********* epoch 9 ********* test accuracy for mode 34:0.1215 test loss: 251.763
85000: ********* epoch 9 ********* test accuracy for mode 35:0.002 test loss: 401.261
85000: ********* epoch 9 ********* test accuracy for mode 36:0.065 test loss: 416.335
85010: accuracy:0.32 loss: 195.709 (lr:0.0001)
85020: accuracy:0.23 loss: 220.451 (lr:0.0001)
85030: accuracy:0.37 loss: 224.031 (lr:0.0001)
85040: accuracy:0.32 loss: 210.241 (lr:0.0001)
85050: accuracy:0.37 loss: 208.79 (lr:0.0001)
85060: accuracy:0.33 loss: 228.348 (lr:0.0001)
85070: accuracy:0.34 loss: 222.656 (lr:0.0001)
85080: accuracy:0.3 loss: 213.754 (lr:0.0001)
85090: accuracy:0.32 loss: 209.656 (lr:0.0001)
85100: accuracy:0.4 loss: 202.589 (lr:0.0001)
85110: accuracy:0.26 loss: 218.083 (lr:0.0001)
85120: accuracy:0.3 loss: 235.604 (lr:0.0001)
85130: accuracy:0.32 loss: 215.028 (lr:0.0001)
85140: accuracy:0.34 loss: 221.874 (lr:0.0001)
85150: accuracy:0.3 loss: 222.674 (lr:0.0001)
85160: accuracy:0.39 loss: 218.096 (lr:0.0001)
85170: accuracy:0.28 loss: 220.805 (lr:0.0001)
85180: accuracy:0.29 loss: 223.235 (lr:0.0001)
85190: accuracy:0.28 loss: 231.249 (lr:0.0001)
85200: accuracy:0.43 loss: 204.525 (lr:0.0001)
85210: accuracy:0.29 loss: 217.054 (lr:0.0001)
85220: accuracy:0.29 loss: 237.64 (lr:0.0001)
85230: accuracy:0.34 loss: 223.16 (lr:0.0001)
85240: accuracy:0.34 loss: 206.863 (lr:0.0001)
85250: accuracy:0.28 loss: 227.831 (lr:0.0001)
85260: accuracy:0.3 loss: 217.188 (lr:0.0001)
85270: accuracy:0.29 loss: 228.628 (lr:0.0001)
85280: accuracy:0.33 loss: 222.5 (lr:0.0001)
85290: accuracy:0.4 loss: 219.725 (lr:0.0001)
85300: accuracy:0.35 loss: 219.832 (lr:0.0001)
85310: accuracy:0.33 loss: 226.531 (lr:0.0001)
85320: accuracy:0.27 loss: 218.446 (lr:0.0001)
85330: accuracy:0.27 loss: 225.924 (lr:0.0001)
85340: accuracy:0.24 loss: 227.795 (lr:0.0001)
85350: accuracy:0.31 loss: 215.527 (lr:0.0001)
85360: accuracy:0.3 loss: 233.673 (lr:0.0001)
85370: accuracy:0.35 loss: 211.54 (lr:0.0001)
85380: accuracy:0.4 loss: 207.211 (lr:0.0001)
85390: accuracy:0.37 loss: 205.498 (lr:0.0001)
85400: accuracy:0.26 loss: 232.886 (lr:0.0001)
85410: accuracy:0.29 loss: 242.744 (lr:0.0001)
85420: accuracy:0.3 loss: 223.838 (lr:0.0001)
85430: accuracy:0.27 loss: 224.122 (lr:0.0001)
85440: accuracy:0.27 loss: 228.84 (lr:0.0001)
85450: accuracy:0.33 loss: 228.572 (lr:0.0001)
85460: accuracy:0.39 loss: 208.315 (lr:0.0001)
85470: accuracy:0.31 loss: 203.946 (lr:0.0001)
85480: accuracy:0.39 loss: 200.003 (lr:0.0001)
85490: accuracy:0.21 loss: 217.414 (lr:0.0001)
85500: accuracy:0.34 loss: 210.483 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
85500: ********* epoch 9 ********* test accuracy for all:0.247676 test loss: 255.476
85500: ********* epoch 9 ********* test accuracy for mode 0:0.009 test loss: 428.979
85500: ********* epoch 9 ********* test accuracy for mode 1:0.045 test loss: 410.98
85500: ********* epoch 9 ********* test accuracy for mode 2:0.0705 test loss: 266.036
85500: ********* epoch 9 ********* test accuracy for mode 24:0.2785 test loss: 253.968
85500: ********* epoch 9 ********* test accuracy for mode 25:0.3665 test loss: 229.613
85500: ********* epoch 9 ********* test accuracy for mode 26:0.3625 test loss: 168.749
85500: ********* epoch 9 ********* test accuracy for mode 27:0.274 test loss: 255.77
85500: ********* epoch 9 ********* test accuracy for mode 28:0.3085 test loss: 252.94
85500: ********* epoch 9 ********* test accuracy for mode 29:0.231 test loss: 267.762
85500: ********* epoch 9 ********* test accuracy for mode 30:0.245 test loss: 255.221
85500: ********* epoch 9 ********* test accuracy for mode 31:0.194 test loss: 257.608
85500: ********* epoch 9 ********* test accuracy for mode 32:0.222 test loss: 247.055
85500: ********* epoch 9 ********* test accuracy for mode 33:0.2505 test loss: 250.441
85500: ********* epoch 9 ********* test accuracy for mode 34:0.175 test loss: 249.14
85500: ********* epoch 9 ********* test accuracy for mode 35:0.0 test loss: 428.371
85500: ********* epoch 9 ********* test accuracy for mode 36:0.0465 test loss: 437.861
85510: accuracy:0.39 loss: 198.272 (lr:0.0001)
85520: accuracy:0.34 loss: 213.754 (lr:0.0001)
85530: accuracy:0.4 loss: 201.646 (lr:0.0001)
85540: accuracy:0.29 loss: 206.572 (lr:0.0001)
85550: accuracy:0.34 loss: 236.289 (lr:0.0001)
85560: accuracy:0.28 loss: 230.661 (lr:0.0001)
85570: accuracy:0.33 loss: 216.858 (lr:0.0001)
85580: accuracy:0.3 loss: 217.615 (lr:0.0001)
85590: accuracy:0.27 loss: 236.475 (lr:0.0001)
85600: accuracy:0.32 loss: 229.976 (lr:0.0001)
85610: accuracy:0.33 loss: 218.667 (lr:0.0001)
85620: accuracy:0.32 loss: 214.354 (lr:0.0001)
85630: accuracy:0.24 loss: 231.532 (lr:0.0001)
85640: accuracy:0.35 loss: 220.271 (lr:0.0001)
85650: accuracy:0.36 loss: 230.697 (lr:0.0001)
85660: accuracy:0.26 loss: 234.473 (lr:0.0001)
85670: accuracy:0.25 loss: 236.242 (lr:0.0001)
85680: accuracy:0.36 loss: 215.135 (lr:0.0001)
85690: accuracy:0.39 loss: 217.255 (lr:0.0001)
85700: accuracy:0.24 loss: 238.733 (lr:0.0001)
85710: accuracy:0.31 loss: 227.659 (lr:0.0001)
85720: accuracy:0.31 loss: 237.819 (lr:0.0001)
85730: accuracy:0.3 loss: 218.331 (lr:0.0001)
85740: accuracy:0.29 loss: 227.462 (lr:0.0001)
85750: accuracy:0.3 loss: 204.726 (lr:0.0001)
85760: accuracy:0.29 loss: 228.548 (lr:0.0001)
85770: accuracy:0.34 loss: 225.417 (lr:0.0001)
85780: accuracy:0.25 loss: 217.505 (lr:0.0001)
85790: accuracy:0.31 loss: 215.802 (lr:0.0001)
85800: accuracy:0.27 loss: 223.792 (lr:0.0001)
85810: accuracy:0.29 loss: 224.414 (lr:0.0001)
85820: accuracy:0.34 loss: 211.823 (lr:0.0001)
85830: accuracy:0.26 loss: 229.163 (lr:0.0001)
85840: accuracy:0.35 loss: 228.247 (lr:0.0001)
85850: accuracy:0.23 loss: 225.172 (lr:0.0001)
85860: accuracy:0.23 loss: 224.137 (lr:0.0001)
85870: accuracy:0.31 loss: 222.322 (lr:0.0001)
85880: accuracy:0.36 loss: 207.667 (lr:0.0001)
85890: accuracy:0.24 loss: 232.956 (lr:0.0001)
85900: accuracy:0.22 loss: 236.841 (lr:0.0001)
85910: accuracy:0.32 loss: 236.745 (lr:0.0001)
85920: accuracy:0.26 loss: 231.46 (lr:0.0001)
85930: accuracy:0.23 loss: 242.707 (lr:0.0001)
85940: accuracy:0.34 loss: 227.564 (lr:0.0001)
85950: accuracy:0.35 loss: 212.352 (lr:0.0001)
85960: accuracy:0.3 loss: 206.268 (lr:0.0001)
85970: accuracy:0.27 loss: 215.606 (lr:0.0001)
85980: accuracy:0.34 loss: 229.463 (lr:0.0001)
85990: accuracy:0.35 loss: 208.725 (lr:0.0001)
86000: accuracy:0.3 loss: 225.717 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
86000: ********* epoch 9 ********* test accuracy for all:0.247041 test loss: 257.146
86000: ********* epoch 9 ********* test accuracy for mode 0:0.0075 test loss: 427.559
86000: ********* epoch 9 ********* test accuracy for mode 1:0.048 test loss: 410.014
86000: ********* epoch 9 ********* test accuracy for mode 2:0.0455 test loss: 265.203
86000: ********* epoch 9 ********* test accuracy for mode 24:0.2415 test loss: 268.326
86000: ********* epoch 9 ********* test accuracy for mode 25:0.2885 test loss: 243.533
86000: ********* epoch 9 ********* test accuracy for mode 26:0.4885 test loss: 163.167
86000: ********* epoch 9 ********* test accuracy for mode 27:0.2125 test loss: 266.783
86000: ********* epoch 9 ********* test accuracy for mode 28:0.3105 test loss: 253.973
86000: ********* epoch 9 ********* test accuracy for mode 29:0.261 test loss: 260.063
86000: ********* epoch 9 ********* test accuracy for mode 30:0.2605 test loss: 248.434
86000: ********* epoch 9 ********* test accuracy for mode 31:0.1875 test loss: 251.344
86000: ********* epoch 9 ********* test accuracy for mode 32:0.231 test loss: 239.577
86000: ********* epoch 9 ********* test accuracy for mode 33:0.285 test loss: 243.89
86000: ********* epoch 9 ********* test accuracy for mode 34:0.149 test loss: 249.464
86000: ********* epoch 9 ********* test accuracy for mode 35:0.003 test loss: 425.147
86000: ********* epoch 9 ********* test accuracy for mode 36:0.0855 test loss: 456.958
86010: accuracy:0.36 loss: 223.21 (lr:0.0001)
86020: accuracy:0.27 loss: 234.52 (lr:0.0001)
86030: accuracy:0.35 loss: 221.547 (lr:0.0001)
86040: accuracy:0.25 loss: 238.075 (lr:0.0001)
86050: accuracy:0.31 loss: 227.4 (lr:0.0001)
86060: accuracy:0.32 loss: 215.449 (lr:0.0001)
86070: accuracy:0.24 loss: 226.062 (lr:0.0001)
86080: accuracy:0.27 loss: 233.292 (lr:0.0001)
86090: accuracy:0.28 loss: 224.891 (lr:0.0001)
86100: accuracy:0.26 loss: 240.545 (lr:0.0001)
86110: accuracy:0.31 loss: 205.467 (lr:0.0001)
86120: accuracy:0.32 loss: 233.359 (lr:0.0001)
86130: accuracy:0.26 loss: 243.719 (lr:0.0001)
86140: accuracy:0.31 loss: 207.02 (lr:0.0001)
86150: accuracy:0.29 loss: 236.989 (lr:0.0001)
86160: accuracy:0.36 loss: 204.64 (lr:0.0001)
86170: accuracy:0.37 loss: 221.426 (lr:0.0001)
86180: accuracy:0.29 loss: 218.415 (lr:0.0001)
86190: accuracy:0.3 loss: 212.531 (lr:0.0001)
86200: accuracy:0.3 loss: 230.099 (lr:0.0001)
86210: accuracy:0.3 loss: 210.13 (lr:0.0001)
86220: accuracy:0.33 loss: 222.846 (lr:0.0001)
86230: accuracy:0.23 loss: 226.339 (lr:0.0001)
86240: accuracy:0.38 loss: 221.031 (lr:0.0001)
86250: accuracy:0.41 loss: 208.793 (lr:0.0001)
86260: accuracy:0.3 loss: 226.717 (lr:0.0001)
86270: accuracy:0.24 loss: 231.207 (lr:0.0001)
86280: accuracy:0.35 loss: 228.412 (lr:0.0001)
86290: accuracy:0.34 loss: 228.862 (lr:0.0001)
86300: accuracy:0.39 loss: 217.86 (lr:0.0001)
86310: accuracy:0.31 loss: 204.023 (lr:0.0001)
86320: accuracy:0.38 loss: 201.813 (lr:0.0001)
86330: accuracy:0.24 loss: 235.718 (lr:0.0001)
86340: accuracy:0.33 loss: 227.227 (lr:0.0001)
86350: accuracy:0.29 loss: 217.374 (lr:0.0001)
86360: accuracy:0.31 loss: 231.876 (lr:0.0001)
86370: accuracy:0.33 loss: 217.049 (lr:0.0001)
86380: accuracy:0.35 loss: 222.288 (lr:0.0001)
86390: accuracy:0.29 loss: 223.59 (lr:0.0001)
86400: accuracy:0.32 loss: 211.412 (lr:0.0001)
86410: accuracy:0.32 loss: 230.131 (lr:0.0001)
86420: accuracy:0.34 loss: 207.624 (lr:0.0001)
86430: accuracy:0.33 loss: 222.787 (lr:0.0001)
86440: accuracy:0.43 loss: 197.283 (lr:0.0001)
86450: accuracy:0.24 loss: 231.661 (lr:0.0001)
86460: accuracy:0.4 loss: 208.766 (lr:0.0001)
86470: accuracy:0.24 loss: 255.686 (lr:0.0001)
86480: accuracy:0.25 loss: 221.98 (lr:0.0001)
86490: accuracy:0.31 loss: 222.977 (lr:0.0001)
86500: accuracy:0.36 loss: 204.545 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
86500: ********* epoch 9 ********* test accuracy for all:0.245162 test loss: 255.834
86500: ********* epoch 9 ********* test accuracy for mode 0:0.011 test loss: 415.485
86500: ********* epoch 9 ********* test accuracy for mode 1:0.0525 test loss: 403.233
86500: ********* epoch 9 ********* test accuracy for mode 2:0.05 test loss: 266.038
86500: ********* epoch 9 ********* test accuracy for mode 24:0.2225 test loss: 280.993
86500: ********* epoch 9 ********* test accuracy for mode 25:0.26 test loss: 258.033
86500: ********* epoch 9 ********* test accuracy for mode 26:0.3695 test loss: 176.586
86500: ********* epoch 9 ********* test accuracy for mode 27:0.237 test loss: 268.047
86500: ********* epoch 9 ********* test accuracy for mode 28:0.264 test loss: 262.076
86500: ********* epoch 9 ********* test accuracy for mode 29:0.2835 test loss: 256.246
86500: ********* epoch 9 ********* test accuracy for mode 30:0.2265 test loss: 251.529
86500: ********* epoch 9 ********* test accuracy for mode 31:0.2075 test loss: 253.008
86500: ********* epoch 9 ********* test accuracy for mode 32:0.2095 test loss: 243.609
86500: ********* epoch 9 ********* test accuracy for mode 33:0.3025 test loss: 244.608
86500: ********* epoch 9 ********* test accuracy for mode 34:0.162 test loss: 248.979
86500: ********* epoch 9 ********* test accuracy for mode 35:0.007 test loss: 399.419
86500: ********* epoch 9 ********* test accuracy for mode 36:0.1635 test loss: 400.323
86510: accuracy:0.35 loss: 225.977 (lr:0.0001)
86520: accuracy:0.33 loss: 220.389 (lr:0.0001)
86530: accuracy:0.35 loss: 216.519 (lr:0.0001)
86540: accuracy:0.34 loss: 227.602 (lr:0.0001)
86550: accuracy:0.28 loss: 224.853 (lr:0.0001)
86560: accuracy:0.24 loss: 242.217 (lr:0.0001)
86570: accuracy:0.37 loss: 212.51 (lr:0.0001)
86580: accuracy:0.38 loss: 209.816 (lr:0.0001)
86590: accuracy:0.36 loss: 210.003 (lr:0.0001)
86600: accuracy:0.36 loss: 209.905 (lr:0.0001)
86610: accuracy:0.29 loss: 227.842 (lr:0.0001)
86620: accuracy:0.31 loss: 213.495 (lr:0.0001)
86630: accuracy:0.25 loss: 246.475 (lr:0.0001)
86640: accuracy:0.24 loss: 227.673 (lr:0.0001)
86650: accuracy:0.31 loss: 228.527 (lr:0.0001)
86660: accuracy:0.31 loss: 220.0 (lr:0.0001)
86670: accuracy:0.35 loss: 211.127 (lr:0.0001)
86680: accuracy:0.27 loss: 219.776 (lr:0.0001)
86690: accuracy:0.29 loss: 222.573 (lr:0.0001)
86700: accuracy:0.26 loss: 220.905 (lr:0.0001)
86710: accuracy:0.26 loss: 237.743 (lr:0.0001)
86720: accuracy:0.38 loss: 185.058 (lr:0.0001)
86730: accuracy:0.36 loss: 205.839 (lr:0.0001)
86740: accuracy:0.25 loss: 242.894 (lr:0.0001)
86750: accuracy:0.31 loss: 229.988 (lr:0.0001)
86760: accuracy:0.34 loss: 198.667 (lr:0.0001)
86770: accuracy:0.27 loss: 217.503 (lr:0.0001)
86780: accuracy:0.3 loss: 231.33 (lr:0.0001)
86790: accuracy:0.2 loss: 232.092 (lr:0.0001)
86800: accuracy:0.41 loss: 215.707 (lr:0.0001)
86810: accuracy:0.31 loss: 247.786 (lr:0.0001)
86820: accuracy:0.32 loss: 231.618 (lr:0.0001)
86830: accuracy:0.37 loss: 200.654 (lr:0.0001)
86840: accuracy:0.33 loss: 223.937 (lr:0.0001)
86850: accuracy:0.31 loss: 213.225 (lr:0.0001)
86860: accuracy:0.34 loss: 206.79 (lr:0.0001)
86870: accuracy:0.32 loss: 227.94 (lr:0.0001)
86880: accuracy:0.32 loss: 215.715 (lr:0.0001)
86890: accuracy:0.3 loss: 221.048 (lr:0.0001)
86900: accuracy:0.28 loss: 224.918 (lr:0.0001)
86910: accuracy:0.31 loss: 225.47 (lr:0.0001)
86920: accuracy:0.34 loss: 227.762 (lr:0.0001)
86930: accuracy:0.32 loss: 224.64 (lr:0.0001)
86940: accuracy:0.24 loss: 236.086 (lr:0.0001)
86950: accuracy:0.38 loss: 210.229 (lr:0.0001)
86960: accuracy:0.36 loss: 206.202 (lr:0.0001)
86970: accuracy:0.31 loss: 222.333 (lr:0.0001)
86980: accuracy:0.25 loss: 226.217 (lr:0.0001)
86990: accuracy:0.29 loss: 233.757 (lr:0.0001)
87000: accuracy:0.34 loss: 199.498 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
87000: ********* epoch 9 ********* test accuracy for all:0.242365 test loss: 257.624
87000: ********* epoch 9 ********* test accuracy for mode 0:0.003 test loss: 428.677
87000: ********* epoch 9 ********* test accuracy for mode 1:0.04 test loss: 413.782
87000: ********* epoch 9 ********* test accuracy for mode 2:0.0215 test loss: 269.408
87000: ********* epoch 9 ********* test accuracy for mode 24:0.207 test loss: 285.761
87000: ********* epoch 9 ********* test accuracy for mode 25:0.247 test loss: 257.143
87000: ********* epoch 9 ********* test accuracy for mode 26:0.3975 test loss: 176.871
87000: ********* epoch 9 ********* test accuracy for mode 27:0.245 test loss: 267.297
87000: ********* epoch 9 ********* test accuracy for mode 28:0.286 test loss: 261.26
87000: ********* epoch 9 ********* test accuracy for mode 29:0.2675 test loss: 265.161
87000: ********* epoch 9 ********* test accuracy for mode 30:0.208 test loss: 258.903
87000: ********* epoch 9 ********* test accuracy for mode 31:0.2085 test loss: 253.792
87000: ********* epoch 9 ********* test accuracy for mode 32:0.287 test loss: 239.633
87000: ********* epoch 9 ********* test accuracy for mode 33:0.252 test loss: 245.973
87000: ********* epoch 9 ********* test accuracy for mode 34:0.132 test loss: 250.257
87000: ********* epoch 9 ********* test accuracy for mode 35:0.0075 test loss: 404.656
87000: ********* epoch 9 ********* test accuracy for mode 36:0.0495 test loss: 432.401
87010: accuracy:0.31 loss: 226.212 (lr:0.0001)
87020: accuracy:0.31 loss: 230.999 (lr:0.0001)
87030: accuracy:0.36 loss: 213.564 (lr:0.0001)
87040: accuracy:0.32 loss: 217.839 (lr:0.0001)
87050: accuracy:0.34 loss: 205.464 (lr:0.0001)
87060: accuracy:0.31 loss: 227.511 (lr:0.0001)
87070: accuracy:0.29 loss: 235.503 (lr:0.0001)
87080: accuracy:0.23 loss: 234.173 (lr:0.0001)
87090: accuracy:0.33 loss: 244.75 (lr:0.0001)
87100: accuracy:0.38 loss: 220.233 (lr:0.0001)
87110: accuracy:0.29 loss: 221.829 (lr:0.0001)
87120: accuracy:0.39 loss: 201.006 (lr:0.0001)
87130: accuracy:0.35 loss: 226.404 (lr:0.0001)
87140: accuracy:0.28 loss: 250.037 (lr:0.0001)
87150: accuracy:0.4 loss: 198.514 (lr:0.0001)
87160: accuracy:0.31 loss: 204.285 (lr:0.0001)
87170: accuracy:0.29 loss: 204.348 (lr:0.0001)
87180: accuracy:0.22 loss: 239.72 (lr:0.0001)
87190: accuracy:0.28 loss: 218.992 (lr:0.0001)
87200: accuracy:0.33 loss: 207.727 (lr:0.0001)
87210: accuracy:0.33 loss: 224.479 (lr:0.0001)
87220: accuracy:0.27 loss: 219.898 (lr:0.0001)
87230: accuracy:0.29 loss: 227.314 (lr:0.0001)
87240: accuracy:0.28 loss: 222.436 (lr:0.0001)
87250: accuracy:0.25 loss: 233.234 (lr:0.0001)
87260: accuracy:0.31 loss: 219.016 (lr:0.0001)
87270: accuracy:0.32 loss: 212.215 (lr:0.0001)
87280: accuracy:0.26 loss: 218.802 (lr:0.0001)
87290: accuracy:0.33 loss: 207.905 (lr:0.0001)
87300: accuracy:0.34 loss: 212.655 (lr:0.0001)
87310: accuracy:0.31 loss: 222.007 (lr:0.0001)
87320: accuracy:0.32 loss: 231.716 (lr:0.0001)
87330: accuracy:0.31 loss: 234.619 (lr:0.0001)
87340: accuracy:0.35 loss: 198.27 (lr:0.0001)
87350: accuracy:0.27 loss: 222.704 (lr:0.0001)
87360: accuracy:0.38 loss: 213.138 (lr:0.0001)
87370: accuracy:0.29 loss: 219.058 (lr:0.0001)
87380: accuracy:0.38 loss: 211.725 (lr:0.0001)
87390: accuracy:0.33 loss: 221.074 (lr:0.0001)
87400: accuracy:0.35 loss: 189.606 (lr:0.0001)
87410: accuracy:0.29 loss: 218.977 (lr:0.0001)
87420: accuracy:0.27 loss: 229.099 (lr:0.0001)
87430: accuracy:0.33 loss: 223.339 (lr:0.0001)
87440: accuracy:0.29 loss: 221.06 (lr:0.0001)
87450: accuracy:0.26 loss: 221.919 (lr:0.0001)
87460: accuracy:0.23 loss: 217.703 (lr:0.0001)
87470: accuracy:0.36 loss: 200.891 (lr:0.0001)
87480: accuracy:0.19 loss: 247.74 (lr:0.0001)
87490: accuracy:0.3 loss: 225.781 (lr:0.0001)
87500: accuracy:0.32 loss: 228.022 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
87500: ********* epoch 9 ********* test accuracy for all:0.246338 test loss: 256.325
87500: ********* epoch 9 ********* test accuracy for mode 0:0.0045 test loss: 432.732
87500: ********* epoch 9 ********* test accuracy for mode 1:0.0465 test loss: 408.996
87500: ********* epoch 9 ********* test accuracy for mode 2:0.0505 test loss: 270.376
87500: ********* epoch 9 ********* test accuracy for mode 24:0.236 test loss: 266.56
87500: ********* epoch 9 ********* test accuracy for mode 25:0.3205 test loss: 236.529
87500: ********* epoch 9 ********* test accuracy for mode 26:0.4675 test loss: 163.048
87500: ********* epoch 9 ********* test accuracy for mode 27:0.238 test loss: 260.772
87500: ********* epoch 9 ********* test accuracy for mode 28:0.302 test loss: 252.121
87500: ********* epoch 9 ********* test accuracy for mode 29:0.2605 test loss: 258.687
87500: ********* epoch 9 ********* test accuracy for mode 30:0.232 test loss: 254.516
87500: ********* epoch 9 ********* test accuracy for mode 31:0.185 test loss: 258.064
87500: ********* epoch 9 ********* test accuracy for mode 32:0.193 test loss: 247.407
87500: ********* epoch 9 ********* test accuracy for mode 33:0.3235 test loss: 245.84
87500: ********* epoch 9 ********* test accuracy for mode 34:0.0985 test loss: 254.154
87500: ********* epoch 9 ********* test accuracy for mode 35:0.0035 test loss: 425.566
87500: ********* epoch 9 ********* test accuracy for mode 36:0.06 test loss: 442.34
87510: accuracy:0.3 loss: 222.944 (lr:0.0001)
87520: accuracy:0.34 loss: 215.688 (lr:0.0001)
87530: accuracy:0.34 loss: 228.668 (lr:0.0001)
87540: accuracy:0.26 loss: 225.653 (lr:0.0001)
87550: accuracy:0.35 loss: 207.137 (lr:0.0001)
87560: accuracy:0.33 loss: 239.211 (lr:0.0001)
87570: accuracy:0.34 loss: 201.689 (lr:0.0001)
87580: accuracy:0.35 loss: 218.435 (lr:0.0001)
87590: accuracy:0.42 loss: 213.746 (lr:0.0001)
87600: accuracy:0.23 loss: 228.767 (lr:0.0001)
87610: accuracy:0.34 loss: 227.088 (lr:0.0001)
87620: accuracy:0.36 loss: 219.225 (lr:0.0001)
87630: accuracy:0.26 loss: 213.602 (lr:0.0001)
87640: accuracy:0.35 loss: 222.214 (lr:0.0001)
87650: accuracy:0.34 loss: 203.677 (lr:0.0001)
87660: accuracy:0.32 loss: 239.035 (lr:0.0001)
87670: accuracy:0.29 loss: 240.656 (lr:0.0001)
87680: accuracy:0.36 loss: 195.941 (lr:0.0001)
87690: accuracy:0.35 loss: 208.441 (lr:0.0001)
87700: accuracy:0.27 loss: 233.997 (lr:0.0001)
87710: accuracy:0.29 loss: 218.402 (lr:0.0001)
87720: accuracy:0.41 loss: 220.926 (lr:0.0001)
87730: accuracy:0.21 loss: 236.496 (lr:0.0001)
87740: accuracy:0.3 loss: 222.598 (lr:0.0001)
87750: accuracy:0.29 loss: 217.173 (lr:0.0001)
87760: accuracy:0.28 loss: 227.478 (lr:0.0001)
87770: accuracy:0.25 loss: 250.947 (lr:0.0001)
87780: accuracy:0.35 loss: 216.548 (lr:0.0001)
87790: accuracy:0.38 loss: 209.373 (lr:0.0001)
87800: accuracy:0.34 loss: 217.405 (lr:0.0001)
87810: accuracy:0.29 loss: 220.156 (lr:0.0001)
87820: accuracy:0.33 loss: 223.044 (lr:0.0001)
87830: accuracy:0.26 loss: 235.999 (lr:0.0001)
87840: accuracy:0.32 loss: 219.508 (lr:0.0001)
87850: accuracy:0.31 loss: 230.112 (lr:0.0001)
87860: accuracy:0.34 loss: 223.303 (lr:0.0001)
87870: accuracy:0.38 loss: 201.943 (lr:0.0001)
87880: accuracy:0.31 loss: 243.092 (lr:0.0001)
87890: accuracy:0.31 loss: 217.743 (lr:0.0001)
87900: accuracy:0.23 loss: 227.87 (lr:0.0001)
87910: accuracy:0.28 loss: 217.13 (lr:0.0001)
87920: accuracy:0.24 loss: 234.154 (lr:0.0001)
87930: accuracy:0.27 loss: 226.144 (lr:0.0001)
87940: accuracy:0.36 loss: 202.88 (lr:0.0001)
87950: accuracy:0.38 loss: 223.589 (lr:0.0001)
87960: accuracy:0.36 loss: 211.644 (lr:0.0001)
87970: accuracy:0.32 loss: 210.588 (lr:0.0001)
87980: accuracy:0.31 loss: 228.779 (lr:0.0001)
87990: accuracy:0.25 loss: 253.433 (lr:0.0001)
88000: accuracy:0.31 loss: 217.576 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
88000: ********* epoch 10 ********* test accuracy for all:0.244378 test loss: 257.746
88000: ********* epoch 10 ********* test accuracy for mode 0:0.005 test loss: 432.126
88000: ********* epoch 10 ********* test accuracy for mode 1:0.0465 test loss: 412.039
88000: ********* epoch 10 ********* test accuracy for mode 2:0.0455 test loss: 269.782
88000: ********* epoch 10 ********* test accuracy for mode 24:0.2385 test loss: 281.122
88000: ********* epoch 10 ********* test accuracy for mode 25:0.252 test loss: 255.881
88000: ********* epoch 10 ********* test accuracy for mode 26:0.4305 test loss: 167.864
88000: ********* epoch 10 ********* test accuracy for mode 27:0.2505 test loss: 273.823
88000: ********* epoch 10 ********* test accuracy for mode 28:0.264 test loss: 267.375
88000: ********* epoch 10 ********* test accuracy for mode 29:0.258 test loss: 270.343
88000: ********* epoch 10 ********* test accuracy for mode 30:0.224 test loss: 261.555
88000: ********* epoch 10 ********* test accuracy for mode 31:0.183 test loss: 260.714
88000: ********* epoch 10 ********* test accuracy for mode 32:0.2745 test loss: 243.226
88000: ********* epoch 10 ********* test accuracy for mode 33:0.2505 test loss: 247.161
88000: ********* epoch 10 ********* test accuracy for mode 34:0.1545 test loss: 248.892
88000: ********* epoch 10 ********* test accuracy for mode 35:0.0025 test loss: 427.159
88000: ********* epoch 10 ********* test accuracy for mode 36:0.0525 test loss: 462.222
88010: accuracy:0.26 loss: 205.141 (lr:0.0001)
88020: accuracy:0.34 loss: 226.388 (lr:0.0001)
88030: accuracy:0.31 loss: 229.147 (lr:0.0001)
88040: accuracy:0.34 loss: 207.233 (lr:0.0001)
88050: accuracy:0.35 loss: 233.978 (lr:0.0001)
88060: accuracy:0.31 loss: 211.197 (lr:0.0001)
88070: accuracy:0.21 loss: 211.281 (lr:0.0001)
88080: accuracy:0.28 loss: 216.397 (lr:0.0001)
88090: accuracy:0.28 loss: 239.541 (lr:0.0001)
88100: accuracy:0.33 loss: 208.078 (lr:0.0001)
88110: accuracy:0.34 loss: 222.658 (lr:0.0001)
88120: accuracy:0.34 loss: 225.098 (lr:0.0001)
88130: accuracy:0.34 loss: 216.524 (lr:0.0001)
88140: accuracy:0.25 loss: 221.965 (lr:0.0001)
88150: accuracy:0.29 loss: 222.743 (lr:0.0001)
88160: accuracy:0.25 loss: 222.12 (lr:0.0001)
88170: accuracy:0.25 loss: 209.165 (lr:0.0001)
88180: accuracy:0.34 loss: 224.633 (lr:0.0001)
88190: accuracy:0.39 loss: 208.892 (lr:0.0001)
88200: accuracy:0.35 loss: 212.748 (lr:0.0001)
88210: accuracy:0.29 loss: 232.099 (lr:0.0001)
88220: accuracy:0.32 loss: 219.887 (lr:0.0001)
88230: accuracy:0.29 loss: 224.316 (lr:0.0001)
88240: accuracy:0.24 loss: 219.589 (lr:0.0001)
88250: accuracy:0.36 loss: 208.16 (lr:0.0001)
88260: accuracy:0.34 loss: 200.769 (lr:0.0001)
88270: accuracy:0.35 loss: 220.385 (lr:0.0001)
88280: accuracy:0.36 loss: 221.065 (lr:0.0001)
88290: accuracy:0.32 loss: 204.653 (lr:0.0001)
88300: accuracy:0.25 loss: 236.042 (lr:0.0001)
88310: accuracy:0.33 loss: 207.44 (lr:0.0001)
88320: accuracy:0.29 loss: 202.844 (lr:0.0001)
88330: accuracy:0.29 loss: 219.137 (lr:0.0001)
88340: accuracy:0.35 loss: 210.278 (lr:0.0001)
88350: accuracy:0.28 loss: 231.545 (lr:0.0001)
88360: accuracy:0.26 loss: 231.927 (lr:0.0001)
88370: accuracy:0.27 loss: 235.083 (lr:0.0001)
88380: accuracy:0.31 loss: 231.198 (lr:0.0001)
88390: accuracy:0.28 loss: 218.81 (lr:0.0001)
88400: accuracy:0.29 loss: 230.164 (lr:0.0001)
88410: accuracy:0.35 loss: 216.338 (lr:0.0001)
88420: accuracy:0.37 loss: 209.481 (lr:0.0001)
88430: accuracy:0.37 loss: 200.003 (lr:0.0001)
88440: accuracy:0.38 loss: 199.134 (lr:0.0001)
88450: accuracy:0.26 loss: 230.966 (lr:0.0001)
88460: accuracy:0.32 loss: 216.333 (lr:0.0001)
88470: accuracy:0.39 loss: 206.561 (lr:0.0001)
88480: accuracy:0.3 loss: 207.774 (lr:0.0001)
88490: accuracy:0.38 loss: 204.572 (lr:0.0001)
88500: accuracy:0.27 loss: 237.809 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
88500: ********* epoch 10 ********* test accuracy for all:0.247554 test loss: 255.762
88500: ********* epoch 10 ********* test accuracy for mode 0:0.007 test loss: 427.117
88500: ********* epoch 10 ********* test accuracy for mode 1:0.045 test loss: 408.207
88500: ********* epoch 10 ********* test accuracy for mode 2:0.0285 test loss: 272.923
88500: ********* epoch 10 ********* test accuracy for mode 24:0.235 test loss: 270.778
88500: ********* epoch 10 ********* test accuracy for mode 25:0.275 test loss: 245.557
88500: ********* epoch 10 ********* test accuracy for mode 26:0.4205 test loss: 167.277
88500: ********* epoch 10 ********* test accuracy for mode 27:0.2465 test loss: 268.357
88500: ********* epoch 10 ********* test accuracy for mode 28:0.2775 test loss: 257.75
88500: ********* epoch 10 ********* test accuracy for mode 29:0.2825 test loss: 261.908
88500: ********* epoch 10 ********* test accuracy for mode 30:0.2155 test loss: 258.518
88500: ********* epoch 10 ********* test accuracy for mode 31:0.2135 test loss: 259.769
88500: ********* epoch 10 ********* test accuracy for mode 32:0.2435 test loss: 248.491
88500: ********* epoch 10 ********* test accuracy for mode 33:0.2415 test loss: 252.564
88500: ********* epoch 10 ********* test accuracy for mode 34:0.1755 test loss: 250.941
88500: ********* epoch 10 ********* test accuracy for mode 35:0.0015 test loss: 414.697
88500: ********* epoch 10 ********* test accuracy for mode 36:0.0895 test loss: 424.233
88510: accuracy:0.29 loss: 225.533 (lr:0.0001)
88520: accuracy:0.3 loss: 210.811 (lr:0.0001)
88530: accuracy:0.31 loss: 240.899 (lr:0.0001)
88540: accuracy:0.38 loss: 226.264 (lr:0.0001)
88550: accuracy:0.31 loss: 219.316 (lr:0.0001)
88560: accuracy:0.2 loss: 229.705 (lr:0.0001)
88570: accuracy:0.33 loss: 217.067 (lr:0.0001)
88580: accuracy:0.24 loss: 224.324 (lr:0.0001)
88590: accuracy:0.25 loss: 231.774 (lr:0.0001)
88600: accuracy:0.25 loss: 236.589 (lr:0.0001)
88610: accuracy:0.42 loss: 190.642 (lr:0.0001)
88620: accuracy:0.28 loss: 224.215 (lr:0.0001)
88630: accuracy:0.33 loss: 211.558 (lr:0.0001)
88640: accuracy:0.35 loss: 229.591 (lr:0.0001)
88650: accuracy:0.29 loss: 211.097 (lr:0.0001)
88660: accuracy:0.36 loss: 223.976 (lr:0.0001)
88670: accuracy:0.42 loss: 201.739 (lr:0.0001)
88680: accuracy:0.35 loss: 212.339 (lr:0.0001)
88690: accuracy:0.3 loss: 232.478 (lr:0.0001)
88700: accuracy:0.35 loss: 201.174 (lr:0.0001)
88710: accuracy:0.3 loss: 223.138 (lr:0.0001)
88720: accuracy:0.28 loss: 212.904 (lr:0.0001)
88730: accuracy:0.35 loss: 219.35 (lr:0.0001)
88740: accuracy:0.33 loss: 212.676 (lr:0.0001)
88750: accuracy:0.33 loss: 218.173 (lr:0.0001)
88760: accuracy:0.36 loss: 207.394 (lr:0.0001)
88770: accuracy:0.25 loss: 224.647 (lr:0.0001)
88780: accuracy:0.25 loss: 250.493 (lr:0.0001)
88790: accuracy:0.29 loss: 212.581 (lr:0.0001)
88800: accuracy:0.33 loss: 235.594 (lr:0.0001)
88810: accuracy:0.3 loss: 226.759 (lr:0.0001)
88820: accuracy:0.29 loss: 237.795 (lr:0.0001)
88830: accuracy:0.27 loss: 217.822 (lr:0.0001)
88840: accuracy:0.31 loss: 210.716 (lr:0.0001)
88850: accuracy:0.31 loss: 225.79 (lr:0.0001)
88860: accuracy:0.32 loss: 216.462 (lr:0.0001)
88870: accuracy:0.31 loss: 222.733 (lr:0.0001)
88880: accuracy:0.41 loss: 201.13 (lr:0.0001)
88890: accuracy:0.28 loss: 211.165 (lr:0.0001)
88900: accuracy:0.28 loss: 221.261 (lr:0.0001)
88910: accuracy:0.33 loss: 215.77 (lr:0.0001)
88920: accuracy:0.28 loss: 219.994 (lr:0.0001)
88930: accuracy:0.21 loss: 239.482 (lr:0.0001)
88940: accuracy:0.31 loss: 216.952 (lr:0.0001)
88950: accuracy:0.31 loss: 217.271 (lr:0.0001)
88960: accuracy:0.35 loss: 219.312 (lr:0.0001)
88970: accuracy:0.31 loss: 226.514 (lr:0.0001)
88980: accuracy:0.39 loss: 199.936 (lr:0.0001)
88990: accuracy:0.38 loss: 211.069 (lr:0.0001)
89000: accuracy:0.32 loss: 217.599 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
89000: ********* epoch 10 ********* test accuracy for all:0.245027 test loss: 257.223
89000: ********* epoch 10 ********* test accuracy for mode 0:0.003 test loss: 433.452
89000: ********* epoch 10 ********* test accuracy for mode 1:0.0385 test loss: 415.747
89000: ********* epoch 10 ********* test accuracy for mode 2:0.021 test loss: 268.784
89000: ********* epoch 10 ********* test accuracy for mode 24:0.2545 test loss: 265.075
89000: ********* epoch 10 ********* test accuracy for mode 25:0.297 test loss: 246.498
89000: ********* epoch 10 ********* test accuracy for mode 26:0.393 test loss: 167.888
89000: ********* epoch 10 ********* test accuracy for mode 27:0.2325 test loss: 266.313
89000: ********* epoch 10 ********* test accuracy for mode 28:0.3005 test loss: 255.069
89000: ********* epoch 10 ********* test accuracy for mode 29:0.2375 test loss: 262.949
89000: ********* epoch 10 ********* test accuracy for mode 30:0.2405 test loss: 251.655
89000: ********* epoch 10 ********* test accuracy for mode 31:0.211 test loss: 252.806
89000: ********* epoch 10 ********* test accuracy for mode 32:0.249 test loss: 242.574
89000: ********* epoch 10 ********* test accuracy for mode 33:0.231 test loss: 247.182
89000: ********* epoch 10 ********* test accuracy for mode 34:0.178 test loss: 244.082
89000: ********* epoch 10 ********* test accuracy for mode 35:0.004 test loss: 425.057
89000: ********* epoch 10 ********* test accuracy for mode 36:0.07 test loss: 447.292
89010: accuracy:0.27 loss: 243.333 (lr:0.0001)
89020: accuracy:0.28 loss: 203.86 (lr:0.0001)
89030: accuracy:0.24 loss: 239.9 (lr:0.0001)
89040: accuracy:0.28 loss: 211.033 (lr:0.0001)
89050: accuracy:0.22 loss: 224.151 (lr:0.0001)
89060: accuracy:0.29 loss: 231.473 (lr:0.0001)
89070: accuracy:0.24 loss: 216.393 (lr:0.0001)
89080: accuracy:0.33 loss: 217.397 (lr:0.0001)
89090: accuracy:0.37 loss: 216.103 (lr:0.0001)
89100: accuracy:0.34 loss: 219.464 (lr:0.0001)
89110: accuracy:0.37 loss: 206.426 (lr:0.0001)
89120: accuracy:0.39 loss: 193.774 (lr:0.0001)
89130: accuracy:0.35 loss: 218.914 (lr:0.0001)
89140: accuracy:0.32 loss: 216.467 (lr:0.0001)
89150: accuracy:0.26 loss: 237.919 (lr:0.0001)
89160: accuracy:0.37 loss: 210.048 (lr:0.0001)
89170: accuracy:0.28 loss: 218.983 (lr:0.0001)
89180: accuracy:0.3 loss: 233.738 (lr:0.0001)
89190: accuracy:0.37 loss: 208.502 (lr:0.0001)
89200: accuracy:0.31 loss: 218.798 (lr:0.0001)
89210: accuracy:0.37 loss: 201.958 (lr:0.0001)
89220: accuracy:0.29 loss: 217.117 (lr:0.0001)
89230: accuracy:0.35 loss: 212.91 (lr:0.0001)
89240: accuracy:0.42 loss: 205.345 (lr:0.0001)
89250: accuracy:0.43 loss: 228.866 (lr:0.0001)
89260: accuracy:0.33 loss: 206.04 (lr:0.0001)
89270: accuracy:0.3 loss: 223.71 (lr:0.0001)
89280: accuracy:0.31 loss: 204.754 (lr:0.0001)
89290: accuracy:0.35 loss: 214.551 (lr:0.0001)
89300: accuracy:0.37 loss: 203.969 (lr:0.0001)
89310: accuracy:0.28 loss: 205.708 (lr:0.0001)
89320: accuracy:0.33 loss: 210.803 (lr:0.0001)
89330: accuracy:0.33 loss: 217.13 (lr:0.0001)
89340: accuracy:0.3 loss: 223.137 (lr:0.0001)
89350: accuracy:0.35 loss: 202.037 (lr:0.0001)
89360: accuracy:0.29 loss: 236.013 (lr:0.0001)
89370: accuracy:0.3 loss: 214.517 (lr:0.0001)
89380: accuracy:0.31 loss: 215.546 (lr:0.0001)
89390: accuracy:0.35 loss: 215.283 (lr:0.0001)
89400: accuracy:0.35 loss: 201.997 (lr:0.0001)
89410: accuracy:0.25 loss: 220.704 (lr:0.0001)
89420: accuracy:0.34 loss: 220.994 (lr:0.0001)
89430: accuracy:0.25 loss: 229.536 (lr:0.0001)
89440: accuracy:0.27 loss: 201.146 (lr:0.0001)
89450: accuracy:0.35 loss: 213.498 (lr:0.0001)
89460: accuracy:0.28 loss: 218.838 (lr:0.0001)
89470: accuracy:0.32 loss: 210.652 (lr:0.0001)
89480: accuracy:0.33 loss: 246.945 (lr:0.0001)
89490: accuracy:0.28 loss: 237.156 (lr:0.0001)
89500: accuracy:0.23 loss: 239.409 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
89500: ********* epoch 10 ********* test accuracy for all:0.244135 test loss: 257.909
89500: ********* epoch 10 ********* test accuracy for mode 0:0.008 test loss: 431.32
89500: ********* epoch 10 ********* test accuracy for mode 1:0.0425 test loss: 415.67
89500: ********* epoch 10 ********* test accuracy for mode 2:0.0405 test loss: 262.099
89500: ********* epoch 10 ********* test accuracy for mode 24:0.2425 test loss: 278.371
89500: ********* epoch 10 ********* test accuracy for mode 25:0.2825 test loss: 255.488
89500: ********* epoch 10 ********* test accuracy for mode 26:0.388 test loss: 170.534
89500: ********* epoch 10 ********* test accuracy for mode 27:0.2455 test loss: 272.502
89500: ********* epoch 10 ********* test accuracy for mode 28:0.3135 test loss: 256.222
89500: ********* epoch 10 ********* test accuracy for mode 29:0.248 test loss: 265.446
89500: ********* epoch 10 ********* test accuracy for mode 30:0.2305 test loss: 253.782
89500: ********* epoch 10 ********* test accuracy for mode 31:0.221 test loss: 253.521
89500: ********* epoch 10 ********* test accuracy for mode 32:0.201 test loss: 245.666
89500: ********* epoch 10 ********* test accuracy for mode 33:0.2655 test loss: 244.883
89500: ********* epoch 10 ********* test accuracy for mode 34:0.175 test loss: 244.544
89500: ********* epoch 10 ********* test accuracy for mode 35:0.0025 test loss: 423.376
89500: ********* epoch 10 ********* test accuracy for mode 36:0.053 test loss: 460.682
89510: accuracy:0.36 loss: 210.033 (lr:0.0001)
89520: accuracy:0.29 loss: 213.859 (lr:0.0001)
89530: accuracy:0.26 loss: 235.429 (lr:0.0001)
89540: accuracy:0.33 loss: 199.577 (lr:0.0001)
89550: accuracy:0.32 loss: 229.128 (lr:0.0001)
89560: accuracy:0.36 loss: 194.59 (lr:0.0001)
89570: accuracy:0.23 loss: 223.69 (lr:0.0001)
89580: accuracy:0.18 loss: 243.557 (lr:0.0001)
89590: accuracy:0.28 loss: 238.768 (lr:0.0001)
89600: accuracy:0.3 loss: 212.197 (lr:0.0001)
89610: accuracy:0.34 loss: 207.328 (lr:0.0001)
89620: accuracy:0.28 loss: 254.409 (lr:0.0001)
89630: accuracy:0.36 loss: 204.592 (lr:0.0001)
89640: accuracy:0.27 loss: 232.724 (lr:0.0001)
89650: accuracy:0.35 loss: 210.905 (lr:0.0001)
89660: accuracy:0.34 loss: 221.856 (lr:0.0001)
89670: accuracy:0.34 loss: 221.68 (lr:0.0001)
89680: accuracy:0.27 loss: 228.631 (lr:0.0001)
89690: accuracy:0.36 loss: 214.835 (lr:0.0001)
89700: accuracy:0.32 loss: 227.022 (lr:0.0001)
89710: accuracy:0.28 loss: 220.107 (lr:0.0001)
89720: accuracy:0.35 loss: 235.679 (lr:0.0001)
89730: accuracy:0.31 loss: 201.262 (lr:0.0001)
89740: accuracy:0.3 loss: 233.363 (lr:0.0001)
89750: accuracy:0.35 loss: 210.735 (lr:0.0001)
89760: accuracy:0.34 loss: 205.355 (lr:0.0001)
89770: accuracy:0.32 loss: 210.655 (lr:0.0001)
89780: accuracy:0.3 loss: 215.917 (lr:0.0001)
89790: accuracy:0.32 loss: 221.639 (lr:0.0001)
89800: accuracy:0.28 loss: 239.13 (lr:0.0001)
89810: accuracy:0.29 loss: 222.043 (lr:0.0001)
89820: accuracy:0.27 loss: 241.954 (lr:0.0001)
89830: accuracy:0.28 loss: 233.475 (lr:0.0001)
89840: accuracy:0.39 loss: 201.517 (lr:0.0001)
89850: accuracy:0.29 loss: 225.106 (lr:0.0001)
89860: accuracy:0.36 loss: 206.889 (lr:0.0001)
89870: accuracy:0.29 loss: 226.958 (lr:0.0001)
89880: accuracy:0.25 loss: 232.107 (lr:0.0001)
89890: accuracy:0.26 loss: 231.246 (lr:0.0001)
89900: accuracy:0.3 loss: 218.772 (lr:0.0001)
89910: accuracy:0.3 loss: 220.015 (lr:0.0001)
89920: accuracy:0.3 loss: 225.226 (lr:0.0001)
89930: accuracy:0.24 loss: 221.161 (lr:0.0001)
89940: accuracy:0.29 loss: 221.394 (lr:0.0001)
89950: accuracy:0.24 loss: 220.721 (lr:0.0001)
89960: accuracy:0.27 loss: 219.121 (lr:0.0001)
89970: accuracy:0.32 loss: 211.274 (lr:0.0001)
89980: accuracy:0.33 loss: 217.377 (lr:0.0001)
89990: accuracy:0.28 loss: 224.304 (lr:0.0001)
90000: accuracy:0.31 loss: 214.914 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
90000: ********* epoch 10 ********* test accuracy for all:0.245338 test loss: 256.592
90000: ********* epoch 10 ********* test accuracy for mode 0:0.009 test loss: 424.497
90000: ********* epoch 10 ********* test accuracy for mode 1:0.037 test loss: 416.266
90000: ********* epoch 10 ********* test accuracy for mode 2:0.0475 test loss: 261.742
90000: ********* epoch 10 ********* test accuracy for mode 24:0.2405 test loss: 274.652
90000: ********* epoch 10 ********* test accuracy for mode 25:0.2925 test loss: 253.502
90000: ********* epoch 10 ********* test accuracy for mode 26:0.382 test loss: 176.396
90000: ********* epoch 10 ********* test accuracy for mode 27:0.2105 test loss: 282.897
90000: ********* epoch 10 ********* test accuracy for mode 28:0.2615 test loss: 263.229
90000: ********* epoch 10 ********* test accuracy for mode 29:0.274 test loss: 260.097
90000: ********* epoch 10 ********* test accuracy for mode 30:0.2425 test loss: 250.886
90000: ********* epoch 10 ********* test accuracy for mode 31:0.1775 test loss: 252.237
90000: ********* epoch 10 ********* test accuracy for mode 32:0.3075 test loss: 235.881
90000: ********* epoch 10 ********* test accuracy for mode 33:0.211 test loss: 249.088
90000: ********* epoch 10 ********* test accuracy for mode 34:0.17 test loss: 247.164
90000: ********* epoch 10 ********* test accuracy for mode 35:0.012 test loss: 403.267
90000: ********* epoch 10 ********* test accuracy for mode 36:0.057 test loss: 450.091
90010: accuracy:0.28 loss: 229.018 (lr:0.0001)
90020: accuracy:0.39 loss: 202.083 (lr:0.0001)
90030: accuracy:0.37 loss: 214.822 (lr:0.0001)
90040: accuracy:0.4 loss: 206.987 (lr:0.0001)
90050: accuracy:0.26 loss: 218.386 (lr:0.0001)
90060: accuracy:0.31 loss: 210.836 (lr:0.0001)
90070: accuracy:0.31 loss: 232.219 (lr:0.0001)
90080: accuracy:0.23 loss: 232.783 (lr:0.0001)
90090: accuracy:0.42 loss: 201.194 (lr:0.0001)
90100: accuracy:0.28 loss: 240.051 (lr:0.0001)
90110: accuracy:0.26 loss: 222.623 (lr:0.0001)
90120: accuracy:0.33 loss: 212.271 (lr:0.0001)
90130: accuracy:0.36 loss: 210.778 (lr:0.0001)
90140: accuracy:0.31 loss: 216.758 (lr:0.0001)
90150: accuracy:0.27 loss: 226.071 (lr:0.0001)
90160: accuracy:0.36 loss: 216.599 (lr:0.0001)
90170: accuracy:0.35 loss: 210.098 (lr:0.0001)
90180: accuracy:0.38 loss: 223.084 (lr:0.0001)
90190: accuracy:0.32 loss: 222.742 (lr:0.0001)
90200: accuracy:0.26 loss: 206.332 (lr:0.0001)
90210: accuracy:0.3 loss: 221.735 (lr:0.0001)
90220: accuracy:0.39 loss: 185.189 (lr:0.0001)
90230: accuracy:0.28 loss: 219.755 (lr:0.0001)
90240: accuracy:0.3 loss: 225.169 (lr:0.0001)
90250: accuracy:0.4 loss: 198.771 (lr:0.0001)
90260: accuracy:0.22 loss: 225.577 (lr:0.0001)
90270: accuracy:0.3 loss: 213.316 (lr:0.0001)
90280: accuracy:0.35 loss: 232.78 (lr:0.0001)
90290: accuracy:0.3 loss: 225.394 (lr:0.0001)
90300: accuracy:0.3 loss: 220.633 (lr:0.0001)
90310: accuracy:0.32 loss: 210.822 (lr:0.0001)
90320: accuracy:0.31 loss: 214.397 (lr:0.0001)
90330: accuracy:0.33 loss: 205.518 (lr:0.0001)
90340: accuracy:0.31 loss: 216.743 (lr:0.0001)
90350: accuracy:0.44 loss: 201.212 (lr:0.0001)
90360: accuracy:0.31 loss: 228.225 (lr:0.0001)
90370: accuracy:0.27 loss: 238.08 (lr:0.0001)
90380: accuracy:0.28 loss: 220.934 (lr:0.0001)
90390: accuracy:0.32 loss: 211.658 (lr:0.0001)
90400: accuracy:0.38 loss: 209.907 (lr:0.0001)
90410: accuracy:0.32 loss: 216.644 (lr:0.0001)
90420: accuracy:0.3 loss: 223.604 (lr:0.0001)
90430: accuracy:0.3 loss: 220.85 (lr:0.0001)
90440: accuracy:0.32 loss: 202.061 (lr:0.0001)
90450: accuracy:0.28 loss: 219.08 (lr:0.0001)
90460: accuracy:0.35 loss: 208.763 (lr:0.0001)
90470: accuracy:0.3 loss: 220.61 (lr:0.0001)
90480: accuracy:0.39 loss: 198.548 (lr:0.0001)
90490: accuracy:0.35 loss: 196.138 (lr:0.0001)
90500: accuracy:0.35 loss: 200.679 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
90500: ********* epoch 10 ********* test accuracy for all:0.245108 test loss: 257.816
90500: ********* epoch 10 ********* test accuracy for mode 0:0.0125 test loss: 426.372
90500: ********* epoch 10 ********* test accuracy for mode 1:0.0435 test loss: 417.457
90500: ********* epoch 10 ********* test accuracy for mode 2:0.0515 test loss: 267.521
90500: ********* epoch 10 ********* test accuracy for mode 24:0.2355 test loss: 271.825
90500: ********* epoch 10 ********* test accuracy for mode 25:0.3025 test loss: 245.671
90500: ********* epoch 10 ********* test accuracy for mode 26:0.348 test loss: 173.153
90500: ********* epoch 10 ********* test accuracy for mode 27:0.2825 test loss: 265.289
90500: ********* epoch 10 ********* test accuracy for mode 28:0.268 test loss: 257.477
90500: ********* epoch 10 ********* test accuracy for mode 29:0.311 test loss: 258.34
90500: ********* epoch 10 ********* test accuracy for mode 30:0.2065 test loss: 256.111
90500: ********* epoch 10 ********* test accuracy for mode 31:0.233 test loss: 256.732
90500: ********* epoch 10 ********* test accuracy for mode 32:0.181 test loss: 247.295
90500: ********* epoch 10 ********* test accuracy for mode 33:0.284 test loss: 248.293
90500: ********* epoch 10 ********* test accuracy for mode 34:0.108 test loss: 253.491
90500: ********* epoch 10 ********* test accuracy for mode 35:0.013 test loss: 419.417
90500: ********* epoch 10 ********* test accuracy for mode 36:0.0475 test loss: 452.907
90510: accuracy:0.34 loss: 203.649 (lr:0.0001)
90520: accuracy:0.27 loss: 223.028 (lr:0.0001)
90530: accuracy:0.32 loss: 220.454 (lr:0.0001)
90540: accuracy:0.4 loss: 203.745 (lr:0.0001)
90550: accuracy:0.36 loss: 205.575 (lr:0.0001)
90560: accuracy:0.33 loss: 223.171 (lr:0.0001)
90570: accuracy:0.36 loss: 214.278 (lr:0.0001)
90580: accuracy:0.32 loss: 226.948 (lr:0.0001)
90590: accuracy:0.27 loss: 204.736 (lr:0.0001)
90600: accuracy:0.33 loss: 223.21 (lr:0.0001)
90610: accuracy:0.29 loss: 206.155 (lr:0.0001)
90620: accuracy:0.27 loss: 217.142 (lr:0.0001)
90630: accuracy:0.3 loss: 222.254 (lr:0.0001)
90640: accuracy:0.25 loss: 236.692 (lr:0.0001)
90650: accuracy:0.33 loss: 231.275 (lr:0.0001)
90660: accuracy:0.34 loss: 213.936 (lr:0.0001)
90670: accuracy:0.39 loss: 198.671 (lr:0.0001)
90680: accuracy:0.35 loss: 216.594 (lr:0.0001)
90690: accuracy:0.3 loss: 213.218 (lr:0.0001)
90700: accuracy:0.3 loss: 226.299 (lr:0.0001)
90710: accuracy:0.39 loss: 217.838 (lr:0.0001)
90720: accuracy:0.33 loss: 214.543 (lr:0.0001)
90730: accuracy:0.26 loss: 231.4 (lr:0.0001)
90740: accuracy:0.29 loss: 222.925 (lr:0.0001)
90750: accuracy:0.32 loss: 206.636 (lr:0.0001)
90760: accuracy:0.32 loss: 226.938 (lr:0.0001)
90770: accuracy:0.33 loss: 214.573 (lr:0.0001)
90780: accuracy:0.27 loss: 208.848 (lr:0.0001)
90790: accuracy:0.27 loss: 219.352 (lr:0.0001)
90800: accuracy:0.34 loss: 220.527 (lr:0.0001)
90810: accuracy:0.36 loss: 216.562 (lr:0.0001)
90820: accuracy:0.31 loss: 235.589 (lr:0.0001)
90830: accuracy:0.29 loss: 232.777 (lr:0.0001)
90840: accuracy:0.31 loss: 220.18 (lr:0.0001)
90850: accuracy:0.32 loss: 216.062 (lr:0.0001)
90860: accuracy:0.22 loss: 227.911 (lr:0.0001)
90870: accuracy:0.29 loss: 228.202 (lr:0.0001)
90880: accuracy:0.28 loss: 235.29 (lr:0.0001)
90890: accuracy:0.39 loss: 215.699 (lr:0.0001)
90900: accuracy:0.27 loss: 228.262 (lr:0.0001)
90910: accuracy:0.31 loss: 207.598 (lr:0.0001)
90920: accuracy:0.35 loss: 221.858 (lr:0.0001)
90930: accuracy:0.38 loss: 196.893 (lr:0.0001)
90940: accuracy:0.23 loss: 228.765 (lr:0.0001)
90950: accuracy:0.27 loss: 224.486 (lr:0.0001)
90960: accuracy:0.31 loss: 224.736 (lr:0.0001)
90970: accuracy:0.29 loss: 217.107 (lr:0.0001)
90980: accuracy:0.27 loss: 232.53 (lr:0.0001)
90990: accuracy:0.33 loss: 242.133 (lr:0.0001)
91000: accuracy:0.33 loss: 200.926 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
91000: ********* epoch 10 ********* test accuracy for all:0.250446 test loss: 254.844
91000: ********* epoch 10 ********* test accuracy for mode 0:0.0135 test loss: 425.853
91000: ********* epoch 10 ********* test accuracy for mode 1:0.0455 test loss: 415.199
91000: ********* epoch 10 ********* test accuracy for mode 2:0.045 test loss: 270.251
91000: ********* epoch 10 ********* test accuracy for mode 24:0.252 test loss: 261.765
91000: ********* epoch 10 ********* test accuracy for mode 25:0.342 test loss: 233.71
91000: ********* epoch 10 ********* test accuracy for mode 26:0.404 test loss: 168.374
91000: ********* epoch 10 ********* test accuracy for mode 27:0.268 test loss: 258.121
91000: ********* epoch 10 ********* test accuracy for mode 28:0.295 test loss: 253.286
91000: ********* epoch 10 ********* test accuracy for mode 29:0.2475 test loss: 261.311
91000: ********* epoch 10 ********* test accuracy for mode 30:0.2715 test loss: 252.78
91000: ********* epoch 10 ********* test accuracy for mode 31:0.172 test loss: 261.109
91000: ********* epoch 10 ********* test accuracy for mode 32:0.2005 test loss: 252.653
91000: ********* epoch 10 ********* test accuracy for mode 33:0.2285 test loss: 254.896
91000: ********* epoch 10 ********* test accuracy for mode 34:0.1685 test loss: 252.431
91000: ********* epoch 10 ********* test accuracy for mode 35:0.007 test loss: 418.766
91000: ********* epoch 10 ********* test accuracy for mode 36:0.0945 test loss: 433.677
91010: accuracy:0.26 loss: 227.545 (lr:0.0001)
91020: accuracy:0.33 loss: 214.546 (lr:0.0001)
91030: accuracy:0.36 loss: 201.426 (lr:0.0001)
91040: accuracy:0.27 loss: 243.637 (lr:0.0001)
91050: accuracy:0.35 loss: 218.394 (lr:0.0001)
91060: accuracy:0.25 loss: 216.046 (lr:0.0001)
91070: accuracy:0.22 loss: 238.972 (lr:0.0001)
91080: accuracy:0.38 loss: 215.801 (lr:0.0001)
91090: accuracy:0.27 loss: 227.41 (lr:0.0001)
91100: accuracy:0.31 loss: 233.99 (lr:0.0001)
91110: accuracy:0.28 loss: 228.141 (lr:0.0001)
91120: accuracy:0.3 loss: 205.605 (lr:0.0001)
91130: accuracy:0.32 loss: 223.895 (lr:0.0001)
91140: accuracy:0.26 loss: 223.268 (lr:0.0001)
91150: accuracy:0.3 loss: 226.576 (lr:0.0001)
91160: accuracy:0.32 loss: 222.435 (lr:0.0001)
91170: accuracy:0.33 loss: 208.264 (lr:0.0001)
91180: accuracy:0.28 loss: 222.045 (lr:0.0001)
91190: accuracy:0.32 loss: 209.921 (lr:0.0001)
91200: accuracy:0.36 loss: 210.219 (lr:0.0001)
91210: accuracy:0.36 loss: 212.0 (lr:0.0001)
91220: accuracy:0.27 loss: 228.545 (lr:0.0001)
91230: accuracy:0.33 loss: 224.536 (lr:0.0001)
91240: accuracy:0.3 loss: 214.442 (lr:0.0001)
91250: accuracy:0.34 loss: 207.546 (lr:0.0001)
91260: accuracy:0.35 loss: 222.323 (lr:0.0001)
91270: accuracy:0.26 loss: 210.993 (lr:0.0001)
91280: accuracy:0.31 loss: 222.405 (lr:0.0001)
91290: accuracy:0.3 loss: 231.296 (lr:0.0001)
91300: accuracy:0.35 loss: 198.924 (lr:0.0001)
91310: accuracy:0.27 loss: 231.959 (lr:0.0001)
91320: accuracy:0.32 loss: 222.967 (lr:0.0001)
91330: accuracy:0.29 loss: 228.892 (lr:0.0001)
91340: accuracy:0.31 loss: 219.727 (lr:0.0001)
91350: accuracy:0.27 loss: 229.094 (lr:0.0001)
91360: accuracy:0.3 loss: 221.729 (lr:0.0001)
91370: accuracy:0.38 loss: 211.5 (lr:0.0001)
91380: accuracy:0.44 loss: 196.349 (lr:0.0001)
91390: accuracy:0.38 loss: 195.388 (lr:0.0001)
91400: accuracy:0.32 loss: 209.27 (lr:0.0001)
91410: accuracy:0.36 loss: 206.392 (lr:0.0001)
91420: accuracy:0.33 loss: 221.443 (lr:0.0001)
91430: accuracy:0.31 loss: 213.006 (lr:0.0001)
91440: accuracy:0.36 loss: 218.767 (lr:0.0001)
91450: accuracy:0.36 loss: 213.545 (lr:0.0001)
91460: accuracy:0.36 loss: 195.061 (lr:0.0001)
91470: accuracy:0.26 loss: 230.612 (lr:0.0001)
91480: accuracy:0.3 loss: 215.102 (lr:0.0001)
91490: accuracy:0.27 loss: 237.43 (lr:0.0001)
91500: accuracy:0.28 loss: 213.397 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
91500: ********* epoch 10 ********* test accuracy for all:0.246973 test loss: 255.362
91500: ********* epoch 10 ********* test accuracy for mode 0:0.011 test loss: 432.304
91500: ********* epoch 10 ********* test accuracy for mode 1:0.044 test loss: 418.651
91500: ********* epoch 10 ********* test accuracy for mode 2:0.026 test loss: 276.452
91500: ********* epoch 10 ********* test accuracy for mode 24:0.223 test loss: 271.845
91500: ********* epoch 10 ********* test accuracy for mode 25:0.316 test loss: 241.852
91500: ********* epoch 10 ********* test accuracy for mode 26:0.433 test loss: 164.794
91500: ********* epoch 10 ********* test accuracy for mode 27:0.265 test loss: 256.395
91500: ********* epoch 10 ********* test accuracy for mode 28:0.3095 test loss: 243.557
91500: ********* epoch 10 ********* test accuracy for mode 29:0.289 test loss: 252.046
91500: ********* epoch 10 ********* test accuracy for mode 30:0.2665 test loss: 246.195
91500: ********* epoch 10 ********* test accuracy for mode 31:0.177 test loss: 257.468
91500: ********* epoch 10 ********* test accuracy for mode 32:0.218 test loss: 245.227
91500: ********* epoch 10 ********* test accuracy for mode 33:0.2515 test loss: 250.745
91500: ********* epoch 10 ********* test accuracy for mode 34:0.15 test loss: 256.885
91500: ********* epoch 10 ********* test accuracy for mode 35:0.006 test loss: 429.078
91500: ********* epoch 10 ********* test accuracy for mode 36:0.0785 test loss: 437.424
91510: accuracy:0.39 loss: 209.701 (lr:0.0001)
91520: accuracy:0.22 loss: 234.874 (lr:0.0001)
91530: accuracy:0.26 loss: 245.237 (lr:0.0001)
91540: accuracy:0.35 loss: 234.552 (lr:0.0001)
91550: accuracy:0.29 loss: 224.261 (lr:0.0001)
91560: accuracy:0.33 loss: 236.064 (lr:0.0001)
91570: accuracy:0.38 loss: 215.361 (lr:0.0001)
91580: accuracy:0.24 loss: 229.855 (lr:0.0001)
91590: accuracy:0.3 loss: 221.34 (lr:0.0001)
91600: accuracy:0.31 loss: 208.006 (lr:0.0001)
91610: accuracy:0.28 loss: 224.142 (lr:0.0001)
91620: accuracy:0.28 loss: 223.742 (lr:0.0001)
91630: accuracy:0.37 loss: 237.119 (lr:0.0001)
91640: accuracy:0.32 loss: 231.296 (lr:0.0001)
91650: accuracy:0.35 loss: 211.93 (lr:0.0001)
91660: accuracy:0.23 loss: 234.371 (lr:0.0001)
91670: accuracy:0.26 loss: 218.417 (lr:0.0001)
91680: accuracy:0.35 loss: 207.487 (lr:0.0001)
91690: accuracy:0.24 loss: 231.305 (lr:0.0001)
91700: accuracy:0.32 loss: 232.444 (lr:0.0001)
91710: accuracy:0.32 loss: 220.149 (lr:0.0001)
91720: accuracy:0.36 loss: 219.097 (lr:0.0001)
91730: accuracy:0.4 loss: 208.194 (lr:0.0001)
91740: accuracy:0.26 loss: 227.803 (lr:0.0001)
91750: accuracy:0.35 loss: 214.852 (lr:0.0001)
91760: accuracy:0.3 loss: 221.08 (lr:0.0001)
91770: accuracy:0.32 loss: 218.934 (lr:0.0001)
91780: accuracy:0.36 loss: 196.899 (lr:0.0001)
91790: accuracy:0.29 loss: 230.357 (lr:0.0001)
91800: accuracy:0.34 loss: 191.184 (lr:0.0001)
91810: accuracy:0.29 loss: 232.473 (lr:0.0001)
91820: accuracy:0.33 loss: 232.644 (lr:0.0001)
91830: accuracy:0.29 loss: 231.015 (lr:0.0001)
91840: accuracy:0.35 loss: 205.001 (lr:0.0001)
91850: accuracy:0.28 loss: 223.47 (lr:0.0001)
91860: accuracy:0.36 loss: 206.592 (lr:0.0001)
91870: accuracy:0.32 loss: 217.775 (lr:0.0001)
91880: accuracy:0.33 loss: 200.892 (lr:0.0001)
91890: accuracy:0.45 loss: 210.417 (lr:0.0001)
91900: accuracy:0.28 loss: 230.768 (lr:0.0001)
91910: accuracy:0.45 loss: 197.54 (lr:0.0001)
91920: accuracy:0.34 loss: 223.044 (lr:0.0001)
91930: accuracy:0.35 loss: 219.08 (lr:0.0001)
91940: accuracy:0.29 loss: 218.498 (lr:0.0001)
91950: accuracy:0.32 loss: 224.436 (lr:0.0001)
91960: accuracy:0.35 loss: 216.829 (lr:0.0001)
91970: accuracy:0.37 loss: 222.323 (lr:0.0001)
91980: accuracy:0.32 loss: 227.971 (lr:0.0001)
91990: accuracy:0.36 loss: 211.003 (lr:0.0001)
92000: accuracy:0.29 loss: 224.219 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
92000: ********* epoch 10 ********* test accuracy for all:0.250473 test loss: 255.137
92000: ********* epoch 10 ********* test accuracy for mode 0:0.009 test loss: 420.744
92000: ********* epoch 10 ********* test accuracy for mode 1:0.049 test loss: 407.954
92000: ********* epoch 10 ********* test accuracy for mode 2:0.0345 test loss: 275.581
92000: ********* epoch 10 ********* test accuracy for mode 24:0.2585 test loss: 255.344
92000: ********* epoch 10 ********* test accuracy for mode 25:0.33 test loss: 233.767
92000: ********* epoch 10 ********* test accuracy for mode 26:0.4155 test loss: 166.336
92000: ********* epoch 10 ********* test accuracy for mode 27:0.2465 test loss: 257.612
92000: ********* epoch 10 ********* test accuracy for mode 28:0.321 test loss: 243.67
92000: ********* epoch 10 ********* test accuracy for mode 29:0.2615 test loss: 250.396
92000: ********* epoch 10 ********* test accuracy for mode 30:0.2385 test loss: 243.598
92000: ********* epoch 10 ********* test accuracy for mode 31:0.253 test loss: 246.066
92000: ********* epoch 10 ********* test accuracy for mode 32:0.1825 test loss: 243.228
92000: ********* epoch 10 ********* test accuracy for mode 33:0.294 test loss: 245.522
92000: ********* epoch 10 ********* test accuracy for mode 34:0.1435 test loss: 255.129
92000: ********* epoch 10 ********* test accuracy for mode 35:0.003 test loss: 410.563
92000: ********* epoch 10 ********* test accuracy for mode 36:0.2185 test loss: 422.902
92010: accuracy:0.34 loss: 210.879 (lr:0.0001)
92020: accuracy:0.33 loss: 197.831 (lr:0.0001)
92030: accuracy:0.32 loss: 209.831 (lr:0.0001)
92040: accuracy:0.21 loss: 219.398 (lr:0.0001)
92050: accuracy:0.21 loss: 243.904 (lr:0.0001)
92060: accuracy:0.29 loss: 228.28 (lr:0.0001)
92070: accuracy:0.37 loss: 234.422 (lr:0.0001)
92080: accuracy:0.36 loss: 209.13 (lr:0.0001)
92090: accuracy:0.23 loss: 223.927 (lr:0.0001)
92100: accuracy:0.34 loss: 216.246 (lr:0.0001)
92110: accuracy:0.29 loss: 228.045 (lr:0.0001)
92120: accuracy:0.38 loss: 201.521 (lr:0.0001)
92130: accuracy:0.37 loss: 234.336 (lr:0.0001)
92140: accuracy:0.28 loss: 236.443 (lr:0.0001)
92150: accuracy:0.32 loss: 237.547 (lr:0.0001)
92160: accuracy:0.33 loss: 230.677 (lr:0.0001)
92170: accuracy:0.25 loss: 232.24 (lr:0.0001)
92180: accuracy:0.37 loss: 205.312 (lr:0.0001)
92190: accuracy:0.39 loss: 213.002 (lr:0.0001)
92200: accuracy:0.24 loss: 247.434 (lr:0.0001)
92210: accuracy:0.28 loss: 228.556 (lr:0.0001)
92220: accuracy:0.35 loss: 213.42 (lr:0.0001)
92230: accuracy:0.36 loss: 192.503 (lr:0.0001)
92240: accuracy:0.29 loss: 223.099 (lr:0.0001)
92250: accuracy:0.28 loss: 223.391 (lr:0.0001)
92260: accuracy:0.27 loss: 224.704 (lr:0.0001)
92270: accuracy:0.4 loss: 205.09 (lr:0.0001)
92280: accuracy:0.31 loss: 220.863 (lr:0.0001)
92290: accuracy:0.29 loss: 226.608 (lr:0.0001)
92300: accuracy:0.29 loss: 227.569 (lr:0.0001)
92310: accuracy:0.34 loss: 209.855 (lr:0.0001)
92320: accuracy:0.46 loss: 202.704 (lr:0.0001)
92330: accuracy:0.32 loss: 225.008 (lr:0.0001)
92340: accuracy:0.29 loss: 218.889 (lr:0.0001)
92350: accuracy:0.28 loss: 232.499 (lr:0.0001)
92360: accuracy:0.3 loss: 223.406 (lr:0.0001)
92370: accuracy:0.24 loss: 206.359 (lr:0.0001)
92380: accuracy:0.29 loss: 223.588 (lr:0.0001)
92390: accuracy:0.32 loss: 218.701 (lr:0.0001)
92400: accuracy:0.36 loss: 216.589 (lr:0.0001)
92410: accuracy:0.33 loss: 215.655 (lr:0.0001)
92420: accuracy:0.37 loss: 203.712 (lr:0.0001)
92430: accuracy:0.34 loss: 225.767 (lr:0.0001)
92440: accuracy:0.25 loss: 235.365 (lr:0.0001)
92450: accuracy:0.33 loss: 225.823 (lr:0.0001)
92460: accuracy:0.37 loss: 206.686 (lr:0.0001)
92470: accuracy:0.32 loss: 211.083 (lr:0.0001)
92480: accuracy:0.33 loss: 218.699 (lr:0.0001)
92490: accuracy:0.29 loss: 219.624 (lr:0.0001)
92500: accuracy:0.33 loss: 206.81 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
92500: ********* epoch 10 ********* test accuracy for all:0.241419 test loss: 255.67
92500: ********* epoch 10 ********* test accuracy for mode 0:0.0095 test loss: 411.086
92500: ********* epoch 10 ********* test accuracy for mode 1:0.057 test loss: 397.587
92500: ********* epoch 10 ********* test accuracy for mode 2:0.048 test loss: 272.889
92500: ********* epoch 10 ********* test accuracy for mode 24:0.235 test loss: 265.751
92500: ********* epoch 10 ********* test accuracy for mode 25:0.2775 test loss: 248.305
92500: ********* epoch 10 ********* test accuracy for mode 26:0.3665 test loss: 177.496
92500: ********* epoch 10 ********* test accuracy for mode 27:0.21 test loss: 282.499
92500: ********* epoch 10 ********* test accuracy for mode 28:0.257 test loss: 267.001
92500: ********* epoch 10 ********* test accuracy for mode 29:0.28 test loss: 267.333
92500: ********* epoch 10 ********* test accuracy for mode 30:0.2245 test loss: 260.327
92500: ********* epoch 10 ********* test accuracy for mode 31:0.221 test loss: 259.691
92500: ********* epoch 10 ********* test accuracy for mode 32:0.164 test loss: 253.069
92500: ********* epoch 10 ********* test accuracy for mode 33:0.274 test loss: 252.458
92500: ********* epoch 10 ********* test accuracy for mode 34:0.1795 test loss: 252.475
92500: ********* epoch 10 ********* test accuracy for mode 35:0.01 test loss: 391.175
92500: ********* epoch 10 ********* test accuracy for mode 36:0.0795 test loss: 413.629
92510: accuracy:0.31 loss: 231.448 (lr:0.0001)
92520: accuracy:0.36 loss: 202.65 (lr:0.0001)
92530: accuracy:0.37 loss: 221.829 (lr:0.0001)
92540: accuracy:0.29 loss: 210.884 (lr:0.0001)
92550: accuracy:0.32 loss: 225.559 (lr:0.0001)
92560: accuracy:0.3 loss: 205.709 (lr:0.0001)
92570: accuracy:0.29 loss: 222.365 (lr:0.0001)
92580: accuracy:0.34 loss: 218.28 (lr:0.0001)
92590: accuracy:0.28 loss: 225.644 (lr:0.0001)
92600: accuracy:0.31 loss: 226.902 (lr:0.0001)
92610: accuracy:0.28 loss: 235.507 (lr:0.0001)
92620: accuracy:0.34 loss: 227.714 (lr:0.0001)
92630: accuracy:0.31 loss: 223.959 (lr:0.0001)
92640: accuracy:0.31 loss: 192.529 (lr:0.0001)
92650: accuracy:0.28 loss: 232.412 (lr:0.0001)
92660: accuracy:0.37 loss: 213.403 (lr:0.0001)
92670: accuracy:0.35 loss: 230.996 (lr:0.0001)
92680: accuracy:0.32 loss: 213.423 (lr:0.0001)
92690: accuracy:0.31 loss: 214.207 (lr:0.0001)
92700: accuracy:0.34 loss: 220.149 (lr:0.0001)
92710: accuracy:0.21 loss: 243.417 (lr:0.0001)
92720: accuracy:0.28 loss: 227.534 (lr:0.0001)
92730: accuracy:0.22 loss: 228.272 (lr:0.0001)
92740: accuracy:0.32 loss: 221.144 (lr:0.0001)
92750: accuracy:0.31 loss: 230.364 (lr:0.0001)
92760: accuracy:0.37 loss: 211.953 (lr:0.0001)
92770: accuracy:0.23 loss: 234.063 (lr:0.0001)
92780: accuracy:0.26 loss: 224.703 (lr:0.0001)
92790: accuracy:0.34 loss: 208.545 (lr:0.0001)
92800: accuracy:0.28 loss: 207.166 (lr:0.0001)
92810: accuracy:0.38 loss: 215.637 (lr:0.0001)
92820: accuracy:0.24 loss: 229.476 (lr:0.0001)
92830: accuracy:0.28 loss: 221.547 (lr:0.0001)
92840: accuracy:0.32 loss: 211.368 (lr:0.0001)
92850: accuracy:0.37 loss: 203.986 (lr:0.0001)
92860: accuracy:0.33 loss: 218.859 (lr:0.0001)
92870: accuracy:0.38 loss: 212.07 (lr:0.0001)
92880: accuracy:0.33 loss: 228.977 (lr:0.0001)
92890: accuracy:0.33 loss: 232.566 (lr:0.0001)
92900: accuracy:0.27 loss: 225.892 (lr:0.0001)
92910: accuracy:0.32 loss: 239.299 (lr:0.0001)
92920: accuracy:0.34 loss: 210.849 (lr:0.0001)
92930: accuracy:0.39 loss: 201.419 (lr:0.0001)
92940: accuracy:0.39 loss: 199.36 (lr:0.0001)
92950: accuracy:0.27 loss: 221.775 (lr:0.0001)
92960: accuracy:0.29 loss: 221.647 (lr:0.0001)
92970: accuracy:0.25 loss: 230.945 (lr:0.0001)
92980: accuracy:0.27 loss: 223.994 (lr:0.0001)
92990: accuracy:0.21 loss: 254.552 (lr:0.0001)
93000: accuracy:0.3 loss: 202.06 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
93000: ********* epoch 10 ********* test accuracy for all:0.248108 test loss: 254.69
93000: ********* epoch 10 ********* test accuracy for mode 0:0.0065 test loss: 413.349
93000: ********* epoch 10 ********* test accuracy for mode 1:0.0545 test loss: 400.588
93000: ********* epoch 10 ********* test accuracy for mode 2:0.051 test loss: 266.747
93000: ********* epoch 10 ********* test accuracy for mode 24:0.215 test loss: 274.307
93000: ********* epoch 10 ********* test accuracy for mode 25:0.2625 test loss: 255.285
93000: ********* epoch 10 ********* test accuracy for mode 26:0.4995 test loss: 167.484
93000: ********* epoch 10 ********* test accuracy for mode 27:0.253 test loss: 267.976
93000: ********* epoch 10 ********* test accuracy for mode 28:0.2795 test loss: 258.406
93000: ********* epoch 10 ********* test accuracy for mode 29:0.264 test loss: 260.485
93000: ********* epoch 10 ********* test accuracy for mode 30:0.2735 test loss: 247.11
93000: ********* epoch 10 ********* test accuracy for mode 31:0.22 test loss: 252.015
93000: ********* epoch 10 ********* test accuracy for mode 32:0.2065 test loss: 244.736
93000: ********* epoch 10 ********* test accuracy for mode 33:0.2735 test loss: 248.878
93000: ********* epoch 10 ********* test accuracy for mode 34:0.1365 test loss: 254.924
93000: ********* epoch 10 ********* test accuracy for mode 35:0.008 test loss: 398.091
93000: ********* epoch 10 ********* test accuracy for mode 36:0.0745 test loss: 419.834
93010: accuracy:0.38 loss: 220.321 (lr:0.0001)
93020: accuracy:0.36 loss: 199.274 (lr:0.0001)
93030: accuracy:0.36 loss: 213.272 (lr:0.0001)
93040: accuracy:0.23 loss: 237.246 (lr:0.0001)
93050: accuracy:0.38 loss: 198.797 (lr:0.0001)
93060: accuracy:0.29 loss: 221.613 (lr:0.0001)
93070: accuracy:0.4 loss: 211.684 (lr:0.0001)
93080: accuracy:0.38 loss: 221.2 (lr:0.0001)
93090: accuracy:0.37 loss: 222.128 (lr:0.0001)
93100: accuracy:0.43 loss: 198.571 (lr:0.0001)
93110: accuracy:0.41 loss: 197.789 (lr:0.0001)
93120: accuracy:0.34 loss: 208.638 (lr:0.0001)
93130: accuracy:0.26 loss: 223.052 (lr:0.0001)
93140: accuracy:0.39 loss: 202.813 (lr:0.0001)
93150: accuracy:0.39 loss: 214.929 (lr:0.0001)
93160: accuracy:0.37 loss: 212.985 (lr:0.0001)
93170: accuracy:0.26 loss: 219.533 (lr:0.0001)
93180: accuracy:0.3 loss: 216.68 (lr:0.0001)
93190: accuracy:0.31 loss: 228.475 (lr:0.0001)
93200: accuracy:0.44 loss: 202.109 (lr:0.0001)
93210: accuracy:0.28 loss: 221.972 (lr:0.0001)
93220: accuracy:0.31 loss: 207.099 (lr:0.0001)
93230: accuracy:0.3 loss: 225.97 (lr:0.0001)
93240: accuracy:0.35 loss: 213.483 (lr:0.0001)
93250: accuracy:0.38 loss: 195.498 (lr:0.0001)
93260: accuracy:0.28 loss: 222.022 (lr:0.0001)
93270: accuracy:0.23 loss: 226.771 (lr:0.0001)
93280: accuracy:0.29 loss: 207.787 (lr:0.0001)
93290: accuracy:0.26 loss: 248.249 (lr:0.0001)
93300: accuracy:0.32 loss: 222.009 (lr:0.0001)
93310: accuracy:0.4 loss: 199.78 (lr:0.0001)
93320: accuracy:0.31 loss: 221.718 (lr:0.0001)
93330: accuracy:0.3 loss: 204.939 (lr:0.0001)
93340: accuracy:0.34 loss: 213.236 (lr:0.0001)
93350: accuracy:0.32 loss: 215.9 (lr:0.0001)
93360: accuracy:0.32 loss: 209.179 (lr:0.0001)
93370: accuracy:0.37 loss: 219.177 (lr:0.0001)
93380: accuracy:0.24 loss: 225.372 (lr:0.0001)
93390: accuracy:0.33 loss: 215.232 (lr:0.0001)
93400: accuracy:0.33 loss: 233.2 (lr:0.0001)
93410: accuracy:0.35 loss: 203.434 (lr:0.0001)
93420: accuracy:0.28 loss: 215.208 (lr:0.0001)
93430: accuracy:0.38 loss: 202.478 (lr:0.0001)
93440: accuracy:0.32 loss: 231.097 (lr:0.0001)
93450: accuracy:0.27 loss: 209.504 (lr:0.0001)
93460: accuracy:0.29 loss: 215.206 (lr:0.0001)
93470: accuracy:0.29 loss: 228.037 (lr:0.0001)
93480: accuracy:0.39 loss: 190.168 (lr:0.0001)
93490: accuracy:0.35 loss: 221.698 (lr:0.0001)
93500: accuracy:0.32 loss: 203.52 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
93500: ********* epoch 10 ********* test accuracy for all:0.24777 test loss: 255.808
93500: ********* epoch 10 ********* test accuracy for mode 0:0.01 test loss: 427.744
93500: ********* epoch 10 ********* test accuracy for mode 1:0.0475 test loss: 408.38
93500: ********* epoch 10 ********* test accuracy for mode 2:0.0555 test loss: 272.883
93500: ********* epoch 10 ********* test accuracy for mode 24:0.248 test loss: 265.255
93500: ********* epoch 10 ********* test accuracy for mode 25:0.2485 test loss: 250.799
93500: ********* epoch 10 ********* test accuracy for mode 26:0.4685 test loss: 165.783
93500: ********* epoch 10 ********* test accuracy for mode 27:0.243 test loss: 263.024
93500: ********* epoch 10 ********* test accuracy for mode 28:0.2965 test loss: 249.498
93500: ********* epoch 10 ********* test accuracy for mode 29:0.276 test loss: 257.504
93500: ********* epoch 10 ********* test accuracy for mode 30:0.196 test loss: 254.235
93500: ********* epoch 10 ********* test accuracy for mode 31:0.245 test loss: 251.503
93500: ********* epoch 10 ********* test accuracy for mode 32:0.2005 test loss: 245.382
93500: ********* epoch 10 ********* test accuracy for mode 33:0.2655 test loss: 248.032
93500: ********* epoch 10 ********* test accuracy for mode 34:0.219 test loss: 247.904
93500: ********* epoch 10 ********* test accuracy for mode 35:0.011 test loss: 424.387
93500: ********* epoch 10 ********* test accuracy for mode 36:0.07 test loss: 461.786
93510: accuracy:0.34 loss: 214.074 (lr:0.0001)
93520: accuracy:0.36 loss: 233.195 (lr:0.0001)
93530: accuracy:0.37 loss: 207.457 (lr:0.0001)
93540: accuracy:0.36 loss: 201.633 (lr:0.0001)
93550: accuracy:0.29 loss: 231.769 (lr:0.0001)
93560: accuracy:0.37 loss: 197.434 (lr:0.0001)
93570: accuracy:0.37 loss: 214.293 (lr:0.0001)
93580: accuracy:0.3 loss: 224.484 (lr:0.0001)
93590: accuracy:0.28 loss: 209.185 (lr:0.0001)
93600: accuracy:0.24 loss: 236.059 (lr:0.0001)
93610: accuracy:0.27 loss: 230.514 (lr:0.0001)
93620: accuracy:0.31 loss: 238.113 (lr:0.0001)
93630: accuracy:0.33 loss: 205.485 (lr:0.0001)
93640: accuracy:0.37 loss: 210.441 (lr:0.0001)
93650: accuracy:0.29 loss: 223.756 (lr:0.0001)
93660: accuracy:0.31 loss: 251.301 (lr:0.0001)
93670: accuracy:0.26 loss: 206.592 (lr:0.0001)
93680: accuracy:0.31 loss: 199.616 (lr:0.0001)
93690: accuracy:0.26 loss: 228.757 (lr:0.0001)
93700: accuracy:0.35 loss: 207.944 (lr:0.0001)
93710: accuracy:0.33 loss: 208.745 (lr:0.0001)
93720: accuracy:0.41 loss: 197.926 (lr:0.0001)
93730: accuracy:0.29 loss: 216.673 (lr:0.0001)
93740: accuracy:0.34 loss: 206.718 (lr:0.0001)
93750: accuracy:0.29 loss: 211.548 (lr:0.0001)
93760: accuracy:0.27 loss: 244.558 (lr:0.0001)
93770: accuracy:0.36 loss: 213.667 (lr:0.0001)
93780: accuracy:0.32 loss: 208.736 (lr:0.0001)
93790: accuracy:0.3 loss: 221.262 (lr:0.0001)
93800: accuracy:0.36 loss: 204.627 (lr:0.0001)
93810: accuracy:0.3 loss: 205.813 (lr:0.0001)
93820: accuracy:0.37 loss: 216.029 (lr:0.0001)
93830: accuracy:0.33 loss: 215.617 (lr:0.0001)
93840: accuracy:0.34 loss: 202.452 (lr:0.0001)
93850: accuracy:0.42 loss: 201.329 (lr:0.0001)
93860: accuracy:0.35 loss: 214.09 (lr:0.0001)
93870: accuracy:0.3 loss: 220.815 (lr:0.0001)
93880: accuracy:0.31 loss: 231.294 (lr:0.0001)
93890: accuracy:0.25 loss: 228.035 (lr:0.0001)
93900: accuracy:0.33 loss: 215.184 (lr:0.0001)
93910: accuracy:0.33 loss: 222.658 (lr:0.0001)
93920: accuracy:0.35 loss: 218.923 (lr:0.0001)
93930: accuracy:0.33 loss: 209.481 (lr:0.0001)
93940: accuracy:0.34 loss: 202.277 (lr:0.0001)
93950: accuracy:0.34 loss: 223.805 (lr:0.0001)
93960: accuracy:0.36 loss: 224.278 (lr:0.0001)
93970: accuracy:0.29 loss: 226.052 (lr:0.0001)
93980: accuracy:0.29 loss: 228.179 (lr:0.0001)
93990: accuracy:0.35 loss: 215.589 (lr:0.0001)
94000: accuracy:0.33 loss: 229.592 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
94000: ********* epoch 10 ********* test accuracy for all:0.248162 test loss: 254.33
94000: ********* epoch 10 ********* test accuracy for mode 0:0.0095 test loss: 418.601
94000: ********* epoch 10 ********* test accuracy for mode 1:0.0515 test loss: 404.63
94000: ********* epoch 10 ********* test accuracy for mode 2:0.054 test loss: 271.383
94000: ********* epoch 10 ********* test accuracy for mode 24:0.2335 test loss: 263.645
94000: ********* epoch 10 ********* test accuracy for mode 25:0.2695 test loss: 246.628
94000: ********* epoch 10 ********* test accuracy for mode 26:0.495 test loss: 160.993
94000: ********* epoch 10 ********* test accuracy for mode 27:0.2505 test loss: 262.737
94000: ********* epoch 10 ********* test accuracy for mode 28:0.291 test loss: 254.713
94000: ********* epoch 10 ********* test accuracy for mode 29:0.29 test loss: 261.038
94000: ********* epoch 10 ********* test accuracy for mode 30:0.1965 test loss: 258.477
94000: ********* epoch 10 ********* test accuracy for mode 31:0.221 test loss: 258.519
94000: ********* epoch 10 ********* test accuracy for mode 32:0.188 test loss: 251.325
94000: ********* epoch 10 ********* test accuracy for mode 33:0.266 test loss: 253.637
94000: ********* epoch 10 ********* test accuracy for mode 34:0.147 test loss: 254.726
94000: ********* epoch 10 ********* test accuracy for mode 35:0.007 test loss: 414.017
94000: ********* epoch 10 ********* test accuracy for mode 36:0.069 test loss: 431.009
94010: accuracy:0.3 loss: 217.175 (lr:0.0001)
94020: accuracy:0.23 loss: 218.74 (lr:0.0001)
94030: accuracy:0.4 loss: 213.465 (lr:0.0001)
94040: accuracy:0.33 loss: 222.066 (lr:0.0001)
94050: accuracy:0.28 loss: 216.103 (lr:0.0001)
94060: accuracy:0.31 loss: 209.346 (lr:0.0001)
94070: accuracy:0.37 loss: 222.524 (lr:0.0001)
94080: accuracy:0.37 loss: 206.819 (lr:0.0001)
94090: accuracy:0.26 loss: 218.46 (lr:0.0001)
94100: accuracy:0.29 loss: 231.75 (lr:0.0001)
94110: accuracy:0.36 loss: 216.599 (lr:0.0001)
94120: accuracy:0.32 loss: 197.852 (lr:0.0001)
94130: accuracy:0.35 loss: 220.561 (lr:0.0001)
94140: accuracy:0.37 loss: 198.017 (lr:0.0001)
94150: accuracy:0.32 loss: 220.051 (lr:0.0001)
94160: accuracy:0.37 loss: 210.845 (lr:0.0001)
94170: accuracy:0.34 loss: 227.42 (lr:0.0001)
94180: accuracy:0.31 loss: 211.991 (lr:0.0001)
94190: accuracy:0.33 loss: 209.349 (lr:0.0001)
94200: accuracy:0.29 loss: 226.281 (lr:0.0001)
94210: accuracy:0.37 loss: 192.869 (lr:0.0001)
94220: accuracy:0.38 loss: 231.183 (lr:0.0001)
94230: accuracy:0.37 loss: 204.157 (lr:0.0001)
94240: accuracy:0.34 loss: 198.686 (lr:0.0001)
94250: accuracy:0.29 loss: 227.04 (lr:0.0001)
94260: accuracy:0.39 loss: 214.153 (lr:0.0001)
94270: accuracy:0.28 loss: 214.642 (lr:0.0001)
94280: accuracy:0.37 loss: 207.688 (lr:0.0001)
94290: accuracy:0.26 loss: 205.937 (lr:0.0001)
94300: accuracy:0.4 loss: 208.894 (lr:0.0001)
94310: accuracy:0.31 loss: 210.676 (lr:0.0001)
94320: accuracy:0.33 loss: 212.815 (lr:0.0001)
94330: accuracy:0.32 loss: 208.97 (lr:0.0001)
94340: accuracy:0.32 loss: 234.31 (lr:0.0001)
94350: accuracy:0.28 loss: 220.109 (lr:0.0001)
94360: accuracy:0.33 loss: 225.03 (lr:0.0001)
94370: accuracy:0.34 loss: 229.93 (lr:0.0001)
94380: accuracy:0.29 loss: 217.865 (lr:0.0001)
94390: accuracy:0.33 loss: 217.43 (lr:0.0001)
94400: accuracy:0.32 loss: 221.519 (lr:0.0001)
94410: accuracy:0.26 loss: 230.144 (lr:0.0001)
94420: accuracy:0.26 loss: 236.834 (lr:0.0001)
94430: accuracy:0.29 loss: 227.986 (lr:0.0001)
94440: accuracy:0.3 loss: 214.669 (lr:0.0001)
94450: accuracy:0.27 loss: 212.322 (lr:0.0001)
94460: accuracy:0.27 loss: 220.3 (lr:0.0001)
94470: accuracy:0.34 loss: 206.718 (lr:0.0001)
94480: accuracy:0.25 loss: 234.722 (lr:0.0001)
94490: accuracy:0.36 loss: 221.623 (lr:0.0001)
94500: accuracy:0.36 loss: 204.295 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
94500: ********* epoch 10 ********* test accuracy for all:0.248676 test loss: 255.165
94500: ********* epoch 10 ********* test accuracy for mode 0:0.007 test loss: 423.763
94500: ********* epoch 10 ********* test accuracy for mode 1:0.0455 test loss: 407.632
94500: ********* epoch 10 ********* test accuracy for mode 2:0.044 test loss: 274.878
94500: ********* epoch 10 ********* test accuracy for mode 24:0.2345 test loss: 259.541
94500: ********* epoch 10 ********* test accuracy for mode 25:0.315 test loss: 239.45
94500: ********* epoch 10 ********* test accuracy for mode 26:0.418 test loss: 170.022
94500: ********* epoch 10 ********* test accuracy for mode 27:0.2465 test loss: 268.445
94500: ********* epoch 10 ********* test accuracy for mode 28:0.3055 test loss: 253.28
94500: ********* epoch 10 ********* test accuracy for mode 29:0.251 test loss: 263.133
94500: ********* epoch 10 ********* test accuracy for mode 30:0.254 test loss: 252.523
94500: ********* epoch 10 ********* test accuracy for mode 31:0.168 test loss: 255.338
94500: ********* epoch 10 ********* test accuracy for mode 32:0.3235 test loss: 239.872
94500: ********* epoch 10 ********* test accuracy for mode 33:0.196 test loss: 255.183
94500: ********* epoch 10 ********* test accuracy for mode 34:0.129 test loss: 256.774
94500: ********* epoch 10 ********* test accuracy for mode 35:0.009 test loss: 418.769
94500: ********* epoch 10 ********* test accuracy for mode 36:0.0955 test loss: 429.594
94510: accuracy:0.31 loss: 207.979 (lr:0.0001)
94520: accuracy:0.4 loss: 207.499 (lr:0.0001)
94530: accuracy:0.28 loss: 225.91 (lr:0.0001)
94540: accuracy:0.33 loss: 200.325 (lr:0.0001)
94550: accuracy:0.31 loss: 220.229 (lr:0.0001)
94560: accuracy:0.28 loss: 221.387 (lr:0.0001)
94570: accuracy:0.33 loss: 201.012 (lr:0.0001)
94580: accuracy:0.31 loss: 217.549 (lr:0.0001)
94590: accuracy:0.33 loss: 210.581 (lr:0.0001)
94600: accuracy:0.35 loss: 217.807 (lr:0.0001)
94610: accuracy:0.32 loss: 221.682 (lr:0.0001)
94620: accuracy:0.28 loss: 228.465 (lr:0.0001)
94630: accuracy:0.33 loss: 203.512 (lr:0.0001)
94640: accuracy:0.39 loss: 213.518 (lr:0.0001)
94650: accuracy:0.34 loss: 224.747 (lr:0.0001)
94660: accuracy:0.31 loss: 219.912 (lr:0.0001)
94670: accuracy:0.35 loss: 211.089 (lr:0.0001)
94680: accuracy:0.38 loss: 209.594 (lr:0.0001)
94690: accuracy:0.32 loss: 223.571 (lr:0.0001)
94700: accuracy:0.31 loss: 217.571 (lr:0.0001)
94710: accuracy:0.34 loss: 230.697 (lr:0.0001)
94720: accuracy:0.35 loss: 209.345 (lr:0.0001)
94730: accuracy:0.32 loss: 215.647 (lr:0.0001)
94740: accuracy:0.45 loss: 192.239 (lr:0.0001)
94750: accuracy:0.31 loss: 226.367 (lr:0.0001)
94760: accuracy:0.32 loss: 216.181 (lr:0.0001)
94770: accuracy:0.26 loss: 229.189 (lr:0.0001)
94780: accuracy:0.33 loss: 211.989 (lr:0.0001)
94790: accuracy:0.27 loss: 227.054 (lr:0.0001)
94800: accuracy:0.34 loss: 222.703 (lr:0.0001)
94810: accuracy:0.31 loss: 229.224 (lr:0.0001)
94820: accuracy:0.39 loss: 217.204 (lr:0.0001)
94830: accuracy:0.33 loss: 235.308 (lr:0.0001)
94840: accuracy:0.32 loss: 216.167 (lr:0.0001)
94850: accuracy:0.33 loss: 215.711 (lr:0.0001)
94860: accuracy:0.34 loss: 218.074 (lr:0.0001)
94870: accuracy:0.37 loss: 211.097 (lr:0.0001)
94880: accuracy:0.29 loss: 219.484 (lr:0.0001)
94890: accuracy:0.27 loss: 212.808 (lr:0.0001)
94900: accuracy:0.27 loss: 237.117 (lr:0.0001)
94910: accuracy:0.28 loss: 228.203 (lr:0.0001)
94920: accuracy:0.32 loss: 222.543 (lr:0.0001)
94930: accuracy:0.33 loss: 213.224 (lr:0.0001)
94940: accuracy:0.35 loss: 206.402 (lr:0.0001)
94950: accuracy:0.32 loss: 239.203 (lr:0.0001)
94960: accuracy:0.34 loss: 232.774 (lr:0.0001)
94970: accuracy:0.3 loss: 239.608 (lr:0.0001)
94980: accuracy:0.32 loss: 226.124 (lr:0.0001)
94990: accuracy:0.24 loss: 220.919 (lr:0.0001)
95000: accuracy:0.34 loss: 229.127 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
95000: ********* epoch 10 ********* test accuracy for all:0.250054 test loss: 252.959
95000: ********* epoch 10 ********* test accuracy for mode 0:0.0065 test loss: 429.375
95000: ********* epoch 10 ********* test accuracy for mode 1:0.043 test loss: 409.368
95000: ********* epoch 10 ********* test accuracy for mode 2:0.0285 test loss: 280.611
95000: ********* epoch 10 ********* test accuracy for mode 24:0.2325 test loss: 266.525
95000: ********* epoch 10 ********* test accuracy for mode 25:0.3045 test loss: 235.373
95000: ********* epoch 10 ********* test accuracy for mode 26:0.4465 test loss: 166.401
95000: ********* epoch 10 ********* test accuracy for mode 27:0.2485 test loss: 257.486
95000: ********* epoch 10 ********* test accuracy for mode 28:0.2985 test loss: 244.191
95000: ********* epoch 10 ********* test accuracy for mode 29:0.284 test loss: 251.006
95000: ********* epoch 10 ********* test accuracy for mode 30:0.276 test loss: 241.185
95000: ********* epoch 10 ********* test accuracy for mode 31:0.214 test loss: 249.707
95000: ********* epoch 10 ********* test accuracy for mode 32:0.215 test loss: 243.623
95000: ********* epoch 10 ********* test accuracy for mode 33:0.2575 test loss: 250.051
95000: ********* epoch 10 ********* test accuracy for mode 34:0.1885 test loss: 254.631
95000: ********* epoch 10 ********* test accuracy for mode 35:0.021 test loss: 412.201
95000: ********* epoch 10 ********* test accuracy for mode 36:0.066 test loss: 431.491
95010: accuracy:0.3 loss: 203.424 (lr:0.0001)
95020: accuracy:0.38 loss: 193.421 (lr:0.0001)
95030: accuracy:0.38 loss: 212.282 (lr:0.0001)
95040: accuracy:0.29 loss: 222.948 (lr:0.0001)
95050: accuracy:0.32 loss: 208.828 (lr:0.0001)
95060: accuracy:0.25 loss: 212.64 (lr:0.0001)
95070: accuracy:0.33 loss: 197.57 (lr:0.0001)
95080: accuracy:0.28 loss: 224.526 (lr:0.0001)
95090: accuracy:0.24 loss: 227.935 (lr:0.0001)
95100: accuracy:0.35 loss: 213.02 (lr:0.0001)
95110: accuracy:0.31 loss: 218.363 (lr:0.0001)
95120: accuracy:0.22 loss: 219.233 (lr:0.0001)
95130: accuracy:0.39 loss: 199.669 (lr:0.0001)
95140: accuracy:0.3 loss: 204.771 (lr:0.0001)
95150: accuracy:0.33 loss: 215.416 (lr:0.0001)
95160: accuracy:0.39 loss: 200.599 (lr:0.0001)
95170: accuracy:0.24 loss: 245.412 (lr:0.0001)
95180: accuracy:0.35 loss: 202.813 (lr:0.0001)
95190: accuracy:0.31 loss: 217.424 (lr:0.0001)
95200: accuracy:0.31 loss: 227.155 (lr:0.0001)
95210: accuracy:0.32 loss: 220.0 (lr:0.0001)
95220: accuracy:0.35 loss: 233.193 (lr:0.0001)
95230: accuracy:0.32 loss: 221.628 (lr:0.0001)
95240: accuracy:0.33 loss: 232.45 (lr:0.0001)
95250: accuracy:0.35 loss: 205.516 (lr:0.0001)
95260: accuracy:0.41 loss: 218.412 (lr:0.0001)
95270: accuracy:0.33 loss: 215.344 (lr:0.0001)
95280: accuracy:0.19 loss: 254.045 (lr:0.0001)
95290: accuracy:0.23 loss: 231.912 (lr:0.0001)
95300: accuracy:0.34 loss: 225.224 (lr:0.0001)
95310: accuracy:0.36 loss: 208.943 (lr:0.0001)
95320: accuracy:0.35 loss: 226.118 (lr:0.0001)
95330: accuracy:0.32 loss: 225.619 (lr:0.0001)
95340: accuracy:0.32 loss: 219.177 (lr:0.0001)
95350: accuracy:0.18 loss: 234.44 (lr:0.0001)
95360: accuracy:0.35 loss: 214.544 (lr:0.0001)
95370: accuracy:0.29 loss: 205.813 (lr:0.0001)
95380: accuracy:0.36 loss: 193.82 (lr:0.0001)
95390: accuracy:0.34 loss: 210.888 (lr:0.0001)
95400: accuracy:0.3 loss: 216.349 (lr:0.0001)
95410: accuracy:0.29 loss: 208.711 (lr:0.0001)
95420: accuracy:0.33 loss: 213.887 (lr:0.0001)
95430: accuracy:0.29 loss: 217.19 (lr:0.0001)
95440: accuracy:0.29 loss: 218.705 (lr:0.0001)
95450: accuracy:0.39 loss: 213.078 (lr:0.0001)
95460: accuracy:0.34 loss: 220.76 (lr:0.0001)
95470: accuracy:0.3 loss: 223.212 (lr:0.0001)
95480: accuracy:0.28 loss: 217.551 (lr:0.0001)
95490: accuracy:0.27 loss: 226.07 (lr:0.0001)
95500: accuracy:0.31 loss: 197.632 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
95500: ********* epoch 10 ********* test accuracy for all:0.246473 test loss: 256.426
95500: ********* epoch 10 ********* test accuracy for mode 0:0.0095 test loss: 431.001
95500: ********* epoch 10 ********* test accuracy for mode 1:0.0445 test loss: 415.514
95500: ********* epoch 10 ********* test accuracy for mode 2:0.036 test loss: 264.595
95500: ********* epoch 10 ********* test accuracy for mode 24:0.2315 test loss: 273.102
95500: ********* epoch 10 ********* test accuracy for mode 25:0.3355 test loss: 238.738
95500: ********* epoch 10 ********* test accuracy for mode 26:0.4175 test loss: 165.898
95500: ********* epoch 10 ********* test accuracy for mode 27:0.266 test loss: 262.606
95500: ********* epoch 10 ********* test accuracy for mode 28:0.2795 test loss: 257.849
95500: ********* epoch 10 ********* test accuracy for mode 29:0.2565 test loss: 266.386
95500: ********* epoch 10 ********* test accuracy for mode 30:0.2335 test loss: 253.775
95500: ********* epoch 10 ********* test accuracy for mode 31:0.1965 test loss: 255.862
95500: ********* epoch 10 ********* test accuracy for mode 32:0.2425 test loss: 240.487
95500: ********* epoch 10 ********* test accuracy for mode 33:0.2645 test loss: 245.035
95500: ********* epoch 10 ********* test accuracy for mode 34:0.1475 test loss: 247.766
95500: ********* epoch 10 ********* test accuracy for mode 35:0.0105 test loss: 426.337
95500: ********* epoch 10 ********* test accuracy for mode 36:0.0565 test loss: 446.293
95510: accuracy:0.3 loss: 229.481 (lr:0.0001)
95520: accuracy:0.35 loss: 209.679 (lr:0.0001)
95530: accuracy:0.3 loss: 222.374 (lr:0.0001)
95540: accuracy:0.32 loss: 214.725 (lr:0.0001)
95550: accuracy:0.27 loss: 226.059 (lr:0.0001)
95560: accuracy:0.29 loss: 210.343 (lr:0.0001)
95570: accuracy:0.42 loss: 193.826 (lr:0.0001)
95580: accuracy:0.35 loss: 217.327 (lr:0.0001)
95590: accuracy:0.37 loss: 212.167 (lr:0.0001)
95600: accuracy:0.31 loss: 234.968 (lr:0.0001)
95610: accuracy:0.28 loss: 227.225 (lr:0.0001)
95620: accuracy:0.27 loss: 233.085 (lr:0.0001)
95630: accuracy:0.33 loss: 220.348 (lr:0.0001)
95640: accuracy:0.34 loss: 227.753 (lr:0.0001)
95650: accuracy:0.34 loss: 206.545 (lr:0.0001)
95660: accuracy:0.33 loss: 210.444 (lr:0.0001)
95670: accuracy:0.29 loss: 203.716 (lr:0.0001)
95680: accuracy:0.3 loss: 204.476 (lr:0.0001)
95690: accuracy:0.37 loss: 217.717 (lr:0.0001)
95700: accuracy:0.26 loss: 236.054 (lr:0.0001)
95710: accuracy:0.28 loss: 214.366 (lr:0.0001)
95720: accuracy:0.32 loss: 232.582 (lr:0.0001)
95730: accuracy:0.33 loss: 211.344 (lr:0.0001)
95740: accuracy:0.33 loss: 215.314 (lr:0.0001)
95750: accuracy:0.26 loss: 232.502 (lr:0.0001)
95760: accuracy:0.34 loss: 224.743 (lr:0.0001)
95770: accuracy:0.29 loss: 219.127 (lr:0.0001)
95780: accuracy:0.35 loss: 219.343 (lr:0.0001)
95790: accuracy:0.35 loss: 206.722 (lr:0.0001)
95800: accuracy:0.34 loss: 210.876 (lr:0.0001)
95810: accuracy:0.28 loss: 257.934 (lr:0.0001)
95820: accuracy:0.31 loss: 235.718 (lr:0.0001)
95830: accuracy:0.3 loss: 215.342 (lr:0.0001)
95840: accuracy:0.46 loss: 194.026 (lr:0.0001)
95850: accuracy:0.32 loss: 188.436 (lr:0.0001)
95860: accuracy:0.27 loss: 214.852 (lr:0.0001)
95870: accuracy:0.3 loss: 218.692 (lr:0.0001)
95880: accuracy:0.38 loss: 200.777 (lr:0.0001)
95890: accuracy:0.29 loss: 224.874 (lr:0.0001)
95900: accuracy:0.35 loss: 191.046 (lr:0.0001)
95910: accuracy:0.28 loss: 218.596 (lr:0.0001)
95920: accuracy:0.37 loss: 218.844 (lr:0.0001)
95930: accuracy:0.25 loss: 234.698 (lr:0.0001)
95940: accuracy:0.28 loss: 235.499 (lr:0.0001)
95950: accuracy:0.35 loss: 211.741 (lr:0.0001)
95960: accuracy:0.25 loss: 235.413 (lr:0.0001)
95970: accuracy:0.33 loss: 225.236 (lr:0.0001)
95980: accuracy:0.28 loss: 209.318 (lr:0.0001)
95990: accuracy:0.27 loss: 245.851 (lr:0.0001)
96000: accuracy:0.33 loss: 212.577 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
96000: ********* epoch 10 ********* test accuracy for all:0.253932 test loss: 253.153
96000: ********* epoch 10 ********* test accuracy for mode 0:0.01 test loss: 423.186
96000: ********* epoch 10 ********* test accuracy for mode 1:0.0385 test loss: 409.662
96000: ********* epoch 10 ********* test accuracy for mode 2:0.0385 test loss: 267.777
96000: ********* epoch 10 ********* test accuracy for mode 24:0.2555 test loss: 259.624
96000: ********* epoch 10 ********* test accuracy for mode 25:0.3145 test loss: 236.788
96000: ********* epoch 10 ********* test accuracy for mode 26:0.4575 test loss: 162.993
96000: ********* epoch 10 ********* test accuracy for mode 27:0.274 test loss: 254.59
96000: ********* epoch 10 ********* test accuracy for mode 28:0.313 test loss: 245.687
96000: ********* epoch 10 ********* test accuracy for mode 29:0.279 test loss: 253.303
96000: ********* epoch 10 ********* test accuracy for mode 30:0.2335 test loss: 247.72
96000: ********* epoch 10 ********* test accuracy for mode 31:0.2165 test loss: 251.343
96000: ********* epoch 10 ********* test accuracy for mode 32:0.202 test loss: 245.129
96000: ********* epoch 10 ********* test accuracy for mode 33:0.248 test loss: 247.415
96000: ********* epoch 10 ********* test accuracy for mode 34:0.2235 test loss: 245.793
96000: ********* epoch 10 ********* test accuracy for mode 35:0.006 test loss: 417.39
96000: ********* epoch 10 ********* test accuracy for mode 36:0.1145 test loss: 428.98
96010: accuracy:0.39 loss: 203.844 (lr:0.0001)
96020: accuracy:0.3 loss: 219.388 (lr:0.0001)
96030: accuracy:0.33 loss: 211.908 (lr:0.0001)
96040: accuracy:0.34 loss: 218.511 (lr:0.0001)
96050: accuracy:0.31 loss: 212.018 (lr:0.0001)
96060: accuracy:0.32 loss: 209.13 (lr:0.0001)
96070: accuracy:0.39 loss: 215.437 (lr:0.0001)
96080: accuracy:0.33 loss: 222.594 (lr:0.0001)
96090: accuracy:0.35 loss: 199.993 (lr:0.0001)
96100: accuracy:0.32 loss: 206.331 (lr:0.0001)
96110: accuracy:0.34 loss: 216.483 (lr:0.0001)
96120: accuracy:0.3 loss: 228.082 (lr:0.0001)
96130: accuracy:0.31 loss: 234.659 (lr:0.0001)
96140: accuracy:0.3 loss: 210.293 (lr:0.0001)
96150: accuracy:0.37 loss: 200.474 (lr:0.0001)
96160: accuracy:0.29 loss: 224.448 (lr:0.0001)
96170: accuracy:0.36 loss: 218.328 (lr:0.0001)
96180: accuracy:0.33 loss: 214.668 (lr:0.0001)
96190: accuracy:0.29 loss: 224.11 (lr:0.0001)
96200: accuracy:0.39 loss: 221.108 (lr:0.0001)
96210: accuracy:0.29 loss: 231.722 (lr:0.0001)
96220: accuracy:0.28 loss: 230.959 (lr:0.0001)
96230: accuracy:0.34 loss: 203.405 (lr:0.0001)
96240: accuracy:0.3 loss: 227.675 (lr:0.0001)
96250: accuracy:0.4 loss: 205.321 (lr:0.0001)
96260: accuracy:0.28 loss: 203.223 (lr:0.0001)
96270: accuracy:0.35 loss: 212.089 (lr:0.0001)
96280: accuracy:0.3 loss: 211.015 (lr:0.0001)
96290: accuracy:0.4 loss: 207.438 (lr:0.0001)
96300: accuracy:0.3 loss: 238.181 (lr:0.0001)
96310: accuracy:0.32 loss: 215.069 (lr:0.0001)
96320: accuracy:0.25 loss: 220.308 (lr:0.0001)
96330: accuracy:0.41 loss: 191.525 (lr:0.0001)
96340: accuracy:0.17 loss: 252.569 (lr:0.0001)
96350: accuracy:0.35 loss: 214.401 (lr:0.0001)
96360: accuracy:0.27 loss: 223.036 (lr:0.0001)
96370: accuracy:0.27 loss: 228.511 (lr:0.0001)
96380: accuracy:0.34 loss: 214.489 (lr:0.0001)
96390: accuracy:0.27 loss: 228.458 (lr:0.0001)
96400: accuracy:0.29 loss: 212.719 (lr:0.0001)
96410: accuracy:0.35 loss: 222.34 (lr:0.0001)
96420: accuracy:0.39 loss: 221.069 (lr:0.0001)
96430: accuracy:0.36 loss: 185.393 (lr:0.0001)
96440: accuracy:0.32 loss: 195.276 (lr:0.0001)
96450: accuracy:0.43 loss: 205.934 (lr:0.0001)
96460: accuracy:0.29 loss: 215.351 (lr:0.0001)
96470: accuracy:0.3 loss: 214.171 (lr:0.0001)
96480: accuracy:0.33 loss: 202.265 (lr:0.0001)
96490: accuracy:0.27 loss: 226.902 (lr:0.0001)
96500: accuracy:0.34 loss: 218.065 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
96500: ********* epoch 10 ********* test accuracy for all:0.247541 test loss: 255.467
96500: ********* epoch 10 ********* test accuracy for mode 0:0.012 test loss: 418.485
96500: ********* epoch 10 ********* test accuracy for mode 1:0.059 test loss: 404.396
96500: ********* epoch 10 ********* test accuracy for mode 2:0.0485 test loss: 272.813
96500: ********* epoch 10 ********* test accuracy for mode 24:0.241 test loss: 263.435
96500: ********* epoch 10 ********* test accuracy for mode 25:0.2705 test loss: 242.296
96500: ********* epoch 10 ********* test accuracy for mode 26:0.4345 test loss: 167.899
96500: ********* epoch 10 ********* test accuracy for mode 27:0.245 test loss: 259.061
96500: ********* epoch 10 ********* test accuracy for mode 28:0.2995 test loss: 246.71
96500: ********* epoch 10 ********* test accuracy for mode 29:0.2515 test loss: 256.299
96500: ********* epoch 10 ********* test accuracy for mode 30:0.281 test loss: 242.592
96500: ********* epoch 10 ********* test accuracy for mode 31:0.255 test loss: 245.064
96500: ********* epoch 10 ********* test accuracy for mode 32:0.192 test loss: 240.794
96500: ********* epoch 10 ********* test accuracy for mode 33:0.277 test loss: 245.032
96500: ********* epoch 10 ********* test accuracy for mode 34:0.156 test loss: 251.603
96500: ********* epoch 10 ********* test accuracy for mode 35:0.0255 test loss: 418.017
96500: ********* epoch 10 ********* test accuracy for mode 36:0.0625 test loss: 441.841
96510: accuracy:0.33 loss: 230.046 (lr:0.0001)
96520: accuracy:0.31 loss: 228.461 (lr:0.0001)
96530: accuracy:0.3 loss: 226.039 (lr:0.0001)
96540: accuracy:0.29 loss: 216.095 (lr:0.0001)
96550: accuracy:0.24 loss: 245.275 (lr:0.0001)
96560: accuracy:0.31 loss: 219.784 (lr:0.0001)
96570: accuracy:0.31 loss: 226.813 (lr:0.0001)
96580: accuracy:0.31 loss: 224.398 (lr:0.0001)
96590: accuracy:0.36 loss: 211.124 (lr:0.0001)
96600: accuracy:0.27 loss: 250.737 (lr:0.0001)
96610: accuracy:0.29 loss: 224.098 (lr:0.0001)
96620: accuracy:0.4 loss: 197.986 (lr:0.0001)
96630: accuracy:0.31 loss: 223.579 (lr:0.0001)
96640: accuracy:0.3 loss: 233.094 (lr:0.0001)
96650: accuracy:0.34 loss: 217.819 (lr:0.0001)
96660: accuracy:0.27 loss: 223.762 (lr:0.0001)
96670: accuracy:0.28 loss: 219.278 (lr:0.0001)
96680: accuracy:0.38 loss: 195.771 (lr:0.0001)
96690: accuracy:0.29 loss: 215.839 (lr:0.0001)
96700: accuracy:0.37 loss: 232.639 (lr:0.0001)
96710: accuracy:0.3 loss: 229.479 (lr:0.0001)
96720: accuracy:0.24 loss: 228.116 (lr:0.0001)
96730: accuracy:0.24 loss: 226.584 (lr:0.0001)
96740: accuracy:0.36 loss: 222.642 (lr:0.0001)
96750: accuracy:0.33 loss: 208.28 (lr:0.0001)
96760: accuracy:0.28 loss: 205.469 (lr:0.0001)
96770: accuracy:0.36 loss: 220.921 (lr:0.0001)
96780: accuracy:0.22 loss: 226.936 (lr:0.0001)
96790: accuracy:0.23 loss: 240.253 (lr:0.0001)
96800: accuracy:0.27 loss: 221.102 (lr:0.0001)
96810: accuracy:0.28 loss: 234.531 (lr:0.0001)
96820: accuracy:0.34 loss: 222.128 (lr:0.0001)
96830: accuracy:0.31 loss: 226.059 (lr:0.0001)
96840: accuracy:0.29 loss: 224.596 (lr:0.0001)
96850: accuracy:0.34 loss: 213.054 (lr:0.0001)
96860: accuracy:0.36 loss: 209.711 (lr:0.0001)
96870: accuracy:0.27 loss: 220.16 (lr:0.0001)
96880: accuracy:0.34 loss: 218.421 (lr:0.0001)
96890: accuracy:0.3 loss: 244.043 (lr:0.0001)
96900: accuracy:0.36 loss: 201.332 (lr:0.0001)
96910: accuracy:0.37 loss: 211.458 (lr:0.0001)
96920: accuracy:0.3 loss: 222.164 (lr:0.0001)
96930: accuracy:0.24 loss: 219.835 (lr:0.0001)
96940: accuracy:0.35 loss: 199.943 (lr:0.0001)
96950: accuracy:0.38 loss: 197.142 (lr:0.0001)
96960: accuracy:0.33 loss: 229.758 (lr:0.0001)
96970: accuracy:0.29 loss: 223.189 (lr:0.0001)
96980: accuracy:0.32 loss: 221.078 (lr:0.0001)
96990: accuracy:0.26 loss: 220.936 (lr:0.0001)
97000: accuracy:0.25 loss: 231.038 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
97000: ********* epoch 10 ********* test accuracy for all:0.246365 test loss: 256.526
97000: ********* epoch 10 ********* test accuracy for mode 0:0.013 test loss: 419.601
97000: ********* epoch 10 ********* test accuracy for mode 1:0.0455 test loss: 413.493
97000: ********* epoch 10 ********* test accuracy for mode 2:0.036 test loss: 266.958
97000: ********* epoch 10 ********* test accuracy for mode 24:0.222 test loss: 274.405
97000: ********* epoch 10 ********* test accuracy for mode 25:0.2525 test loss: 250.607
97000: ********* epoch 10 ********* test accuracy for mode 26:0.449 test loss: 169.004
97000: ********* epoch 10 ********* test accuracy for mode 27:0.266 test loss: 261.594
97000: ********* epoch 10 ********* test accuracy for mode 28:0.265 test loss: 254.009
97000: ********* epoch 10 ********* test accuracy for mode 29:0.2785 test loss: 258.163
97000: ********* epoch 10 ********* test accuracy for mode 30:0.283 test loss: 244.332
97000: ********* epoch 10 ********* test accuracy for mode 31:0.1995 test loss: 251.837
97000: ********* epoch 10 ********* test accuracy for mode 32:0.2135 test loss: 242.953
97000: ********* epoch 10 ********* test accuracy for mode 33:0.2805 test loss: 245.649
97000: ********* epoch 10 ********* test accuracy for mode 34:0.144 test loss: 250.273
97000: ********* epoch 10 ********* test accuracy for mode 35:0.0025 test loss: 419.316
97000: ********* epoch 10 ********* test accuracy for mode 36:0.0835 test loss: 434.607
97010: accuracy:0.34 loss: 220.463 (lr:0.0001)
97020: accuracy:0.29 loss: 225.326 (lr:0.0001)
97030: accuracy:0.43 loss: 195.907 (lr:0.0001)
97040: accuracy:0.29 loss: 224.586 (lr:0.0001)
97050: accuracy:0.24 loss: 225.344 (lr:0.0001)
97060: accuracy:0.33 loss: 214.384 (lr:0.0001)
97070: accuracy:0.35 loss: 216.406 (lr:0.0001)
97080: accuracy:0.35 loss: 215.192 (lr:0.0001)
97090: accuracy:0.32 loss: 222.53 (lr:0.0001)
97100: accuracy:0.31 loss: 230.541 (lr:0.0001)
97110: accuracy:0.33 loss: 214.244 (lr:0.0001)
97120: accuracy:0.39 loss: 192.763 (lr:0.0001)
97130: accuracy:0.38 loss: 204.916 (lr:0.0001)
97140: accuracy:0.42 loss: 200.971 (lr:0.0001)
97150: accuracy:0.31 loss: 205.809 (lr:0.0001)
97160: accuracy:0.32 loss: 225.167 (lr:0.0001)
97170: accuracy:0.34 loss: 229.309 (lr:0.0001)
97180: accuracy:0.25 loss: 247.488 (lr:0.0001)
97190: accuracy:0.4 loss: 196.009 (lr:0.0001)
97200: accuracy:0.36 loss: 198.87 (lr:0.0001)
97210: accuracy:0.35 loss: 220.174 (lr:0.0001)
97220: accuracy:0.28 loss: 236.061 (lr:0.0001)
97230: accuracy:0.3 loss: 222.711 (lr:0.0001)
97240: accuracy:0.31 loss: 221.115 (lr:0.0001)
97250: accuracy:0.33 loss: 217.028 (lr:0.0001)
97260: accuracy:0.3 loss: 207.89 (lr:0.0001)
97270: accuracy:0.32 loss: 206.138 (lr:0.0001)
97280: accuracy:0.26 loss: 210.446 (lr:0.0001)
97290: accuracy:0.32 loss: 218.063 (lr:0.0001)
97300: accuracy:0.25 loss: 220.254 (lr:0.0001)
97310: accuracy:0.35 loss: 200.657 (lr:0.0001)
97320: accuracy:0.33 loss: 203.817 (lr:0.0001)
97330: accuracy:0.36 loss: 219.611 (lr:0.0001)
97340: accuracy:0.39 loss: 209.601 (lr:0.0001)
97350: accuracy:0.27 loss: 238.934 (lr:0.0001)
97360: accuracy:0.33 loss: 211.223 (lr:0.0001)
97370: accuracy:0.32 loss: 217.549 (lr:0.0001)
97380: accuracy:0.39 loss: 221.653 (lr:0.0001)
97390: accuracy:0.3 loss: 219.509 (lr:0.0001)
97400: accuracy:0.41 loss: 203.052 (lr:0.0001)
97410: accuracy:0.43 loss: 190.725 (lr:0.0001)
97420: accuracy:0.28 loss: 212.814 (lr:0.0001)
97430: accuracy:0.26 loss: 221.806 (lr:0.0001)
97440: accuracy:0.35 loss: 205.444 (lr:0.0001)
97450: accuracy:0.28 loss: 224.242 (lr:0.0001)
97460: accuracy:0.39 loss: 206.626 (lr:0.0001)
97470: accuracy:0.33 loss: 215.553 (lr:0.0001)
97480: accuracy:0.45 loss: 195.347 (lr:0.0001)
97490: accuracy:0.4 loss: 215.61 (lr:0.0001)
97500: accuracy:0.33 loss: 220.879 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
97500: ********* epoch 11 ********* test accuracy for all:0.25023 test loss: 255.462
97500: ********* epoch 11 ********* test accuracy for mode 0:0.009 test loss: 422.995
97500: ********* epoch 11 ********* test accuracy for mode 1:0.0445 test loss: 414.38
97500: ********* epoch 11 ********* test accuracy for mode 2:0.0655 test loss: 268.895
97500: ********* epoch 11 ********* test accuracy for mode 24:0.2385 test loss: 267.302
97500: ********* epoch 11 ********* test accuracy for mode 25:0.261 test loss: 251.502
97500: ********* epoch 11 ********* test accuracy for mode 26:0.5055 test loss: 161.147
97500: ********* epoch 11 ********* test accuracy for mode 27:0.267 test loss: 264.958
97500: ********* epoch 11 ********* test accuracy for mode 28:0.2585 test loss: 254.578
97500: ********* epoch 11 ********* test accuracy for mode 29:0.3315 test loss: 253.861
97500: ********* epoch 11 ********* test accuracy for mode 30:0.224 test loss: 248.682
97500: ********* epoch 11 ********* test accuracy for mode 31:0.2135 test loss: 250.028
97500: ********* epoch 11 ********* test accuracy for mode 32:0.2215 test loss: 239.467
97500: ********* epoch 11 ********* test accuracy for mode 33:0.231 test loss: 247.204
97500: ********* epoch 11 ********* test accuracy for mode 34:0.1755 test loss: 248.834
97500: ********* epoch 11 ********* test accuracy for mode 35:0.004 test loss: 424.67
97500: ********* epoch 11 ********* test accuracy for mode 36:0.0575 test loss: 458.436
97510: accuracy:0.29 loss: 223.323 (lr:0.0001)
97520: accuracy:0.32 loss: 217.673 (lr:0.0001)
97530: accuracy:0.2 loss: 229.292 (lr:0.0001)
97540: accuracy:0.33 loss: 228.751 (lr:0.0001)
97550: accuracy:0.33 loss: 220.207 (lr:0.0001)
97560: accuracy:0.37 loss: 208.032 (lr:0.0001)
97570: accuracy:0.22 loss: 245.798 (lr:0.0001)
97580: accuracy:0.38 loss: 206.615 (lr:0.0001)
97590: accuracy:0.3 loss: 222.055 (lr:0.0001)
97600: accuracy:0.27 loss: 217.638 (lr:0.0001)
97610: accuracy:0.34 loss: 214.811 (lr:0.0001)
97620: accuracy:0.3 loss: 234.316 (lr:0.0001)
97630: accuracy:0.31 loss: 239.238 (lr:0.0001)
97640: accuracy:0.41 loss: 205.75 (lr:0.0001)
97650: accuracy:0.29 loss: 208.721 (lr:0.0001)
97660: accuracy:0.31 loss: 230.825 (lr:0.0001)
97670: accuracy:0.26 loss: 237.206 (lr:0.0001)
97680: accuracy:0.24 loss: 230.901 (lr:0.0001)
97690: accuracy:0.31 loss: 205.946 (lr:0.0001)
97700: accuracy:0.3 loss: 212.08 (lr:0.0001)
97710: accuracy:0.29 loss: 228.242 (lr:0.0001)
97720: accuracy:0.29 loss: 232.596 (lr:0.0001)
97730: accuracy:0.28 loss: 220.733 (lr:0.0001)
97740: accuracy:0.35 loss: 207.029 (lr:0.0001)
97750: accuracy:0.39 loss: 192.674 (lr:0.0001)
97760: accuracy:0.31 loss: 208.039 (lr:0.0001)
97770: accuracy:0.31 loss: 206.319 (lr:0.0001)
97780: accuracy:0.27 loss: 235.374 (lr:0.0001)
97790: accuracy:0.27 loss: 228.139 (lr:0.0001)
97800: accuracy:0.28 loss: 219.662 (lr:0.0001)
97810: accuracy:0.3 loss: 205.338 (lr:0.0001)
97820: accuracy:0.34 loss: 220.427 (lr:0.0001)
97830: accuracy:0.33 loss: 229.029 (lr:0.0001)
97840: accuracy:0.28 loss: 223.734 (lr:0.0001)
97850: accuracy:0.32 loss: 219.229 (lr:0.0001)
97860: accuracy:0.26 loss: 201.146 (lr:0.0001)
97870: accuracy:0.24 loss: 236.841 (lr:0.0001)
97880: accuracy:0.27 loss: 222.097 (lr:0.0001)
97890: accuracy:0.41 loss: 199.049 (lr:0.0001)
97900: accuracy:0.31 loss: 216.274 (lr:0.0001)
97910: accuracy:0.26 loss: 222.59 (lr:0.0001)
97920: accuracy:0.37 loss: 208.731 (lr:0.0001)
97930: accuracy:0.43 loss: 204.186 (lr:0.0001)
97940: accuracy:0.47 loss: 189.078 (lr:0.0001)
97950: accuracy:0.32 loss: 218.991 (lr:0.0001)
97960: accuracy:0.3 loss: 209.209 (lr:0.0001)
97970: accuracy:0.28 loss: 214.24 (lr:0.0001)
97980: accuracy:0.31 loss: 228.695 (lr:0.0001)
97990: accuracy:0.31 loss: 223.074 (lr:0.0001)
98000: accuracy:0.33 loss: 208.178 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
98000: ********* epoch 11 ********* test accuracy for all:0.248622 test loss: 255.408
98000: ********* epoch 11 ********* test accuracy for mode 0:0.0085 test loss: 428.913
98000: ********* epoch 11 ********* test accuracy for mode 1:0.045 test loss: 424.556
98000: ********* epoch 11 ********* test accuracy for mode 2:0.0485 test loss: 269.596
98000: ********* epoch 11 ********* test accuracy for mode 24:0.22 test loss: 272.262
98000: ********* epoch 11 ********* test accuracy for mode 25:0.285 test loss: 245.348
98000: ********* epoch 11 ********* test accuracy for mode 26:0.471 test loss: 165.063
98000: ********* epoch 11 ********* test accuracy for mode 27:0.2355 test loss: 272.193
98000: ********* epoch 11 ********* test accuracy for mode 28:0.2675 test loss: 260.279
98000: ********* epoch 11 ********* test accuracy for mode 29:0.268 test loss: 266.234
98000: ********* epoch 11 ********* test accuracy for mode 30:0.2295 test loss: 252.24
98000: ********* epoch 11 ********* test accuracy for mode 31:0.235 test loss: 250.936
98000: ********* epoch 11 ********* test accuracy for mode 32:0.174 test loss: 246.124
98000: ********* epoch 11 ********* test accuracy for mode 33:0.2795 test loss: 246.047
98000: ********* epoch 11 ********* test accuracy for mode 34:0.1755 test loss: 248.808
98000: ********* epoch 11 ********* test accuracy for mode 35:0.0255 test loss: 409.013
98000: ********* epoch 11 ********* test accuracy for mode 36:0.067 test loss: 438.069
98010: accuracy:0.29 loss: 221.798 (lr:0.0001)
98020: accuracy:0.35 loss: 222.867 (lr:0.0001)
98030: accuracy:0.27 loss: 212.389 (lr:0.0001)
98040: accuracy:0.38 loss: 212.067 (lr:0.0001)
98050: accuracy:0.39 loss: 188.941 (lr:0.0001)
98060: accuracy:0.31 loss: 216.464 (lr:0.0001)
98070: accuracy:0.37 loss: 214.831 (lr:0.0001)
98080: accuracy:0.3 loss: 231.882 (lr:0.0001)
98090: accuracy:0.3 loss: 231.573 (lr:0.0001)
98100: accuracy:0.35 loss: 206.856 (lr:0.0001)
98110: accuracy:0.34 loss: 214.226 (lr:0.0001)
98120: accuracy:0.39 loss: 200.438 (lr:0.0001)
98130: accuracy:0.37 loss: 214.304 (lr:0.0001)
98140: accuracy:0.38 loss: 210.057 (lr:0.0001)
98150: accuracy:0.38 loss: 210.338 (lr:0.0001)
98160: accuracy:0.34 loss: 230.697 (lr:0.0001)
98170: accuracy:0.34 loss: 232.447 (lr:0.0001)
98180: accuracy:0.41 loss: 211.521 (lr:0.0001)
98190: accuracy:0.32 loss: 209.327 (lr:0.0001)
98200: accuracy:0.3 loss: 214.923 (lr:0.0001)
98210: accuracy:0.23 loss: 218.81 (lr:0.0001)
98220: accuracy:0.38 loss: 218.814 (lr:0.0001)
98230: accuracy:0.35 loss: 199.442 (lr:0.0001)
98240: accuracy:0.36 loss: 208.504 (lr:0.0001)
98250: accuracy:0.25 loss: 220.598 (lr:0.0001)
98260: accuracy:0.34 loss: 214.121 (lr:0.0001)
98270: accuracy:0.3 loss: 230.384 (lr:0.0001)
98280: accuracy:0.3 loss: 218.213 (lr:0.0001)
98290: accuracy:0.34 loss: 215.05 (lr:0.0001)
98300: accuracy:0.37 loss: 204.578 (lr:0.0001)
98310: accuracy:0.32 loss: 223.074 (lr:0.0001)
98320: accuracy:0.33 loss: 206.146 (lr:0.0001)
98330: accuracy:0.28 loss: 203.402 (lr:0.0001)
98340: accuracy:0.32 loss: 238.007 (lr:0.0001)
98350: accuracy:0.37 loss: 204.909 (lr:0.0001)
98360: accuracy:0.3 loss: 208.288 (lr:0.0001)
98370: accuracy:0.22 loss: 239.432 (lr:0.0001)
98380: accuracy:0.37 loss: 214.161 (lr:0.0001)
98390: accuracy:0.35 loss: 220.557 (lr:0.0001)
98400: accuracy:0.34 loss: 238.045 (lr:0.0001)
98410: accuracy:0.33 loss: 215.978 (lr:0.0001)
98420: accuracy:0.36 loss: 198.881 (lr:0.0001)
98430: accuracy:0.38 loss: 205.393 (lr:0.0001)
98440: accuracy:0.39 loss: 194.637 (lr:0.0001)
98450: accuracy:0.36 loss: 207.412 (lr:0.0001)
98460: accuracy:0.29 loss: 216.907 (lr:0.0001)
98470: accuracy:0.37 loss: 204.264 (lr:0.0001)
98480: accuracy:0.24 loss: 253.787 (lr:0.0001)
98490: accuracy:0.29 loss: 225.908 (lr:0.0001)
98500: accuracy:0.34 loss: 216.708 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
98500: ********* epoch 11 ********* test accuracy for all:0.246122 test loss: 254.434
98500: ********* epoch 11 ********* test accuracy for mode 0:0.0105 test loss: 404.548
98500: ********* epoch 11 ********* test accuracy for mode 1:0.065 test loss: 389.838
98500: ********* epoch 11 ********* test accuracy for mode 2:0.059 test loss: 272.045
98500: ********* epoch 11 ********* test accuracy for mode 24:0.258 test loss: 265.532
98500: ********* epoch 11 ********* test accuracy for mode 25:0.2685 test loss: 248.37
98500: ********* epoch 11 ********* test accuracy for mode 26:0.4455 test loss: 165.816
98500: ********* epoch 11 ********* test accuracy for mode 27:0.248 test loss: 271.336
98500: ********* epoch 11 ********* test accuracy for mode 28:0.2745 test loss: 258.499
98500: ********* epoch 11 ********* test accuracy for mode 29:0.286 test loss: 264.321
98500: ********* epoch 11 ********* test accuracy for mode 30:0.2475 test loss: 256.117
98500: ********* epoch 11 ********* test accuracy for mode 31:0.182 test loss: 261.782
98500: ********* epoch 11 ********* test accuracy for mode 32:0.214 test loss: 251.266
98500: ********* epoch 11 ********* test accuracy for mode 33:0.2295 test loss: 253.04
98500: ********* epoch 11 ********* test accuracy for mode 34:0.1775 test loss: 252.605
98500: ********* epoch 11 ********* test accuracy for mode 35:0.035 test loss: 391.152
98500: ********* epoch 11 ********* test accuracy for mode 36:0.1045 test loss: 414.668
98510: accuracy:0.35 loss: 222.732 (lr:0.0001)
98520: accuracy:0.34 loss: 212.186 (lr:0.0001)
98530: accuracy:0.31 loss: 229.387 (lr:0.0001)
98540: accuracy:0.34 loss: 222.226 (lr:0.0001)
98550: accuracy:0.33 loss: 221.923 (lr:0.0001)
98560: accuracy:0.31 loss: 225.04 (lr:0.0001)
98570: accuracy:0.34 loss: 220.818 (lr:0.0001)
98580: accuracy:0.3 loss: 211.8 (lr:0.0001)
98590: accuracy:0.35 loss: 227.426 (lr:0.0001)
98600: accuracy:0.34 loss: 235.49 (lr:0.0001)
98610: accuracy:0.36 loss: 226.567 (lr:0.0001)
98620: accuracy:0.34 loss: 208.243 (lr:0.0001)
98630: accuracy:0.37 loss: 220.864 (lr:0.0001)
98640: accuracy:0.31 loss: 202.288 (lr:0.0001)
98650: accuracy:0.29 loss: 216.232 (lr:0.0001)
98660: accuracy:0.28 loss: 211.385 (lr:0.0001)
98670: accuracy:0.34 loss: 208.039 (lr:0.0001)
98680: accuracy:0.32 loss: 214.672 (lr:0.0001)
98690: accuracy:0.39 loss: 202.007 (lr:0.0001)
98700: accuracy:0.43 loss: 190.729 (lr:0.0001)
98710: accuracy:0.28 loss: 241.833 (lr:0.0001)
98720: accuracy:0.37 loss: 215.154 (lr:0.0001)
98730: accuracy:0.4 loss: 195.717 (lr:0.0001)
98740: accuracy:0.31 loss: 232.81 (lr:0.0001)
98750: accuracy:0.27 loss: 236.3 (lr:0.0001)
98760: accuracy:0.32 loss: 228.397 (lr:0.0001)
98770: accuracy:0.31 loss: 209.214 (lr:0.0001)
98780: accuracy:0.36 loss: 208.352 (lr:0.0001)
98790: accuracy:0.37 loss: 203.28 (lr:0.0001)
98800: accuracy:0.38 loss: 202.039 (lr:0.0001)
98810: accuracy:0.29 loss: 222.872 (lr:0.0001)
98820: accuracy:0.4 loss: 192.701 (lr:0.0001)
98830: accuracy:0.35 loss: 205.575 (lr:0.0001)
98840: accuracy:0.22 loss: 235.209 (lr:0.0001)
98850: accuracy:0.36 loss: 214.777 (lr:0.0001)
98860: accuracy:0.25 loss: 211.91 (lr:0.0001)
98870: accuracy:0.33 loss: 235.64 (lr:0.0001)
98880: accuracy:0.24 loss: 215.599 (lr:0.0001)
98890: accuracy:0.38 loss: 207.338 (lr:0.0001)
98900: accuracy:0.31 loss: 233.875 (lr:0.0001)
98910: accuracy:0.37 loss: 197.981 (lr:0.0001)
98920: accuracy:0.29 loss: 225.162 (lr:0.0001)
98930: accuracy:0.3 loss: 236.536 (lr:0.0001)
98940: accuracy:0.3 loss: 222.65 (lr:0.0001)
98950: accuracy:0.25 loss: 220.601 (lr:0.0001)
98960: accuracy:0.31 loss: 225.047 (lr:0.0001)
98970: accuracy:0.27 loss: 223.25 (lr:0.0001)
98980: accuracy:0.38 loss: 202.317 (lr:0.0001)
98990: accuracy:0.33 loss: 209.258 (lr:0.0001)
99000: accuracy:0.32 loss: 214.0 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
99000: ********* epoch 11 ********* test accuracy for all:0.248068 test loss: 254.678
99000: ********* epoch 11 ********* test accuracy for mode 0:0.0085 test loss: 423.376
99000: ********* epoch 11 ********* test accuracy for mode 1:0.042 test loss: 413.985
99000: ********* epoch 11 ********* test accuracy for mode 2:0.055 test loss: 269.716
99000: ********* epoch 11 ********* test accuracy for mode 24:0.248 test loss: 269.66
99000: ********* epoch 11 ********* test accuracy for mode 25:0.2765 test loss: 248.516
99000: ********* epoch 11 ********* test accuracy for mode 26:0.379 test loss: 173.664
99000: ********* epoch 11 ********* test accuracy for mode 27:0.262 test loss: 263.286
99000: ********* epoch 11 ********* test accuracy for mode 28:0.273 test loss: 252.737
99000: ********* epoch 11 ********* test accuracy for mode 29:0.277 test loss: 257.533
99000: ********* epoch 11 ********* test accuracy for mode 30:0.281 test loss: 244.427
99000: ********* epoch 11 ********* test accuracy for mode 31:0.1775 test loss: 250.544
99000: ********* epoch 11 ********* test accuracy for mode 32:0.224 test loss: 242.039
99000: ********* epoch 11 ********* test accuracy for mode 33:0.26 test loss: 244.92
99000: ********* epoch 11 ********* test accuracy for mode 34:0.179 test loss: 248.402
99000: ********* epoch 11 ********* test accuracy for mode 35:0.0235 test loss: 413.811
99000: ********* epoch 11 ********* test accuracy for mode 36:0.127 test loss: 427.773
99010: accuracy:0.4 loss: 208.059 (lr:0.0001)
99020: accuracy:0.26 loss: 230.475 (lr:0.0001)
99030: accuracy:0.23 loss: 215.56 (lr:0.0001)
99040: accuracy:0.26 loss: 208.482 (lr:0.0001)
99050: accuracy:0.31 loss: 235.405 (lr:0.0001)
99060: accuracy:0.35 loss: 207.475 (lr:0.0001)
99070: accuracy:0.34 loss: 215.692 (lr:0.0001)
99080: accuracy:0.34 loss: 221.255 (lr:0.0001)
99090: accuracy:0.43 loss: 201.137 (lr:0.0001)
99100: accuracy:0.33 loss: 208.324 (lr:0.0001)
99110: accuracy:0.31 loss: 217.919 (lr:0.0001)
99120: accuracy:0.34 loss: 211.383 (lr:0.0001)
99130: accuracy:0.36 loss: 216.821 (lr:0.0001)
99140: accuracy:0.36 loss: 230.328 (lr:0.0001)
99150: accuracy:0.35 loss: 219.302 (lr:0.0001)
99160: accuracy:0.28 loss: 222.427 (lr:0.0001)
99170: accuracy:0.27 loss: 228.953 (lr:0.0001)
99180: accuracy:0.44 loss: 193.223 (lr:0.0001)
99190: accuracy:0.28 loss: 226.918 (lr:0.0001)
99200: accuracy:0.39 loss: 202.039 (lr:0.0001)
99210: accuracy:0.3 loss: 219.206 (lr:0.0001)
99220: accuracy:0.32 loss: 208.211 (lr:0.0001)
99230: accuracy:0.3 loss: 228.306 (lr:0.0001)
99240: accuracy:0.29 loss: 223.976 (lr:0.0001)
99250: accuracy:0.36 loss: 185.408 (lr:0.0001)
99260: accuracy:0.34 loss: 233.468 (lr:0.0001)
99270: accuracy:0.28 loss: 209.83 (lr:0.0001)
99280: accuracy:0.38 loss: 218.264 (lr:0.0001)
99290: accuracy:0.34 loss: 208.669 (lr:0.0001)
99300: accuracy:0.27 loss: 225.255 (lr:0.0001)
99310: accuracy:0.34 loss: 256.72 (lr:0.0001)
99320: accuracy:0.31 loss: 221.279 (lr:0.0001)
99330: accuracy:0.26 loss: 223.423 (lr:0.0001)
99340: accuracy:0.24 loss: 240.909 (lr:0.0001)
99350: accuracy:0.39 loss: 203.521 (lr:0.0001)
99360: accuracy:0.25 loss: 232.395 (lr:0.0001)
99370: accuracy:0.35 loss: 194.809 (lr:0.0001)
99380: accuracy:0.37 loss: 208.65 (lr:0.0001)
99390: accuracy:0.29 loss: 228.277 (lr:0.0001)
99400: accuracy:0.29 loss: 208.592 (lr:0.0001)
99410: accuracy:0.31 loss: 222.527 (lr:0.0001)
99420: accuracy:0.34 loss: 206.374 (lr:0.0001)
99430: accuracy:0.28 loss: 201.24 (lr:0.0001)
99440: accuracy:0.25 loss: 229.999 (lr:0.0001)
99450: accuracy:0.34 loss: 204.702 (lr:0.0001)
99460: accuracy:0.29 loss: 218.619 (lr:0.0001)
99470: accuracy:0.31 loss: 208.483 (lr:0.0001)
99480: accuracy:0.3 loss: 220.082 (lr:0.0001)
99490: accuracy:0.45 loss: 206.618 (lr:0.0001)
99500: accuracy:0.33 loss: 230.74 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
99500: ********* epoch 11 ********* test accuracy for all:0.246986 test loss: 256.136
99500: ********* epoch 11 ********* test accuracy for mode 0:0.01 test loss: 422.15
99500: ********* epoch 11 ********* test accuracy for mode 1:0.0445 test loss: 409.703
99500: ********* epoch 11 ********* test accuracy for mode 2:0.071 test loss: 263.825
99500: ********* epoch 11 ********* test accuracy for mode 24:0.223 test loss: 276.145
99500: ********* epoch 11 ********* test accuracy for mode 25:0.276 test loss: 251.873
99500: ********* epoch 11 ********* test accuracy for mode 26:0.4295 test loss: 165.623
99500: ********* epoch 11 ********* test accuracy for mode 27:0.262 test loss: 265.788
99500: ********* epoch 11 ********* test accuracy for mode 28:0.289 test loss: 252.017
99500: ********* epoch 11 ********* test accuracy for mode 29:0.274 test loss: 260.863
99500: ********* epoch 11 ********* test accuracy for mode 30:0.214 test loss: 255.037
99500: ********* epoch 11 ********* test accuracy for mode 31:0.228 test loss: 251.652
99500: ********* epoch 11 ********* test accuracy for mode 32:0.216 test loss: 244.821
99500: ********* epoch 11 ********* test accuracy for mode 33:0.2695 test loss: 248.135
99500: ********* epoch 11 ********* test accuracy for mode 34:0.1185 test loss: 254.172
99500: ********* epoch 11 ********* test accuracy for mode 35:0.0095 test loss: 430.362
99500: ********* epoch 11 ********* test accuracy for mode 36:0.073 test loss: 445.352
99510: accuracy:0.33 loss: 225.693 (lr:0.0001)
99520: accuracy:0.31 loss: 214.425 (lr:0.0001)
99530: accuracy:0.29 loss: 220.205 (lr:0.0001)
99540: accuracy:0.37 loss: 209.408 (lr:0.0001)
99550: accuracy:0.28 loss: 221.402 (lr:0.0001)
99560: accuracy:0.38 loss: 198.912 (lr:0.0001)
99570: accuracy:0.31 loss: 209.285 (lr:0.0001)
99580: accuracy:0.35 loss: 216.99 (lr:0.0001)
99590: accuracy:0.34 loss: 206.445 (lr:0.0001)
99600: accuracy:0.23 loss: 230.255 (lr:0.0001)
99610: accuracy:0.29 loss: 211.45 (lr:0.0001)
99620: accuracy:0.38 loss: 208.074 (lr:0.0001)
99630: accuracy:0.34 loss: 219.629 (lr:0.0001)
99640: accuracy:0.24 loss: 236.825 (lr:0.0001)
99650: accuracy:0.35 loss: 211.585 (lr:0.0001)
99660: accuracy:0.3 loss: 210.693 (lr:0.0001)
99670: accuracy:0.31 loss: 210.128 (lr:0.0001)
99680: accuracy:0.35 loss: 210.314 (lr:0.0001)
99690: accuracy:0.31 loss: 236.992 (lr:0.0001)
99700: accuracy:0.29 loss: 252.581 (lr:0.0001)
99710: accuracy:0.33 loss: 220.513 (lr:0.0001)
99720: accuracy:0.3 loss: 211.208 (lr:0.0001)
99730: accuracy:0.33 loss: 218.517 (lr:0.0001)
99740: accuracy:0.31 loss: 200.405 (lr:0.0001)
99750: accuracy:0.38 loss: 206.485 (lr:0.0001)
99760: accuracy:0.23 loss: 228.601 (lr:0.0001)
99770: accuracy:0.32 loss: 219.358 (lr:0.0001)
99780: accuracy:0.37 loss: 215.941 (lr:0.0001)
99790: accuracy:0.32 loss: 223.929 (lr:0.0001)
99800: accuracy:0.3 loss: 212.651 (lr:0.0001)
99810: accuracy:0.41 loss: 210.393 (lr:0.0001)
99820: accuracy:0.29 loss: 226.576 (lr:0.0001)
99830: accuracy:0.25 loss: 225.212 (lr:0.0001)
99840: accuracy:0.28 loss: 200.037 (lr:0.0001)
99850: accuracy:0.28 loss: 209.551 (lr:0.0001)
99860: accuracy:0.26 loss: 228.395 (lr:0.0001)
99870: accuracy:0.33 loss: 224.18 (lr:0.0001)
99880: accuracy:0.36 loss: 224.992 (lr:0.0001)
99890: accuracy:0.28 loss: 229.735 (lr:0.0001)
99900: accuracy:0.29 loss: 229.403 (lr:0.0001)
99910: accuracy:0.36 loss: 198.772 (lr:0.0001)
99920: accuracy:0.25 loss: 236.592 (lr:0.0001)
99930: accuracy:0.31 loss: 222.986 (lr:0.0001)
99940: accuracy:0.33 loss: 230.183 (lr:0.0001)
99950: accuracy:0.34 loss: 226.624 (lr:0.0001)
99960: accuracy:0.32 loss: 213.85 (lr:0.0001)
99970: accuracy:0.29 loss: 220.965 (lr:0.0001)
99980: accuracy:0.34 loss: 205.783 (lr:0.0001)
99990: accuracy:0.36 loss: 211.964 (lr:0.0001)
100000: accuracy:0.31 loss: 241.515 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
100000: ********* epoch 11 ********* test accuracy for all:0.246324 test loss: 257.703
100000: ********* epoch 11 ********* test accuracy for mode 0:0.01 test loss: 427.978
100000: ********* epoch 11 ********* test accuracy for mode 1:0.0405 test loss: 419.032
100000: ********* epoch 11 ********* test accuracy for mode 2:0.0675 test loss: 260.078
100000: ********* epoch 11 ********* test accuracy for mode 24:0.2175 test loss: 280.593
100000: ********* epoch 11 ********* test accuracy for mode 25:0.267 test loss: 262.091
100000: ********* epoch 11 ********* test accuracy for mode 26:0.4585 test loss: 164.61
100000: ********* epoch 11 ********* test accuracy for mode 27:0.2635 test loss: 273.535
100000: ********* epoch 11 ********* test accuracy for mode 28:0.2915 test loss: 262.132
100000: ********* epoch 11 ********* test accuracy for mode 29:0.249 test loss: 266.143
100000: ********* epoch 11 ********* test accuracy for mode 30:0.2525 test loss: 252.179
100000: ********* epoch 11 ********* test accuracy for mode 31:0.1885 test loss: 251.853
100000: ********* epoch 11 ********* test accuracy for mode 32:0.2105 test loss: 242.534
100000: ********* epoch 11 ********* test accuracy for mode 33:0.2825 test loss: 243.674
100000: ********* epoch 11 ********* test accuracy for mode 34:0.1395 test loss: 251.241
100000: ********* epoch 11 ********* test accuracy for mode 35:0.0185 test loss: 421.766
100000: ********* epoch 11 ********* test accuracy for mode 36:0.085 test loss: 454.967
100010: accuracy:0.29 loss: 212.856 (lr:0.0001)
100020: accuracy:0.36 loss: 206.807 (lr:0.0001)
100030: accuracy:0.29 loss: 213.672 (lr:0.0001)
100040: accuracy:0.4 loss: 202.392 (lr:0.0001)
100050: accuracy:0.3 loss: 217.49 (lr:0.0001)
100060: accuracy:0.29 loss: 215.828 (lr:0.0001)
100070: accuracy:0.26 loss: 227.621 (lr:0.0001)
100080: accuracy:0.29 loss: 224.923 (lr:0.0001)
100090: accuracy:0.22 loss: 227.962 (lr:0.0001)
100100: accuracy:0.38 loss: 216.298 (lr:0.0001)
100110: accuracy:0.33 loss: 211.982 (lr:0.0001)
100120: accuracy:0.33 loss: 224.782 (lr:0.0001)
100130: accuracy:0.32 loss: 230.84 (lr:0.0001)
100140: accuracy:0.27 loss: 223.651 (lr:0.0001)
100150: accuracy:0.37 loss: 219.945 (lr:0.0001)
100160: accuracy:0.29 loss: 214.548 (lr:0.0001)
100170: accuracy:0.31 loss: 219.253 (lr:0.0001)
100180: accuracy:0.35 loss: 203.515 (lr:0.0001)
100190: accuracy:0.35 loss: 204.524 (lr:0.0001)
100200: accuracy:0.41 loss: 203.47 (lr:0.0001)
100210: accuracy:0.32 loss: 243.226 (lr:0.0001)
100220: accuracy:0.33 loss: 220.297 (lr:0.0001)
100230: accuracy:0.27 loss: 229.553 (lr:0.0001)
100240: accuracy:0.31 loss: 214.841 (lr:0.0001)
100250: accuracy:0.23 loss: 228.526 (lr:0.0001)
100260: accuracy:0.33 loss: 224.024 (lr:0.0001)
100270: accuracy:0.35 loss: 211.826 (lr:0.0001)
100280: accuracy:0.33 loss: 204.196 (lr:0.0001)
100290: accuracy:0.34 loss: 232.842 (lr:0.0001)
100300: accuracy:0.34 loss: 187.311 (lr:0.0001)
100310: accuracy:0.26 loss: 206.886 (lr:0.0001)
100320: accuracy:0.28 loss: 213.172 (lr:0.0001)
100330: accuracy:0.31 loss: 202.761 (lr:0.0001)
100340: accuracy:0.34 loss: 222.024 (lr:0.0001)
100350: accuracy:0.32 loss: 225.667 (lr:0.0001)
100360: accuracy:0.28 loss: 219.901 (lr:0.0001)
100370: accuracy:0.3 loss: 212.539 (lr:0.0001)
100380: accuracy:0.26 loss: 219.295 (lr:0.0001)
100390: accuracy:0.41 loss: 204.013 (lr:0.0001)
100400: accuracy:0.35 loss: 215.234 (lr:0.0001)
100410: accuracy:0.32 loss: 214.41 (lr:0.0001)
100420: accuracy:0.32 loss: 219.658 (lr:0.0001)
100430: accuracy:0.37 loss: 207.491 (lr:0.0001)
100440: accuracy:0.36 loss: 210.378 (lr:0.0001)
100450: accuracy:0.28 loss: 219.068 (lr:0.0001)
100460: accuracy:0.36 loss: 231.264 (lr:0.0001)
100470: accuracy:0.28 loss: 220.596 (lr:0.0001)
100480: accuracy:0.33 loss: 213.308 (lr:0.0001)
100490: accuracy:0.36 loss: 202.415 (lr:0.0001)
100500: accuracy:0.26 loss: 212.229 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
100500: ********* epoch 11 ********* test accuracy for all:0.252216 test loss: 253.715
100500: ********* epoch 11 ********* test accuracy for mode 0:0.0115 test loss: 419.966
100500: ********* epoch 11 ********* test accuracy for mode 1:0.044 test loss: 408.436
100500: ********* epoch 11 ********* test accuracy for mode 2:0.055 test loss: 268.899
100500: ********* epoch 11 ********* test accuracy for mode 24:0.2775 test loss: 254.572
100500: ********* epoch 11 ********* test accuracy for mode 25:0.3295 test loss: 233.099
100500: ********* epoch 11 ********* test accuracy for mode 26:0.4315 test loss: 163.69
100500: ********* epoch 11 ********* test accuracy for mode 27:0.2485 test loss: 263.116
100500: ********* epoch 11 ********* test accuracy for mode 28:0.288 test loss: 251.355
100500: ********* epoch 11 ********* test accuracy for mode 29:0.265 test loss: 262.871
100500: ********* epoch 11 ********* test accuracy for mode 30:0.2705 test loss: 252.634
100500: ********* epoch 11 ********* test accuracy for mode 31:0.1525 test loss: 262.363
100500: ********* epoch 11 ********* test accuracy for mode 32:0.236 test loss: 247.271
100500: ********* epoch 11 ********* test accuracy for mode 33:0.249 test loss: 250.959
100500: ********* epoch 11 ********* test accuracy for mode 34:0.188 test loss: 251.053
100500: ********* epoch 11 ********* test accuracy for mode 35:0.018 test loss: 425.726
100500: ********* epoch 11 ********* test accuracy for mode 36:0.068 test loss: 437.916
100510: accuracy:0.29 loss: 208.193 (lr:0.0001)
100520: accuracy:0.34 loss: 213.948 (lr:0.0001)
100530: accuracy:0.36 loss: 229.223 (lr:0.0001)
100540: accuracy:0.34 loss: 210.58 (lr:0.0001)
100550: accuracy:0.26 loss: 221.731 (lr:0.0001)
100560: accuracy:0.38 loss: 194.873 (lr:0.0001)
100570: accuracy:0.34 loss: 216.984 (lr:0.0001)
100580: accuracy:0.33 loss: 215.876 (lr:0.0001)
100590: accuracy:0.39 loss: 204.987 (lr:0.0001)
100600: accuracy:0.3 loss: 225.622 (lr:0.0001)
100610: accuracy:0.4 loss: 231.429 (lr:0.0001)
100620: accuracy:0.22 loss: 241.752 (lr:0.0001)
100630: accuracy:0.34 loss: 201.412 (lr:0.0001)
100640: accuracy:0.25 loss: 225.771 (lr:0.0001)
100650: accuracy:0.31 loss: 225.256 (lr:0.0001)
100660: accuracy:0.25 loss: 215.027 (lr:0.0001)
100670: accuracy:0.39 loss: 209.003 (lr:0.0001)
100680: accuracy:0.34 loss: 235.356 (lr:0.0001)
100690: accuracy:0.42 loss: 201.302 (lr:0.0001)
100700: accuracy:0.28 loss: 256.067 (lr:0.0001)
100710: accuracy:0.3 loss: 216.646 (lr:0.0001)
100720: accuracy:0.25 loss: 231.687 (lr:0.0001)
100730: accuracy:0.28 loss: 215.544 (lr:0.0001)
100740: accuracy:0.26 loss: 223.411 (lr:0.0001)
100750: accuracy:0.3 loss: 216.55 (lr:0.0001)
100760: accuracy:0.39 loss: 202.022 (lr:0.0001)
100770: accuracy:0.25 loss: 241.889 (lr:0.0001)
100780: accuracy:0.33 loss: 226.001 (lr:0.0001)
100790: accuracy:0.28 loss: 227.395 (lr:0.0001)
100800: accuracy:0.25 loss: 210.177 (lr:0.0001)
100810: accuracy:0.38 loss: 196.257 (lr:0.0001)
100820: accuracy:0.27 loss: 222.024 (lr:0.0001)
100830: accuracy:0.36 loss: 197.593 (lr:0.0001)
100840: accuracy:0.31 loss: 211.932 (lr:0.0001)
100850: accuracy:0.31 loss: 214.997 (lr:0.0001)
100860: accuracy:0.32 loss: 211.122 (lr:0.0001)
100870: accuracy:0.28 loss: 216.307 (lr:0.0001)
100880: accuracy:0.37 loss: 220.665 (lr:0.0001)
100890: accuracy:0.35 loss: 211.065 (lr:0.0001)
100900: accuracy:0.36 loss: 198.663 (lr:0.0001)
100910: accuracy:0.31 loss: 214.923 (lr:0.0001)
100920: accuracy:0.44 loss: 190.066 (lr:0.0001)
100930: accuracy:0.33 loss: 225.068 (lr:0.0001)
100940: accuracy:0.23 loss: 237.056 (lr:0.0001)
100950: accuracy:0.27 loss: 234.64 (lr:0.0001)
100960: accuracy:0.29 loss: 199.574 (lr:0.0001)
100970: accuracy:0.32 loss: 221.376 (lr:0.0001)
100980: accuracy:0.31 loss: 225.436 (lr:0.0001)
100990: accuracy:0.34 loss: 204.68 (lr:0.0001)
101000: accuracy:0.36 loss: 195.433 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
101000: ********* epoch 11 ********* test accuracy for all:0.249649 test loss: 255.199
101000: ********* epoch 11 ********* test accuracy for mode 0:0.014 test loss: 420.446
101000: ********* epoch 11 ********* test accuracy for mode 1:0.039 test loss: 419.175
101000: ********* epoch 11 ********* test accuracy for mode 2:0.0655 test loss: 265.903
101000: ********* epoch 11 ********* test accuracy for mode 24:0.244 test loss: 269.099
101000: ********* epoch 11 ********* test accuracy for mode 25:0.2635 test loss: 251.106
101000: ********* epoch 11 ********* test accuracy for mode 26:0.466 test loss: 166.268
101000: ********* epoch 11 ********* test accuracy for mode 27:0.236 test loss: 272.045
101000: ********* epoch 11 ********* test accuracy for mode 28:0.276 test loss: 259.152
101000: ********* epoch 11 ********* test accuracy for mode 29:0.254 test loss: 262.891
101000: ********* epoch 11 ********* test accuracy for mode 30:0.2825 test loss: 242.089
101000: ********* epoch 11 ********* test accuracy for mode 31:0.1945 test loss: 246.362
101000: ********* epoch 11 ********* test accuracy for mode 32:0.232 test loss: 238.129
101000: ********* epoch 11 ********* test accuracy for mode 33:0.26 test loss: 242.839
101000: ********* epoch 11 ********* test accuracy for mode 34:0.1865 test loss: 244.647
101000: ********* epoch 11 ********* test accuracy for mode 35:0.0215 test loss: 414.044
101000: ********* epoch 11 ********* test accuracy for mode 36:0.1005 test loss: 413.921
101010: accuracy:0.32 loss: 200.291 (lr:0.0001)
101020: accuracy:0.27 loss: 213.427 (lr:0.0001)
101030: accuracy:0.34 loss: 215.436 (lr:0.0001)
101040: accuracy:0.32 loss: 205.823 (lr:0.0001)
101050: accuracy:0.36 loss: 203.142 (lr:0.0001)
101060: accuracy:0.35 loss: 214.796 (lr:0.0001)
101070: accuracy:0.33 loss: 208.773 (lr:0.0001)
101080: accuracy:0.34 loss: 227.768 (lr:0.0001)
101090: accuracy:0.38 loss: 215.333 (lr:0.0001)
101100: accuracy:0.3 loss: 218.723 (lr:0.0001)
101110: accuracy:0.33 loss: 217.207 (lr:0.0001)
101120: accuracy:0.37 loss: 224.698 (lr:0.0001)
101130: accuracy:0.37 loss: 220.547 (lr:0.0001)
101140: accuracy:0.27 loss: 210.959 (lr:0.0001)
101150: accuracy:0.4 loss: 213.636 (lr:0.0001)
101160: accuracy:0.32 loss: 203.731 (lr:0.0001)
101170: accuracy:0.33 loss: 197.58 (lr:0.0001)
101180: accuracy:0.36 loss: 210.739 (lr:0.0001)
101190: accuracy:0.41 loss: 211.606 (lr:0.0001)
101200: accuracy:0.28 loss: 216.318 (lr:0.0001)
101210: accuracy:0.24 loss: 218.264 (lr:0.0001)
101220: accuracy:0.32 loss: 213.792 (lr:0.0001)
101230: accuracy:0.39 loss: 207.744 (lr:0.0001)
101240: accuracy:0.25 loss: 212.3 (lr:0.0001)
101250: accuracy:0.33 loss: 225.831 (lr:0.0001)
101260: accuracy:0.42 loss: 200.611 (lr:0.0001)
101270: accuracy:0.31 loss: 209.721 (lr:0.0001)
101280: accuracy:0.36 loss: 223.518 (lr:0.0001)
101290: accuracy:0.39 loss: 200.794 (lr:0.0001)
101300: accuracy:0.33 loss: 226.45 (lr:0.0001)
101310: accuracy:0.32 loss: 228.051 (lr:0.0001)
101320: accuracy:0.38 loss: 218.676 (lr:0.0001)
101330: accuracy:0.4 loss: 202.254 (lr:0.0001)
101340: accuracy:0.34 loss: 206.435 (lr:0.0001)
101350: accuracy:0.25 loss: 240.172 (lr:0.0001)
101360: accuracy:0.37 loss: 207.338 (lr:0.0001)
101370: accuracy:0.28 loss: 205.183 (lr:0.0001)
101380: accuracy:0.28 loss: 218.129 (lr:0.0001)
101390: accuracy:0.4 loss: 201.884 (lr:0.0001)
101400: accuracy:0.28 loss: 215.433 (lr:0.0001)
101410: accuracy:0.36 loss: 223.443 (lr:0.0001)
101420: accuracy:0.34 loss: 223.127 (lr:0.0001)
101430: accuracy:0.3 loss: 218.245 (lr:0.0001)
101440: accuracy:0.4 loss: 209.497 (lr:0.0001)
101450: accuracy:0.31 loss: 218.981 (lr:0.0001)
101460: accuracy:0.34 loss: 199.09 (lr:0.0001)
101470: accuracy:0.35 loss: 209.07 (lr:0.0001)
101480: accuracy:0.27 loss: 231.842 (lr:0.0001)
101490: accuracy:0.39 loss: 202.01 (lr:0.0001)
101500: accuracy:0.41 loss: 199.442 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
101500: ********* epoch 11 ********* test accuracy for all:0.24827 test loss: 256.089
101500: ********* epoch 11 ********* test accuracy for mode 0:0.016 test loss: 421.584
101500: ********* epoch 11 ********* test accuracy for mode 1:0.047 test loss: 415.549
101500: ********* epoch 11 ********* test accuracy for mode 2:0.0525 test loss: 269.499
101500: ********* epoch 11 ********* test accuracy for mode 24:0.2 test loss: 273.808
101500: ********* epoch 11 ********* test accuracy for mode 25:0.2825 test loss: 249.519
101500: ********* epoch 11 ********* test accuracy for mode 26:0.4185 test loss: 172.248
101500: ********* epoch 11 ********* test accuracy for mode 27:0.2395 test loss: 272.547
101500: ********* epoch 11 ********* test accuracy for mode 28:0.26 test loss: 260.048
101500: ********* epoch 11 ********* test accuracy for mode 29:0.2755 test loss: 262.721
101500: ********* epoch 11 ********* test accuracy for mode 30:0.2445 test loss: 251.011
101500: ********* epoch 11 ********* test accuracy for mode 31:0.2125 test loss: 250.616
101500: ********* epoch 11 ********* test accuracy for mode 32:0.2485 test loss: 237.29
101500: ********* epoch 11 ********* test accuracy for mode 33:0.282 test loss: 243.233
101500: ********* epoch 11 ********* test accuracy for mode 34:0.109 test loss: 252.861
101500: ********* epoch 11 ********* test accuracy for mode 35:0.0265 test loss: 411.138
101500: ********* epoch 11 ********* test accuracy for mode 36:0.0845 test loss: 451.049
101510: accuracy:0.28 loss: 221.493 (lr:0.0001)
101520: accuracy:0.26 loss: 219.659 (lr:0.0001)
101530: accuracy:0.41 loss: 194.598 (lr:0.0001)
101540: accuracy:0.34 loss: 193.584 (lr:0.0001)
101550: accuracy:0.42 loss: 196.123 (lr:0.0001)
101560: accuracy:0.22 loss: 235.257 (lr:0.0001)
101570: accuracy:0.25 loss: 224.165 (lr:0.0001)
101580: accuracy:0.33 loss: 213.219 (lr:0.0001)
101590: accuracy:0.3 loss: 222.301 (lr:0.0001)
101600: accuracy:0.3 loss: 202.034 (lr:0.0001)
101610: accuracy:0.37 loss: 207.982 (lr:0.0001)
101620: accuracy:0.3 loss: 220.603 (lr:0.0001)
101630: accuracy:0.31 loss: 228.246 (lr:0.0001)
101640: accuracy:0.34 loss: 221.93 (lr:0.0001)
101650: accuracy:0.36 loss: 213.133 (lr:0.0001)
101660: accuracy:0.3 loss: 218.445 (lr:0.0001)
101670: accuracy:0.34 loss: 213.092 (lr:0.0001)
101680: accuracy:0.3 loss: 222.953 (lr:0.0001)
101690: accuracy:0.3 loss: 218.114 (lr:0.0001)
101700: accuracy:0.3 loss: 217.768 (lr:0.0001)
101710: accuracy:0.27 loss: 212.303 (lr:0.0001)
101720: accuracy:0.34 loss: 191.704 (lr:0.0001)
101730: accuracy:0.3 loss: 218.478 (lr:0.0001)
101740: accuracy:0.35 loss: 193.61 (lr:0.0001)
101750: accuracy:0.36 loss: 216.53 (lr:0.0001)
101760: accuracy:0.29 loss: 218.019 (lr:0.0001)
101770: accuracy:0.33 loss: 211.504 (lr:0.0001)
101780: accuracy:0.29 loss: 209.164 (lr:0.0001)
101790: accuracy:0.34 loss: 207.008 (lr:0.0001)
101800: accuracy:0.24 loss: 219.374 (lr:0.0001)
101810: accuracy:0.32 loss: 195.486 (lr:0.0001)
101820: accuracy:0.37 loss: 222.456 (lr:0.0001)
101830: accuracy:0.36 loss: 222.054 (lr:0.0001)
101840: accuracy:0.37 loss: 211.165 (lr:0.0001)
101850: accuracy:0.39 loss: 205.413 (lr:0.0001)
101860: accuracy:0.33 loss: 238.857 (lr:0.0001)
101870: accuracy:0.36 loss: 204.779 (lr:0.0001)
101880: accuracy:0.3 loss: 233.592 (lr:0.0001)
101890: accuracy:0.32 loss: 219.732 (lr:0.0001)
101900: accuracy:0.37 loss: 196.056 (lr:0.0001)
101910: accuracy:0.34 loss: 218.279 (lr:0.0001)
101920: accuracy:0.37 loss: 207.874 (lr:0.0001)
101930: accuracy:0.36 loss: 202.635 (lr:0.0001)
101940: accuracy:0.28 loss: 231.337 (lr:0.0001)
101950: accuracy:0.33 loss: 207.882 (lr:0.0001)
101960: accuracy:0.34 loss: 217.28 (lr:0.0001)
101970: accuracy:0.35 loss: 204.604 (lr:0.0001)
101980: accuracy:0.28 loss: 212.716 (lr:0.0001)
101990: accuracy:0.27 loss: 207.335 (lr:0.0001)
102000: accuracy:0.37 loss: 192.153 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
102000: ********* epoch 11 ********* test accuracy for all:0.248581 test loss: 255.356
102000: ********* epoch 11 ********* test accuracy for mode 0:0.0095 test loss: 421.392
102000: ********* epoch 11 ********* test accuracy for mode 1:0.046 test loss: 413.302
102000: ********* epoch 11 ********* test accuracy for mode 2:0.075 test loss: 264.084
102000: ********* epoch 11 ********* test accuracy for mode 24:0.2415 test loss: 267.43
102000: ********* epoch 11 ********* test accuracy for mode 25:0.278 test loss: 254.503
102000: ********* epoch 11 ********* test accuracy for mode 26:0.389 test loss: 176.855
102000: ********* epoch 11 ********* test accuracy for mode 27:0.234 test loss: 276.832
102000: ********* epoch 11 ********* test accuracy for mode 28:0.2795 test loss: 261.617
102000: ********* epoch 11 ********* test accuracy for mode 29:0.288 test loss: 260.97
102000: ********* epoch 11 ********* test accuracy for mode 30:0.2355 test loss: 254.692
102000: ********* epoch 11 ********* test accuracy for mode 31:0.2155 test loss: 252.234
102000: ********* epoch 11 ********* test accuracy for mode 32:0.2325 test loss: 242.881
102000: ********* epoch 11 ********* test accuracy for mode 33:0.247 test loss: 248.578
102000: ********* epoch 11 ********* test accuracy for mode 34:0.1885 test loss: 248.59
102000: ********* epoch 11 ********* test accuracy for mode 35:0.0215 test loss: 413.736
102000: ********* epoch 11 ********* test accuracy for mode 36:0.0995 test loss: 439.114
102010: accuracy:0.34 loss: 194.264 (lr:0.0001)
102020: accuracy:0.34 loss: 210.447 (lr:0.0001)
102030: accuracy:0.31 loss: 211.409 (lr:0.0001)
102040: accuracy:0.29 loss: 216.845 (lr:0.0001)
102050: accuracy:0.32 loss: 214.077 (lr:0.0001)
102060: accuracy:0.37 loss: 214.276 (lr:0.0001)
102070: accuracy:0.36 loss: 215.385 (lr:0.0001)
102080: accuracy:0.29 loss: 217.175 (lr:0.0001)
102090: accuracy:0.38 loss: 217.38 (lr:0.0001)
102100: accuracy:0.28 loss: 214.022 (lr:0.0001)
102110: accuracy:0.35 loss: 224.31 (lr:0.0001)
102120: accuracy:0.29 loss: 227.798 (lr:0.0001)
102130: accuracy:0.29 loss: 221.111 (lr:0.0001)
102140: accuracy:0.33 loss: 209.506 (lr:0.0001)
102150: accuracy:0.41 loss: 225.683 (lr:0.0001)
102160: accuracy:0.33 loss: 199.841 (lr:0.0001)
102170: accuracy:0.28 loss: 219.766 (lr:0.0001)
102180: accuracy:0.29 loss: 202.936 (lr:0.0001)
102190: accuracy:0.36 loss: 202.514 (lr:0.0001)
102200: accuracy:0.26 loss: 224.736 (lr:0.0001)
102210: accuracy:0.37 loss: 207.248 (lr:0.0001)
102220: accuracy:0.37 loss: 206.959 (lr:0.0001)
102230: accuracy:0.37 loss: 210.588 (lr:0.0001)
102240: accuracy:0.39 loss: 204.218 (lr:0.0001)
102250: accuracy:0.25 loss: 238.082 (lr:0.0001)
102260: accuracy:0.33 loss: 214.857 (lr:0.0001)
102270: accuracy:0.31 loss: 244.565 (lr:0.0001)
102280: accuracy:0.34 loss: 220.433 (lr:0.0001)
102290: accuracy:0.35 loss: 212.365 (lr:0.0001)
102300: accuracy:0.27 loss: 217.912 (lr:0.0001)
102310: accuracy:0.3 loss: 214.275 (lr:0.0001)
102320: accuracy:0.26 loss: 222.437 (lr:0.0001)
102330: accuracy:0.33 loss: 231.798 (lr:0.0001)
102340: accuracy:0.31 loss: 212.593 (lr:0.0001)
102350: accuracy:0.25 loss: 210.493 (lr:0.0001)
102360: accuracy:0.39 loss: 196.101 (lr:0.0001)
102370: accuracy:0.27 loss: 224.375 (lr:0.0001)
102380: accuracy:0.32 loss: 229.617 (lr:0.0001)
102390: accuracy:0.25 loss: 227.646 (lr:0.0001)
102400: accuracy:0.34 loss: 216.928 (lr:0.0001)
102410: accuracy:0.21 loss: 220.18 (lr:0.0001)
102420: accuracy:0.36 loss: 213.608 (lr:0.0001)
102430: accuracy:0.32 loss: 220.012 (lr:0.0001)
102440: accuracy:0.39 loss: 199.617 (lr:0.0001)
102450: accuracy:0.34 loss: 217.08 (lr:0.0001)
102460: accuracy:0.28 loss: 218.325 (lr:0.0001)
102470: accuracy:0.39 loss: 206.518 (lr:0.0001)
102480: accuracy:0.33 loss: 222.044 (lr:0.0001)
102490: accuracy:0.27 loss: 237.329 (lr:0.0001)
102500: accuracy:0.21 loss: 240.59 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
102500: ********* epoch 11 ********* test accuracy for all:0.250054 test loss: 254.865
102500: ********* epoch 11 ********* test accuracy for mode 0:0.016 test loss: 423.21
102500: ********* epoch 11 ********* test accuracy for mode 1:0.0435 test loss: 413.102
102500: ********* epoch 11 ********* test accuracy for mode 2:0.051 test loss: 268.61
102500: ********* epoch 11 ********* test accuracy for mode 24:0.2515 test loss: 261.904
102500: ********* epoch 11 ********* test accuracy for mode 25:0.2905 test loss: 244.675
102500: ********* epoch 11 ********* test accuracy for mode 26:0.416 test loss: 167.405
102500: ********* epoch 11 ********* test accuracy for mode 27:0.269 test loss: 264.599
102500: ********* epoch 11 ********* test accuracy for mode 28:0.2605 test loss: 258.707
102500: ********* epoch 11 ********* test accuracy for mode 29:0.2615 test loss: 261.475
102500: ********* epoch 11 ********* test accuracy for mode 30:0.1765 test loss: 254.206
102500: ********* epoch 11 ********* test accuracy for mode 31:0.2355 test loss: 249.502
102500: ********* epoch 11 ********* test accuracy for mode 32:0.233 test loss: 240.992
102500: ********* epoch 11 ********* test accuracy for mode 33:0.2305 test loss: 245.634
102500: ********* epoch 11 ********* test accuracy for mode 34:0.2435 test loss: 244.887
102500: ********* epoch 11 ********* test accuracy for mode 35:0.053 test loss: 415.28
102500: ********* epoch 11 ********* test accuracy for mode 36:0.0645 test loss: 457.927
102510: accuracy:0.34 loss: 209.887 (lr:0.0001)
102520: accuracy:0.32 loss: 219.874 (lr:0.0001)
102530: accuracy:0.34 loss: 201.051 (lr:0.0001)
102540: accuracy:0.39 loss: 209.471 (lr:0.0001)
102550: accuracy:0.31 loss: 215.029 (lr:0.0001)
102560: accuracy:0.35 loss: 223.887 (lr:0.0001)
102570: accuracy:0.37 loss: 225.811 (lr:0.0001)
102580: accuracy:0.35 loss: 189.15 (lr:0.0001)
102590: accuracy:0.32 loss: 219.804 (lr:0.0001)
102600: accuracy:0.33 loss: 202.097 (lr:0.0001)
102610: accuracy:0.31 loss: 212.248 (lr:0.0001)
102620: accuracy:0.36 loss: 219.6 (lr:0.0001)
102630: accuracy:0.36 loss: 223.473 (lr:0.0001)
102640: accuracy:0.36 loss: 209.626 (lr:0.0001)
102650: accuracy:0.31 loss: 218.548 (lr:0.0001)
102660: accuracy:0.34 loss: 212.073 (lr:0.0001)
102670: accuracy:0.35 loss: 217.127 (lr:0.0001)
102680: accuracy:0.33 loss: 215.291 (lr:0.0001)
102690: accuracy:0.35 loss: 215.572 (lr:0.0001)
102700: accuracy:0.36 loss: 197.379 (lr:0.0001)
102710: accuracy:0.42 loss: 187.529 (lr:0.0001)
102720: accuracy:0.37 loss: 218.904 (lr:0.0001)
102730: accuracy:0.29 loss: 224.17 (lr:0.0001)
102740: accuracy:0.33 loss: 221.478 (lr:0.0001)
102750: accuracy:0.32 loss: 219.456 (lr:0.0001)
102760: accuracy:0.29 loss: 235.384 (lr:0.0001)
102770: accuracy:0.26 loss: 216.472 (lr:0.0001)
102780: accuracy:0.28 loss: 221.155 (lr:0.0001)
102790: accuracy:0.39 loss: 212.321 (lr:0.0001)
102800: accuracy:0.32 loss: 220.239 (lr:0.0001)
102810: accuracy:0.38 loss: 196.455 (lr:0.0001)
102820: accuracy:0.27 loss: 217.594 (lr:0.0001)
102830: accuracy:0.34 loss: 209.531 (lr:0.0001)
102840: accuracy:0.34 loss: 206.517 (lr:0.0001)
102850: accuracy:0.29 loss: 211.477 (lr:0.0001)
102860: accuracy:0.29 loss: 207.111 (lr:0.0001)
102870: accuracy:0.36 loss: 220.611 (lr:0.0001)
102880: accuracy:0.4 loss: 207.327 (lr:0.0001)
102890: accuracy:0.32 loss: 210.075 (lr:0.0001)
102900: accuracy:0.38 loss: 214.215 (lr:0.0001)
102910: accuracy:0.31 loss: 218.506 (lr:0.0001)
102920: accuracy:0.34 loss: 203.272 (lr:0.0001)
102930: accuracy:0.28 loss: 220.546 (lr:0.0001)
102940: accuracy:0.36 loss: 218.5 (lr:0.0001)
102950: accuracy:0.36 loss: 204.747 (lr:0.0001)
102960: accuracy:0.42 loss: 205.173 (lr:0.0001)
102970: accuracy:0.41 loss: 203.065 (lr:0.0001)
102980: accuracy:0.38 loss: 204.545 (lr:0.0001)
102990: accuracy:0.35 loss: 218.72 (lr:0.0001)
103000: accuracy:0.34 loss: 210.091 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
103000: ********* epoch 11 ********* test accuracy for all:0.255338 test loss: 252.662
103000: ********* epoch 11 ********* test accuracy for mode 0:0.017 test loss: 413.641
103000: ********* epoch 11 ********* test accuracy for mode 1:0.042 test loss: 410.668
103000: ********* epoch 11 ********* test accuracy for mode 2:0.0525 test loss: 271.574
103000: ********* epoch 11 ********* test accuracy for mode 24:0.267 test loss: 257.327
103000: ********* epoch 11 ********* test accuracy for mode 25:0.285 test loss: 241.138
103000: ********* epoch 11 ********* test accuracy for mode 26:0.5325 test loss: 153.301
103000: ********* epoch 11 ********* test accuracy for mode 27:0.276 test loss: 255.493
103000: ********* epoch 11 ********* test accuracy for mode 28:0.3095 test loss: 246.68
103000: ********* epoch 11 ********* test accuracy for mode 29:0.2725 test loss: 255.29
103000: ********* epoch 11 ********* test accuracy for mode 30:0.262 test loss: 248.535
103000: ********* epoch 11 ********* test accuracy for mode 31:0.1625 test loss: 258.142
103000: ********* epoch 11 ********* test accuracy for mode 32:0.238 test loss: 245.574
103000: ********* epoch 11 ********* test accuracy for mode 33:0.246 test loss: 250.341
103000: ********* epoch 11 ********* test accuracy for mode 34:0.1405 test loss: 256.008
103000: ********* epoch 11 ********* test accuracy for mode 35:0.0135 test loss: 421.239
103000: ********* epoch 11 ********* test accuracy for mode 36:0.074 test loss: 452.734
103010: accuracy:0.34 loss: 230.676 (lr:0.0001)
103020: accuracy:0.39 loss: 208.192 (lr:0.0001)
103030: accuracy:0.26 loss: 230.382 (lr:0.0001)
103040: accuracy:0.29 loss: 219.047 (lr:0.0001)
103050: accuracy:0.3 loss: 220.392 (lr:0.0001)
103060: accuracy:0.29 loss: 235.622 (lr:0.0001)
103070: accuracy:0.27 loss: 223.607 (lr:0.0001)
103080: accuracy:0.28 loss: 242.421 (lr:0.0001)
103090: accuracy:0.29 loss: 226.125 (lr:0.0001)
103100: accuracy:0.37 loss: 217.295 (lr:0.0001)
103110: accuracy:0.33 loss: 200.092 (lr:0.0001)
103120: accuracy:0.3 loss: 203.411 (lr:0.0001)
103130: accuracy:0.27 loss: 225.167 (lr:0.0001)
103140: accuracy:0.33 loss: 216.893 (lr:0.0001)
103150: accuracy:0.34 loss: 215.771 (lr:0.0001)
103160: accuracy:0.26 loss: 229.901 (lr:0.0001)
103170: accuracy:0.36 loss: 211.616 (lr:0.0001)
103180: accuracy:0.31 loss: 215.684 (lr:0.0001)
103190: accuracy:0.3 loss: 224.923 (lr:0.0001)
103200: accuracy:0.37 loss: 221.594 (lr:0.0001)
103210: accuracy:0.25 loss: 219.407 (lr:0.0001)
103220: accuracy:0.39 loss: 200.235 (lr:0.0001)
103230: accuracy:0.4 loss: 185.469 (lr:0.0001)
103240: accuracy:0.29 loss: 222.413 (lr:0.0001)
103250: accuracy:0.35 loss: 218.27 (lr:0.0001)
103260: accuracy:0.37 loss: 220.508 (lr:0.0001)
103270: accuracy:0.33 loss: 218.282 (lr:0.0001)
103280: accuracy:0.35 loss: 208.422 (lr:0.0001)
103290: accuracy:0.31 loss: 214.554 (lr:0.0001)
103300: accuracy:0.3 loss: 214.477 (lr:0.0001)
103310: accuracy:0.35 loss: 220.857 (lr:0.0001)
103320: accuracy:0.4 loss: 226.98 (lr:0.0001)
103330: accuracy:0.34 loss: 198.257 (lr:0.0001)
103340: accuracy:0.33 loss: 237.116 (lr:0.0001)
103350: accuracy:0.35 loss: 214.041 (lr:0.0001)
103360: accuracy:0.36 loss: 201.121 (lr:0.0001)
103370: accuracy:0.34 loss: 204.617 (lr:0.0001)
103380: accuracy:0.33 loss: 215.582 (lr:0.0001)
103390: accuracy:0.32 loss: 220.493 (lr:0.0001)
103400: accuracy:0.25 loss: 221.65 (lr:0.0001)
103410: accuracy:0.32 loss: 220.699 (lr:0.0001)
103420: accuracy:0.45 loss: 195.867 (lr:0.0001)
103430: accuracy:0.32 loss: 215.877 (lr:0.0001)
103440: accuracy:0.35 loss: 218.297 (lr:0.0001)
103450: accuracy:0.35 loss: 217.093 (lr:0.0001)
103460: accuracy:0.39 loss: 222.377 (lr:0.0001)
103470: accuracy:0.28 loss: 225.342 (lr:0.0001)
103480: accuracy:0.33 loss: 200.04 (lr:0.0001)
103490: accuracy:0.37 loss: 192.275 (lr:0.0001)
103500: accuracy:0.37 loss: 220.531 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
103500: ********* epoch 11 ********* test accuracy for all:0.2495 test loss: 254.958
103500: ********* epoch 11 ********* test accuracy for mode 0:0.008 test loss: 427.044
103500: ********* epoch 11 ********* test accuracy for mode 1:0.0415 test loss: 418.168
103500: ********* epoch 11 ********* test accuracy for mode 2:0.0515 test loss: 269.727
103500: ********* epoch 11 ********* test accuracy for mode 24:0.193 test loss: 273.06
103500: ********* epoch 11 ********* test accuracy for mode 25:0.259 test loss: 252.675
103500: ********* epoch 11 ********* test accuracy for mode 26:0.457 test loss: 163.933
103500: ********* epoch 11 ********* test accuracy for mode 27:0.243 test loss: 269.798
103500: ********* epoch 11 ********* test accuracy for mode 28:0.2875 test loss: 259.069
103500: ********* epoch 11 ********* test accuracy for mode 29:0.2665 test loss: 263.872
103500: ********* epoch 11 ********* test accuracy for mode 30:0.215 test loss: 254.007
103500: ********* epoch 11 ********* test accuracy for mode 31:0.18 test loss: 253.608
103500: ********* epoch 11 ********* test accuracy for mode 32:0.2755 test loss: 236.045
103500: ********* epoch 11 ********* test accuracy for mode 33:0.2935 test loss: 242.765
103500: ********* epoch 11 ********* test accuracy for mode 34:0.1115 test loss: 253.285
103500: ********* epoch 11 ********* test accuracy for mode 35:0.0295 test loss: 412.232
103500: ********* epoch 11 ********* test accuracy for mode 36:0.085 test loss: 425.837
103510: accuracy:0.29 loss: 221.064 (lr:0.0001)
103520: accuracy:0.26 loss: 222.303 (lr:0.0001)
103530: accuracy:0.28 loss: 226.729 (lr:0.0001)
103540: accuracy:0.31 loss: 205.636 (lr:0.0001)
103550: accuracy:0.3 loss: 230.531 (lr:0.0001)
103560: accuracy:0.37 loss: 249.15 (lr:0.0001)
103570: accuracy:0.19 loss: 243.086 (lr:0.0001)
103580: accuracy:0.29 loss: 212.295 (lr:0.0001)
103590: accuracy:0.34 loss: 225.494 (lr:0.0001)
103600: accuracy:0.27 loss: 215.964 (lr:0.0001)
103610: accuracy:0.3 loss: 232.843 (lr:0.0001)
103620: accuracy:0.36 loss: 184.261 (lr:0.0001)
103630: accuracy:0.3 loss: 218.402 (lr:0.0001)
103640: accuracy:0.3 loss: 216.06 (lr:0.0001)
103650: accuracy:0.34 loss: 218.223 (lr:0.0001)
103660: accuracy:0.31 loss: 217.353 (lr:0.0001)
103670: accuracy:0.41 loss: 199.154 (lr:0.0001)
103680: accuracy:0.32 loss: 211.956 (lr:0.0001)
103690: accuracy:0.34 loss: 211.182 (lr:0.0001)
103700: accuracy:0.33 loss: 221.808 (lr:0.0001)
103710: accuracy:0.35 loss: 214.536 (lr:0.0001)
103720: accuracy:0.32 loss: 226.992 (lr:0.0001)
103730: accuracy:0.39 loss: 203.228 (lr:0.0001)
103740: accuracy:0.37 loss: 224.359 (lr:0.0001)
103750: accuracy:0.35 loss: 225.674 (lr:0.0001)
103760: accuracy:0.32 loss: 223.853 (lr:0.0001)
103770: accuracy:0.27 loss: 208.351 (lr:0.0001)
103780: accuracy:0.37 loss: 209.447 (lr:0.0001)
103790: accuracy:0.29 loss: 222.242 (lr:0.0001)
103800: accuracy:0.34 loss: 202.836 (lr:0.0001)
103810: accuracy:0.37 loss: 214.896 (lr:0.0001)
103820: accuracy:0.35 loss: 208.876 (lr:0.0001)
103830: accuracy:0.29 loss: 224.414 (lr:0.0001)
103840: accuracy:0.31 loss: 223.299 (lr:0.0001)
103850: accuracy:0.36 loss: 220.511 (lr:0.0001)
103860: accuracy:0.29 loss: 215.111 (lr:0.0001)
103870: accuracy:0.28 loss: 244.37 (lr:0.0001)
103880: accuracy:0.33 loss: 211.247 (lr:0.0001)
103890: accuracy:0.32 loss: 218.413 (lr:0.0001)
103900: accuracy:0.28 loss: 244.954 (lr:0.0001)
103910: accuracy:0.31 loss: 221.369 (lr:0.0001)
103920: accuracy:0.35 loss: 220.725 (lr:0.0001)
103930: accuracy:0.36 loss: 206.76 (lr:0.0001)
103940: accuracy:0.36 loss: 222.112 (lr:0.0001)
103950: accuracy:0.36 loss: 216.425 (lr:0.0001)
103960: accuracy:0.28 loss: 238.127 (lr:0.0001)
103970: accuracy:0.29 loss: 229.694 (lr:0.0001)
103980: accuracy:0.36 loss: 197.56 (lr:0.0001)
103990: accuracy:0.38 loss: 209.703 (lr:0.0001)
104000: accuracy:0.38 loss: 225.708 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
104000: ********* epoch 11 ********* test accuracy for all:0.253541 test loss: 253.109
104000: ********* epoch 11 ********* test accuracy for mode 0:0.011 test loss: 420.393
104000: ********* epoch 11 ********* test accuracy for mode 1:0.042 test loss: 418.324
104000: ********* epoch 11 ********* test accuracy for mode 2:0.039 test loss: 270.086
104000: ********* epoch 11 ********* test accuracy for mode 24:0.256 test loss: 256.624
104000: ********* epoch 11 ********* test accuracy for mode 25:0.3275 test loss: 238.927
104000: ********* epoch 11 ********* test accuracy for mode 26:0.4205 test loss: 166.624
104000: ********* epoch 11 ********* test accuracy for mode 27:0.2245 test loss: 271.635
104000: ********* epoch 11 ********* test accuracy for mode 28:0.3125 test loss: 253.524
104000: ********* epoch 11 ********* test accuracy for mode 29:0.2565 test loss: 261.865
104000: ********* epoch 11 ********* test accuracy for mode 30:0.271 test loss: 246.06
104000: ********* epoch 11 ********* test accuracy for mode 31:0.1865 test loss: 255.464
104000: ********* epoch 11 ********* test accuracy for mode 32:0.2095 test loss: 243.014
104000: ********* epoch 11 ********* test accuracy for mode 33:0.271 test loss: 244.2
104000: ********* epoch 11 ********* test accuracy for mode 34:0.1735 test loss: 246.908
104000: ********* epoch 11 ********* test accuracy for mode 35:0.044 test loss: 401.172
104000: ********* epoch 11 ********* test accuracy for mode 36:0.059 test loss: 440.07
104010: accuracy:0.36 loss: 214.219 (lr:0.0001)
104020: accuracy:0.36 loss: 210.002 (lr:0.0001)
104030: accuracy:0.31 loss: 211.269 (lr:0.0001)
104040: accuracy:0.31 loss: 226.994 (lr:0.0001)
104050: accuracy:0.31 loss: 220.143 (lr:0.0001)
104060: accuracy:0.31 loss: 205.661 (lr:0.0001)
104070: accuracy:0.31 loss: 229.622 (lr:0.0001)
104080: accuracy:0.28 loss: 215.481 (lr:0.0001)
104090: accuracy:0.26 loss: 221.162 (lr:0.0001)
104100: accuracy:0.25 loss: 236.905 (lr:0.0001)
104110: accuracy:0.35 loss: 189.77 (lr:0.0001)
104120: accuracy:0.28 loss: 218.904 (lr:0.0001)
104130: accuracy:0.23 loss: 236.365 (lr:0.0001)
104140: accuracy:0.28 loss: 242.57 (lr:0.0001)
104150: accuracy:0.25 loss: 211.002 (lr:0.0001)
104160: accuracy:0.31 loss: 219.571 (lr:0.0001)
104170: accuracy:0.41 loss: 214.835 (lr:0.0001)
104180: accuracy:0.26 loss: 238.593 (lr:0.0001)
104190: accuracy:0.36 loss: 225.22 (lr:0.0001)
104200: accuracy:0.47 loss: 211.942 (lr:0.0001)
104210: accuracy:0.32 loss: 232.444 (lr:0.0001)
104220: accuracy:0.27 loss: 228.791 (lr:0.0001)
104230: accuracy:0.23 loss: 220.928 (lr:0.0001)
104240: accuracy:0.35 loss: 231.937 (lr:0.0001)
104250: accuracy:0.36 loss: 223.159 (lr:0.0001)
104260: accuracy:0.26 loss: 214.796 (lr:0.0001)
104270: accuracy:0.44 loss: 208.842 (lr:0.0001)
104280: accuracy:0.34 loss: 212.359 (lr:0.0001)
104290: accuracy:0.35 loss: 182.942 (lr:0.0001)
104300: accuracy:0.31 loss: 224.737 (lr:0.0001)
104310: accuracy:0.33 loss: 193.294 (lr:0.0001)
104320: accuracy:0.29 loss: 209.538 (lr:0.0001)
104330: accuracy:0.4 loss: 215.344 (lr:0.0001)
104340: accuracy:0.39 loss: 207.227 (lr:0.0001)
104350: accuracy:0.36 loss: 213.123 (lr:0.0001)
104360: accuracy:0.39 loss: 213.806 (lr:0.0001)
104370: accuracy:0.29 loss: 224.11 (lr:0.0001)
104380: accuracy:0.25 loss: 215.908 (lr:0.0001)
104390: accuracy:0.32 loss: 218.943 (lr:0.0001)
104400: accuracy:0.29 loss: 239.99 (lr:0.0001)
104410: accuracy:0.27 loss: 222.773 (lr:0.0001)
104420: accuracy:0.37 loss: 197.155 (lr:0.0001)
104430: accuracy:0.45 loss: 203.827 (lr:0.0001)
104440: accuracy:0.3 loss: 209.037 (lr:0.0001)
104450: accuracy:0.33 loss: 229.718 (lr:0.0001)
104460: accuracy:0.37 loss: 219.294 (lr:0.0001)
104470: accuracy:0.32 loss: 206.512 (lr:0.0001)
104480: accuracy:0.41 loss: 205.729 (lr:0.0001)
104490: accuracy:0.3 loss: 212.997 (lr:0.0001)
104500: accuracy:0.37 loss: 206.874 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
104500: ********* epoch 11 ********* test accuracy for all:0.251162 test loss: 255.353
104500: ********* epoch 11 ********* test accuracy for mode 0:0.014 test loss: 419.921
104500: ********* epoch 11 ********* test accuracy for mode 1:0.0425 test loss: 414.17
104500: ********* epoch 11 ********* test accuracy for mode 2:0.027 test loss: 275.117
104500: ********* epoch 11 ********* test accuracy for mode 24:0.2495 test loss: 272.814
104500: ********* epoch 11 ********* test accuracy for mode 25:0.314 test loss: 250.459
104500: ********* epoch 11 ********* test accuracy for mode 26:0.422 test loss: 167.253
104500: ********* epoch 11 ********* test accuracy for mode 27:0.301 test loss: 264.466
104500: ********* epoch 11 ********* test accuracy for mode 28:0.2815 test loss: 262.551
104500: ********* epoch 11 ********* test accuracy for mode 29:0.2595 test loss: 273.426
104500: ********* epoch 11 ********* test accuracy for mode 30:0.21 test loss: 260.87
104500: ********* epoch 11 ********* test accuracy for mode 31:0.1945 test loss: 262.593
104500: ********* epoch 11 ********* test accuracy for mode 32:0.23 test loss: 245.383
104500: ********* epoch 11 ********* test accuracy for mode 33:0.2695 test loss: 247.889
104500: ********* epoch 11 ********* test accuracy for mode 34:0.1355 test loss: 253.478
104500: ********* epoch 11 ********* test accuracy for mode 35:0.018 test loss: 412.028
104500: ********* epoch 11 ********* test accuracy for mode 36:0.0775 test loss: 441.52
104510: accuracy:0.38 loss: 228.759 (lr:0.0001)
104520: accuracy:0.37 loss: 220.907 (lr:0.0001)
104530: accuracy:0.32 loss: 216.331 (lr:0.0001)
104540: accuracy:0.28 loss: 223.54 (lr:0.0001)
104550: accuracy:0.24 loss: 229.082 (lr:0.0001)
104560: accuracy:0.33 loss: 210.877 (lr:0.0001)
104570: accuracy:0.28 loss: 221.761 (lr:0.0001)
104580: accuracy:0.31 loss: 242.847 (lr:0.0001)
104590: accuracy:0.24 loss: 221.823 (lr:0.0001)
104600: accuracy:0.24 loss: 241.979 (lr:0.0001)
104610: accuracy:0.32 loss: 219.915 (lr:0.0001)
104620: accuracy:0.28 loss: 218.203 (lr:0.0001)
104630: accuracy:0.31 loss: 234.548 (lr:0.0001)
104640: accuracy:0.31 loss: 201.37 (lr:0.0001)
104650: accuracy:0.28 loss: 241.312 (lr:0.0001)
104660: accuracy:0.38 loss: 212.146 (lr:0.0001)
104670: accuracy:0.36 loss: 211.323 (lr:0.0001)
104680: accuracy:0.39 loss: 211.426 (lr:0.0001)
104690: accuracy:0.23 loss: 220.555 (lr:0.0001)
104700: accuracy:0.34 loss: 223.797 (lr:0.0001)
104710: accuracy:0.22 loss: 222.679 (lr:0.0001)
104720: accuracy:0.34 loss: 214.551 (lr:0.0001)
104730: accuracy:0.27 loss: 212.062 (lr:0.0001)
104740: accuracy:0.26 loss: 219.043 (lr:0.0001)
104750: accuracy:0.33 loss: 204.154 (lr:0.0001)
104760: accuracy:0.34 loss: 224.327 (lr:0.0001)
104770: accuracy:0.3 loss: 219.298 (lr:0.0001)
104780: accuracy:0.35 loss: 207.583 (lr:0.0001)
104790: accuracy:0.34 loss: 203.663 (lr:0.0001)
104800: accuracy:0.34 loss: 218.276 (lr:0.0001)
104810: accuracy:0.37 loss: 217.925 (lr:0.0001)
104820: accuracy:0.29 loss: 200.41 (lr:0.0001)
104830: accuracy:0.35 loss: 200.185 (lr:0.0001)
104840: accuracy:0.28 loss: 225.29 (lr:0.0001)
104850: accuracy:0.38 loss: 191.09 (lr:0.0001)
104860: accuracy:0.21 loss: 226.312 (lr:0.0001)
104870: accuracy:0.31 loss: 214.77 (lr:0.0001)
104880: accuracy:0.3 loss: 209.697 (lr:0.0001)
104890: accuracy:0.3 loss: 214.449 (lr:0.0001)
104900: accuracy:0.31 loss: 240.411 (lr:0.0001)
104910: accuracy:0.36 loss: 207.577 (lr:0.0001)
104920: accuracy:0.33 loss: 190.113 (lr:0.0001)
104930: accuracy:0.29 loss: 219.411 (lr:0.0001)
104940: accuracy:0.28 loss: 214.741 (lr:0.0001)
104950: accuracy:0.38 loss: 211.755 (lr:0.0001)
104960: accuracy:0.3 loss: 229.324 (lr:0.0001)
104970: accuracy:0.26 loss: 223.564 (lr:0.0001)
104980: accuracy:0.32 loss: 209.44 (lr:0.0001)
104990: accuracy:0.34 loss: 226.052 (lr:0.0001)
105000: accuracy:0.34 loss: 223.246 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
105000: ********* epoch 11 ********* test accuracy for all:0.252946 test loss: 254.017
105000: ********* epoch 11 ********* test accuracy for mode 0:0.0095 test loss: 421.888
105000: ********* epoch 11 ********* test accuracy for mode 1:0.05 test loss: 408.751
105000: ********* epoch 11 ********* test accuracy for mode 2:0.043 test loss: 272.286
105000: ********* epoch 11 ********* test accuracy for mode 24:0.2565 test loss: 258.33
105000: ********* epoch 11 ********* test accuracy for mode 25:0.297 test loss: 241.779
105000: ********* epoch 11 ********* test accuracy for mode 26:0.4975 test loss: 158.083
105000: ********* epoch 11 ********* test accuracy for mode 27:0.2845 test loss: 256.945
105000: ********* epoch 11 ********* test accuracy for mode 28:0.2895 test loss: 255.609
105000: ********* epoch 11 ********* test accuracy for mode 29:0.254 test loss: 266.707
105000: ********* epoch 11 ********* test accuracy for mode 30:0.255 test loss: 251.992
105000: ********* epoch 11 ********* test accuracy for mode 31:0.1825 test loss: 259.947
105000: ********* epoch 11 ********* test accuracy for mode 32:0.179 test loss: 250.249
105000: ********* epoch 11 ********* test accuracy for mode 33:0.2805 test loss: 250.23
105000: ********* epoch 11 ********* test accuracy for mode 34:0.145 test loss: 255.073
105000: ********* epoch 11 ********* test accuracy for mode 35:0.0165 test loss: 423.047
105000: ********* epoch 11 ********* test accuracy for mode 36:0.064 test loss: 459.3
105010: accuracy:0.27 loss: 213.118 (lr:0.0001)
105020: accuracy:0.19 loss: 243.95 (lr:0.0001)
105030: accuracy:0.27 loss: 214.712 (lr:0.0001)
105040: accuracy:0.37 loss: 210.291 (lr:0.0001)
105050: accuracy:0.38 loss: 200.338 (lr:0.0001)
105060: accuracy:0.3 loss: 220.939 (lr:0.0001)
105070: accuracy:0.34 loss: 227.863 (lr:0.0001)
105080: accuracy:0.33 loss: 201.842 (lr:0.0001)
105090: accuracy:0.36 loss: 218.421 (lr:0.0001)
105100: accuracy:0.25 loss: 245.609 (lr:0.0001)
105110: accuracy:0.27 loss: 216.589 (lr:0.0001)
105120: accuracy:0.32 loss: 198.164 (lr:0.0001)
105130: accuracy:0.35 loss: 194.702 (lr:0.0001)
105140: accuracy:0.36 loss: 216.679 (lr:0.0001)
105150: accuracy:0.32 loss: 207.649 (lr:0.0001)
105160: accuracy:0.31 loss: 200.463 (lr:0.0001)
105170: accuracy:0.29 loss: 217.054 (lr:0.0001)
105180: accuracy:0.36 loss: 224.912 (lr:0.0001)
105190: accuracy:0.29 loss: 205.893 (lr:0.0001)
105200: accuracy:0.38 loss: 205.581 (lr:0.0001)
105210: accuracy:0.3 loss: 236.515 (lr:0.0001)
105220: accuracy:0.39 loss: 225.829 (lr:0.0001)
105230: accuracy:0.26 loss: 226.366 (lr:0.0001)
105240: accuracy:0.35 loss: 217.468 (lr:0.0001)
105250: accuracy:0.32 loss: 206.995 (lr:0.0001)
105260: accuracy:0.27 loss: 213.173 (lr:0.0001)
105270: accuracy:0.31 loss: 215.631 (lr:0.0001)
105280: accuracy:0.32 loss: 213.59 (lr:0.0001)
105290: accuracy:0.42 loss: 192.947 (lr:0.0001)
105300: accuracy:0.28 loss: 220.161 (lr:0.0001)
105310: accuracy:0.37 loss: 208.97 (lr:0.0001)
105320: accuracy:0.31 loss: 228.814 (lr:0.0001)
105330: accuracy:0.29 loss: 211.363 (lr:0.0001)
105340: accuracy:0.32 loss: 212.153 (lr:0.0001)
105350: accuracy:0.29 loss: 218.37 (lr:0.0001)
105360: accuracy:0.41 loss: 206.136 (lr:0.0001)
105370: accuracy:0.34 loss: 213.596 (lr:0.0001)
105380: accuracy:0.34 loss: 225.852 (lr:0.0001)
105390: accuracy:0.4 loss: 215.132 (lr:0.0001)
105400: accuracy:0.29 loss: 240.35 (lr:0.0001)
105410: accuracy:0.28 loss: 207.466 (lr:0.0001)
105420: accuracy:0.36 loss: 219.899 (lr:0.0001)
105430: accuracy:0.4 loss: 220.258 (lr:0.0001)
105440: accuracy:0.32 loss: 229.486 (lr:0.0001)
105450: accuracy:0.32 loss: 236.249 (lr:0.0001)
105460: accuracy:0.41 loss: 197.824 (lr:0.0001)
105470: accuracy:0.42 loss: 208.805 (lr:0.0001)
105480: accuracy:0.25 loss: 230.658 (lr:0.0001)
105490: accuracy:0.27 loss: 219.833 (lr:0.0001)
105500: accuracy:0.35 loss: 224.098 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
105500: ********* epoch 11 ********* test accuracy for all:0.252081 test loss: 254.135
105500: ********* epoch 11 ********* test accuracy for mode 0:0.012 test loss: 417.215
105500: ********* epoch 11 ********* test accuracy for mode 1:0.047 test loss: 407.397
105500: ********* epoch 11 ********* test accuracy for mode 2:0.0385 test loss: 270.978
105500: ********* epoch 11 ********* test accuracy for mode 24:0.2575 test loss: 267.444
105500: ********* epoch 11 ********* test accuracy for mode 25:0.279 test loss: 243.266
105500: ********* epoch 11 ********* test accuracy for mode 26:0.5185 test loss: 159.509
105500: ********* epoch 11 ********* test accuracy for mode 27:0.239 test loss: 263.315
105500: ********* epoch 11 ********* test accuracy for mode 28:0.308 test loss: 250.803
105500: ********* epoch 11 ********* test accuracy for mode 29:0.2735 test loss: 261.884
105500: ********* epoch 11 ********* test accuracy for mode 30:0.1825 test loss: 254.764
105500: ********* epoch 11 ********* test accuracy for mode 31:0.2395 test loss: 254.55
105500: ********* epoch 11 ********* test accuracy for mode 32:0.215 test loss: 244.51
105500: ********* epoch 11 ********* test accuracy for mode 33:0.241 test loss: 248.304
105500: ********* epoch 11 ********* test accuracy for mode 34:0.1915 test loss: 248.968
105500: ********* epoch 11 ********* test accuracy for mode 35:0.029 test loss: 412.356
105500: ********* epoch 11 ********* test accuracy for mode 36:0.081 test loss: 434.034
105510: accuracy:0.37 loss: 214.289 (lr:0.0001)
105520: accuracy:0.33 loss: 223.643 (lr:0.0001)
105530: accuracy:0.36 loss: 212.085 (lr:0.0001)
105540: accuracy:0.28 loss: 225.75 (lr:0.0001)
105550: accuracy:0.35 loss: 203.154 (lr:0.0001)
105560: accuracy:0.37 loss: 210.636 (lr:0.0001)
105570: accuracy:0.34 loss: 215.054 (lr:0.0001)
105580: accuracy:0.28 loss: 225.665 (lr:0.0001)
105590: accuracy:0.3 loss: 214.341 (lr:0.0001)
105600: accuracy:0.3 loss: 237.725 (lr:0.0001)
105610: accuracy:0.39 loss: 212.856 (lr:0.0001)
105620: accuracy:0.19 loss: 236.842 (lr:0.0001)
105630: accuracy:0.29 loss: 243.909 (lr:0.0001)
105640: accuracy:0.33 loss: 217.276 (lr:0.0001)
105650: accuracy:0.36 loss: 209.078 (lr:0.0001)
105660: accuracy:0.26 loss: 220.437 (lr:0.0001)
105670: accuracy:0.24 loss: 227.721 (lr:0.0001)
105680: accuracy:0.28 loss: 231.678 (lr:0.0001)
105690: accuracy:0.35 loss: 210.609 (lr:0.0001)
105700: accuracy:0.32 loss: 208.773 (lr:0.0001)
105710: accuracy:0.3 loss: 219.493 (lr:0.0001)
105720: accuracy:0.26 loss: 217.959 (lr:0.0001)
105730: accuracy:0.38 loss: 206.778 (lr:0.0001)
105740: accuracy:0.3 loss: 230.229 (lr:0.0001)
105750: accuracy:0.26 loss: 240.549 (lr:0.0001)
105760: accuracy:0.31 loss: 221.679 (lr:0.0001)
105770: accuracy:0.28 loss: 221.834 (lr:0.0001)
105780: accuracy:0.32 loss: 206.662 (lr:0.0001)
105790: accuracy:0.46 loss: 176.922 (lr:0.0001)
105800: accuracy:0.32 loss: 187.624 (lr:0.0001)
105810: accuracy:0.34 loss: 211.122 (lr:0.0001)
105820: accuracy:0.3 loss: 206.978 (lr:0.0001)
105830: accuracy:0.26 loss: 230.437 (lr:0.0001)
105840: accuracy:0.26 loss: 208.313 (lr:0.0001)
105850: accuracy:0.33 loss: 213.703 (lr:0.0001)
105860: accuracy:0.36 loss: 231.646 (lr:0.0001)
105870: accuracy:0.28 loss: 229.621 (lr:0.0001)
105880: accuracy:0.39 loss: 200.649 (lr:0.0001)
105890: accuracy:0.43 loss: 196.03 (lr:0.0001)
105900: accuracy:0.32 loss: 213.039 (lr:0.0001)
105910: accuracy:0.3 loss: 212.963 (lr:0.0001)
105920: accuracy:0.33 loss: 223.906 (lr:0.0001)
105930: accuracy:0.28 loss: 217.64 (lr:0.0001)
105940: accuracy:0.33 loss: 208.494 (lr:0.0001)
105950: accuracy:0.36 loss: 211.265 (lr:0.0001)
105960: accuracy:0.35 loss: 213.28 (lr:0.0001)
105970: accuracy:0.34 loss: 225.551 (lr:0.0001)
105980: accuracy:0.36 loss: 215.296 (lr:0.0001)
105990: accuracy:0.39 loss: 202.763 (lr:0.0001)
106000: accuracy:0.27 loss: 208.411 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
106000: ********* epoch 11 ********* test accuracy for all:0.251622 test loss: 254.295
106000: ********* epoch 11 ********* test accuracy for mode 0:0.012 test loss: 421.745
106000: ********* epoch 11 ********* test accuracy for mode 1:0.0405 test loss: 416.649
106000: ********* epoch 11 ********* test accuracy for mode 2:0.0465 test loss: 269.751
106000: ********* epoch 11 ********* test accuracy for mode 24:0.2375 test loss: 269.397
106000: ********* epoch 11 ********* test accuracy for mode 25:0.2405 test loss: 249.192
106000: ********* epoch 11 ********* test accuracy for mode 26:0.53 test loss: 158.25
106000: ********* epoch 11 ********* test accuracy for mode 27:0.2215 test loss: 267.979
106000: ********* epoch 11 ********* test accuracy for mode 28:0.295 test loss: 254.773
106000: ********* epoch 11 ********* test accuracy for mode 29:0.2525 test loss: 263.017
106000: ********* epoch 11 ********* test accuracy for mode 30:0.2635 test loss: 247.334
106000: ********* epoch 11 ********* test accuracy for mode 31:0.1905 test loss: 253.953
106000: ********* epoch 11 ********* test accuracy for mode 32:0.226 test loss: 240.072
106000: ********* epoch 11 ********* test accuracy for mode 33:0.302 test loss: 240.906
106000: ********* epoch 11 ********* test accuracy for mode 34:0.1795 test loss: 247.219
106000: ********* epoch 11 ********* test accuracy for mode 35:0.0165 test loss: 423.234
106000: ********* epoch 11 ********* test accuracy for mode 36:0.128 test loss: 436.189
106010: accuracy:0.32 loss: 212.371 (lr:0.0001)
106020: accuracy:0.27 loss: 218.605 (lr:0.0001)
106030: accuracy:0.33 loss: 207.265 (lr:0.0001)
106040: accuracy:0.35 loss: 220.529 (lr:0.0001)
106050: accuracy:0.24 loss: 223.733 (lr:0.0001)
106060: accuracy:0.32 loss: 231.941 (lr:0.0001)
106070: accuracy:0.31 loss: 220.022 (lr:0.0001)
106080: accuracy:0.36 loss: 190.119 (lr:0.0001)
106090: accuracy:0.34 loss: 202.514 (lr:0.0001)
106100: accuracy:0.29 loss: 218.033 (lr:0.0001)
106110: accuracy:0.38 loss: 205.341 (lr:0.0001)
106120: accuracy:0.28 loss: 215.139 (lr:0.0001)
106130: accuracy:0.41 loss: 193.959 (lr:0.0001)
106140: accuracy:0.36 loss: 198.09 (lr:0.0001)
106150: accuracy:0.32 loss: 202.491 (lr:0.0001)
106160: accuracy:0.3 loss: 235.127 (lr:0.0001)
106170: accuracy:0.26 loss: 233.906 (lr:0.0001)
106180: accuracy:0.3 loss: 206.393 (lr:0.0001)
106190: accuracy:0.31 loss: 229.446 (lr:0.0001)
106200: accuracy:0.35 loss: 218.614 (lr:0.0001)
106210: accuracy:0.24 loss: 225.136 (lr:0.0001)
106220: accuracy:0.25 loss: 235.987 (lr:0.0001)
106230: accuracy:0.36 loss: 208.652 (lr:0.0001)
106240: accuracy:0.28 loss: 231.966 (lr:0.0001)
106250: accuracy:0.28 loss: 231.816 (lr:0.0001)
106260: accuracy:0.29 loss: 214.197 (lr:0.0001)
106270: accuracy:0.34 loss: 214.897 (lr:0.0001)
106280: accuracy:0.33 loss: 212.785 (lr:0.0001)
106290: accuracy:0.28 loss: 228.072 (lr:0.0001)
106300: accuracy:0.32 loss: 202.878 (lr:0.0001)
106310: accuracy:0.37 loss: 222.151 (lr:0.0001)
106320: accuracy:0.49 loss: 194.799 (lr:0.0001)
106330: accuracy:0.27 loss: 221.603 (lr:0.0001)
106340: accuracy:0.36 loss: 214.065 (lr:0.0001)
106350: accuracy:0.35 loss: 195.573 (lr:0.0001)
106360: accuracy:0.28 loss: 240.457 (lr:0.0001)
106370: accuracy:0.3 loss: 233.89 (lr:0.0001)
106380: accuracy:0.38 loss: 215.89 (lr:0.0001)
106390: accuracy:0.34 loss: 215.464 (lr:0.0001)
106400: accuracy:0.35 loss: 214.084 (lr:0.0001)
106410: accuracy:0.3 loss: 214.857 (lr:0.0001)
106420: accuracy:0.31 loss: 215.148 (lr:0.0001)
106430: accuracy:0.33 loss: 231.424 (lr:0.0001)
106440: accuracy:0.31 loss: 222.994 (lr:0.0001)
106450: accuracy:0.28 loss: 229.756 (lr:0.0001)
106460: accuracy:0.3 loss: 231.224 (lr:0.0001)
106470: accuracy:0.3 loss: 216.959 (lr:0.0001)
106480: accuracy:0.29 loss: 235.391 (lr:0.0001)
106490: accuracy:0.29 loss: 247.488 (lr:0.0001)
106500: accuracy:0.32 loss: 195.75 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
106500: ********* epoch 11 ********* test accuracy for all:0.252959 test loss: 255.304
106500: ********* epoch 11 ********* test accuracy for mode 0:0.0125 test loss: 425.481
106500: ********* epoch 11 ********* test accuracy for mode 1:0.036 test loss: 422.17
106500: ********* epoch 11 ********* test accuracy for mode 2:0.0765 test loss: 268.228
106500: ********* epoch 11 ********* test accuracy for mode 24:0.2595 test loss: 265.153
106500: ********* epoch 11 ********* test accuracy for mode 25:0.2685 test loss: 246.268
106500: ********* epoch 11 ********* test accuracy for mode 26:0.502 test loss: 163.18
106500: ********* epoch 11 ********* test accuracy for mode 27:0.2535 test loss: 260.988
106500: ********* epoch 11 ********* test accuracy for mode 28:0.308 test loss: 253.469
106500: ********* epoch 11 ********* test accuracy for mode 29:0.2365 test loss: 268.804
106500: ********* epoch 11 ********* test accuracy for mode 30:0.2575 test loss: 251.14
106500: ********* epoch 11 ********* test accuracy for mode 31:0.1655 test loss: 258.082
106500: ********* epoch 11 ********* test accuracy for mode 32:0.241 test loss: 242.493
106500: ********* epoch 11 ********* test accuracy for mode 33:0.267 test loss: 245.836
106500: ********* epoch 11 ********* test accuracy for mode 34:0.157 test loss: 249.932
106500: ********* epoch 11 ********* test accuracy for mode 35:0.0095 test loss: 430.839
106500: ********* epoch 11 ********* test accuracy for mode 36:0.064 test loss: 472.523
106510: accuracy:0.27 loss: 216.385 (lr:0.0001)
106520: accuracy:0.36 loss: 218.033 (lr:0.0001)
106530: accuracy:0.31 loss: 240.006 (lr:0.0001)
106540: accuracy:0.28 loss: 214.498 (lr:0.0001)
106550: accuracy:0.27 loss: 223.151 (lr:0.0001)
106560: accuracy:0.31 loss: 228.442 (lr:0.0001)
106570: accuracy:0.34 loss: 250.533 (lr:0.0001)
106580: accuracy:0.29 loss: 213.743 (lr:0.0001)
106590: accuracy:0.33 loss: 221.006 (lr:0.0001)
106600: accuracy:0.33 loss: 222.527 (lr:0.0001)
106610: accuracy:0.36 loss: 194.641 (lr:0.0001)
106620: accuracy:0.38 loss: 218.433 (lr:0.0001)
106630: accuracy:0.37 loss: 204.967 (lr:0.0001)
106640: accuracy:0.29 loss: 205.81 (lr:0.0001)
106650: accuracy:0.35 loss: 193.327 (lr:0.0001)
106660: accuracy:0.4 loss: 214.308 (lr:0.0001)
106670: accuracy:0.31 loss: 208.951 (lr:0.0001)
106680: accuracy:0.35 loss: 215.249 (lr:0.0001)
106690: accuracy:0.3 loss: 216.015 (lr:0.0001)
106700: accuracy:0.42 loss: 193.472 (lr:0.0001)
106710: accuracy:0.32 loss: 202.439 (lr:0.0001)
106720: accuracy:0.31 loss: 224.121 (lr:0.0001)
106730: accuracy:0.33 loss: 226.529 (lr:0.0001)
106740: accuracy:0.32 loss: 227.202 (lr:0.0001)
106750: accuracy:0.27 loss: 222.453 (lr:0.0001)
106760: accuracy:0.35 loss: 213.424 (lr:0.0001)
106770: accuracy:0.25 loss: 227.492 (lr:0.0001)
106780: accuracy:0.37 loss: 210.182 (lr:0.0001)
106790: accuracy:0.28 loss: 221.753 (lr:0.0001)
106800: accuracy:0.31 loss: 229.357 (lr:0.0001)
106810: accuracy:0.29 loss: 222.493 (lr:0.0001)
106820: accuracy:0.37 loss: 214.514 (lr:0.0001)
106830: accuracy:0.35 loss: 198.093 (lr:0.0001)
106840: accuracy:0.39 loss: 192.985 (lr:0.0001)
106850: accuracy:0.4 loss: 202.513 (lr:0.0001)
106860: accuracy:0.38 loss: 194.081 (lr:0.0001)
106870: accuracy:0.28 loss: 221.049 (lr:0.0001)
106880: accuracy:0.27 loss: 219.634 (lr:0.0001)
106890: accuracy:0.39 loss: 203.685 (lr:0.0001)
106900: accuracy:0.31 loss: 221.138 (lr:0.0001)
106910: accuracy:0.32 loss: 210.393 (lr:0.0001)
106920: accuracy:0.3 loss: 209.736 (lr:0.0001)
106930: accuracy:0.33 loss: 206.19 (lr:0.0001)
106940: accuracy:0.32 loss: 218.766 (lr:0.0001)
106950: accuracy:0.33 loss: 198.783 (lr:0.0001)
106960: accuracy:0.28 loss: 209.147 (lr:0.0001)
106970: accuracy:0.32 loss: 202.884 (lr:0.0001)
106980: accuracy:0.31 loss: 211.432 (lr:0.0001)
106990: accuracy:0.34 loss: 195.804 (lr:0.0001)
107000: accuracy:0.32 loss: 219.062 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
107000: ********* epoch 12 ********* test accuracy for all:0.252351 test loss: 253.742
107000: ********* epoch 12 ********* test accuracy for mode 0:0.015 test loss: 419.387
107000: ********* epoch 12 ********* test accuracy for mode 1:0.0525 test loss: 406.227
107000: ********* epoch 12 ********* test accuracy for mode 2:0.0455 test loss: 269.65
107000: ********* epoch 12 ********* test accuracy for mode 24:0.254 test loss: 270.518
107000: ********* epoch 12 ********* test accuracy for mode 25:0.2675 test loss: 250.939
107000: ********* epoch 12 ********* test accuracy for mode 26:0.469 test loss: 165.347
107000: ********* epoch 12 ********* test accuracy for mode 27:0.235 test loss: 268.2
107000: ********* epoch 12 ********* test accuracy for mode 28:0.2855 test loss: 257.403
107000: ********* epoch 12 ********* test accuracy for mode 29:0.237 test loss: 265.769
107000: ********* epoch 12 ********* test accuracy for mode 30:0.246 test loss: 251.12
107000: ********* epoch 12 ********* test accuracy for mode 31:0.196 test loss: 247.914
107000: ********* epoch 12 ********* test accuracy for mode 32:0.28 test loss: 231.737
107000: ********* epoch 12 ********* test accuracy for mode 33:0.233 test loss: 239.155
107000: ********* epoch 12 ********* test accuracy for mode 34:0.217 test loss: 239.37
107000: ********* epoch 12 ********* test accuracy for mode 35:0.02 test loss: 417.397
107000: ********* epoch 12 ********* test accuracy for mode 36:0.0995 test loss: 423.136
107010: accuracy:0.33 loss: 216.386 (lr:0.0001)
107020: accuracy:0.36 loss: 208.191 (lr:0.0001)
107030: accuracy:0.32 loss: 210.199 (lr:0.0001)
107040: accuracy:0.36 loss: 197.574 (lr:0.0001)
107050: accuracy:0.41 loss: 193.951 (lr:0.0001)
107060: accuracy:0.41 loss: 197.661 (lr:0.0001)
107070: accuracy:0.4 loss: 208.467 (lr:0.0001)
107080: accuracy:0.36 loss: 208.292 (lr:0.0001)
107090: accuracy:0.39 loss: 206.425 (lr:0.0001)
107100: accuracy:0.29 loss: 231.436 (lr:0.0001)
107110: accuracy:0.35 loss: 195.06 (lr:0.0001)
107120: accuracy:0.38 loss: 185.671 (lr:0.0001)
107130: accuracy:0.4 loss: 196.28 (lr:0.0001)
107140: accuracy:0.35 loss: 206.012 (lr:0.0001)
107150: accuracy:0.38 loss: 193.775 (lr:0.0001)
107160: accuracy:0.38 loss: 199.049 (lr:0.0001)
107170: accuracy:0.28 loss: 231.816 (lr:0.0001)
107180: accuracy:0.29 loss: 208.108 (lr:0.0001)
107190: accuracy:0.32 loss: 220.487 (lr:0.0001)
107200: accuracy:0.36 loss: 209.673 (lr:0.0001)
107210: accuracy:0.38 loss: 210.347 (lr:0.0001)
107220: accuracy:0.41 loss: 203.901 (lr:0.0001)
107230: accuracy:0.32 loss: 230.041 (lr:0.0001)
107240: accuracy:0.31 loss: 218.198 (lr:0.0001)
107250: accuracy:0.34 loss: 215.627 (lr:0.0001)
107260: accuracy:0.43 loss: 199.839 (lr:0.0001)
107270: accuracy:0.29 loss: 206.563 (lr:0.0001)
107280: accuracy:0.42 loss: 208.604 (lr:0.0001)
107290: accuracy:0.35 loss: 193.92 (lr:0.0001)
107300: accuracy:0.34 loss: 218.893 (lr:0.0001)
107310: accuracy:0.3 loss: 225.087 (lr:0.0001)
107320: accuracy:0.35 loss: 198.577 (lr:0.0001)
107330: accuracy:0.36 loss: 195.841 (lr:0.0001)
107340: accuracy:0.36 loss: 211.987 (lr:0.0001)
107350: accuracy:0.24 loss: 207.295 (lr:0.0001)
107360: accuracy:0.28 loss: 210.383 (lr:0.0001)
107370: accuracy:0.24 loss: 222.822 (lr:0.0001)
107380: accuracy:0.36 loss: 212.307 (lr:0.0001)
107390: accuracy:0.31 loss: 221.634 (lr:0.0001)
107400: accuracy:0.36 loss: 207.288 (lr:0.0001)
107410: accuracy:0.35 loss: 203.646 (lr:0.0001)
107420: accuracy:0.3 loss: 208.948 (lr:0.0001)
107430: accuracy:0.28 loss: 235.37 (lr:0.0001)
107440: accuracy:0.3 loss: 216.341 (lr:0.0001)
107450: accuracy:0.29 loss: 226.85 (lr:0.0001)
107460: accuracy:0.3 loss: 206.202 (lr:0.0001)
107470: accuracy:0.33 loss: 202.635 (lr:0.0001)
107480: accuracy:0.36 loss: 187.288 (lr:0.0001)
107490: accuracy:0.25 loss: 224.5 (lr:0.0001)
107500: accuracy:0.29 loss: 216.697 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
107500: ********* epoch 12 ********* test accuracy for all:0.252459 test loss: 254.947
107500: ********* epoch 12 ********* test accuracy for mode 0:0.0105 test loss: 425.7
107500: ********* epoch 12 ********* test accuracy for mode 1:0.048 test loss: 406.54
107500: ********* epoch 12 ********* test accuracy for mode 2:0.056 test loss: 269.485
107500: ********* epoch 12 ********* test accuracy for mode 24:0.247 test loss: 269.499
107500: ********* epoch 12 ********* test accuracy for mode 25:0.275 test loss: 246.236
107500: ********* epoch 12 ********* test accuracy for mode 26:0.4975 test loss: 156.612
107500: ********* epoch 12 ********* test accuracy for mode 27:0.289 test loss: 247.317
107500: ********* epoch 12 ********* test accuracy for mode 28:0.3165 test loss: 242.975
107500: ********* epoch 12 ********* test accuracy for mode 29:0.276 test loss: 253.221
107500: ********* epoch 12 ********* test accuracy for mode 30:0.281 test loss: 239.254
107500: ********* epoch 12 ********* test accuracy for mode 31:0.2125 test loss: 246.654
107500: ********* epoch 12 ********* test accuracy for mode 32:0.1695 test loss: 241.643
107500: ********* epoch 12 ********* test accuracy for mode 33:0.2855 test loss: 240.958
107500: ********* epoch 12 ********* test accuracy for mode 34:0.1395 test loss: 247.43
107500: ********* epoch 12 ********* test accuracy for mode 35:0.019 test loss: 440.591
107500: ********* epoch 12 ********* test accuracy for mode 36:0.0735 test loss: 457.203
107510: accuracy:0.35 loss: 212.497 (lr:0.0001)
107520: accuracy:0.4 loss: 229.343 (lr:0.0001)
107530: accuracy:0.18 loss: 241.219 (lr:0.0001)
107540: accuracy:0.32 loss: 228.828 (lr:0.0001)
107550: accuracy:0.32 loss: 207.066 (lr:0.0001)
107560: accuracy:0.3 loss: 206.391 (lr:0.0001)
107570: accuracy:0.37 loss: 214.726 (lr:0.0001)
107580: accuracy:0.27 loss: 232.03 (lr:0.0001)
107590: accuracy:0.37 loss: 205.299 (lr:0.0001)
107600: accuracy:0.39 loss: 214.935 (lr:0.0001)
107610: accuracy:0.35 loss: 225.754 (lr:0.0001)
107620: accuracy:0.34 loss: 198.244 (lr:0.0001)
107630: accuracy:0.25 loss: 229.001 (lr:0.0001)
107640: accuracy:0.34 loss: 213.329 (lr:0.0001)
107650: accuracy:0.31 loss: 203.937 (lr:0.0001)
107660: accuracy:0.3 loss: 232.191 (lr:0.0001)
107670: accuracy:0.3 loss: 218.891 (lr:0.0001)
107680: accuracy:0.34 loss: 209.391 (lr:0.0001)
107690: accuracy:0.32 loss: 210.272 (lr:0.0001)
107700: accuracy:0.33 loss: 215.966 (lr:0.0001)
107710: accuracy:0.37 loss: 204.189 (lr:0.0001)
107720: accuracy:0.34 loss: 201.663 (lr:0.0001)
107730: accuracy:0.33 loss: 201.27 (lr:0.0001)
107740: accuracy:0.23 loss: 235.145 (lr:0.0001)
107750: accuracy:0.4 loss: 206.026 (lr:0.0001)
107760: accuracy:0.29 loss: 203.866 (lr:0.0001)
107770: accuracy:0.32 loss: 224.698 (lr:0.0001)
107780: accuracy:0.37 loss: 198.474 (lr:0.0001)
107790: accuracy:0.27 loss: 225.4 (lr:0.0001)
107800: accuracy:0.32 loss: 210.202 (lr:0.0001)
107810: accuracy:0.36 loss: 207.638 (lr:0.0001)
107820: accuracy:0.38 loss: 202.2 (lr:0.0001)
107830: accuracy:0.24 loss: 248.476 (lr:0.0001)
107840: accuracy:0.3 loss: 217.427 (lr:0.0001)
107850: accuracy:0.3 loss: 225.408 (lr:0.0001)
107860: accuracy:0.35 loss: 206.446 (lr:0.0001)
107870: accuracy:0.35 loss: 221.17 (lr:0.0001)
107880: accuracy:0.32 loss: 202.242 (lr:0.0001)
107890: accuracy:0.23 loss: 231.382 (lr:0.0001)
107900: accuracy:0.38 loss: 195.846 (lr:0.0001)
107910: accuracy:0.28 loss: 221.121 (lr:0.0001)
107920: accuracy:0.34 loss: 213.462 (lr:0.0001)
107930: accuracy:0.32 loss: 213.614 (lr:0.0001)
107940: accuracy:0.33 loss: 216.556 (lr:0.0001)
107950: accuracy:0.38 loss: 210.982 (lr:0.0001)
107960: accuracy:0.22 loss: 249.457 (lr:0.0001)
107970: accuracy:0.38 loss: 228.275 (lr:0.0001)
107980: accuracy:0.31 loss: 201.145 (lr:0.0001)
107990: accuracy:0.3 loss: 218.507 (lr:0.0001)
108000: accuracy:0.35 loss: 199.267 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
108000: ********* epoch 12 ********* test accuracy for all:0.25077 test loss: 255.527
108000: ********* epoch 12 ********* test accuracy for mode 0:0.009 test loss: 429.348
108000: ********* epoch 12 ********* test accuracy for mode 1:0.036 test loss: 414.864
108000: ********* epoch 12 ********* test accuracy for mode 2:0.061 test loss: 261.025
108000: ********* epoch 12 ********* test accuracy for mode 24:0.218 test loss: 276.175
108000: ********* epoch 12 ********* test accuracy for mode 25:0.275 test loss: 254.352
108000: ********* epoch 12 ********* test accuracy for mode 26:0.381 test loss: 176.931
108000: ********* epoch 12 ********* test accuracy for mode 27:0.2755 test loss: 263.614
108000: ********* epoch 12 ********* test accuracy for mode 28:0.2555 test loss: 259.454
108000: ********* epoch 12 ********* test accuracy for mode 29:0.2855 test loss: 255.953
108000: ********* epoch 12 ********* test accuracy for mode 30:0.1985 test loss: 249.575
108000: ********* epoch 12 ********* test accuracy for mode 31:0.2225 test loss: 242.044
108000: ********* epoch 12 ********* test accuracy for mode 32:0.263 test loss: 229.85
108000: ********* epoch 12 ********* test accuracy for mode 33:0.2585 test loss: 239.686
108000: ********* epoch 12 ********* test accuracy for mode 34:0.2255 test loss: 242.595
108000: ********* epoch 12 ********* test accuracy for mode 35:0.0205 test loss: 428.604
108000: ********* epoch 12 ********* test accuracy for mode 36:0.135 test loss: 438.863
108010: accuracy:0.31 loss: 222.21 (lr:0.0001)
108020: accuracy:0.31 loss: 215.036 (lr:0.0001)
108030: accuracy:0.33 loss: 200.146 (lr:0.0001)
108040: accuracy:0.27 loss: 218.944 (lr:0.0001)
108050: accuracy:0.31 loss: 202.134 (lr:0.0001)
108060: accuracy:0.27 loss: 235.984 (lr:0.0001)
108070: accuracy:0.34 loss: 204.233 (lr:0.0001)
108080: accuracy:0.4 loss: 226.488 (lr:0.0001)
108090: accuracy:0.3 loss: 217.208 (lr:0.0001)
108100: accuracy:0.28 loss: 223.941 (lr:0.0001)
108110: accuracy:0.33 loss: 210.566 (lr:0.0001)
108120: accuracy:0.21 loss: 235.326 (lr:0.0001)
108130: accuracy:0.31 loss: 221.008 (lr:0.0001)
108140: accuracy:0.38 loss: 200.918 (lr:0.0001)
108150: accuracy:0.34 loss: 191.554 (lr:0.0001)
108160: accuracy:0.41 loss: 196.343 (lr:0.0001)
108170: accuracy:0.32 loss: 230.197 (lr:0.0001)
108180: accuracy:0.39 loss: 197.54 (lr:0.0001)
108190: accuracy:0.43 loss: 190.337 (lr:0.0001)
108200: accuracy:0.38 loss: 219.687 (lr:0.0001)
108210: accuracy:0.37 loss: 215.239 (lr:0.0001)
108220: accuracy:0.36 loss: 220.155 (lr:0.0001)
108230: accuracy:0.27 loss: 212.019 (lr:0.0001)
108240: accuracy:0.42 loss: 191.248 (lr:0.0001)
108250: accuracy:0.27 loss: 230.407 (lr:0.0001)
108260: accuracy:0.34 loss: 216.243 (lr:0.0001)
108270: accuracy:0.24 loss: 238.572 (lr:0.0001)
108280: accuracy:0.39 loss: 215.061 (lr:0.0001)
108290: accuracy:0.27 loss: 249.091 (lr:0.0001)
108300: accuracy:0.29 loss: 226.092 (lr:0.0001)
108310: accuracy:0.32 loss: 216.229 (lr:0.0001)
108320: accuracy:0.39 loss: 207.631 (lr:0.0001)
108330: accuracy:0.3 loss: 222.474 (lr:0.0001)
108340: accuracy:0.32 loss: 202.173 (lr:0.0001)
108350: accuracy:0.32 loss: 216.236 (lr:0.0001)
108360: accuracy:0.29 loss: 224.959 (lr:0.0001)
108370: accuracy:0.37 loss: 230.391 (lr:0.0001)
108380: accuracy:0.34 loss: 202.063 (lr:0.0001)
108390: accuracy:0.31 loss: 206.45 (lr:0.0001)
108400: accuracy:0.32 loss: 194.82 (lr:0.0001)
108410: accuracy:0.17 loss: 238.135 (lr:0.0001)
108420: accuracy:0.29 loss: 239.381 (lr:0.0001)
108430: accuracy:0.32 loss: 194.772 (lr:0.0001)
108440: accuracy:0.39 loss: 201.114 (lr:0.0001)
108450: accuracy:0.28 loss: 208.666 (lr:0.0001)
108460: accuracy:0.39 loss: 208.203 (lr:0.0001)
108470: accuracy:0.29 loss: 217.218 (lr:0.0001)
108480: accuracy:0.3 loss: 226.387 (lr:0.0001)
108490: accuracy:0.36 loss: 200.409 (lr:0.0001)
108500: accuracy:0.37 loss: 186.441 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
108500: ********* epoch 12 ********* test accuracy for all:0.250014 test loss: 255.962
108500: ********* epoch 12 ********* test accuracy for mode 0:0.0125 test loss: 423.737
108500: ********* epoch 12 ********* test accuracy for mode 1:0.0385 test loss: 417.888
108500: ********* epoch 12 ********* test accuracy for mode 2:0.0615 test loss: 260.867
108500: ********* epoch 12 ********* test accuracy for mode 24:0.2555 test loss: 270.5
108500: ********* epoch 12 ********* test accuracy for mode 25:0.259 test loss: 254.943
108500: ********* epoch 12 ********* test accuracy for mode 26:0.436 test loss: 169.072
108500: ********* epoch 12 ********* test accuracy for mode 27:0.218 test loss: 276.313
108500: ********* epoch 12 ********* test accuracy for mode 28:0.288 test loss: 259.768
108500: ********* epoch 12 ********* test accuracy for mode 29:0.2425 test loss: 263.789
108500: ********* epoch 12 ********* test accuracy for mode 30:0.2745 test loss: 247.288
108500: ********* epoch 12 ********* test accuracy for mode 31:0.1865 test loss: 251.514
108500: ********* epoch 12 ********* test accuracy for mode 32:0.2225 test loss: 240.023
108500: ********* epoch 12 ********* test accuracy for mode 33:0.254 test loss: 244.576
108500: ********* epoch 12 ********* test accuracy for mode 34:0.192 test loss: 246.447
108500: ********* epoch 12 ********* test accuracy for mode 35:0.0285 test loss: 417.299
108500: ********* epoch 12 ********* test accuracy for mode 36:0.0985 test loss: 444.176
108510: accuracy:0.32 loss: 228.718 (lr:0.0001)
108520: accuracy:0.28 loss: 216.409 (lr:0.0001)
108530: accuracy:0.26 loss: 252.291 (lr:0.0001)
108540: accuracy:0.33 loss: 209.399 (lr:0.0001)
108550: accuracy:0.24 loss: 234.743 (lr:0.0001)
108560: accuracy:0.34 loss: 210.861 (lr:0.0001)
108570: accuracy:0.31 loss: 222.247 (lr:0.0001)
108580: accuracy:0.38 loss: 222.83 (lr:0.0001)
108590: accuracy:0.35 loss: 211.625 (lr:0.0001)
108600: accuracy:0.36 loss: 209.511 (lr:0.0001)
108610: accuracy:0.33 loss: 224.165 (lr:0.0001)
108620: accuracy:0.3 loss: 236.228 (lr:0.0001)
108630: accuracy:0.4 loss: 192.678 (lr:0.0001)
108640: accuracy:0.29 loss: 242.711 (lr:0.0001)
108650: accuracy:0.21 loss: 229.601 (lr:0.0001)
108660: accuracy:0.31 loss: 220.058 (lr:0.0001)
108670: accuracy:0.31 loss: 236.817 (lr:0.0001)
108680: accuracy:0.39 loss: 208.057 (lr:0.0001)
108690: accuracy:0.32 loss: 213.098 (lr:0.0001)
108700: accuracy:0.33 loss: 210.121 (lr:0.0001)
108710: accuracy:0.32 loss: 208.581 (lr:0.0001)
108720: accuracy:0.31 loss: 199.855 (lr:0.0001)
108730: accuracy:0.32 loss: 208.774 (lr:0.0001)
108740: accuracy:0.29 loss: 228.899 (lr:0.0001)
108750: accuracy:0.39 loss: 211.939 (lr:0.0001)
108760: accuracy:0.36 loss: 200.157 (lr:0.0001)
108770: accuracy:0.46 loss: 196.813 (lr:0.0001)
108780: accuracy:0.33 loss: 206.245 (lr:0.0001)
108790: accuracy:0.39 loss: 202.152 (lr:0.0001)
108800: accuracy:0.32 loss: 218.071 (lr:0.0001)
108810: accuracy:0.32 loss: 219.9 (lr:0.0001)
108820: accuracy:0.31 loss: 226.01 (lr:0.0001)
108830: accuracy:0.26 loss: 220.962 (lr:0.0001)
108840: accuracy:0.36 loss: 193.576 (lr:0.0001)
108850: accuracy:0.29 loss: 234.876 (lr:0.0001)
108860: accuracy:0.36 loss: 210.067 (lr:0.0001)
108870: accuracy:0.38 loss: 217.41 (lr:0.0001)
108880: accuracy:0.37 loss: 226.127 (lr:0.0001)
108890: accuracy:0.32 loss: 209.88 (lr:0.0001)
108900: accuracy:0.32 loss: 215.673 (lr:0.0001)
108910: accuracy:0.36 loss: 228.847 (lr:0.0001)
108920: accuracy:0.28 loss: 216.63 (lr:0.0001)
108930: accuracy:0.35 loss: 218.474 (lr:0.0001)
108940: accuracy:0.37 loss: 197.286 (lr:0.0001)
108950: accuracy:0.37 loss: 188.191 (lr:0.0001)
108960: accuracy:0.34 loss: 219.781 (lr:0.0001)
108970: accuracy:0.39 loss: 206.273 (lr:0.0001)
108980: accuracy:0.29 loss: 214.902 (lr:0.0001)
108990: accuracy:0.31 loss: 204.97 (lr:0.0001)
109000: accuracy:0.33 loss: 229.405 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
109000: ********* epoch 12 ********* test accuracy for all:0.252757 test loss: 256.458
109000: ********* epoch 12 ********* test accuracy for mode 0:0.0175 test loss: 425.475
109000: ********* epoch 12 ********* test accuracy for mode 1:0.0425 test loss: 418.503
109000: ********* epoch 12 ********* test accuracy for mode 2:0.0375 test loss: 270.69
109000: ********* epoch 12 ********* test accuracy for mode 24:0.2555 test loss: 267.005
109000: ********* epoch 12 ********* test accuracy for mode 25:0.334 test loss: 240.322
109000: ********* epoch 12 ********* test accuracy for mode 26:0.4285 test loss: 168.595
109000: ********* epoch 12 ********* test accuracy for mode 27:0.254 test loss: 262.972
109000: ********* epoch 12 ********* test accuracy for mode 28:0.326 test loss: 255.483
109000: ********* epoch 12 ********* test accuracy for mode 29:0.24 test loss: 272.634
109000: ********* epoch 12 ********* test accuracy for mode 30:0.214 test loss: 263.533
109000: ********* epoch 12 ********* test accuracy for mode 31:0.186 test loss: 265.173
109000: ********* epoch 12 ********* test accuracy for mode 32:0.229 test loss: 245.431
109000: ********* epoch 12 ********* test accuracy for mode 33:0.2565 test loss: 247.707
109000: ********* epoch 12 ********* test accuracy for mode 34:0.19 test loss: 248.505
109000: ********* epoch 12 ********* test accuracy for mode 35:0.0155 test loss: 433.116
109000: ********* epoch 12 ********* test accuracy for mode 36:0.067 test loss: 481.02
109010: accuracy:0.26 loss: 220.325 (lr:0.0001)
109020: accuracy:0.3 loss: 208.222 (lr:0.0001)
109030: accuracy:0.27 loss: 217.493 (lr:0.0001)
109040: accuracy:0.31 loss: 217.73 (lr:0.0001)
109050: accuracy:0.3 loss: 219.461 (lr:0.0001)
109060: accuracy:0.34 loss: 225.731 (lr:0.0001)
109070: accuracy:0.39 loss: 195.903 (lr:0.0001)
109080: accuracy:0.28 loss: 223.928 (lr:0.0001)
109090: accuracy:0.31 loss: 212.847 (lr:0.0001)
109100: accuracy:0.37 loss: 189.916 (lr:0.0001)
109110: accuracy:0.27 loss: 218.971 (lr:0.0001)
109120: accuracy:0.34 loss: 219.727 (lr:0.0001)
109130: accuracy:0.29 loss: 228.806 (lr:0.0001)
109140: accuracy:0.28 loss: 197.585 (lr:0.0001)
109150: accuracy:0.39 loss: 224.145 (lr:0.0001)
109160: accuracy:0.4 loss: 216.053 (lr:0.0001)
109170: accuracy:0.37 loss: 212.373 (lr:0.0001)
109180: accuracy:0.25 loss: 218.656 (lr:0.0001)
109190: accuracy:0.3 loss: 207.639 (lr:0.0001)
109200: accuracy:0.33 loss: 228.393 (lr:0.0001)
109210: accuracy:0.38 loss: 188.922 (lr:0.0001)
109220: accuracy:0.33 loss: 219.615 (lr:0.0001)
109230: accuracy:0.33 loss: 222.78 (lr:0.0001)
109240: accuracy:0.38 loss: 218.516 (lr:0.0001)
109250: accuracy:0.36 loss: 216.981 (lr:0.0001)
109260: accuracy:0.41 loss: 206.354 (lr:0.0001)
109270: accuracy:0.35 loss: 225.425 (lr:0.0001)
109280: accuracy:0.35 loss: 193.117 (lr:0.0001)
109290: accuracy:0.28 loss: 229.019 (lr:0.0001)
109300: accuracy:0.32 loss: 217.409 (lr:0.0001)
109310: accuracy:0.33 loss: 217.539 (lr:0.0001)
109320: accuracy:0.32 loss: 218.475 (lr:0.0001)
109330: accuracy:0.28 loss: 236.132 (lr:0.0001)
109340: accuracy:0.34 loss: 221.919 (lr:0.0001)
109350: accuracy:0.33 loss: 221.317 (lr:0.0001)
109360: accuracy:0.38 loss: 181.542 (lr:0.0001)
109370: accuracy:0.3 loss: 222.94 (lr:0.0001)
109380: accuracy:0.26 loss: 231.275 (lr:0.0001)
109390: accuracy:0.31 loss: 211.372 (lr:0.0001)
109400: accuracy:0.39 loss: 200.865 (lr:0.0001)
109410: accuracy:0.31 loss: 209.315 (lr:0.0001)
109420: accuracy:0.32 loss: 209.507 (lr:0.0001)
109430: accuracy:0.41 loss: 186.669 (lr:0.0001)
109440: accuracy:0.4 loss: 190.668 (lr:0.0001)
109450: accuracy:0.39 loss: 212.376 (lr:0.0001)
109460: accuracy:0.24 loss: 223.505 (lr:0.0001)
109470: accuracy:0.35 loss: 229.383 (lr:0.0001)
109480: accuracy:0.33 loss: 202.213 (lr:0.0001)
109490: accuracy:0.44 loss: 201.763 (lr:0.0001)
109500: accuracy:0.31 loss: 211.067 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
109500: ********* epoch 12 ********* test accuracy for all:0.254243 test loss: 253.974
109500: ********* epoch 12 ********* test accuracy for mode 0:0.019 test loss: 415.965
109500: ********* epoch 12 ********* test accuracy for mode 1:0.0405 test loss: 416.389
109500: ********* epoch 12 ********* test accuracy for mode 2:0.037 test loss: 269.565
109500: ********* epoch 12 ********* test accuracy for mode 24:0.2275 test loss: 271.148
109500: ********* epoch 12 ********* test accuracy for mode 25:0.3225 test loss: 243.452
109500: ********* epoch 12 ********* test accuracy for mode 26:0.438 test loss: 166.164
109500: ********* epoch 12 ********* test accuracy for mode 27:0.2825 test loss: 261.654
109500: ********* epoch 12 ********* test accuracy for mode 28:0.295 test loss: 255.03
109500: ********* epoch 12 ********* test accuracy for mode 29:0.281 test loss: 260.066
109500: ********* epoch 12 ********* test accuracy for mode 30:0.207 test loss: 254.573
109500: ********* epoch 12 ********* test accuracy for mode 31:0.2115 test loss: 253.491
109500: ********* epoch 12 ********* test accuracy for mode 32:0.2525 test loss: 238.804
109500: ********* epoch 12 ********* test accuracy for mode 33:0.2425 test loss: 246.351
109500: ********* epoch 12 ********* test accuracy for mode 34:0.168 test loss: 248.645
109500: ********* epoch 12 ********* test accuracy for mode 35:0.023 test loss: 425.543
109500: ********* epoch 12 ********* test accuracy for mode 36:0.078 test loss: 452.495
109510: accuracy:0.29 loss: 216.01 (lr:0.0001)
109520: accuracy:0.33 loss: 208.668 (lr:0.0001)
109530: accuracy:0.38 loss: 217.669 (lr:0.0001)
109540: accuracy:0.36 loss: 222.805 (lr:0.0001)
109550: accuracy:0.35 loss: 226.761 (lr:0.0001)
109560: accuracy:0.34 loss: 215.508 (lr:0.0001)
109570: accuracy:0.41 loss: 204.557 (lr:0.0001)
109580: accuracy:0.38 loss: 209.616 (lr:0.0001)
109590: accuracy:0.37 loss: 209.554 (lr:0.0001)
109600: accuracy:0.34 loss: 220.81 (lr:0.0001)
109610: accuracy:0.4 loss: 215.265 (lr:0.0001)
109620: accuracy:0.33 loss: 206.757 (lr:0.0001)
109630: accuracy:0.3 loss: 216.127 (lr:0.0001)
109640: accuracy:0.38 loss: 211.352 (lr:0.0001)
109650: accuracy:0.29 loss: 200.733 (lr:0.0001)
109660: accuracy:0.29 loss: 208.323 (lr:0.0001)
109670: accuracy:0.26 loss: 217.061 (lr:0.0001)
109680: accuracy:0.31 loss: 230.279 (lr:0.0001)
109690: accuracy:0.34 loss: 213.071 (lr:0.0001)
109700: accuracy:0.43 loss: 189.182 (lr:0.0001)
109710: accuracy:0.44 loss: 177.385 (lr:0.0001)
109720: accuracy:0.34 loss: 212.419 (lr:0.0001)
109730: accuracy:0.32 loss: 204.274 (lr:0.0001)
109740: accuracy:0.38 loss: 202.005 (lr:0.0001)
109750: accuracy:0.36 loss: 200.11 (lr:0.0001)
109760: accuracy:0.34 loss: 213.808 (lr:0.0001)
109770: accuracy:0.33 loss: 210.428 (lr:0.0001)
109780: accuracy:0.41 loss: 210.1 (lr:0.0001)
109790: accuracy:0.46 loss: 186.052 (lr:0.0001)
109800: accuracy:0.31 loss: 210.821 (lr:0.0001)
109810: accuracy:0.34 loss: 201.248 (lr:0.0001)
109820: accuracy:0.37 loss: 197.795 (lr:0.0001)
109830: accuracy:0.37 loss: 200.605 (lr:0.0001)
109840: accuracy:0.38 loss: 191.528 (lr:0.0001)
109850: accuracy:0.31 loss: 208.64 (lr:0.0001)
109860: accuracy:0.27 loss: 237.272 (lr:0.0001)
109870: accuracy:0.24 loss: 225.981 (lr:0.0001)
109880: accuracy:0.31 loss: 209.56 (lr:0.0001)
109890: accuracy:0.4 loss: 210.493 (lr:0.0001)
109900: accuracy:0.34 loss: 217.494 (lr:0.0001)
109910: accuracy:0.33 loss: 204.491 (lr:0.0001)
109920: accuracy:0.31 loss: 227.237 (lr:0.0001)
109930: accuracy:0.38 loss: 217.46 (lr:0.0001)
109940: accuracy:0.36 loss: 213.962 (lr:0.0001)
109950: accuracy:0.25 loss: 204.888 (lr:0.0001)
109960: accuracy:0.37 loss: 211.479 (lr:0.0001)
109970: accuracy:0.31 loss: 212.959 (lr:0.0001)
109980: accuracy:0.37 loss: 213.286 (lr:0.0001)
109990: accuracy:0.26 loss: 216.79 (lr:0.0001)
110000: accuracy:0.25 loss: 225.65 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
110000: ********* epoch 12 ********* test accuracy for all:0.253189 test loss: 252.738
110000: ********* epoch 12 ********* test accuracy for mode 0:0.013 test loss: 410.71
110000: ********* epoch 12 ********* test accuracy for mode 1:0.04 test loss: 410.613
110000: ********* epoch 12 ********* test accuracy for mode 2:0.0655 test loss: 264.869
110000: ********* epoch 12 ********* test accuracy for mode 24:0.274 test loss: 257.787
110000: ********* epoch 12 ********* test accuracy for mode 25:0.2805 test loss: 234.301
110000: ********* epoch 12 ********* test accuracy for mode 26:0.473 test loss: 161.407
110000: ********* epoch 12 ********* test accuracy for mode 27:0.2555 test loss: 257.435
110000: ********* epoch 12 ********* test accuracy for mode 28:0.278 test loss: 250.226
110000: ********* epoch 12 ********* test accuracy for mode 29:0.2865 test loss: 254.436
110000: ********* epoch 12 ********* test accuracy for mode 30:0.2235 test loss: 249.38
110000: ********* epoch 12 ********* test accuracy for mode 31:0.2055 test loss: 251.198
110000: ********* epoch 12 ********* test accuracy for mode 32:0.265 test loss: 236.561
110000: ********* epoch 12 ********* test accuracy for mode 33:0.2755 test loss: 242.79
110000: ********* epoch 12 ********* test accuracy for mode 34:0.1455 test loss: 251.743
110000: ********* epoch 12 ********* test accuracy for mode 35:0.0395 test loss: 397.421
110000: ********* epoch 12 ********* test accuracy for mode 36:0.1015 test loss: 416.255
110010: accuracy:0.31 loss: 210.731 (lr:0.0001)
110020: accuracy:0.34 loss: 209.238 (lr:0.0001)
110030: accuracy:0.32 loss: 202.608 (lr:0.0001)
110040: accuracy:0.36 loss: 223.576 (lr:0.0001)
110050: accuracy:0.28 loss: 214.013 (lr:0.0001)
110060: accuracy:0.37 loss: 198.749 (lr:0.0001)
110070: accuracy:0.31 loss: 210.799 (lr:0.0001)
110080: accuracy:0.35 loss: 221.327 (lr:0.0001)
110090: accuracy:0.29 loss: 210.437 (lr:0.0001)
110100: accuracy:0.3 loss: 202.608 (lr:0.0001)
110110: accuracy:0.33 loss: 227.548 (lr:0.0001)
110120: accuracy:0.24 loss: 233.441 (lr:0.0001)
110130: accuracy:0.36 loss: 209.56 (lr:0.0001)
110140: accuracy:0.37 loss: 230.035 (lr:0.0001)
110150: accuracy:0.35 loss: 195.953 (lr:0.0001)
110160: accuracy:0.34 loss: 220.292 (lr:0.0001)
110170: accuracy:0.35 loss: 206.546 (lr:0.0001)
110180: accuracy:0.34 loss: 215.913 (lr:0.0001)
110190: accuracy:0.29 loss: 193.421 (lr:0.0001)
110200: accuracy:0.39 loss: 191.86 (lr:0.0001)
110210: accuracy:0.3 loss: 198.794 (lr:0.0001)
110220: accuracy:0.41 loss: 195.129 (lr:0.0001)
110230: accuracy:0.26 loss: 204.934 (lr:0.0001)
110240: accuracy:0.41 loss: 198.696 (lr:0.0001)
110250: accuracy:0.37 loss: 216.374 (lr:0.0001)
110260: accuracy:0.34 loss: 216.495 (lr:0.0001)
110270: accuracy:0.36 loss: 199.568 (lr:0.0001)
110280: accuracy:0.37 loss: 203.314 (lr:0.0001)
110290: accuracy:0.36 loss: 220.285 (lr:0.0001)
110300: accuracy:0.34 loss: 231.184 (lr:0.0001)
110310: accuracy:0.28 loss: 220.516 (lr:0.0001)
110320: accuracy:0.24 loss: 235.431 (lr:0.0001)
110330: accuracy:0.34 loss: 200.417 (lr:0.0001)
110340: accuracy:0.35 loss: 215.645 (lr:0.0001)
110350: accuracy:0.4 loss: 202.22 (lr:0.0001)
110360: accuracy:0.3 loss: 234.09 (lr:0.0001)
110370: accuracy:0.33 loss: 227.539 (lr:0.0001)
110380: accuracy:0.38 loss: 194.104 (lr:0.0001)
110390: accuracy:0.29 loss: 234.058 (lr:0.0001)
110400: accuracy:0.32 loss: 209.771 (lr:0.0001)
110410: accuracy:0.38 loss: 182.629 (lr:0.0001)
110420: accuracy:0.39 loss: 190.899 (lr:0.0001)
110430: accuracy:0.32 loss: 205.506 (lr:0.0001)
110440: accuracy:0.47 loss: 187.929 (lr:0.0001)
110450: accuracy:0.34 loss: 214.928 (lr:0.0001)
110460: accuracy:0.25 loss: 219.199 (lr:0.0001)
110470: accuracy:0.32 loss: 214.289 (lr:0.0001)
110480: accuracy:0.3 loss: 209.122 (lr:0.0001)
110490: accuracy:0.4 loss: 199.312 (lr:0.0001)
110500: accuracy:0.34 loss: 218.15 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
110500: ********* epoch 12 ********* test accuracy for all:0.252757 test loss: 253.744
110500: ********* epoch 12 ********* test accuracy for mode 0:0.015 test loss: 418.629
110500: ********* epoch 12 ********* test accuracy for mode 1:0.045 test loss: 407.498
110500: ********* epoch 12 ********* test accuracy for mode 2:0.0395 test loss: 268.728
110500: ********* epoch 12 ********* test accuracy for mode 24:0.255 test loss: 262.256
110500: ********* epoch 12 ********* test accuracy for mode 25:0.2655 test loss: 245.055
110500: ********* epoch 12 ********* test accuracy for mode 26:0.4575 test loss: 163.759
110500: ********* epoch 12 ********* test accuracy for mode 27:0.248 test loss: 264.597
110500: ********* epoch 12 ********* test accuracy for mode 28:0.2935 test loss: 251.737
110500: ********* epoch 12 ********* test accuracy for mode 29:0.2445 test loss: 263.643
110500: ********* epoch 12 ********* test accuracy for mode 30:0.248 test loss: 249.401
110500: ********* epoch 12 ********* test accuracy for mode 31:0.162 test loss: 257.461
110500: ********* epoch 12 ********* test accuracy for mode 32:0.282 test loss: 236.249
110500: ********* epoch 12 ********* test accuracy for mode 33:0.271 test loss: 241.224
110500: ********* epoch 12 ********* test accuracy for mode 34:0.172 test loss: 247.439
110500: ********* epoch 12 ********* test accuracy for mode 35:0.0215 test loss: 419.967
110500: ********* epoch 12 ********* test accuracy for mode 36:0.0975 test loss: 440.714
110510: accuracy:0.33 loss: 230.296 (lr:0.0001)
110520: accuracy:0.26 loss: 236.491 (lr:0.0001)
110530: accuracy:0.36 loss: 206.851 (lr:0.0001)
110540: accuracy:0.3 loss: 207.802 (lr:0.0001)
110550: accuracy:0.32 loss: 210.246 (lr:0.0001)
110560: accuracy:0.37 loss: 207.769 (lr:0.0001)
110570: accuracy:0.35 loss: 234.978 (lr:0.0001)
110580: accuracy:0.29 loss: 223.653 (lr:0.0001)
110590: accuracy:0.35 loss: 215.852 (lr:0.0001)
110600: accuracy:0.37 loss: 202.757 (lr:0.0001)
110610: accuracy:0.28 loss: 213.183 (lr:0.0001)
110620: accuracy:0.3 loss: 225.211 (lr:0.0001)
110630: accuracy:0.37 loss: 205.815 (lr:0.0001)
110640: accuracy:0.39 loss: 210.551 (lr:0.0001)
110650: accuracy:0.39 loss: 190.507 (lr:0.0001)
110660: accuracy:0.39 loss: 210.347 (lr:0.0001)
110670: accuracy:0.31 loss: 205.804 (lr:0.0001)
110680: accuracy:0.33 loss: 197.053 (lr:0.0001)
110690: accuracy:0.31 loss: 218.914 (lr:0.0001)
110700: accuracy:0.4 loss: 203.744 (lr:0.0001)
110710: accuracy:0.3 loss: 237.78 (lr:0.0001)
110720: accuracy:0.38 loss: 204.825 (lr:0.0001)
110730: accuracy:0.31 loss: 231.976 (lr:0.0001)
110740: accuracy:0.33 loss: 187.377 (lr:0.0001)
110750: accuracy:0.32 loss: 218.211 (lr:0.0001)
110760: accuracy:0.35 loss: 209.043 (lr:0.0001)
110770: accuracy:0.26 loss: 233.939 (lr:0.0001)
110780: accuracy:0.37 loss: 222.125 (lr:0.0001)
110790: accuracy:0.35 loss: 230.899 (lr:0.0001)
110800: accuracy:0.29 loss: 216.412 (lr:0.0001)
110810: accuracy:0.34 loss: 220.524 (lr:0.0001)
110820: accuracy:0.32 loss: 229.725 (lr:0.0001)
110830: accuracy:0.3 loss: 198.132 (lr:0.0001)
110840: accuracy:0.24 loss: 216.797 (lr:0.0001)
110850: accuracy:0.3 loss: 214.294 (lr:0.0001)
110860: accuracy:0.33 loss: 216.954 (lr:0.0001)
110870: accuracy:0.35 loss: 202.273 (lr:0.0001)
110880: accuracy:0.36 loss: 201.897 (lr:0.0001)
110890: accuracy:0.29 loss: 227.993 (lr:0.0001)
110900: accuracy:0.35 loss: 198.609 (lr:0.0001)
110910: accuracy:0.28 loss: 226.977 (lr:0.0001)
110920: accuracy:0.32 loss: 207.121 (lr:0.0001)
110930: accuracy:0.36 loss: 215.006 (lr:0.0001)
110940: accuracy:0.42 loss: 205.122 (lr:0.0001)
110950: accuracy:0.29 loss: 217.243 (lr:0.0001)
110960: accuracy:0.33 loss: 207.495 (lr:0.0001)
110970: accuracy:0.36 loss: 217.641 (lr:0.0001)
110980: accuracy:0.39 loss: 198.784 (lr:0.0001)
110990: accuracy:0.25 loss: 237.325 (lr:0.0001)
111000: accuracy:0.35 loss: 212.031 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
111000: ********* epoch 12 ********* test accuracy for all:0.252932 test loss: 255.059
111000: ********* epoch 12 ********* test accuracy for mode 0:0.0115 test loss: 424.558
111000: ********* epoch 12 ********* test accuracy for mode 1:0.04 test loss: 414.493
111000: ********* epoch 12 ********* test accuracy for mode 2:0.0585 test loss: 263.064
111000: ********* epoch 12 ********* test accuracy for mode 24:0.204 test loss: 278.355
111000: ********* epoch 12 ********* test accuracy for mode 25:0.286 test loss: 242.63
111000: ********* epoch 12 ********* test accuracy for mode 26:0.474 test loss: 160.956
111000: ********* epoch 12 ********* test accuracy for mode 27:0.2525 test loss: 265.176
111000: ********* epoch 12 ********* test accuracy for mode 28:0.2715 test loss: 254.783
111000: ********* epoch 12 ********* test accuracy for mode 29:0.2875 test loss: 257.633
111000: ********* epoch 12 ********* test accuracy for mode 30:0.219 test loss: 248.686
111000: ********* epoch 12 ********* test accuracy for mode 31:0.1805 test loss: 252.829
111000: ********* epoch 12 ********* test accuracy for mode 32:0.2655 test loss: 233.493
111000: ********* epoch 12 ********* test accuracy for mode 33:0.2735 test loss: 239.968
111000: ********* epoch 12 ********* test accuracy for mode 34:0.1835 test loss: 247.46
111000: ********* epoch 12 ********* test accuracy for mode 35:0.018 test loss: 435.864
111000: ********* epoch 12 ********* test accuracy for mode 36:0.091 test loss: 463.076
111010: accuracy:0.27 loss: 234.992 (lr:0.0001)
111020: accuracy:0.29 loss: 224.172 (lr:0.0001)
111030: accuracy:0.34 loss: 212.912 (lr:0.0001)
111040: accuracy:0.34 loss: 216.347 (lr:0.0001)
111050: accuracy:0.3 loss: 207.062 (lr:0.0001)
111060: accuracy:0.25 loss: 222.497 (lr:0.0001)
111070: accuracy:0.39 loss: 201.028 (lr:0.0001)
111080: accuracy:0.36 loss: 202.823 (lr:0.0001)
111090: accuracy:0.32 loss: 216.974 (lr:0.0001)
111100: accuracy:0.33 loss: 198.604 (lr:0.0001)
111110: accuracy:0.38 loss: 214.045 (lr:0.0001)
111120: accuracy:0.33 loss: 192.961 (lr:0.0001)
111130: accuracy:0.34 loss: 199.918 (lr:0.0001)
111140: accuracy:0.35 loss: 215.325 (lr:0.0001)
111150: accuracy:0.41 loss: 197.286 (lr:0.0001)
111160: accuracy:0.25 loss: 219.577 (lr:0.0001)
111170: accuracy:0.33 loss: 216.299 (lr:0.0001)
111180: accuracy:0.28 loss: 227.516 (lr:0.0001)
111190: accuracy:0.45 loss: 203.24 (lr:0.0001)
111200: accuracy:0.29 loss: 231.417 (lr:0.0001)
111210: accuracy:0.26 loss: 223.094 (lr:0.0001)
111220: accuracy:0.3 loss: 220.3 (lr:0.0001)
111230: accuracy:0.33 loss: 219.112 (lr:0.0001)
111240: accuracy:0.3 loss: 221.745 (lr:0.0001)
111250: accuracy:0.32 loss: 217.581 (lr:0.0001)
111260: accuracy:0.28 loss: 221.12 (lr:0.0001)
111270: accuracy:0.25 loss: 234.913 (lr:0.0001)
111280: accuracy:0.39 loss: 184.793 (lr:0.0001)
111290: accuracy:0.37 loss: 199.478 (lr:0.0001)
111300: accuracy:0.4 loss: 203.187 (lr:0.0001)
111310: accuracy:0.38 loss: 205.718 (lr:0.0001)
111320: accuracy:0.3 loss: 215.15 (lr:0.0001)
111330: accuracy:0.34 loss: 208.495 (lr:0.0001)
111340: accuracy:0.25 loss: 233.423 (lr:0.0001)
111350: accuracy:0.34 loss: 207.387 (lr:0.0001)
111360: accuracy:0.35 loss: 212.945 (lr:0.0001)
111370: accuracy:0.32 loss: 222.307 (lr:0.0001)
111380: accuracy:0.29 loss: 219.462 (lr:0.0001)
111390: accuracy:0.34 loss: 209.076 (lr:0.0001)
111400: accuracy:0.27 loss: 216.583 (lr:0.0001)
111410: accuracy:0.33 loss: 217.088 (lr:0.0001)
111420: accuracy:0.29 loss: 224.1 (lr:0.0001)
111430: accuracy:0.29 loss: 219.62 (lr:0.0001)
111440: accuracy:0.3 loss: 211.378 (lr:0.0001)
111450: accuracy:0.4 loss: 202.137 (lr:0.0001)
111460: accuracy:0.33 loss: 226.465 (lr:0.0001)
111470: accuracy:0.25 loss: 234.896 (lr:0.0001)
111480: accuracy:0.34 loss: 197.226 (lr:0.0001)
111490: accuracy:0.28 loss: 212.407 (lr:0.0001)
111500: accuracy:0.35 loss: 227.834 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
111500: ********* epoch 12 ********* test accuracy for all:0.248311 test loss: 257.565
111500: ********* epoch 12 ********* test accuracy for mode 0:0.01 test loss: 421.004
111500: ********* epoch 12 ********* test accuracy for mode 1:0.039 test loss: 412.462
111500: ********* epoch 12 ********* test accuracy for mode 2:0.072 test loss: 260.793
111500: ********* epoch 12 ********* test accuracy for mode 24:0.2695 test loss: 261.296
111500: ********* epoch 12 ********* test accuracy for mode 25:0.2455 test loss: 251.352
111500: ********* epoch 12 ********* test accuracy for mode 26:0.4595 test loss: 168.364
111500: ********* epoch 12 ********* test accuracy for mode 27:0.239 test loss: 275.762
111500: ********* epoch 12 ********* test accuracy for mode 28:0.277 test loss: 262.192
111500: ********* epoch 12 ********* test accuracy for mode 29:0.2585 test loss: 269.055
111500: ********* epoch 12 ********* test accuracy for mode 30:0.22 test loss: 257.202
111500: ********* epoch 12 ********* test accuracy for mode 31:0.207 test loss: 257.8
111500: ********* epoch 12 ********* test accuracy for mode 32:0.2155 test loss: 239.508
111500: ********* epoch 12 ********* test accuracy for mode 33:0.313 test loss: 240.422
111500: ********* epoch 12 ********* test accuracy for mode 34:0.1335 test loss: 251.249
111500: ********* epoch 12 ********* test accuracy for mode 35:0.023 test loss: 440.305
111500: ********* epoch 12 ********* test accuracy for mode 36:0.077 test loss: 471.014
111510: accuracy:0.29 loss: 217.141 (lr:0.0001)
111520: accuracy:0.34 loss: 217.532 (lr:0.0001)
111530: accuracy:0.31 loss: 224.054 (lr:0.0001)
111540: accuracy:0.37 loss: 197.225 (lr:0.0001)
111550: accuracy:0.34 loss: 209.858 (lr:0.0001)
111560: accuracy:0.33 loss: 224.399 (lr:0.0001)
111570: accuracy:0.34 loss: 205.206 (lr:0.0001)
111580: accuracy:0.45 loss: 210.56 (lr:0.0001)
111590: accuracy:0.33 loss: 207.489 (lr:0.0001)
111600: accuracy:0.3 loss: 221.929 (lr:0.0001)
111610: accuracy:0.32 loss: 229.444 (lr:0.0001)
111620: accuracy:0.38 loss: 207.121 (lr:0.0001)
111630: accuracy:0.27 loss: 229.659 (lr:0.0001)
111640: accuracy:0.28 loss: 215.581 (lr:0.0001)
111650: accuracy:0.3 loss: 225.911 (lr:0.0001)
111660: accuracy:0.37 loss: 217.077 (lr:0.0001)
111670: accuracy:0.34 loss: 192.963 (lr:0.0001)
111680: accuracy:0.34 loss: 232.568 (lr:0.0001)
111690: accuracy:0.33 loss: 216.189 (lr:0.0001)
111700: accuracy:0.33 loss: 212.851 (lr:0.0001)
111710: accuracy:0.29 loss: 224.243 (lr:0.0001)
111720: accuracy:0.29 loss: 212.074 (lr:0.0001)
111730: accuracy:0.33 loss: 229.725 (lr:0.0001)
111740: accuracy:0.33 loss: 208.027 (lr:0.0001)
111750: accuracy:0.3 loss: 210.352 (lr:0.0001)
111760: accuracy:0.37 loss: 197.522 (lr:0.0001)
111770: accuracy:0.37 loss: 203.574 (lr:0.0001)
111780: accuracy:0.31 loss: 224.467 (lr:0.0001)
111790: accuracy:0.36 loss: 193.789 (lr:0.0001)
111800: accuracy:0.2 loss: 213.935 (lr:0.0001)
111810: accuracy:0.44 loss: 191.82 (lr:0.0001)
111820: accuracy:0.41 loss: 201.186 (lr:0.0001)
111830: accuracy:0.25 loss: 238.216 (lr:0.0001)
111840: accuracy:0.35 loss: 210.335 (lr:0.0001)
111850: accuracy:0.33 loss: 209.862 (lr:0.0001)
111860: accuracy:0.28 loss: 232.339 (lr:0.0001)
111870: accuracy:0.3 loss: 205.414 (lr:0.0001)
111880: accuracy:0.3 loss: 222.673 (lr:0.0001)
111890: accuracy:0.36 loss: 229.113 (lr:0.0001)
111900: accuracy:0.32 loss: 189.368 (lr:0.0001)
111910: accuracy:0.34 loss: 196.509 (lr:0.0001)
111920: accuracy:0.33 loss: 223.776 (lr:0.0001)
111930: accuracy:0.39 loss: 205.217 (lr:0.0001)
111940: accuracy:0.34 loss: 206.991 (lr:0.0001)
111950: accuracy:0.29 loss: 238.876 (lr:0.0001)
111960: accuracy:0.29 loss: 224.442 (lr:0.0001)
111970: accuracy:0.37 loss: 201.146 (lr:0.0001)
111980: accuracy:0.26 loss: 248.423 (lr:0.0001)
111990: accuracy:0.32 loss: 193.594 (lr:0.0001)
112000: accuracy:0.31 loss: 223.316 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
112000: ********* epoch 12 ********* test accuracy for all:0.253959 test loss: 253.962
112000: ********* epoch 12 ********* test accuracy for mode 0:0.0115 test loss: 426.049
112000: ********* epoch 12 ********* test accuracy for mode 1:0.042 test loss: 418.107
112000: ********* epoch 12 ********* test accuracy for mode 2:0.044 test loss: 272.482
112000: ********* epoch 12 ********* test accuracy for mode 24:0.2215 test loss: 267.561
112000: ********* epoch 12 ********* test accuracy for mode 25:0.263 test loss: 246.241
112000: ********* epoch 12 ********* test accuracy for mode 26:0.421 test loss: 168.308
112000: ********* epoch 12 ********* test accuracy for mode 27:0.2725 test loss: 262.206
112000: ********* epoch 12 ********* test accuracy for mode 28:0.3195 test loss: 249.374
112000: ********* epoch 12 ********* test accuracy for mode 29:0.2585 test loss: 263.002
112000: ********* epoch 12 ********* test accuracy for mode 30:0.256 test loss: 249.737
112000: ********* epoch 12 ********* test accuracy for mode 31:0.1875 test loss: 255.977
112000: ********* epoch 12 ********* test accuracy for mode 32:0.233 test loss: 240.185
112000: ********* epoch 12 ********* test accuracy for mode 33:0.279 test loss: 244.947
112000: ********* epoch 12 ********* test accuracy for mode 34:0.171 test loss: 251.455
112000: ********* epoch 12 ********* test accuracy for mode 35:0.04 test loss: 434.324
112000: ********* epoch 12 ********* test accuracy for mode 36:0.076 test loss: 454.758
112010: accuracy:0.35 loss: 208.919 (lr:0.0001)
112020: accuracy:0.3 loss: 200.659 (lr:0.0001)
112030: accuracy:0.36 loss: 214.44 (lr:0.0001)
112040: accuracy:0.3 loss: 227.997 (lr:0.0001)
112050: accuracy:0.32 loss: 209.526 (lr:0.0001)
112060: accuracy:0.43 loss: 198.999 (lr:0.0001)
112070: accuracy:0.35 loss: 215.965 (lr:0.0001)
112080: accuracy:0.24 loss: 229.225 (lr:0.0001)
112090: accuracy:0.31 loss: 214.514 (lr:0.0001)
112100: accuracy:0.35 loss: 224.714 (lr:0.0001)
112110: accuracy:0.29 loss: 226.239 (lr:0.0001)
112120: accuracy:0.34 loss: 218.522 (lr:0.0001)
112130: accuracy:0.31 loss: 220.392 (lr:0.0001)
112140: accuracy:0.39 loss: 204.481 (lr:0.0001)
112150: accuracy:0.4 loss: 204.411 (lr:0.0001)
112160: accuracy:0.43 loss: 202.638 (lr:0.0001)
112170: accuracy:0.34 loss: 205.406 (lr:0.0001)
112180: accuracy:0.31 loss: 244.589 (lr:0.0001)
112190: accuracy:0.38 loss: 216.285 (lr:0.0001)
112200: accuracy:0.32 loss: 206.855 (lr:0.0001)
112210: accuracy:0.31 loss: 207.25 (lr:0.0001)
112220: accuracy:0.31 loss: 222.233 (lr:0.0001)
112230: accuracy:0.29 loss: 217.909 (lr:0.0001)
112240: accuracy:0.27 loss: 221.039 (lr:0.0001)
112250: accuracy:0.3 loss: 215.7 (lr:0.0001)
112260: accuracy:0.38 loss: 202.675 (lr:0.0001)
112270: accuracy:0.23 loss: 221.013 (lr:0.0001)
112280: accuracy:0.3 loss: 205.817 (lr:0.0001)
112290: accuracy:0.31 loss: 205.632 (lr:0.0001)
112300: accuracy:0.35 loss: 203.247 (lr:0.0001)
112310: accuracy:0.35 loss: 232.929 (lr:0.0001)
112320: accuracy:0.35 loss: 195.088 (lr:0.0001)
112330: accuracy:0.34 loss: 213.497 (lr:0.0001)
112340: accuracy:0.34 loss: 209.785 (lr:0.0001)
112350: accuracy:0.26 loss: 211.903 (lr:0.0001)
112360: accuracy:0.31 loss: 223.478 (lr:0.0001)
112370: accuracy:0.33 loss: 223.411 (lr:0.0001)
112380: accuracy:0.35 loss: 214.435 (lr:0.0001)
112390: accuracy:0.2 loss: 235.477 (lr:0.0001)
112400: accuracy:0.26 loss: 238.921 (lr:0.0001)
112410: accuracy:0.36 loss: 194.783 (lr:0.0001)
112420: accuracy:0.31 loss: 234.429 (lr:0.0001)
112430: accuracy:0.27 loss: 222.742 (lr:0.0001)
112440: accuracy:0.34 loss: 219.912 (lr:0.0001)
112450: accuracy:0.37 loss: 223.054 (lr:0.0001)
112460: accuracy:0.25 loss: 212.631 (lr:0.0001)
112470: accuracy:0.37 loss: 222.865 (lr:0.0001)
112480: accuracy:0.35 loss: 197.041 (lr:0.0001)
112490: accuracy:0.33 loss: 219.749 (lr:0.0001)
112500: accuracy:0.38 loss: 225.939 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
112500: ********* epoch 12 ********* test accuracy for all:0.251581 test loss: 254.448
112500: ********* epoch 12 ********* test accuracy for mode 0:0.013 test loss: 427.633
112500: ********* epoch 12 ********* test accuracy for mode 1:0.0365 test loss: 418.007
112500: ********* epoch 12 ********* test accuracy for mode 2:0.031 test loss: 266.22
112500: ********* epoch 12 ********* test accuracy for mode 24:0.2455 test loss: 271.693
112500: ********* epoch 12 ********* test accuracy for mode 25:0.316 test loss: 241.994
112500: ********* epoch 12 ********* test accuracy for mode 26:0.3945 test loss: 167.59
112500: ********* epoch 12 ********* test accuracy for mode 27:0.293 test loss: 258.975
112500: ********* epoch 12 ********* test accuracy for mode 28:0.2635 test loss: 262.033
112500: ********* epoch 12 ********* test accuracy for mode 29:0.248 test loss: 270.459
112500: ********* epoch 12 ********* test accuracy for mode 30:0.2055 test loss: 256.774
112500: ********* epoch 12 ********* test accuracy for mode 31:0.232 test loss: 252.78
112500: ********* epoch 12 ********* test accuracy for mode 32:0.1985 test loss: 241.325
112500: ********* epoch 12 ********* test accuracy for mode 33:0.264 test loss: 245.604
112500: ********* epoch 12 ********* test accuracy for mode 34:0.1665 test loss: 248.297
112500: ********* epoch 12 ********* test accuracy for mode 35:0.062 test loss: 430.029
112500: ********* epoch 12 ********* test accuracy for mode 36:0.059 test loss: 445.346
112510: accuracy:0.3 loss: 218.006 (lr:0.0001)
112520: accuracy:0.29 loss: 216.028 (lr:0.0001)
112530: accuracy:0.31 loss: 215.405 (lr:0.0001)
112540: accuracy:0.34 loss: 213.696 (lr:0.0001)
112550: accuracy:0.35 loss: 213.918 (lr:0.0001)
112560: accuracy:0.35 loss: 207.189 (lr:0.0001)
112570: accuracy:0.4 loss: 205.132 (lr:0.0001)
112580: accuracy:0.32 loss: 215.18 (lr:0.0001)
112590: accuracy:0.39 loss: 207.641 (lr:0.0001)
112600: accuracy:0.36 loss: 199.707 (lr:0.0001)
112610: accuracy:0.28 loss: 230.087 (lr:0.0001)
112620: accuracy:0.34 loss: 214.873 (lr:0.0001)
112630: accuracy:0.34 loss: 218.713 (lr:0.0001)
112640: accuracy:0.31 loss: 209.118 (lr:0.0001)
112650: accuracy:0.27 loss: 228.896 (lr:0.0001)
112660: accuracy:0.24 loss: 221.568 (lr:0.0001)
112670: accuracy:0.32 loss: 219.931 (lr:0.0001)
112680: accuracy:0.33 loss: 229.284 (lr:0.0001)
112690: accuracy:0.33 loss: 219.498 (lr:0.0001)
112700: accuracy:0.39 loss: 210.697 (lr:0.0001)
112710: accuracy:0.38 loss: 205.878 (lr:0.0001)
112720: accuracy:0.42 loss: 202.278 (lr:0.0001)
112730: accuracy:0.28 loss: 209.984 (lr:0.0001)
112740: accuracy:0.28 loss: 219.871 (lr:0.0001)
112750: accuracy:0.34 loss: 239.894 (lr:0.0001)
112760: accuracy:0.34 loss: 216.663 (lr:0.0001)
112770: accuracy:0.32 loss: 218.872 (lr:0.0001)
112780: accuracy:0.36 loss: 211.909 (lr:0.0001)
112790: accuracy:0.3 loss: 206.996 (lr:0.0001)
112800: accuracy:0.27 loss: 235.012 (lr:0.0001)
112810: accuracy:0.33 loss: 208.278 (lr:0.0001)
112820: accuracy:0.32 loss: 200.701 (lr:0.0001)
112830: accuracy:0.33 loss: 210.267 (lr:0.0001)
112840: accuracy:0.37 loss: 229.199 (lr:0.0001)
112850: accuracy:0.39 loss: 194.556 (lr:0.0001)
112860: accuracy:0.31 loss: 211.544 (lr:0.0001)
112870: accuracy:0.31 loss: 220.264 (lr:0.0001)
112880: accuracy:0.38 loss: 186.815 (lr:0.0001)
112890: accuracy:0.35 loss: 210.376 (lr:0.0001)
112900: accuracy:0.35 loss: 205.085 (lr:0.0001)
112910: accuracy:0.39 loss: 226.179 (lr:0.0001)
112920: accuracy:0.3 loss: 214.783 (lr:0.0001)
112930: accuracy:0.36 loss: 211.156 (lr:0.0001)
112940: accuracy:0.37 loss: 209.258 (lr:0.0001)
112950: accuracy:0.37 loss: 212.248 (lr:0.0001)
112960: accuracy:0.37 loss: 224.054 (lr:0.0001)
112970: accuracy:0.33 loss: 209.022 (lr:0.0001)
112980: accuracy:0.39 loss: 208.11 (lr:0.0001)
112990: accuracy:0.26 loss: 222.805 (lr:0.0001)
113000: accuracy:0.35 loss: 225.904 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
113000: ********* epoch 12 ********* test accuracy for all:0.253838 test loss: 253.44
113000: ********* epoch 12 ********* test accuracy for mode 0:0.0135 test loss: 423.647
113000: ********* epoch 12 ********* test accuracy for mode 1:0.046 test loss: 411.849
113000: ********* epoch 12 ********* test accuracy for mode 2:0.032 test loss: 271.195
113000: ********* epoch 12 ********* test accuracy for mode 24:0.259 test loss: 260.945
113000: ********* epoch 12 ********* test accuracy for mode 25:0.3025 test loss: 244.869
113000: ********* epoch 12 ********* test accuracy for mode 26:0.3995 test loss: 171.963
113000: ********* epoch 12 ********* test accuracy for mode 27:0.2345 test loss: 271.452
113000: ********* epoch 12 ********* test accuracy for mode 28:0.303 test loss: 255.335
113000: ********* epoch 12 ********* test accuracy for mode 29:0.2445 test loss: 264.102
113000: ********* epoch 12 ********* test accuracy for mode 30:0.274 test loss: 248.048
113000: ********* epoch 12 ********* test accuracy for mode 31:0.184 test loss: 255.868
113000: ********* epoch 12 ********* test accuracy for mode 32:0.214 test loss: 242.983
113000: ********* epoch 12 ********* test accuracy for mode 33:0.25 test loss: 249.896
113000: ********* epoch 12 ********* test accuracy for mode 34:0.174 test loss: 251.22
113000: ********* epoch 12 ********* test accuracy for mode 35:0.053 test loss: 426.376
113000: ********* epoch 12 ********* test accuracy for mode 36:0.0775 test loss: 456.93
113010: accuracy:0.35 loss: 194.214 (lr:0.0001)
113020: accuracy:0.25 loss: 208.953 (lr:0.0001)
113030: accuracy:0.43 loss: 193.795 (lr:0.0001)
113040: accuracy:0.33 loss: 221.195 (lr:0.0001)
113050: accuracy:0.32 loss: 228.051 (lr:0.0001)
113060: accuracy:0.19 loss: 234.936 (lr:0.0001)
113070: accuracy:0.33 loss: 229.018 (lr:0.0001)
113080: accuracy:0.35 loss: 205.44 (lr:0.0001)
113090: accuracy:0.33 loss: 200.1 (lr:0.0001)
113100: accuracy:0.33 loss: 207.875 (lr:0.0001)
113110: accuracy:0.29 loss: 222.659 (lr:0.0001)
113120: accuracy:0.3 loss: 228.916 (lr:0.0001)
113130: accuracy:0.42 loss: 199.202 (lr:0.0001)
113140: accuracy:0.34 loss: 201.541 (lr:0.0001)
113150: accuracy:0.26 loss: 231.989 (lr:0.0001)
113160: accuracy:0.31 loss: 191.034 (lr:0.0001)
113170: accuracy:0.39 loss: 201.12 (lr:0.0001)
113180: accuracy:0.29 loss: 214.769 (lr:0.0001)
113190: accuracy:0.34 loss: 208.489 (lr:0.0001)
113200: accuracy:0.31 loss: 215.452 (lr:0.0001)
113210: accuracy:0.32 loss: 212.85 (lr:0.0001)
113220: accuracy:0.35 loss: 203.994 (lr:0.0001)
113230: accuracy:0.25 loss: 202.064 (lr:0.0001)
113240: accuracy:0.38 loss: 197.156 (lr:0.0001)
113250: accuracy:0.34 loss: 221.055 (lr:0.0001)
113260: accuracy:0.36 loss: 204.441 (lr:0.0001)
113270: accuracy:0.25 loss: 216.51 (lr:0.0001)
113280: accuracy:0.28 loss: 211.178 (lr:0.0001)
113290: accuracy:0.34 loss: 206.482 (lr:0.0001)
113300: accuracy:0.41 loss: 185.884 (lr:0.0001)
113310: accuracy:0.41 loss: 215.927 (lr:0.0001)
113320: accuracy:0.36 loss: 205.449 (lr:0.0001)
113330: accuracy:0.35 loss: 201.778 (lr:0.0001)
113340: accuracy:0.3 loss: 237.177 (lr:0.0001)
113350: accuracy:0.38 loss: 219.141 (lr:0.0001)
113360: accuracy:0.47 loss: 188.229 (lr:0.0001)
113370: accuracy:0.3 loss: 211.532 (lr:0.0001)
113380: accuracy:0.34 loss: 213.374 (lr:0.0001)
113390: accuracy:0.28 loss: 218.045 (lr:0.0001)
113400: accuracy:0.35 loss: 215.467 (lr:0.0001)
113410: accuracy:0.3 loss: 236.871 (lr:0.0001)
113420: accuracy:0.41 loss: 202.744 (lr:0.0001)
113430: accuracy:0.32 loss: 202.904 (lr:0.0001)
113440: accuracy:0.31 loss: 219.485 (lr:0.0001)
113450: accuracy:0.35 loss: 223.769 (lr:0.0001)
113460: accuracy:0.29 loss: 246.134 (lr:0.0001)
113470: accuracy:0.3 loss: 228.458 (lr:0.0001)
113480: accuracy:0.36 loss: 210.523 (lr:0.0001)
113490: accuracy:0.27 loss: 223.937 (lr:0.0001)
113500: accuracy:0.41 loss: 192.336 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
113500: ********* epoch 12 ********* test accuracy for all:0.254297 test loss: 253.766
113500: ********* epoch 12 ********* test accuracy for mode 0:0.015 test loss: 422.114
113500: ********* epoch 12 ********* test accuracy for mode 1:0.051 test loss: 409.555
113500: ********* epoch 12 ********* test accuracy for mode 2:0.0405 test loss: 269.268
113500: ********* epoch 12 ********* test accuracy for mode 24:0.21 test loss: 275.517
113500: ********* epoch 12 ********* test accuracy for mode 25:0.316 test loss: 238.206
113500: ********* epoch 12 ********* test accuracy for mode 26:0.437 test loss: 163.826
113500: ********* epoch 12 ********* test accuracy for mode 27:0.2625 test loss: 259.762
113500: ********* epoch 12 ********* test accuracy for mode 28:0.301 test loss: 251.199
113500: ********* epoch 12 ********* test accuracy for mode 29:0.2615 test loss: 260.659
113500: ********* epoch 12 ********* test accuracy for mode 30:0.252 test loss: 248.597
113500: ********* epoch 12 ********* test accuracy for mode 31:0.2 test loss: 252.85
113500: ********* epoch 12 ********* test accuracy for mode 32:0.257 test loss: 239.221
113500: ********* epoch 12 ********* test accuracy for mode 33:0.208 test loss: 251.884
113500: ********* epoch 12 ********* test accuracy for mode 34:0.177 test loss: 250.112
113500: ********* epoch 12 ********* test accuracy for mode 35:0.046 test loss: 408.391
113500: ********* epoch 12 ********* test accuracy for mode 36:0.081 test loss: 453.075
113510: accuracy:0.34 loss: 197.329 (lr:0.0001)
113520: accuracy:0.32 loss: 215.022 (lr:0.0001)
113530: accuracy:0.38 loss: 228.368 (lr:0.0001)
113540: accuracy:0.31 loss: 217.953 (lr:0.0001)
113550: accuracy:0.34 loss: 209.632 (lr:0.0001)
113560: accuracy:0.38 loss: 208.866 (lr:0.0001)
113570: accuracy:0.33 loss: 221.99 (lr:0.0001)
113580: accuracy:0.34 loss: 217.222 (lr:0.0001)
113590: accuracy:0.27 loss: 226.935 (lr:0.0001)
113600: accuracy:0.42 loss: 213.074 (lr:0.0001)
113610: accuracy:0.33 loss: 202.416 (lr:0.0001)
113620: accuracy:0.33 loss: 222.798 (lr:0.0001)
113630: accuracy:0.24 loss: 210.987 (lr:0.0001)
113640: accuracy:0.37 loss: 202.374 (lr:0.0001)
113650: accuracy:0.25 loss: 223.09 (lr:0.0001)
113660: accuracy:0.33 loss: 208.063 (lr:0.0001)
113670: accuracy:0.32 loss: 210.155 (lr:0.0001)
113680: accuracy:0.38 loss: 199.205 (lr:0.0001)
113690: accuracy:0.34 loss: 218.851 (lr:0.0001)
113700: accuracy:0.27 loss: 230.14 (lr:0.0001)
113710: accuracy:0.28 loss: 219.564 (lr:0.0001)
113720: accuracy:0.42 loss: 202.726 (lr:0.0001)
113730: accuracy:0.36 loss: 212.332 (lr:0.0001)
113740: accuracy:0.32 loss: 201.795 (lr:0.0001)
113750: accuracy:0.37 loss: 205.553 (lr:0.0001)
113760: accuracy:0.29 loss: 245.973 (lr:0.0001)
113770: accuracy:0.31 loss: 225.437 (lr:0.0001)
113780: accuracy:0.37 loss: 208.987 (lr:0.0001)
113790: accuracy:0.37 loss: 194.278 (lr:0.0001)
113800: accuracy:0.29 loss: 217.853 (lr:0.0001)
113810: accuracy:0.22 loss: 216.916 (lr:0.0001)
113820: accuracy:0.4 loss: 209.605 (lr:0.0001)
113830: accuracy:0.37 loss: 211.769 (lr:0.0001)
113840: accuracy:0.37 loss: 220.173 (lr:0.0001)
113850: accuracy:0.31 loss: 221.565 (lr:0.0001)
113860: accuracy:0.31 loss: 220.7 (lr:0.0001)
113870: accuracy:0.35 loss: 199.278 (lr:0.0001)
113880: accuracy:0.33 loss: 196.775 (lr:0.0001)
113890: accuracy:0.35 loss: 215.628 (lr:0.0001)
113900: accuracy:0.27 loss: 225.86 (lr:0.0001)
113910: accuracy:0.33 loss: 220.071 (lr:0.0001)
113920: accuracy:0.31 loss: 220.04 (lr:0.0001)
113930: accuracy:0.26 loss: 233.706 (lr:0.0001)
113940: accuracy:0.42 loss: 192.068 (lr:0.0001)
113950: accuracy:0.26 loss: 240.2 (lr:0.0001)
113960: accuracy:0.36 loss: 199.27 (lr:0.0001)
113970: accuracy:0.3 loss: 211.679 (lr:0.0001)
113980: accuracy:0.29 loss: 227.676 (lr:0.0001)
113990: accuracy:0.41 loss: 185.816 (lr:0.0001)
114000: accuracy:0.29 loss: 231.418 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
114000: ********* epoch 12 ********* test accuracy for all:0.254338 test loss: 253.468
114000: ********* epoch 12 ********* test accuracy for mode 0:0.0145 test loss: 420.848
114000: ********* epoch 12 ********* test accuracy for mode 1:0.046 test loss: 406.552
114000: ********* epoch 12 ********* test accuracy for mode 2:0.0245 test loss: 272.694
114000: ********* epoch 12 ********* test accuracy for mode 24:0.276 test loss: 258.434
114000: ********* epoch 12 ********* test accuracy for mode 25:0.3235 test loss: 235.147
114000: ********* epoch 12 ********* test accuracy for mode 26:0.425 test loss: 163.829
114000: ********* epoch 12 ********* test accuracy for mode 27:0.2775 test loss: 252.791
114000: ********* epoch 12 ********* test accuracy for mode 28:0.321 test loss: 244.254
114000: ********* epoch 12 ********* test accuracy for mode 29:0.2705 test loss: 258.464
114000: ********* epoch 12 ********* test accuracy for mode 30:0.2685 test loss: 244.528
114000: ********* epoch 12 ********* test accuracy for mode 31:0.1765 test loss: 256.099
114000: ********* epoch 12 ********* test accuracy for mode 32:0.22 test loss: 244.569
114000: ********* epoch 12 ********* test accuracy for mode 33:0.2065 test loss: 251.083
114000: ********* epoch 12 ********* test accuracy for mode 34:0.2255 test loss: 244.904
114000: ********* epoch 12 ********* test accuracy for mode 35:0.0185 test loss: 420.645
114000: ********* epoch 12 ********* test accuracy for mode 36:0.092 test loss: 439.295
114010: accuracy:0.37 loss: 215.653 (lr:0.0001)
114020: accuracy:0.37 loss: 216.516 (lr:0.0001)
114030: accuracy:0.36 loss: 213.023 (lr:0.0001)
114040: accuracy:0.23 loss: 248.618 (lr:0.0001)
114050: accuracy:0.37 loss: 208.869 (lr:0.0001)
114060: accuracy:0.24 loss: 239.057 (lr:0.0001)
114070: accuracy:0.32 loss: 210.512 (lr:0.0001)
114080: accuracy:0.27 loss: 244.371 (lr:0.0001)
114090: accuracy:0.35 loss: 209.593 (lr:0.0001)
114100: accuracy:0.25 loss: 238.387 (lr:0.0001)
114110: accuracy:0.36 loss: 204.499 (lr:0.0001)
114120: accuracy:0.45 loss: 187.909 (lr:0.0001)
114130: accuracy:0.33 loss: 216.21 (lr:0.0001)
114140: accuracy:0.41 loss: 203.737 (lr:0.0001)
114150: accuracy:0.36 loss: 208.01 (lr:0.0001)
114160: accuracy:0.36 loss: 199.034 (lr:0.0001)
114170: accuracy:0.32 loss: 218.532 (lr:0.0001)
114180: accuracy:0.33 loss: 218.756 (lr:0.0001)
114190: accuracy:0.34 loss: 213.948 (lr:0.0001)
114200: accuracy:0.27 loss: 224.586 (lr:0.0001)
114210: accuracy:0.29 loss: 229.477 (lr:0.0001)
114220: accuracy:0.29 loss: 210.315 (lr:0.0001)
114230: accuracy:0.37 loss: 213.368 (lr:0.0001)
114240: accuracy:0.35 loss: 199.913 (lr:0.0001)
114250: accuracy:0.33 loss: 216.043 (lr:0.0001)
114260: accuracy:0.33 loss: 211.866 (lr:0.0001)
114270: accuracy:0.27 loss: 219.251 (lr:0.0001)
114280: accuracy:0.33 loss: 205.168 (lr:0.0001)
114290: accuracy:0.29 loss: 206.034 (lr:0.0001)
114300: accuracy:0.37 loss: 200.684 (lr:0.0001)
114310: accuracy:0.28 loss: 225.038 (lr:0.0001)
114320: accuracy:0.33 loss: 207.526 (lr:0.0001)
114330: accuracy:0.3 loss: 199.925 (lr:0.0001)
114340: accuracy:0.39 loss: 209.55 (lr:0.0001)
114350: accuracy:0.39 loss: 223.151 (lr:0.0001)
114360: accuracy:0.3 loss: 214.154 (lr:0.0001)
114370: accuracy:0.31 loss: 216.682 (lr:0.0001)
114380: accuracy:0.35 loss: 198.432 (lr:0.0001)
114390: accuracy:0.37 loss: 206.364 (lr:0.0001)
114400: accuracy:0.35 loss: 210.068 (lr:0.0001)
114410: accuracy:0.29 loss: 199.614 (lr:0.0001)
114420: accuracy:0.33 loss: 213.234 (lr:0.0001)
114430: accuracy:0.37 loss: 222.268 (lr:0.0001)
114440: accuracy:0.32 loss: 207.337 (lr:0.0001)
114450: accuracy:0.33 loss: 210.75 (lr:0.0001)
114460: accuracy:0.29 loss: 218.227 (lr:0.0001)
114470: accuracy:0.33 loss: 218.051 (lr:0.0001)
114480: accuracy:0.36 loss: 199.229 (lr:0.0001)
114490: accuracy:0.34 loss: 219.579 (lr:0.0001)
114500: accuracy:0.31 loss: 224.022 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
114500: ********* epoch 12 ********* test accuracy for all:0.254851 test loss: 256.665
114500: ********* epoch 12 ********* test accuracy for mode 0:0.0145 test loss: 433.922
114500: ********* epoch 12 ********* test accuracy for mode 1:0.0365 test loss: 423.955
114500: ********* epoch 12 ********* test accuracy for mode 2:0.0255 test loss: 271.373
114500: ********* epoch 12 ********* test accuracy for mode 24:0.279 test loss: 266.519
114500: ********* epoch 12 ********* test accuracy for mode 25:0.3135 test loss: 243.364
114500: ********* epoch 12 ********* test accuracy for mode 26:0.3895 test loss: 172.499
114500: ********* epoch 12 ********* test accuracy for mode 27:0.267 test loss: 262.332
114500: ********* epoch 12 ********* test accuracy for mode 28:0.313 test loss: 253.238
114500: ********* epoch 12 ********* test accuracy for mode 29:0.288 test loss: 258.505
114500: ********* epoch 12 ********* test accuracy for mode 30:0.2215 test loss: 252.099
114500: ********* epoch 12 ********* test accuracy for mode 31:0.204 test loss: 252.757
114500: ********* epoch 12 ********* test accuracy for mode 32:0.2205 test loss: 240.889
114500: ********* epoch 12 ********* test accuracy for mode 33:0.2875 test loss: 244.348
114500: ********* epoch 12 ********* test accuracy for mode 34:0.156 test loss: 251.914
114500: ********* epoch 12 ********* test accuracy for mode 35:0.02 test loss: 451.022
114500: ********* epoch 12 ********* test accuracy for mode 36:0.12 test loss: 463.676
114510: accuracy:0.34 loss: 203.272 (lr:0.0001)
114520: accuracy:0.43 loss: 175.01 (lr:0.0001)
114530: accuracy:0.33 loss: 208.35 (lr:0.0001)
114540: accuracy:0.29 loss: 236.45 (lr:0.0001)
114550: accuracy:0.39 loss: 199.82 (lr:0.0001)
114560: accuracy:0.3 loss: 213.26 (lr:0.0001)
114570: accuracy:0.31 loss: 212.871 (lr:0.0001)
114580: accuracy:0.28 loss: 244.646 (lr:0.0001)
114590: accuracy:0.32 loss: 208.204 (lr:0.0001)
114600: accuracy:0.33 loss: 209.85 (lr:0.0001)
114610: accuracy:0.32 loss: 215.836 (lr:0.0001)
114620: accuracy:0.31 loss: 221.999 (lr:0.0001)
114630: accuracy:0.33 loss: 206.793 (lr:0.0001)
114640: accuracy:0.4 loss: 202.621 (lr:0.0001)
114650: accuracy:0.27 loss: 218.432 (lr:0.0001)
114660: accuracy:0.41 loss: 200.959 (lr:0.0001)
114670: accuracy:0.39 loss: 210.409 (lr:0.0001)
114680: accuracy:0.29 loss: 218.687 (lr:0.0001)
114690: accuracy:0.35 loss: 205.579 (lr:0.0001)
114700: accuracy:0.32 loss: 204.152 (lr:0.0001)
114710: accuracy:0.31 loss: 218.979 (lr:0.0001)
114720: accuracy:0.32 loss: 217.389 (lr:0.0001)
114730: accuracy:0.34 loss: 203.377 (lr:0.0001)
114740: accuracy:0.4 loss: 206.714 (lr:0.0001)
114750: accuracy:0.24 loss: 220.304 (lr:0.0001)
114760: accuracy:0.28 loss: 207.397 (lr:0.0001)
114770: accuracy:0.32 loss: 222.549 (lr:0.0001)
114780: accuracy:0.37 loss: 193.961 (lr:0.0001)
114790: accuracy:0.37 loss: 198.022 (lr:0.0001)
114800: accuracy:0.32 loss: 217.125 (lr:0.0001)
114810: accuracy:0.3 loss: 236.605 (lr:0.0001)
114820: accuracy:0.34 loss: 193.096 (lr:0.0001)
114830: accuracy:0.35 loss: 203.957 (lr:0.0001)
114840: accuracy:0.3 loss: 211.974 (lr:0.0001)
114850: accuracy:0.34 loss: 213.821 (lr:0.0001)
114860: accuracy:0.28 loss: 228.716 (lr:0.0001)
114870: accuracy:0.37 loss: 196.025 (lr:0.0001)
114880: accuracy:0.3 loss: 238.288 (lr:0.0001)
114890: accuracy:0.36 loss: 215.57 (lr:0.0001)
114900: accuracy:0.37 loss: 197.165 (lr:0.0001)
114910: accuracy:0.42 loss: 216.369 (lr:0.0001)
114920: accuracy:0.31 loss: 220.187 (lr:0.0001)
114930: accuracy:0.3 loss: 221.447 (lr:0.0001)
114940: accuracy:0.39 loss: 189.088 (lr:0.0001)
114950: accuracy:0.29 loss: 229.499 (lr:0.0001)
114960: accuracy:0.38 loss: 201.714 (lr:0.0001)
114970: accuracy:0.37 loss: 217.282 (lr:0.0001)
114980: accuracy:0.34 loss: 202.893 (lr:0.0001)
114990: accuracy:0.34 loss: 234.254 (lr:0.0001)
115000: accuracy:0.33 loss: 224.294 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
115000: ********* epoch 12 ********* test accuracy for all:0.251419 test loss: 257.367
115000: ********* epoch 12 ********* test accuracy for mode 0:0.014 test loss: 425.888
115000: ********* epoch 12 ********* test accuracy for mode 1:0.0375 test loss: 421.644
115000: ********* epoch 12 ********* test accuracy for mode 2:0.025 test loss: 261.535
115000: ********* epoch 12 ********* test accuracy for mode 24:0.2575 test loss: 276.965
115000: ********* epoch 12 ********* test accuracy for mode 25:0.2855 test loss: 255.761
115000: ********* epoch 12 ********* test accuracy for mode 26:0.4425 test loss: 169.584
115000: ********* epoch 12 ********* test accuracy for mode 27:0.262 test loss: 270.302
115000: ********* epoch 12 ********* test accuracy for mode 28:0.272 test loss: 264.012
115000: ********* epoch 12 ********* test accuracy for mode 29:0.252 test loss: 268.498
115000: ********* epoch 12 ********* test accuracy for mode 30:0.2125 test loss: 256.014
115000: ********* epoch 12 ********* test accuracy for mode 31:0.233 test loss: 248.848
115000: ********* epoch 12 ********* test accuracy for mode 32:0.185 test loss: 241.092
115000: ********* epoch 12 ********* test accuracy for mode 33:0.274 test loss: 241.791
115000: ********* epoch 12 ********* test accuracy for mode 34:0.191 test loss: 244.889
115000: ********* epoch 12 ********* test accuracy for mode 35:0.046 test loss: 442.086
115000: ********* epoch 12 ********* test accuracy for mode 36:0.091 test loss: 462.114
115010: accuracy:0.39 loss: 217.549 (lr:0.0001)
115020: accuracy:0.31 loss: 215.298 (lr:0.0001)
115030: accuracy:0.34 loss: 192.451 (lr:0.0001)
115040: accuracy:0.29 loss: 213.775 (lr:0.0001)
115050: accuracy:0.35 loss: 187.57 (lr:0.0001)
115060: accuracy:0.35 loss: 209.555 (lr:0.0001)
115070: accuracy:0.33 loss: 207.51 (lr:0.0001)
115080: accuracy:0.34 loss: 215.312 (lr:0.0001)
115090: accuracy:0.32 loss: 235.775 (lr:0.0001)
115100: accuracy:0.31 loss: 229.951 (lr:0.0001)
115110: accuracy:0.37 loss: 196.536 (lr:0.0001)
115120: accuracy:0.37 loss: 207.334 (lr:0.0001)
115130: accuracy:0.32 loss: 200.949 (lr:0.0001)
115140: accuracy:0.41 loss: 200.916 (lr:0.0001)
115150: accuracy:0.32 loss: 221.332 (lr:0.0001)
115160: accuracy:0.26 loss: 228.784 (lr:0.0001)
115170: accuracy:0.34 loss: 204.165 (lr:0.0001)
115180: accuracy:0.29 loss: 227.033 (lr:0.0001)
115190: accuracy:0.37 loss: 211.215 (lr:0.0001)
115200: accuracy:0.36 loss: 207.639 (lr:0.0001)
115210: accuracy:0.29 loss: 218.501 (lr:0.0001)
115220: accuracy:0.46 loss: 171.538 (lr:0.0001)
115230: accuracy:0.3 loss: 201.293 (lr:0.0001)
115240: accuracy:0.34 loss: 203.734 (lr:0.0001)
115250: accuracy:0.31 loss: 229.425 (lr:0.0001)
115260: accuracy:0.25 loss: 212.419 (lr:0.0001)
115270: accuracy:0.33 loss: 211.623 (lr:0.0001)
115280: accuracy:0.37 loss: 206.157 (lr:0.0001)
115290: accuracy:0.31 loss: 212.232 (lr:0.0001)
115300: accuracy:0.28 loss: 213.407 (lr:0.0001)
115310: accuracy:0.28 loss: 212.544 (lr:0.0001)
115320: accuracy:0.31 loss: 221.321 (lr:0.0001)
115330: accuracy:0.29 loss: 229.224 (lr:0.0001)
115340: accuracy:0.31 loss: 195.507 (lr:0.0001)
115350: accuracy:0.25 loss: 231.476 (lr:0.0001)
115360: accuracy:0.29 loss: 229.177 (lr:0.0001)
115370: accuracy:0.32 loss: 233.587 (lr:0.0001)
115380: accuracy:0.29 loss: 207.281 (lr:0.0001)
115390: accuracy:0.35 loss: 210.614 (lr:0.0001)
115400: accuracy:0.34 loss: 208.542 (lr:0.0001)
115410: accuracy:0.38 loss: 212.517 (lr:0.0001)
115420: accuracy:0.36 loss: 214.48 (lr:0.0001)
115430: accuracy:0.38 loss: 204.407 (lr:0.0001)
115440: accuracy:0.33 loss: 215.558 (lr:0.0001)
115450: accuracy:0.39 loss: 209.309 (lr:0.0001)
115460: accuracy:0.28 loss: 245.893 (lr:0.0001)
115470: accuracy:0.33 loss: 209.723 (lr:0.0001)
115480: accuracy:0.29 loss: 226.408 (lr:0.0001)
115490: accuracy:0.36 loss: 222.631 (lr:0.0001)
115500: accuracy:0.33 loss: 200.183 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
115500: ********* epoch 12 ********* test accuracy for all:0.254824 test loss: 252.638
115500: ********* epoch 12 ********* test accuracy for mode 0:0.0155 test loss: 422.291
115500: ********* epoch 12 ********* test accuracy for mode 1:0.04 test loss: 418.923
115500: ********* epoch 12 ********* test accuracy for mode 2:0.032 test loss: 267.522
115500: ********* epoch 12 ********* test accuracy for mode 24:0.247 test loss: 264.209
115500: ********* epoch 12 ********* test accuracy for mode 25:0.343 test loss: 236.414
115500: ********* epoch 12 ********* test accuracy for mode 26:0.431 test loss: 161.795
115500: ********* epoch 12 ********* test accuracy for mode 27:0.265 test loss: 255.359
115500: ********* epoch 12 ********* test accuracy for mode 28:0.302 test loss: 250.036
115500: ********* epoch 12 ********* test accuracy for mode 29:0.273 test loss: 253.211
115500: ********* epoch 12 ********* test accuracy for mode 30:0.234 test loss: 247.546
115500: ********* epoch 12 ********* test accuracy for mode 31:0.1845 test loss: 248.086
115500: ********* epoch 12 ********* test accuracy for mode 32:0.2165 test loss: 234.379
115500: ********* epoch 12 ********* test accuracy for mode 33:0.3165 test loss: 234.416
115500: ********* epoch 12 ********* test accuracy for mode 34:0.185 test loss: 241.836
115500: ********* epoch 12 ********* test accuracy for mode 35:0.043 test loss: 407.496
115500: ********* epoch 12 ********* test accuracy for mode 36:0.146 test loss: 416.988
115510: accuracy:0.35 loss: 198.786 (lr:0.0001)
115520: accuracy:0.31 loss: 209.918 (lr:0.0001)
115530: accuracy:0.41 loss: 193.677 (lr:0.0001)
115540: accuracy:0.34 loss: 202.837 (lr:0.0001)
115550: accuracy:0.37 loss: 198.872 (lr:0.0001)
115560: accuracy:0.35 loss: 197.696 (lr:0.0001)
115570: accuracy:0.3 loss: 195.797 (lr:0.0001)
115580: accuracy:0.29 loss: 225.568 (lr:0.0001)
115590: accuracy:0.22 loss: 219.274 (lr:0.0001)
115600: accuracy:0.33 loss: 201.463 (lr:0.0001)
115610: accuracy:0.36 loss: 215.118 (lr:0.0001)
115620: accuracy:0.28 loss: 222.068 (lr:0.0001)
115630: accuracy:0.33 loss: 221.225 (lr:0.0001)
115640: accuracy:0.36 loss: 218.813 (lr:0.0001)
115650: accuracy:0.37 loss: 204.3 (lr:0.0001)
115660: accuracy:0.35 loss: 203.824 (lr:0.0001)
115670: accuracy:0.37 loss: 207.14 (lr:0.0001)
115680: accuracy:0.43 loss: 196.716 (lr:0.0001)
115690: accuracy:0.27 loss: 229.216 (lr:0.0001)
115700: accuracy:0.43 loss: 194.886 (lr:0.0001)
115710: accuracy:0.35 loss: 201.336 (lr:0.0001)
115720: accuracy:0.3 loss: 227.131 (lr:0.0001)
115730: accuracy:0.27 loss: 212.729 (lr:0.0001)
115740: accuracy:0.41 loss: 218.439 (lr:0.0001)
115750: accuracy:0.32 loss: 224.037 (lr:0.0001)
115760: accuracy:0.4 loss: 193.354 (lr:0.0001)
115770: accuracy:0.33 loss: 230.688 (lr:0.0001)
115780: accuracy:0.35 loss: 206.395 (lr:0.0001)
115790: accuracy:0.31 loss: 209.338 (lr:0.0001)
115800: accuracy:0.28 loss: 210.665 (lr:0.0001)
115810: accuracy:0.26 loss: 219.578 (lr:0.0001)
115820: accuracy:0.27 loss: 225.983 (lr:0.0001)
115830: accuracy:0.35 loss: 218.393 (lr:0.0001)
115840: accuracy:0.35 loss: 205.038 (lr:0.0001)
115850: accuracy:0.33 loss: 207.446 (lr:0.0001)
115860: accuracy:0.32 loss: 204.142 (lr:0.0001)
115870: accuracy:0.34 loss: 215.705 (lr:0.0001)
115880: accuracy:0.46 loss: 195.869 (lr:0.0001)
115890: accuracy:0.26 loss: 232.857 (lr:0.0001)
115900: accuracy:0.34 loss: 214.167 (lr:0.0001)
115910: accuracy:0.37 loss: 184.672 (lr:0.0001)
115920: accuracy:0.25 loss: 233.576 (lr:0.0001)
115930: accuracy:0.35 loss: 217.821 (lr:0.0001)
115940: accuracy:0.42 loss: 215.284 (lr:0.0001)
115950: accuracy:0.26 loss: 217.471 (lr:0.0001)
115960: accuracy:0.29 loss: 203.276 (lr:0.0001)
115970: accuracy:0.28 loss: 211.598 (lr:0.0001)
115980: accuracy:0.34 loss: 192.104 (lr:0.0001)
115990: accuracy:0.27 loss: 228.549 (lr:0.0001)
116000: accuracy:0.34 loss: 212.135 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
116000: ********* epoch 12 ********* test accuracy for all:0.256324 test loss: 253.897
116000: ********* epoch 12 ********* test accuracy for mode 0:0.0155 test loss: 429.111
116000: ********* epoch 12 ********* test accuracy for mode 1:0.032 test loss: 425.742
116000: ********* epoch 12 ********* test accuracy for mode 2:0.0385 test loss: 266.941
116000: ********* epoch 12 ********* test accuracy for mode 24:0.2585 test loss: 268.893
116000: ********* epoch 12 ********* test accuracy for mode 25:0.2745 test loss: 250.87
116000: ********* epoch 12 ********* test accuracy for mode 26:0.507 test loss: 161.357
116000: ********* epoch 12 ********* test accuracy for mode 27:0.236 test loss: 267.715
116000: ********* epoch 12 ********* test accuracy for mode 28:0.2925 test loss: 257.847
116000: ********* epoch 12 ********* test accuracy for mode 29:0.258 test loss: 263.165
116000: ********* epoch 12 ********* test accuracy for mode 30:0.249 test loss: 248.003
116000: ********* epoch 12 ********* test accuracy for mode 31:0.242 test loss: 247.574
116000: ********* epoch 12 ********* test accuracy for mode 32:0.1785 test loss: 240.175
116000: ********* epoch 12 ********* test accuracy for mode 33:0.288 test loss: 241.036
116000: ********* epoch 12 ********* test accuracy for mode 34:0.181 test loss: 244.713
116000: ********* epoch 12 ********* test accuracy for mode 35:0.0285 test loss: 420.734
116000: ********* epoch 12 ********* test accuracy for mode 36:0.1 test loss: 440.424
116010: accuracy:0.36 loss: 216.816 (lr:0.0001)
116020: accuracy:0.33 loss: 217.01 (lr:0.0001)
116030: accuracy:0.39 loss: 203.427 (lr:0.0001)
116040: accuracy:0.34 loss: 198.16 (lr:0.0001)
116050: accuracy:0.36 loss: 225.003 (lr:0.0001)
116060: accuracy:0.31 loss: 216.357 (lr:0.0001)
116070: accuracy:0.31 loss: 231.569 (lr:0.0001)
116080: accuracy:0.28 loss: 239.974 (lr:0.0001)
116090: accuracy:0.47 loss: 194.981 (lr:0.0001)
116100: accuracy:0.38 loss: 212.606 (lr:0.0001)
116110: accuracy:0.34 loss: 215.514 (lr:0.0001)
116120: accuracy:0.32 loss: 212.948 (lr:0.0001)
116130: accuracy:0.29 loss: 210.331 (lr:0.0001)
116140: accuracy:0.29 loss: 215.822 (lr:0.0001)
116150: accuracy:0.28 loss: 215.102 (lr:0.0001)
116160: accuracy:0.37 loss: 201.875 (lr:0.0001)
116170: accuracy:0.33 loss: 215.748 (lr:0.0001)
116180: accuracy:0.38 loss: 210.22 (lr:0.0001)
116190: accuracy:0.31 loss: 206.852 (lr:0.0001)
116200: accuracy:0.29 loss: 248.102 (lr:0.0001)
116210: accuracy:0.37 loss: 209.388 (lr:0.0001)
116220: accuracy:0.34 loss: 209.795 (lr:0.0001)
116230: accuracy:0.37 loss: 189.093 (lr:0.0001)
116240: accuracy:0.36 loss: 208.359 (lr:0.0001)
116250: accuracy:0.36 loss: 222.292 (lr:0.0001)
116260: accuracy:0.31 loss: 205.284 (lr:0.0001)
116270: accuracy:0.33 loss: 219.562 (lr:0.0001)
116280: accuracy:0.43 loss: 218.21 (lr:0.0001)
116290: accuracy:0.29 loss: 225.099 (lr:0.0001)
116300: accuracy:0.34 loss: 206.469 (lr:0.0001)
116310: accuracy:0.23 loss: 230.821 (lr:0.0001)
116320: accuracy:0.34 loss: 204.264 (lr:0.0001)
116330: accuracy:0.34 loss: 221.32 (lr:0.0001)
116340: accuracy:0.41 loss: 188.738 (lr:0.0001)
116350: accuracy:0.34 loss: 210.333 (lr:0.0001)
116360: accuracy:0.38 loss: 206.407 (lr:0.0001)
116370: accuracy:0.42 loss: 202.418 (lr:0.0001)
116380: accuracy:0.32 loss: 220.115 (lr:0.0001)
116390: accuracy:0.24 loss: 232.361 (lr:0.0001)
116400: accuracy:0.31 loss: 196.291 (lr:0.0001)
116410: accuracy:0.39 loss: 204.311 (lr:0.0001)
116420: accuracy:0.39 loss: 198.836 (lr:0.0001)
116430: accuracy:0.35 loss: 219.858 (lr:0.0001)
116440: accuracy:0.27 loss: 237.964 (lr:0.0001)
116450: accuracy:0.34 loss: 205.339 (lr:0.0001)
116460: accuracy:0.36 loss: 210.514 (lr:0.0001)
116470: accuracy:0.33 loss: 211.67 (lr:0.0001)
116480: accuracy:0.34 loss: 210.956 (lr:0.0001)
116490: accuracy:0.32 loss: 204.48 (lr:0.0001)
116500: accuracy:0.34 loss: 210.614 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
116500: ********* epoch 12 ********* test accuracy for all:0.253581 test loss: 252.293
116500: ********* epoch 12 ********* test accuracy for mode 0:0.0155 test loss: 423.816
116500: ********* epoch 12 ********* test accuracy for mode 1:0.0415 test loss: 412.208
116500: ********* epoch 12 ********* test accuracy for mode 2:0.0355 test loss: 267.927
116500: ********* epoch 12 ********* test accuracy for mode 24:0.2885 test loss: 255.518
116500: ********* epoch 12 ********* test accuracy for mode 25:0.2715 test loss: 238.066
116500: ********* epoch 12 ********* test accuracy for mode 26:0.4455 test loss: 161.065
116500: ********* epoch 12 ********* test accuracy for mode 27:0.3035 test loss: 242.267
116500: ********* epoch 12 ********* test accuracy for mode 28:0.3025 test loss: 240.881
116500: ********* epoch 12 ********* test accuracy for mode 29:0.2985 test loss: 246.242
116500: ********* epoch 12 ********* test accuracy for mode 30:0.2385 test loss: 244.76
116500: ********* epoch 12 ********* test accuracy for mode 31:0.207 test loss: 250.68
116500: ********* epoch 12 ********* test accuracy for mode 32:0.222 test loss: 243.555
116500: ********* epoch 12 ********* test accuracy for mode 33:0.2285 test loss: 248.779
116500: ********* epoch 12 ********* test accuracy for mode 34:0.2045 test loss: 249.527
116500: ********* epoch 12 ********* test accuracy for mode 35:0.0515 test loss: 425.969
116500: ********* epoch 12 ********* test accuracy for mode 36:0.086 test loss: 453.134
116510: accuracy:0.28 loss: 222.442 (lr:0.0001)
116520: accuracy:0.4 loss: 205.13 (lr:0.0001)
116530: accuracy:0.24 loss: 233.877 (lr:0.0001)
116540: accuracy:0.38 loss: 194.437 (lr:0.0001)
116550: accuracy:0.37 loss: 219.722 (lr:0.0001)
116560: accuracy:0.36 loss: 225.176 (lr:0.0001)
116570: accuracy:0.29 loss: 218.016 (lr:0.0001)
116580: accuracy:0.26 loss: 228.044 (lr:0.0001)
116590: accuracy:0.31 loss: 214.45 (lr:0.0001)
116600: accuracy:0.32 loss: 198.708 (lr:0.0001)
116610: accuracy:0.4 loss: 190.621 (lr:0.0001)
116620: accuracy:0.38 loss: 203.256 (lr:0.0001)
116630: accuracy:0.28 loss: 209.852 (lr:0.0001)
116640: accuracy:0.24 loss: 227.214 (lr:0.0001)
116650: accuracy:0.37 loss: 215.658 (lr:0.0001)
116660: accuracy:0.29 loss: 205.357 (lr:0.0001)
116670: accuracy:0.32 loss: 221.405 (lr:0.0001)
116680: accuracy:0.32 loss: 226.103 (lr:0.0001)
116690: accuracy:0.32 loss: 205.6 (lr:0.0001)
116700: accuracy:0.34 loss: 218.389 (lr:0.0001)
116710: accuracy:0.41 loss: 195.662 (lr:0.0001)
116720: accuracy:0.36 loss: 210.64 (lr:0.0001)
116730: accuracy:0.36 loss: 215.936 (lr:0.0001)
116740: accuracy:0.35 loss: 198.48 (lr:0.0001)
116750: accuracy:0.4 loss: 202.106 (lr:0.0001)
116760: accuracy:0.42 loss: 179.412 (lr:0.0001)
116770: accuracy:0.37 loss: 193.372 (lr:0.0001)
116780: accuracy:0.36 loss: 192.464 (lr:0.0001)
116790: accuracy:0.28 loss: 227.29 (lr:0.0001)
116800: accuracy:0.31 loss: 201.696 (lr:0.0001)
116810: accuracy:0.3 loss: 212.601 (lr:0.0001)
116820: accuracy:0.42 loss: 199.752 (lr:0.0001)
116830: accuracy:0.35 loss: 199.776 (lr:0.0001)
116840: accuracy:0.37 loss: 206.412 (lr:0.0001)
116850: accuracy:0.26 loss: 240.948 (lr:0.0001)
116860: accuracy:0.4 loss: 201.978 (lr:0.0001)
116870: accuracy:0.33 loss: 207.515 (lr:0.0001)
116880: accuracy:0.35 loss: 203.29 (lr:0.0001)
116890: accuracy:0.35 loss: 206.62 (lr:0.0001)
116900: accuracy:0.35 loss: 208.946 (lr:0.0001)
116910: accuracy:0.32 loss: 214.468 (lr:0.0001)
116920: accuracy:0.36 loss: 217.662 (lr:0.0001)
116930: accuracy:0.32 loss: 213.964 (lr:0.0001)
116940: accuracy:0.29 loss: 216.806 (lr:0.0001)
116950: accuracy:0.43 loss: 199.368 (lr:0.0001)
116960: accuracy:0.3 loss: 222.002 (lr:0.0001)
116970: accuracy:0.38 loss: 192.668 (lr:0.0001)
116980: accuracy:0.35 loss: 216.222 (lr:0.0001)
116990: accuracy:0.25 loss: 246.46 (lr:0.0001)
117000: accuracy:0.38 loss: 216.074 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
117000: ********* epoch 13 ********* test accuracy for all:0.252635 test loss: 254.817
117000: ********* epoch 13 ********* test accuracy for mode 0:0.0205 test loss: 427.411
117000: ********* epoch 13 ********* test accuracy for mode 1:0.0385 test loss: 420.121
117000: ********* epoch 13 ********* test accuracy for mode 2:0.018 test loss: 263.608
117000: ********* epoch 13 ********* test accuracy for mode 24:0.2385 test loss: 273.7
117000: ********* epoch 13 ********* test accuracy for mode 25:0.2395 test loss: 257.435
117000: ********* epoch 13 ********* test accuracy for mode 26:0.401 test loss: 168.923
117000: ********* epoch 13 ********* test accuracy for mode 27:0.2525 test loss: 268.045
117000: ********* epoch 13 ********* test accuracy for mode 28:0.293 test loss: 252.451
117000: ********* epoch 13 ********* test accuracy for mode 29:0.278 test loss: 254.176
117000: ********* epoch 13 ********* test accuracy for mode 30:0.2665 test loss: 244.581
117000: ********* epoch 13 ********* test accuracy for mode 31:0.209 test loss: 246.528
117000: ********* epoch 13 ********* test accuracy for mode 32:0.208 test loss: 234.983
117000: ********* epoch 13 ********* test accuracy for mode 33:0.299 test loss: 234.089
117000: ********* epoch 13 ********* test accuracy for mode 34:0.2445 test loss: 237.648
117000: ********* epoch 13 ********* test accuracy for mode 35:0.0765 test loss: 418.654
117000: ********* epoch 13 ********* test accuracy for mode 36:0.123 test loss: 431.85
117010: accuracy:0.36 loss: 217.386 (lr:0.0001)
117020: accuracy:0.27 loss: 217.7 (lr:0.0001)
117030: accuracy:0.39 loss: 192.675 (lr:0.0001)
117040: accuracy:0.38 loss: 206.033 (lr:0.0001)
117050: accuracy:0.39 loss: 199.146 (lr:0.0001)
117060: accuracy:0.37 loss: 203.627 (lr:0.0001)
117070: accuracy:0.36 loss: 206.069 (lr:0.0001)
117080: accuracy:0.34 loss: 211.555 (lr:0.0001)
117090: accuracy:0.39 loss: 206.848 (lr:0.0001)
117100: accuracy:0.37 loss: 209.282 (lr:0.0001)
117110: accuracy:0.32 loss: 235.675 (lr:0.0001)
117120: accuracy:0.42 loss: 195.565 (lr:0.0001)
117130: accuracy:0.26 loss: 233.085 (lr:0.0001)
117140: accuracy:0.37 loss: 196.409 (lr:0.0001)
117150: accuracy:0.39 loss: 193.425 (lr:0.0001)
117160: accuracy:0.35 loss: 221.451 (lr:0.0001)
117170: accuracy:0.3 loss: 226.698 (lr:0.0001)
117180: accuracy:0.38 loss: 194.333 (lr:0.0001)
117190: accuracy:0.31 loss: 218.852 (lr:0.0001)
117200: accuracy:0.25 loss: 209.467 (lr:0.0001)
117210: accuracy:0.39 loss: 202.636 (lr:0.0001)
117220: accuracy:0.47 loss: 181.315 (lr:0.0001)
117230: accuracy:0.33 loss: 199.577 (lr:0.0001)
117240: accuracy:0.34 loss: 207.789 (lr:0.0001)
117250: accuracy:0.31 loss: 206.46 (lr:0.0001)
117260: accuracy:0.28 loss: 221.32 (lr:0.0001)
117270: accuracy:0.25 loss: 216.506 (lr:0.0001)
117280: accuracy:0.36 loss: 191.368 (lr:0.0001)
117290: accuracy:0.35 loss: 205.031 (lr:0.0001)
117300: accuracy:0.42 loss: 211.849 (lr:0.0001)
117310: accuracy:0.35 loss: 200.454 (lr:0.0001)
117320: accuracy:0.25 loss: 227.173 (lr:0.0001)
117330: accuracy:0.27 loss: 210.564 (lr:0.0001)
117340: accuracy:0.38 loss: 202.658 (lr:0.0001)
117350: accuracy:0.33 loss: 218.62 (lr:0.0001)
117360: accuracy:0.34 loss: 208.203 (lr:0.0001)
117370: accuracy:0.25 loss: 213.982 (lr:0.0001)
117380: accuracy:0.36 loss: 207.293 (lr:0.0001)
117390: accuracy:0.28 loss: 214.868 (lr:0.0001)
117400: accuracy:0.39 loss: 209.111 (lr:0.0001)
117410: accuracy:0.34 loss: 217.647 (lr:0.0001)
117420: accuracy:0.34 loss: 214.142 (lr:0.0001)
117430: accuracy:0.29 loss: 208.819 (lr:0.0001)
117440: accuracy:0.29 loss: 222.277 (lr:0.0001)
117450: accuracy:0.36 loss: 206.918 (lr:0.0001)
117460: accuracy:0.29 loss: 214.132 (lr:0.0001)
117470: accuracy:0.32 loss: 206.74 (lr:0.0001)
117480: accuracy:0.35 loss: 199.726 (lr:0.0001)
117490: accuracy:0.43 loss: 208.681 (lr:0.0001)
117500: accuracy:0.33 loss: 202.964 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
117500: ********* epoch 13 ********* test accuracy for all:0.257797 test loss: 253.696
117500: ********* epoch 13 ********* test accuracy for mode 0:0.0195 test loss: 426.162
117500: ********* epoch 13 ********* test accuracy for mode 1:0.04 test loss: 416.87
117500: ********* epoch 13 ********* test accuracy for mode 2:0.066 test loss: 259.844
117500: ********* epoch 13 ********* test accuracy for mode 24:0.256 test loss: 261.551
117500: ********* epoch 13 ********* test accuracy for mode 25:0.3235 test loss: 238.49
117500: ********* epoch 13 ********* test accuracy for mode 26:0.3645 test loss: 169.996
117500: ********* epoch 13 ********* test accuracy for mode 27:0.257 test loss: 260.286
117500: ********* epoch 13 ********* test accuracy for mode 28:0.2945 test loss: 251.762
117500: ********* epoch 13 ********* test accuracy for mode 29:0.237 test loss: 257.748
117500: ********* epoch 13 ********* test accuracy for mode 30:0.2715 test loss: 244.025
117500: ********* epoch 13 ********* test accuracy for mode 31:0.1875 test loss: 247.115
117500: ********* epoch 13 ********* test accuracy for mode 32:0.242 test loss: 233.391
117500: ********* epoch 13 ********* test accuracy for mode 33:0.2985 test loss: 233.934
117500: ********* epoch 13 ********* test accuracy for mode 34:0.1695 test loss: 244.308
117500: ********* epoch 13 ********* test accuracy for mode 35:0.073 test loss: 429.468
117500: ********* epoch 13 ********* test accuracy for mode 36:0.201 test loss: 437.073
117510: accuracy:0.3 loss: 212.805 (lr:0.0001)
117520: accuracy:0.43 loss: 189.012 (lr:0.0001)
117530: accuracy:0.34 loss: 217.676 (lr:0.0001)
117540: accuracy:0.43 loss: 177.818 (lr:0.0001)
117550: accuracy:0.31 loss: 218.15 (lr:0.0001)
117560: accuracy:0.28 loss: 209.722 (lr:0.0001)
117570: accuracy:0.34 loss: 206.026 (lr:0.0001)
117580: accuracy:0.4 loss: 206.218 (lr:0.0001)
117590: accuracy:0.47 loss: 184.751 (lr:0.0001)
117600: accuracy:0.37 loss: 208.22 (lr:0.0001)
117610: accuracy:0.36 loss: 199.468 (lr:0.0001)
117620: accuracy:0.42 loss: 190.898 (lr:0.0001)
117630: accuracy:0.33 loss: 210.915 (lr:0.0001)
117640: accuracy:0.22 loss: 252.585 (lr:0.0001)
117650: accuracy:0.27 loss: 213.995 (lr:0.0001)
117660: accuracy:0.35 loss: 198.936 (lr:0.0001)
117670: accuracy:0.35 loss: 216.561 (lr:0.0001)
117680: accuracy:0.37 loss: 202.99 (lr:0.0001)
117690: accuracy:0.32 loss: 204.469 (lr:0.0001)
117700: accuracy:0.3 loss: 192.527 (lr:0.0001)
117710: accuracy:0.3 loss: 226.97 (lr:0.0001)
117720: accuracy:0.42 loss: 192.417 (lr:0.0001)
117730: accuracy:0.32 loss: 207.023 (lr:0.0001)
117740: accuracy:0.42 loss: 197.37 (lr:0.0001)
117750: accuracy:0.33 loss: 196.927 (lr:0.0001)
117760: accuracy:0.31 loss: 223.553 (lr:0.0001)
117770: accuracy:0.37 loss: 203.485 (lr:0.0001)
117780: accuracy:0.25 loss: 233.075 (lr:0.0001)
117790: accuracy:0.34 loss: 200.731 (lr:0.0001)
117800: accuracy:0.3 loss: 215.382 (lr:0.0001)
117810: accuracy:0.3 loss: 214.37 (lr:0.0001)
117820: accuracy:0.28 loss: 216.499 (lr:0.0001)
117830: accuracy:0.36 loss: 180.876 (lr:0.0001)
117840: accuracy:0.27 loss: 219.847 (lr:0.0001)
117850: accuracy:0.35 loss: 209.647 (lr:0.0001)
117860: accuracy:0.28 loss: 222.318 (lr:0.0001)
117870: accuracy:0.35 loss: 217.977 (lr:0.0001)
117880: accuracy:0.29 loss: 222.599 (lr:0.0001)
117890: accuracy:0.26 loss: 240.489 (lr:0.0001)
117900: accuracy:0.3 loss: 203.544 (lr:0.0001)
117910: accuracy:0.35 loss: 194.037 (lr:0.0001)
117920: accuracy:0.37 loss: 202.049 (lr:0.0001)
117930: accuracy:0.41 loss: 198.915 (lr:0.0001)
117940: accuracy:0.34 loss: 196.611 (lr:0.0001)
117950: accuracy:0.35 loss: 221.046 (lr:0.0001)
117960: accuracy:0.32 loss: 216.417 (lr:0.0001)
117970: accuracy:0.32 loss: 197.451 (lr:0.0001)
117980: accuracy:0.36 loss: 220.588 (lr:0.0001)
117990: accuracy:0.35 loss: 206.35 (lr:0.0001)
118000: accuracy:0.34 loss: 222.316 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
118000: ********* epoch 13 ********* test accuracy for all:0.255095 test loss: 253.458
118000: ********* epoch 13 ********* test accuracy for mode 0:0.022 test loss: 419.191
118000: ********* epoch 13 ********* test accuracy for mode 1:0.0405 test loss: 413.336
118000: ********* epoch 13 ********* test accuracy for mode 2:0.049 test loss: 265.309
118000: ********* epoch 13 ********* test accuracy for mode 24:0.2485 test loss: 267.552
118000: ********* epoch 13 ********* test accuracy for mode 25:0.303 test loss: 243.878
118000: ********* epoch 13 ********* test accuracy for mode 26:0.378 test loss: 169.633
118000: ********* epoch 13 ********* test accuracy for mode 27:0.25 test loss: 268.027
118000: ********* epoch 13 ********* test accuracy for mode 28:0.33 test loss: 249.41
118000: ********* epoch 13 ********* test accuracy for mode 29:0.268 test loss: 259.113
118000: ********* epoch 13 ********* test accuracy for mode 30:0.22 test loss: 250.755
118000: ********* epoch 13 ********* test accuracy for mode 31:0.269 test loss: 245.801
118000: ********* epoch 13 ********* test accuracy for mode 32:0.184 test loss: 243.674
118000: ********* epoch 13 ********* test accuracy for mode 33:0.244 test loss: 246.691
118000: ********* epoch 13 ********* test accuracy for mode 34:0.1945 test loss: 250.316
118000: ********* epoch 13 ********* test accuracy for mode 35:0.071 test loss: 423.804
118000: ********* epoch 13 ********* test accuracy for mode 36:0.0925 test loss: 444.05
118010: accuracy:0.41 loss: 202.969 (lr:0.0001)
118020: accuracy:0.34 loss: 218.576 (lr:0.0001)
118030: accuracy:0.34 loss: 217.523 (lr:0.0001)
118040: accuracy:0.36 loss: 202.461 (lr:0.0001)
118050: accuracy:0.29 loss: 215.557 (lr:0.0001)
118060: accuracy:0.36 loss: 214.089 (lr:0.0001)
118070: accuracy:0.31 loss: 227.835 (lr:0.0001)
118080: accuracy:0.27 loss: 232.828 (lr:0.0001)
118090: accuracy:0.34 loss: 204.033 (lr:0.0001)
118100: accuracy:0.42 loss: 194.264 (lr:0.0001)
118110: accuracy:0.36 loss: 205.826 (lr:0.0001)
118120: accuracy:0.41 loss: 206.331 (lr:0.0001)
118130: accuracy:0.33 loss: 213.555 (lr:0.0001)
118140: accuracy:0.37 loss: 200.194 (lr:0.0001)
118150: accuracy:0.35 loss: 219.962 (lr:0.0001)
118160: accuracy:0.36 loss: 207.687 (lr:0.0001)
118170: accuracy:0.28 loss: 226.727 (lr:0.0001)
118180: accuracy:0.36 loss: 208.99 (lr:0.0001)
118190: accuracy:0.34 loss: 222.796 (lr:0.0001)
118200: accuracy:0.25 loss: 241.392 (lr:0.0001)
118210: accuracy:0.32 loss: 222.424 (lr:0.0001)
118220: accuracy:0.38 loss: 203.993 (lr:0.0001)
118230: accuracy:0.28 loss: 226.032 (lr:0.0001)
118240: accuracy:0.3 loss: 216.152 (lr:0.0001)
118250: accuracy:0.31 loss: 220.083 (lr:0.0001)
118260: accuracy:0.37 loss: 206.675 (lr:0.0001)
118270: accuracy:0.4 loss: 216.424 (lr:0.0001)
118280: accuracy:0.27 loss: 230.243 (lr:0.0001)
118290: accuracy:0.32 loss: 224.241 (lr:0.0001)
118300: accuracy:0.29 loss: 221.081 (lr:0.0001)
118310: accuracy:0.39 loss: 206.406 (lr:0.0001)
118320: accuracy:0.32 loss: 209.712 (lr:0.0001)
118330: accuracy:0.25 loss: 217.592 (lr:0.0001)
118340: accuracy:0.37 loss: 191.582 (lr:0.0001)
118350: accuracy:0.29 loss: 197.861 (lr:0.0001)
118360: accuracy:0.29 loss: 211.964 (lr:0.0001)
118370: accuracy:0.34 loss: 201.766 (lr:0.0001)
118380: accuracy:0.34 loss: 225.603 (lr:0.0001)
118390: accuracy:0.25 loss: 244.74 (lr:0.0001)
118400: accuracy:0.26 loss: 215.18 (lr:0.0001)
118410: accuracy:0.34 loss: 219.69 (lr:0.0001)
118420: accuracy:0.25 loss: 217.256 (lr:0.0001)
118430: accuracy:0.38 loss: 205.12 (lr:0.0001)
118440: accuracy:0.32 loss: 230.092 (lr:0.0001)
118450: accuracy:0.32 loss: 212.028 (lr:0.0001)
118460: accuracy:0.31 loss: 223.778 (lr:0.0001)
118470: accuracy:0.29 loss: 233.549 (lr:0.0001)
118480: accuracy:0.29 loss: 213.121 (lr:0.0001)
118490: accuracy:0.37 loss: 207.692 (lr:0.0001)
118500: accuracy:0.29 loss: 231.57 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
118500: ********* epoch 13 ********* test accuracy for all:0.254405 test loss: 255.17
118500: ********* epoch 13 ********* test accuracy for mode 0:0.0135 test loss: 434.753
118500: ********* epoch 13 ********* test accuracy for mode 1:0.0385 test loss: 420.63
118500: ********* epoch 13 ********* test accuracy for mode 2:0.028 test loss: 269.87
118500: ********* epoch 13 ********* test accuracy for mode 24:0.254 test loss: 264.027
118500: ********* epoch 13 ********* test accuracy for mode 25:0.293 test loss: 242.345
118500: ********* epoch 13 ********* test accuracy for mode 26:0.49 test loss: 154.933
118500: ********* epoch 13 ********* test accuracy for mode 27:0.281 test loss: 257.95
118500: ********* epoch 13 ********* test accuracy for mode 28:0.2825 test loss: 258.605
118500: ********* epoch 13 ********* test accuracy for mode 29:0.2535 test loss: 268.37
118500: ********* epoch 13 ********* test accuracy for mode 30:0.227 test loss: 260.167
118500: ********* epoch 13 ********* test accuracy for mode 31:0.192 test loss: 262.365
118500: ********* epoch 13 ********* test accuracy for mode 32:0.2045 test loss: 248.377
118500: ********* epoch 13 ********* test accuracy for mode 33:0.2405 test loss: 249.172
118500: ********* epoch 13 ********* test accuracy for mode 34:0.235 test loss: 249.614
118500: ********* epoch 13 ********* test accuracy for mode 35:0.037 test loss: 443.757
118500: ********* epoch 13 ********* test accuracy for mode 36:0.087 test loss: 483.041
118510: accuracy:0.38 loss: 195.164 (lr:0.0001)
118520: accuracy:0.28 loss: 199.243 (lr:0.0001)
118530: accuracy:0.38 loss: 197.519 (lr:0.0001)
118540: accuracy:0.2 loss: 226.99 (lr:0.0001)
118550: accuracy:0.23 loss: 229.61 (lr:0.0001)
118560: accuracy:0.41 loss: 214.247 (lr:0.0001)
118570: accuracy:0.27 loss: 217.537 (lr:0.0001)
118580: accuracy:0.43 loss: 198.63 (lr:0.0001)
118590: accuracy:0.28 loss: 219.759 (lr:0.0001)
118600: accuracy:0.32 loss: 201.327 (lr:0.0001)
118610: accuracy:0.36 loss: 196.468 (lr:0.0001)
118620: accuracy:0.44 loss: 204.854 (lr:0.0001)
118630: accuracy:0.38 loss: 225.298 (lr:0.0001)
118640: accuracy:0.31 loss: 209.596 (lr:0.0001)
118650: accuracy:0.34 loss: 214.019 (lr:0.0001)
118660: accuracy:0.35 loss: 205.2 (lr:0.0001)
118670: accuracy:0.34 loss: 217.816 (lr:0.0001)
118680: accuracy:0.46 loss: 195.54 (lr:0.0001)
118690: accuracy:0.33 loss: 211.942 (lr:0.0001)
118700: accuracy:0.39 loss: 209.459 (lr:0.0001)
118710: accuracy:0.43 loss: 200.699 (lr:0.0001)
118720: accuracy:0.41 loss: 203.324 (lr:0.0001)
118730: accuracy:0.36 loss: 195.02 (lr:0.0001)
118740: accuracy:0.41 loss: 191.472 (lr:0.0001)
118750: accuracy:0.34 loss: 201.633 (lr:0.0001)
118760: accuracy:0.35 loss: 218.929 (lr:0.0001)
118770: accuracy:0.27 loss: 203.388 (lr:0.0001)
118780: accuracy:0.29 loss: 213.461 (lr:0.0001)
118790: accuracy:0.31 loss: 205.701 (lr:0.0001)
118800: accuracy:0.36 loss: 216.314 (lr:0.0001)
118810: accuracy:0.4 loss: 218.948 (lr:0.0001)
118820: accuracy:0.32 loss: 201.139 (lr:0.0001)
118830: accuracy:0.36 loss: 219.911 (lr:0.0001)
118840: accuracy:0.31 loss: 225.519 (lr:0.0001)
118850: accuracy:0.33 loss: 229.553 (lr:0.0001)
118860: accuracy:0.37 loss: 219.623 (lr:0.0001)
118870: accuracy:0.34 loss: 208.107 (lr:0.0001)
118880: accuracy:0.31 loss: 221.631 (lr:0.0001)
118890: accuracy:0.33 loss: 204.46 (lr:0.0001)
118900: accuracy:0.36 loss: 202.702 (lr:0.0001)
118910: accuracy:0.25 loss: 229.754 (lr:0.0001)
118920: accuracy:0.39 loss: 205.862 (lr:0.0001)
118930: accuracy:0.3 loss: 207.69 (lr:0.0001)
118940: accuracy:0.32 loss: 203.639 (lr:0.0001)
118950: accuracy:0.29 loss: 205.365 (lr:0.0001)
118960: accuracy:0.35 loss: 198.159 (lr:0.0001)
118970: accuracy:0.32 loss: 228.081 (lr:0.0001)
118980: accuracy:0.4 loss: 196.345 (lr:0.0001)
118990: accuracy:0.36 loss: 191.833 (lr:0.0001)
119000: accuracy:0.3 loss: 210.606 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
119000: ********* epoch 13 ********* test accuracy for all:0.25323 test loss: 254.557
119000: ********* epoch 13 ********* test accuracy for mode 0:0.018 test loss: 420.587
119000: ********* epoch 13 ********* test accuracy for mode 1:0.041 test loss: 409.597
119000: ********* epoch 13 ********* test accuracy for mode 2:0.056 test loss: 270.709
119000: ********* epoch 13 ********* test accuracy for mode 24:0.25 test loss: 268.595
119000: ********* epoch 13 ********* test accuracy for mode 25:0.282 test loss: 244.307
119000: ********* epoch 13 ********* test accuracy for mode 26:0.4435 test loss: 163.625
119000: ********* epoch 13 ********* test accuracy for mode 27:0.239 test loss: 267.956
119000: ********* epoch 13 ********* test accuracy for mode 28:0.3065 test loss: 256.059
119000: ********* epoch 13 ********* test accuracy for mode 29:0.249 test loss: 264.872
119000: ********* epoch 13 ********* test accuracy for mode 30:0.232 test loss: 251.68
119000: ********* epoch 13 ********* test accuracy for mode 31:0.2485 test loss: 251.459
119000: ********* epoch 13 ********* test accuracy for mode 32:0.1485 test loss: 248.184
119000: ********* epoch 13 ********* test accuracy for mode 33:0.273 test loss: 244.761
119000: ********* epoch 13 ********* test accuracy for mode 34:0.206 test loss: 250.514
119000: ********* epoch 13 ********* test accuracy for mode 35:0.0325 test loss: 430.725
119000: ********* epoch 13 ********* test accuracy for mode 36:0.1185 test loss: 433.026
119010: accuracy:0.44 loss: 189.955 (lr:0.0001)
119020: accuracy:0.37 loss: 202.576 (lr:0.0001)
119030: accuracy:0.36 loss: 196.979 (lr:0.0001)
119040: accuracy:0.28 loss: 227.154 (lr:0.0001)
119050: accuracy:0.29 loss: 214.449 (lr:0.0001)
119060: accuracy:0.4 loss: 204.661 (lr:0.0001)
119070: accuracy:0.42 loss: 193.363 (lr:0.0001)
119080: accuracy:0.32 loss: 222.436 (lr:0.0001)
119090: accuracy:0.33 loss: 204.205 (lr:0.0001)
119100: accuracy:0.41 loss: 195.194 (lr:0.0001)
119110: accuracy:0.33 loss: 202.354 (lr:0.0001)
119120: accuracy:0.26 loss: 205.069 (lr:0.0001)
119130: accuracy:0.3 loss: 212.178 (lr:0.0001)
119140: accuracy:0.43 loss: 210.188 (lr:0.0001)
119150: accuracy:0.33 loss: 208.949 (lr:0.0001)
119160: accuracy:0.42 loss: 204.804 (lr:0.0001)
119170: accuracy:0.33 loss: 198.019 (lr:0.0001)
119180: accuracy:0.34 loss: 203.54 (lr:0.0001)
119190: accuracy:0.34 loss: 208.934 (lr:0.0001)
119200: accuracy:0.43 loss: 196.943 (lr:0.0001)
119210: accuracy:0.46 loss: 190.478 (lr:0.0001)
119220: accuracy:0.38 loss: 204.311 (lr:0.0001)
119230: accuracy:0.3 loss: 203.858 (lr:0.0001)
119240: accuracy:0.36 loss: 213.547 (lr:0.0001)
119250: accuracy:0.32 loss: 206.935 (lr:0.0001)
119260: accuracy:0.39 loss: 201.371 (lr:0.0001)
119270: accuracy:0.39 loss: 202.05 (lr:0.0001)
119280: accuracy:0.34 loss: 192.145 (lr:0.0001)
119290: accuracy:0.31 loss: 222.396 (lr:0.0001)
119300: accuracy:0.37 loss: 214.281 (lr:0.0001)
119310: accuracy:0.31 loss: 212.067 (lr:0.0001)
119320: accuracy:0.35 loss: 200.949 (lr:0.0001)
119330: accuracy:0.31 loss: 208.601 (lr:0.0001)
119340: accuracy:0.32 loss: 208.541 (lr:0.0001)
119350: accuracy:0.31 loss: 229.712 (lr:0.0001)
119360: accuracy:0.36 loss: 218.476 (lr:0.0001)
119370: accuracy:0.28 loss: 217.894 (lr:0.0001)
119380: accuracy:0.27 loss: 212.171 (lr:0.0001)
119390: accuracy:0.35 loss: 196.78 (lr:0.0001)
119400: accuracy:0.33 loss: 223.795 (lr:0.0001)
119410: accuracy:0.35 loss: 213.085 (lr:0.0001)
119420: accuracy:0.3 loss: 189.5 (lr:0.0001)
119430: accuracy:0.43 loss: 198.867 (lr:0.0001)
119440: accuracy:0.38 loss: 191.311 (lr:0.0001)
119450: accuracy:0.33 loss: 211.696 (lr:0.0001)
119460: accuracy:0.31 loss: 215.633 (lr:0.0001)
119470: accuracy:0.29 loss: 226.018 (lr:0.0001)
119480: accuracy:0.35 loss: 207.101 (lr:0.0001)
119490: accuracy:0.43 loss: 200.895 (lr:0.0001)
119500: accuracy:0.29 loss: 221.025 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
119500: ********* epoch 13 ********* test accuracy for all:0.254595 test loss: 255.419
119500: ********* epoch 13 ********* test accuracy for mode 0:0.02 test loss: 426.594
119500: ********* epoch 13 ********* test accuracy for mode 1:0.036 test loss: 418.189
119500: ********* epoch 13 ********* test accuracy for mode 2:0.055 test loss: 261.176
119500: ********* epoch 13 ********* test accuracy for mode 24:0.253 test loss: 269.027
119500: ********* epoch 13 ********* test accuracy for mode 25:0.324 test loss: 240.182
119500: ********* epoch 13 ********* test accuracy for mode 26:0.4025 test loss: 167.834
119500: ********* epoch 13 ********* test accuracy for mode 27:0.266 test loss: 257.772
119500: ********* epoch 13 ********* test accuracy for mode 28:0.301 test loss: 248.612
119500: ********* epoch 13 ********* test accuracy for mode 29:0.292 test loss: 249.093
119500: ********* epoch 13 ********* test accuracy for mode 30:0.2455 test loss: 239.023
119500: ********* epoch 13 ********* test accuracy for mode 31:0.248 test loss: 238.978
119500: ********* epoch 13 ********* test accuracy for mode 32:0.1925 test loss: 232.477
119500: ********* epoch 13 ********* test accuracy for mode 33:0.285 test loss: 234.586
119500: ********* epoch 13 ********* test accuracy for mode 34:0.21 test loss: 241.905
119500: ********* epoch 13 ********* test accuracy for mode 35:0.05 test loss: 443.071
119500: ********* epoch 13 ********* test accuracy for mode 36:0.054 test loss: 516.859
119510: accuracy:0.37 loss: 211.694 (lr:0.0001)
119520: accuracy:0.28 loss: 214.156 (lr:0.0001)
119530: accuracy:0.31 loss: 209.914 (lr:0.0001)
119540: accuracy:0.38 loss: 195.919 (lr:0.0001)
119550: accuracy:0.38 loss: 189.838 (lr:0.0001)
119560: accuracy:0.39 loss: 188.688 (lr:0.0001)
119570: accuracy:0.24 loss: 211.798 (lr:0.0001)
119580: accuracy:0.41 loss: 189.866 (lr:0.0001)
119590: accuracy:0.38 loss: 210.777 (lr:0.0001)
119600: accuracy:0.26 loss: 211.86 (lr:0.0001)
119610: accuracy:0.35 loss: 223.15 (lr:0.0001)
119620: accuracy:0.36 loss: 207.903 (lr:0.0001)
119630: accuracy:0.33 loss: 201.582 (lr:0.0001)
119640: accuracy:0.43 loss: 193.276 (lr:0.0001)
119650: accuracy:0.38 loss: 213.732 (lr:0.0001)
119660: accuracy:0.39 loss: 184.275 (lr:0.0001)
119670: accuracy:0.36 loss: 205.605 (lr:0.0001)
119680: accuracy:0.42 loss: 189.511 (lr:0.0001)
119690: accuracy:0.34 loss: 204.057 (lr:0.0001)
119700: accuracy:0.28 loss: 237.638 (lr:0.0001)
119710: accuracy:0.39 loss: 215.819 (lr:0.0001)
119720: accuracy:0.28 loss: 221.839 (lr:0.0001)
119730: accuracy:0.36 loss: 183.385 (lr:0.0001)
119740: accuracy:0.32 loss: 208.411 (lr:0.0001)
119750: accuracy:0.3 loss: 212.611 (lr:0.0001)
119760: accuracy:0.3 loss: 220.079 (lr:0.0001)
119770: accuracy:0.28 loss: 211.428 (lr:0.0001)
119780: accuracy:0.33 loss: 213.665 (lr:0.0001)
119790: accuracy:0.3 loss: 231.848 (lr:0.0001)
119800: accuracy:0.29 loss: 239.478 (lr:0.0001)
119810: accuracy:0.27 loss: 220.526 (lr:0.0001)
119820: accuracy:0.35 loss: 211.315 (lr:0.0001)
119830: accuracy:0.38 loss: 211.127 (lr:0.0001)
119840: accuracy:0.37 loss: 198.488 (lr:0.0001)
119850: accuracy:0.34 loss: 221.857 (lr:0.0001)
119860: accuracy:0.36 loss: 231.098 (lr:0.0001)
119870: accuracy:0.34 loss: 202.385 (lr:0.0001)
119880: accuracy:0.29 loss: 212.507 (lr:0.0001)
119890: accuracy:0.38 loss: 210.486 (lr:0.0001)
119900: accuracy:0.32 loss: 217.778 (lr:0.0001)
119910: accuracy:0.42 loss: 211.759 (lr:0.0001)
119920: accuracy:0.31 loss: 214.184 (lr:0.0001)
119930: accuracy:0.32 loss: 206.628 (lr:0.0001)
119940: accuracy:0.38 loss: 231.379 (lr:0.0001)
119950: accuracy:0.38 loss: 198.855 (lr:0.0001)
119960: accuracy:0.35 loss: 204.444 (lr:0.0001)
119970: accuracy:0.39 loss: 209.94 (lr:0.0001)
119980: accuracy:0.31 loss: 220.453 (lr:0.0001)
119990: accuracy:0.43 loss: 185.1 (lr:0.0001)
120000: accuracy:0.41 loss: 195.001 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
120000: ********* epoch 13 ********* test accuracy for all:0.250122 test loss: 255.834
120000: ********* epoch 13 ********* test accuracy for mode 0:0.022 test loss: 420.823
120000: ********* epoch 13 ********* test accuracy for mode 1:0.029 test loss: 422.599
120000: ********* epoch 13 ********* test accuracy for mode 2:0.054 test loss: 264.639
120000: ********* epoch 13 ********* test accuracy for mode 24:0.2315 test loss: 268.23
120000: ********* epoch 13 ********* test accuracy for mode 25:0.3275 test loss: 241.393
120000: ********* epoch 13 ********* test accuracy for mode 26:0.389 test loss: 171.515
120000: ********* epoch 13 ********* test accuracy for mode 27:0.253 test loss: 267.271
120000: ********* epoch 13 ********* test accuracy for mode 28:0.276 test loss: 256.465
120000: ********* epoch 13 ********* test accuracy for mode 29:0.2705 test loss: 253.751
120000: ********* epoch 13 ********* test accuracy for mode 30:0.249 test loss: 240.548
120000: ********* epoch 13 ********* test accuracy for mode 31:0.3 test loss: 234.896
120000: ********* epoch 13 ********* test accuracy for mode 32:0.155 test loss: 231.219
120000: ********* epoch 13 ********* test accuracy for mode 33:0.293 test loss: 233.454
120000: ********* epoch 13 ********* test accuracy for mode 34:0.202 test loss: 240.452
120000: ********* epoch 13 ********* test accuracy for mode 35:0.0635 test loss: 428.821
120000: ********* epoch 13 ********* test accuracy for mode 36:0.089 test loss: 466.097
120010: accuracy:0.4 loss: 205.226 (lr:0.0001)
120020: accuracy:0.32 loss: 215.226 (lr:0.0001)
120030: accuracy:0.36 loss: 211.655 (lr:0.0001)
120040: accuracy:0.41 loss: 204.259 (lr:0.0001)
120050: accuracy:0.38 loss: 208.231 (lr:0.0001)
120060: accuracy:0.33 loss: 219.012 (lr:0.0001)
120070: accuracy:0.34 loss: 203.362 (lr:0.0001)
120080: accuracy:0.37 loss: 208.748 (lr:0.0001)
120090: accuracy:0.38 loss: 208.808 (lr:0.0001)
120100: accuracy:0.34 loss: 223.35 (lr:0.0001)
120110: accuracy:0.36 loss: 231.812 (lr:0.0001)
120120: accuracy:0.29 loss: 220.612 (lr:0.0001)
120130: accuracy:0.37 loss: 208.025 (lr:0.0001)
120140: accuracy:0.32 loss: 222.814 (lr:0.0001)
120150: accuracy:0.34 loss: 208.438 (lr:0.0001)
120160: accuracy:0.31 loss: 220.606 (lr:0.0001)
120170: accuracy:0.48 loss: 174.684 (lr:0.0001)
120180: accuracy:0.43 loss: 203.801 (lr:0.0001)
120190: accuracy:0.29 loss: 213.85 (lr:0.0001)
120200: accuracy:0.33 loss: 216.218 (lr:0.0001)
120210: accuracy:0.23 loss: 227.857 (lr:0.0001)
120220: accuracy:0.29 loss: 222.06 (lr:0.0001)
120230: accuracy:0.34 loss: 219.842 (lr:0.0001)
120240: accuracy:0.31 loss: 198.871 (lr:0.0001)
120250: accuracy:0.27 loss: 208.697 (lr:0.0001)
120260: accuracy:0.37 loss: 211.5 (lr:0.0001)
120270: accuracy:0.38 loss: 217.507 (lr:0.0001)
120280: accuracy:0.29 loss: 200.435 (lr:0.0001)
120290: accuracy:0.28 loss: 219.216 (lr:0.0001)
120300: accuracy:0.3 loss: 207.271 (lr:0.0001)
120310: accuracy:0.39 loss: 197.95 (lr:0.0001)
120320: accuracy:0.35 loss: 202.697 (lr:0.0001)
120330: accuracy:0.27 loss: 211.148 (lr:0.0001)
120340: accuracy:0.35 loss: 215.493 (lr:0.0001)
120350: accuracy:0.33 loss: 234.322 (lr:0.0001)
120360: accuracy:0.38 loss: 215.322 (lr:0.0001)
120370: accuracy:0.3 loss: 196.704 (lr:0.0001)
120380: accuracy:0.31 loss: 208.885 (lr:0.0001)
120390: accuracy:0.27 loss: 209.557 (lr:0.0001)
120400: accuracy:0.33 loss: 216.116 (lr:0.0001)
120410: accuracy:0.3 loss: 198.39 (lr:0.0001)
120420: accuracy:0.4 loss: 189.29 (lr:0.0001)
120430: accuracy:0.22 loss: 219.915 (lr:0.0001)
120440: accuracy:0.27 loss: 222.848 (lr:0.0001)
120450: accuracy:0.3 loss: 209.524 (lr:0.0001)
120460: accuracy:0.29 loss: 218.985 (lr:0.0001)
120470: accuracy:0.38 loss: 192.253 (lr:0.0001)
120480: accuracy:0.38 loss: 228.267 (lr:0.0001)
120490: accuracy:0.31 loss: 210.265 (lr:0.0001)
120500: accuracy:0.42 loss: 197.734 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
120500: ********* epoch 13 ********* test accuracy for all:0.256378 test loss: 253.47
120500: ********* epoch 13 ********* test accuracy for mode 0:0.0265 test loss: 416.913
120500: ********* epoch 13 ********* test accuracy for mode 1:0.0355 test loss: 415.664
120500: ********* epoch 13 ********* test accuracy for mode 2:0.055 test loss: 265.596
120500: ********* epoch 13 ********* test accuracy for mode 24:0.2225 test loss: 274.412
120500: ********* epoch 13 ********* test accuracy for mode 25:0.279 test loss: 247.93
120500: ********* epoch 13 ********* test accuracy for mode 26:0.495 test loss: 158.01
120500: ********* epoch 13 ********* test accuracy for mode 27:0.2605 test loss: 264.327
120500: ********* epoch 13 ********* test accuracy for mode 28:0.3005 test loss: 256.019
120500: ********* epoch 13 ********* test accuracy for mode 29:0.259 test loss: 264.294
120500: ********* epoch 13 ********* test accuracy for mode 30:0.2255 test loss: 255.465
120500: ********* epoch 13 ********* test accuracy for mode 31:0.1895 test loss: 255.656
120500: ********* epoch 13 ********* test accuracy for mode 32:0.24 test loss: 237.031
120500: ********* epoch 13 ********* test accuracy for mode 33:0.2605 test loss: 240.849
120500: ********* epoch 13 ********* test accuracy for mode 34:0.2385 test loss: 242.198
120500: ********* epoch 13 ********* test accuracy for mode 35:0.062 test loss: 426.011
120500: ********* epoch 13 ********* test accuracy for mode 36:0.1065 test loss: 440.37
120510: accuracy:0.35 loss: 215.696 (lr:0.0001)
120520: accuracy:0.37 loss: 211.435 (lr:0.0001)
120530: accuracy:0.4 loss: 205.561 (lr:0.0001)
120540: accuracy:0.31 loss: 222.471 (lr:0.0001)
120550: accuracy:0.39 loss: 204.432 (lr:0.0001)
120560: accuracy:0.28 loss: 219.64 (lr:0.0001)
120570: accuracy:0.3 loss: 213.496 (lr:0.0001)
120580: accuracy:0.33 loss: 217.277 (lr:0.0001)
120590: accuracy:0.23 loss: 220.188 (lr:0.0001)
120600: accuracy:0.35 loss: 220.924 (lr:0.0001)
120610: accuracy:0.31 loss: 206.217 (lr:0.0001)
120620: accuracy:0.37 loss: 197.392 (lr:0.0001)
120630: accuracy:0.38 loss: 203.132 (lr:0.0001)
120640: accuracy:0.34 loss: 195.164 (lr:0.0001)
120650: accuracy:0.4 loss: 179.004 (lr:0.0001)
120660: accuracy:0.32 loss: 220.312 (lr:0.0001)
120670: accuracy:0.37 loss: 216.866 (lr:0.0001)
120680: accuracy:0.34 loss: 200.574 (lr:0.0001)
120690: accuracy:0.32 loss: 200.425 (lr:0.0001)
120700: accuracy:0.32 loss: 201.294 (lr:0.0001)
120710: accuracy:0.34 loss: 195.445 (lr:0.0001)
120720: accuracy:0.41 loss: 210.62 (lr:0.0001)
120730: accuracy:0.23 loss: 226.877 (lr:0.0001)
120740: accuracy:0.4 loss: 200.29 (lr:0.0001)
120750: accuracy:0.34 loss: 212.218 (lr:0.0001)
120760: accuracy:0.36 loss: 218.95 (lr:0.0001)
120770: accuracy:0.29 loss: 194.972 (lr:0.0001)
120780: accuracy:0.35 loss: 205.847 (lr:0.0001)
120790: accuracy:0.37 loss: 213.54 (lr:0.0001)
120800: accuracy:0.31 loss: 210.239 (lr:0.0001)
120810: accuracy:0.34 loss: 226.694 (lr:0.0001)
120820: accuracy:0.33 loss: 183.672 (lr:0.0001)
120830: accuracy:0.32 loss: 221.12 (lr:0.0001)
120840: accuracy:0.45 loss: 217.438 (lr:0.0001)
120850: accuracy:0.35 loss: 213.541 (lr:0.0001)
120860: accuracy:0.33 loss: 221.135 (lr:0.0001)
120870: accuracy:0.37 loss: 207.787 (lr:0.0001)
120880: accuracy:0.35 loss: 198.818 (lr:0.0001)
120890: accuracy:0.33 loss: 221.417 (lr:0.0001)
120900: accuracy:0.34 loss: 213.699 (lr:0.0001)
120910: accuracy:0.42 loss: 204.484 (lr:0.0001)
120920: accuracy:0.39 loss: 217.823 (lr:0.0001)
120930: accuracy:0.31 loss: 216.713 (lr:0.0001)
120940: accuracy:0.3 loss: 221.292 (lr:0.0001)
120950: accuracy:0.39 loss: 183.859 (lr:0.0001)
120960: accuracy:0.24 loss: 258.096 (lr:0.0001)
120970: accuracy:0.37 loss: 190.15 (lr:0.0001)
120980: accuracy:0.33 loss: 194.317 (lr:0.0001)
120990: accuracy:0.39 loss: 206.51 (lr:0.0001)
121000: accuracy:0.35 loss: 199.476 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
121000: ********* epoch 13 ********* test accuracy for all:0.253135 test loss: 255.778
121000: ********* epoch 13 ********* test accuracy for mode 0:0.0205 test loss: 430.012
121000: ********* epoch 13 ********* test accuracy for mode 1:0.0335 test loss: 424.161
121000: ********* epoch 13 ********* test accuracy for mode 2:0.0285 test loss: 269.097
121000: ********* epoch 13 ********* test accuracy for mode 24:0.223 test loss: 273.914
121000: ********* epoch 13 ********* test accuracy for mode 25:0.268 test loss: 241.755
121000: ********* epoch 13 ********* test accuracy for mode 26:0.417 test loss: 167.853
121000: ********* epoch 13 ********* test accuracy for mode 27:0.231 test loss: 251.812
121000: ********* epoch 13 ********* test accuracy for mode 28:0.3195 test loss: 238.746
121000: ********* epoch 13 ********* test accuracy for mode 29:0.284 test loss: 243.925
121000: ********* epoch 13 ********* test accuracy for mode 30:0.2635 test loss: 236.468
121000: ********* epoch 13 ********* test accuracy for mode 31:0.2195 test loss: 242.535
121000: ********* epoch 13 ********* test accuracy for mode 32:0.207 test loss: 231.009
121000: ********* epoch 13 ********* test accuracy for mode 33:0.294 test loss: 234.309
121000: ********* epoch 13 ********* test accuracy for mode 34:0.223 test loss: 239.777
121000: ********* epoch 13 ********* test accuracy for mode 35:0.048 test loss: 436.086
121000: ********* epoch 13 ********* test accuracy for mode 36:0.222 test loss: 439.085
121010: accuracy:0.36 loss: 189.175 (lr:0.0001)
121020: accuracy:0.34 loss: 203.449 (lr:0.0001)
121030: accuracy:0.28 loss: 222.127 (lr:0.0001)
121040: accuracy:0.3 loss: 224.045 (lr:0.0001)
121050: accuracy:0.31 loss: 218.203 (lr:0.0001)
121060: accuracy:0.24 loss: 223.227 (lr:0.0001)
121070: accuracy:0.32 loss: 211.805 (lr:0.0001)
121080: accuracy:0.37 loss: 218.07 (lr:0.0001)
121090: accuracy:0.31 loss: 221.389 (lr:0.0001)
121100: accuracy:0.35 loss: 201.69 (lr:0.0001)
121110: accuracy:0.26 loss: 222.807 (lr:0.0001)
121120: accuracy:0.4 loss: 208.663 (lr:0.0001)
121130: accuracy:0.27 loss: 219.915 (lr:0.0001)
121140: accuracy:0.29 loss: 225.73 (lr:0.0001)
121150: accuracy:0.28 loss: 248.072 (lr:0.0001)
121160: accuracy:0.38 loss: 207.875 (lr:0.0001)
121170: accuracy:0.36 loss: 221.994 (lr:0.0001)
121180: accuracy:0.29 loss: 214.051 (lr:0.0001)
121190: accuracy:0.32 loss: 212.518 (lr:0.0001)
121200: accuracy:0.28 loss: 239.448 (lr:0.0001)
121210: accuracy:0.36 loss: 213.543 (lr:0.0001)
121220: accuracy:0.36 loss: 201.696 (lr:0.0001)
121230: accuracy:0.34 loss: 226.924 (lr:0.0001)
121240: accuracy:0.26 loss: 222.836 (lr:0.0001)
121250: accuracy:0.39 loss: 195.197 (lr:0.0001)
121260: accuracy:0.29 loss: 214.527 (lr:0.0001)
121270: accuracy:0.4 loss: 194.079 (lr:0.0001)
121280: accuracy:0.22 loss: 227.793 (lr:0.0001)
121290: accuracy:0.4 loss: 209.894 (lr:0.0001)
121300: accuracy:0.28 loss: 233.658 (lr:0.0001)
121310: accuracy:0.36 loss: 191.451 (lr:0.0001)
121320: accuracy:0.39 loss: 204.989 (lr:0.0001)
121330: accuracy:0.39 loss: 203.326 (lr:0.0001)
121340: accuracy:0.33 loss: 231.275 (lr:0.0001)
121350: accuracy:0.38 loss: 213.761 (lr:0.0001)
121360: accuracy:0.38 loss: 214.461 (lr:0.0001)
121370: accuracy:0.3 loss: 218.005 (lr:0.0001)
121380: accuracy:0.36 loss: 196.594 (lr:0.0001)
121390: accuracy:0.38 loss: 211.108 (lr:0.0001)
121400: accuracy:0.29 loss: 240.386 (lr:0.0001)
121410: accuracy:0.36 loss: 199.684 (lr:0.0001)
121420: accuracy:0.37 loss: 210.704 (lr:0.0001)
121430: accuracy:0.38 loss: 188.888 (lr:0.0001)
121440: accuracy:0.33 loss: 219.229 (lr:0.0001)
121450: accuracy:0.31 loss: 211.295 (lr:0.0001)
121460: accuracy:0.37 loss: 208.485 (lr:0.0001)
121470: accuracy:0.36 loss: 218.19 (lr:0.0001)
121480: accuracy:0.35 loss: 217.928 (lr:0.0001)
121490: accuracy:0.45 loss: 205.663 (lr:0.0001)
121500: accuracy:0.34 loss: 208.022 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
121500: ********* epoch 13 ********* test accuracy for all:0.255986 test loss: 256.744
121500: ********* epoch 13 ********* test accuracy for mode 0:0.026 test loss: 422.593
121500: ********* epoch 13 ********* test accuracy for mode 1:0.0375 test loss: 421.746
121500: ********* epoch 13 ********* test accuracy for mode 2:0.065 test loss: 255.655
121500: ********* epoch 13 ********* test accuracy for mode 24:0.2395 test loss: 271.898
121500: ********* epoch 13 ********* test accuracy for mode 25:0.321 test loss: 246.287
121500: ********* epoch 13 ********* test accuracy for mode 26:0.491 test loss: 159.768
121500: ********* epoch 13 ********* test accuracy for mode 27:0.2725 test loss: 270.259
121500: ********* epoch 13 ********* test accuracy for mode 28:0.277 test loss: 270.352
121500: ********* epoch 13 ********* test accuracy for mode 29:0.2475 test loss: 276.455
121500: ********* epoch 13 ********* test accuracy for mode 30:0.2045 test loss: 259.233
121500: ********* epoch 13 ********* test accuracy for mode 31:0.2165 test loss: 256.875
121500: ********* epoch 13 ********* test accuracy for mode 32:0.2015 test loss: 241.43
121500: ********* epoch 13 ********* test accuracy for mode 33:0.2385 test loss: 242.446
121500: ********* epoch 13 ********* test accuracy for mode 34:0.2645 test loss: 237.461
121500: ********* epoch 13 ********* test accuracy for mode 35:0.0395 test loss: 438.113
121500: ********* epoch 13 ********* test accuracy for mode 36:0.0625 test loss: 498.374
121510: accuracy:0.34 loss: 210.264 (lr:0.0001)
121520: accuracy:0.3 loss: 226.873 (lr:0.0001)
121530: accuracy:0.32 loss: 209.205 (lr:0.0001)
121540: accuracy:0.4 loss: 192.935 (lr:0.0001)
121550: accuracy:0.31 loss: 214.923 (lr:0.0001)
121560: accuracy:0.36 loss: 194.97 (lr:0.0001)
121570: accuracy:0.32 loss: 233.093 (lr:0.0001)
121580: accuracy:0.29 loss: 224.669 (lr:0.0001)
121590: accuracy:0.37 loss: 216.517 (lr:0.0001)
121600: accuracy:0.44 loss: 182.394 (lr:0.0001)
121610: accuracy:0.35 loss: 201.691 (lr:0.0001)
121620: accuracy:0.38 loss: 213.28 (lr:0.0001)
121630: accuracy:0.37 loss: 201.887 (lr:0.0001)
121640: accuracy:0.33 loss: 206.218 (lr:0.0001)
121650: accuracy:0.29 loss: 213.945 (lr:0.0001)
121660: accuracy:0.26 loss: 215.147 (lr:0.0001)
121670: accuracy:0.31 loss: 195.92 (lr:0.0001)
121680: accuracy:0.4 loss: 183.382 (lr:0.0001)
121690: accuracy:0.25 loss: 224.598 (lr:0.0001)
121700: accuracy:0.33 loss: 199.646 (lr:0.0001)
121710: accuracy:0.32 loss: 219.785 (lr:0.0001)
121720: accuracy:0.3 loss: 247.204 (lr:0.0001)
121730: accuracy:0.32 loss: 236.807 (lr:0.0001)
121740: accuracy:0.35 loss: 203.881 (lr:0.0001)
121750: accuracy:0.32 loss: 211.419 (lr:0.0001)
121760: accuracy:0.35 loss: 201.224 (lr:0.0001)
121770: accuracy:0.3 loss: 203.891 (lr:0.0001)
121780: accuracy:0.3 loss: 213.823 (lr:0.0001)
121790: accuracy:0.33 loss: 219.965 (lr:0.0001)
121800: accuracy:0.38 loss: 210.261 (lr:0.0001)
121810: accuracy:0.3 loss: 205.248 (lr:0.0001)
121820: accuracy:0.37 loss: 210.787 (lr:0.0001)
121830: accuracy:0.35 loss: 203.342 (lr:0.0001)
121840: accuracy:0.32 loss: 209.733 (lr:0.0001)
121850: accuracy:0.38 loss: 206.798 (lr:0.0001)
121860: accuracy:0.32 loss: 223.576 (lr:0.0001)
121870: accuracy:0.28 loss: 203.629 (lr:0.0001)
121880: accuracy:0.35 loss: 206.281 (lr:0.0001)
121890: accuracy:0.46 loss: 210.017 (lr:0.0001)
121900: accuracy:0.35 loss: 222.285 (lr:0.0001)
121910: accuracy:0.35 loss: 221.945 (lr:0.0001)
121920: accuracy:0.28 loss: 226.642 (lr:0.0001)
121930: accuracy:0.26 loss: 206.809 (lr:0.0001)
121940: accuracy:0.39 loss: 216.716 (lr:0.0001)
121950: accuracy:0.36 loss: 203.794 (lr:0.0001)
121960: accuracy:0.41 loss: 216.947 (lr:0.0001)
121970: accuracy:0.36 loss: 208.211 (lr:0.0001)
121980: accuracy:0.31 loss: 214.23 (lr:0.0001)
121990: accuracy:0.39 loss: 216.742 (lr:0.0001)
122000: accuracy:0.37 loss: 208.229 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
122000: ********* epoch 13 ********* test accuracy for all:0.25373 test loss: 255.539
122000: ********* epoch 13 ********* test accuracy for mode 0:0.0225 test loss: 426.437
122000: ********* epoch 13 ********* test accuracy for mode 1:0.0345 test loss: 419.288
122000: ********* epoch 13 ********* test accuracy for mode 2:0.031 test loss: 266.007
122000: ********* epoch 13 ********* test accuracy for mode 24:0.245 test loss: 269.921
122000: ********* epoch 13 ********* test accuracy for mode 25:0.272 test loss: 245.828
122000: ********* epoch 13 ********* test accuracy for mode 26:0.5405 test loss: 156.251
122000: ********* epoch 13 ********* test accuracy for mode 27:0.2355 test loss: 269.3
122000: ********* epoch 13 ********* test accuracy for mode 28:0.2485 test loss: 265.251
122000: ********* epoch 13 ********* test accuracy for mode 29:0.29 test loss: 258.322
122000: ********* epoch 13 ********* test accuracy for mode 30:0.2295 test loss: 247.711
122000: ********* epoch 13 ********* test accuracy for mode 31:0.1725 test loss: 249.293
122000: ********* epoch 13 ********* test accuracy for mode 32:0.2705 test loss: 227.23
122000: ********* epoch 13 ********* test accuracy for mode 33:0.2945 test loss: 230.286
122000: ********* epoch 13 ********* test accuracy for mode 34:0.253 test loss: 237.889
122000: ********* epoch 13 ********* test accuracy for mode 35:0.0425 test loss: 429.329
122000: ********* epoch 13 ********* test accuracy for mode 36:0.082 test loss: 477.722
122010: accuracy:0.38 loss: 201.813 (lr:0.0001)
122020: accuracy:0.33 loss: 198.442 (lr:0.0001)
122030: accuracy:0.32 loss: 192.672 (lr:0.0001)
122040: accuracy:0.38 loss: 198.477 (lr:0.0001)
122050: accuracy:0.38 loss: 199.031 (lr:0.0001)
122060: accuracy:0.3 loss: 220.292 (lr:0.0001)
122070: accuracy:0.29 loss: 222.629 (lr:0.0001)
122080: accuracy:0.3 loss: 216.622 (lr:0.0001)
122090: accuracy:0.38 loss: 208.721 (lr:0.0001)
122100: accuracy:0.36 loss: 229.679 (lr:0.0001)
122110: accuracy:0.32 loss: 221.38 (lr:0.0001)
122120: accuracy:0.4 loss: 195.088 (lr:0.0001)
122130: accuracy:0.38 loss: 216.642 (lr:0.0001)
122140: accuracy:0.31 loss: 235.633 (lr:0.0001)
122150: accuracy:0.32 loss: 213.232 (lr:0.0001)
122160: accuracy:0.35 loss: 201.265 (lr:0.0001)
122170: accuracy:0.32 loss: 222.929 (lr:0.0001)
122180: accuracy:0.35 loss: 212.044 (lr:0.0001)
122190: accuracy:0.27 loss: 231.269 (lr:0.0001)
122200: accuracy:0.38 loss: 206.929 (lr:0.0001)
122210: accuracy:0.38 loss: 215.953 (lr:0.0001)
122220: accuracy:0.44 loss: 200.626 (lr:0.0001)
122230: accuracy:0.24 loss: 222.538 (lr:0.0001)
122240: accuracy:0.38 loss: 200.99 (lr:0.0001)
122250: accuracy:0.34 loss: 211.331 (lr:0.0001)
122260: accuracy:0.34 loss: 200.171 (lr:0.0001)
122270: accuracy:0.27 loss: 226.541 (lr:0.0001)
122280: accuracy:0.34 loss: 216.447 (lr:0.0001)
122290: accuracy:0.36 loss: 219.679 (lr:0.0001)
122300: accuracy:0.4 loss: 202.968 (lr:0.0001)
122310: accuracy:0.35 loss: 203.136 (lr:0.0001)
122320: accuracy:0.33 loss: 205.981 (lr:0.0001)
122330: accuracy:0.34 loss: 208.207 (lr:0.0001)
122340: accuracy:0.38 loss: 197.457 (lr:0.0001)
122350: accuracy:0.35 loss: 216.5 (lr:0.0001)
122360: accuracy:0.27 loss: 218.067 (lr:0.0001)
122370: accuracy:0.29 loss: 212.302 (lr:0.0001)
122380: accuracy:0.31 loss: 205.082 (lr:0.0001)
122390: accuracy:0.35 loss: 196.363 (lr:0.0001)
122400: accuracy:0.37 loss: 199.385 (lr:0.0001)
122410: accuracy:0.43 loss: 198.258 (lr:0.0001)
122420: accuracy:0.29 loss: 222.934 (lr:0.0001)
122430: accuracy:0.28 loss: 219.679 (lr:0.0001)
122440: accuracy:0.25 loss: 218.695 (lr:0.0001)
122450: accuracy:0.45 loss: 186.899 (lr:0.0001)
122460: accuracy:0.29 loss: 221.803 (lr:0.0001)
122470: accuracy:0.34 loss: 211.559 (lr:0.0001)
122480: accuracy:0.38 loss: 211.694 (lr:0.0001)
122490: accuracy:0.31 loss: 219.712 (lr:0.0001)
122500: accuracy:0.33 loss: 225.422 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
122500: ********* epoch 13 ********* test accuracy for all:0.253473 test loss: 254.024
122500: ********* epoch 13 ********* test accuracy for mode 0:0.016 test loss: 425.887
122500: ********* epoch 13 ********* test accuracy for mode 1:0.0405 test loss: 412.587
122500: ********* epoch 13 ********* test accuracy for mode 2:0.047 test loss: 259.771
122500: ********* epoch 13 ********* test accuracy for mode 24:0.238 test loss: 272.062
122500: ********* epoch 13 ********* test accuracy for mode 25:0.2825 test loss: 250.006
122500: ********* epoch 13 ********* test accuracy for mode 26:0.431 test loss: 164.901
122500: ********* epoch 13 ********* test accuracy for mode 27:0.248 test loss: 267.378
122500: ********* epoch 13 ********* test accuracy for mode 28:0.2705 test loss: 261.283
122500: ********* epoch 13 ********* test accuracy for mode 29:0.302 test loss: 257.214
122500: ********* epoch 13 ********* test accuracy for mode 30:0.1945 test loss: 251.189
122500: ********* epoch 13 ********* test accuracy for mode 31:0.262 test loss: 244.827
122500: ********* epoch 13 ********* test accuracy for mode 32:0.1525 test loss: 241.081
122500: ********* epoch 13 ********* test accuracy for mode 33:0.3085 test loss: 236.869
122500: ********* epoch 13 ********* test accuracy for mode 34:0.223 test loss: 241.65
122500: ********* epoch 13 ********* test accuracy for mode 35:0.0615 test loss: 423.021
122500: ********* epoch 13 ********* test accuracy for mode 36:0.124 test loss: 450.671
122510: accuracy:0.29 loss: 228.129 (lr:0.0001)
122520: accuracy:0.37 loss: 200.914 (lr:0.0001)
122530: accuracy:0.26 loss: 230.419 (lr:0.0001)
122540: accuracy:0.4 loss: 185.514 (lr:0.0001)
122550: accuracy:0.32 loss: 218.906 (lr:0.0001)
122560: accuracy:0.29 loss: 211.253 (lr:0.0001)
122570: accuracy:0.28 loss: 204.203 (lr:0.0001)
122580: accuracy:0.32 loss: 226.733 (lr:0.0001)
122590: accuracy:0.32 loss: 192.484 (lr:0.0001)
122600: accuracy:0.4 loss: 199.961 (lr:0.0001)
122610: accuracy:0.34 loss: 211.397 (lr:0.0001)
122620: accuracy:0.39 loss: 208.821 (lr:0.0001)
122630: accuracy:0.29 loss: 211.719 (lr:0.0001)
122640: accuracy:0.37 loss: 207.36 (lr:0.0001)
122650: accuracy:0.33 loss: 196.969 (lr:0.0001)
122660: accuracy:0.34 loss: 230.368 (lr:0.0001)
122670: accuracy:0.27 loss: 233.823 (lr:0.0001)
122680: accuracy:0.41 loss: 215.326 (lr:0.0001)
122690: accuracy:0.36 loss: 218.097 (lr:0.0001)
122700: accuracy:0.35 loss: 218.212 (lr:0.0001)
122710: accuracy:0.34 loss: 203.565 (lr:0.0001)
122720: accuracy:0.33 loss: 227.53 (lr:0.0001)
122730: accuracy:0.27 loss: 224.316 (lr:0.0001)
122740: accuracy:0.29 loss: 204.163 (lr:0.0001)
122750: accuracy:0.41 loss: 194.391 (lr:0.0001)
122760: accuracy:0.31 loss: 215.952 (lr:0.0001)
122770: accuracy:0.28 loss: 213.521 (lr:0.0001)
122780: accuracy:0.37 loss: 200.704 (lr:0.0001)
122790: accuracy:0.43 loss: 202.06 (lr:0.0001)
122800: accuracy:0.27 loss: 203.911 (lr:0.0001)
122810: accuracy:0.38 loss: 203.34 (lr:0.0001)
122820: accuracy:0.32 loss: 208.835 (lr:0.0001)
122830: accuracy:0.45 loss: 187.561 (lr:0.0001)
122840: accuracy:0.34 loss: 201.544 (lr:0.0001)
122850: accuracy:0.35 loss: 207.856 (lr:0.0001)
122860: accuracy:0.35 loss: 216.945 (lr:0.0001)
122870: accuracy:0.3 loss: 209.859 (lr:0.0001)
122880: accuracy:0.38 loss: 199.277 (lr:0.0001)
122890: accuracy:0.32 loss: 227.288 (lr:0.0001)
122900: accuracy:0.37 loss: 207.343 (lr:0.0001)
122910: accuracy:0.38 loss: 199.108 (lr:0.0001)
122920: accuracy:0.36 loss: 216.952 (lr:0.0001)
122930: accuracy:0.36 loss: 197.743 (lr:0.0001)
122940: accuracy:0.36 loss: 207.942 (lr:0.0001)
122950: accuracy:0.29 loss: 213.48 (lr:0.0001)
122960: accuracy:0.29 loss: 217.874 (lr:0.0001)
122970: accuracy:0.35 loss: 213.838 (lr:0.0001)
122980: accuracy:0.29 loss: 216.2 (lr:0.0001)
122990: accuracy:0.35 loss: 213.954 (lr:0.0001)
123000: accuracy:0.28 loss: 226.332 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
123000: ********* epoch 13 ********* test accuracy for all:0.251527 test loss: 258.19
123000: ********* epoch 13 ********* test accuracy for mode 0:0.017 test loss: 439.836
123000: ********* epoch 13 ********* test accuracy for mode 1:0.0415 test loss: 423.689
123000: ********* epoch 13 ********* test accuracy for mode 2:0.036 test loss: 264.763
123000: ********* epoch 13 ********* test accuracy for mode 24:0.2305 test loss: 273.895
123000: ********* epoch 13 ********* test accuracy for mode 25:0.304 test loss: 249.372
123000: ********* epoch 13 ********* test accuracy for mode 26:0.459 test loss: 158.459
123000: ********* epoch 13 ********* test accuracy for mode 27:0.2355 test loss: 270.418
123000: ********* epoch 13 ********* test accuracy for mode 28:0.268 test loss: 267.92
123000: ********* epoch 13 ********* test accuracy for mode 29:0.243 test loss: 271.073
123000: ********* epoch 13 ********* test accuracy for mode 30:0.227 test loss: 253.776
123000: ********* epoch 13 ********* test accuracy for mode 31:0.2225 test loss: 247.923
123000: ********* epoch 13 ********* test accuracy for mode 32:0.2255 test loss: 237.622
123000: ********* epoch 13 ********* test accuracy for mode 33:0.2815 test loss: 238.38
123000: ********* epoch 13 ********* test accuracy for mode 34:0.2045 test loss: 243.057
123000: ********* epoch 13 ********* test accuracy for mode 35:0.04 test loss: 444.484
123000: ********* epoch 13 ********* test accuracy for mode 36:0.1825 test loss: 439.117
123010: accuracy:0.32 loss: 219.464 (lr:0.0001)
123020: accuracy:0.33 loss: 204.052 (lr:0.0001)
123030: accuracy:0.32 loss: 200.921 (lr:0.0001)
123040: accuracy:0.39 loss: 186.294 (lr:0.0001)
123050: accuracy:0.35 loss: 208.822 (lr:0.0001)
123060: accuracy:0.35 loss: 205.927 (lr:0.0001)
123070: accuracy:0.36 loss: 192.919 (lr:0.0001)
123080: accuracy:0.3 loss: 215.251 (lr:0.0001)
123090: accuracy:0.4 loss: 207.984 (lr:0.0001)
123100: accuracy:0.41 loss: 215.173 (lr:0.0001)
123110: accuracy:0.33 loss: 204.453 (lr:0.0001)
123120: accuracy:0.26 loss: 233.677 (lr:0.0001)
123130: accuracy:0.31 loss: 210.409 (lr:0.0001)
123140: accuracy:0.38 loss: 220.914 (lr:0.0001)
123150: accuracy:0.25 loss: 222.779 (lr:0.0001)
123160: accuracy:0.35 loss: 211.134 (lr:0.0001)
123170: accuracy:0.37 loss: 204.859 (lr:0.0001)
123180: accuracy:0.35 loss: 197.553 (lr:0.0001)
123190: accuracy:0.27 loss: 217.16 (lr:0.0001)
123200: accuracy:0.32 loss: 227.32 (lr:0.0001)
123210: accuracy:0.48 loss: 189.332 (lr:0.0001)
123220: accuracy:0.34 loss: 211.109 (lr:0.0001)
123230: accuracy:0.33 loss: 219.722 (lr:0.0001)
123240: accuracy:0.29 loss: 209.413 (lr:0.0001)
123250: accuracy:0.42 loss: 200.359 (lr:0.0001)
123260: accuracy:0.38 loss: 199.604 (lr:0.0001)
123270: accuracy:0.23 loss: 229.712 (lr:0.0001)
123280: accuracy:0.31 loss: 204.565 (lr:0.0001)
123290: accuracy:0.45 loss: 215.285 (lr:0.0001)
123300: accuracy:0.22 loss: 226.88 (lr:0.0001)
123310: accuracy:0.29 loss: 219.885 (lr:0.0001)
123320: accuracy:0.31 loss: 214.057 (lr:0.0001)
123330: accuracy:0.35 loss: 215.956 (lr:0.0001)
123340: accuracy:0.31 loss: 218.831 (lr:0.0001)
123350: accuracy:0.37 loss: 209.245 (lr:0.0001)
123360: accuracy:0.36 loss: 192.489 (lr:0.0001)
123370: accuracy:0.31 loss: 215.399 (lr:0.0001)
123380: accuracy:0.33 loss: 228.213 (lr:0.0001)
123390: accuracy:0.37 loss: 200.382 (lr:0.0001)
123400: accuracy:0.36 loss: 210.473 (lr:0.0001)
123410: accuracy:0.37 loss: 209.81 (lr:0.0001)
123420: accuracy:0.37 loss: 204.048 (lr:0.0001)
123430: accuracy:0.32 loss: 212.009 (lr:0.0001)
123440: accuracy:0.39 loss: 204.0 (lr:0.0001)
123450: accuracy:0.37 loss: 214.683 (lr:0.0001)
123460: accuracy:0.36 loss: 226.778 (lr:0.0001)
123470: accuracy:0.39 loss: 180.831 (lr:0.0001)
123480: accuracy:0.37 loss: 221.269 (lr:0.0001)
123490: accuracy:0.4 loss: 188.555 (lr:0.0001)
123500: accuracy:0.34 loss: 207.402 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
123500: ********* epoch 13 ********* test accuracy for all:0.252149 test loss: 256.539
123500: ********* epoch 13 ********* test accuracy for mode 0:0.03 test loss: 434.365
123500: ********* epoch 13 ********* test accuracy for mode 1:0.0345 test loss: 426.72
123500: ********* epoch 13 ********* test accuracy for mode 2:0.0325 test loss: 261.184
123500: ********* epoch 13 ********* test accuracy for mode 24:0.238 test loss: 270.421
123500: ********* epoch 13 ********* test accuracy for mode 25:0.3395 test loss: 238.971
123500: ********* epoch 13 ********* test accuracy for mode 26:0.373 test loss: 170.342
123500: ********* epoch 13 ********* test accuracy for mode 27:0.2665 test loss: 258.86
123500: ********* epoch 13 ********* test accuracy for mode 28:0.298 test loss: 253.702
123500: ********* epoch 13 ********* test accuracy for mode 29:0.28 test loss: 259.458
123500: ********* epoch 13 ********* test accuracy for mode 30:0.2015 test loss: 248.488
123500: ********* epoch 13 ********* test accuracy for mode 31:0.2425 test loss: 245.139
123500: ********* epoch 13 ********* test accuracy for mode 32:0.186 test loss: 239.845
123500: ********* epoch 13 ********* test accuracy for mode 33:0.296 test loss: 237.576
123500: ********* epoch 13 ********* test accuracy for mode 34:0.1955 test loss: 245.222
123500: ********* epoch 13 ********* test accuracy for mode 35:0.055 test loss: 444.962
123500: ********* epoch 13 ********* test accuracy for mode 36:0.093 test loss: 472.776
123510: accuracy:0.27 loss: 228.834 (lr:0.0001)
123520: accuracy:0.39 loss: 198.649 (lr:0.0001)
123530: accuracy:0.38 loss: 200.886 (lr:0.0001)
123540: accuracy:0.36 loss: 208.052 (lr:0.0001)
123550: accuracy:0.38 loss: 207.315 (lr:0.0001)
123560: accuracy:0.39 loss: 199.456 (lr:0.0001)
123570: accuracy:0.27 loss: 227.91 (lr:0.0001)
123580: accuracy:0.39 loss: 206.902 (lr:0.0001)
123590: accuracy:0.33 loss: 198.464 (lr:0.0001)
123600: accuracy:0.33 loss: 224.102 (lr:0.0001)
123610: accuracy:0.33 loss: 190.849 (lr:0.0001)
123620: accuracy:0.36 loss: 199.934 (lr:0.0001)
123630: accuracy:0.4 loss: 206.855 (lr:0.0001)
123640: accuracy:0.28 loss: 209.557 (lr:0.0001)
123650: accuracy:0.33 loss: 205.948 (lr:0.0001)
123660: accuracy:0.3 loss: 223.127 (lr:0.0001)
123670: accuracy:0.33 loss: 218.511 (lr:0.0001)
123680: accuracy:0.36 loss: 205.19 (lr:0.0001)
123690: accuracy:0.27 loss: 225.953 (lr:0.0001)
123700: accuracy:0.39 loss: 215.573 (lr:0.0001)
123710: accuracy:0.37 loss: 211.242 (lr:0.0001)
123720: accuracy:0.32 loss: 225.687 (lr:0.0001)
123730: accuracy:0.41 loss: 207.284 (lr:0.0001)
123740: accuracy:0.35 loss: 203.663 (lr:0.0001)
123750: accuracy:0.32 loss: 214.407 (lr:0.0001)
123760: accuracy:0.36 loss: 207.502 (lr:0.0001)
123770: accuracy:0.28 loss: 219.815 (lr:0.0001)
123780: accuracy:0.4 loss: 215.616 (lr:0.0001)
123790: accuracy:0.3 loss: 212.469 (lr:0.0001)
123800: accuracy:0.33 loss: 224.558 (lr:0.0001)
123810: accuracy:0.31 loss: 218.434 (lr:0.0001)
123820: accuracy:0.35 loss: 216.374 (lr:0.0001)
123830: accuracy:0.31 loss: 226.669 (lr:0.0001)
123840: accuracy:0.38 loss: 206.07 (lr:0.0001)
123850: accuracy:0.35 loss: 195.522 (lr:0.0001)
123860: accuracy:0.36 loss: 226.405 (lr:0.0001)
123870: accuracy:0.37 loss: 243.155 (lr:0.0001)
123880: accuracy:0.38 loss: 209.052 (lr:0.0001)
123890: accuracy:0.31 loss: 219.992 (lr:0.0001)
123900: accuracy:0.39 loss: 196.123 (lr:0.0001)
123910: accuracy:0.31 loss: 198.683 (lr:0.0001)
123920: accuracy:0.3 loss: 215.383 (lr:0.0001)
123930: accuracy:0.31 loss: 223.606 (lr:0.0001)
123940: accuracy:0.3 loss: 205.252 (lr:0.0001)
123950: accuracy:0.36 loss: 204.657 (lr:0.0001)
123960: accuracy:0.35 loss: 212.332 (lr:0.0001)
123970: accuracy:0.23 loss: 226.591 (lr:0.0001)
123980: accuracy:0.3 loss: 220.504 (lr:0.0001)
123990: accuracy:0.34 loss: 189.024 (lr:0.0001)
124000: accuracy:0.35 loss: 204.723 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
124000: ********* epoch 13 ********* test accuracy for all:0.258257 test loss: 253.197
124000: ********* epoch 13 ********* test accuracy for mode 0:0.033 test loss: 420.236
124000: ********* epoch 13 ********* test accuracy for mode 1:0.0395 test loss: 414.407
124000: ********* epoch 13 ********* test accuracy for mode 2:0.0295 test loss: 269.908
124000: ********* epoch 13 ********* test accuracy for mode 24:0.273 test loss: 261.185
124000: ********* epoch 13 ********* test accuracy for mode 25:0.256 test loss: 249.253
124000: ********* epoch 13 ********* test accuracy for mode 26:0.469 test loss: 160.503
124000: ********* epoch 13 ********* test accuracy for mode 27:0.224 test loss: 269.026
124000: ********* epoch 13 ********* test accuracy for mode 28:0.3295 test loss: 247.029
124000: ********* epoch 13 ********* test accuracy for mode 29:0.2685 test loss: 256.869
124000: ********* epoch 13 ********* test accuracy for mode 30:0.245 test loss: 247.687
124000: ********* epoch 13 ********* test accuracy for mode 31:0.1785 test loss: 254.393
124000: ********* epoch 13 ********* test accuracy for mode 32:0.2105 test loss: 239.954
124000: ********* epoch 13 ********* test accuracy for mode 33:0.3065 test loss: 240.271
124000: ********* epoch 13 ********* test accuracy for mode 34:0.1615 test loss: 248.275
124000: ********* epoch 13 ********* test accuracy for mode 35:0.071 test loss: 436.722
124000: ********* epoch 13 ********* test accuracy for mode 36:0.137 test loss: 449.78
124010: accuracy:0.36 loss: 197.326 (lr:0.0001)
124020: accuracy:0.43 loss: 202.76 (lr:0.0001)
124030: accuracy:0.35 loss: 213.484 (lr:0.0001)
124040: accuracy:0.44 loss: 192.014 (lr:0.0001)
124050: accuracy:0.34 loss: 224.544 (lr:0.0001)
124060: accuracy:0.31 loss: 205.395 (lr:0.0001)
124070: accuracy:0.38 loss: 189.277 (lr:0.0001)
124080: accuracy:0.33 loss: 220.775 (lr:0.0001)
124090: accuracy:0.29 loss: 213.857 (lr:0.0001)
124100: accuracy:0.36 loss: 198.833 (lr:0.0001)
124110: accuracy:0.38 loss: 202.207 (lr:0.0001)
124120: accuracy:0.3 loss: 214.358 (lr:0.0001)
124130: accuracy:0.26 loss: 209.454 (lr:0.0001)
124140: accuracy:0.26 loss: 215.823 (lr:0.0001)
124150: accuracy:0.41 loss: 208.848 (lr:0.0001)
124160: accuracy:0.37 loss: 220.125 (lr:0.0001)
124170: accuracy:0.3 loss: 206.061 (lr:0.0001)
124180: accuracy:0.44 loss: 197.657 (lr:0.0001)
124190: accuracy:0.29 loss: 219.884 (lr:0.0001)
124200: accuracy:0.37 loss: 206.397 (lr:0.0001)
124210: accuracy:0.26 loss: 210.146 (lr:0.0001)
124220: accuracy:0.29 loss: 213.772 (lr:0.0001)
124230: accuracy:0.38 loss: 207.348 (lr:0.0001)
124240: accuracy:0.36 loss: 216.537 (lr:0.0001)
124250: accuracy:0.26 loss: 204.22 (lr:0.0001)
124260: accuracy:0.37 loss: 220.165 (lr:0.0001)
124270: accuracy:0.33 loss: 207.792 (lr:0.0001)
124280: accuracy:0.33 loss: 199.407 (lr:0.0001)
124290: accuracy:0.32 loss: 206.999 (lr:0.0001)
124300: accuracy:0.37 loss: 217.885 (lr:0.0001)
124310: accuracy:0.38 loss: 199.425 (lr:0.0001)
124320: accuracy:0.37 loss: 210.716 (lr:0.0001)
124330: accuracy:0.35 loss: 209.207 (lr:0.0001)
124340: accuracy:0.36 loss: 208.93 (lr:0.0001)
124350: accuracy:0.35 loss: 217.254 (lr:0.0001)
124360: accuracy:0.28 loss: 241.265 (lr:0.0001)
124370: accuracy:0.29 loss: 227.849 (lr:0.0001)
124380: accuracy:0.3 loss: 214.391 (lr:0.0001)
124390: accuracy:0.27 loss: 225.079 (lr:0.0001)
124400: accuracy:0.29 loss: 216.972 (lr:0.0001)
124410: accuracy:0.34 loss: 211.583 (lr:0.0001)
124420: accuracy:0.28 loss: 216.402 (lr:0.0001)
124430: accuracy:0.37 loss: 225.485 (lr:0.0001)
124440: accuracy:0.25 loss: 208.829 (lr:0.0001)
124450: accuracy:0.35 loss: 207.874 (lr:0.0001)
124460: accuracy:0.31 loss: 196.056 (lr:0.0001)
124470: accuracy:0.27 loss: 216.714 (lr:0.0001)
124480: accuracy:0.33 loss: 235.36 (lr:0.0001)
124490: accuracy:0.32 loss: 209.624 (lr:0.0001)
124500: accuracy:0.28 loss: 236.569 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
124500: ********* epoch 13 ********* test accuracy for all:0.258068 test loss: 253.201
124500: ********* epoch 13 ********* test accuracy for mode 0:0.024 test loss: 427.501
124500: ********* epoch 13 ********* test accuracy for mode 1:0.0425 test loss: 414.909
124500: ********* epoch 13 ********* test accuracy for mode 2:0.054 test loss: 266.863
124500: ********* epoch 13 ********* test accuracy for mode 24:0.288 test loss: 256.307
124500: ********* epoch 13 ********* test accuracy for mode 25:0.2975 test loss: 236.487
124500: ********* epoch 13 ********* test accuracy for mode 26:0.4875 test loss: 156.284
124500: ********* epoch 13 ********* test accuracy for mode 27:0.257 test loss: 256.88
124500: ********* epoch 13 ********* test accuracy for mode 28:0.3045 test loss: 251.979
124500: ********* epoch 13 ********* test accuracy for mode 29:0.2725 test loss: 257.859
124500: ********* epoch 13 ********* test accuracy for mode 30:0.224 test loss: 245.342
124500: ********* epoch 13 ********* test accuracy for mode 31:0.2205 test loss: 248.295
124500: ********* epoch 13 ********* test accuracy for mode 32:0.2015 test loss: 240.089
124500: ********* epoch 13 ********* test accuracy for mode 33:0.2845 test loss: 242.924
124500: ********* epoch 13 ********* test accuracy for mode 34:0.1455 test loss: 251.276
124500: ********* epoch 13 ********* test accuracy for mode 35:0.0485 test loss: 430.326
124500: ********* epoch 13 ********* test accuracy for mode 36:0.102 test loss: 463.622
124510: accuracy:0.39 loss: 207.271 (lr:0.0001)
124520: accuracy:0.39 loss: 201.716 (lr:0.0001)
124530: accuracy:0.39 loss: 179.777 (lr:0.0001)
124540: accuracy:0.34 loss: 204.913 (lr:0.0001)
124550: accuracy:0.33 loss: 212.831 (lr:0.0001)
124560: accuracy:0.33 loss: 211.832 (lr:0.0001)
124570: accuracy:0.31 loss: 218.245 (lr:0.0001)
124580: accuracy:0.38 loss: 212.038 (lr:0.0001)
124590: accuracy:0.25 loss: 231.106 (lr:0.0001)
124600: accuracy:0.43 loss: 196.554 (lr:0.0001)
124610: accuracy:0.4 loss: 212.666 (lr:0.0001)
124620: accuracy:0.4 loss: 202.151 (lr:0.0001)
124630: accuracy:0.4 loss: 186.738 (lr:0.0001)
124640: accuracy:0.28 loss: 215.871 (lr:0.0001)
124650: accuracy:0.24 loss: 216.456 (lr:0.0001)
124660: accuracy:0.36 loss: 198.797 (lr:0.0001)
124670: accuracy:0.35 loss: 207.833 (lr:0.0001)
124680: accuracy:0.42 loss: 207.965 (lr:0.0001)
124690: accuracy:0.28 loss: 211.336 (lr:0.0001)
124700: accuracy:0.36 loss: 211.572 (lr:0.0001)
124710: accuracy:0.36 loss: 199.856 (lr:0.0001)
124720: accuracy:0.41 loss: 203.499 (lr:0.0001)
124730: accuracy:0.24 loss: 245.015 (lr:0.0001)
124740: accuracy:0.33 loss: 208.95 (lr:0.0001)
124750: accuracy:0.3 loss: 205.178 (lr:0.0001)
124760: accuracy:0.31 loss: 202.052 (lr:0.0001)
124770: accuracy:0.37 loss: 207.753 (lr:0.0001)
124780: accuracy:0.31 loss: 222.125 (lr:0.0001)
124790: accuracy:0.37 loss: 210.668 (lr:0.0001)
124800: accuracy:0.38 loss: 205.738 (lr:0.0001)
124810: accuracy:0.33 loss: 205.076 (lr:0.0001)
124820: accuracy:0.39 loss: 200.575 (lr:0.0001)
124830: accuracy:0.33 loss: 228.383 (lr:0.0001)
124840: accuracy:0.37 loss: 215.312 (lr:0.0001)
124850: accuracy:0.34 loss: 205.372 (lr:0.0001)
124860: accuracy:0.29 loss: 230.418 (lr:0.0001)
124870: accuracy:0.41 loss: 205.297 (lr:0.0001)
124880: accuracy:0.37 loss: 188.549 (lr:0.0001)
124890: accuracy:0.34 loss: 231.532 (lr:0.0001)
124900: accuracy:0.28 loss: 210.765 (lr:0.0001)
124910: accuracy:0.34 loss: 206.316 (lr:0.0001)
124920: accuracy:0.28 loss: 214.596 (lr:0.0001)
124930: accuracy:0.42 loss: 212.148 (lr:0.0001)
124940: accuracy:0.36 loss: 216.872 (lr:0.0001)
124950: accuracy:0.26 loss: 232.81 (lr:0.0001)
124960: accuracy:0.31 loss: 209.229 (lr:0.0001)
124970: accuracy:0.26 loss: 241.281 (lr:0.0001)
124980: accuracy:0.4 loss: 202.656 (lr:0.0001)
124990: accuracy:0.31 loss: 224.297 (lr:0.0001)
125000: accuracy:0.33 loss: 207.146 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
125000: ********* epoch 13 ********* test accuracy for all:0.254378 test loss: 256.713
125000: ********* epoch 13 ********* test accuracy for mode 0:0.0265 test loss: 428.937
125000: ********* epoch 13 ********* test accuracy for mode 1:0.035 test loss: 417.884
125000: ********* epoch 13 ********* test accuracy for mode 2:0.0475 test loss: 264.8
125000: ********* epoch 13 ********* test accuracy for mode 24:0.2555 test loss: 269.261
125000: ********* epoch 13 ********* test accuracy for mode 25:0.325 test loss: 244.002
125000: ********* epoch 13 ********* test accuracy for mode 26:0.4145 test loss: 169.49
125000: ********* epoch 13 ********* test accuracy for mode 27:0.2515 test loss: 267.289
125000: ********* epoch 13 ********* test accuracy for mode 28:0.2925 test loss: 261.741
125000: ********* epoch 13 ********* test accuracy for mode 29:0.2685 test loss: 272.883
125000: ********* epoch 13 ********* test accuracy for mode 30:0.2035 test loss: 261.347
125000: ********* epoch 13 ********* test accuracy for mode 31:0.1845 test loss: 263.667
125000: ********* epoch 13 ********* test accuracy for mode 32:0.209 test loss: 248.327
125000: ********* epoch 13 ********* test accuracy for mode 33:0.2755 test loss: 245.752
125000: ********* epoch 13 ********* test accuracy for mode 34:0.1895 test loss: 248.077
125000: ********* epoch 13 ********* test accuracy for mode 35:0.0595 test loss: 430.91
125000: ********* epoch 13 ********* test accuracy for mode 36:0.046 test loss: 512.158
125010: accuracy:0.34 loss: 217.734 (lr:0.0001)
125020: accuracy:0.39 loss: 207.32 (lr:0.0001)
125030: accuracy:0.34 loss: 206.713 (lr:0.0001)
125040: accuracy:0.36 loss: 217.314 (lr:0.0001)
125050: accuracy:0.3 loss: 216.345 (lr:0.0001)
125060: accuracy:0.33 loss: 216.72 (lr:0.0001)
125070: accuracy:0.46 loss: 189.623 (lr:0.0001)
125080: accuracy:0.34 loss: 201.055 (lr:0.0001)
125090: accuracy:0.33 loss: 229.138 (lr:0.0001)
125100: accuracy:0.4 loss: 202.074 (lr:0.0001)
125110: accuracy:0.28 loss: 227.979 (lr:0.0001)
125120: accuracy:0.38 loss: 207.134 (lr:0.0001)
125130: accuracy:0.3 loss: 229.702 (lr:0.0001)
125140: accuracy:0.39 loss: 206.248 (lr:0.0001)
125150: accuracy:0.43 loss: 197.721 (lr:0.0001)
125160: accuracy:0.32 loss: 211.148 (lr:0.0001)
125170: accuracy:0.31 loss: 199.802 (lr:0.0001)
125180: accuracy:0.32 loss: 203.74 (lr:0.0001)
125190: accuracy:0.41 loss: 204.653 (lr:0.0001)
125200: accuracy:0.27 loss: 228.228 (lr:0.0001)
125210: accuracy:0.35 loss: 208.798 (lr:0.0001)
125220: accuracy:0.38 loss: 181.814 (lr:0.0001)
125230: accuracy:0.24 loss: 219.999 (lr:0.0001)
125240: accuracy:0.36 loss: 208.017 (lr:0.0001)
125250: accuracy:0.39 loss: 213.035 (lr:0.0001)
125260: accuracy:0.35 loss: 217.858 (lr:0.0001)
125270: accuracy:0.34 loss: 225.476 (lr:0.0001)
125280: accuracy:0.36 loss: 202.688 (lr:0.0001)
125290: accuracy:0.32 loss: 214.676 (lr:0.0001)
125300: accuracy:0.37 loss: 222.651 (lr:0.0001)
125310: accuracy:0.35 loss: 200.491 (lr:0.0001)
125320: accuracy:0.28 loss: 225.549 (lr:0.0001)
125330: accuracy:0.35 loss: 197.062 (lr:0.0001)
125340: accuracy:0.43 loss: 192.446 (lr:0.0001)
125350: accuracy:0.33 loss: 195.238 (lr:0.0001)
125360: accuracy:0.33 loss: 212.072 (lr:0.0001)
125370: accuracy:0.29 loss: 209.182 (lr:0.0001)
125380: accuracy:0.29 loss: 221.589 (lr:0.0001)
125390: accuracy:0.39 loss: 207.677 (lr:0.0001)
125400: accuracy:0.37 loss: 209.71 (lr:0.0001)
125410: accuracy:0.4 loss: 203.732 (lr:0.0001)
125420: accuracy:0.34 loss: 200.175 (lr:0.0001)
125430: accuracy:0.29 loss: 219.517 (lr:0.0001)
125440: accuracy:0.4 loss: 188.987 (lr:0.0001)
125450: accuracy:0.36 loss: 214.61 (lr:0.0001)
125460: accuracy:0.33 loss: 221.133 (lr:0.0001)
125470: accuracy:0.42 loss: 185.036 (lr:0.0001)
125480: accuracy:0.36 loss: 205.344 (lr:0.0001)
125490: accuracy:0.27 loss: 227.165 (lr:0.0001)
125500: accuracy:0.27 loss: 226.211 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
125500: ********* epoch 13 ********* test accuracy for all:0.25423 test loss: 255.121
125500: ********* epoch 13 ********* test accuracy for mode 0:0.028 test loss: 422.603
125500: ********* epoch 13 ********* test accuracy for mode 1:0.0385 test loss: 416.033
125500: ********* epoch 13 ********* test accuracy for mode 2:0.043 test loss: 257.301
125500: ********* epoch 13 ********* test accuracy for mode 24:0.2395 test loss: 279.383
125500: ********* epoch 13 ********* test accuracy for mode 25:0.2555 test loss: 262.092
125500: ********* epoch 13 ********* test accuracy for mode 26:0.418 test loss: 169.624
125500: ********* epoch 13 ********* test accuracy for mode 27:0.2815 test loss: 260.128
125500: ********* epoch 13 ********* test accuracy for mode 28:0.273 test loss: 256.274
125500: ********* epoch 13 ********* test accuracy for mode 29:0.2805 test loss: 255.442
125500: ********* epoch 13 ********* test accuracy for mode 30:0.2615 test loss: 243.829
125500: ********* epoch 13 ********* test accuracy for mode 31:0.1975 test loss: 246.629
125500: ********* epoch 13 ********* test accuracy for mode 32:0.24 test loss: 234.105
125500: ********* epoch 13 ********* test accuracy for mode 33:0.2275 test loss: 237.205
125500: ********* epoch 13 ********* test accuracy for mode 34:0.3185 test loss: 234.404
125500: ********* epoch 13 ********* test accuracy for mode 35:0.073 test loss: 413.68
125500: ********* epoch 13 ********* test accuracy for mode 36:0.113 test loss: 434.107
125510: accuracy:0.36 loss: 225.591 (lr:0.0001)
125520: accuracy:0.28 loss: 218.007 (lr:0.0001)
125530: accuracy:0.32 loss: 214.038 (lr:0.0001)
125540: accuracy:0.31 loss: 218.01 (lr:0.0001)
125550: accuracy:0.3 loss: 215.733 (lr:0.0001)
125560: accuracy:0.3 loss: 222.612 (lr:0.0001)
125570: accuracy:0.3 loss: 215.954 (lr:0.0001)
125580: accuracy:0.31 loss: 229.708 (lr:0.0001)
125590: accuracy:0.42 loss: 190.865 (lr:0.0001)
125600: accuracy:0.36 loss: 225.284 (lr:0.0001)
125610: accuracy:0.31 loss: 206.78 (lr:0.0001)
125620: accuracy:0.3 loss: 228.028 (lr:0.0001)
125630: accuracy:0.45 loss: 192.663 (lr:0.0001)
125640: accuracy:0.38 loss: 206.988 (lr:0.0001)
125650: accuracy:0.41 loss: 185.678 (lr:0.0001)
125660: accuracy:0.29 loss: 215.97 (lr:0.0001)
125670: accuracy:0.35 loss: 210.912 (lr:0.0001)
125680: accuracy:0.4 loss: 194.392 (lr:0.0001)
125690: accuracy:0.4 loss: 213.684 (lr:0.0001)
125700: accuracy:0.34 loss: 217.506 (lr:0.0001)
125710: accuracy:0.35 loss: 220.065 (lr:0.0001)
125720: accuracy:0.26 loss: 217.331 (lr:0.0001)
125730: accuracy:0.28 loss: 223.007 (lr:0.0001)
125740: accuracy:0.36 loss: 207.083 (lr:0.0001)
125750: accuracy:0.33 loss: 207.489 (lr:0.0001)
125760: accuracy:0.34 loss: 217.224 (lr:0.0001)
125770: accuracy:0.39 loss: 187.06 (lr:0.0001)
125780: accuracy:0.3 loss: 220.515 (lr:0.0001)
125790: accuracy:0.29 loss: 217.744 (lr:0.0001)
125800: accuracy:0.44 loss: 195.09 (lr:0.0001)
125810: accuracy:0.33 loss: 214.467 (lr:0.0001)
125820: accuracy:0.3 loss: 232.966 (lr:0.0001)
125830: accuracy:0.37 loss: 215.802 (lr:0.0001)
125840: accuracy:0.31 loss: 216.183 (lr:0.0001)
125850: accuracy:0.4 loss: 190.573 (lr:0.0001)
125860: accuracy:0.29 loss: 221.537 (lr:0.0001)
125870: accuracy:0.31 loss: 236.314 (lr:0.0001)
125880: accuracy:0.42 loss: 226.962 (lr:0.0001)
125890: accuracy:0.35 loss: 214.052 (lr:0.0001)
125900: accuracy:0.33 loss: 210.886 (lr:0.0001)
125910: accuracy:0.37 loss: 203.26 (lr:0.0001)
125920: accuracy:0.23 loss: 220.455 (lr:0.0001)
125930: accuracy:0.37 loss: 206.365 (lr:0.0001)
125940: accuracy:0.33 loss: 206.799 (lr:0.0001)
125950: accuracy:0.25 loss: 236.829 (lr:0.0001)
125960: accuracy:0.29 loss: 218.948 (lr:0.0001)
125970: accuracy:0.38 loss: 197.892 (lr:0.0001)
125980: accuracy:0.35 loss: 206.169 (lr:0.0001)
125990: accuracy:0.33 loss: 223.247 (lr:0.0001)
126000: accuracy:0.38 loss: 210.914 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
126000: ********* epoch 13 ********* test accuracy for all:0.256514 test loss: 253.27
126000: ********* epoch 13 ********* test accuracy for mode 0:0.0195 test loss: 433.631
126000: ********* epoch 13 ********* test accuracy for mode 1:0.0375 test loss: 418.444
126000: ********* epoch 13 ********* test accuracy for mode 2:0.0445 test loss: 268.959
126000: ********* epoch 13 ********* test accuracy for mode 24:0.287 test loss: 252.621
126000: ********* epoch 13 ********* test accuracy for mode 25:0.3505 test loss: 233.258
126000: ********* epoch 13 ********* test accuracy for mode 26:0.372 test loss: 164.976
126000: ********* epoch 13 ********* test accuracy for mode 27:0.2515 test loss: 266.158
126000: ********* epoch 13 ********* test accuracy for mode 28:0.3 test loss: 251.478
126000: ********* epoch 13 ********* test accuracy for mode 29:0.269 test loss: 259.235
126000: ********* epoch 13 ********* test accuracy for mode 30:0.2555 test loss: 248.573
126000: ********* epoch 13 ********* test accuracy for mode 31:0.1885 test loss: 254.118
126000: ********* epoch 13 ********* test accuracy for mode 32:0.2125 test loss: 241.732
126000: ********* epoch 13 ********* test accuracy for mode 33:0.258 test loss: 244.149
126000: ********* epoch 13 ********* test accuracy for mode 34:0.1915 test loss: 248.669
126000: ********* epoch 13 ********* test accuracy for mode 35:0.0515 test loss: 431.494
126000: ********* epoch 13 ********* test accuracy for mode 36:0.0965 test loss: 470.669
126010: accuracy:0.33 loss: 198.786 (lr:0.0001)
126020: accuracy:0.37 loss: 190.846 (lr:0.0001)
126030: accuracy:0.38 loss: 202.275 (lr:0.0001)
126040: accuracy:0.27 loss: 225.614 (lr:0.0001)
126050: accuracy:0.35 loss: 208.496 (lr:0.0001)
126060: accuracy:0.38 loss: 206.053 (lr:0.0001)
126070: accuracy:0.32 loss: 203.033 (lr:0.0001)
126080: accuracy:0.4 loss: 201.28 (lr:0.0001)
126090: accuracy:0.32 loss: 207.785 (lr:0.0001)
126100: accuracy:0.26 loss: 246.662 (lr:0.0001)
126110: accuracy:0.42 loss: 194.345 (lr:0.0001)
126120: accuracy:0.25 loss: 224.559 (lr:0.0001)
126130: accuracy:0.27 loss: 247.515 (lr:0.0001)
126140: accuracy:0.31 loss: 202.189 (lr:0.0001)
126150: accuracy:0.36 loss: 188.715 (lr:0.0001)
126160: accuracy:0.39 loss: 200.635 (lr:0.0001)
126170: accuracy:0.4 loss: 211.697 (lr:0.0001)
126180: accuracy:0.35 loss: 207.42 (lr:0.0001)
126190: accuracy:0.33 loss: 223.526 (lr:0.0001)
126200: accuracy:0.36 loss: 231.966 (lr:0.0001)
126210: accuracy:0.24 loss: 229.514 (lr:0.0001)
126220: accuracy:0.37 loss: 184.003 (lr:0.0001)
126230: accuracy:0.33 loss: 211.483 (lr:0.0001)
126240: accuracy:0.36 loss: 205.315 (lr:0.0001)
126250: accuracy:0.33 loss: 214.561 (lr:0.0001)
126260: accuracy:0.33 loss: 219.427 (lr:0.0001)
126270: accuracy:0.3 loss: 198.67 (lr:0.0001)
126280: accuracy:0.33 loss: 220.811 (lr:0.0001)
126290: accuracy:0.29 loss: 220.861 (lr:0.0001)
126300: accuracy:0.37 loss: 204.184 (lr:0.0001)
126310: accuracy:0.35 loss: 209.659 (lr:0.0001)
126320: accuracy:0.39 loss: 211.86 (lr:0.0001)
126330: accuracy:0.34 loss: 213.685 (lr:0.0001)
126340: accuracy:0.3 loss: 208.101 (lr:0.0001)
126350: accuracy:0.34 loss: 228.124 (lr:0.0001)
126360: accuracy:0.33 loss: 205.884 (lr:0.0001)
126370: accuracy:0.38 loss: 190.899 (lr:0.0001)
126380: accuracy:0.34 loss: 209.405 (lr:0.0001)
126390: accuracy:0.36 loss: 221.963 (lr:0.0001)
126400: accuracy:0.33 loss: 217.444 (lr:0.0001)
126410: accuracy:0.35 loss: 224.135 (lr:0.0001)
126420: accuracy:0.28 loss: 222.531 (lr:0.0001)
126430: accuracy:0.34 loss: 211.799 (lr:0.0001)
126440: accuracy:0.41 loss: 203.902 (lr:0.0001)
126450: accuracy:0.33 loss: 195.197 (lr:0.0001)
126460: accuracy:0.35 loss: 211.346 (lr:0.0001)
126470: accuracy:0.3 loss: 202.237 (lr:0.0001)
126480: accuracy:0.3 loss: 236.594 (lr:0.0001)
126490: accuracy:0.4 loss: 200.928 (lr:0.0001)
126500: accuracy:0.35 loss: 213.491 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
126500: ********* epoch 14 ********* test accuracy for all:0.255568 test loss: 253.024
126500: ********* epoch 14 ********* test accuracy for mode 0:0.0315 test loss: 420.047
126500: ********* epoch 14 ********* test accuracy for mode 1:0.0425 test loss: 408.236
126500: ********* epoch 14 ********* test accuracy for mode 2:0.051 test loss: 267.889
126500: ********* epoch 14 ********* test accuracy for mode 24:0.2485 test loss: 270.206
126500: ********* epoch 14 ********* test accuracy for mode 25:0.2765 test loss: 242.993
126500: ********* epoch 14 ********* test accuracy for mode 26:0.494 test loss: 155.139
126500: ********* epoch 14 ********* test accuracy for mode 27:0.281 test loss: 251.779
126500: ********* epoch 14 ********* test accuracy for mode 28:0.2775 test loss: 257.513
126500: ********* epoch 14 ********* test accuracy for mode 29:0.2655 test loss: 261.54
126500: ********* epoch 14 ********* test accuracy for mode 30:0.2605 test loss: 253.274
126500: ********* epoch 14 ********* test accuracy for mode 31:0.17 test loss: 260.237
126500: ********* epoch 14 ********* test accuracy for mode 32:0.203 test loss: 245.467
126500: ********* epoch 14 ********* test accuracy for mode 33:0.278 test loss: 242.64
126500: ********* epoch 14 ********* test accuracy for mode 34:0.176 test loss: 250.322
126500: ********* epoch 14 ********* test accuracy for mode 35:0.0535 test loss: 412.641
126500: ********* epoch 14 ********* test accuracy for mode 36:0.0955 test loss: 450.667
126510: accuracy:0.37 loss: 194.811 (lr:0.0001)
126520: accuracy:0.38 loss: 197.267 (lr:0.0001)
126530: accuracy:0.38 loss: 214.751 (lr:0.0001)
126540: accuracy:0.4 loss: 190.481 (lr:0.0001)
126550: accuracy:0.44 loss: 197.551 (lr:0.0001)
126560: accuracy:0.39 loss: 203.597 (lr:0.0001)
126570: accuracy:0.31 loss: 216.959 (lr:0.0001)
126580: accuracy:0.27 loss: 218.621 (lr:0.0001)
126590: accuracy:0.32 loss: 222.879 (lr:0.0001)
126600: accuracy:0.34 loss: 216.295 (lr:0.0001)
126610: accuracy:0.36 loss: 214.664 (lr:0.0001)
126620: accuracy:0.44 loss: 205.652 (lr:0.0001)
126630: accuracy:0.27 loss: 238.943 (lr:0.0001)
126640: accuracy:0.31 loss: 221.379 (lr:0.0001)
126650: accuracy:0.37 loss: 201.296 (lr:0.0001)
126660: accuracy:0.37 loss: 216.779 (lr:0.0001)
126670: accuracy:0.37 loss: 192.018 (lr:0.0001)
126680: accuracy:0.32 loss: 214.762 (lr:0.0001)
126690: accuracy:0.28 loss: 212.729 (lr:0.0001)
126700: accuracy:0.37 loss: 200.072 (lr:0.0001)
126710: accuracy:0.42 loss: 192.869 (lr:0.0001)
126720: accuracy:0.27 loss: 232.185 (lr:0.0001)
126730: accuracy:0.32 loss: 197.499 (lr:0.0001)
126740: accuracy:0.4 loss: 180.22 (lr:0.0001)
126750: accuracy:0.36 loss: 201.36 (lr:0.0001)
126760: accuracy:0.4 loss: 197.619 (lr:0.0001)
126770: accuracy:0.39 loss: 209.72 (lr:0.0001)
126780: accuracy:0.42 loss: 174.5 (lr:0.0001)
126790: accuracy:0.34 loss: 203.091 (lr:0.0001)
126800: accuracy:0.32 loss: 224.477 (lr:0.0001)
126810: accuracy:0.31 loss: 195.06 (lr:0.0001)
126820: accuracy:0.35 loss: 214.82 (lr:0.0001)
126830: accuracy:0.34 loss: 200.991 (lr:0.0001)
126840: accuracy:0.38 loss: 204.289 (lr:0.0001)
126850: accuracy:0.26 loss: 208.818 (lr:0.0001)
126860: accuracy:0.37 loss: 206.633 (lr:0.0001)
126870: accuracy:0.39 loss: 186.433 (lr:0.0001)
126880: accuracy:0.35 loss: 203.552 (lr:0.0001)
126890: accuracy:0.36 loss: 199.989 (lr:0.0001)
126900: accuracy:0.42 loss: 188.79 (lr:0.0001)
126910: accuracy:0.42 loss: 192.395 (lr:0.0001)
126920: accuracy:0.32 loss: 204.445 (lr:0.0001)
126930: accuracy:0.34 loss: 205.834 (lr:0.0001)
126940: accuracy:0.38 loss: 198.883 (lr:0.0001)
126950: accuracy:0.42 loss: 175.177 (lr:0.0001)
126960: accuracy:0.33 loss: 219.265 (lr:0.0001)
126970: accuracy:0.38 loss: 218.734 (lr:0.0001)
126980: accuracy:0.39 loss: 187.043 (lr:0.0001)
126990: accuracy:0.33 loss: 219.154 (lr:0.0001)
127000: accuracy:0.38 loss: 205.813 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
127000: ********* epoch 14 ********* test accuracy for all:0.25623 test loss: 255.354
127000: ********* epoch 14 ********* test accuracy for mode 0:0.03 test loss: 437.609
127000: ********* epoch 14 ********* test accuracy for mode 1:0.0365 test loss: 421.799
127000: ********* epoch 14 ********* test accuracy for mode 2:0.0365 test loss: 264.883
127000: ********* epoch 14 ********* test accuracy for mode 24:0.2325 test loss: 271.337
127000: ********* epoch 14 ********* test accuracy for mode 25:0.307 test loss: 241.764
127000: ********* epoch 14 ********* test accuracy for mode 26:0.4785 test loss: 159.026
127000: ********* epoch 14 ********* test accuracy for mode 27:0.254 test loss: 258.795
127000: ********* epoch 14 ********* test accuracy for mode 28:0.2785 test loss: 256.004
127000: ********* epoch 14 ********* test accuracy for mode 29:0.2725 test loss: 258.588
127000: ********* epoch 14 ********* test accuracy for mode 30:0.2575 test loss: 245.721
127000: ********* epoch 14 ********* test accuracy for mode 31:0.1815 test loss: 250.87
127000: ********* epoch 14 ********* test accuracy for mode 32:0.239 test loss: 236.096
127000: ********* epoch 14 ********* test accuracy for mode 33:0.226 test loss: 239.012
127000: ********* epoch 14 ********* test accuracy for mode 34:0.2525 test loss: 239.177
127000: ********* epoch 14 ********* test accuracy for mode 35:0.039 test loss: 443.747
127000: ********* epoch 14 ********* test accuracy for mode 36:0.1005 test loss: 479.697
127010: accuracy:0.3 loss: 223.177 (lr:0.0001)
127020: accuracy:0.39 loss: 203.184 (lr:0.0001)
127030: accuracy:0.31 loss: 208.442 (lr:0.0001)
127040: accuracy:0.34 loss: 213.597 (lr:0.0001)
127050: accuracy:0.31 loss: 214.221 (lr:0.0001)
127060: accuracy:0.36 loss: 206.712 (lr:0.0001)
127070: accuracy:0.41 loss: 200.25 (lr:0.0001)
127080: accuracy:0.34 loss: 228.252 (lr:0.0001)
127090: accuracy:0.35 loss: 189.111 (lr:0.0001)
127100: accuracy:0.36 loss: 199.563 (lr:0.0001)
127110: accuracy:0.27 loss: 211.689 (lr:0.0001)
127120: accuracy:0.41 loss: 213.268 (lr:0.0001)
127130: accuracy:0.41 loss: 193.4 (lr:0.0001)
127140: accuracy:0.28 loss: 226.644 (lr:0.0001)
127150: accuracy:0.35 loss: 198.875 (lr:0.0001)
127160: accuracy:0.35 loss: 228.04 (lr:0.0001)
127170: accuracy:0.27 loss: 225.568 (lr:0.0001)
127180: accuracy:0.36 loss: 239.02 (lr:0.0001)
127190: accuracy:0.36 loss: 200.585 (lr:0.0001)
127200: accuracy:0.44 loss: 195.272 (lr:0.0001)
127210: accuracy:0.41 loss: 183.732 (lr:0.0001)
127220: accuracy:0.4 loss: 214.0 (lr:0.0001)
127230: accuracy:0.34 loss: 216.479 (lr:0.0001)
127240: accuracy:0.33 loss: 205.507 (lr:0.0001)
127250: accuracy:0.37 loss: 217.173 (lr:0.0001)
127260: accuracy:0.41 loss: 193.546 (lr:0.0001)
127270: accuracy:0.39 loss: 209.148 (lr:0.0001)
127280: accuracy:0.35 loss: 214.864 (lr:0.0001)
127290: accuracy:0.38 loss: 210.595 (lr:0.0001)
127300: accuracy:0.33 loss: 222.934 (lr:0.0001)
127310: accuracy:0.38 loss: 205.992 (lr:0.0001)
127320: accuracy:0.38 loss: 205.353 (lr:0.0001)
127330: accuracy:0.35 loss: 209.068 (lr:0.0001)
127340: accuracy:0.44 loss: 223.425 (lr:0.0001)
127350: accuracy:0.31 loss: 222.238 (lr:0.0001)
127360: accuracy:0.35 loss: 202.051 (lr:0.0001)
127370: accuracy:0.38 loss: 214.254 (lr:0.0001)
127380: accuracy:0.41 loss: 185.687 (lr:0.0001)
127390: accuracy:0.43 loss: 209.457 (lr:0.0001)
127400: accuracy:0.38 loss: 193.729 (lr:0.0001)
127410: accuracy:0.4 loss: 190.976 (lr:0.0001)
127420: accuracy:0.26 loss: 234.567 (lr:0.0001)
127430: accuracy:0.35 loss: 211.73 (lr:0.0001)
127440: accuracy:0.35 loss: 205.464 (lr:0.0001)
127450: accuracy:0.38 loss: 203.541 (lr:0.0001)
127460: accuracy:0.37 loss: 192.364 (lr:0.0001)
127470: accuracy:0.32 loss: 207.156 (lr:0.0001)
127480: accuracy:0.28 loss: 204.212 (lr:0.0001)
127490: accuracy:0.33 loss: 215.72 (lr:0.0001)
127500: accuracy:0.3 loss: 212.858 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
127500: ********* epoch 14 ********* test accuracy for all:0.258365 test loss: 253.356
127500: ********* epoch 14 ********* test accuracy for mode 0:0.0275 test loss: 433.275
127500: ********* epoch 14 ********* test accuracy for mode 1:0.038 test loss: 416.271
127500: ********* epoch 14 ********* test accuracy for mode 2:0.028 test loss: 273.573
127500: ********* epoch 14 ********* test accuracy for mode 24:0.279 test loss: 260.106
127500: ********* epoch 14 ********* test accuracy for mode 25:0.3 test loss: 238.274
127500: ********* epoch 14 ********* test accuracy for mode 26:0.505 test loss: 153.302
127500: ********* epoch 14 ********* test accuracy for mode 27:0.2625 test loss: 253.359
127500: ********* epoch 14 ********* test accuracy for mode 28:0.3225 test loss: 247.335
127500: ********* epoch 14 ********* test accuracy for mode 29:0.2495 test loss: 259.513
127500: ********* epoch 14 ********* test accuracy for mode 30:0.256 test loss: 248.16
127500: ********* epoch 14 ********* test accuracy for mode 31:0.191 test loss: 254.528
127500: ********* epoch 14 ********* test accuracy for mode 32:0.195 test loss: 243.025
127500: ********* epoch 14 ********* test accuracy for mode 33:0.2765 test loss: 240.761
127500: ********* epoch 14 ********* test accuracy for mode 34:0.179 test loss: 248.221
127500: ********* epoch 14 ********* test accuracy for mode 35:0.062 test loss: 423.545
127500: ********* epoch 14 ********* test accuracy for mode 36:0.1395 test loss: 429.002
127510: accuracy:0.29 loss: 214.566 (lr:0.0001)
127520: accuracy:0.37 loss: 207.047 (lr:0.0001)
127530: accuracy:0.4 loss: 231.903 (lr:0.0001)
127540: accuracy:0.34 loss: 206.374 (lr:0.0001)
127550: accuracy:0.36 loss: 208.396 (lr:0.0001)
127560: accuracy:0.34 loss: 206.577 (lr:0.0001)
127570: accuracy:0.29 loss: 230.874 (lr:0.0001)
127580: accuracy:0.35 loss: 202.626 (lr:0.0001)
127590: accuracy:0.38 loss: 219.387 (lr:0.0001)
127600: accuracy:0.28 loss: 217.173 (lr:0.0001)
127610: accuracy:0.37 loss: 199.609 (lr:0.0001)
127620: accuracy:0.32 loss: 210.816 (lr:0.0001)
127630: accuracy:0.32 loss: 221.749 (lr:0.0001)
127640: accuracy:0.42 loss: 185.513 (lr:0.0001)
127650: accuracy:0.35 loss: 206.0 (lr:0.0001)
127660: accuracy:0.32 loss: 214.807 (lr:0.0001)
127670: accuracy:0.31 loss: 222.0 (lr:0.0001)
127680: accuracy:0.43 loss: 174.123 (lr:0.0001)
127690: accuracy:0.32 loss: 212.447 (lr:0.0001)
127700: accuracy:0.3 loss: 238.183 (lr:0.0001)
127710: accuracy:0.34 loss: 210.08 (lr:0.0001)
127720: accuracy:0.39 loss: 207.662 (lr:0.0001)
127730: accuracy:0.31 loss: 217.7 (lr:0.0001)
127740: accuracy:0.27 loss: 240.944 (lr:0.0001)
127750: accuracy:0.41 loss: 208.483 (lr:0.0001)
127760: accuracy:0.38 loss: 191.581 (lr:0.0001)
127770: accuracy:0.29 loss: 216.813 (lr:0.0001)
127780: accuracy:0.4 loss: 188.434 (lr:0.0001)
127790: accuracy:0.38 loss: 218.607 (lr:0.0001)
127800: accuracy:0.36 loss: 197.231 (lr:0.0001)
127810: accuracy:0.37 loss: 214.337 (lr:0.0001)
127820: accuracy:0.36 loss: 212.438 (lr:0.0001)
127830: accuracy:0.38 loss: 188.927 (lr:0.0001)
127840: accuracy:0.38 loss: 198.36 (lr:0.0001)
127850: accuracy:0.35 loss: 206.404 (lr:0.0001)
127860: accuracy:0.4 loss: 200.559 (lr:0.0001)
127870: accuracy:0.34 loss: 197.475 (lr:0.0001)
127880: accuracy:0.34 loss: 217.654 (lr:0.0001)
127890: accuracy:0.29 loss: 209.871 (lr:0.0001)
127900: accuracy:0.3 loss: 213.745 (lr:0.0001)
127910: accuracy:0.34 loss: 213.151 (lr:0.0001)
127920: accuracy:0.4 loss: 196.022 (lr:0.0001)
127930: accuracy:0.32 loss: 212.545 (lr:0.0001)
127940: accuracy:0.41 loss: 202.198 (lr:0.0001)
127950: accuracy:0.38 loss: 214.14 (lr:0.0001)
127960: accuracy:0.28 loss: 217.887 (lr:0.0001)
127970: accuracy:0.4 loss: 212.242 (lr:0.0001)
127980: accuracy:0.38 loss: 200.53 (lr:0.0001)
127990: accuracy:0.36 loss: 208.29 (lr:0.0001)
128000: accuracy:0.44 loss: 193.34 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
128000: ********* epoch 14 ********* test accuracy for all:0.253189 test loss: 257.309
128000: ********* epoch 14 ********* test accuracy for mode 0:0.03 test loss: 432.249
128000: ********* epoch 14 ********* test accuracy for mode 1:0.032 test loss: 421.209
128000: ********* epoch 14 ********* test accuracy for mode 2:0.049 test loss: 267.656
128000: ********* epoch 14 ********* test accuracy for mode 24:0.235 test loss: 273.445
128000: ********* epoch 14 ********* test accuracy for mode 25:0.2915 test loss: 253.138
128000: ********* epoch 14 ********* test accuracy for mode 26:0.4465 test loss: 169.155
128000: ********* epoch 14 ********* test accuracy for mode 27:0.261 test loss: 273.524
128000: ********* epoch 14 ********* test accuracy for mode 28:0.3005 test loss: 262.88
128000: ********* epoch 14 ********* test accuracy for mode 29:0.2465 test loss: 270.581
128000: ********* epoch 14 ********* test accuracy for mode 30:0.237 test loss: 259.083
128000: ********* epoch 14 ********* test accuracy for mode 31:0.185 test loss: 259.677
128000: ********* epoch 14 ********* test accuracy for mode 32:0.2015 test loss: 241.58
128000: ********* epoch 14 ********* test accuracy for mode 33:0.314 test loss: 235.095
128000: ********* epoch 14 ********* test accuracy for mode 34:0.183 test loss: 243.647
128000: ********* epoch 14 ********* test accuracy for mode 35:0.0415 test loss: 436.912
128000: ********* epoch 14 ********* test accuracy for mode 36:0.1195 test loss: 448.141
128010: accuracy:0.39 loss: 212.414 (lr:0.0001)
128020: accuracy:0.4 loss: 196.492 (lr:0.0001)
128030: accuracy:0.35 loss: 215.411 (lr:0.0001)
128040: accuracy:0.34 loss: 201.663 (lr:0.0001)
128050: accuracy:0.39 loss: 209.559 (lr:0.0001)
128060: accuracy:0.34 loss: 206.899 (lr:0.0001)
128070: accuracy:0.39 loss: 200.245 (lr:0.0001)
128080: accuracy:0.34 loss: 219.481 (lr:0.0001)
128090: accuracy:0.33 loss: 225.553 (lr:0.0001)
128100: accuracy:0.35 loss: 223.655 (lr:0.0001)
128110: accuracy:0.35 loss: 205.515 (lr:0.0001)
128120: accuracy:0.32 loss: 204.745 (lr:0.0001)
128130: accuracy:0.39 loss: 195.81 (lr:0.0001)
128140: accuracy:0.27 loss: 223.822 (lr:0.0001)
128150: accuracy:0.4 loss: 190.686 (lr:0.0001)
128160: accuracy:0.32 loss: 184.386 (lr:0.0001)
128170: accuracy:0.36 loss: 196.634 (lr:0.0001)
128180: accuracy:0.3 loss: 204.941 (lr:0.0001)
128190: accuracy:0.38 loss: 204.909 (lr:0.0001)
128200: accuracy:0.34 loss: 206.047 (lr:0.0001)
128210: accuracy:0.38 loss: 198.847 (lr:0.0001)
128220: accuracy:0.32 loss: 208.262 (lr:0.0001)
128230: accuracy:0.33 loss: 207.756 (lr:0.0001)
128240: accuracy:0.3 loss: 211.745 (lr:0.0001)
128250: accuracy:0.33 loss: 203.536 (lr:0.0001)
128260: accuracy:0.32 loss: 224.545 (lr:0.0001)
128270: accuracy:0.34 loss: 227.574 (lr:0.0001)
128280: accuracy:0.34 loss: 210.141 (lr:0.0001)
128290: accuracy:0.33 loss: 203.928 (lr:0.0001)
128300: accuracy:0.4 loss: 192.042 (lr:0.0001)
128310: accuracy:0.31 loss: 210.749 (lr:0.0001)
128320: accuracy:0.42 loss: 185.987 (lr:0.0001)
128330: accuracy:0.25 loss: 229.807 (lr:0.0001)
128340: accuracy:0.26 loss: 213.706 (lr:0.0001)
128350: accuracy:0.41 loss: 200.949 (lr:0.0001)
128360: accuracy:0.32 loss: 207.192 (lr:0.0001)
128370: accuracy:0.29 loss: 230.638 (lr:0.0001)
128380: accuracy:0.32 loss: 212.211 (lr:0.0001)
128390: accuracy:0.31 loss: 199.691 (lr:0.0001)
128400: accuracy:0.25 loss: 231.148 (lr:0.0001)
128410: accuracy:0.31 loss: 216.222 (lr:0.0001)
128420: accuracy:0.31 loss: 204.535 (lr:0.0001)
128430: accuracy:0.29 loss: 221.383 (lr:0.0001)
128440: accuracy:0.36 loss: 217.403 (lr:0.0001)
128450: accuracy:0.29 loss: 212.553 (lr:0.0001)
128460: accuracy:0.32 loss: 232.037 (lr:0.0001)
128470: accuracy:0.36 loss: 192.073 (lr:0.0001)
128480: accuracy:0.29 loss: 205.392 (lr:0.0001)
128490: accuracy:0.32 loss: 222.766 (lr:0.0001)
128500: accuracy:0.33 loss: 213.751 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
128500: ********* epoch 14 ********* test accuracy for all:0.25823 test loss: 253.486
128500: ********* epoch 14 ********* test accuracy for mode 0:0.0315 test loss: 426.331
128500: ********* epoch 14 ********* test accuracy for mode 1:0.036 test loss: 419.398
128500: ********* epoch 14 ********* test accuracy for mode 2:0.0485 test loss: 264.356
128500: ********* epoch 14 ********* test accuracy for mode 24:0.264 test loss: 264.745
128500: ********* epoch 14 ********* test accuracy for mode 25:0.2845 test loss: 245.985
128500: ********* epoch 14 ********* test accuracy for mode 26:0.5035 test loss: 161.155
128500: ********* epoch 14 ********* test accuracy for mode 27:0.2585 test loss: 257.977
128500: ********* epoch 14 ********* test accuracy for mode 28:0.336 test loss: 246.59
128500: ********* epoch 14 ********* test accuracy for mode 29:0.252 test loss: 262.232
128500: ********* epoch 14 ********* test accuracy for mode 30:0.238 test loss: 251.674
128500: ********* epoch 14 ********* test accuracy for mode 31:0.221 test loss: 249.857
128500: ********* epoch 14 ********* test accuracy for mode 32:0.223 test loss: 236.493
128500: ********* epoch 14 ********* test accuracy for mode 33:0.2385 test loss: 240.453
128500: ********* epoch 14 ********* test accuracy for mode 34:0.2445 test loss: 239.911
128500: ********* epoch 14 ********* test accuracy for mode 35:0.0385 test loss: 429.712
128500: ********* epoch 14 ********* test accuracy for mode 36:0.139 test loss: 436.499
128510: accuracy:0.35 loss: 212.056 (lr:0.0001)
128520: accuracy:0.33 loss: 193.483 (lr:0.0001)
128530: accuracy:0.27 loss: 197.926 (lr:0.0001)
128540: accuracy:0.32 loss: 198.888 (lr:0.0001)
128550: accuracy:0.22 loss: 210.302 (lr:0.0001)
128560: accuracy:0.35 loss: 202.701 (lr:0.0001)
128570: accuracy:0.43 loss: 193.759 (lr:0.0001)
128580: accuracy:0.39 loss: 203.842 (lr:0.0001)
128590: accuracy:0.33 loss: 207.383 (lr:0.0001)
128600: accuracy:0.35 loss: 197.519 (lr:0.0001)
128610: accuracy:0.32 loss: 200.127 (lr:0.0001)
128620: accuracy:0.47 loss: 176.965 (lr:0.0001)
128630: accuracy:0.37 loss: 214.933 (lr:0.0001)
128640: accuracy:0.33 loss: 210.882 (lr:0.0001)
128650: accuracy:0.31 loss: 197.714 (lr:0.0001)
128660: accuracy:0.35 loss: 201.679 (lr:0.0001)
128670: accuracy:0.38 loss: 187.521 (lr:0.0001)
128680: accuracy:0.39 loss: 184.919 (lr:0.0001)
128690: accuracy:0.29 loss: 209.561 (lr:0.0001)
128700: accuracy:0.4 loss: 223.521 (lr:0.0001)
128710: accuracy:0.32 loss: 211.42 (lr:0.0001)
128720: accuracy:0.37 loss: 209.887 (lr:0.0001)
128730: accuracy:0.32 loss: 231.799 (lr:0.0001)
128740: accuracy:0.34 loss: 211.142 (lr:0.0001)
128750: accuracy:0.33 loss: 224.115 (lr:0.0001)
128760: accuracy:0.32 loss: 201.006 (lr:0.0001)
128770: accuracy:0.32 loss: 216.005 (lr:0.0001)
128780: accuracy:0.25 loss: 222.572 (lr:0.0001)
128790: accuracy:0.37 loss: 209.624 (lr:0.0001)
128800: accuracy:0.42 loss: 182.517 (lr:0.0001)
128810: accuracy:0.28 loss: 201.61 (lr:0.0001)
128820: accuracy:0.34 loss: 185.336 (lr:0.0001)
128830: accuracy:0.4 loss: 192.453 (lr:0.0001)
128840: accuracy:0.26 loss: 221.003 (lr:0.0001)
128850: accuracy:0.36 loss: 204.383 (lr:0.0001)
128860: accuracy:0.31 loss: 203.14 (lr:0.0001)
128870: accuracy:0.36 loss: 215.55 (lr:0.0001)
128880: accuracy:0.41 loss: 199.802 (lr:0.0001)
128890: accuracy:0.38 loss: 210.779 (lr:0.0001)
128900: accuracy:0.47 loss: 188.351 (lr:0.0001)
128910: accuracy:0.36 loss: 210.61 (lr:0.0001)
128920: accuracy:0.41 loss: 194.364 (lr:0.0001)
128930: accuracy:0.37 loss: 196.786 (lr:0.0001)
128940: accuracy:0.37 loss: 199.021 (lr:0.0001)
128950: accuracy:0.3 loss: 209.159 (lr:0.0001)
128960: accuracy:0.28 loss: 211.979 (lr:0.0001)
128970: accuracy:0.29 loss: 214.161 (lr:0.0001)
128980: accuracy:0.39 loss: 203.726 (lr:0.0001)
128990: accuracy:0.28 loss: 239.697 (lr:0.0001)
129000: accuracy:0.38 loss: 202.695 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
129000: ********* epoch 14 ********* test accuracy for all:0.257297 test loss: 254.867
129000: ********* epoch 14 ********* test accuracy for mode 0:0.038 test loss: 427.863
129000: ********* epoch 14 ********* test accuracy for mode 1:0.038 test loss: 414.006
129000: ********* epoch 14 ********* test accuracy for mode 2:0.082 test loss: 263.951
129000: ********* epoch 14 ********* test accuracy for mode 24:0.2295 test loss: 266.698
129000: ********* epoch 14 ********* test accuracy for mode 25:0.253 test loss: 245.98
129000: ********* epoch 14 ********* test accuracy for mode 26:0.55 test loss: 151.815
129000: ********* epoch 14 ********* test accuracy for mode 27:0.2725 test loss: 253.749
129000: ********* epoch 14 ********* test accuracy for mode 28:0.3275 test loss: 249.255
129000: ********* epoch 14 ********* test accuracy for mode 29:0.242 test loss: 263.409
129000: ********* epoch 14 ********* test accuracy for mode 30:0.2385 test loss: 252.937
129000: ********* epoch 14 ********* test accuracy for mode 31:0.213 test loss: 256.775
129000: ********* epoch 14 ********* test accuracy for mode 32:0.251 test loss: 240.747
129000: ********* epoch 14 ********* test accuracy for mode 33:0.212 test loss: 248.751
129000: ********* epoch 14 ********* test accuracy for mode 34:0.223 test loss: 247.808
129000: ********* epoch 14 ********* test accuracy for mode 35:0.0625 test loss: 439.443
129000: ********* epoch 14 ********* test accuracy for mode 36:0.078 test loss: 493.027
129010: accuracy:0.33 loss: 211.511 (lr:0.0001)
129020: accuracy:0.42 loss: 193.007 (lr:0.0001)
129030: accuracy:0.31 loss: 221.965 (lr:0.0001)
129040: accuracy:0.34 loss: 221.41 (lr:0.0001)
129050: accuracy:0.29 loss: 215.054 (lr:0.0001)
129060: accuracy:0.34 loss: 218.864 (lr:0.0001)
129070: accuracy:0.37 loss: 219.935 (lr:0.0001)
129080: accuracy:0.34 loss: 200.927 (lr:0.0001)
129090: accuracy:0.28 loss: 221.621 (lr:0.0001)
129100: accuracy:0.35 loss: 205.696 (lr:0.0001)
129110: accuracy:0.37 loss: 212.971 (lr:0.0001)
129120: accuracy:0.28 loss: 211.61 (lr:0.0001)
129130: accuracy:0.3 loss: 228.284 (lr:0.0001)
129140: accuracy:0.35 loss: 202.163 (lr:0.0001)
129150: accuracy:0.38 loss: 186.608 (lr:0.0001)
129160: accuracy:0.33 loss: 216.447 (lr:0.0001)
129170: accuracy:0.38 loss: 201.346 (lr:0.0001)
129180: accuracy:0.33 loss: 207.019 (lr:0.0001)
129190: accuracy:0.32 loss: 204.788 (lr:0.0001)
129200: accuracy:0.3 loss: 211.613 (lr:0.0001)
129210: accuracy:0.32 loss: 226.395 (lr:0.0001)
129220: accuracy:0.28 loss: 219.343 (lr:0.0001)
129230: accuracy:0.35 loss: 199.69 (lr:0.0001)
129240: accuracy:0.35 loss: 206.766 (lr:0.0001)
129250: accuracy:0.36 loss: 213.718 (lr:0.0001)
129260: accuracy:0.35 loss: 204.286 (lr:0.0001)
129270: accuracy:0.41 loss: 197.913 (lr:0.0001)
129280: accuracy:0.44 loss: 204.511 (lr:0.0001)
129290: accuracy:0.31 loss: 220.113 (lr:0.0001)
129300: accuracy:0.29 loss: 217.772 (lr:0.0001)
129310: accuracy:0.28 loss: 213.836 (lr:0.0001)
129320: accuracy:0.35 loss: 209.229 (lr:0.0001)
129330: accuracy:0.43 loss: 180.1 (lr:0.0001)
129340: accuracy:0.36 loss: 213.053 (lr:0.0001)
129350: accuracy:0.44 loss: 190.559 (lr:0.0001)
129360: accuracy:0.39 loss: 207.381 (lr:0.0001)
129370: accuracy:0.3 loss: 215.785 (lr:0.0001)
129380: accuracy:0.38 loss: 193.615 (lr:0.0001)
129390: accuracy:0.33 loss: 218.588 (lr:0.0001)
129400: accuracy:0.39 loss: 202.281 (lr:0.0001)
129410: accuracy:0.32 loss: 220.546 (lr:0.0001)
129420: accuracy:0.28 loss: 229.517 (lr:0.0001)
129430: accuracy:0.32 loss: 216.921 (lr:0.0001)
129440: accuracy:0.37 loss: 200.39 (lr:0.0001)
129450: accuracy:0.3 loss: 228.424 (lr:0.0001)
129460: accuracy:0.36 loss: 207.504 (lr:0.0001)
129470: accuracy:0.35 loss: 201.56 (lr:0.0001)
129480: accuracy:0.21 loss: 242.783 (lr:0.0001)
129490: accuracy:0.38 loss: 176.059 (lr:0.0001)
129500: accuracy:0.4 loss: 213.963 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
129500: ********* epoch 14 ********* test accuracy for all:0.255649 test loss: 255.598
129500: ********* epoch 14 ********* test accuracy for mode 0:0.0305 test loss: 433.114
129500: ********* epoch 14 ********* test accuracy for mode 1:0.0305 test loss: 422.169
129500: ********* epoch 14 ********* test accuracy for mode 2:0.0375 test loss: 267.65
129500: ********* epoch 14 ********* test accuracy for mode 24:0.221 test loss: 267.809
129500: ********* epoch 14 ********* test accuracy for mode 25:0.333 test loss: 242.803
129500: ********* epoch 14 ********* test accuracy for mode 26:0.4285 test loss: 159.717
129500: ********* epoch 14 ********* test accuracy for mode 27:0.272 test loss: 266.333
129500: ********* epoch 14 ********* test accuracy for mode 28:0.2975 test loss: 255.209
129500: ********* epoch 14 ********* test accuracy for mode 29:0.297 test loss: 261.723
129500: ********* epoch 14 ********* test accuracy for mode 30:0.225 test loss: 251.648
129500: ********* epoch 14 ********* test accuracy for mode 31:0.2095 test loss: 253.322
129500: ********* epoch 14 ********* test accuracy for mode 32:0.2385 test loss: 236.845
129500: ********* epoch 14 ********* test accuracy for mode 33:0.269 test loss: 240.13
129500: ********* epoch 14 ********* test accuracy for mode 34:0.2195 test loss: 244.398
129500: ********* epoch 14 ********* test accuracy for mode 35:0.049 test loss: 441.783
129500: ********* epoch 14 ********* test accuracy for mode 36:0.114 test loss: 467.09
129510: accuracy:0.35 loss: 193.547 (lr:0.0001)
129520: accuracy:0.46 loss: 190.584 (lr:0.0001)
129530: accuracy:0.31 loss: 216.555 (lr:0.0001)
129540: accuracy:0.36 loss: 202.407 (lr:0.0001)
129550: accuracy:0.34 loss: 231.127 (lr:0.0001)
129560: accuracy:0.37 loss: 199.796 (lr:0.0001)
129570: accuracy:0.26 loss: 219.752 (lr:0.0001)
129580: accuracy:0.39 loss: 200.779 (lr:0.0001)
129590: accuracy:0.41 loss: 220.585 (lr:0.0001)
129600: accuracy:0.4 loss: 193.508 (lr:0.0001)
129610: accuracy:0.4 loss: 209.495 (lr:0.0001)
129620: accuracy:0.33 loss: 194.861 (lr:0.0001)
129630: accuracy:0.3 loss: 206.902 (lr:0.0001)
129640: accuracy:0.33 loss: 198.34 (lr:0.0001)
129650: accuracy:0.41 loss: 196.452 (lr:0.0001)
129660: accuracy:0.37 loss: 199.587 (lr:0.0001)
129670: accuracy:0.28 loss: 222.044 (lr:0.0001)
129680: accuracy:0.29 loss: 237.472 (lr:0.0001)
129690: accuracy:0.33 loss: 194.035 (lr:0.0001)
129700: accuracy:0.34 loss: 220.542 (lr:0.0001)
129710: accuracy:0.39 loss: 198.469 (lr:0.0001)
129720: accuracy:0.44 loss: 202.983 (lr:0.0001)
129730: accuracy:0.38 loss: 200.438 (lr:0.0001)
129740: accuracy:0.3 loss: 217.162 (lr:0.0001)
129750: accuracy:0.39 loss: 189.24 (lr:0.0001)
129760: accuracy:0.31 loss: 208.088 (lr:0.0001)
129770: accuracy:0.32 loss: 202.785 (lr:0.0001)
129780: accuracy:0.22 loss: 230.625 (lr:0.0001)
129790: accuracy:0.26 loss: 227.083 (lr:0.0001)
129800: accuracy:0.35 loss: 217.527 (lr:0.0001)
129810: accuracy:0.38 loss: 202.512 (lr:0.0001)
129820: accuracy:0.29 loss: 207.759 (lr:0.0001)
129830: accuracy:0.35 loss: 204.774 (lr:0.0001)
129840: accuracy:0.33 loss: 205.653 (lr:0.0001)
129850: accuracy:0.24 loss: 226.126 (lr:0.0001)
129860: accuracy:0.38 loss: 200.468 (lr:0.0001)
129870: accuracy:0.3 loss: 221.121 (lr:0.0001)
129880: accuracy:0.35 loss: 204.051 (lr:0.0001)
129890: accuracy:0.38 loss: 189.502 (lr:0.0001)
129900: accuracy:0.23 loss: 220.743 (lr:0.0001)
129910: accuracy:0.31 loss: 232.871 (lr:0.0001)
129920: accuracy:0.38 loss: 211.879 (lr:0.0001)
129930: accuracy:0.37 loss: 210.161 (lr:0.0001)
129940: accuracy:0.32 loss: 223.748 (lr:0.0001)
129950: accuracy:0.37 loss: 206.226 (lr:0.0001)
129960: accuracy:0.38 loss: 214.121 (lr:0.0001)
129970: accuracy:0.39 loss: 205.165 (lr:0.0001)
129980: accuracy:0.28 loss: 216.077 (lr:0.0001)
129990: accuracy:0.39 loss: 207.45 (lr:0.0001)
130000: accuracy:0.34 loss: 215.624 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
130000: ********* epoch 14 ********* test accuracy for all:0.261581 test loss: 253.603
130000: ********* epoch 14 ********* test accuracy for mode 0:0.0315 test loss: 432.802
130000: ********* epoch 14 ********* test accuracy for mode 1:0.0335 test loss: 420.874
130000: ********* epoch 14 ********* test accuracy for mode 2:0.0645 test loss: 264.044
130000: ********* epoch 14 ********* test accuracy for mode 24:0.2485 test loss: 264.874
130000: ********* epoch 14 ********* test accuracy for mode 25:0.3145 test loss: 237.778
130000: ********* epoch 14 ********* test accuracy for mode 26:0.494 test loss: 159.682
130000: ********* epoch 14 ********* test accuracy for mode 27:0.2725 test loss: 254.573
130000: ********* epoch 14 ********* test accuracy for mode 28:0.2665 test loss: 258.277
130000: ********* epoch 14 ********* test accuracy for mode 29:0.277 test loss: 260.802
130000: ********* epoch 14 ********* test accuracy for mode 30:0.24 test loss: 252.955
130000: ********* epoch 14 ********* test accuracy for mode 31:0.187 test loss: 255.231
130000: ********* epoch 14 ********* test accuracy for mode 32:0.26 test loss: 236.712
130000: ********* epoch 14 ********* test accuracy for mode 33:0.2425 test loss: 241.48
130000: ********* epoch 14 ********* test accuracy for mode 34:0.258 test loss: 241.663
130000: ********* epoch 14 ********* test accuracy for mode 35:0.061 test loss: 428.702
130000: ********* epoch 14 ********* test accuracy for mode 36:0.2185 test loss: 434.636
130010: accuracy:0.34 loss: 197.966 (lr:0.0001)
130020: accuracy:0.36 loss: 211.008 (lr:0.0001)
130030: accuracy:0.38 loss: 201.455 (lr:0.0001)
130040: accuracy:0.3 loss: 201.747 (lr:0.0001)
130050: accuracy:0.25 loss: 207.925 (lr:0.0001)
130060: accuracy:0.3 loss: 216.173 (lr:0.0001)
130070: accuracy:0.38 loss: 207.128 (lr:0.0001)
130080: accuracy:0.45 loss: 180.821 (lr:0.0001)
130090: accuracy:0.46 loss: 192.983 (lr:0.0001)
130100: accuracy:0.3 loss: 220.303 (lr:0.0001)
130110: accuracy:0.36 loss: 205.739 (lr:0.0001)
130120: accuracy:0.34 loss: 226.401 (lr:0.0001)
130130: accuracy:0.21 loss: 250.603 (lr:0.0001)
130140: accuracy:0.26 loss: 218.869 (lr:0.0001)
130150: accuracy:0.38 loss: 214.011 (lr:0.0001)
130160: accuracy:0.32 loss: 219.881 (lr:0.0001)
130170: accuracy:0.43 loss: 206.043 (lr:0.0001)
130180: accuracy:0.27 loss: 210.801 (lr:0.0001)
130190: accuracy:0.29 loss: 220.261 (lr:0.0001)
130200: accuracy:0.32 loss: 220.423 (lr:0.0001)
130210: accuracy:0.38 loss: 200.923 (lr:0.0001)
130220: accuracy:0.35 loss: 206.31 (lr:0.0001)
130230: accuracy:0.41 loss: 213.368 (lr:0.0001)
130240: accuracy:0.35 loss: 221.878 (lr:0.0001)
130250: accuracy:0.31 loss: 205.568 (lr:0.0001)
130260: accuracy:0.24 loss: 227.44 (lr:0.0001)
130270: accuracy:0.36 loss: 219.218 (lr:0.0001)
130280: accuracy:0.32 loss: 197.443 (lr:0.0001)
130290: accuracy:0.26 loss: 236.062 (lr:0.0001)
130300: accuracy:0.38 loss: 197.147 (lr:0.0001)
130310: accuracy:0.35 loss: 207.985 (lr:0.0001)
130320: accuracy:0.39 loss: 186.482 (lr:0.0001)
130330: accuracy:0.33 loss: 201.07 (lr:0.0001)
130340: accuracy:0.37 loss: 209.635 (lr:0.0001)
130350: accuracy:0.27 loss: 228.701 (lr:0.0001)
130360: accuracy:0.31 loss: 219.445 (lr:0.0001)
130370: accuracy:0.31 loss: 212.322 (lr:0.0001)
130380: accuracy:0.34 loss: 232.014 (lr:0.0001)
130390: accuracy:0.39 loss: 180.005 (lr:0.0001)
130400: accuracy:0.3 loss: 211.839 (lr:0.0001)
130410: accuracy:0.38 loss: 187.12 (lr:0.0001)
130420: accuracy:0.38 loss: 196.713 (lr:0.0001)
130430: accuracy:0.29 loss: 229.997 (lr:0.0001)
130440: accuracy:0.35 loss: 226.521 (lr:0.0001)
130450: accuracy:0.37 loss: 201.351 (lr:0.0001)
130460: accuracy:0.34 loss: 228.074 (lr:0.0001)
130470: accuracy:0.3 loss: 227.86 (lr:0.0001)
130480: accuracy:0.32 loss: 223.887 (lr:0.0001)
130490: accuracy:0.32 loss: 220.404 (lr:0.0001)
130500: accuracy:0.33 loss: 211.359 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
130500: ********* epoch 14 ********* test accuracy for all:0.254243 test loss: 255.597
130500: ********* epoch 14 ********* test accuracy for mode 0:0.035 test loss: 433.474
130500: ********* epoch 14 ********* test accuracy for mode 1:0.0425 test loss: 423.056
130500: ********* epoch 14 ********* test accuracy for mode 2:0.0535 test loss: 266.509
130500: ********* epoch 14 ********* test accuracy for mode 24:0.2555 test loss: 265.645
130500: ********* epoch 14 ********* test accuracy for mode 25:0.3045 test loss: 243.042
130500: ********* epoch 14 ********* test accuracy for mode 26:0.4405 test loss: 164.367
130500: ********* epoch 14 ********* test accuracy for mode 27:0.2265 test loss: 269.795
130500: ********* epoch 14 ********* test accuracy for mode 28:0.2745 test loss: 260.216
130500: ********* epoch 14 ********* test accuracy for mode 29:0.268 test loss: 265.3
130500: ********* epoch 14 ********* test accuracy for mode 30:0.3005 test loss: 249.683
130500: ********* epoch 14 ********* test accuracy for mode 31:0.158 test loss: 259.629
130500: ********* epoch 14 ********* test accuracy for mode 32:0.206 test loss: 244.9
130500: ********* epoch 14 ********* test accuracy for mode 33:0.2615 test loss: 245.73
130500: ********* epoch 14 ********* test accuracy for mode 34:0.1765 test loss: 250.487
130500: ********* epoch 14 ********* test accuracy for mode 35:0.0705 test loss: 433.29
130500: ********* epoch 14 ********* test accuracy for mode 36:0.119 test loss: 434.673
130510: accuracy:0.4 loss: 207.04 (lr:0.0001)
130520: accuracy:0.36 loss: 187.748 (lr:0.0001)
130530: accuracy:0.31 loss: 227.116 (lr:0.0001)
130540: accuracy:0.39 loss: 189.713 (lr:0.0001)
130550: accuracy:0.49 loss: 177.782 (lr:0.0001)
130560: accuracy:0.34 loss: 209.403 (lr:0.0001)
130570: accuracy:0.34 loss: 224.262 (lr:0.0001)
130580: accuracy:0.31 loss: 221.723 (lr:0.0001)
130590: accuracy:0.35 loss: 193.776 (lr:0.0001)
130600: accuracy:0.38 loss: 198.198 (lr:0.0001)
130610: accuracy:0.32 loss: 210.14 (lr:0.0001)
130620: accuracy:0.36 loss: 209.774 (lr:0.0001)
130630: accuracy:0.3 loss: 218.821 (lr:0.0001)
130640: accuracy:0.32 loss: 224.785 (lr:0.0001)
130650: accuracy:0.31 loss: 204.605 (lr:0.0001)
130660: accuracy:0.36 loss: 202.372 (lr:0.0001)
130670: accuracy:0.32 loss: 215.047 (lr:0.0001)
130680: accuracy:0.39 loss: 186.932 (lr:0.0001)
130690: accuracy:0.35 loss: 205.09 (lr:0.0001)
130700: accuracy:0.29 loss: 221.762 (lr:0.0001)
130710: accuracy:0.31 loss: 238.106 (lr:0.0001)
130720: accuracy:0.37 loss: 214.792 (lr:0.0001)
130730: accuracy:0.3 loss: 201.624 (lr:0.0001)
130740: accuracy:0.33 loss: 211.882 (lr:0.0001)
130750: accuracy:0.3 loss: 217.796 (lr:0.0001)
130760: accuracy:0.33 loss: 200.36 (lr:0.0001)
130770: accuracy:0.36 loss: 217.089 (lr:0.0001)
130780: accuracy:0.39 loss: 201.876 (lr:0.0001)
130790: accuracy:0.35 loss: 212.919 (lr:0.0001)
130800: accuracy:0.31 loss: 218.408 (lr:0.0001)
130810: accuracy:0.28 loss: 230.301 (lr:0.0001)
130820: accuracy:0.36 loss: 193.69 (lr:0.0001)
130830: accuracy:0.3 loss: 211.589 (lr:0.0001)
130840: accuracy:0.34 loss: 201.134 (lr:0.0001)
130850: accuracy:0.39 loss: 210.757 (lr:0.0001)
130860: accuracy:0.41 loss: 187.381 (lr:0.0001)
130870: accuracy:0.34 loss: 205.988 (lr:0.0001)
130880: accuracy:0.3 loss: 236.076 (lr:0.0001)
130890: accuracy:0.21 loss: 226.563 (lr:0.0001)
130900: accuracy:0.35 loss: 199.667 (lr:0.0001)
130910: accuracy:0.3 loss: 225.365 (lr:0.0001)
130920: accuracy:0.32 loss: 213.436 (lr:0.0001)
130930: accuracy:0.4 loss: 202.789 (lr:0.0001)
130940: accuracy:0.39 loss: 197.458 (lr:0.0001)
130950: accuracy:0.26 loss: 223.958 (lr:0.0001)
130960: accuracy:0.36 loss: 207.495 (lr:0.0001)
130970: accuracy:0.39 loss: 201.919 (lr:0.0001)
130980: accuracy:0.33 loss: 208.658 (lr:0.0001)
130990: accuracy:0.34 loss: 206.964 (lr:0.0001)
131000: accuracy:0.35 loss: 207.251 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
131000: ********* epoch 14 ********* test accuracy for all:0.260622 test loss: 254.165
131000: ********* epoch 14 ********* test accuracy for mode 0:0.027 test loss: 434.813
131000: ********* epoch 14 ********* test accuracy for mode 1:0.028 test loss: 418.739
131000: ********* epoch 14 ********* test accuracy for mode 2:0.05 test loss: 260.378
131000: ********* epoch 14 ********* test accuracy for mode 24:0.2255 test loss: 277.583
131000: ********* epoch 14 ********* test accuracy for mode 25:0.2905 test loss: 256.994
131000: ********* epoch 14 ********* test accuracy for mode 26:0.448 test loss: 166.565
131000: ********* epoch 14 ********* test accuracy for mode 27:0.2295 test loss: 274.839
131000: ********* epoch 14 ********* test accuracy for mode 28:0.284 test loss: 263.715
131000: ********* epoch 14 ********* test accuracy for mode 29:0.2315 test loss: 271.714
131000: ********* epoch 14 ********* test accuracy for mode 30:0.231 test loss: 254.535
131000: ********* epoch 14 ********* test accuracy for mode 31:0.217 test loss: 250.443
131000: ********* epoch 14 ********* test accuracy for mode 32:0.2215 test loss: 234.196
131000: ********* epoch 14 ********* test accuracy for mode 33:0.2985 test loss: 232.961
131000: ********* epoch 14 ********* test accuracy for mode 34:0.216 test loss: 238.035
131000: ********* epoch 14 ********* test accuracy for mode 35:0.079 test loss: 419.917
131000: ********* epoch 14 ********* test accuracy for mode 36:0.286 test loss: 414.885
131010: accuracy:0.27 loss: 221.388 (lr:0.0001)
131020: accuracy:0.33 loss: 206.123 (lr:0.0001)
131030: accuracy:0.28 loss: 225.54 (lr:0.0001)
131040: accuracy:0.37 loss: 199.553 (lr:0.0001)
131050: accuracy:0.33 loss: 216.944 (lr:0.0001)
131060: accuracy:0.36 loss: 200.638 (lr:0.0001)
131070: accuracy:0.36 loss: 215.501 (lr:0.0001)
131080: accuracy:0.37 loss: 199.081 (lr:0.0001)
131090: accuracy:0.34 loss: 219.292 (lr:0.0001)
131100: accuracy:0.31 loss: 201.508 (lr:0.0001)
131110: accuracy:0.32 loss: 217.807 (lr:0.0001)
131120: accuracy:0.23 loss: 242.755 (lr:0.0001)
131130: accuracy:0.3 loss: 223.502 (lr:0.0001)
131140: accuracy:0.41 loss: 179.881 (lr:0.0001)
131150: accuracy:0.32 loss: 224.623 (lr:0.0001)
131160: accuracy:0.38 loss: 199.146 (lr:0.0001)
131170: accuracy:0.32 loss: 216.049 (lr:0.0001)
131180: accuracy:0.31 loss: 224.148 (lr:0.0001)
131190: accuracy:0.28 loss: 211.146 (lr:0.0001)
131200: accuracy:0.32 loss: 212.563 (lr:0.0001)
131210: accuracy:0.3 loss: 218.281 (lr:0.0001)
131220: accuracy:0.48 loss: 189.174 (lr:0.0001)
131230: accuracy:0.39 loss: 193.697 (lr:0.0001)
131240: accuracy:0.38 loss: 192.49 (lr:0.0001)
131250: accuracy:0.36 loss: 217.094 (lr:0.0001)
131260: accuracy:0.35 loss: 218.318 (lr:0.0001)
131270: accuracy:0.38 loss: 207.573 (lr:0.0001)
131280: accuracy:0.41 loss: 204.733 (lr:0.0001)
131290: accuracy:0.32 loss: 215.921 (lr:0.0001)
131300: accuracy:0.34 loss: 214.725 (lr:0.0001)
131310: accuracy:0.36 loss: 200.484 (lr:0.0001)
131320: accuracy:0.41 loss: 196.851 (lr:0.0001)
131330: accuracy:0.33 loss: 206.901 (lr:0.0001)
131340: accuracy:0.4 loss: 199.66 (lr:0.0001)
131350: accuracy:0.27 loss: 240.377 (lr:0.0001)
131360: accuracy:0.35 loss: 210.159 (lr:0.0001)
131370: accuracy:0.33 loss: 185.718 (lr:0.0001)
131380: accuracy:0.28 loss: 228.016 (lr:0.0001)
131390: accuracy:0.27 loss: 207.915 (lr:0.0001)
131400: accuracy:0.37 loss: 200.079 (lr:0.0001)
131410: accuracy:0.27 loss: 212.741 (lr:0.0001)
131420: accuracy:0.29 loss: 225.022 (lr:0.0001)
131430: accuracy:0.42 loss: 196.699 (lr:0.0001)
131440: accuracy:0.27 loss: 219.619 (lr:0.0001)
131450: accuracy:0.36 loss: 187.253 (lr:0.0001)
131460: accuracy:0.28 loss: 234.937 (lr:0.0001)
131470: accuracy:0.42 loss: 196.808 (lr:0.0001)
131480: accuracy:0.34 loss: 204.279 (lr:0.0001)
131490: accuracy:0.39 loss: 212.234 (lr:0.0001)
131500: accuracy:0.33 loss: 199.679 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
131500: ********* epoch 14 ********* test accuracy for all:0.258162 test loss: 254.405
131500: ********* epoch 14 ********* test accuracy for mode 0:0.0335 test loss: 438.28
131500: ********* epoch 14 ********* test accuracy for mode 1:0.0305 test loss: 432.088
131500: ********* epoch 14 ********* test accuracy for mode 2:0.0475 test loss: 262.563
131500: ********* epoch 14 ********* test accuracy for mode 24:0.2365 test loss: 268.665
131500: ********* epoch 14 ********* test accuracy for mode 25:0.346 test loss: 233.366
131500: ********* epoch 14 ********* test accuracy for mode 26:0.4215 test loss: 164.765
131500: ********* epoch 14 ********* test accuracy for mode 27:0.28 test loss: 253.543
131500: ********* epoch 14 ********* test accuracy for mode 28:0.289 test loss: 252.931
131500: ********* epoch 14 ********* test accuracy for mode 29:0.2905 test loss: 257.512
131500: ********* epoch 14 ********* test accuracy for mode 30:0.1975 test loss: 254.288
131500: ********* epoch 14 ********* test accuracy for mode 31:0.238 test loss: 251.91
131500: ********* epoch 14 ********* test accuracy for mode 32:0.1505 test loss: 245.838
131500: ********* epoch 14 ********* test accuracy for mode 33:0.3095 test loss: 239.175
131500: ********* epoch 14 ********* test accuracy for mode 34:0.208 test loss: 243.722
131500: ********* epoch 14 ********* test accuracy for mode 35:0.0475 test loss: 462.405
131500: ********* epoch 14 ********* test accuracy for mode 36:0.0705 test loss: 504.604
131510: accuracy:0.37 loss: 228.885 (lr:0.0001)
131520: accuracy:0.28 loss: 220.115 (lr:0.0001)
131530: accuracy:0.32 loss: 197.659 (lr:0.0001)
131540: accuracy:0.32 loss: 211.855 (lr:0.0001)
131550: accuracy:0.37 loss: 196.147 (lr:0.0001)
131560: accuracy:0.4 loss: 216.89 (lr:0.0001)
131570: accuracy:0.36 loss: 203.173 (lr:0.0001)
131580: accuracy:0.38 loss: 198.755 (lr:0.0001)
131590: accuracy:0.39 loss: 206.699 (lr:0.0001)
131600: accuracy:0.3 loss: 207.746 (lr:0.0001)
131610: accuracy:0.33 loss: 203.877 (lr:0.0001)
131620: accuracy:0.37 loss: 188.363 (lr:0.0001)
131630: accuracy:0.3 loss: 207.046 (lr:0.0001)
131640: accuracy:0.41 loss: 203.049 (lr:0.0001)
131650: accuracy:0.32 loss: 203.37 (lr:0.0001)
131660: accuracy:0.39 loss: 196.916 (lr:0.0001)
131670: accuracy:0.32 loss: 213.114 (lr:0.0001)
131680: accuracy:0.34 loss: 216.927 (lr:0.0001)
131690: accuracy:0.32 loss: 211.238 (lr:0.0001)
131700: accuracy:0.27 loss: 220.589 (lr:0.0001)
131710: accuracy:0.37 loss: 202.234 (lr:0.0001)
131720: accuracy:0.33 loss: 207.039 (lr:0.0001)
131730: accuracy:0.35 loss: 194.496 (lr:0.0001)
131740: accuracy:0.44 loss: 190.425 (lr:0.0001)
131750: accuracy:0.36 loss: 204.875 (lr:0.0001)
131760: accuracy:0.38 loss: 199.463 (lr:0.0001)
131770: accuracy:0.36 loss: 217.277 (lr:0.0001)
131780: accuracy:0.35 loss: 206.348 (lr:0.0001)
131790: accuracy:0.28 loss: 221.797 (lr:0.0001)
131800: accuracy:0.38 loss: 183.987 (lr:0.0001)
131810: accuracy:0.28 loss: 232.385 (lr:0.0001)
131820: accuracy:0.35 loss: 207.269 (lr:0.0001)
131830: accuracy:0.34 loss: 190.793 (lr:0.0001)
131840: accuracy:0.27 loss: 211.441 (lr:0.0001)
131850: accuracy:0.31 loss: 217.922 (lr:0.0001)
131860: accuracy:0.3 loss: 238.754 (lr:0.0001)
131870: accuracy:0.32 loss: 207.438 (lr:0.0001)
131880: accuracy:0.32 loss: 203.356 (lr:0.0001)
131890: accuracy:0.36 loss: 201.739 (lr:0.0001)
131900: accuracy:0.37 loss: 207.123 (lr:0.0001)
131910: accuracy:0.3 loss: 211.424 (lr:0.0001)
131920: accuracy:0.43 loss: 181.943 (lr:0.0001)
131930: accuracy:0.37 loss: 212.352 (lr:0.0001)
131940: accuracy:0.4 loss: 206.424 (lr:0.0001)
131950: accuracy:0.37 loss: 214.179 (lr:0.0001)
131960: accuracy:0.35 loss: 204.213 (lr:0.0001)
131970: accuracy:0.37 loss: 216.479 (lr:0.0001)
131980: accuracy:0.3 loss: 217.344 (lr:0.0001)
131990: accuracy:0.35 loss: 210.214 (lr:0.0001)
132000: accuracy:0.35 loss: 197.153 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
132000: ********* epoch 14 ********* test accuracy for all:0.258905 test loss: 253.601
132000: ********* epoch 14 ********* test accuracy for mode 0:0.0345 test loss: 423.253
132000: ********* epoch 14 ********* test accuracy for mode 1:0.032 test loss: 421.423
132000: ********* epoch 14 ********* test accuracy for mode 2:0.049 test loss: 264.379
132000: ********* epoch 14 ********* test accuracy for mode 24:0.2355 test loss: 275.439
132000: ********* epoch 14 ********* test accuracy for mode 25:0.3235 test loss: 245.435
132000: ********* epoch 14 ********* test accuracy for mode 26:0.42 test loss: 164.433
132000: ********* epoch 14 ********* test accuracy for mode 27:0.27 test loss: 257.427
132000: ********* epoch 14 ********* test accuracy for mode 28:0.316 test loss: 248.669
132000: ********* epoch 14 ********* test accuracy for mode 29:0.265 test loss: 255.256
132000: ********* epoch 14 ********* test accuracy for mode 30:0.25 test loss: 241.576
132000: ********* epoch 14 ********* test accuracy for mode 31:0.1895 test loss: 248.02
132000: ********* epoch 14 ********* test accuracy for mode 32:0.236 test loss: 231.745
132000: ********* epoch 14 ********* test accuracy for mode 33:0.285 test loss: 233.775
132000: ********* epoch 14 ********* test accuracy for mode 34:0.249 test loss: 237.195
132000: ********* epoch 14 ********* test accuracy for mode 35:0.0935 test loss: 427.301
132000: ********* epoch 14 ********* test accuracy for mode 36:0.1125 test loss: 455.567
132010: accuracy:0.36 loss: 219.238 (lr:0.0001)
132020: accuracy:0.35 loss: 192.487 (lr:0.0001)
132030: accuracy:0.41 loss: 191.386 (lr:0.0001)
132040: accuracy:0.38 loss: 206.007 (lr:0.0001)
132050: accuracy:0.39 loss: 189.577 (lr:0.0001)
132060: accuracy:0.34 loss: 207.207 (lr:0.0001)
132070: accuracy:0.35 loss: 194.028 (lr:0.0001)
132080: accuracy:0.3 loss: 205.858 (lr:0.0001)
132090: accuracy:0.33 loss: 225.793 (lr:0.0001)
132100: accuracy:0.37 loss: 209.297 (lr:0.0001)
132110: accuracy:0.36 loss: 189.338 (lr:0.0001)
132120: accuracy:0.37 loss: 205.829 (lr:0.0001)
132130: accuracy:0.32 loss: 197.486 (lr:0.0001)
132140: accuracy:0.38 loss: 195.247 (lr:0.0001)
132150: accuracy:0.32 loss: 212.141 (lr:0.0001)
132160: accuracy:0.26 loss: 237.305 (lr:0.0001)
132170: accuracy:0.3 loss: 210.812 (lr:0.0001)
132180: accuracy:0.47 loss: 193.171 (lr:0.0001)
132190: accuracy:0.36 loss: 195.505 (lr:0.0001)
132200: accuracy:0.29 loss: 229.709 (lr:0.0001)
132210: accuracy:0.41 loss: 201.073 (lr:0.0001)
132220: accuracy:0.35 loss: 193.634 (lr:0.0001)
132230: accuracy:0.25 loss: 218.706 (lr:0.0001)
132240: accuracy:0.36 loss: 202.884 (lr:0.0001)
132250: accuracy:0.26 loss: 224.613 (lr:0.0001)
132260: accuracy:0.36 loss: 197.817 (lr:0.0001)
132270: accuracy:0.36 loss: 212.969 (lr:0.0001)
132280: accuracy:0.36 loss: 198.708 (lr:0.0001)
132290: accuracy:0.32 loss: 224.26 (lr:0.0001)
132300: accuracy:0.36 loss: 200.099 (lr:0.0001)
132310: accuracy:0.32 loss: 206.556 (lr:0.0001)
132320: accuracy:0.32 loss: 220.254 (lr:0.0001)
132330: accuracy:0.34 loss: 205.958 (lr:0.0001)
132340: accuracy:0.34 loss: 212.16 (lr:0.0001)
132350: accuracy:0.35 loss: 205.555 (lr:0.0001)
132360: accuracy:0.31 loss: 209.092 (lr:0.0001)
132370: accuracy:0.34 loss: 216.038 (lr:0.0001)
132380: accuracy:0.4 loss: 202.583 (lr:0.0001)
132390: accuracy:0.35 loss: 203.363 (lr:0.0001)
132400: accuracy:0.41 loss: 203.452 (lr:0.0001)
132410: accuracy:0.44 loss: 196.179 (lr:0.0001)
132420: accuracy:0.36 loss: 211.249 (lr:0.0001)
132430: accuracy:0.35 loss: 200.242 (lr:0.0001)
132440: accuracy:0.41 loss: 197.209 (lr:0.0001)
132450: accuracy:0.3 loss: 210.294 (lr:0.0001)
132460: accuracy:0.39 loss: 202.02 (lr:0.0001)
132470: accuracy:0.32 loss: 212.499 (lr:0.0001)
132480: accuracy:0.3 loss: 224.642 (lr:0.0001)
132490: accuracy:0.38 loss: 191.654 (lr:0.0001)
132500: accuracy:0.35 loss: 214.345 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
132500: ********* epoch 14 ********* test accuracy for all:0.25623 test loss: 255.404
132500: ********* epoch 14 ********* test accuracy for mode 0:0.039 test loss: 426.237
132500: ********* epoch 14 ********* test accuracy for mode 1:0.036 test loss: 427.632
132500: ********* epoch 14 ********* test accuracy for mode 2:0.035 test loss: 263.69
132500: ********* epoch 14 ********* test accuracy for mode 24:0.2435 test loss: 275.468
132500: ********* epoch 14 ********* test accuracy for mode 25:0.3065 test loss: 247.264
132500: ********* epoch 14 ********* test accuracy for mode 26:0.429 test loss: 166.221
132500: ********* epoch 14 ********* test accuracy for mode 27:0.2535 test loss: 267.035
132500: ********* epoch 14 ********* test accuracy for mode 28:0.2605 test loss: 258.716
132500: ********* epoch 14 ********* test accuracy for mode 29:0.254 test loss: 259.983
132500: ********* epoch 14 ********* test accuracy for mode 30:0.2845 test loss: 240.936
132500: ********* epoch 14 ********* test accuracy for mode 31:0.202 test loss: 246.262
132500: ********* epoch 14 ********* test accuracy for mode 32:0.2415 test loss: 232.705
132500: ********* epoch 14 ********* test accuracy for mode 33:0.2685 test loss: 234.863
132500: ********* epoch 14 ********* test accuracy for mode 34:0.2345 test loss: 237.585
132500: ********* epoch 14 ********* test accuracy for mode 35:0.104 test loss: 429.504
132500: ********* epoch 14 ********* test accuracy for mode 36:0.072 test loss: 471.468
132510: accuracy:0.28 loss: 207.2 (lr:0.0001)
132520: accuracy:0.3 loss: 213.746 (lr:0.0001)
132530: accuracy:0.27 loss: 214.352 (lr:0.0001)
132540: accuracy:0.29 loss: 215.637 (lr:0.0001)
132550: accuracy:0.33 loss: 223.854 (lr:0.0001)
132560: accuracy:0.39 loss: 189.464 (lr:0.0001)
132570: accuracy:0.27 loss: 215.874 (lr:0.0001)
132580: accuracy:0.36 loss: 198.165 (lr:0.0001)
132590: accuracy:0.4 loss: 186.867 (lr:0.0001)
132600: accuracy:0.37 loss: 204.675 (lr:0.0001)
132610: accuracy:0.32 loss: 224.081 (lr:0.0001)
132620: accuracy:0.24 loss: 206.736 (lr:0.0001)
132630: accuracy:0.44 loss: 204.895 (lr:0.0001)
132640: accuracy:0.27 loss: 212.141 (lr:0.0001)
132650: accuracy:0.3 loss: 204.611 (lr:0.0001)
132660: accuracy:0.31 loss: 217.204 (lr:0.0001)
132670: accuracy:0.31 loss: 210.297 (lr:0.0001)
132680: accuracy:0.29 loss: 216.189 (lr:0.0001)
132690: accuracy:0.36 loss: 208.868 (lr:0.0001)
132700: accuracy:0.32 loss: 209.045 (lr:0.0001)
132710: accuracy:0.3 loss: 211.26 (lr:0.0001)
132720: accuracy:0.36 loss: 198.661 (lr:0.0001)
132730: accuracy:0.43 loss: 184.544 (lr:0.0001)
132740: accuracy:0.36 loss: 218.423 (lr:0.0001)
132750: accuracy:0.31 loss: 224.383 (lr:0.0001)
132760: accuracy:0.37 loss: 217.692 (lr:0.0001)
132770: accuracy:0.37 loss: 207.35 (lr:0.0001)
132780: accuracy:0.29 loss: 226.627 (lr:0.0001)
132790: accuracy:0.33 loss: 213.135 (lr:0.0001)
132800: accuracy:0.4 loss: 191.97 (lr:0.0001)
132810: accuracy:0.37 loss: 206.072 (lr:0.0001)
132820: accuracy:0.32 loss: 212.666 (lr:0.0001)
132830: accuracy:0.36 loss: 210.518 (lr:0.0001)
132840: accuracy:0.36 loss: 210.496 (lr:0.0001)
132850: accuracy:0.44 loss: 188.001 (lr:0.0001)
132860: accuracy:0.28 loss: 215.621 (lr:0.0001)
132870: accuracy:0.42 loss: 197.793 (lr:0.0001)
132880: accuracy:0.4 loss: 203.41 (lr:0.0001)
132890: accuracy:0.35 loss: 205.95 (lr:0.0001)
132900: accuracy:0.34 loss: 230.156 (lr:0.0001)
132910: accuracy:0.37 loss: 236.853 (lr:0.0001)
132920: accuracy:0.33 loss: 219.047 (lr:0.0001)
132930: accuracy:0.36 loss: 216.047 (lr:0.0001)
132940: accuracy:0.45 loss: 205.422 (lr:0.0001)
132950: accuracy:0.28 loss: 212.328 (lr:0.0001)
132960: accuracy:0.35 loss: 205.384 (lr:0.0001)
132970: accuracy:0.32 loss: 217.812 (lr:0.0001)
132980: accuracy:0.33 loss: 205.798 (lr:0.0001)
132990: accuracy:0.36 loss: 199.194 (lr:0.0001)
133000: accuracy:0.33 loss: 213.775 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
133000: ********* epoch 14 ********* test accuracy for all:0.25977 test loss: 253.95
133000: ********* epoch 14 ********* test accuracy for mode 0:0.043 test loss: 417.831
133000: ********* epoch 14 ********* test accuracy for mode 1:0.0385 test loss: 424.747
133000: ********* epoch 14 ********* test accuracy for mode 2:0.036 test loss: 272.699
133000: ********* epoch 14 ********* test accuracy for mode 24:0.2665 test loss: 263.664
133000: ********* epoch 14 ********* test accuracy for mode 25:0.302 test loss: 237.654
133000: ********* epoch 14 ********* test accuracy for mode 26:0.401 test loss: 168.315
133000: ********* epoch 14 ********* test accuracy for mode 27:0.2425 test loss: 261.702
133000: ********* epoch 14 ********* test accuracy for mode 28:0.2815 test loss: 252.492
133000: ********* epoch 14 ********* test accuracy for mode 29:0.261 test loss: 261.337
133000: ********* epoch 14 ********* test accuracy for mode 30:0.262 test loss: 249.918
133000: ********* epoch 14 ********* test accuracy for mode 31:0.1785 test loss: 259.395
133000: ********* epoch 14 ********* test accuracy for mode 32:0.1705 test loss: 247.451
133000: ********* epoch 14 ********* test accuracy for mode 33:0.2875 test loss: 243.755
133000: ********* epoch 14 ********* test accuracy for mode 34:0.2105 test loss: 246.47
133000: ********* epoch 14 ********* test accuracy for mode 35:0.1285 test loss: 412.403
133000: ********* epoch 14 ********* test accuracy for mode 36:0.3115 test loss: 417.697
133010: accuracy:0.3 loss: 228.704 (lr:0.0001)
133020: accuracy:0.38 loss: 199.189 (lr:0.0001)
133030: accuracy:0.37 loss: 207.693 (lr:0.0001)
133040: accuracy:0.34 loss: 217.738 (lr:0.0001)
133050: accuracy:0.38 loss: 191.41 (lr:0.0001)
133060: accuracy:0.39 loss: 201.185 (lr:0.0001)
133070: accuracy:0.37 loss: 199.913 (lr:0.0001)
133080: accuracy:0.37 loss: 198.982 (lr:0.0001)
133090: accuracy:0.32 loss: 200.015 (lr:0.0001)
133100: accuracy:0.33 loss: 220.142 (lr:0.0001)
133110: accuracy:0.37 loss: 206.626 (lr:0.0001)
133120: accuracy:0.34 loss: 209.39 (lr:0.0001)
133130: accuracy:0.31 loss: 208.358 (lr:0.0001)
133140: accuracy:0.34 loss: 202.623 (lr:0.0001)
133150: accuracy:0.3 loss: 216.838 (lr:0.0001)
133160: accuracy:0.35 loss: 209.221 (lr:0.0001)
133170: accuracy:0.39 loss: 200.164 (lr:0.0001)
133180: accuracy:0.41 loss: 195.495 (lr:0.0001)
133190: accuracy:0.36 loss: 216.194 (lr:0.0001)
133200: accuracy:0.31 loss: 197.418 (lr:0.0001)
133210: accuracy:0.39 loss: 204.954 (lr:0.0001)
133220: accuracy:0.33 loss: 226.141 (lr:0.0001)
133230: accuracy:0.28 loss: 231.409 (lr:0.0001)
133240: accuracy:0.29 loss: 217.964 (lr:0.0001)
133250: accuracy:0.36 loss: 224.905 (lr:0.0001)
133260: accuracy:0.28 loss: 228.425 (lr:0.0001)
133270: accuracy:0.37 loss: 213.266 (lr:0.0001)
133280: accuracy:0.48 loss: 189.226 (lr:0.0001)
133290: accuracy:0.26 loss: 226.496 (lr:0.0001)
133300: accuracy:0.27 loss: 214.123 (lr:0.0001)
133310: accuracy:0.42 loss: 196.686 (lr:0.0001)
133320: accuracy:0.33 loss: 192.092 (lr:0.0001)
133330: accuracy:0.38 loss: 206.28 (lr:0.0001)
133340: accuracy:0.36 loss: 197.759 (lr:0.0001)
133350: accuracy:0.32 loss: 208.668 (lr:0.0001)
133360: accuracy:0.27 loss: 204.386 (lr:0.0001)
133370: accuracy:0.35 loss: 186.792 (lr:0.0001)
133380: accuracy:0.28 loss: 222.417 (lr:0.0001)
133390: accuracy:0.4 loss: 215.039 (lr:0.0001)
133400: accuracy:0.36 loss: 196.023 (lr:0.0001)
133410: accuracy:0.4 loss: 201.17 (lr:0.0001)
133420: accuracy:0.26 loss: 228.59 (lr:0.0001)
133430: accuracy:0.32 loss: 196.193 (lr:0.0001)
133440: accuracy:0.3 loss: 233.792 (lr:0.0001)
133450: accuracy:0.39 loss: 197.798 (lr:0.0001)
133460: accuracy:0.41 loss: 199.262 (lr:0.0001)
133470: accuracy:0.42 loss: 174.202 (lr:0.0001)
133480: accuracy:0.23 loss: 211.712 (lr:0.0001)
133490: accuracy:0.35 loss: 202.156 (lr:0.0001)
133500: accuracy:0.32 loss: 203.765 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
133500: ********* epoch 14 ********* test accuracy for all:0.265351 test loss: 254.259
133500: ********* epoch 14 ********* test accuracy for mode 0:0.043 test loss: 427.461
133500: ********* epoch 14 ********* test accuracy for mode 1:0.0295 test loss: 425.872
133500: ********* epoch 14 ********* test accuracy for mode 2:0.07 test loss: 259.917
133500: ********* epoch 14 ********* test accuracy for mode 24:0.2255 test loss: 270.727
133500: ********* epoch 14 ********* test accuracy for mode 25:0.261 test loss: 245.848
133500: ********* epoch 14 ********* test accuracy for mode 26:0.509 test loss: 153.943
133500: ********* epoch 14 ********* test accuracy for mode 27:0.251 test loss: 259.772
133500: ********* epoch 14 ********* test accuracy for mode 28:0.274 test loss: 255.844
133500: ********* epoch 14 ********* test accuracy for mode 29:0.2605 test loss: 266.498
133500: ********* epoch 14 ********* test accuracy for mode 30:0.252 test loss: 253.551
133500: ********* epoch 14 ********* test accuracy for mode 31:0.1605 test loss: 262.111
133500: ********* epoch 14 ********* test accuracy for mode 32:0.194 test loss: 244.457
133500: ********* epoch 14 ********* test accuracy for mode 33:0.2545 test loss: 243.014
133500: ********* epoch 14 ********* test accuracy for mode 34:0.2565 test loss: 239.905
133500: ********* epoch 14 ********* test accuracy for mode 35:0.116 test loss: 434.583
133500: ********* epoch 14 ********* test accuracy for mode 36:0.344 test loss: 428.566
133510: accuracy:0.41 loss: 195.165 (lr:0.0001)
133520: accuracy:0.37 loss: 220.283 (lr:0.0001)
133530: accuracy:0.27 loss: 228.081 (lr:0.0001)
133540: accuracy:0.39 loss: 203.29 (lr:0.0001)
133550: accuracy:0.37 loss: 201.927 (lr:0.0001)
133560: accuracy:0.31 loss: 216.368 (lr:0.0001)
133570: accuracy:0.37 loss: 206.248 (lr:0.0001)
133580: accuracy:0.35 loss: 227.16 (lr:0.0001)
133590: accuracy:0.35 loss: 187.358 (lr:0.0001)
133600: accuracy:0.39 loss: 201.751 (lr:0.0001)
133610: accuracy:0.34 loss: 215.775 (lr:0.0001)
133620: accuracy:0.4 loss: 205.978 (lr:0.0001)
133630: accuracy:0.38 loss: 203.75 (lr:0.0001)
133640: accuracy:0.32 loss: 234.248 (lr:0.0001)
133650: accuracy:0.3 loss: 202.268 (lr:0.0001)
133660: accuracy:0.28 loss: 213.324 (lr:0.0001)
133670: accuracy:0.3 loss: 214.606 (lr:0.0001)
133680: accuracy:0.39 loss: 191.42 (lr:0.0001)
133690: accuracy:0.37 loss: 207.6 (lr:0.0001)
133700: accuracy:0.32 loss: 209.67 (lr:0.0001)
133710: accuracy:0.38 loss: 212.445 (lr:0.0001)
133720: accuracy:0.28 loss: 205.593 (lr:0.0001)
133730: accuracy:0.36 loss: 211.907 (lr:0.0001)
133740: accuracy:0.34 loss: 204.51 (lr:0.0001)
133750: accuracy:0.37 loss: 218.183 (lr:0.0001)
133760: accuracy:0.29 loss: 223.672 (lr:0.0001)
133770: accuracy:0.39 loss: 196.464 (lr:0.0001)
133780: accuracy:0.33 loss: 230.276 (lr:0.0001)
133790: accuracy:0.34 loss: 214.663 (lr:0.0001)
133800: accuracy:0.32 loss: 234.51 (lr:0.0001)
133810: accuracy:0.31 loss: 214.048 (lr:0.0001)
133820: accuracy:0.38 loss: 182.592 (lr:0.0001)
133830: accuracy:0.39 loss: 188.866 (lr:0.0001)
133840: accuracy:0.27 loss: 217.218 (lr:0.0001)
133850: accuracy:0.35 loss: 212.341 (lr:0.0001)
133860: accuracy:0.36 loss: 206.117 (lr:0.0001)
133870: accuracy:0.38 loss: 203.097 (lr:0.0001)
133880: accuracy:0.39 loss: 214.404 (lr:0.0001)
133890: accuracy:0.34 loss: 198.384 (lr:0.0001)
133900: accuracy:0.37 loss: 212.923 (lr:0.0001)
133910: accuracy:0.35 loss: 204.59 (lr:0.0001)
133920: accuracy:0.38 loss: 222.258 (lr:0.0001)
133930: accuracy:0.3 loss: 223.03 (lr:0.0001)
133940: accuracy:0.31 loss: 216.577 (lr:0.0001)
133950: accuracy:0.35 loss: 215.109 (lr:0.0001)
133960: accuracy:0.29 loss: 221.95 (lr:0.0001)
133970: accuracy:0.3 loss: 245.16 (lr:0.0001)
133980: accuracy:0.27 loss: 219.194 (lr:0.0001)
133990: accuracy:0.34 loss: 208.443 (lr:0.0001)
134000: accuracy:0.32 loss: 206.713 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
134000: ********* epoch 14 ********* test accuracy for all:0.2595 test loss: 254.09
134000: ********* epoch 14 ********* test accuracy for mode 0:0.0355 test loss: 429.731
134000: ********* epoch 14 ********* test accuracy for mode 1:0.0385 test loss: 423.275
134000: ********* epoch 14 ********* test accuracy for mode 2:0.044 test loss: 264.61
134000: ********* epoch 14 ********* test accuracy for mode 24:0.252 test loss: 264.963
134000: ********* epoch 14 ********* test accuracy for mode 25:0.3045 test loss: 244.803
134000: ********* epoch 14 ********* test accuracy for mode 26:0.4485 test loss: 162.796
134000: ********* epoch 14 ********* test accuracy for mode 27:0.223 test loss: 269.507
134000: ********* epoch 14 ********* test accuracy for mode 28:0.2955 test loss: 252.759
134000: ********* epoch 14 ********* test accuracy for mode 29:0.2885 test loss: 259.795
134000: ********* epoch 14 ********* test accuracy for mode 30:0.278 test loss: 242.95
134000: ********* epoch 14 ********* test accuracy for mode 31:0.181 test loss: 252.124
134000: ********* epoch 14 ********* test accuracy for mode 32:0.229 test loss: 234.494
134000: ********* epoch 14 ********* test accuracy for mode 33:0.275 test loss: 235.706
134000: ********* epoch 14 ********* test accuracy for mode 34:0.2555 test loss: 237.874
134000: ********* epoch 14 ********* test accuracy for mode 35:0.063 test loss: 437.105
134000: ********* epoch 14 ********* test accuracy for mode 36:0.0915 test loss: 475.471
134010: accuracy:0.26 loss: 217.596 (lr:0.0001)
134020: accuracy:0.38 loss: 206.907 (lr:0.0001)
134030: accuracy:0.39 loss: 195.2 (lr:0.0001)
134040: accuracy:0.28 loss: 225.493 (lr:0.0001)
134050: accuracy:0.44 loss: 211.216 (lr:0.0001)
134060: accuracy:0.38 loss: 209.022 (lr:0.0001)
134070: accuracy:0.39 loss: 199.986 (lr:0.0001)
134080: accuracy:0.32 loss: 210.639 (lr:0.0001)
134090: accuracy:0.28 loss: 218.629 (lr:0.0001)
134100: accuracy:0.31 loss: 216.408 (lr:0.0001)
134110: accuracy:0.3 loss: 209.743 (lr:0.0001)
134120: accuracy:0.29 loss: 223.16 (lr:0.0001)
134130: accuracy:0.34 loss: 196.51 (lr:0.0001)
134140: accuracy:0.42 loss: 192.439 (lr:0.0001)
134150: accuracy:0.34 loss: 208.726 (lr:0.0001)
134160: accuracy:0.28 loss: 233.686 (lr:0.0001)
134170: accuracy:0.32 loss: 211.981 (lr:0.0001)
134180: accuracy:0.32 loss: 220.02 (lr:0.0001)
134190: accuracy:0.36 loss: 214.442 (lr:0.0001)
134200: accuracy:0.31 loss: 221.804 (lr:0.0001)
134210: accuracy:0.33 loss: 208.758 (lr:0.0001)
134220: accuracy:0.29 loss: 218.664 (lr:0.0001)
134230: accuracy:0.34 loss: 198.333 (lr:0.0001)
134240: accuracy:0.41 loss: 197.927 (lr:0.0001)
134250: accuracy:0.32 loss: 219.091 (lr:0.0001)
134260: accuracy:0.4 loss: 191.319 (lr:0.0001)
134270: accuracy:0.38 loss: 210.654 (lr:0.0001)
134280: accuracy:0.35 loss: 204.21 (lr:0.0001)
134290: accuracy:0.44 loss: 192.548 (lr:0.0001)
134300: accuracy:0.37 loss: 194.357 (lr:0.0001)
134310: accuracy:0.41 loss: 208.121 (lr:0.0001)
134320: accuracy:0.36 loss: 202.411 (lr:0.0001)
134330: accuracy:0.36 loss: 205.712 (lr:0.0001)
134340: accuracy:0.32 loss: 222.342 (lr:0.0001)
134350: accuracy:0.27 loss: 229.16 (lr:0.0001)
134360: accuracy:0.34 loss: 217.883 (lr:0.0001)
134370: accuracy:0.36 loss: 199.491 (lr:0.0001)
134380: accuracy:0.3 loss: 214.583 (lr:0.0001)
134390: accuracy:0.32 loss: 217.644 (lr:0.0001)
134400: accuracy:0.31 loss: 197.841 (lr:0.0001)
134410: accuracy:0.34 loss: 201.35 (lr:0.0001)
134420: accuracy:0.35 loss: 211.493 (lr:0.0001)
134430: accuracy:0.27 loss: 209.378 (lr:0.0001)
134440: accuracy:0.33 loss: 205.978 (lr:0.0001)
134450: accuracy:0.32 loss: 206.998 (lr:0.0001)
134460: accuracy:0.32 loss: 204.291 (lr:0.0001)
134470: accuracy:0.35 loss: 203.83 (lr:0.0001)
134480: accuracy:0.35 loss: 212.208 (lr:0.0001)
134490: accuracy:0.23 loss: 242.212 (lr:0.0001)
134500: accuracy:0.36 loss: 227.207 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
134500: ********* epoch 14 ********* test accuracy for all:0.259135 test loss: 253.782
134500: ********* epoch 14 ********* test accuracy for mode 0:0.0425 test loss: 429.785
134500: ********* epoch 14 ********* test accuracy for mode 1:0.035 test loss: 425.67
134500: ********* epoch 14 ********* test accuracy for mode 2:0.055 test loss: 255.788
134500: ********* epoch 14 ********* test accuracy for mode 24:0.263 test loss: 273.337
134500: ********* epoch 14 ********* test accuracy for mode 25:0.259 test loss: 257.949
134500: ********* epoch 14 ********* test accuracy for mode 26:0.457 test loss: 165.61
134500: ********* epoch 14 ********* test accuracy for mode 27:0.254 test loss: 265.649
134500: ********* epoch 14 ********* test accuracy for mode 28:0.31 test loss: 255.354
134500: ********* epoch 14 ********* test accuracy for mode 29:0.2435 test loss: 267.068
134500: ********* epoch 14 ********* test accuracy for mode 30:0.255 test loss: 247.686
134500: ********* epoch 14 ********* test accuracy for mode 31:0.203 test loss: 252.093
134500: ********* epoch 14 ********* test accuracy for mode 32:0.194 test loss: 237.075
134500: ********* epoch 14 ********* test accuracy for mode 33:0.3005 test loss: 235.816
134500: ********* epoch 14 ********* test accuracy for mode 34:0.193 test loss: 240.947
134500: ********* epoch 14 ********* test accuracy for mode 35:0.0655 test loss: 427.4
134500: ********* epoch 14 ********* test accuracy for mode 36:0.1335 test loss: 446.029
134510: accuracy:0.4 loss: 183.675 (lr:0.0001)
134520: accuracy:0.29 loss: 216.102 (lr:0.0001)
134530: accuracy:0.38 loss: 211.665 (lr:0.0001)
134540: accuracy:0.35 loss: 207.199 (lr:0.0001)
134550: accuracy:0.39 loss: 213.23 (lr:0.0001)
134560: accuracy:0.42 loss: 189.429 (lr:0.0001)
134570: accuracy:0.35 loss: 201.025 (lr:0.0001)
134580: accuracy:0.36 loss: 214.951 (lr:0.0001)
134590: accuracy:0.31 loss: 214.295 (lr:0.0001)
134600: accuracy:0.39 loss: 223.984 (lr:0.0001)
134610: accuracy:0.46 loss: 195.641 (lr:0.0001)
134620: accuracy:0.37 loss: 214.058 (lr:0.0001)
134630: accuracy:0.32 loss: 198.719 (lr:0.0001)
134640: accuracy:0.4 loss: 187.527 (lr:0.0001)
134650: accuracy:0.29 loss: 229.948 (lr:0.0001)
134660: accuracy:0.34 loss: 211.329 (lr:0.0001)
134670: accuracy:0.36 loss: 202.147 (lr:0.0001)
134680: accuracy:0.4 loss: 196.668 (lr:0.0001)
134690: accuracy:0.28 loss: 193.016 (lr:0.0001)
134700: accuracy:0.4 loss: 186.022 (lr:0.0001)
134710: accuracy:0.35 loss: 191.6 (lr:0.0001)
134720: accuracy:0.38 loss: 192.798 (lr:0.0001)
134730: accuracy:0.3 loss: 208.812 (lr:0.0001)
134740: accuracy:0.28 loss: 221.843 (lr:0.0001)
134750: accuracy:0.38 loss: 202.799 (lr:0.0001)
134760: accuracy:0.36 loss: 205.091 (lr:0.0001)
134770: accuracy:0.44 loss: 183.04 (lr:0.0001)
134780: accuracy:0.29 loss: 223.559 (lr:0.0001)
134790: accuracy:0.38 loss: 204.206 (lr:0.0001)
134800: accuracy:0.3 loss: 216.358 (lr:0.0001)
134810: accuracy:0.33 loss: 201.88 (lr:0.0001)
134820: accuracy:0.39 loss: 202.256 (lr:0.0001)
134830: accuracy:0.38 loss: 196.709 (lr:0.0001)
134840: accuracy:0.35 loss: 203.588 (lr:0.0001)
134850: accuracy:0.37 loss: 193.308 (lr:0.0001)
134860: accuracy:0.35 loss: 200.736 (lr:0.0001)
134870: accuracy:0.37 loss: 193.722 (lr:0.0001)
134880: accuracy:0.36 loss: 184.125 (lr:0.0001)
134890: accuracy:0.35 loss: 207.574 (lr:0.0001)
134900: accuracy:0.31 loss: 216.693 (lr:0.0001)
134910: accuracy:0.4 loss: 198.558 (lr:0.0001)
134920: accuracy:0.34 loss: 221.959 (lr:0.0001)
134930: accuracy:0.33 loss: 195.177 (lr:0.0001)
134940: accuracy:0.37 loss: 212.378 (lr:0.0001)
134950: accuracy:0.41 loss: 200.923 (lr:0.0001)
134960: accuracy:0.43 loss: 189.691 (lr:0.0001)
134970: accuracy:0.39 loss: 198.239 (lr:0.0001)
134980: accuracy:0.34 loss: 224.913 (lr:0.0001)
134990: accuracy:0.29 loss: 223.874 (lr:0.0001)
135000: accuracy:0.37 loss: 212.062 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
135000: ********* epoch 14 ********* test accuracy for all:0.258095 test loss: 254.036
135000: ********* epoch 14 ********* test accuracy for mode 0:0.0385 test loss: 431.392
135000: ********* epoch 14 ********* test accuracy for mode 1:0.033 test loss: 426.685
135000: ********* epoch 14 ********* test accuracy for mode 2:0.077 test loss: 262.166
135000: ********* epoch 14 ********* test accuracy for mode 24:0.2485 test loss: 262.044
135000: ********* epoch 14 ********* test accuracy for mode 25:0.308 test loss: 240.868
135000: ********* epoch 14 ********* test accuracy for mode 26:0.4905 test loss: 158.436
135000: ********* epoch 14 ********* test accuracy for mode 27:0.249 test loss: 262.192
135000: ********* epoch 14 ********* test accuracy for mode 28:0.2825 test loss: 251.955
135000: ********* epoch 14 ********* test accuracy for mode 29:0.2805 test loss: 261.304
135000: ********* epoch 14 ********* test accuracy for mode 30:0.254 test loss: 246.155
135000: ********* epoch 14 ********* test accuracy for mode 31:0.213 test loss: 252.083
135000: ********* epoch 14 ********* test accuracy for mode 32:0.2005 test loss: 238.981
135000: ********* epoch 14 ********* test accuracy for mode 33:0.2725 test loss: 241.579
135000: ********* epoch 14 ********* test accuracy for mode 34:0.199 test loss: 248.976
135000: ********* epoch 14 ********* test accuracy for mode 35:0.0485 test loss: 447.262
135000: ********* epoch 14 ********* test accuracy for mode 36:0.077 test loss: 496.526
135010: accuracy:0.36 loss: 195.183 (lr:0.0001)
135020: accuracy:0.38 loss: 198.078 (lr:0.0001)
135030: accuracy:0.34 loss: 195.301 (lr:0.0001)
135040: accuracy:0.35 loss: 220.384 (lr:0.0001)
135050: accuracy:0.41 loss: 198.726 (lr:0.0001)
135060: accuracy:0.32 loss: 214.203 (lr:0.0001)
135070: accuracy:0.34 loss: 217.403 (lr:0.0001)
135080: accuracy:0.33 loss: 207.7 (lr:0.0001)
135090: accuracy:0.34 loss: 213.604 (lr:0.0001)
135100: accuracy:0.31 loss: 211.615 (lr:0.0001)
135110: accuracy:0.28 loss: 209.896 (lr:0.0001)
135120: accuracy:0.38 loss: 208.006 (lr:0.0001)
135130: accuracy:0.33 loss: 209.503 (lr:0.0001)
135140: accuracy:0.31 loss: 226.188 (lr:0.0001)
135150: accuracy:0.3 loss: 209.48 (lr:0.0001)
135160: accuracy:0.34 loss: 199.609 (lr:0.0001)
135170: accuracy:0.35 loss: 211.685 (lr:0.0001)
135180: accuracy:0.29 loss: 224.786 (lr:0.0001)
135190: accuracy:0.4 loss: 201.111 (lr:0.0001)
135200: accuracy:0.38 loss: 206.527 (lr:0.0001)
135210: accuracy:0.28 loss: 232.401 (lr:0.0001)
135220: accuracy:0.38 loss: 192.335 (lr:0.0001)
135230: accuracy:0.35 loss: 204.611 (lr:0.0001)
135240: accuracy:0.32 loss: 194.943 (lr:0.0001)
135250: accuracy:0.37 loss: 212.098 (lr:0.0001)
135260: accuracy:0.26 loss: 216.611 (lr:0.0001)
135270: accuracy:0.32 loss: 209.928 (lr:0.0001)
135280: accuracy:0.35 loss: 204.693 (lr:0.0001)
135290: accuracy:0.32 loss: 204.901 (lr:0.0001)
135300: accuracy:0.33 loss: 224.202 (lr:0.0001)
135310: accuracy:0.42 loss: 210.463 (lr:0.0001)
135320: accuracy:0.41 loss: 205.232 (lr:0.0001)
135330: accuracy:0.41 loss: 195.207 (lr:0.0001)
135340: accuracy:0.35 loss: 201.662 (lr:0.0001)
135350: accuracy:0.44 loss: 185.88 (lr:0.0001)
135360: accuracy:0.38 loss: 220.146 (lr:0.0001)
135370: accuracy:0.33 loss: 209.012 (lr:0.0001)
135380: accuracy:0.34 loss: 214.154 (lr:0.0001)
135390: accuracy:0.29 loss: 227.444 (lr:0.0001)
135400: accuracy:0.36 loss: 214.438 (lr:0.0001)
135410: accuracy:0.38 loss: 190.802 (lr:0.0001)
135420: accuracy:0.27 loss: 211.103 (lr:0.0001)
135430: accuracy:0.32 loss: 215.201 (lr:0.0001)
135440: accuracy:0.41 loss: 205.308 (lr:0.0001)
135450: accuracy:0.31 loss: 213.684 (lr:0.0001)
135460: accuracy:0.4 loss: 188.071 (lr:0.0001)
135470: accuracy:0.28 loss: 205.4 (lr:0.0001)
135480: accuracy:0.31 loss: 230.649 (lr:0.0001)
135490: accuracy:0.39 loss: 192.798 (lr:0.0001)
135500: accuracy:0.36 loss: 213.402 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
135500: ********* epoch 14 ********* test accuracy for all:0.258486 test loss: 254.881
135500: ********* epoch 14 ********* test accuracy for mode 0:0.046 test loss: 436.146
135500: ********* epoch 14 ********* test accuracy for mode 1:0.0305 test loss: 432.913
135500: ********* epoch 14 ********* test accuracy for mode 2:0.0395 test loss: 262.961
135500: ********* epoch 14 ********* test accuracy for mode 24:0.274 test loss: 265.467
135500: ********* epoch 14 ********* test accuracy for mode 25:0.3245 test loss: 242.391
135500: ********* epoch 14 ********* test accuracy for mode 26:0.487 test loss: 155.962
135500: ********* epoch 14 ********* test accuracy for mode 27:0.2735 test loss: 259.388
135500: ********* epoch 14 ********* test accuracy for mode 28:0.2695 test loss: 260.889
135500: ********* epoch 14 ********* test accuracy for mode 29:0.2665 test loss: 268.184
135500: ********* epoch 14 ********* test accuracy for mode 30:0.258 test loss: 252.008
135500: ********* epoch 14 ********* test accuracy for mode 31:0.18 test loss: 258.642
135500: ********* epoch 14 ********* test accuracy for mode 32:0.2005 test loss: 242.292
135500: ********* epoch 14 ********* test accuracy for mode 33:0.27 test loss: 244.012
135500: ********* epoch 14 ********* test accuracy for mode 34:0.2135 test loss: 246.757
135500: ********* epoch 14 ********* test accuracy for mode 35:0.0545 test loss: 443.169
135500: ********* epoch 14 ********* test accuracy for mode 36:0.0935 test loss: 465.41
135510: accuracy:0.44 loss: 185.71 (lr:0.0001)
135520: accuracy:0.29 loss: 216.247 (lr:0.0001)
135530: accuracy:0.28 loss: 210.772 (lr:0.0001)
135540: accuracy:0.33 loss: 196.11 (lr:0.0001)
135550: accuracy:0.31 loss: 210.215 (lr:0.0001)
135560: accuracy:0.31 loss: 211.389 (lr:0.0001)
135570: accuracy:0.3 loss: 206.499 (lr:0.0001)
135580: accuracy:0.33 loss: 213.497 (lr:0.0001)
135590: accuracy:0.38 loss: 214.349 (lr:0.0001)
135600: accuracy:0.25 loss: 233.031 (lr:0.0001)
135610: accuracy:0.48 loss: 199.281 (lr:0.0001)
135620: accuracy:0.42 loss: 206.551 (lr:0.0001)
135630: accuracy:0.34 loss: 213.44 (lr:0.0001)
135640: accuracy:0.34 loss: 210.867 (lr:0.0001)
135650: accuracy:0.29 loss: 205.787 (lr:0.0001)
135660: accuracy:0.39 loss: 207.194 (lr:0.0001)
135670: accuracy:0.31 loss: 215.116 (lr:0.0001)
135680: accuracy:0.35 loss: 195.532 (lr:0.0001)
135690: accuracy:0.29 loss: 208.527 (lr:0.0001)
135700: accuracy:0.35 loss: 190.459 (lr:0.0001)
135710: accuracy:0.47 loss: 190.552 (lr:0.0001)
135720: accuracy:0.36 loss: 192.383 (lr:0.0001)
135730: accuracy:0.29 loss: 222.864 (lr:0.0001)
135740: accuracy:0.39 loss: 189.178 (lr:0.0001)
135750: accuracy:0.27 loss: 228.695 (lr:0.0001)
135760: accuracy:0.4 loss: 203.988 (lr:0.0001)
135770: accuracy:0.3 loss: 218.06 (lr:0.0001)
135780: accuracy:0.37 loss: 206.42 (lr:0.0001)
135790: accuracy:0.33 loss: 208.703 (lr:0.0001)
135800: accuracy:0.36 loss: 207.584 (lr:0.0001)
135810: accuracy:0.44 loss: 187.647 (lr:0.0001)
135820: accuracy:0.32 loss: 193.657 (lr:0.0001)
135830: accuracy:0.36 loss: 217.658 (lr:0.0001)
135840: accuracy:0.34 loss: 216.977 (lr:0.0001)
135850: accuracy:0.42 loss: 191.414 (lr:0.0001)
135860: accuracy:0.25 loss: 223.158 (lr:0.0001)
135870: accuracy:0.28 loss: 238.079 (lr:0.0001)
135880: accuracy:0.27 loss: 210.573 (lr:0.0001)
135890: accuracy:0.28 loss: 212.779 (lr:0.0001)
135900: accuracy:0.33 loss: 208.567 (lr:0.0001)
135910: accuracy:0.3 loss: 200.754 (lr:0.0001)
135920: accuracy:0.39 loss: 186.16 (lr:0.0001)
135930: accuracy:0.37 loss: 206.642 (lr:0.0001)
135940: accuracy:0.37 loss: 200.191 (lr:0.0001)
135950: accuracy:0.38 loss: 203.714 (lr:0.0001)
135960: accuracy:0.41 loss: 216.827 (lr:0.0001)
135970: accuracy:0.34 loss: 198.744 (lr:0.0001)
135980: accuracy:0.32 loss: 210.082 (lr:0.0001)
135990: accuracy:0.4 loss: 205.482 (lr:0.0001)
136000: accuracy:0.32 loss: 213.374 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
136000: ********* epoch 14 ********* test accuracy for all:0.258486 test loss: 254.437
136000: ********* epoch 14 ********* test accuracy for mode 0:0.047 test loss: 418.309
136000: ********* epoch 14 ********* test accuracy for mode 1:0.036 test loss: 412.518
136000: ********* epoch 14 ********* test accuracy for mode 2:0.0255 test loss: 268.266
136000: ********* epoch 14 ********* test accuracy for mode 24:0.2545 test loss: 258.055
136000: ********* epoch 14 ********* test accuracy for mode 25:0.317 test loss: 239.056
136000: ********* epoch 14 ********* test accuracy for mode 26:0.4335 test loss: 168.413
136000: ********* epoch 14 ********* test accuracy for mode 27:0.221 test loss: 266.472
136000: ********* epoch 14 ********* test accuracy for mode 28:0.2905 test loss: 248.571
136000: ********* epoch 14 ********* test accuracy for mode 29:0.2945 test loss: 253.17
136000: ********* epoch 14 ********* test accuracy for mode 30:0.2365 test loss: 247.183
136000: ********* epoch 14 ********* test accuracy for mode 31:0.235 test loss: 251.982
136000: ********* epoch 14 ********* test accuracy for mode 32:0.2165 test loss: 239.51
136000: ********* epoch 14 ********* test accuracy for mode 33:0.284 test loss: 242.541
136000: ********* epoch 14 ********* test accuracy for mode 34:0.2185 test loss: 247.138
136000: ********* epoch 14 ********* test accuracy for mode 35:0.0635 test loss: 427.439
136000: ********* epoch 14 ********* test accuracy for mode 36:0.0775 test loss: 507.278
136010: accuracy:0.34 loss: 210.922 (lr:0.0001)
136020: accuracy:0.36 loss: 198.937 (lr:0.0001)
136030: accuracy:0.39 loss: 195.834 (lr:0.0001)
136040: accuracy:0.38 loss: 199.468 (lr:0.0001)
136050: accuracy:0.34 loss: 194.257 (lr:0.0001)
136060: accuracy:0.37 loss: 209.172 (lr:0.0001)
136070: accuracy:0.28 loss: 202.821 (lr:0.0001)
136080: accuracy:0.36 loss: 199.45 (lr:0.0001)
136090: accuracy:0.27 loss: 232.997 (lr:0.0001)
136100: accuracy:0.39 loss: 206.54 (lr:0.0001)
136110: accuracy:0.35 loss: 210.141 (lr:0.0001)
136120: accuracy:0.35 loss: 210.223 (lr:0.0001)
136130: accuracy:0.42 loss: 203.349 (lr:0.0001)
136140: accuracy:0.39 loss: 195.53 (lr:0.0001)
136150: accuracy:0.42 loss: 187.677 (lr:0.0001)
136160: accuracy:0.34 loss: 217.704 (lr:0.0001)
136170: accuracy:0.47 loss: 203.685 (lr:0.0001)
136180: accuracy:0.24 loss: 226.195 (lr:0.0001)
136190: accuracy:0.42 loss: 191.397 (lr:0.0001)
136200: accuracy:0.36 loss: 234.278 (lr:0.0001)
136210: accuracy:0.4 loss: 203.119 (lr:0.0001)
136220: accuracy:0.32 loss: 213.366 (lr:0.0001)
136230: accuracy:0.36 loss: 203.258 (lr:0.0001)
136240: accuracy:0.34 loss: 211.968 (lr:0.0001)
136250: accuracy:0.31 loss: 198.202 (lr:0.0001)
136260: accuracy:0.35 loss: 204.225 (lr:0.0001)
136270: accuracy:0.33 loss: 210.768 (lr:0.0001)
136280: accuracy:0.29 loss: 219.721 (lr:0.0001)
136290: accuracy:0.38 loss: 200.491 (lr:0.0001)
136300: accuracy:0.34 loss: 221.79 (lr:0.0001)
136310: accuracy:0.35 loss: 190.51 (lr:0.0001)
136320: accuracy:0.3 loss: 211.481 (lr:0.0001)
136330: accuracy:0.41 loss: 196.838 (lr:0.0001)
136340: accuracy:0.31 loss: 205.714 (lr:0.0001)
136350: accuracy:0.37 loss: 201.658 (lr:0.0001)
136360: accuracy:0.42 loss: 188.906 (lr:0.0001)
136370: accuracy:0.31 loss: 209.798 (lr:0.0001)
136380: accuracy:0.43 loss: 216.637 (lr:0.0001)
136390: accuracy:0.36 loss: 193.37 (lr:0.0001)
136400: accuracy:0.33 loss: 197.405 (lr:0.0001)
136410: accuracy:0.41 loss: 189.047 (lr:0.0001)
136420: accuracy:0.32 loss: 220.942 (lr:0.0001)
136430: accuracy:0.38 loss: 211.762 (lr:0.0001)
136440: accuracy:0.32 loss: 204.925 (lr:0.0001)
136450: accuracy:0.38 loss: 183.22 (lr:0.0001)
136460: accuracy:0.33 loss: 201.077 (lr:0.0001)
136470: accuracy:0.36 loss: 210.126 (lr:0.0001)
136480: accuracy:0.39 loss: 205.721 (lr:0.0001)
136490: accuracy:0.39 loss: 193.33 (lr:0.0001)
136500: accuracy:0.36 loss: 203.915 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
136500: ********* epoch 15 ********* test accuracy for all:0.261122 test loss: 255.448
136500: ********* epoch 15 ********* test accuracy for mode 0:0.0375 test loss: 444.126
136500: ********* epoch 15 ********* test accuracy for mode 1:0.036 test loss: 433.725
136500: ********* epoch 15 ********* test accuracy for mode 2:0.053 test loss: 257.785
136500: ********* epoch 15 ********* test accuracy for mode 24:0.2465 test loss: 266.936
136500: ********* epoch 15 ********* test accuracy for mode 25:0.3 test loss: 249.427
136500: ********* epoch 15 ********* test accuracy for mode 26:0.4865 test loss: 163.387
136500: ********* epoch 15 ********* test accuracy for mode 27:0.222 test loss: 273.099
136500: ********* epoch 15 ********* test accuracy for mode 28:0.2705 test loss: 260.927
136500: ********* epoch 15 ********* test accuracy for mode 29:0.25 test loss: 259.793
136500: ********* epoch 15 ********* test accuracy for mode 30:0.2695 test loss: 241.072
136500: ********* epoch 15 ********* test accuracy for mode 31:0.186 test loss: 246.175
136500: ********* epoch 15 ********* test accuracy for mode 32:0.2385 test loss: 228.294
136500: ********* epoch 15 ********* test accuracy for mode 33:0.3115 test loss: 230.456
136500: ********* epoch 15 ********* test accuracy for mode 34:0.1695 test loss: 240.098
136500: ********* epoch 15 ********* test accuracy for mode 35:0.0815 test loss: 431.385
136500: ********* epoch 15 ********* test accuracy for mode 36:0.273 test loss: 437.508
136510: accuracy:0.38 loss: 187.917 (lr:0.0001)
136520: accuracy:0.38 loss: 194.195 (lr:0.0001)
136530: accuracy:0.33 loss: 222.107 (lr:0.0001)
136540: accuracy:0.37 loss: 207.388 (lr:0.0001)
136550: accuracy:0.35 loss: 199.933 (lr:0.0001)
136560: accuracy:0.36 loss: 198.486 (lr:0.0001)
136570: accuracy:0.4 loss: 184.311 (lr:0.0001)
136580: accuracy:0.32 loss: 201.588 (lr:0.0001)
136590: accuracy:0.3 loss: 213.126 (lr:0.0001)
136600: accuracy:0.35 loss: 230.617 (lr:0.0001)
136610: accuracy:0.33 loss: 242.437 (lr:0.0001)
136620: accuracy:0.37 loss: 197.807 (lr:0.0001)
136630: accuracy:0.38 loss: 202.626 (lr:0.0001)
136640: accuracy:0.36 loss: 197.6 (lr:0.0001)
136650: accuracy:0.26 loss: 235.944 (lr:0.0001)
136660: accuracy:0.42 loss: 195.123 (lr:0.0001)
136670: accuracy:0.35 loss: 212.446 (lr:0.0001)
136680: accuracy:0.4 loss: 193.581 (lr:0.0001)
136690: accuracy:0.44 loss: 183.532 (lr:0.0001)
136700: accuracy:0.42 loss: 197.481 (lr:0.0001)
136710: accuracy:0.34 loss: 179.572 (lr:0.0001)
136720: accuracy:0.31 loss: 198.234 (lr:0.0001)
136730: accuracy:0.43 loss: 185.584 (lr:0.0001)
136740: accuracy:0.25 loss: 215.4 (lr:0.0001)
136750: accuracy:0.33 loss: 197.748 (lr:0.0001)
136760: accuracy:0.36 loss: 200.409 (lr:0.0001)
136770: accuracy:0.3 loss: 199.42 (lr:0.0001)
136780: accuracy:0.31 loss: 203.244 (lr:0.0001)
136790: accuracy:0.39 loss: 189.134 (lr:0.0001)
136800: accuracy:0.33 loss: 185.791 (lr:0.0001)
136810: accuracy:0.47 loss: 175.504 (lr:0.0001)
136820: accuracy:0.38 loss: 210.457 (lr:0.0001)
136830: accuracy:0.33 loss: 203.749 (lr:0.0001)
136840: accuracy:0.38 loss: 186.669 (lr:0.0001)
136850: accuracy:0.32 loss: 222.015 (lr:0.0001)
136860: accuracy:0.3 loss: 224.019 (lr:0.0001)
136870: accuracy:0.36 loss: 199.007 (lr:0.0001)
136880: accuracy:0.31 loss: 219.461 (lr:0.0001)
136890: accuracy:0.38 loss: 198.098 (lr:0.0001)
136900: accuracy:0.37 loss: 201.902 (lr:0.0001)
136910: accuracy:0.3 loss: 215.667 (lr:0.0001)
136920: accuracy:0.3 loss: 197.561 (lr:0.0001)
136930: accuracy:0.47 loss: 170.58 (lr:0.0001)
136940: accuracy:0.37 loss: 184.111 (lr:0.0001)
136950: accuracy:0.35 loss: 213.97 (lr:0.0001)
136960: accuracy:0.29 loss: 228.9 (lr:0.0001)
136970: accuracy:0.32 loss: 228.272 (lr:0.0001)
136980: accuracy:0.33 loss: 218.063 (lr:0.0001)
136990: accuracy:0.35 loss: 210.013 (lr:0.0001)
137000: accuracy:0.3 loss: 223.466 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
137000: ********* epoch 15 ********* test accuracy for all:0.257149 test loss: 256.008
137000: ********* epoch 15 ********* test accuracy for mode 0:0.0395 test loss: 436.413
137000: ********* epoch 15 ********* test accuracy for mode 1:0.0315 test loss: 428.161
137000: ********* epoch 15 ********* test accuracy for mode 2:0.037 test loss: 261.321
137000: ********* epoch 15 ********* test accuracy for mode 24:0.2485 test loss: 271.792
137000: ********* epoch 15 ********* test accuracy for mode 25:0.255 test loss: 256.728
137000: ********* epoch 15 ********* test accuracy for mode 26:0.5255 test loss: 159.483
137000: ********* epoch 15 ********* test accuracy for mode 27:0.27 test loss: 263.064
137000: ********* epoch 15 ********* test accuracy for mode 28:0.289 test loss: 261.902
137000: ********* epoch 15 ********* test accuracy for mode 29:0.232 test loss: 268.599
137000: ********* epoch 15 ********* test accuracy for mode 30:0.241 test loss: 250.979
137000: ********* epoch 15 ********* test accuracy for mode 31:0.1915 test loss: 253.525
137000: ********* epoch 15 ********* test accuracy for mode 32:0.2335 test loss: 237.363
137000: ********* epoch 15 ********* test accuracy for mode 33:0.2785 test loss: 239.804
137000: ********* epoch 15 ********* test accuracy for mode 34:0.206 test loss: 244.958
137000: ********* epoch 15 ********* test accuracy for mode 35:0.067 test loss: 437.246
137000: ********* epoch 15 ********* test accuracy for mode 36:0.0695 test loss: 514.485
137010: accuracy:0.35 loss: 191.676 (lr:0.0001)
137020: accuracy:0.32 loss: 207.224 (lr:0.0001)
137030: accuracy:0.3 loss: 210.891 (lr:0.0001)
137040: accuracy:0.28 loss: 219.922 (lr:0.0001)
137050: accuracy:0.31 loss: 206.165 (lr:0.0001)
137060: accuracy:0.45 loss: 186.371 (lr:0.0001)
137070: accuracy:0.43 loss: 189.783 (lr:0.0001)
137080: accuracy:0.42 loss: 194.768 (lr:0.0001)
137090: accuracy:0.34 loss: 207.97 (lr:0.0001)
137100: accuracy:0.24 loss: 212.308 (lr:0.0001)
137110: accuracy:0.32 loss: 193.237 (lr:0.0001)
137120: accuracy:0.31 loss: 214.261 (lr:0.0001)
137130: accuracy:0.33 loss: 199.479 (lr:0.0001)
137140: accuracy:0.34 loss: 210.222 (lr:0.0001)
137150: accuracy:0.41 loss: 213.096 (lr:0.0001)
137160: accuracy:0.31 loss: 208.881 (lr:0.0001)
137170: accuracy:0.32 loss: 202.188 (lr:0.0001)
137180: accuracy:0.41 loss: 190.653 (lr:0.0001)
137190: accuracy:0.36 loss: 202.897 (lr:0.0001)
137200: accuracy:0.37 loss: 193.043 (lr:0.0001)
137210: accuracy:0.36 loss: 194.148 (lr:0.0001)
137220: accuracy:0.33 loss: 226.299 (lr:0.0001)
137230: accuracy:0.31 loss: 197.71 (lr:0.0001)
137240: accuracy:0.35 loss: 197.138 (lr:0.0001)
137250: accuracy:0.37 loss: 204.529 (lr:0.0001)
137260: accuracy:0.32 loss: 213.386 (lr:0.0001)
137270: accuracy:0.42 loss: 191.446 (lr:0.0001)
137280: accuracy:0.42 loss: 195.07 (lr:0.0001)
137290: accuracy:0.28 loss: 211.512 (lr:0.0001)
137300: accuracy:0.35 loss: 211.53 (lr:0.0001)
137310: accuracy:0.29 loss: 207.898 (lr:0.0001)
137320: accuracy:0.37 loss: 202.44 (lr:0.0001)
137330: accuracy:0.32 loss: 216.076 (lr:0.0001)
137340: accuracy:0.29 loss: 217.205 (lr:0.0001)
137350: accuracy:0.41 loss: 178.471 (lr:0.0001)
137360: accuracy:0.31 loss: 204.514 (lr:0.0001)
137370: accuracy:0.47 loss: 190.609 (lr:0.0001)
137380: accuracy:0.28 loss: 222.278 (lr:0.0001)
137390: accuracy:0.31 loss: 222.061 (lr:0.0001)
137400: accuracy:0.29 loss: 212.921 (lr:0.0001)
137410: accuracy:0.35 loss: 215.229 (lr:0.0001)
137420: accuracy:0.35 loss: 206.443 (lr:0.0001)
137430: accuracy:0.33 loss: 234.242 (lr:0.0001)
137440: accuracy:0.33 loss: 207.72 (lr:0.0001)
137450: accuracy:0.35 loss: 194.103 (lr:0.0001)
137460: accuracy:0.38 loss: 187.094 (lr:0.0001)
137470: accuracy:0.28 loss: 206.583 (lr:0.0001)
137480: accuracy:0.33 loss: 198.058 (lr:0.0001)
137490: accuracy:0.36 loss: 218.001 (lr:0.0001)
137500: accuracy:0.41 loss: 185.829 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
137500: ********* epoch 15 ********* test accuracy for all:0.256878 test loss: 255.242
137500: ********* epoch 15 ********* test accuracy for mode 0:0.0445 test loss: 437.719
137500: ********* epoch 15 ********* test accuracy for mode 1:0.0315 test loss: 433.031
137500: ********* epoch 15 ********* test accuracy for mode 2:0.0395 test loss: 259.979
137500: ********* epoch 15 ********* test accuracy for mode 24:0.2405 test loss: 278.702
137500: ********* epoch 15 ********* test accuracy for mode 25:0.326 test loss: 249.095
137500: ********* epoch 15 ********* test accuracy for mode 26:0.4485 test loss: 166.043
137500: ********* epoch 15 ********* test accuracy for mode 27:0.269 test loss: 261.1
137500: ********* epoch 15 ********* test accuracy for mode 28:0.3035 test loss: 258.952
137500: ********* epoch 15 ********* test accuracy for mode 29:0.2525 test loss: 267.795
137500: ********* epoch 15 ********* test accuracy for mode 30:0.2335 test loss: 250.033
137500: ********* epoch 15 ********* test accuracy for mode 31:0.2205 test loss: 247.792
137500: ********* epoch 15 ********* test accuracy for mode 32:0.206 test loss: 235.242
137500: ********* epoch 15 ********* test accuracy for mode 33:0.2855 test loss: 235.559
137500: ********* epoch 15 ********* test accuracy for mode 34:0.22 test loss: 239.662
137500: ********* epoch 15 ********* test accuracy for mode 35:0.051 test loss: 425.274
137500: ********* epoch 15 ********* test accuracy for mode 36:0.1255 test loss: 459.945
137510: accuracy:0.27 loss: 235.17 (lr:0.0001)
137520: accuracy:0.27 loss: 227.265 (lr:0.0001)
137530: accuracy:0.35 loss: 211.819 (lr:0.0001)
137540: accuracy:0.35 loss: 194.678 (lr:0.0001)
137550: accuracy:0.42 loss: 198.824 (lr:0.0001)
137560: accuracy:0.33 loss: 231.446 (lr:0.0001)
137570: accuracy:0.33 loss: 200.418 (lr:0.0001)
137580: accuracy:0.38 loss: 203.068 (lr:0.0001)
137590: accuracy:0.37 loss: 196.266 (lr:0.0001)
137600: accuracy:0.41 loss: 206.464 (lr:0.0001)
137610: accuracy:0.36 loss: 197.422 (lr:0.0001)
137620: accuracy:0.3 loss: 204.971 (lr:0.0001)
137630: accuracy:0.34 loss: 225.867 (lr:0.0001)
137640: accuracy:0.32 loss: 211.375 (lr:0.0001)
137650: accuracy:0.4 loss: 200.333 (lr:0.0001)
137660: accuracy:0.31 loss: 206.409 (lr:0.0001)
137670: accuracy:0.42 loss: 186.542 (lr:0.0001)
137680: accuracy:0.36 loss: 198.558 (lr:0.0001)
137690: accuracy:0.36 loss: 184.516 (lr:0.0001)
137700: accuracy:0.32 loss: 211.983 (lr:0.0001)
137710: accuracy:0.32 loss: 208.032 (lr:0.0001)
137720: accuracy:0.27 loss: 213.485 (lr:0.0001)
137730: accuracy:0.35 loss: 207.804 (lr:0.0001)
137740: accuracy:0.39 loss: 195.114 (lr:0.0001)
137750: accuracy:0.31 loss: 203.608 (lr:0.0001)
137760: accuracy:0.33 loss: 214.555 (lr:0.0001)
137770: accuracy:0.4 loss: 219.623 (lr:0.0001)
137780: accuracy:0.3 loss: 218.048 (lr:0.0001)
137790: accuracy:0.41 loss: 216.657 (lr:0.0001)
137800: accuracy:0.39 loss: 188.332 (lr:0.0001)
137810: accuracy:0.37 loss: 206.489 (lr:0.0001)
137820: accuracy:0.31 loss: 206.379 (lr:0.0001)
137830: accuracy:0.32 loss: 211.113 (lr:0.0001)
137840: accuracy:0.46 loss: 190.71 (lr:0.0001)
137850: accuracy:0.37 loss: 194.075 (lr:0.0001)
137860: accuracy:0.47 loss: 181.115 (lr:0.0001)
137870: accuracy:0.28 loss: 239.378 (lr:0.0001)
137880: accuracy:0.42 loss: 194.134 (lr:0.0001)
137890: accuracy:0.31 loss: 212.106 (lr:0.0001)
137900: accuracy:0.36 loss: 205.921 (lr:0.0001)
137910: accuracy:0.42 loss: 182.428 (lr:0.0001)
137920: accuracy:0.35 loss: 213.815 (lr:0.0001)
137930: accuracy:0.36 loss: 212.332 (lr:0.0001)
137940: accuracy:0.39 loss: 219.104 (lr:0.0001)
137950: accuracy:0.36 loss: 193.08 (lr:0.0001)
137960: accuracy:0.31 loss: 207.433 (lr:0.0001)
137970: accuracy:0.46 loss: 188.391 (lr:0.0001)
137980: accuracy:0.38 loss: 195.563 (lr:0.0001)
137990: accuracy:0.26 loss: 224.377 (lr:0.0001)
138000: accuracy:0.34 loss: 224.778 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
138000: ********* epoch 15 ********* test accuracy for all:0.260919 test loss: 253.666
138000: ********* epoch 15 ********* test accuracy for mode 0:0.0455 test loss: 434.047
138000: ********* epoch 15 ********* test accuracy for mode 1:0.0285 test loss: 427.735
138000: ********* epoch 15 ********* test accuracy for mode 2:0.0365 test loss: 265.613
138000: ********* epoch 15 ********* test accuracy for mode 24:0.2395 test loss: 279.325
138000: ********* epoch 15 ********* test accuracy for mode 25:0.275 test loss: 251.628
138000: ********* epoch 15 ********* test accuracy for mode 26:0.515 test loss: 153.647
138000: ********* epoch 15 ********* test accuracy for mode 27:0.298 test loss: 251.0
138000: ********* epoch 15 ********* test accuracy for mode 28:0.268 test loss: 255.377
138000: ********* epoch 15 ********* test accuracy for mode 29:0.261 test loss: 260.941
138000: ********* epoch 15 ********* test accuracy for mode 30:0.2725 test loss: 245.263
138000: ********* epoch 15 ********* test accuracy for mode 31:0.1545 test loss: 253.538
138000: ********* epoch 15 ********* test accuracy for mode 32:0.244 test loss: 230.715
138000: ********* epoch 15 ********* test accuracy for mode 33:0.2805 test loss: 232.972
138000: ********* epoch 15 ********* test accuracy for mode 34:0.243 test loss: 234.244
138000: ********* epoch 15 ********* test accuracy for mode 35:0.072 test loss: 415.114
138000: ********* epoch 15 ********* test accuracy for mode 36:0.2095 test loss: 442.082
138010: accuracy:0.38 loss: 200.274 (lr:0.0001)
138020: accuracy:0.39 loss: 180.619 (lr:0.0001)
138030: accuracy:0.36 loss: 205.992 (lr:0.0001)
138040: accuracy:0.43 loss: 187.313 (lr:0.0001)
138050: accuracy:0.4 loss: 197.246 (lr:0.0001)
138060: accuracy:0.29 loss: 251.081 (lr:0.0001)
138070: accuracy:0.39 loss: 202.85 (lr:0.0001)
138080: accuracy:0.3 loss: 212.67 (lr:0.0001)
138090: accuracy:0.34 loss: 204.803 (lr:0.0001)
138100: accuracy:0.33 loss: 221.985 (lr:0.0001)
138110: accuracy:0.31 loss: 206.03 (lr:0.0001)
138120: accuracy:0.35 loss: 207.494 (lr:0.0001)
138130: accuracy:0.32 loss: 199.204 (lr:0.0001)
138140: accuracy:0.23 loss: 211.071 (lr:0.0001)
138150: accuracy:0.26 loss: 217.166 (lr:0.0001)
138160: accuracy:0.27 loss: 208.925 (lr:0.0001)
138170: accuracy:0.32 loss: 226.987 (lr:0.0001)
138180: accuracy:0.34 loss: 204.637 (lr:0.0001)
138190: accuracy:0.42 loss: 190.933 (lr:0.0001)
138200: accuracy:0.3 loss: 215.899 (lr:0.0001)
138210: accuracy:0.35 loss: 191.646 (lr:0.0001)
138220: accuracy:0.38 loss: 198.089 (lr:0.0001)
138230: accuracy:0.31 loss: 222.499 (lr:0.0001)
138240: accuracy:0.39 loss: 184.065 (lr:0.0001)
138250: accuracy:0.39 loss: 188.033 (lr:0.0001)
138260: accuracy:0.32 loss: 199.279 (lr:0.0001)
138270: accuracy:0.34 loss: 213.122 (lr:0.0001)
138280: accuracy:0.36 loss: 209.326 (lr:0.0001)
138290: accuracy:0.28 loss: 206.601 (lr:0.0001)
138300: accuracy:0.39 loss: 205.32 (lr:0.0001)
138310: accuracy:0.27 loss: 223.645 (lr:0.0001)
138320: accuracy:0.39 loss: 199.555 (lr:0.0001)
138330: accuracy:0.42 loss: 201.01 (lr:0.0001)
138340: accuracy:0.31 loss: 213.533 (lr:0.0001)
138350: accuracy:0.4 loss: 199.012 (lr:0.0001)
138360: accuracy:0.39 loss: 198.929 (lr:0.0001)
138370: accuracy:0.35 loss: 205.797 (lr:0.0001)
138380: accuracy:0.33 loss: 199.653 (lr:0.0001)
138390: accuracy:0.36 loss: 205.432 (lr:0.0001)
138400: accuracy:0.31 loss: 213.36 (lr:0.0001)
138410: accuracy:0.33 loss: 212.379 (lr:0.0001)
138420: accuracy:0.35 loss: 210.124 (lr:0.0001)
138430: accuracy:0.39 loss: 190.749 (lr:0.0001)
138440: accuracy:0.34 loss: 218.001 (lr:0.0001)
138450: accuracy:0.32 loss: 207.876 (lr:0.0001)
138460: accuracy:0.24 loss: 243.072 (lr:0.0001)
138470: accuracy:0.4 loss: 189.777 (lr:0.0001)
138480: accuracy:0.39 loss: 219.321 (lr:0.0001)
138490: accuracy:0.3 loss: 238.042 (lr:0.0001)
138500: accuracy:0.32 loss: 207.93 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
138500: ********* epoch 15 ********* test accuracy for all:0.255257 test loss: 255.711
138500: ********* epoch 15 ********* test accuracy for mode 0:0.033 test loss: 441.841
138500: ********* epoch 15 ********* test accuracy for mode 1:0.0315 test loss: 426.183
138500: ********* epoch 15 ********* test accuracy for mode 2:0.059 test loss: 260.838
138500: ********* epoch 15 ********* test accuracy for mode 24:0.25 test loss: 277.757
138500: ********* epoch 15 ********* test accuracy for mode 25:0.2405 test loss: 261.621
138500: ********* epoch 15 ********* test accuracy for mode 26:0.531 test loss: 155.857
138500: ********* epoch 15 ********* test accuracy for mode 27:0.245 test loss: 264.921
138500: ********* epoch 15 ********* test accuracy for mode 28:0.2985 test loss: 255.839
138500: ********* epoch 15 ********* test accuracy for mode 29:0.2835 test loss: 261.436
138500: ********* epoch 15 ********* test accuracy for mode 30:0.2315 test loss: 249.635
138500: ********* epoch 15 ********* test accuracy for mode 31:0.199 test loss: 251.724
138500: ********* epoch 15 ********* test accuracy for mode 32:0.1955 test loss: 236.25
138500: ********* epoch 15 ********* test accuracy for mode 33:0.319 test loss: 235.536
138500: ********* epoch 15 ********* test accuracy for mode 34:0.191 test loss: 242.745
138500: ********* epoch 15 ********* test accuracy for mode 35:0.08 test loss: 428.055
138500: ********* epoch 15 ********* test accuracy for mode 36:0.0745 test loss: 485.151
138510: accuracy:0.3 loss: 213.837 (lr:0.0001)
138520: accuracy:0.33 loss: 197.397 (lr:0.0001)
138530: accuracy:0.3 loss: 214.19 (lr:0.0001)
138540: accuracy:0.35 loss: 203.552 (lr:0.0001)
138550: accuracy:0.37 loss: 216.481 (lr:0.0001)
138560: accuracy:0.45 loss: 193.23 (lr:0.0001)
138570: accuracy:0.33 loss: 213.791 (lr:0.0001)
138580: accuracy:0.4 loss: 207.478 (lr:0.0001)
138590: accuracy:0.34 loss: 189.98 (lr:0.0001)
138600: accuracy:0.37 loss: 179.896 (lr:0.0001)
138610: accuracy:0.29 loss: 213.32 (lr:0.0001)
138620: accuracy:0.29 loss: 233.697 (lr:0.0001)
138630: accuracy:0.34 loss: 219.376 (lr:0.0001)
138640: accuracy:0.31 loss: 210.779 (lr:0.0001)
138650: accuracy:0.36 loss: 184.887 (lr:0.0001)
138660: accuracy:0.37 loss: 216.878 (lr:0.0001)
138670: accuracy:0.28 loss: 215.457 (lr:0.0001)
138680: accuracy:0.23 loss: 224.697 (lr:0.0001)
138690: accuracy:0.31 loss: 213.841 (lr:0.0001)
138700: accuracy:0.4 loss: 209.657 (lr:0.0001)
138710: accuracy:0.41 loss: 198.365 (lr:0.0001)
138720: accuracy:0.41 loss: 181.393 (lr:0.0001)
138730: accuracy:0.4 loss: 206.568 (lr:0.0001)
138740: accuracy:0.33 loss: 221.67 (lr:0.0001)
138750: accuracy:0.32 loss: 196.687 (lr:0.0001)
138760: accuracy:0.35 loss: 201.957 (lr:0.0001)
138770: accuracy:0.33 loss: 222.725 (lr:0.0001)
138780: accuracy:0.34 loss: 194.213 (lr:0.0001)
138790: accuracy:0.39 loss: 195.873 (lr:0.0001)
138800: accuracy:0.33 loss: 216.146 (lr:0.0001)
138810: accuracy:0.45 loss: 200.468 (lr:0.0001)
138820: accuracy:0.39 loss: 202.117 (lr:0.0001)
138830: accuracy:0.35 loss: 211.007 (lr:0.0001)
138840: accuracy:0.39 loss: 202.561 (lr:0.0001)
138850: accuracy:0.4 loss: 199.147 (lr:0.0001)
138860: accuracy:0.4 loss: 194.336 (lr:0.0001)
138870: accuracy:0.36 loss: 223.192 (lr:0.0001)
138880: accuracy:0.29 loss: 221.809 (lr:0.0001)
138890: accuracy:0.34 loss: 194.42 (lr:0.0001)
138900: accuracy:0.45 loss: 202.566 (lr:0.0001)
138910: accuracy:0.37 loss: 202.921 (lr:0.0001)
138920: accuracy:0.38 loss: 222.208 (lr:0.0001)
138930: accuracy:0.32 loss: 217.161 (lr:0.0001)
138940: accuracy:0.38 loss: 186.535 (lr:0.0001)
138950: accuracy:0.39 loss: 200.015 (lr:0.0001)
138960: accuracy:0.3 loss: 218.956 (lr:0.0001)
138970: accuracy:0.34 loss: 202.732 (lr:0.0001)
138980: accuracy:0.38 loss: 201.415 (lr:0.0001)
138990: accuracy:0.34 loss: 207.404 (lr:0.0001)
139000: accuracy:0.39 loss: 222.277 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
139000: ********* epoch 15 ********* test accuracy for all:0.260203 test loss: 255.928
139000: ********* epoch 15 ********* test accuracy for mode 0:0.0395 test loss: 446.428
139000: ********* epoch 15 ********* test accuracy for mode 1:0.0315 test loss: 430.205
139000: ********* epoch 15 ********* test accuracy for mode 2:0.0605 test loss: 258.954
139000: ********* epoch 15 ********* test accuracy for mode 24:0.217 test loss: 279.245
139000: ********* epoch 15 ********* test accuracy for mode 25:0.3275 test loss: 249.14
139000: ********* epoch 15 ********* test accuracy for mode 26:0.4865 test loss: 159.197
139000: ********* epoch 15 ********* test accuracy for mode 27:0.235 test loss: 270.222
139000: ********* epoch 15 ********* test accuracy for mode 28:0.278 test loss: 262.983
139000: ********* epoch 15 ********* test accuracy for mode 29:0.2635 test loss: 269.149
139000: ********* epoch 15 ********* test accuracy for mode 30:0.234 test loss: 254.342
139000: ********* epoch 15 ********* test accuracy for mode 31:0.207 test loss: 254.933
139000: ********* epoch 15 ********* test accuracy for mode 32:0.188 test loss: 237.448
139000: ********* epoch 15 ********* test accuracy for mode 33:0.293 test loss: 235.556
139000: ********* epoch 15 ********* test accuracy for mode 34:0.2165 test loss: 238.683
139000: ********* epoch 15 ********* test accuracy for mode 35:0.085 test loss: 437.555
139000: ********* epoch 15 ********* test accuracy for mode 36:0.1585 test loss: 464.52
139010: accuracy:0.41 loss: 191.469 (lr:0.0001)
139020: accuracy:0.37 loss: 217.752 (lr:0.0001)
139030: accuracy:0.34 loss: 214.11 (lr:0.0001)
139040: accuracy:0.47 loss: 178.892 (lr:0.0001)
139050: accuracy:0.32 loss: 205.178 (lr:0.0001)
139060: accuracy:0.27 loss: 213.362 (lr:0.0001)
139070: accuracy:0.34 loss: 215.454 (lr:0.0001)
139080: accuracy:0.34 loss: 203.742 (lr:0.0001)
139090: accuracy:0.36 loss: 195.725 (lr:0.0001)
139100: accuracy:0.4 loss: 194.361 (lr:0.0001)
139110: accuracy:0.4 loss: 191.806 (lr:0.0001)
139120: accuracy:0.42 loss: 189.022 (lr:0.0001)
139130: accuracy:0.33 loss: 216.911 (lr:0.0001)
139140: accuracy:0.34 loss: 209.22 (lr:0.0001)
139150: accuracy:0.35 loss: 195.505 (lr:0.0001)
139160: accuracy:0.24 loss: 226.472 (lr:0.0001)
139170: accuracy:0.27 loss: 217.074 (lr:0.0001)
139180: accuracy:0.3 loss: 212.259 (lr:0.0001)
139190: accuracy:0.28 loss: 212.344 (lr:0.0001)
139200: accuracy:0.39 loss: 202.046 (lr:0.0001)
139210: accuracy:0.33 loss: 194.61 (lr:0.0001)
139220: accuracy:0.36 loss: 206.161 (lr:0.0001)
139230: accuracy:0.32 loss: 225.23 (lr:0.0001)
139240: accuracy:0.33 loss: 203.545 (lr:0.0001)
139250: accuracy:0.37 loss: 201.159 (lr:0.0001)
139260: accuracy:0.37 loss: 203.97 (lr:0.0001)
139270: accuracy:0.43 loss: 195.252 (lr:0.0001)
139280: accuracy:0.32 loss: 187.397 (lr:0.0001)
139290: accuracy:0.42 loss: 196.994 (lr:0.0001)
139300: accuracy:0.36 loss: 205.2 (lr:0.0001)
139310: accuracy:0.29 loss: 249.047 (lr:0.0001)
139320: accuracy:0.34 loss: 208.139 (lr:0.0001)
139330: accuracy:0.38 loss: 204.166 (lr:0.0001)
139340: accuracy:0.28 loss: 231.093 (lr:0.0001)
139350: accuracy:0.37 loss: 203.594 (lr:0.0001)
139360: accuracy:0.37 loss: 216.518 (lr:0.0001)
139370: accuracy:0.33 loss: 202.319 (lr:0.0001)
139380: accuracy:0.33 loss: 212.836 (lr:0.0001)
139390: accuracy:0.33 loss: 214.106 (lr:0.0001)
139400: accuracy:0.36 loss: 208.071 (lr:0.0001)
139410: accuracy:0.38 loss: 197.646 (lr:0.0001)
139420: accuracy:0.35 loss: 199.837 (lr:0.0001)
139430: accuracy:0.37 loss: 193.162 (lr:0.0001)
139440: accuracy:0.29 loss: 209.738 (lr:0.0001)
139450: accuracy:0.36 loss: 199.732 (lr:0.0001)
139460: accuracy:0.34 loss: 201.747 (lr:0.0001)
139470: accuracy:0.32 loss: 210.481 (lr:0.0001)
139480: accuracy:0.35 loss: 202.544 (lr:0.0001)
139490: accuracy:0.46 loss: 188.962 (lr:0.0001)
139500: accuracy:0.36 loss: 209.753 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
139500: ********* epoch 15 ********* test accuracy for all:0.256622 test loss: 254.871
139500: ********* epoch 15 ********* test accuracy for mode 0:0.0435 test loss: 433.458
139500: ********* epoch 15 ********* test accuracy for mode 1:0.0335 test loss: 429.745
139500: ********* epoch 15 ********* test accuracy for mode 2:0.042 test loss: 268.021
139500: ********* epoch 15 ********* test accuracy for mode 24:0.262 test loss: 268.601
139500: ********* epoch 15 ********* test accuracy for mode 25:0.284 test loss: 247.503
139500: ********* epoch 15 ********* test accuracy for mode 26:0.499 test loss: 157.321
139500: ********* epoch 15 ********* test accuracy for mode 27:0.21 test loss: 267.904
139500: ********* epoch 15 ********* test accuracy for mode 28:0.275 test loss: 259.401
139500: ********* epoch 15 ********* test accuracy for mode 29:0.2575 test loss: 266.065
139500: ********* epoch 15 ********* test accuracy for mode 30:0.256 test loss: 250.02
139500: ********* epoch 15 ********* test accuracy for mode 31:0.1935 test loss: 252.682
139500: ********* epoch 15 ********* test accuracy for mode 32:0.1965 test loss: 237.063
139500: ********* epoch 15 ********* test accuracy for mode 33:0.299 test loss: 235.955
139500: ********* epoch 15 ********* test accuracy for mode 34:0.2295 test loss: 238.164
139500: ********* epoch 15 ********* test accuracy for mode 35:0.084 test loss: 411.909
139500: ********* epoch 15 ********* test accuracy for mode 36:0.076 test loss: 453.151
139510: accuracy:0.4 loss: 206.105 (lr:0.0001)
139520: accuracy:0.34 loss: 218.595 (lr:0.0001)
139530: accuracy:0.37 loss: 200.454 (lr:0.0001)
139540: accuracy:0.26 loss: 237.22 (lr:0.0001)
139550: accuracy:0.37 loss: 197.203 (lr:0.0001)
139560: accuracy:0.28 loss: 243.296 (lr:0.0001)
139570: accuracy:0.32 loss: 177.151 (lr:0.0001)
139580: accuracy:0.39 loss: 210.964 (lr:0.0001)
139590: accuracy:0.27 loss: 202.579 (lr:0.0001)
139600: accuracy:0.29 loss: 245.894 (lr:0.0001)
139610: accuracy:0.39 loss: 194.817 (lr:0.0001)
139620: accuracy:0.42 loss: 210.99 (lr:0.0001)
139630: accuracy:0.4 loss: 179.199 (lr:0.0001)
139640: accuracy:0.36 loss: 199.983 (lr:0.0001)
139650: accuracy:0.4 loss: 201.23 (lr:0.0001)
139660: accuracy:0.31 loss: 206.59 (lr:0.0001)
139670: accuracy:0.39 loss: 205.77 (lr:0.0001)
139680: accuracy:0.26 loss: 219.256 (lr:0.0001)
139690: accuracy:0.38 loss: 197.254 (lr:0.0001)
139700: accuracy:0.37 loss: 213.195 (lr:0.0001)
139710: accuracy:0.36 loss: 190.227 (lr:0.0001)
139720: accuracy:0.39 loss: 201.666 (lr:0.0001)
139730: accuracy:0.35 loss: 219.626 (lr:0.0001)
139740: accuracy:0.4 loss: 190.563 (lr:0.0001)
139750: accuracy:0.32 loss: 222.27 (lr:0.0001)
139760: accuracy:0.35 loss: 208.884 (lr:0.0001)
139770: accuracy:0.44 loss: 215.587 (lr:0.0001)
139780: accuracy:0.34 loss: 206.535 (lr:0.0001)
139790: accuracy:0.32 loss: 204.498 (lr:0.0001)
139800: accuracy:0.41 loss: 206.451 (lr:0.0001)
139810: accuracy:0.31 loss: 191.907 (lr:0.0001)
139820: accuracy:0.36 loss: 211.084 (lr:0.0001)
139830: accuracy:0.27 loss: 217.098 (lr:0.0001)
139840: accuracy:0.37 loss: 200.122 (lr:0.0001)
139850: accuracy:0.32 loss: 214.459 (lr:0.0001)
139860: accuracy:0.41 loss: 192.294 (lr:0.0001)
139870: accuracy:0.34 loss: 197.731 (lr:0.0001)
139880: accuracy:0.32 loss: 216.146 (lr:0.0001)
139890: accuracy:0.36 loss: 217.995 (lr:0.0001)
139900: accuracy:0.31 loss: 202.046 (lr:0.0001)
139910: accuracy:0.41 loss: 187.906 (lr:0.0001)
139920: accuracy:0.39 loss: 208.927 (lr:0.0001)
139930: accuracy:0.4 loss: 194.525 (lr:0.0001)
139940: accuracy:0.43 loss: 195.71 (lr:0.0001)
139950: accuracy:0.33 loss: 220.098 (lr:0.0001)
139960: accuracy:0.36 loss: 201.05 (lr:0.0001)
139970: accuracy:0.37 loss: 199.915 (lr:0.0001)
139980: accuracy:0.37 loss: 212.922 (lr:0.0001)
139990: accuracy:0.4 loss: 201.853 (lr:0.0001)
140000: accuracy:0.34 loss: 218.014 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
140000: ********* epoch 15 ********* test accuracy for all:0.256892 test loss: 256.776
140000: ********* epoch 15 ********* test accuracy for mode 0:0.036 test loss: 445.194
140000: ********* epoch 15 ********* test accuracy for mode 1:0.0235 test loss: 433.378
140000: ********* epoch 15 ********* test accuracy for mode 2:0.0715 test loss: 260.883
140000: ********* epoch 15 ********* test accuracy for mode 24:0.255 test loss: 273.542
140000: ********* epoch 15 ********* test accuracy for mode 25:0.285 test loss: 251.71
140000: ********* epoch 15 ********* test accuracy for mode 26:0.44 test loss: 165.435
140000: ********* epoch 15 ********* test accuracy for mode 27:0.291 test loss: 260.013
140000: ********* epoch 15 ********* test accuracy for mode 28:0.2655 test loss: 261.733
140000: ********* epoch 15 ********* test accuracy for mode 29:0.274 test loss: 262.152
140000: ********* epoch 15 ********* test accuracy for mode 30:0.238 test loss: 247.69
140000: ********* epoch 15 ********* test accuracy for mode 31:0.2395 test loss: 245.182
140000: ********* epoch 15 ********* test accuracy for mode 32:0.182 test loss: 232.816
140000: ********* epoch 15 ********* test accuracy for mode 33:0.2795 test loss: 231.551
140000: ********* epoch 15 ********* test accuracy for mode 34:0.271 test loss: 231.881
140000: ********* epoch 15 ********* test accuracy for mode 35:0.0675 test loss: 447.974
140000: ********* epoch 15 ********* test accuracy for mode 36:0.082 test loss: 500.802
140010: accuracy:0.36 loss: 207.691 (lr:0.0001)
140020: accuracy:0.37 loss: 203.851 (lr:0.0001)
140030: accuracy:0.39 loss: 199.426 (lr:0.0001)
140040: accuracy:0.33 loss: 223.392 (lr:0.0001)
140050: accuracy:0.37 loss: 198.905 (lr:0.0001)
140060: accuracy:0.37 loss: 207.617 (lr:0.0001)
140070: accuracy:0.28 loss: 209.725 (lr:0.0001)
140080: accuracy:0.39 loss: 191.793 (lr:0.0001)
140090: accuracy:0.31 loss: 205.718 (lr:0.0001)
140100: accuracy:0.27 loss: 222.685 (lr:0.0001)
140110: accuracy:0.41 loss: 179.422 (lr:0.0001)
140120: accuracy:0.29 loss: 230.112 (lr:0.0001)
140130: accuracy:0.39 loss: 198.172 (lr:0.0001)
140140: accuracy:0.32 loss: 211.982 (lr:0.0001)
140150: accuracy:0.45 loss: 172.986 (lr:0.0001)
140160: accuracy:0.32 loss: 233.611 (lr:0.0001)
140170: accuracy:0.43 loss: 177.366 (lr:0.0001)
140180: accuracy:0.4 loss: 201.303 (lr:0.0001)
140190: accuracy:0.41 loss: 198.656 (lr:0.0001)
140200: accuracy:0.36 loss: 207.499 (lr:0.0001)
140210: accuracy:0.4 loss: 186.224 (lr:0.0001)
140220: accuracy:0.32 loss: 216.033 (lr:0.0001)
140230: accuracy:0.37 loss: 216.738 (lr:0.0001)
140240: accuracy:0.39 loss: 224.401 (lr:0.0001)
140250: accuracy:0.37 loss: 203.664 (lr:0.0001)
140260: accuracy:0.44 loss: 198.224 (lr:0.0001)
140270: accuracy:0.42 loss: 190.083 (lr:0.0001)
140280: accuracy:0.29 loss: 207.417 (lr:0.0001)
140290: accuracy:0.36 loss: 203.44 (lr:0.0001)
140300: accuracy:0.37 loss: 189.96 (lr:0.0001)
140310: accuracy:0.35 loss: 194.29 (lr:0.0001)
140320: accuracy:0.33 loss: 204.453 (lr:0.0001)
140330: accuracy:0.37 loss: 203.974 (lr:0.0001)
140340: accuracy:0.41 loss: 203.172 (lr:0.0001)
140350: accuracy:0.35 loss: 204.706 (lr:0.0001)
140360: accuracy:0.31 loss: 209.651 (lr:0.0001)
140370: accuracy:0.34 loss: 214.192 (lr:0.0001)
140380: accuracy:0.3 loss: 203.909 (lr:0.0001)
140390: accuracy:0.36 loss: 199.763 (lr:0.0001)
140400: accuracy:0.38 loss: 222.971 (lr:0.0001)
140410: accuracy:0.34 loss: 198.615 (lr:0.0001)
140420: accuracy:0.28 loss: 233.558 (lr:0.0001)
140430: accuracy:0.28 loss: 234.164 (lr:0.0001)
140440: accuracy:0.36 loss: 211.163 (lr:0.0001)
140450: accuracy:0.3 loss: 216.477 (lr:0.0001)
140460: accuracy:0.37 loss: 192.299 (lr:0.0001)
140470: accuracy:0.4 loss: 190.207 (lr:0.0001)
140480: accuracy:0.39 loss: 203.524 (lr:0.0001)
140490: accuracy:0.33 loss: 211.386 (lr:0.0001)
140500: accuracy:0.42 loss: 184.758 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
140500: ********* epoch 15 ********* test accuracy for all:0.260338 test loss: 254.818
140500: ********* epoch 15 ********* test accuracy for mode 0:0.045 test loss: 435.604
140500: ********* epoch 15 ********* test accuracy for mode 1:0.033 test loss: 431.751
140500: ********* epoch 15 ********* test accuracy for mode 2:0.0565 test loss: 257.995
140500: ********* epoch 15 ********* test accuracy for mode 24:0.261 test loss: 271.179
140500: ********* epoch 15 ********* test accuracy for mode 25:0.361 test loss: 243.051
140500: ********* epoch 15 ********* test accuracy for mode 26:0.357 test loss: 174.024
140500: ********* epoch 15 ********* test accuracy for mode 27:0.243 test loss: 274.458
140500: ********* epoch 15 ********* test accuracy for mode 28:0.308 test loss: 258.471
140500: ********* epoch 15 ********* test accuracy for mode 29:0.233 test loss: 269.125
140500: ********* epoch 15 ********* test accuracy for mode 30:0.214 test loss: 252.701
140500: ********* epoch 15 ********* test accuracy for mode 31:0.21 test loss: 249.226
140500: ********* epoch 15 ********* test accuracy for mode 32:0.225 test loss: 230.704
140500: ********* epoch 15 ********* test accuracy for mode 33:0.3365 test loss: 227.936
140500: ********* epoch 15 ********* test accuracy for mode 34:0.198 test loss: 237.779
140500: ********* epoch 15 ********* test accuracy for mode 35:0.079 test loss: 427.027
140500: ********* epoch 15 ********* test accuracy for mode 36:0.199 test loss: 445.925
140510: accuracy:0.33 loss: 220.053 (lr:0.0001)
140520: accuracy:0.43 loss: 183.05 (lr:0.0001)
140530: accuracy:0.29 loss: 218.168 (lr:0.0001)
140540: accuracy:0.31 loss: 213.323 (lr:0.0001)
140550: accuracy:0.35 loss: 190.953 (lr:0.0001)
140560: accuracy:0.41 loss: 195.712 (lr:0.0001)
140570: accuracy:0.39 loss: 187.611 (lr:0.0001)
140580: accuracy:0.4 loss: 207.67 (lr:0.0001)
140590: accuracy:0.36 loss: 202.59 (lr:0.0001)
140600: accuracy:0.4 loss: 191.072 (lr:0.0001)
140610: accuracy:0.37 loss: 201.57 (lr:0.0001)
140620: accuracy:0.37 loss: 210.985 (lr:0.0001)
140630: accuracy:0.33 loss: 229.811 (lr:0.0001)
140640: accuracy:0.36 loss: 209.912 (lr:0.0001)
140650: accuracy:0.42 loss: 202.016 (lr:0.0001)
140660: accuracy:0.32 loss: 208.998 (lr:0.0001)
140670: accuracy:0.36 loss: 204.865 (lr:0.0001)
140680: accuracy:0.36 loss: 202.248 (lr:0.0001)
140690: accuracy:0.46 loss: 186.288 (lr:0.0001)
140700: accuracy:0.42 loss: 191.133 (lr:0.0001)
140710: accuracy:0.34 loss: 210.704 (lr:0.0001)
140720: accuracy:0.3 loss: 203.561 (lr:0.0001)
140730: accuracy:0.23 loss: 219.328 (lr:0.0001)
140740: accuracy:0.37 loss: 231.154 (lr:0.0001)
140750: accuracy:0.27 loss: 234.567 (lr:0.0001)
140760: accuracy:0.35 loss: 182.102 (lr:0.0001)
140770: accuracy:0.28 loss: 215.508 (lr:0.0001)
140780: accuracy:0.31 loss: 213.796 (lr:0.0001)
140790: accuracy:0.41 loss: 192.736 (lr:0.0001)
140800: accuracy:0.4 loss: 201.388 (lr:0.0001)
140810: accuracy:0.4 loss: 194.271 (lr:0.0001)
140820: accuracy:0.31 loss: 218.929 (lr:0.0001)
140830: accuracy:0.33 loss: 220.181 (lr:0.0001)
140840: accuracy:0.44 loss: 198.73 (lr:0.0001)
140850: accuracy:0.34 loss: 216.725 (lr:0.0001)
140860: accuracy:0.48 loss: 178.309 (lr:0.0001)
140870: accuracy:0.33 loss: 208.14 (lr:0.0001)
140880: accuracy:0.34 loss: 204.865 (lr:0.0001)
140890: accuracy:0.33 loss: 219.644 (lr:0.0001)
140900: accuracy:0.41 loss: 191.673 (lr:0.0001)
140910: accuracy:0.34 loss: 202.243 (lr:0.0001)
140920: accuracy:0.43 loss: 207.22 (lr:0.0001)
140930: accuracy:0.26 loss: 212.649 (lr:0.0001)
140940: accuracy:0.35 loss: 205.926 (lr:0.0001)
140950: accuracy:0.36 loss: 204.291 (lr:0.0001)
140960: accuracy:0.35 loss: 193.912 (lr:0.0001)
140970: accuracy:0.4 loss: 185.465 (lr:0.0001)
140980: accuracy:0.43 loss: 200.455 (lr:0.0001)
140990: accuracy:0.4 loss: 191.015 (lr:0.0001)
141000: accuracy:0.35 loss: 201.033 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
141000: ********* epoch 15 ********* test accuracy for all:0.256635 test loss: 257.559
141000: ********* epoch 15 ********* test accuracy for mode 0:0.042 test loss: 439.529
141000: ********* epoch 15 ********* test accuracy for mode 1:0.029 test loss: 425.982
141000: ********* epoch 15 ********* test accuracy for mode 2:0.0715 test loss: 255.699
141000: ********* epoch 15 ********* test accuracy for mode 24:0.2505 test loss: 276.851
141000: ********* epoch 15 ********* test accuracy for mode 25:0.2905 test loss: 258.723
141000: ********* epoch 15 ********* test accuracy for mode 26:0.466 test loss: 159.683
141000: ********* epoch 15 ********* test accuracy for mode 27:0.2485 test loss: 279.296
141000: ********* epoch 15 ********* test accuracy for mode 28:0.2745 test loss: 266.408
141000: ********* epoch 15 ********* test accuracy for mode 29:0.2335 test loss: 274.782
141000: ********* epoch 15 ********* test accuracy for mode 30:0.2625 test loss: 252.28
141000: ********* epoch 15 ********* test accuracy for mode 31:0.205 test loss: 254.068
141000: ********* epoch 15 ********* test accuracy for mode 32:0.1725 test loss: 237.477
141000: ********* epoch 15 ********* test accuracy for mode 33:0.349 test loss: 230.608
141000: ********* epoch 15 ********* test accuracy for mode 34:0.1565 test loss: 240.878
141000: ********* epoch 15 ********* test accuracy for mode 35:0.084 test loss: 444.595
141000: ********* epoch 15 ********* test accuracy for mode 36:0.104 test loss: 490.625
141010: accuracy:0.35 loss: 193.332 (lr:0.0001)
141020: accuracy:0.32 loss: 202.07 (lr:0.0001)
141030: accuracy:0.3 loss: 223.256 (lr:0.0001)
141040: accuracy:0.38 loss: 205.12 (lr:0.0001)
141050: accuracy:0.41 loss: 186.897 (lr:0.0001)
141060: accuracy:0.38 loss: 190.986 (lr:0.0001)
141070: accuracy:0.37 loss: 201.973 (lr:0.0001)
141080: accuracy:0.36 loss: 207.115 (lr:0.0001)
141090: accuracy:0.44 loss: 188.897 (lr:0.0001)
141100: accuracy:0.37 loss: 217.275 (lr:0.0001)
141110: accuracy:0.36 loss: 202.309 (lr:0.0001)
141120: accuracy:0.29 loss: 226.658 (lr:0.0001)
141130: accuracy:0.37 loss: 209.501 (lr:0.0001)
141140: accuracy:0.37 loss: 195.405 (lr:0.0001)
141150: accuracy:0.37 loss: 203.462 (lr:0.0001)
141160: accuracy:0.32 loss: 206.635 (lr:0.0001)
141170: accuracy:0.32 loss: 222.048 (lr:0.0001)
141180: accuracy:0.38 loss: 206.312 (lr:0.0001)
141190: accuracy:0.36 loss: 224.078 (lr:0.0001)
141200: accuracy:0.3 loss: 210.39 (lr:0.0001)
141210: accuracy:0.36 loss: 205.158 (lr:0.0001)
141220: accuracy:0.32 loss: 216.736 (lr:0.0001)
141230: accuracy:0.34 loss: 234.054 (lr:0.0001)
141240: accuracy:0.33 loss: 207.359 (lr:0.0001)
141250: accuracy:0.39 loss: 205.062 (lr:0.0001)
141260: accuracy:0.35 loss: 214.225 (lr:0.0001)
141270: accuracy:0.33 loss: 214.207 (lr:0.0001)
141280: accuracy:0.33 loss: 219.974 (lr:0.0001)
141290: accuracy:0.31 loss: 207.452 (lr:0.0001)
141300: accuracy:0.39 loss: 215.465 (lr:0.0001)
141310: accuracy:0.43 loss: 183.703 (lr:0.0001)
141320: accuracy:0.35 loss: 211.731 (lr:0.0001)
141330: accuracy:0.39 loss: 187.393 (lr:0.0001)
141340: accuracy:0.41 loss: 197.404 (lr:0.0001)
141350: accuracy:0.42 loss: 195.129 (lr:0.0001)
141360: accuracy:0.31 loss: 204.693 (lr:0.0001)
141370: accuracy:0.28 loss: 216.23 (lr:0.0001)
141380: accuracy:0.35 loss: 205.01 (lr:0.0001)
141390: accuracy:0.31 loss: 199.977 (lr:0.0001)
141400: accuracy:0.43 loss: 186.051 (lr:0.0001)
141410: accuracy:0.36 loss: 202.143 (lr:0.0001)
141420: accuracy:0.28 loss: 217.99 (lr:0.0001)
141430: accuracy:0.4 loss: 204.808 (lr:0.0001)
141440: accuracy:0.37 loss: 215.048 (lr:0.0001)
141450: accuracy:0.36 loss: 205.503 (lr:0.0001)
141460: accuracy:0.38 loss: 201.996 (lr:0.0001)
141470: accuracy:0.34 loss: 219.3 (lr:0.0001)
141480: accuracy:0.34 loss: 190.742 (lr:0.0001)
141490: accuracy:0.38 loss: 216.411 (lr:0.0001)
141500: accuracy:0.37 loss: 207.034 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
141500: ********* epoch 15 ********* test accuracy for all:0.262014 test loss: 256.074
141500: ********* epoch 15 ********* test accuracy for mode 0:0.039 test loss: 448.714
141500: ********* epoch 15 ********* test accuracy for mode 1:0.028 test loss: 429.105
141500: ********* epoch 15 ********* test accuracy for mode 2:0.048 test loss: 263.446
141500: ********* epoch 15 ********* test accuracy for mode 24:0.2405 test loss: 272.098
141500: ********* epoch 15 ********* test accuracy for mode 25:0.318 test loss: 244.985
141500: ********* epoch 15 ********* test accuracy for mode 26:0.4455 test loss: 164.696
141500: ********* epoch 15 ********* test accuracy for mode 27:0.2785 test loss: 267.62
141500: ********* epoch 15 ********* test accuracy for mode 28:0.2925 test loss: 259.054
141500: ********* epoch 15 ********* test accuracy for mode 29:0.2815 test loss: 267.083
141500: ********* epoch 15 ********* test accuracy for mode 30:0.2025 test loss: 257.404
141500: ********* epoch 15 ********* test accuracy for mode 31:0.2175 test loss: 253.843
141500: ********* epoch 15 ********* test accuracy for mode 32:0.238 test loss: 235.833
141500: ********* epoch 15 ********* test accuracy for mode 33:0.2755 test loss: 238.365
141500: ********* epoch 15 ********* test accuracy for mode 34:0.2115 test loss: 241.732
141500: ********* epoch 15 ********* test accuracy for mode 35:0.0675 test loss: 460.957
141500: ********* epoch 15 ********* test accuracy for mode 36:0.2275 test loss: 473.669
141510: accuracy:0.34 loss: 212.768 (lr:0.0001)
141520: accuracy:0.28 loss: 211.836 (lr:0.0001)
141530: accuracy:0.42 loss: 200.298 (lr:0.0001)
141540: accuracy:0.4 loss: 201.797 (lr:0.0001)
141550: accuracy:0.37 loss: 216.683 (lr:0.0001)
141560: accuracy:0.32 loss: 201.411 (lr:0.0001)
141570: accuracy:0.36 loss: 219.3 (lr:0.0001)
141580: accuracy:0.39 loss: 217.701 (lr:0.0001)
141590: accuracy:0.44 loss: 192.723 (lr:0.0001)
141600: accuracy:0.29 loss: 252.393 (lr:0.0001)
141610: accuracy:0.37 loss: 206.866 (lr:0.0001)
141620: accuracy:0.4 loss: 212.007 (lr:0.0001)
141630: accuracy:0.38 loss: 192.482 (lr:0.0001)
141640: accuracy:0.4 loss: 196.844 (lr:0.0001)
141650: accuracy:0.39 loss: 195.994 (lr:0.0001)
141660: accuracy:0.4 loss: 208.517 (lr:0.0001)
141670: accuracy:0.36 loss: 202.617 (lr:0.0001)
141680: accuracy:0.38 loss: 215.716 (lr:0.0001)
141690: accuracy:0.32 loss: 211.066 (lr:0.0001)
141700: accuracy:0.32 loss: 217.373 (lr:0.0001)
141710: accuracy:0.45 loss: 196.775 (lr:0.0001)
141720: accuracy:0.32 loss: 204.007 (lr:0.0001)
141730: accuracy:0.45 loss: 187.294 (lr:0.0001)
141740: accuracy:0.3 loss: 206.895 (lr:0.0001)
141750: accuracy:0.4 loss: 190.486 (lr:0.0001)
141760: accuracy:0.4 loss: 196.253 (lr:0.0001)
141770: accuracy:0.42 loss: 203.336 (lr:0.0001)
141780: accuracy:0.28 loss: 208.576 (lr:0.0001)
141790: accuracy:0.28 loss: 216.758 (lr:0.0001)
141800: accuracy:0.34 loss: 208.566 (lr:0.0001)
141810: accuracy:0.3 loss: 204.692 (lr:0.0001)
141820: accuracy:0.37 loss: 200.219 (lr:0.0001)
141830: accuracy:0.42 loss: 206.393 (lr:0.0001)
141840: accuracy:0.33 loss: 208.788 (lr:0.0001)
141850: accuracy:0.39 loss: 197.696 (lr:0.0001)
141860: accuracy:0.38 loss: 207.565 (lr:0.0001)
141870: accuracy:0.39 loss: 208.295 (lr:0.0001)
141880: accuracy:0.34 loss: 197.23 (lr:0.0001)
141890: accuracy:0.33 loss: 199.928 (lr:0.0001)
141900: accuracy:0.37 loss: 199.809 (lr:0.0001)
141910: accuracy:0.3 loss: 232.252 (lr:0.0001)
141920: accuracy:0.41 loss: 206.575 (lr:0.0001)
141930: accuracy:0.3 loss: 198.727 (lr:0.0001)
141940: accuracy:0.32 loss: 212.221 (lr:0.0001)
141950: accuracy:0.39 loss: 200.174 (lr:0.0001)
141960: accuracy:0.4 loss: 186.402 (lr:0.0001)
141970: accuracy:0.37 loss: 198.078 (lr:0.0001)
141980: accuracy:0.35 loss: 197.004 (lr:0.0001)
141990: accuracy:0.37 loss: 197.762 (lr:0.0001)
142000: accuracy:0.4 loss: 196.073 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
142000: ********* epoch 15 ********* test accuracy for all:0.262135 test loss: 254.124
142000: ********* epoch 15 ********* test accuracy for mode 0:0.039 test loss: 441.206
142000: ********* epoch 15 ********* test accuracy for mode 1:0.04 test loss: 424.204
142000: ********* epoch 15 ********* test accuracy for mode 2:0.042 test loss: 262.971
142000: ********* epoch 15 ********* test accuracy for mode 24:0.27 test loss: 271.767
142000: ********* epoch 15 ********* test accuracy for mode 25:0.316 test loss: 239.895
142000: ********* epoch 15 ********* test accuracy for mode 26:0.491 test loss: 156.135
142000: ********* epoch 15 ********* test accuracy for mode 27:0.2435 test loss: 265.108
142000: ********* epoch 15 ********* test accuracy for mode 28:0.321 test loss: 248.349
142000: ********* epoch 15 ********* test accuracy for mode 29:0.293 test loss: 259.251
142000: ********* epoch 15 ********* test accuracy for mode 30:0.238 test loss: 253.187
142000: ********* epoch 15 ********* test accuracy for mode 31:0.168 test loss: 258.625
142000: ********* epoch 15 ********* test accuracy for mode 32:0.249 test loss: 231.67
142000: ********* epoch 15 ********* test accuracy for mode 33:0.302 test loss: 229.837
142000: ********* epoch 15 ********* test accuracy for mode 34:0.2255 test loss: 235.739
142000: ********* epoch 15 ********* test accuracy for mode 35:0.0685 test loss: 440.808
142000: ********* epoch 15 ********* test accuracy for mode 36:0.125 test loss: 463.156
142010: accuracy:0.35 loss: 217.029 (lr:0.0001)
142020: accuracy:0.35 loss: 203.236 (lr:0.0001)
142030: accuracy:0.23 loss: 203.951 (lr:0.0001)
142040: accuracy:0.36 loss: 202.775 (lr:0.0001)
142050: accuracy:0.37 loss: 210.161 (lr:0.0001)
142060: accuracy:0.28 loss: 237.91 (lr:0.0001)
142070: accuracy:0.34 loss: 225.908 (lr:0.0001)
142080: accuracy:0.4 loss: 191.394 (lr:0.0001)
142090: accuracy:0.38 loss: 201.072 (lr:0.0001)
142100: accuracy:0.42 loss: 195.512 (lr:0.0001)
142110: accuracy:0.41 loss: 201.144 (lr:0.0001)
142120: accuracy:0.3 loss: 216.716 (lr:0.0001)
142130: accuracy:0.37 loss: 191.814 (lr:0.0001)
142140: accuracy:0.4 loss: 221.739 (lr:0.0001)
142150: accuracy:0.35 loss: 212.151 (lr:0.0001)
142160: accuracy:0.37 loss: 200.107 (lr:0.0001)
142170: accuracy:0.41 loss: 209.746 (lr:0.0001)
142180: accuracy:0.42 loss: 201.317 (lr:0.0001)
142190: accuracy:0.27 loss: 208.404 (lr:0.0001)
142200: accuracy:0.38 loss: 201.696 (lr:0.0001)
142210: accuracy:0.38 loss: 199.212 (lr:0.0001)
142220: accuracy:0.35 loss: 200.891 (lr:0.0001)
142230: accuracy:0.33 loss: 225.139 (lr:0.0001)
142240: accuracy:0.33 loss: 204.595 (lr:0.0001)
142250: accuracy:0.42 loss: 193.291 (lr:0.0001)
142260: accuracy:0.41 loss: 190.217 (lr:0.0001)
142270: accuracy:0.37 loss: 200.885 (lr:0.0001)
142280: accuracy:0.4 loss: 190.178 (lr:0.0001)
142290: accuracy:0.35 loss: 224.836 (lr:0.0001)
142300: accuracy:0.43 loss: 206.062 (lr:0.0001)
142310: accuracy:0.48 loss: 188.414 (lr:0.0001)
142320: accuracy:0.31 loss: 228.849 (lr:0.0001)
142330: accuracy:0.36 loss: 200.778 (lr:0.0001)
142340: accuracy:0.31 loss: 208.925 (lr:0.0001)
142350: accuracy:0.34 loss: 225.173 (lr:0.0001)
142360: accuracy:0.35 loss: 210.046 (lr:0.0001)
142370: accuracy:0.41 loss: 199.591 (lr:0.0001)
142380: accuracy:0.34 loss: 207.193 (lr:0.0001)
142390: accuracy:0.38 loss: 206.004 (lr:0.0001)
142400: accuracy:0.32 loss: 196.057 (lr:0.0001)
142410: accuracy:0.36 loss: 192.287 (lr:0.0001)
142420: accuracy:0.34 loss: 211.551 (lr:0.0001)
142430: accuracy:0.3 loss: 198.663 (lr:0.0001)
142440: accuracy:0.33 loss: 213.504 (lr:0.0001)
142450: accuracy:0.32 loss: 203.115 (lr:0.0001)
142460: accuracy:0.37 loss: 204.7 (lr:0.0001)
142470: accuracy:0.39 loss: 201.424 (lr:0.0001)
142480: accuracy:0.38 loss: 214.786 (lr:0.0001)
142490: accuracy:0.36 loss: 210.972 (lr:0.0001)
142500: accuracy:0.37 loss: 207.315 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
142500: ********* epoch 15 ********* test accuracy for all:0.259054 test loss: 257.013
142500: ********* epoch 15 ********* test accuracy for mode 0:0.035 test loss: 450.911
142500: ********* epoch 15 ********* test accuracy for mode 1:0.027 test loss: 438.612
142500: ********* epoch 15 ********* test accuracy for mode 2:0.0425 test loss: 262.622
142500: ********* epoch 15 ********* test accuracy for mode 24:0.2245 test loss: 277.256
142500: ********* epoch 15 ********* test accuracy for mode 25:0.3085 test loss: 244.142
142500: ********* epoch 15 ********* test accuracy for mode 26:0.4885 test loss: 156.416
142500: ********* epoch 15 ********* test accuracy for mode 27:0.2845 test loss: 257.056
142500: ********* epoch 15 ********* test accuracy for mode 28:0.266 test loss: 259.512
142500: ********* epoch 15 ********* test accuracy for mode 29:0.282 test loss: 261.575
142500: ********* epoch 15 ********* test accuracy for mode 30:0.1955 test loss: 252.737
142500: ********* epoch 15 ********* test accuracy for mode 31:0.218 test loss: 249.888
142500: ********* epoch 15 ********* test accuracy for mode 32:0.195 test loss: 235.696
142500: ********* epoch 15 ********* test accuracy for mode 33:0.2845 test loss: 233.294
142500: ********* epoch 15 ********* test accuracy for mode 34:0.233 test loss: 235.573
142500: ********* epoch 15 ********* test accuracy for mode 35:0.052 test loss: 452.259
142500: ********* epoch 15 ********* test accuracy for mode 36:0.143 test loss: 470.028
142510: accuracy:0.37 loss: 197.159 (lr:0.0001)
142520: accuracy:0.38 loss: 210.654 (lr:0.0001)
142530: accuracy:0.36 loss: 195.393 (lr:0.0001)
142540: accuracy:0.37 loss: 214.308 (lr:0.0001)
142550: accuracy:0.31 loss: 203.693 (lr:0.0001)
142560: accuracy:0.35 loss: 208.948 (lr:0.0001)
142570: accuracy:0.34 loss: 199.442 (lr:0.0001)
142580: accuracy:0.35 loss: 192.246 (lr:0.0001)
142590: accuracy:0.38 loss: 190.344 (lr:0.0001)
142600: accuracy:0.4 loss: 193.529 (lr:0.0001)
142610: accuracy:0.49 loss: 180.689 (lr:0.0001)
142620: accuracy:0.47 loss: 188.723 (lr:0.0001)
142630: accuracy:0.34 loss: 219.197 (lr:0.0001)
142640: accuracy:0.41 loss: 189.77 (lr:0.0001)
142650: accuracy:0.38 loss: 209.148 (lr:0.0001)
142660: accuracy:0.41 loss: 190.268 (lr:0.0001)
142670: accuracy:0.36 loss: 204.085 (lr:0.0001)
142680: accuracy:0.38 loss: 210.846 (lr:0.0001)
142690: accuracy:0.4 loss: 210.135 (lr:0.0001)
142700: accuracy:0.31 loss: 208.606 (lr:0.0001)
142710: accuracy:0.41 loss: 200.277 (lr:0.0001)
142720: accuracy:0.31 loss: 212.633 (lr:0.0001)
142730: accuracy:0.32 loss: 228.532 (lr:0.0001)
142740: accuracy:0.38 loss: 194.67 (lr:0.0001)
142750: accuracy:0.27 loss: 235.274 (lr:0.0001)
142760: accuracy:0.42 loss: 194.866 (lr:0.0001)
142770: accuracy:0.27 loss: 196.578 (lr:0.0001)
142780: accuracy:0.28 loss: 212.696 (lr:0.0001)
142790: accuracy:0.33 loss: 233.127 (lr:0.0001)
142800: accuracy:0.31 loss: 210.462 (lr:0.0001)
142810: accuracy:0.38 loss: 196.048 (lr:0.0001)
142820: accuracy:0.33 loss: 224.494 (lr:0.0001)
142830: accuracy:0.35 loss: 205.336 (lr:0.0001)
142840: accuracy:0.38 loss: 206.002 (lr:0.0001)
142850: accuracy:0.35 loss: 206.101 (lr:0.0001)
142860: accuracy:0.25 loss: 244.881 (lr:0.0001)
142870: accuracy:0.29 loss: 200.16 (lr:0.0001)
142880: accuracy:0.28 loss: 205.379 (lr:0.0001)
142890: accuracy:0.44 loss: 197.496 (lr:0.0001)
142900: accuracy:0.32 loss: 205.921 (lr:0.0001)
142910: accuracy:0.38 loss: 202.966 (lr:0.0001)
142920: accuracy:0.27 loss: 209.013 (lr:0.0001)
142930: accuracy:0.41 loss: 192.2 (lr:0.0001)
142940: accuracy:0.27 loss: 227.085 (lr:0.0001)
142950: accuracy:0.4 loss: 183.42 (lr:0.0001)
142960: accuracy:0.33 loss: 202.978 (lr:0.0001)
142970: accuracy:0.25 loss: 200.815 (lr:0.0001)
142980: accuracy:0.38 loss: 189.623 (lr:0.0001)
142990: accuracy:0.36 loss: 207.37 (lr:0.0001)
143000: accuracy:0.34 loss: 184.892 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
143000: ********* epoch 15 ********* test accuracy for all:0.259378 test loss: 254.43
143000: ********* epoch 15 ********* test accuracy for mode 0:0.038 test loss: 441.092
143000: ********* epoch 15 ********* test accuracy for mode 1:0.03 test loss: 430.493
143000: ********* epoch 15 ********* test accuracy for mode 2:0.0555 test loss: 265.583
143000: ********* epoch 15 ********* test accuracy for mode 24:0.239 test loss: 271.645
143000: ********* epoch 15 ********* test accuracy for mode 25:0.325 test loss: 237.877
143000: ********* epoch 15 ********* test accuracy for mode 26:0.478 test loss: 160.162
143000: ********* epoch 15 ********* test accuracy for mode 27:0.226 test loss: 270.258
143000: ********* epoch 15 ********* test accuracy for mode 28:0.2835 test loss: 257.034
143000: ********* epoch 15 ********* test accuracy for mode 29:0.288 test loss: 258.889
143000: ********* epoch 15 ********* test accuracy for mode 30:0.2345 test loss: 246.743
143000: ********* epoch 15 ********* test accuracy for mode 31:0.1805 test loss: 250.155
143000: ********* epoch 15 ********* test accuracy for mode 32:0.3235 test loss: 227.238
143000: ********* epoch 15 ********* test accuracy for mode 33:0.1975 test loss: 243.259
143000: ********* epoch 15 ********* test accuracy for mode 34:0.234 test loss: 243.23
143000: ********* epoch 15 ********* test accuracy for mode 35:0.0435 test loss: 448.916
143000: ********* epoch 15 ********* test accuracy for mode 36:0.1385 test loss: 466.021
143010: accuracy:0.38 loss: 219.802 (lr:0.0001)
143020: accuracy:0.24 loss: 236.863 (lr:0.0001)
143030: accuracy:0.32 loss: 203.183 (lr:0.0001)
143040: accuracy:0.44 loss: 186.042 (lr:0.0001)
143050: accuracy:0.4 loss: 193.225 (lr:0.0001)
143060: accuracy:0.37 loss: 201.901 (lr:0.0001)
143070: accuracy:0.43 loss: 184.969 (lr:0.0001)
143080: accuracy:0.37 loss: 207.114 (lr:0.0001)
143090: accuracy:0.37 loss: 200.046 (lr:0.0001)
143100: accuracy:0.34 loss: 205.104 (lr:0.0001)
143110: accuracy:0.33 loss: 192.173 (lr:0.0001)
143120: accuracy:0.3 loss: 231.846 (lr:0.0001)
143130: accuracy:0.33 loss: 219.487 (lr:0.0001)
143140: accuracy:0.35 loss: 216.634 (lr:0.0001)
143150: accuracy:0.41 loss: 202.813 (lr:0.0001)
143160: accuracy:0.33 loss: 218.432 (lr:0.0001)
143170: accuracy:0.44 loss: 200.03 (lr:0.0001)
143180: accuracy:0.4 loss: 187.441 (lr:0.0001)
143190: accuracy:0.32 loss: 229.714 (lr:0.0001)
143200: accuracy:0.42 loss: 198.055 (lr:0.0001)
143210: accuracy:0.36 loss: 216.548 (lr:0.0001)
143220: accuracy:0.33 loss: 220.686 (lr:0.0001)
143230: accuracy:0.32 loss: 202.558 (lr:0.0001)
143240: accuracy:0.36 loss: 210.708 (lr:0.0001)
143250: accuracy:0.38 loss: 198.794 (lr:0.0001)
143260: accuracy:0.4 loss: 194.247 (lr:0.0001)
143270: accuracy:0.38 loss: 205.007 (lr:0.0001)
143280: accuracy:0.38 loss: 206.819 (lr:0.0001)
143290: accuracy:0.4 loss: 195.449 (lr:0.0001)
143300: accuracy:0.29 loss: 220.608 (lr:0.0001)
143310: accuracy:0.31 loss: 207.977 (lr:0.0001)
143320: accuracy:0.36 loss: 207.173 (lr:0.0001)
143330: accuracy:0.32 loss: 228.412 (lr:0.0001)
143340: accuracy:0.31 loss: 212.508 (lr:0.0001)
143350: accuracy:0.42 loss: 182.632 (lr:0.0001)
143360: accuracy:0.4 loss: 197.214 (lr:0.0001)
143370: accuracy:0.31 loss: 205.901 (lr:0.0001)
143380: accuracy:0.37 loss: 213.234 (lr:0.0001)
143390: accuracy:0.3 loss: 227.728 (lr:0.0001)
143400: accuracy:0.44 loss: 188.344 (lr:0.0001)
143410: accuracy:0.31 loss: 212.328 (lr:0.0001)
143420: accuracy:0.34 loss: 199.309 (lr:0.0001)
143430: accuracy:0.33 loss: 221.413 (lr:0.0001)
143440: accuracy:0.36 loss: 205.17 (lr:0.0001)
143450: accuracy:0.42 loss: 186.474 (lr:0.0001)
143460: accuracy:0.32 loss: 221.69 (lr:0.0001)
143470: accuracy:0.37 loss: 198.852 (lr:0.0001)
143480: accuracy:0.35 loss: 197.04 (lr:0.0001)
143490: accuracy:0.38 loss: 196.639 (lr:0.0001)
143500: accuracy:0.39 loss: 192.106 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
143500: ********* epoch 15 ********* test accuracy for all:0.258662 test loss: 254.426
143500: ********* epoch 15 ********* test accuracy for mode 0:0.043 test loss: 426.242
143500: ********* epoch 15 ********* test accuracy for mode 1:0.041 test loss: 419.498
143500: ********* epoch 15 ********* test accuracy for mode 2:0.0645 test loss: 254.494
143500: ********* epoch 15 ********* test accuracy for mode 24:0.237 test loss: 277.2
143500: ********* epoch 15 ********* test accuracy for mode 25:0.31 test loss: 245.123
143500: ********* epoch 15 ********* test accuracy for mode 26:0.4745 test loss: 161.439
143500: ********* epoch 15 ********* test accuracy for mode 27:0.25 test loss: 267.814
143500: ********* epoch 15 ********* test accuracy for mode 28:0.2835 test loss: 255.321
143500: ********* epoch 15 ********* test accuracy for mode 29:0.2645 test loss: 260.721
143500: ********* epoch 15 ********* test accuracy for mode 30:0.2275 test loss: 246.17
143500: ********* epoch 15 ********* test accuracy for mode 31:0.241 test loss: 244.354
143500: ********* epoch 15 ********* test accuracy for mode 32:0.245 test loss: 232.031
143500: ********* epoch 15 ********* test accuracy for mode 33:0.2155 test loss: 238.466
143500: ********* epoch 15 ********* test accuracy for mode 34:0.3205 test loss: 231.275
143500: ********* epoch 15 ********* test accuracy for mode 35:0.0505 test loss: 438.874
143500: ********* epoch 15 ********* test accuracy for mode 36:0.117 test loss: 464.957
143510: accuracy:0.33 loss: 201.066 (lr:0.0001)
143520: accuracy:0.32 loss: 200.092 (lr:0.0001)
143530: accuracy:0.36 loss: 196.448 (lr:0.0001)
143540: accuracy:0.43 loss: 203.493 (lr:0.0001)
143550: accuracy:0.43 loss: 183.968 (lr:0.0001)
143560: accuracy:0.37 loss: 210.914 (lr:0.0001)
143570: accuracy:0.3 loss: 221.26 (lr:0.0001)
143580: accuracy:0.33 loss: 207.826 (lr:0.0001)
143590: accuracy:0.26 loss: 234.179 (lr:0.0001)
143600: accuracy:0.21 loss: 240.703 (lr:0.0001)
143610: accuracy:0.41 loss: 193.208 (lr:0.0001)
143620: accuracy:0.35 loss: 227.838 (lr:0.0001)
143630: accuracy:0.27 loss: 223.422 (lr:0.0001)
143640: accuracy:0.37 loss: 188.65 (lr:0.0001)
143650: accuracy:0.32 loss: 214.464 (lr:0.0001)
143660: accuracy:0.45 loss: 216.665 (lr:0.0001)
143670: accuracy:0.42 loss: 206.429 (lr:0.0001)
143680: accuracy:0.38 loss: 200.297 (lr:0.0001)
143690: accuracy:0.32 loss: 210.93 (lr:0.0001)
143700: accuracy:0.24 loss: 223.805 (lr:0.0001)
143710: accuracy:0.44 loss: 186.547 (lr:0.0001)
143720: accuracy:0.4 loss: 207.636 (lr:0.0001)
143730: accuracy:0.41 loss: 200.835 (lr:0.0001)
143740: accuracy:0.37 loss: 204.869 (lr:0.0001)
143750: accuracy:0.29 loss: 228.757 (lr:0.0001)
143760: accuracy:0.28 loss: 212.284 (lr:0.0001)
143770: accuracy:0.33 loss: 217.382 (lr:0.0001)
143780: accuracy:0.32 loss: 196.375 (lr:0.0001)
143790: accuracy:0.32 loss: 206.896 (lr:0.0001)
143800: accuracy:0.35 loss: 194.884 (lr:0.0001)
143810: accuracy:0.36 loss: 198.636 (lr:0.0001)
143820: accuracy:0.41 loss: 210.975 (lr:0.0001)
143830: accuracy:0.35 loss: 196.243 (lr:0.0001)
143840: accuracy:0.37 loss: 182.627 (lr:0.0001)
143850: accuracy:0.31 loss: 222.251 (lr:0.0001)
143860: accuracy:0.36 loss: 196.284 (lr:0.0001)
143870: accuracy:0.33 loss: 228.627 (lr:0.0001)
143880: accuracy:0.35 loss: 206.591 (lr:0.0001)
143890: accuracy:0.37 loss: 193.256 (lr:0.0001)
143900: accuracy:0.32 loss: 226.837 (lr:0.0001)
143910: accuracy:0.4 loss: 192.641 (lr:0.0001)
143920: accuracy:0.36 loss: 193.526 (lr:0.0001)
143930: accuracy:0.29 loss: 229.46 (lr:0.0001)
143940: accuracy:0.36 loss: 214.112 (lr:0.0001)
143950: accuracy:0.38 loss: 202.873 (lr:0.0001)
143960: accuracy:0.35 loss: 201.475 (lr:0.0001)
143970: accuracy:0.28 loss: 214.296 (lr:0.0001)
143980: accuracy:0.38 loss: 204.71 (lr:0.0001)
143990: accuracy:0.41 loss: 217.493 (lr:0.0001)
144000: accuracy:0.4 loss: 201.031 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
144000: ********* epoch 15 ********* test accuracy for all:0.26473 test loss: 254.755
144000: ********* epoch 15 ********* test accuracy for mode 0:0.0385 test loss: 446.976
144000: ********* epoch 15 ********* test accuracy for mode 1:0.0275 test loss: 439.823
144000: ********* epoch 15 ********* test accuracy for mode 2:0.053 test loss: 260.55
144000: ********* epoch 15 ********* test accuracy for mode 24:0.2895 test loss: 257.652
144000: ********* epoch 15 ********* test accuracy for mode 25:0.268 test loss: 242.923
144000: ********* epoch 15 ********* test accuracy for mode 26:0.5015 test loss: 159.822
144000: ********* epoch 15 ********* test accuracy for mode 27:0.234 test loss: 267.017
144000: ********* epoch 15 ********* test accuracy for mode 28:0.2865 test loss: 252.38
144000: ********* epoch 15 ********* test accuracy for mode 29:0.2385 test loss: 264.891
144000: ********* epoch 15 ********* test accuracy for mode 30:0.2345 test loss: 246.16
144000: ********* epoch 15 ********* test accuracy for mode 31:0.2385 test loss: 246.902
144000: ********* epoch 15 ********* test accuracy for mode 32:0.1975 test loss: 235.037
144000: ********* epoch 15 ********* test accuracy for mode 33:0.289 test loss: 233.617
144000: ********* epoch 15 ********* test accuracy for mode 34:0.219 test loss: 238.832
144000: ********* epoch 15 ********* test accuracy for mode 35:0.1055 test loss: 427.813
144000: ********* epoch 15 ********* test accuracy for mode 36:0.295 test loss: 441.564
144010: accuracy:0.44 loss: 198.37 (lr:0.0001)
144020: accuracy:0.26 loss: 222.277 (lr:0.0001)
144030: accuracy:0.38 loss: 206.531 (lr:0.0001)
144040: accuracy:0.28 loss: 220.974 (lr:0.0001)
144050: accuracy:0.43 loss: 188.052 (lr:0.0001)
144060: accuracy:0.39 loss: 202.124 (lr:0.0001)
144070: accuracy:0.33 loss: 199.813 (lr:0.0001)
144080: accuracy:0.35 loss: 225.922 (lr:0.0001)
144090: accuracy:0.27 loss: 217.388 (lr:0.0001)
144100: accuracy:0.32 loss: 204.465 (lr:0.0001)
144110: accuracy:0.38 loss: 219.553 (lr:0.0001)
144120: accuracy:0.42 loss: 196.602 (lr:0.0001)
144130: accuracy:0.36 loss: 213.899 (lr:0.0001)
144140: accuracy:0.25 loss: 212.791 (lr:0.0001)
144150: accuracy:0.38 loss: 184.174 (lr:0.0001)
144160: accuracy:0.44 loss: 188.149 (lr:0.0001)
144170: accuracy:0.35 loss: 211.913 (lr:0.0001)
144180: accuracy:0.39 loss: 196.793 (lr:0.0001)
144190: accuracy:0.35 loss: 214.159 (lr:0.0001)
144200: accuracy:0.32 loss: 217.617 (lr:0.0001)
144210: accuracy:0.44 loss: 196.194 (lr:0.0001)
144220: accuracy:0.41 loss: 201.751 (lr:0.0001)
144230: accuracy:0.33 loss: 208.032 (lr:0.0001)
144240: accuracy:0.37 loss: 203.704 (lr:0.0001)
144250: accuracy:0.3 loss: 205.861 (lr:0.0001)
144260: accuracy:0.36 loss: 201.587 (lr:0.0001)
144270: accuracy:0.29 loss: 222.287 (lr:0.0001)
144280: accuracy:0.44 loss: 185.244 (lr:0.0001)
144290: accuracy:0.35 loss: 211.48 (lr:0.0001)
144300: accuracy:0.39 loss: 190.297 (lr:0.0001)
144310: accuracy:0.28 loss: 214.427 (lr:0.0001)
144320: accuracy:0.36 loss: 206.155 (lr:0.0001)
144330: accuracy:0.31 loss: 217.666 (lr:0.0001)
144340: accuracy:0.36 loss: 206.537 (lr:0.0001)
144350: accuracy:0.4 loss: 204.006 (lr:0.0001)
144360: accuracy:0.39 loss: 216.173 (lr:0.0001)
144370: accuracy:0.29 loss: 207.836 (lr:0.0001)
144380: accuracy:0.29 loss: 216.289 (lr:0.0001)
144390: accuracy:0.28 loss: 214.075 (lr:0.0001)
144400: accuracy:0.33 loss: 224.926 (lr:0.0001)
144410: accuracy:0.31 loss: 227.694 (lr:0.0001)
144420: accuracy:0.29 loss: 208.879 (lr:0.0001)
144430: accuracy:0.3 loss: 219.423 (lr:0.0001)
144440: accuracy:0.28 loss: 220.636 (lr:0.0001)
144450: accuracy:0.36 loss: 201.577 (lr:0.0001)
144460: accuracy:0.35 loss: 202.185 (lr:0.0001)
144470: accuracy:0.23 loss: 232.873 (lr:0.0001)
144480: accuracy:0.38 loss: 206.435 (lr:0.0001)
144490: accuracy:0.36 loss: 208.974 (lr:0.0001)
144500: accuracy:0.36 loss: 197.734 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
144500: ********* epoch 15 ********* test accuracy for all:0.263581 test loss: 254.708
144500: ********* epoch 15 ********* test accuracy for mode 0:0.0545 test loss: 427.588
144500: ********* epoch 15 ********* test accuracy for mode 1:0.0355 test loss: 429.265
144500: ********* epoch 15 ********* test accuracy for mode 2:0.076 test loss: 256.845
144500: ********* epoch 15 ********* test accuracy for mode 24:0.2705 test loss: 267.183
144500: ********* epoch 15 ********* test accuracy for mode 25:0.289 test loss: 248.798
144500: ********* epoch 15 ********* test accuracy for mode 26:0.489 test loss: 159.027
144500: ********* epoch 15 ********* test accuracy for mode 27:0.2585 test loss: 264.033
144500: ********* epoch 15 ********* test accuracy for mode 28:0.285 test loss: 260.77
144500: ********* epoch 15 ********* test accuracy for mode 29:0.2575 test loss: 269.963
144500: ********* epoch 15 ********* test accuracy for mode 30:0.2565 test loss: 254.018
144500: ********* epoch 15 ********* test accuracy for mode 31:0.1755 test loss: 263.074
144500: ********* epoch 15 ********* test accuracy for mode 32:0.2005 test loss: 246.501
144500: ********* epoch 15 ********* test accuracy for mode 33:0.2545 test loss: 244.45
144500: ********* epoch 15 ********* test accuracy for mode 34:0.214 test loss: 243.733
144500: ********* epoch 15 ********* test accuracy for mode 35:0.091 test loss: 424.853
144500: ********* epoch 15 ********* test accuracy for mode 36:0.2845 test loss: 440.154
144510: accuracy:0.33 loss: 212.892 (lr:0.0001)
144520: accuracy:0.39 loss: 175.151 (lr:0.0001)
144530: accuracy:0.33 loss: 186.956 (lr:0.0001)
144540: accuracy:0.39 loss: 198.726 (lr:0.0001)
144550: accuracy:0.31 loss: 227.471 (lr:0.0001)
144560: accuracy:0.42 loss: 194.419 (lr:0.0001)
144570: accuracy:0.4 loss: 189.131 (lr:0.0001)
144580: accuracy:0.3 loss: 208.87 (lr:0.0001)
144590: accuracy:0.39 loss: 194.649 (lr:0.0001)
144600: accuracy:0.41 loss: 217.981 (lr:0.0001)
144610: accuracy:0.37 loss: 204.831 (lr:0.0001)
144620: accuracy:0.4 loss: 210.141 (lr:0.0001)
144630: accuracy:0.29 loss: 214.93 (lr:0.0001)
144640: accuracy:0.29 loss: 221.971 (lr:0.0001)
144650: accuracy:0.26 loss: 222.21 (lr:0.0001)
144660: accuracy:0.36 loss: 218.826 (lr:0.0001)
144670: accuracy:0.32 loss: 218.284 (lr:0.0001)
144680: accuracy:0.37 loss: 207.22 (lr:0.0001)
144690: accuracy:0.35 loss: 210.982 (lr:0.0001)
144700: accuracy:0.34 loss: 203.545 (lr:0.0001)
144710: accuracy:0.4 loss: 196.199 (lr:0.0001)
144720: accuracy:0.36 loss: 195.759 (lr:0.0001)
144730: accuracy:0.37 loss: 195.63 (lr:0.0001)
144740: accuracy:0.41 loss: 200.153 (lr:0.0001)
144750: accuracy:0.37 loss: 187.746 (lr:0.0001)
144760: accuracy:0.34 loss: 215.135 (lr:0.0001)
144770: accuracy:0.36 loss: 213.259 (lr:0.0001)
144780: accuracy:0.35 loss: 211.713 (lr:0.0001)
144790: accuracy:0.27 loss: 212.619 (lr:0.0001)
144800: accuracy:0.41 loss: 211.858 (lr:0.0001)
144810: accuracy:0.41 loss: 207.554 (lr:0.0001)
144820: accuracy:0.38 loss: 204.435 (lr:0.0001)
144830: accuracy:0.3 loss: 216.673 (lr:0.0001)
144840: accuracy:0.49 loss: 195.543 (lr:0.0001)
144850: accuracy:0.35 loss: 209.124 (lr:0.0001)
144860: accuracy:0.46 loss: 185.881 (lr:0.0001)
144870: accuracy:0.38 loss: 211.08 (lr:0.0001)
144880: accuracy:0.32 loss: 201.91 (lr:0.0001)
144890: accuracy:0.34 loss: 209.415 (lr:0.0001)
144900: accuracy:0.3 loss: 212.627 (lr:0.0001)
144910: accuracy:0.37 loss: 209.514 (lr:0.0001)
144920: accuracy:0.27 loss: 224.133 (lr:0.0001)
144930: accuracy:0.33 loss: 217.745 (lr:0.0001)
144940: accuracy:0.35 loss: 193.71 (lr:0.0001)
144950: accuracy:0.3 loss: 226.928 (lr:0.0001)
144960: accuracy:0.27 loss: 234.708 (lr:0.0001)
144970: accuracy:0.4 loss: 189.543 (lr:0.0001)
144980: accuracy:0.38 loss: 197.936 (lr:0.0001)
144990: accuracy:0.41 loss: 182.385 (lr:0.0001)
145000: accuracy:0.28 loss: 212.822 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
145000: ********* epoch 15 ********* test accuracy for all:0.258432 test loss: 255.638
145000: ********* epoch 15 ********* test accuracy for mode 0:0.043 test loss: 441.43
145000: ********* epoch 15 ********* test accuracy for mode 1:0.0315 test loss: 438.377
145000: ********* epoch 15 ********* test accuracy for mode 2:0.058 test loss: 258.267
145000: ********* epoch 15 ********* test accuracy for mode 24:0.2565 test loss: 274.852
145000: ********* epoch 15 ********* test accuracy for mode 25:0.2905 test loss: 249.55
145000: ********* epoch 15 ********* test accuracy for mode 26:0.4905 test loss: 161.024
145000: ********* epoch 15 ********* test accuracy for mode 27:0.244 test loss: 267.79
145000: ********* epoch 15 ********* test accuracy for mode 28:0.2535 test loss: 262.327
145000: ********* epoch 15 ********* test accuracy for mode 29:0.2845 test loss: 262.237
145000: ********* epoch 15 ********* test accuracy for mode 30:0.1885 test loss: 253.616
145000: ********* epoch 15 ********* test accuracy for mode 31:0.215 test loss: 248.334
145000: ********* epoch 15 ********* test accuracy for mode 32:0.258 test loss: 230.952
145000: ********* epoch 15 ********* test accuracy for mode 33:0.256 test loss: 235.94
145000: ********* epoch 15 ********* test accuracy for mode 34:0.244 test loss: 238.928
145000: ********* epoch 15 ********* test accuracy for mode 35:0.091 test loss: 426.065
145000: ********* epoch 15 ********* test accuracy for mode 36:0.127 test loss: 457.382
145010: accuracy:0.35 loss: 206.878 (lr:0.0001)
145020: accuracy:0.3 loss: 211.048 (lr:0.0001)
145030: accuracy:0.43 loss: 189.009 (lr:0.0001)
145040: accuracy:0.38 loss: 196.093 (lr:0.0001)
145050: accuracy:0.31 loss: 201.883 (lr:0.0001)
145060: accuracy:0.37 loss: 197.742 (lr:0.0001)
145070: accuracy:0.47 loss: 198.484 (lr:0.0001)
145080: accuracy:0.32 loss: 231.974 (lr:0.0001)
145090: accuracy:0.36 loss: 218.125 (lr:0.0001)
145100: accuracy:0.36 loss: 195.639 (lr:0.0001)
145110: accuracy:0.34 loss: 224.585 (lr:0.0001)
145120: accuracy:0.35 loss: 189.527 (lr:0.0001)
145130: accuracy:0.35 loss: 216.581 (lr:0.0001)
145140: accuracy:0.34 loss: 214.021 (lr:0.0001)
145150: accuracy:0.31 loss: 206.604 (lr:0.0001)
145160: accuracy:0.36 loss: 196.759 (lr:0.0001)
145170: accuracy:0.36 loss: 199.9 (lr:0.0001)
145180: accuracy:0.34 loss: 212.743 (lr:0.0001)
145190: accuracy:0.34 loss: 211.884 (lr:0.0001)
145200: accuracy:0.34 loss: 228.052 (lr:0.0001)
145210: accuracy:0.39 loss: 195.467 (lr:0.0001)
145220: accuracy:0.37 loss: 208.718 (lr:0.0001)
145230: accuracy:0.33 loss: 216.056 (lr:0.0001)
145240: accuracy:0.37 loss: 206.092 (lr:0.0001)
145250: accuracy:0.37 loss: 203.72 (lr:0.0001)
145260: accuracy:0.38 loss: 210.59 (lr:0.0001)
145270: accuracy:0.44 loss: 182.063 (lr:0.0001)
145280: accuracy:0.4 loss: 180.574 (lr:0.0001)
145290: accuracy:0.34 loss: 192.123 (lr:0.0001)
145300: accuracy:0.31 loss: 217.159 (lr:0.0001)
145310: accuracy:0.29 loss: 218.582 (lr:0.0001)
145320: accuracy:0.39 loss: 202.669 (lr:0.0001)
145330: accuracy:0.35 loss: 214.869 (lr:0.0001)
145340: accuracy:0.33 loss: 215.226 (lr:0.0001)
145350: accuracy:0.39 loss: 188.728 (lr:0.0001)
145360: accuracy:0.27 loss: 216.618 (lr:0.0001)
145370: accuracy:0.34 loss: 192.609 (lr:0.0001)
145380: accuracy:0.33 loss: 208.509 (lr:0.0001)
145390: accuracy:0.34 loss: 199.789 (lr:0.0001)
145400: accuracy:0.33 loss: 236.448 (lr:0.0001)
145410: accuracy:0.37 loss: 200.605 (lr:0.0001)
145420: accuracy:0.33 loss: 185.618 (lr:0.0001)
145430: accuracy:0.39 loss: 205.157 (lr:0.0001)
145440: accuracy:0.4 loss: 186.228 (lr:0.0001)
145450: accuracy:0.42 loss: 185.669 (lr:0.0001)
145460: accuracy:0.34 loss: 200.212 (lr:0.0001)
145470: accuracy:0.36 loss: 195.395 (lr:0.0001)
145480: accuracy:0.37 loss: 181.695 (lr:0.0001)
145490: accuracy:0.39 loss: 208.219 (lr:0.0001)
145500: accuracy:0.3 loss: 223.712 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
145500: ********* epoch 15 ********* test accuracy for all:0.254838 test loss: 257.228
145500: ********* epoch 15 ********* test accuracy for mode 0:0.0405 test loss: 440.919
145500: ********* epoch 15 ********* test accuracy for mode 1:0.0325 test loss: 433.842
145500: ********* epoch 15 ********* test accuracy for mode 2:0.03 test loss: 274.275
145500: ********* epoch 15 ********* test accuracy for mode 24:0.232 test loss: 279.191
145500: ********* epoch 15 ********* test accuracy for mode 25:0.2535 test loss: 259.996
145500: ********* epoch 15 ********* test accuracy for mode 26:0.4785 test loss: 162.707
145500: ********* epoch 15 ********* test accuracy for mode 27:0.205 test loss: 278.751
145500: ********* epoch 15 ********* test accuracy for mode 28:0.265 test loss: 270.58
145500: ********* epoch 15 ********* test accuracy for mode 29:0.253 test loss: 277.965
145500: ********* epoch 15 ********* test accuracy for mode 30:0.2565 test loss: 259.99
145500: ********* epoch 15 ********* test accuracy for mode 31:0.163 test loss: 267.638
145500: ********* epoch 15 ********* test accuracy for mode 32:0.2245 test loss: 243.597
145500: ********* epoch 15 ********* test accuracy for mode 33:0.2785 test loss: 242.125
145500: ********* epoch 15 ********* test accuracy for mode 34:0.225 test loss: 244.212
145500: ********* epoch 15 ********* test accuracy for mode 35:0.07 test loss: 430.222
145500: ********* epoch 15 ********* test accuracy for mode 36:0.1255 test loss: 474.218
145510: accuracy:0.39 loss: 190.437 (lr:0.0001)
145520: accuracy:0.31 loss: 207.766 (lr:0.0001)
145530: accuracy:0.31 loss: 197.204 (lr:0.0001)
145540: accuracy:0.37 loss: 218.648 (lr:0.0001)
145550: accuracy:0.31 loss: 195.23 (lr:0.0001)
145560: accuracy:0.34 loss: 201.725 (lr:0.0001)
145570: accuracy:0.4 loss: 190.791 (lr:0.0001)
145580: accuracy:0.3 loss: 207.998 (lr:0.0001)
145590: accuracy:0.37 loss: 208.63 (lr:0.0001)
145600: accuracy:0.38 loss: 198.716 (lr:0.0001)
145610: accuracy:0.32 loss: 216.625 (lr:0.0001)
145620: accuracy:0.38 loss: 199.753 (lr:0.0001)
145630: accuracy:0.32 loss: 211.343 (lr:0.0001)
145640: accuracy:0.31 loss: 239.329 (lr:0.0001)
145650: accuracy:0.44 loss: 196.964 (lr:0.0001)
145660: accuracy:0.36 loss: 203.62 (lr:0.0001)
145670: accuracy:0.32 loss: 198.091 (lr:0.0001)
145680: accuracy:0.37 loss: 203.798 (lr:0.0001)
145690: accuracy:0.37 loss: 202.725 (lr:0.0001)
145700: accuracy:0.32 loss: 225.165 (lr:0.0001)
145710: accuracy:0.47 loss: 183.973 (lr:0.0001)
145720: accuracy:0.43 loss: 184.467 (lr:0.0001)
145730: accuracy:0.36 loss: 195.702 (lr:0.0001)
145740: accuracy:0.4 loss: 197.928 (lr:0.0001)
145750: accuracy:0.35 loss: 209.232 (lr:0.0001)
145760: accuracy:0.35 loss: 210.404 (lr:0.0001)
145770: accuracy:0.35 loss: 203.604 (lr:0.0001)
145780: accuracy:0.38 loss: 185.761 (lr:0.0001)
145790: accuracy:0.3 loss: 224.448 (lr:0.0001)
145800: accuracy:0.41 loss: 190.194 (lr:0.0001)
145810: accuracy:0.34 loss: 215.081 (lr:0.0001)
145820: accuracy:0.33 loss: 204.539 (lr:0.0001)
145830: accuracy:0.34 loss: 188.318 (lr:0.0001)
145840: accuracy:0.38 loss: 184.778 (lr:0.0001)
145850: accuracy:0.29 loss: 202.433 (lr:0.0001)
145860: accuracy:0.38 loss: 196.879 (lr:0.0001)
145870: accuracy:0.39 loss: 186.047 (lr:0.0001)
145880: accuracy:0.39 loss: 190.115 (lr:0.0001)
145890: accuracy:0.28 loss: 222.495 (lr:0.0001)
145900: accuracy:0.33 loss: 211.351 (lr:0.0001)
145910: accuracy:0.34 loss: 221.643 (lr:0.0001)
145920: accuracy:0.38 loss: 190.085 (lr:0.0001)
145930: accuracy:0.28 loss: 217.068 (lr:0.0001)
145940: accuracy:0.39 loss: 189.972 (lr:0.0001)
145950: accuracy:0.29 loss: 213.526 (lr:0.0001)
145960: accuracy:0.29 loss: 211.652 (lr:0.0001)
145970: accuracy:0.4 loss: 209.215 (lr:0.0001)
145980: accuracy:0.35 loss: 200.709 (lr:0.0001)
145990: accuracy:0.44 loss: 186.816 (lr:0.0001)
146000: accuracy:0.37 loss: 197.409 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
146000: ********* epoch 16 ********* test accuracy for all:0.262676 test loss: 254.747
146000: ********* epoch 16 ********* test accuracy for mode 0:0.055 test loss: 440.249
146000: ********* epoch 16 ********* test accuracy for mode 1:0.032 test loss: 433.72
146000: ********* epoch 16 ********* test accuracy for mode 2:0.038 test loss: 259.511
146000: ********* epoch 16 ********* test accuracy for mode 24:0.2265 test loss: 280.591
146000: ********* epoch 16 ********* test accuracy for mode 25:0.286 test loss: 250.554
146000: ********* epoch 16 ********* test accuracy for mode 26:0.5085 test loss: 159.491
146000: ********* epoch 16 ********* test accuracy for mode 27:0.259 test loss: 260.3
146000: ********* epoch 16 ********* test accuracy for mode 28:0.2875 test loss: 257.973
146000: ********* epoch 16 ********* test accuracy for mode 29:0.2575 test loss: 265.935
146000: ********* epoch 16 ********* test accuracy for mode 30:0.235 test loss: 250.332
146000: ********* epoch 16 ********* test accuracy for mode 31:0.182 test loss: 254.321
146000: ********* epoch 16 ********* test accuracy for mode 32:0.2225 test loss: 233.265
146000: ********* epoch 16 ********* test accuracy for mode 33:0.261 test loss: 233.369
146000: ********* epoch 16 ********* test accuracy for mode 34:0.3195 test loss: 229.563
146000: ********* epoch 16 ********* test accuracy for mode 35:0.076 test loss: 443.863
146000: ********* epoch 16 ********* test accuracy for mode 36:0.3 test loss: 451.465
146010: accuracy:0.4 loss: 170.265 (lr:0.0001)
146020: accuracy:0.33 loss: 209.595 (lr:0.0001)
146030: accuracy:0.28 loss: 210.916 (lr:0.0001)
146040: accuracy:0.39 loss: 207.976 (lr:0.0001)
146050: accuracy:0.31 loss: 220.362 (lr:0.0001)
146060: accuracy:0.32 loss: 212.695 (lr:0.0001)
146070: accuracy:0.38 loss: 197.293 (lr:0.0001)
146080: accuracy:0.31 loss: 197.587 (lr:0.0001)
146090: accuracy:0.31 loss: 206.71 (lr:0.0001)
146100: accuracy:0.35 loss: 200.86 (lr:0.0001)
146110: accuracy:0.3 loss: 213.745 (lr:0.0001)
146120: accuracy:0.33 loss: 198.732 (lr:0.0001)
146130: accuracy:0.4 loss: 199.995 (lr:0.0001)
146140: accuracy:0.4 loss: 196.105 (lr:0.0001)
146150: accuracy:0.42 loss: 200.982 (lr:0.0001)
146160: accuracy:0.3 loss: 235.113 (lr:0.0001)
146170: accuracy:0.29 loss: 209.381 (lr:0.0001)
146180: accuracy:0.32 loss: 208.795 (lr:0.0001)
146190: accuracy:0.32 loss: 218.945 (lr:0.0001)
146200: accuracy:0.32 loss: 213.584 (lr:0.0001)
146210: accuracy:0.38 loss: 195.991 (lr:0.0001)
146220: accuracy:0.35 loss: 197.801 (lr:0.0001)
146230: accuracy:0.31 loss: 207.052 (lr:0.0001)
146240: accuracy:0.41 loss: 180.347 (lr:0.0001)
146250: accuracy:0.41 loss: 201.118 (lr:0.0001)
146260: accuracy:0.37 loss: 205.305 (lr:0.0001)
146270: accuracy:0.48 loss: 187.647 (lr:0.0001)
146280: accuracy:0.48 loss: 186.582 (lr:0.0001)
146290: accuracy:0.43 loss: 198.294 (lr:0.0001)
146300: accuracy:0.42 loss: 216.143 (lr:0.0001)
146310: accuracy:0.31 loss: 208.127 (lr:0.0001)
146320: accuracy:0.37 loss: 212.556 (lr:0.0001)
146330: accuracy:0.35 loss: 221.516 (lr:0.0001)
146340: accuracy:0.33 loss: 195.295 (lr:0.0001)
146350: accuracy:0.36 loss: 202.904 (lr:0.0001)
146360: accuracy:0.37 loss: 191.817 (lr:0.0001)
146370: accuracy:0.43 loss: 181.162 (lr:0.0001)
146380: accuracy:0.3 loss: 207.121 (lr:0.0001)
146390: accuracy:0.37 loss: 199.821 (lr:0.0001)
146400: accuracy:0.41 loss: 195.964 (lr:0.0001)
146410: accuracy:0.38 loss: 205.328 (lr:0.0001)
146420: accuracy:0.33 loss: 204.405 (lr:0.0001)
146430: accuracy:0.37 loss: 211.569 (lr:0.0001)
146440: accuracy:0.32 loss: 203.963 (lr:0.0001)
146450: accuracy:0.37 loss: 200.61 (lr:0.0001)
146460: accuracy:0.44 loss: 185.28 (lr:0.0001)
146470: accuracy:0.32 loss: 210.106 (lr:0.0001)
146480: accuracy:0.34 loss: 206.112 (lr:0.0001)
146490: accuracy:0.3 loss: 215.627 (lr:0.0001)
146500: accuracy:0.39 loss: 179.367 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
146500: ********* epoch 16 ********* test accuracy for all:0.257932 test loss: 255.363
146500: ********* epoch 16 ********* test accuracy for mode 0:0.0515 test loss: 442.839
146500: ********* epoch 16 ********* test accuracy for mode 1:0.038 test loss: 433.96
146500: ********* epoch 16 ********* test accuracy for mode 2:0.0225 test loss: 271.114
146500: ********* epoch 16 ********* test accuracy for mode 24:0.225 test loss: 276.528
146500: ********* epoch 16 ********* test accuracy for mode 25:0.2975 test loss: 243.076
146500: ********* epoch 16 ********* test accuracy for mode 26:0.4755 test loss: 156.592
146500: ********* epoch 16 ********* test accuracy for mode 27:0.2465 test loss: 259.809
146500: ********* epoch 16 ********* test accuracy for mode 28:0.2615 test loss: 257.186
146500: ********* epoch 16 ********* test accuracy for mode 29:0.279 test loss: 261.893
146500: ********* epoch 16 ********* test accuracy for mode 30:0.2285 test loss: 252.275
146500: ********* epoch 16 ********* test accuracy for mode 31:0.19 test loss: 256.819
146500: ********* epoch 16 ********* test accuracy for mode 32:0.207 test loss: 239.259
146500: ********* epoch 16 ********* test accuracy for mode 33:0.3125 test loss: 236.235
146500: ********* epoch 16 ********* test accuracy for mode 34:0.2545 test loss: 240.431
146500: ********* epoch 16 ********* test accuracy for mode 35:0.078 test loss: 433.064
146500: ********* epoch 16 ********* test accuracy for mode 36:0.185 test loss: 456.991
146510: accuracy:0.34 loss: 200.178 (lr:0.0001)
146520: accuracy:0.33 loss: 209.933 (lr:0.0001)
146530: accuracy:0.38 loss: 200.123 (lr:0.0001)
146540: accuracy:0.33 loss: 199.517 (lr:0.0001)
146550: accuracy:0.31 loss: 196.542 (lr:0.0001)
146560: accuracy:0.34 loss: 202.231 (lr:0.0001)
146570: accuracy:0.47 loss: 177.873 (lr:0.0001)
146580: accuracy:0.37 loss: 201.674 (lr:0.0001)
146590: accuracy:0.39 loss: 198.382 (lr:0.0001)
146600: accuracy:0.44 loss: 186.185 (lr:0.0001)
146610: accuracy:0.37 loss: 203.481 (lr:0.0001)
146620: accuracy:0.45 loss: 187.027 (lr:0.0001)
146630: accuracy:0.39 loss: 190.08 (lr:0.0001)
146640: accuracy:0.37 loss: 221.244 (lr:0.0001)
146650: accuracy:0.34 loss: 213.256 (lr:0.0001)
146660: accuracy:0.47 loss: 199.805 (lr:0.0001)
146670: accuracy:0.34 loss: 220.596 (lr:0.0001)
146680: accuracy:0.43 loss: 194.133 (lr:0.0001)
146690: accuracy:0.27 loss: 215.485 (lr:0.0001)
146700: accuracy:0.39 loss: 189.076 (lr:0.0001)
146710: accuracy:0.41 loss: 205.919 (lr:0.0001)
146720: accuracy:0.52 loss: 178.529 (lr:0.0001)
146730: accuracy:0.34 loss: 204.619 (lr:0.0001)
146740: accuracy:0.38 loss: 193.3 (lr:0.0001)
146750: accuracy:0.3 loss: 208.211 (lr:0.0001)
146760: accuracy:0.35 loss: 208.252 (lr:0.0001)
146770: accuracy:0.34 loss: 214.199 (lr:0.0001)
146780: accuracy:0.33 loss: 211.024 (lr:0.0001)
146790: accuracy:0.32 loss: 220.421 (lr:0.0001)
146800: accuracy:0.32 loss: 192.067 (lr:0.0001)
146810: accuracy:0.37 loss: 207.982 (lr:0.0001)
146820: accuracy:0.35 loss: 206.344 (lr:0.0001)
146830: accuracy:0.34 loss: 216.629 (lr:0.0001)
146840: accuracy:0.32 loss: 208.285 (lr:0.0001)
146850: accuracy:0.44 loss: 187.885 (lr:0.0001)
146860: accuracy:0.29 loss: 221.826 (lr:0.0001)
146870: accuracy:0.35 loss: 192.107 (lr:0.0001)
146880: accuracy:0.28 loss: 230.349 (lr:0.0001)
146890: accuracy:0.36 loss: 178.499 (lr:0.0001)
146900: accuracy:0.33 loss: 218.038 (lr:0.0001)
146910: accuracy:0.29 loss: 213.909 (lr:0.0001)
146920: accuracy:0.39 loss: 197.011 (lr:0.0001)
146930: accuracy:0.4 loss: 186.629 (lr:0.0001)
146940: accuracy:0.35 loss: 192.495 (lr:0.0001)
146950: accuracy:0.33 loss: 202.763 (lr:0.0001)
146960: accuracy:0.29 loss: 206.286 (lr:0.0001)
146970: accuracy:0.32 loss: 214.247 (lr:0.0001)
146980: accuracy:0.32 loss: 210.155 (lr:0.0001)
146990: accuracy:0.42 loss: 198.549 (lr:0.0001)
147000: accuracy:0.39 loss: 199.589 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
147000: ********* epoch 16 ********* test accuracy for all:0.264297 test loss: 255.174
147000: ********* epoch 16 ********* test accuracy for mode 0:0.046 test loss: 442.93
147000: ********* epoch 16 ********* test accuracy for mode 1:0.031 test loss: 436.04
147000: ********* epoch 16 ********* test accuracy for mode 2:0.031 test loss: 262.383
147000: ********* epoch 16 ********* test accuracy for mode 24:0.248 test loss: 276.255
147000: ********* epoch 16 ********* test accuracy for mode 25:0.259 test loss: 258.889
147000: ********* epoch 16 ********* test accuracy for mode 26:0.4895 test loss: 163.622
147000: ********* epoch 16 ********* test accuracy for mode 27:0.244 test loss: 271.313
147000: ********* epoch 16 ********* test accuracy for mode 28:0.2675 test loss: 257.498
147000: ********* epoch 16 ********* test accuracy for mode 29:0.272 test loss: 260.752
147000: ********* epoch 16 ********* test accuracy for mode 30:0.2355 test loss: 245.859
147000: ********* epoch 16 ********* test accuracy for mode 31:0.2295 test loss: 241.891
147000: ********* epoch 16 ********* test accuracy for mode 32:0.2385 test loss: 229.779
147000: ********* epoch 16 ********* test accuracy for mode 33:0.2635 test loss: 234.367
147000: ********* epoch 16 ********* test accuracy for mode 34:0.252 test loss: 237.481
147000: ********* epoch 16 ********* test accuracy for mode 35:0.0805 test loss: 432.761
147000: ********* epoch 16 ********* test accuracy for mode 36:0.352 test loss: 431.263
147010: accuracy:0.39 loss: 221.077 (lr:0.0001)
147020: accuracy:0.39 loss: 181.197 (lr:0.0001)
147030: accuracy:0.39 loss: 192.427 (lr:0.0001)
147040: accuracy:0.43 loss: 183.459 (lr:0.0001)
147050: accuracy:0.35 loss: 202.727 (lr:0.0001)
147060: accuracy:0.36 loss: 217.135 (lr:0.0001)
147070: accuracy:0.4 loss: 184.517 (lr:0.0001)
147080: accuracy:0.41 loss: 204.17 (lr:0.0001)
147090: accuracy:0.3 loss: 205.857 (lr:0.0001)
147100: accuracy:0.31 loss: 211.526 (lr:0.0001)
147110: accuracy:0.32 loss: 215.708 (lr:0.0001)
147120: accuracy:0.36 loss: 210.622 (lr:0.0001)
147130: accuracy:0.34 loss: 214.227 (lr:0.0001)
147140: accuracy:0.35 loss: 206.271 (lr:0.0001)
147150: accuracy:0.36 loss: 198.387 (lr:0.0001)
147160: accuracy:0.31 loss: 239.169 (lr:0.0001)
147170: accuracy:0.42 loss: 202.048 (lr:0.0001)
147180: accuracy:0.43 loss: 193.964 (lr:0.0001)
147190: accuracy:0.29 loss: 226.812 (lr:0.0001)
147200: accuracy:0.49 loss: 178.67 (lr:0.0001)
147210: accuracy:0.37 loss: 203.62 (lr:0.0001)
147220: accuracy:0.39 loss: 184.441 (lr:0.0001)
147230: accuracy:0.37 loss: 211.344 (lr:0.0001)
147240: accuracy:0.3 loss: 215.38 (lr:0.0001)
147250: accuracy:0.4 loss: 181.698 (lr:0.0001)
147260: accuracy:0.31 loss: 220.06 (lr:0.0001)
147270: accuracy:0.39 loss: 177.099 (lr:0.0001)
147280: accuracy:0.42 loss: 197.655 (lr:0.0001)
147290: accuracy:0.32 loss: 225.191 (lr:0.0001)
147300: accuracy:0.33 loss: 209.035 (lr:0.0001)
147310: accuracy:0.47 loss: 181.452 (lr:0.0001)
147320: accuracy:0.34 loss: 217.018 (lr:0.0001)
147330: accuracy:0.29 loss: 215.82 (lr:0.0001)
147340: accuracy:0.39 loss: 194.986 (lr:0.0001)
147350: accuracy:0.42 loss: 186.927 (lr:0.0001)
147360: accuracy:0.39 loss: 201.323 (lr:0.0001)
147370: accuracy:0.34 loss: 199.932 (lr:0.0001)
147380: accuracy:0.42 loss: 217.217 (lr:0.0001)
147390: accuracy:0.38 loss: 196.551 (lr:0.0001)
147400: accuracy:0.37 loss: 204.139 (lr:0.0001)
147410: accuracy:0.33 loss: 204.074 (lr:0.0001)
147420: accuracy:0.35 loss: 198.804 (lr:0.0001)
147430: accuracy:0.28 loss: 201.843 (lr:0.0001)
147440: accuracy:0.3 loss: 241.139 (lr:0.0001)
147450: accuracy:0.35 loss: 213.849 (lr:0.0001)
147460: accuracy:0.32 loss: 209.162 (lr:0.0001)
147470: accuracy:0.33 loss: 201.432 (lr:0.0001)
147480: accuracy:0.37 loss: 195.77 (lr:0.0001)
147490: accuracy:0.4 loss: 197.12 (lr:0.0001)
147500: accuracy:0.28 loss: 202.999 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
147500: ********* epoch 16 ********* test accuracy for all:0.257568 test loss: 257.37
147500: ********* epoch 16 ********* test accuracy for mode 0:0.052 test loss: 445.71
147500: ********* epoch 16 ********* test accuracy for mode 1:0.0325 test loss: 442.632
147500: ********* epoch 16 ********* test accuracy for mode 2:0.038 test loss: 260.725
147500: ********* epoch 16 ********* test accuracy for mode 24:0.233 test loss: 276.559
147500: ********* epoch 16 ********* test accuracy for mode 25:0.3155 test loss: 244.86
147500: ********* epoch 16 ********* test accuracy for mode 26:0.506 test loss: 157.829
147500: ********* epoch 16 ********* test accuracy for mode 27:0.261 test loss: 262.912
147500: ********* epoch 16 ********* test accuracy for mode 28:0.2875 test loss: 260.238
147500: ********* epoch 16 ********* test accuracy for mode 29:0.2515 test loss: 270.45
147500: ********* epoch 16 ********* test accuracy for mode 30:0.243 test loss: 251.653
147500: ********* epoch 16 ********* test accuracy for mode 31:0.1985 test loss: 252.935
147500: ********* epoch 16 ********* test accuracy for mode 32:0.2105 test loss: 236.106
147500: ********* epoch 16 ********* test accuracy for mode 33:0.29 test loss: 233.556
147500: ********* epoch 16 ********* test accuracy for mode 34:0.234 test loss: 236.926
147500: ********* epoch 16 ********* test accuracy for mode 35:0.047 test loss: 449.092
147500: ********* epoch 16 ********* test accuracy for mode 36:0.0785 test loss: 503.728
147510: accuracy:0.36 loss: 188.699 (lr:0.0001)
147520: accuracy:0.4 loss: 197.148 (lr:0.0001)
147530: accuracy:0.36 loss: 194.156 (lr:0.0001)
147540: accuracy:0.42 loss: 199.376 (lr:0.0001)
147550: accuracy:0.42 loss: 203.991 (lr:0.0001)
147560: accuracy:0.31 loss: 203.754 (lr:0.0001)
147570: accuracy:0.29 loss: 218.451 (lr:0.0001)
147580: accuracy:0.39 loss: 211.165 (lr:0.0001)
147590: accuracy:0.41 loss: 181.305 (lr:0.0001)
147600: accuracy:0.37 loss: 208.564 (lr:0.0001)
147610: accuracy:0.34 loss: 206.02 (lr:0.0001)
147620: accuracy:0.32 loss: 187.035 (lr:0.0001)
147630: accuracy:0.29 loss: 225.165 (lr:0.0001)
147640: accuracy:0.38 loss: 187.298 (lr:0.0001)
147650: accuracy:0.3 loss: 195.823 (lr:0.0001)
147660: accuracy:0.42 loss: 191.971 (lr:0.0001)
147670: accuracy:0.37 loss: 194.984 (lr:0.0001)
147680: accuracy:0.37 loss: 198.484 (lr:0.0001)
147690: accuracy:0.42 loss: 193.378 (lr:0.0001)
147700: accuracy:0.31 loss: 218.285 (lr:0.0001)
147710: accuracy:0.34 loss: 207.766 (lr:0.0001)
147720: accuracy:0.29 loss: 218.579 (lr:0.0001)
147730: accuracy:0.39 loss: 205.232 (lr:0.0001)
147740: accuracy:0.33 loss: 192.526 (lr:0.0001)
147750: accuracy:0.37 loss: 209.983 (lr:0.0001)
147760: accuracy:0.35 loss: 200.028 (lr:0.0001)
147770: accuracy:0.36 loss: 201.69 (lr:0.0001)
147780: accuracy:0.33 loss: 206.323 (lr:0.0001)
147790: accuracy:0.4 loss: 194.43 (lr:0.0001)
147800: accuracy:0.44 loss: 180.469 (lr:0.0001)
147810: accuracy:0.44 loss: 179.182 (lr:0.0001)
147820: accuracy:0.31 loss: 230.666 (lr:0.0001)
147830: accuracy:0.44 loss: 191.135 (lr:0.0001)
147840: accuracy:0.38 loss: 199.821 (lr:0.0001)
147850: accuracy:0.41 loss: 185.398 (lr:0.0001)
147860: accuracy:0.41 loss: 204.374 (lr:0.0001)
147870: accuracy:0.33 loss: 215.956 (lr:0.0001)
147880: accuracy:0.41 loss: 207.266 (lr:0.0001)
147890: accuracy:0.36 loss: 202.861 (lr:0.0001)
147900: accuracy:0.31 loss: 214.831 (lr:0.0001)
147910: accuracy:0.28 loss: 226.968 (lr:0.0001)
147920: accuracy:0.32 loss: 202.217 (lr:0.0001)
147930: accuracy:0.32 loss: 213.311 (lr:0.0001)
147940: accuracy:0.38 loss: 191.147 (lr:0.0001)
147950: accuracy:0.36 loss: 207.574 (lr:0.0001)
147960: accuracy:0.32 loss: 211.741 (lr:0.0001)
147970: accuracy:0.37 loss: 196.506 (lr:0.0001)
147980: accuracy:0.39 loss: 187.388 (lr:0.0001)
147990: accuracy:0.35 loss: 214.728 (lr:0.0001)
148000: accuracy:0.29 loss: 228.895 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
148000: ********* epoch 16 ********* test accuracy for all:0.258919 test loss: 257.433
148000: ********* epoch 16 ********* test accuracy for mode 0:0.0435 test loss: 456.218
148000: ********* epoch 16 ********* test accuracy for mode 1:0.0275 test loss: 448.727
148000: ********* epoch 16 ********* test accuracy for mode 2:0.039 test loss: 263.009
148000: ********* epoch 16 ********* test accuracy for mode 24:0.2575 test loss: 268.402
148000: ********* epoch 16 ********* test accuracy for mode 25:0.3225 test loss: 241.902
148000: ********* epoch 16 ********* test accuracy for mode 26:0.4685 test loss: 161.703
148000: ********* epoch 16 ********* test accuracy for mode 27:0.257 test loss: 265.886
148000: ********* epoch 16 ********* test accuracy for mode 28:0.2815 test loss: 265.54
148000: ********* epoch 16 ********* test accuracy for mode 29:0.2595 test loss: 271.589
148000: ********* epoch 16 ********* test accuracy for mode 30:0.2215 test loss: 255.498
148000: ********* epoch 16 ********* test accuracy for mode 31:0.1845 test loss: 253.318
148000: ********* epoch 16 ********* test accuracy for mode 32:0.2265 test loss: 234.971
148000: ********* epoch 16 ********* test accuracy for mode 33:0.3135 test loss: 233.457
148000: ********* epoch 16 ********* test accuracy for mode 34:0.188 test loss: 241.321
148000: ********* epoch 16 ********* test accuracy for mode 35:0.067 test loss: 447.896
148000: ********* epoch 16 ********* test accuracy for mode 36:0.1515 test loss: 488.141
148010: accuracy:0.34 loss: 219.973 (lr:0.0001)
148020: accuracy:0.43 loss: 197.032 (lr:0.0001)
148030: accuracy:0.41 loss: 201.622 (lr:0.0001)
148040: accuracy:0.32 loss: 199.395 (lr:0.0001)
148050: accuracy:0.31 loss: 220.786 (lr:0.0001)
148060: accuracy:0.35 loss: 187.144 (lr:0.0001)
148070: accuracy:0.31 loss: 233.015 (lr:0.0001)
148080: accuracy:0.3 loss: 213.104 (lr:0.0001)
148090: accuracy:0.33 loss: 213.318 (lr:0.0001)
148100: accuracy:0.38 loss: 193.813 (lr:0.0001)
148110: accuracy:0.28 loss: 216.552 (lr:0.0001)
148120: accuracy:0.42 loss: 202.549 (lr:0.0001)
148130: accuracy:0.36 loss: 203.226 (lr:0.0001)
148140: accuracy:0.39 loss: 186.596 (lr:0.0001)
148150: accuracy:0.37 loss: 188.543 (lr:0.0001)
148160: accuracy:0.36 loss: 205.893 (lr:0.0001)
148170: accuracy:0.41 loss: 209.286 (lr:0.0001)
148180: accuracy:0.41 loss: 192.107 (lr:0.0001)
148190: accuracy:0.37 loss: 220.142 (lr:0.0001)
148200: accuracy:0.36 loss: 208.359 (lr:0.0001)
148210: accuracy:0.44 loss: 190.342 (lr:0.0001)
148220: accuracy:0.38 loss: 212.258 (lr:0.0001)
148230: accuracy:0.35 loss: 210.298 (lr:0.0001)
148240: accuracy:0.32 loss: 206.747 (lr:0.0001)
148250: accuracy:0.37 loss: 209.695 (lr:0.0001)
148260: accuracy:0.38 loss: 208.608 (lr:0.0001)
148270: accuracy:0.36 loss: 207.851 (lr:0.0001)
148280: accuracy:0.32 loss: 201.807 (lr:0.0001)
148290: accuracy:0.35 loss: 202.471 (lr:0.0001)
148300: accuracy:0.25 loss: 226.737 (lr:0.0001)
148310: accuracy:0.38 loss: 209.312 (lr:0.0001)
148320: accuracy:0.43 loss: 196.342 (lr:0.0001)
148330: accuracy:0.38 loss: 209.919 (lr:0.0001)
148340: accuracy:0.38 loss: 207.043 (lr:0.0001)
148350: accuracy:0.32 loss: 220.577 (lr:0.0001)
148360: accuracy:0.34 loss: 214.079 (lr:0.0001)
148370: accuracy:0.33 loss: 214.436 (lr:0.0001)
148380: accuracy:0.42 loss: 199.316 (lr:0.0001)
148390: accuracy:0.39 loss: 184.321 (lr:0.0001)
148400: accuracy:0.32 loss: 212.582 (lr:0.0001)
148410: accuracy:0.37 loss: 195.575 (lr:0.0001)
148420: accuracy:0.41 loss: 201.232 (lr:0.0001)
148430: accuracy:0.32 loss: 193.175 (lr:0.0001)
148440: accuracy:0.32 loss: 193.45 (lr:0.0001)
148450: accuracy:0.3 loss: 238.423 (lr:0.0001)
148460: accuracy:0.33 loss: 211.949 (lr:0.0001)
148470: accuracy:0.49 loss: 176.708 (lr:0.0001)
148480: accuracy:0.42 loss: 196.226 (lr:0.0001)
148490: accuracy:0.42 loss: 199.989 (lr:0.0001)
148500: accuracy:0.24 loss: 218.408 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
148500: ********* epoch 16 ********* test accuracy for all:0.25927 test loss: 257.697
148500: ********* epoch 16 ********* test accuracy for mode 0:0.047 test loss: 450.605
148500: ********* epoch 16 ********* test accuracy for mode 1:0.032 test loss: 439.612
148500: ********* epoch 16 ********* test accuracy for mode 2:0.046 test loss: 263.759
148500: ********* epoch 16 ********* test accuracy for mode 24:0.231 test loss: 273.703
148500: ********* epoch 16 ********* test accuracy for mode 25:0.2885 test loss: 245.915
148500: ********* epoch 16 ********* test accuracy for mode 26:0.493 test loss: 160.718
148500: ********* epoch 16 ********* test accuracy for mode 27:0.2705 test loss: 259.955
148500: ********* epoch 16 ********* test accuracy for mode 28:0.268 test loss: 262.377
148500: ********* epoch 16 ********* test accuracy for mode 29:0.2725 test loss: 267.812
148500: ********* epoch 16 ********* test accuracy for mode 30:0.2495 test loss: 249.897
148500: ********* epoch 16 ********* test accuracy for mode 31:0.1645 test loss: 255.045
148500: ********* epoch 16 ********* test accuracy for mode 32:0.2655 test loss: 230.03
148500: ********* epoch 16 ********* test accuracy for mode 33:0.267 test loss: 233.326
148500: ********* epoch 16 ********* test accuracy for mode 34:0.2355 test loss: 238.09
148500: ********* epoch 16 ********* test accuracy for mode 35:0.075 test loss: 440.306
148500: ********* epoch 16 ********* test accuracy for mode 36:0.257 test loss: 456.691
148510: accuracy:0.45 loss: 195.051 (lr:0.0001)
148520: accuracy:0.35 loss: 197.56 (lr:0.0001)
148530: accuracy:0.33 loss: 196.241 (lr:0.0001)
148540: accuracy:0.29 loss: 215.983 (lr:0.0001)
148550: accuracy:0.36 loss: 213.273 (lr:0.0001)
148560: accuracy:0.34 loss: 189.71 (lr:0.0001)
148570: accuracy:0.37 loss: 199.402 (lr:0.0001)
148580: accuracy:0.34 loss: 203.525 (lr:0.0001)
148590: accuracy:0.42 loss: 229.311 (lr:0.0001)
148600: accuracy:0.37 loss: 197.581 (lr:0.0001)
148610: accuracy:0.29 loss: 196.633 (lr:0.0001)
148620: accuracy:0.37 loss: 208.315 (lr:0.0001)
148630: accuracy:0.38 loss: 202.71 (lr:0.0001)
148640: accuracy:0.38 loss: 209.55 (lr:0.0001)
148650: accuracy:0.3 loss: 226.62 (lr:0.0001)
148660: accuracy:0.33 loss: 210.176 (lr:0.0001)
148670: accuracy:0.36 loss: 192.361 (lr:0.0001)
148680: accuracy:0.34 loss: 208.536 (lr:0.0001)
148690: accuracy:0.38 loss: 196.942 (lr:0.0001)
148700: accuracy:0.31 loss: 222.804 (lr:0.0001)
148710: accuracy:0.32 loss: 203.47 (lr:0.0001)
148720: accuracy:0.37 loss: 202.189 (lr:0.0001)
148730: accuracy:0.31 loss: 208.133 (lr:0.0001)
148740: accuracy:0.28 loss: 226.982 (lr:0.0001)
148750: accuracy:0.33 loss: 204.463 (lr:0.0001)
148760: accuracy:0.47 loss: 180.141 (lr:0.0001)
148770: accuracy:0.38 loss: 207.048 (lr:0.0001)
148780: accuracy:0.42 loss: 185.112 (lr:0.0001)
148790: accuracy:0.27 loss: 219.403 (lr:0.0001)
148800: accuracy:0.36 loss: 205.642 (lr:0.0001)
148810: accuracy:0.44 loss: 201.82 (lr:0.0001)
148820: accuracy:0.37 loss: 222.863 (lr:0.0001)
148830: accuracy:0.26 loss: 237.807 (lr:0.0001)
148840: accuracy:0.25 loss: 231.78 (lr:0.0001)
148850: accuracy:0.4 loss: 187.719 (lr:0.0001)
148860: accuracy:0.35 loss: 198.23 (lr:0.0001)
148870: accuracy:0.34 loss: 209.59 (lr:0.0001)
148880: accuracy:0.33 loss: 189.036 (lr:0.0001)
148890: accuracy:0.39 loss: 194.275 (lr:0.0001)
148900: accuracy:0.38 loss: 184.333 (lr:0.0001)
148910: accuracy:0.36 loss: 235.892 (lr:0.0001)
148920: accuracy:0.3 loss: 210.669 (lr:0.0001)
148930: accuracy:0.35 loss: 201.021 (lr:0.0001)
148940: accuracy:0.34 loss: 200.939 (lr:0.0001)
148950: accuracy:0.37 loss: 206.751 (lr:0.0001)
148960: accuracy:0.41 loss: 179.959 (lr:0.0001)
148970: accuracy:0.45 loss: 193.225 (lr:0.0001)
148980: accuracy:0.38 loss: 194.74 (lr:0.0001)
148990: accuracy:0.37 loss: 207.949 (lr:0.0001)
149000: accuracy:0.4 loss: 201.909 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
149000: ********* epoch 16 ********* test accuracy for all:0.261689 test loss: 255.245
149000: ********* epoch 16 ********* test accuracy for mode 0:0.0455 test loss: 439.889
149000: ********* epoch 16 ********* test accuracy for mode 1:0.031 test loss: 428.624
149000: ********* epoch 16 ********* test accuracy for mode 2:0.0435 test loss: 259.902
149000: ********* epoch 16 ********* test accuracy for mode 24:0.2415 test loss: 278.59
149000: ********* epoch 16 ********* test accuracy for mode 25:0.2915 test loss: 247.89
149000: ********* epoch 16 ********* test accuracy for mode 26:0.401 test loss: 167.177
149000: ********* epoch 16 ********* test accuracy for mode 27:0.281 test loss: 254.751
149000: ********* epoch 16 ********* test accuracy for mode 28:0.291 test loss: 252.106
149000: ********* epoch 16 ********* test accuracy for mode 29:0.2715 test loss: 263.18
149000: ********* epoch 16 ********* test accuracy for mode 30:0.239 test loss: 250.185
149000: ********* epoch 16 ********* test accuracy for mode 31:0.1585 test loss: 255.752
149000: ********* epoch 16 ********* test accuracy for mode 32:0.218 test loss: 232.819
149000: ********* epoch 16 ********* test accuracy for mode 33:0.346 test loss: 225.699
149000: ********* epoch 16 ********* test accuracy for mode 34:0.207 test loss: 237.952
149000: ********* epoch 16 ********* test accuracy for mode 35:0.116 test loss: 422.924
149000: ********* epoch 16 ********* test accuracy for mode 36:0.297 test loss: 439.454
149010: accuracy:0.38 loss: 216.243 (lr:0.0001)
149020: accuracy:0.35 loss: 192.54 (lr:0.0001)
149030: accuracy:0.38 loss: 203.169 (lr:0.0001)
149040: accuracy:0.42 loss: 198.844 (lr:0.0001)
149050: accuracy:0.35 loss: 200.802 (lr:0.0001)
149060: accuracy:0.39 loss: 199.102 (lr:0.0001)
149070: accuracy:0.35 loss: 226.799 (lr:0.0001)
149080: accuracy:0.37 loss: 191.27 (lr:0.0001)
149090: accuracy:0.3 loss: 196.715 (lr:0.0001)
149100: accuracy:0.35 loss: 194.387 (lr:0.0001)
149110: accuracy:0.37 loss: 197.361 (lr:0.0001)
149120: accuracy:0.41 loss: 186.098 (lr:0.0001)
149130: accuracy:0.36 loss: 210.318 (lr:0.0001)
149140: accuracy:0.42 loss: 204.529 (lr:0.0001)
149150: accuracy:0.36 loss: 207.295 (lr:0.0001)
149160: accuracy:0.34 loss: 202.025 (lr:0.0001)
149170: accuracy:0.31 loss: 214.479 (lr:0.0001)
149180: accuracy:0.4 loss: 188.807 (lr:0.0001)
149190: accuracy:0.42 loss: 208.121 (lr:0.0001)
149200: accuracy:0.32 loss: 216.363 (lr:0.0001)
149210: accuracy:0.29 loss: 221.34 (lr:0.0001)
149220: accuracy:0.31 loss: 205.294 (lr:0.0001)
149230: accuracy:0.43 loss: 194.943 (lr:0.0001)
149240: accuracy:0.37 loss: 198.36 (lr:0.0001)
149250: accuracy:0.43 loss: 191.137 (lr:0.0001)
149260: accuracy:0.31 loss: 207.19 (lr:0.0001)
149270: accuracy:0.37 loss: 205.506 (lr:0.0001)
149280: accuracy:0.28 loss: 217.56 (lr:0.0001)
149290: accuracy:0.24 loss: 215.072 (lr:0.0001)
149300: accuracy:0.37 loss: 202.342 (lr:0.0001)
149310: accuracy:0.31 loss: 206.482 (lr:0.0001)
149320: accuracy:0.39 loss: 193.841 (lr:0.0001)
149330: accuracy:0.26 loss: 210.195 (lr:0.0001)
149340: accuracy:0.37 loss: 196.667 (lr:0.0001)
149350: accuracy:0.27 loss: 220.15 (lr:0.0001)
149360: accuracy:0.28 loss: 200.08 (lr:0.0001)
149370: accuracy:0.28 loss: 219.43 (lr:0.0001)
149380: accuracy:0.33 loss: 204.041 (lr:0.0001)
149390: accuracy:0.37 loss: 198.634 (lr:0.0001)
149400: accuracy:0.33 loss: 200.906 (lr:0.0001)
149410: accuracy:0.38 loss: 208.511 (lr:0.0001)
149420: accuracy:0.29 loss: 222.897 (lr:0.0001)
149430: accuracy:0.45 loss: 186.007 (lr:0.0001)
149440: accuracy:0.35 loss: 208.916 (lr:0.0001)
149450: accuracy:0.38 loss: 194.712 (lr:0.0001)
149460: accuracy:0.31 loss: 198.281 (lr:0.0001)
149470: accuracy:0.33 loss: 206.108 (lr:0.0001)
149480: accuracy:0.32 loss: 214.935 (lr:0.0001)
149490: accuracy:0.3 loss: 217.009 (lr:0.0001)
149500: accuracy:0.35 loss: 199.44 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
149500: ********* epoch 16 ********* test accuracy for all:0.261095 test loss: 254.945
149500: ********* epoch 16 ********* test accuracy for mode 0:0.0485 test loss: 440.159
149500: ********* epoch 16 ********* test accuracy for mode 1:0.0335 test loss: 429.177
149500: ********* epoch 16 ********* test accuracy for mode 2:0.033 test loss: 267.353
149500: ********* epoch 16 ********* test accuracy for mode 24:0.251 test loss: 273.099
149500: ********* epoch 16 ********* test accuracy for mode 25:0.3065 test loss: 247.632
149500: ********* epoch 16 ********* test accuracy for mode 26:0.4455 test loss: 166.823
149500: ********* epoch 16 ********* test accuracy for mode 27:0.2815 test loss: 260.399
149500: ********* epoch 16 ********* test accuracy for mode 28:0.2585 test loss: 265.267
149500: ********* epoch 16 ********* test accuracy for mode 29:0.265 test loss: 268.62
149500: ********* epoch 16 ********* test accuracy for mode 30:0.232 test loss: 253.332
149500: ********* epoch 16 ********* test accuracy for mode 31:0.199 test loss: 255.834
149500: ********* epoch 16 ********* test accuracy for mode 32:0.2435 test loss: 235.733
149500: ********* epoch 16 ********* test accuracy for mode 33:0.2935 test loss: 238.065
149500: ********* epoch 16 ********* test accuracy for mode 34:0.176 test loss: 248.272
149500: ********* epoch 16 ********* test accuracy for mode 35:0.0835 test loss: 436.408
149500: ********* epoch 16 ********* test accuracy for mode 36:0.1805 test loss: 469.698
149510: accuracy:0.3 loss: 206.576 (lr:0.0001)
149520: accuracy:0.4 loss: 202.158 (lr:0.0001)
149530: accuracy:0.38 loss: 183.605 (lr:0.0001)
149540: accuracy:0.45 loss: 205.471 (lr:0.0001)
149550: accuracy:0.45 loss: 177.17 (lr:0.0001)
149560: accuracy:0.36 loss: 197.172 (lr:0.0001)
149570: accuracy:0.39 loss: 201.437 (lr:0.0001)
149580: accuracy:0.34 loss: 199.117 (lr:0.0001)
149590: accuracy:0.39 loss: 190.657 (lr:0.0001)
149600: accuracy:0.32 loss: 215.18 (lr:0.0001)
149610: accuracy:0.3 loss: 209.418 (lr:0.0001)
149620: accuracy:0.4 loss: 194.476 (lr:0.0001)
149630: accuracy:0.42 loss: 188.93 (lr:0.0001)
149640: accuracy:0.23 loss: 225.334 (lr:0.0001)
149650: accuracy:0.43 loss: 177.497 (lr:0.0001)
149660: accuracy:0.3 loss: 212.071 (lr:0.0001)
149670: accuracy:0.42 loss: 189.577 (lr:0.0001)
149680: accuracy:0.37 loss: 214.058 (lr:0.0001)
149690: accuracy:0.32 loss: 207.687 (lr:0.0001)
149700: accuracy:0.37 loss: 183.046 (lr:0.0001)
149710: accuracy:0.41 loss: 204.83 (lr:0.0001)
149720: accuracy:0.4 loss: 178.957 (lr:0.0001)
149730: accuracy:0.41 loss: 203.3 (lr:0.0001)
149740: accuracy:0.4 loss: 196.812 (lr:0.0001)
149750: accuracy:0.41 loss: 200.156 (lr:0.0001)
149760: accuracy:0.35 loss: 195.359 (lr:0.0001)
149770: accuracy:0.35 loss: 191.619 (lr:0.0001)
149780: accuracy:0.35 loss: 205.987 (lr:0.0001)
149790: accuracy:0.35 loss: 214.566 (lr:0.0001)
149800: accuracy:0.51 loss: 187.112 (lr:0.0001)
149810: accuracy:0.37 loss: 199.445 (lr:0.0001)
149820: accuracy:0.31 loss: 189.161 (lr:0.0001)
149830: accuracy:0.34 loss: 190.595 (lr:0.0001)
149840: accuracy:0.44 loss: 195.426 (lr:0.0001)
149850: accuracy:0.44 loss: 185.352 (lr:0.0001)
149860: accuracy:0.37 loss: 205.391 (lr:0.0001)
149870: accuracy:0.42 loss: 194.759 (lr:0.0001)
149880: accuracy:0.4 loss: 226.989 (lr:0.0001)
149890: accuracy:0.31 loss: 244.089 (lr:0.0001)
149900: accuracy:0.34 loss: 196.852 (lr:0.0001)
149910: accuracy:0.33 loss: 218.4 (lr:0.0001)
149920: accuracy:0.41 loss: 187.768 (lr:0.0001)
149930: accuracy:0.38 loss: 209.833 (lr:0.0001)
149940: accuracy:0.41 loss: 189.848 (lr:0.0001)
149950: accuracy:0.37 loss: 199.373 (lr:0.0001)
149960: accuracy:0.35 loss: 195.216 (lr:0.0001)
149970: accuracy:0.35 loss: 210.912 (lr:0.0001)
149980: accuracy:0.4 loss: 177.565 (lr:0.0001)
149990: accuracy:0.38 loss: 190.514 (lr:0.0001)
150000: accuracy:0.31 loss: 208.719 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
150000: ********* epoch 16 ********* test accuracy for all:0.262568 test loss: 255.86
150000: ********* epoch 16 ********* test accuracy for mode 0:0.0445 test loss: 444.91
150000: ********* epoch 16 ********* test accuracy for mode 1:0.027 test loss: 441.074
150000: ********* epoch 16 ********* test accuracy for mode 2:0.0695 test loss: 259.255
150000: ********* epoch 16 ********* test accuracy for mode 24:0.291 test loss: 261.391
150000: ********* epoch 16 ********* test accuracy for mode 25:0.2935 test loss: 248.227
150000: ********* epoch 16 ********* test accuracy for mode 26:0.439 test loss: 166.16
150000: ********* epoch 16 ********* test accuracy for mode 27:0.272 test loss: 263.482
150000: ********* epoch 16 ********* test accuracy for mode 28:0.295 test loss: 259.601
150000: ********* epoch 16 ********* test accuracy for mode 29:0.282 test loss: 267.495
150000: ********* epoch 16 ********* test accuracy for mode 30:0.2075 test loss: 256.974
150000: ********* epoch 16 ********* test accuracy for mode 31:0.2215 test loss: 252.669
150000: ********* epoch 16 ********* test accuracy for mode 32:0.241 test loss: 235.531
150000: ********* epoch 16 ********* test accuracy for mode 33:0.242 test loss: 240.182
150000: ********* epoch 16 ********* test accuracy for mode 34:0.2215 test loss: 239.335
150000: ********* epoch 16 ********* test accuracy for mode 35:0.0875 test loss: 434.299
150000: ********* epoch 16 ********* test accuracy for mode 36:0.2305 test loss: 453.357
150010: accuracy:0.38 loss: 205.809 (lr:0.0001)
150020: accuracy:0.34 loss: 224.241 (lr:0.0001)
150030: accuracy:0.3 loss: 222.976 (lr:0.0001)
150040: accuracy:0.37 loss: 211.958 (lr:0.0001)
150050: accuracy:0.4 loss: 214.815 (lr:0.0001)
150060: accuracy:0.22 loss: 217.732 (lr:0.0001)
150070: accuracy:0.38 loss: 213.067 (lr:0.0001)
150080: accuracy:0.46 loss: 196.985 (lr:0.0001)
150090: accuracy:0.34 loss: 206.973 (lr:0.0001)
150100: accuracy:0.33 loss: 212.037 (lr:0.0001)
150110: accuracy:0.34 loss: 193.972 (lr:0.0001)
150120: accuracy:0.37 loss: 208.964 (lr:0.0001)
150130: accuracy:0.38 loss: 204.153 (lr:0.0001)
150140: accuracy:0.43 loss: 204.817 (lr:0.0001)
150150: accuracy:0.37 loss: 210.484 (lr:0.0001)
150160: accuracy:0.4 loss: 192.277 (lr:0.0001)
150170: accuracy:0.34 loss: 219.404 (lr:0.0001)
150180: accuracy:0.28 loss: 234.133 (lr:0.0001)
150190: accuracy:0.32 loss: 201.528 (lr:0.0001)
150200: accuracy:0.42 loss: 198.418 (lr:0.0001)
150210: accuracy:0.36 loss: 217.101 (lr:0.0001)
150220: accuracy:0.33 loss: 213.984 (lr:0.0001)
150230: accuracy:0.33 loss: 215.699 (lr:0.0001)
150240: accuracy:0.46 loss: 183.184 (lr:0.0001)
150250: accuracy:0.37 loss: 188.565 (lr:0.0001)
150260: accuracy:0.34 loss: 210.412 (lr:0.0001)
150270: accuracy:0.33 loss: 226.991 (lr:0.0001)
150280: accuracy:0.38 loss: 207.99 (lr:0.0001)
150290: accuracy:0.3 loss: 202.675 (lr:0.0001)
150300: accuracy:0.35 loss: 198.223 (lr:0.0001)
150310: accuracy:0.44 loss: 171.011 (lr:0.0001)
150320: accuracy:0.38 loss: 191.119 (lr:0.0001)
150330: accuracy:0.34 loss: 227.459 (lr:0.0001)
150340: accuracy:0.31 loss: 212.803 (lr:0.0001)
150350: accuracy:0.39 loss: 194.581 (lr:0.0001)
150360: accuracy:0.28 loss: 216.702 (lr:0.0001)
150370: accuracy:0.39 loss: 203.3 (lr:0.0001)
150380: accuracy:0.29 loss: 209.866 (lr:0.0001)
150390: accuracy:0.32 loss: 211.622 (lr:0.0001)
150400: accuracy:0.37 loss: 200.771 (lr:0.0001)
150410: accuracy:0.42 loss: 185.78 (lr:0.0001)
150420: accuracy:0.36 loss: 200.712 (lr:0.0001)
150430: accuracy:0.34 loss: 218.964 (lr:0.0001)
150440: accuracy:0.32 loss: 210.99 (lr:0.0001)
150450: accuracy:0.38 loss: 188.119 (lr:0.0001)
150460: accuracy:0.32 loss: 206.578 (lr:0.0001)
150470: accuracy:0.35 loss: 208.839 (lr:0.0001)
150480: accuracy:0.38 loss: 186.565 (lr:0.0001)
150490: accuracy:0.33 loss: 209.667 (lr:0.0001)
150500: accuracy:0.36 loss: 205.051 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
150500: ********* epoch 16 ********* test accuracy for all:0.261392 test loss: 253.247
150500: ********* epoch 16 ********* test accuracy for mode 0:0.052 test loss: 437.552
150500: ********* epoch 16 ********* test accuracy for mode 1:0.031 test loss: 429.864
150500: ********* epoch 16 ********* test accuracy for mode 2:0.043 test loss: 263.124
150500: ********* epoch 16 ********* test accuracy for mode 24:0.2365 test loss: 276.402
150500: ********* epoch 16 ********* test accuracy for mode 25:0.2555 test loss: 254.082
150500: ********* epoch 16 ********* test accuracy for mode 26:0.4525 test loss: 161.131
150500: ********* epoch 16 ********* test accuracy for mode 27:0.2965 test loss: 249.652
150500: ********* epoch 16 ********* test accuracy for mode 28:0.2745 test loss: 252.788
150500: ********* epoch 16 ********* test accuracy for mode 29:0.2775 test loss: 255.577
150500: ********* epoch 16 ********* test accuracy for mode 30:0.2395 test loss: 245.741
150500: ********* epoch 16 ********* test accuracy for mode 31:0.2495 test loss: 248.15
150500: ********* epoch 16 ********* test accuracy for mode 32:0.184 test loss: 237.254
150500: ********* epoch 16 ********* test accuracy for mode 33:0.2715 test loss: 238.758
150500: ********* epoch 16 ********* test accuracy for mode 34:0.2335 test loss: 240.476
150500: ********* epoch 16 ********* test accuracy for mode 35:0.1105 test loss: 416.581
150500: ********* epoch 16 ********* test accuracy for mode 36:0.3055 test loss: 429.959
150510: accuracy:0.46 loss: 178.589 (lr:0.0001)
150520: accuracy:0.41 loss: 195.978 (lr:0.0001)
150530: accuracy:0.34 loss: 204.87 (lr:0.0001)
150540: accuracy:0.39 loss: 196.138 (lr:0.0001)
150550: accuracy:0.33 loss: 209.103 (lr:0.0001)
150560: accuracy:0.4 loss: 187.887 (lr:0.0001)
150570: accuracy:0.3 loss: 204.269 (lr:0.0001)
150580: accuracy:0.35 loss: 201.162 (lr:0.0001)
150590: accuracy:0.34 loss: 195.587 (lr:0.0001)
150600: accuracy:0.33 loss: 209.538 (lr:0.0001)
150610: accuracy:0.32 loss: 208.989 (lr:0.0001)
150620: accuracy:0.34 loss: 222.304 (lr:0.0001)
150630: accuracy:0.4 loss: 205.403 (lr:0.0001)
150640: accuracy:0.36 loss: 216.863 (lr:0.0001)
150650: accuracy:0.34 loss: 222.617 (lr:0.0001)
150660: accuracy:0.31 loss: 210.243 (lr:0.0001)
150670: accuracy:0.3 loss: 199.18 (lr:0.0001)
150680: accuracy:0.37 loss: 203.881 (lr:0.0001)
150690: accuracy:0.28 loss: 226.075 (lr:0.0001)
150700: accuracy:0.38 loss: 219.789 (lr:0.0001)
150710: accuracy:0.37 loss: 201.938 (lr:0.0001)
150720: accuracy:0.39 loss: 192.696 (lr:0.0001)
150730: accuracy:0.26 loss: 227.878 (lr:0.0001)
150740: accuracy:0.31 loss: 193.664 (lr:0.0001)
150750: accuracy:0.33 loss: 200.899 (lr:0.0001)
150760: accuracy:0.34 loss: 206.996 (lr:0.0001)
150770: accuracy:0.39 loss: 219.504 (lr:0.0001)
150780: accuracy:0.29 loss: 205.463 (lr:0.0001)
150790: accuracy:0.34 loss: 220.797 (lr:0.0001)
150800: accuracy:0.42 loss: 184.794 (lr:0.0001)
150810: accuracy:0.28 loss: 221.101 (lr:0.0001)
150820: accuracy:0.37 loss: 207.008 (lr:0.0001)
150830: accuracy:0.28 loss: 220.449 (lr:0.0001)
150840: accuracy:0.32 loss: 226.994 (lr:0.0001)
150850: accuracy:0.43 loss: 182.268 (lr:0.0001)
150860: accuracy:0.44 loss: 187.167 (lr:0.0001)
150870: accuracy:0.45 loss: 202.901 (lr:0.0001)
150880: accuracy:0.4 loss: 191.444 (lr:0.0001)
150890: accuracy:0.32 loss: 203.935 (lr:0.0001)
150900: accuracy:0.41 loss: 204.513 (lr:0.0001)
150910: accuracy:0.35 loss: 197.625 (lr:0.0001)
150920: accuracy:0.28 loss: 227.205 (lr:0.0001)
150930: accuracy:0.34 loss: 204.422 (lr:0.0001)
150940: accuracy:0.33 loss: 198.042 (lr:0.0001)
150950: accuracy:0.3 loss: 222.942 (lr:0.0001)
150960: accuracy:0.26 loss: 210.323 (lr:0.0001)
150970: accuracy:0.34 loss: 209.596 (lr:0.0001)
150980: accuracy:0.37 loss: 195.695 (lr:0.0001)
150990: accuracy:0.25 loss: 219.562 (lr:0.0001)
151000: accuracy:0.39 loss: 206.363 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
151000: ********* epoch 16 ********* test accuracy for all:0.257203 test loss: 255.524
151000: ********* epoch 16 ********* test accuracy for mode 0:0.048 test loss: 449.5
151000: ********* epoch 16 ********* test accuracy for mode 1:0.037 test loss: 433.981
151000: ********* epoch 16 ********* test accuracy for mode 2:0.0735 test loss: 259.311
151000: ********* epoch 16 ********* test accuracy for mode 24:0.2375 test loss: 273.736
151000: ********* epoch 16 ********* test accuracy for mode 25:0.294 test loss: 242.072
151000: ********* epoch 16 ********* test accuracy for mode 26:0.4915 test loss: 156.683
151000: ********* epoch 16 ********* test accuracy for mode 27:0.2255 test loss: 268.71
151000: ********* epoch 16 ********* test accuracy for mode 28:0.2825 test loss: 258.923
151000: ********* epoch 16 ********* test accuracy for mode 29:0.262 test loss: 267.533
151000: ********* epoch 16 ********* test accuracy for mode 30:0.2465 test loss: 253.242
151000: ********* epoch 16 ********* test accuracy for mode 31:0.184 test loss: 260.733
151000: ********* epoch 16 ********* test accuracy for mode 32:0.2195 test loss: 240.291
151000: ********* epoch 16 ********* test accuracy for mode 33:0.2705 test loss: 242.133
151000: ********* epoch 16 ********* test accuracy for mode 34:0.192 test loss: 244.668
151000: ********* epoch 16 ********* test accuracy for mode 35:0.094 test loss: 444.677
151000: ********* epoch 16 ********* test accuracy for mode 36:0.098 test loss: 489.226
151010: accuracy:0.31 loss: 216.722 (lr:0.0001)
151020: accuracy:0.28 loss: 221.579 (lr:0.0001)
151030: accuracy:0.29 loss: 194.75 (lr:0.0001)
151040: accuracy:0.28 loss: 211.646 (lr:0.0001)
151050: accuracy:0.36 loss: 211.9 (lr:0.0001)
151060: accuracy:0.42 loss: 201.35 (lr:0.0001)
151070: accuracy:0.45 loss: 194.947 (lr:0.0001)
151080: accuracy:0.4 loss: 208.157 (lr:0.0001)
151090: accuracy:0.29 loss: 221.313 (lr:0.0001)
151100: accuracy:0.33 loss: 184.093 (lr:0.0001)
151110: accuracy:0.32 loss: 197.753 (lr:0.0001)
151120: accuracy:0.44 loss: 188.249 (lr:0.0001)
151130: accuracy:0.38 loss: 210.642 (lr:0.0001)
151140: accuracy:0.43 loss: 202.189 (lr:0.0001)
151150: accuracy:0.33 loss: 214.505 (lr:0.0001)
151160: accuracy:0.43 loss: 186.766 (lr:0.0001)
151170: accuracy:0.4 loss: 189.673 (lr:0.0001)
151180: accuracy:0.36 loss: 191.054 (lr:0.0001)
151190: accuracy:0.37 loss: 212.049 (lr:0.0001)
151200: accuracy:0.36 loss: 201.924 (lr:0.0001)
151210: accuracy:0.41 loss: 185.123 (lr:0.0001)
151220: accuracy:0.38 loss: 204.556 (lr:0.0001)
151230: accuracy:0.39 loss: 191.954 (lr:0.0001)
151240: accuracy:0.46 loss: 187.885 (lr:0.0001)
151250: accuracy:0.33 loss: 218.219 (lr:0.0001)
151260: accuracy:0.43 loss: 196.388 (lr:0.0001)
151270: accuracy:0.31 loss: 213.05 (lr:0.0001)
151280: accuracy:0.35 loss: 195.713 (lr:0.0001)
151290: accuracy:0.29 loss: 217.157 (lr:0.0001)
151300: accuracy:0.37 loss: 219.593 (lr:0.0001)
151310: accuracy:0.35 loss: 200.27 (lr:0.0001)
151320: accuracy:0.33 loss: 212.497 (lr:0.0001)
151330: accuracy:0.38 loss: 198.234 (lr:0.0001)
151340: accuracy:0.4 loss: 199.456 (lr:0.0001)
151350: accuracy:0.42 loss: 180.796 (lr:0.0001)
151360: accuracy:0.41 loss: 204.282 (lr:0.0001)
151370: accuracy:0.41 loss: 195.233 (lr:0.0001)
151380: accuracy:0.33 loss: 202.049 (lr:0.0001)
151390: accuracy:0.39 loss: 203.686 (lr:0.0001)
151400: accuracy:0.38 loss: 211.039 (lr:0.0001)
151410: accuracy:0.37 loss: 221.615 (lr:0.0001)
151420: accuracy:0.39 loss: 200.208 (lr:0.0001)
151430: accuracy:0.26 loss: 226.986 (lr:0.0001)
151440: accuracy:0.34 loss: 206.097 (lr:0.0001)
151450: accuracy:0.43 loss: 207.72 (lr:0.0001)
151460: accuracy:0.29 loss: 210.741 (lr:0.0001)
151470: accuracy:0.36 loss: 197.827 (lr:0.0001)
151480: accuracy:0.34 loss: 214.163 (lr:0.0001)
151490: accuracy:0.37 loss: 199.418 (lr:0.0001)
151500: accuracy:0.31 loss: 216.029 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
151500: ********* epoch 16 ********* test accuracy for all:0.260784 test loss: 256.067
151500: ********* epoch 16 ********* test accuracy for mode 0:0.046 test loss: 448.797
151500: ********* epoch 16 ********* test accuracy for mode 1:0.029 test loss: 435.871
151500: ********* epoch 16 ********* test accuracy for mode 2:0.0895 test loss: 255.562
151500: ********* epoch 16 ********* test accuracy for mode 24:0.253 test loss: 274.127
151500: ********* epoch 16 ********* test accuracy for mode 25:0.2925 test loss: 247.009
151500: ********* epoch 16 ********* test accuracy for mode 26:0.544 test loss: 151.379
151500: ********* epoch 16 ********* test accuracy for mode 27:0.246 test loss: 264.489
151500: ********* epoch 16 ********* test accuracy for mode 28:0.309 test loss: 256.56
151500: ********* epoch 16 ********* test accuracy for mode 29:0.2695 test loss: 268.473
151500: ********* epoch 16 ********* test accuracy for mode 30:0.2165 test loss: 249.86
151500: ********* epoch 16 ********* test accuracy for mode 31:0.199 test loss: 250.596
151500: ********* epoch 16 ********* test accuracy for mode 32:0.258 test loss: 226.574
151500: ********* epoch 16 ********* test accuracy for mode 33:0.2875 test loss: 230.34
151500: ********* epoch 16 ********* test accuracy for mode 34:0.2125 test loss: 236.51
151500: ********* epoch 16 ********* test accuracy for mode 35:0.0525 test loss: 450.764
151500: ********* epoch 16 ********* test accuracy for mode 36:0.093 test loss: 510.598
151510: accuracy:0.36 loss: 208.169 (lr:0.0001)
151520: accuracy:0.4 loss: 202.514 (lr:0.0001)
151530: accuracy:0.39 loss: 193.622 (lr:0.0001)
151540: accuracy:0.39 loss: 176.272 (lr:0.0001)
151550: accuracy:0.43 loss: 193.137 (lr:0.0001)
151560: accuracy:0.42 loss: 186.403 (lr:0.0001)
151570: accuracy:0.38 loss: 184.563 (lr:0.0001)
151580: accuracy:0.41 loss: 191.398 (lr:0.0001)
151590: accuracy:0.4 loss: 182.73 (lr:0.0001)
151600: accuracy:0.32 loss: 222.783 (lr:0.0001)
151610: accuracy:0.3 loss: 212.307 (lr:0.0001)
151620: accuracy:0.37 loss: 211.822 (lr:0.0001)
151630: accuracy:0.35 loss: 203.211 (lr:0.0001)
151640: accuracy:0.44 loss: 200.75 (lr:0.0001)
151650: accuracy:0.35 loss: 196.172 (lr:0.0001)
151660: accuracy:0.42 loss: 197.177 (lr:0.0001)
151670: accuracy:0.35 loss: 207.155 (lr:0.0001)
151680: accuracy:0.35 loss: 194.445 (lr:0.0001)
151690: accuracy:0.28 loss: 220.9 (lr:0.0001)
151700: accuracy:0.3 loss: 207.546 (lr:0.0001)
151710: accuracy:0.28 loss: 232.354 (lr:0.0001)
151720: accuracy:0.36 loss: 199.163 (lr:0.0001)
151730: accuracy:0.34 loss: 219.844 (lr:0.0001)
151740: accuracy:0.36 loss: 235.441 (lr:0.0001)
151750: accuracy:0.4 loss: 213.405 (lr:0.0001)
151760: accuracy:0.34 loss: 216.17 (lr:0.0001)
151770: accuracy:0.31 loss: 225.33 (lr:0.0001)
151780: accuracy:0.35 loss: 209.91 (lr:0.0001)
151790: accuracy:0.28 loss: 214.497 (lr:0.0001)
151800: accuracy:0.36 loss: 209.441 (lr:0.0001)
151810: accuracy:0.34 loss: 207.86 (lr:0.0001)
151820: accuracy:0.41 loss: 183.741 (lr:0.0001)
151830: accuracy:0.35 loss: 185.908 (lr:0.0001)
151840: accuracy:0.41 loss: 208.738 (lr:0.0001)
151850: accuracy:0.44 loss: 178.653 (lr:0.0001)
151860: accuracy:0.41 loss: 212.257 (lr:0.0001)
151870: accuracy:0.39 loss: 194.18 (lr:0.0001)
151880: accuracy:0.29 loss: 216.847 (lr:0.0001)
151890: accuracy:0.36 loss: 202.761 (lr:0.0001)
151900: accuracy:0.4 loss: 212.079 (lr:0.0001)
151910: accuracy:0.33 loss: 218.582 (lr:0.0001)
151920: accuracy:0.38 loss: 206.206 (lr:0.0001)
151930: accuracy:0.44 loss: 207.72 (lr:0.0001)
151940: accuracy:0.35 loss: 227.356 (lr:0.0001)
151950: accuracy:0.34 loss: 199.946 (lr:0.0001)
151960: accuracy:0.35 loss: 203.5 (lr:0.0001)
151970: accuracy:0.36 loss: 188.718 (lr:0.0001)
151980: accuracy:0.38 loss: 199.401 (lr:0.0001)
151990: accuracy:0.38 loss: 206.713 (lr:0.0001)
152000: accuracy:0.35 loss: 216.405 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
152000: ********* epoch 16 ********* test accuracy for all:0.25677 test loss: 257.251
152000: ********* epoch 16 ********* test accuracy for mode 0:0.0485 test loss: 442.344
152000: ********* epoch 16 ********* test accuracy for mode 1:0.039 test loss: 420.778
152000: ********* epoch 16 ********* test accuracy for mode 2:0.047 test loss: 263.237
152000: ********* epoch 16 ********* test accuracy for mode 24:0.247 test loss: 270.781
152000: ********* epoch 16 ********* test accuracy for mode 25:0.2885 test loss: 241.746
152000: ********* epoch 16 ********* test accuracy for mode 26:0.5085 test loss: 155.845
152000: ********* epoch 16 ********* test accuracy for mode 27:0.245 test loss: 266.168
152000: ********* epoch 16 ********* test accuracy for mode 28:0.2635 test loss: 260.854
152000: ********* epoch 16 ********* test accuracy for mode 29:0.2815 test loss: 265.37
152000: ********* epoch 16 ********* test accuracy for mode 30:0.229 test loss: 252.421
152000: ********* epoch 16 ********* test accuracy for mode 31:0.208 test loss: 256.993
152000: ********* epoch 16 ********* test accuracy for mode 32:0.2655 test loss: 236.711
152000: ********* epoch 16 ********* test accuracy for mode 33:0.2325 test loss: 243.067
152000: ********* epoch 16 ********* test accuracy for mode 34:0.2375 test loss: 243.097
152000: ********* epoch 16 ********* test accuracy for mode 35:0.103 test loss: 431.326
152000: ********* epoch 16 ********* test accuracy for mode 36:0.0895 test loss: 505.87
152010: accuracy:0.29 loss: 206.268 (lr:0.0001)
152020: accuracy:0.3 loss: 207.683 (lr:0.0001)
152030: accuracy:0.31 loss: 197.601 (lr:0.0001)
152040: accuracy:0.33 loss: 204.304 (lr:0.0001)
152050: accuracy:0.44 loss: 190.918 (lr:0.0001)
152060: accuracy:0.37 loss: 202.805 (lr:0.0001)
152070: accuracy:0.38 loss: 211.467 (lr:0.0001)
152080: accuracy:0.31 loss: 207.234 (lr:0.0001)
152090: accuracy:0.39 loss: 195.097 (lr:0.0001)
152100: accuracy:0.41 loss: 212.556 (lr:0.0001)
152110: accuracy:0.37 loss: 211.98 (lr:0.0001)
152120: accuracy:0.28 loss: 206.239 (lr:0.0001)
152130: accuracy:0.37 loss: 208.418 (lr:0.0001)
152140: accuracy:0.41 loss: 199.742 (lr:0.0001)
152150: accuracy:0.37 loss: 185.992 (lr:0.0001)
152160: accuracy:0.42 loss: 178.822 (lr:0.0001)
152170: accuracy:0.36 loss: 208.544 (lr:0.0001)
152180: accuracy:0.34 loss: 199.502 (lr:0.0001)
152190: accuracy:0.32 loss: 209.096 (lr:0.0001)
152200: accuracy:0.37 loss: 207.066 (lr:0.0001)
152210: accuracy:0.34 loss: 208.821 (lr:0.0001)
152220: accuracy:0.32 loss: 191.06 (lr:0.0001)
152230: accuracy:0.4 loss: 202.345 (lr:0.0001)
152240: accuracy:0.4 loss: 205.002 (lr:0.0001)
152250: accuracy:0.26 loss: 223.241 (lr:0.0001)
152260: accuracy:0.36 loss: 202.159 (lr:0.0001)
152270: accuracy:0.41 loss: 197.661 (lr:0.0001)
152280: accuracy:0.36 loss: 194.493 (lr:0.0001)
152290: accuracy:0.43 loss: 196.808 (lr:0.0001)
152300: accuracy:0.39 loss: 183.499 (lr:0.0001)
152310: accuracy:0.33 loss: 207.28 (lr:0.0001)
152320: accuracy:0.33 loss: 209.071 (lr:0.0001)
152330: accuracy:0.37 loss: 196.359 (lr:0.0001)
152340: accuracy:0.31 loss: 212.879 (lr:0.0001)
152350: accuracy:0.38 loss: 209.436 (lr:0.0001)
152360: accuracy:0.35 loss: 201.392 (lr:0.0001)
152370: accuracy:0.36 loss: 186.793 (lr:0.0001)
152380: accuracy:0.37 loss: 225.851 (lr:0.0001)
152390: accuracy:0.23 loss: 225.218 (lr:0.0001)
152400: accuracy:0.36 loss: 187.158 (lr:0.0001)
152410: accuracy:0.41 loss: 183.092 (lr:0.0001)
152420: accuracy:0.4 loss: 196.929 (lr:0.0001)
152430: accuracy:0.28 loss: 215.775 (lr:0.0001)
152440: accuracy:0.41 loss: 195.028 (lr:0.0001)
152450: accuracy:0.3 loss: 189.021 (lr:0.0001)
152460: accuracy:0.32 loss: 232.843 (lr:0.0001)
152470: accuracy:0.35 loss: 206.681 (lr:0.0001)
152480: accuracy:0.35 loss: 207.27 (lr:0.0001)
152490: accuracy:0.33 loss: 212.918 (lr:0.0001)
152500: accuracy:0.43 loss: 181.288 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
152500: ********* epoch 16 ********* test accuracy for all:0.258986 test loss: 254.999
152500: ********* epoch 16 ********* test accuracy for mode 0:0.0445 test loss: 433.57
152500: ********* epoch 16 ********* test accuracy for mode 1:0.0435 test loss: 423.047
152500: ********* epoch 16 ********* test accuracy for mode 2:0.053 test loss: 261.048
152500: ********* epoch 16 ********* test accuracy for mode 24:0.278 test loss: 265.743
152500: ********* epoch 16 ********* test accuracy for mode 25:0.282 test loss: 245.786
152500: ********* epoch 16 ********* test accuracy for mode 26:0.451 test loss: 159.566
152500: ********* epoch 16 ********* test accuracy for mode 27:0.2545 test loss: 264.56
152500: ********* epoch 16 ********* test accuracy for mode 28:0.292 test loss: 254.376
152500: ********* epoch 16 ********* test accuracy for mode 29:0.2375 test loss: 272.385
152500: ********* epoch 16 ********* test accuracy for mode 30:0.2735 test loss: 246.42
152500: ********* epoch 16 ********* test accuracy for mode 31:0.2015 test loss: 254.689
152500: ********* epoch 16 ********* test accuracy for mode 32:0.2 test loss: 239.574
152500: ********* epoch 16 ********* test accuracy for mode 33:0.2885 test loss: 236.552
152500: ********* epoch 16 ********* test accuracy for mode 34:0.2475 test loss: 238.242
152500: ********* epoch 16 ********* test accuracy for mode 35:0.105 test loss: 422.51
152500: ********* epoch 16 ********* test accuracy for mode 36:0.1035 test loss: 457.911
152510: accuracy:0.33 loss: 209.119 (lr:0.0001)
152520: accuracy:0.4 loss: 197.561 (lr:0.0001)
152530: accuracy:0.4 loss: 217.447 (lr:0.0001)
152540: accuracy:0.33 loss: 222.102 (lr:0.0001)
152550: accuracy:0.27 loss: 209.965 (lr:0.0001)
152560: accuracy:0.36 loss: 205.055 (lr:0.0001)
152570: accuracy:0.29 loss: 202.106 (lr:0.0001)
152580: accuracy:0.32 loss: 205.655 (lr:0.0001)
152590: accuracy:0.39 loss: 204.437 (lr:0.0001)
152600: accuracy:0.39 loss: 202.296 (lr:0.0001)
152610: accuracy:0.41 loss: 193.098 (lr:0.0001)
152620: accuracy:0.28 loss: 209.981 (lr:0.0001)
152630: accuracy:0.42 loss: 194.65 (lr:0.0001)
152640: accuracy:0.35 loss: 198.801 (lr:0.0001)
152650: accuracy:0.44 loss: 192.484 (lr:0.0001)
152660: accuracy:0.4 loss: 199.832 (lr:0.0001)
152670: accuracy:0.34 loss: 207.067 (lr:0.0001)
152680: accuracy:0.34 loss: 209.807 (lr:0.0001)
152690: accuracy:0.28 loss: 209.587 (lr:0.0001)
152700: accuracy:0.35 loss: 202.866 (lr:0.0001)
152710: accuracy:0.38 loss: 197.701 (lr:0.0001)
152720: accuracy:0.35 loss: 212.665 (lr:0.0001)
152730: accuracy:0.35 loss: 208.721 (lr:0.0001)
152740: accuracy:0.38 loss: 194.902 (lr:0.0001)
152750: accuracy:0.35 loss: 192.662 (lr:0.0001)
152760: accuracy:0.42 loss: 188.592 (lr:0.0001)
152770: accuracy:0.33 loss: 195.488 (lr:0.0001)
152780: accuracy:0.38 loss: 198.943 (lr:0.0001)
152790: accuracy:0.24 loss: 224.02 (lr:0.0001)
152800: accuracy:0.35 loss: 203.339 (lr:0.0001)
152810: accuracy:0.31 loss: 204.29 (lr:0.0001)
152820: accuracy:0.3 loss: 212.468 (lr:0.0001)
152830: accuracy:0.43 loss: 193.036 (lr:0.0001)
152840: accuracy:0.38 loss: 197.693 (lr:0.0001)
152850: accuracy:0.41 loss: 199.405 (lr:0.0001)
152860: accuracy:0.34 loss: 214.937 (lr:0.0001)
152870: accuracy:0.29 loss: 209.861 (lr:0.0001)
152880: accuracy:0.37 loss: 207.755 (lr:0.0001)
152890: accuracy:0.32 loss: 207.037 (lr:0.0001)
152900: accuracy:0.48 loss: 165.295 (lr:0.0001)
152910: accuracy:0.27 loss: 238.2 (lr:0.0001)
152920: accuracy:0.32 loss: 209.064 (lr:0.0001)
152930: accuracy:0.4 loss: 204.52 (lr:0.0001)
152940: accuracy:0.37 loss: 189.067 (lr:0.0001)
152950: accuracy:0.33 loss: 201.415 (lr:0.0001)
152960: accuracy:0.32 loss: 233.028 (lr:0.0001)
152970: accuracy:0.4 loss: 214.917 (lr:0.0001)
152980: accuracy:0.26 loss: 233.708 (lr:0.0001)
152990: accuracy:0.33 loss: 207.614 (lr:0.0001)
153000: accuracy:0.38 loss: 197.332 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
153000: ********* epoch 16 ********* test accuracy for all:0.257432 test loss: 256.919
153000: ********* epoch 16 ********* test accuracy for mode 0:0.0365 test loss: 452.51
153000: ********* epoch 16 ********* test accuracy for mode 1:0.031 test loss: 438.375
153000: ********* epoch 16 ********* test accuracy for mode 2:0.035 test loss: 263.416
153000: ********* epoch 16 ********* test accuracy for mode 24:0.2525 test loss: 268.189
153000: ********* epoch 16 ********* test accuracy for mode 25:0.2995 test loss: 243.438
153000: ********* epoch 16 ********* test accuracy for mode 26:0.471 test loss: 159.396
153000: ********* epoch 16 ********* test accuracy for mode 27:0.245 test loss: 267.735
153000: ********* epoch 16 ********* test accuracy for mode 28:0.323 test loss: 254.849
153000: ********* epoch 16 ********* test accuracy for mode 29:0.253 test loss: 270.908
153000: ********* epoch 16 ********* test accuracy for mode 30:0.2535 test loss: 250.025
153000: ********* epoch 16 ********* test accuracy for mode 31:0.1925 test loss: 257.586
153000: ********* epoch 16 ********* test accuracy for mode 32:0.2165 test loss: 239.219
153000: ********* epoch 16 ********* test accuracy for mode 33:0.2775 test loss: 236.595
153000: ********* epoch 16 ********* test accuracy for mode 34:0.2535 test loss: 237.302
153000: ********* epoch 16 ********* test accuracy for mode 35:0.078 test loss: 439.888
153000: ********* epoch 16 ********* test accuracy for mode 36:0.094 test loss: 467.851
153010: accuracy:0.4 loss: 192.493 (lr:0.0001)
153020: accuracy:0.32 loss: 209.148 (lr:0.0001)
153030: accuracy:0.32 loss: 208.369 (lr:0.0001)
153040: accuracy:0.32 loss: 209.571 (lr:0.0001)
153050: accuracy:0.35 loss: 189.632 (lr:0.0001)
153060: accuracy:0.32 loss: 219.419 (lr:0.0001)
153070: accuracy:0.36 loss: 208.765 (lr:0.0001)
153080: accuracy:0.31 loss: 200.17 (lr:0.0001)
153090: accuracy:0.36 loss: 194.21 (lr:0.0001)
153100: accuracy:0.33 loss: 210.244 (lr:0.0001)
153110: accuracy:0.37 loss: 192.388 (lr:0.0001)
153120: accuracy:0.28 loss: 210.031 (lr:0.0001)
153130: accuracy:0.48 loss: 176.412 (lr:0.0001)
153140: accuracy:0.42 loss: 194.016 (lr:0.0001)
153150: accuracy:0.36 loss: 193.523 (lr:0.0001)
153160: accuracy:0.38 loss: 221.776 (lr:0.0001)
153170: accuracy:0.39 loss: 219.0 (lr:0.0001)
153180: accuracy:0.34 loss: 187.656 (lr:0.0001)
153190: accuracy:0.35 loss: 212.534 (lr:0.0001)
153200: accuracy:0.35 loss: 201.72 (lr:0.0001)
153210: accuracy:0.32 loss: 200.752 (lr:0.0001)
153220: accuracy:0.4 loss: 199.991 (lr:0.0001)
153230: accuracy:0.24 loss: 240.689 (lr:0.0001)
153240: accuracy:0.33 loss: 202.798 (lr:0.0001)
153250: accuracy:0.35 loss: 220.054 (lr:0.0001)
153260: accuracy:0.34 loss: 200.452 (lr:0.0001)
153270: accuracy:0.39 loss: 187.126 (lr:0.0001)
153280: accuracy:0.4 loss: 208.783 (lr:0.0001)
153290: accuracy:0.38 loss: 195.114 (lr:0.0001)
153300: accuracy:0.38 loss: 208.836 (lr:0.0001)
153310: accuracy:0.32 loss: 210.479 (lr:0.0001)
153320: accuracy:0.33 loss: 217.411 (lr:0.0001)
153330: accuracy:0.36 loss: 201.129 (lr:0.0001)
153340: accuracy:0.37 loss: 218.123 (lr:0.0001)
153350: accuracy:0.32 loss: 213.679 (lr:0.0001)
153360: accuracy:0.43 loss: 184.432 (lr:0.0001)
153370: accuracy:0.3 loss: 207.089 (lr:0.0001)
153380: accuracy:0.31 loss: 219.089 (lr:0.0001)
153390: accuracy:0.41 loss: 190.061 (lr:0.0001)
153400: accuracy:0.33 loss: 230.459 (lr:0.0001)
153410: accuracy:0.33 loss: 203.099 (lr:0.0001)
153420: accuracy:0.3 loss: 204.486 (lr:0.0001)
153430: accuracy:0.33 loss: 197.147 (lr:0.0001)
153440: accuracy:0.36 loss: 200.116 (lr:0.0001)
153450: accuracy:0.32 loss: 205.303 (lr:0.0001)
153460: accuracy:0.39 loss: 211.381 (lr:0.0001)
153470: accuracy:0.28 loss: 219.35 (lr:0.0001)
153480: accuracy:0.36 loss: 195.468 (lr:0.0001)
153490: accuracy:0.41 loss: 196.041 (lr:0.0001)
153500: accuracy:0.33 loss: 188.333 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
153500: ********* epoch 16 ********* test accuracy for all:0.263608 test loss: 253.817
153500: ********* epoch 16 ********* test accuracy for mode 0:0.045 test loss: 441.048
153500: ********* epoch 16 ********* test accuracy for mode 1:0.0335 test loss: 429.374
153500: ********* epoch 16 ********* test accuracy for mode 2:0.053 test loss: 260.952
153500: ********* epoch 16 ********* test accuracy for mode 24:0.261 test loss: 269.301
153500: ********* epoch 16 ********* test accuracy for mode 25:0.28 test loss: 240.131
153500: ********* epoch 16 ********* test accuracy for mode 26:0.53 test loss: 152.96
153500: ********* epoch 16 ********* test accuracy for mode 27:0.28 test loss: 250.326
153500: ********* epoch 16 ********* test accuracy for mode 28:0.275 test loss: 253.01
153500: ********* epoch 16 ********* test accuracy for mode 29:0.2635 test loss: 260.326
153500: ********* epoch 16 ********* test accuracy for mode 30:0.237 test loss: 248.916
153500: ********* epoch 16 ********* test accuracy for mode 31:0.18 test loss: 259.083
153500: ********* epoch 16 ********* test accuracy for mode 32:0.186 test loss: 241.922
153500: ********* epoch 16 ********* test accuracy for mode 33:0.2845 test loss: 238.877
153500: ********* epoch 16 ********* test accuracy for mode 34:0.2275 test loss: 240.715
153500: ********* epoch 16 ********* test accuracy for mode 35:0.1125 test loss: 423.498
153500: ********* epoch 16 ********* test accuracy for mode 36:0.334 test loss: 429.045
153510: accuracy:0.3 loss: 209.654 (lr:0.0001)
153520: accuracy:0.39 loss: 186.599 (lr:0.0001)
153530: accuracy:0.46 loss: 187.971 (lr:0.0001)
153540: accuracy:0.35 loss: 215.636 (lr:0.0001)
153550: accuracy:0.36 loss: 206.923 (lr:0.0001)
153560: accuracy:0.37 loss: 200.038 (lr:0.0001)
153570: accuracy:0.36 loss: 194.834 (lr:0.0001)
153580: accuracy:0.45 loss: 181.678 (lr:0.0001)
153590: accuracy:0.31 loss: 222.765 (lr:0.0001)
153600: accuracy:0.41 loss: 194.922 (lr:0.0001)
153610: accuracy:0.3 loss: 205.802 (lr:0.0001)
153620: accuracy:0.41 loss: 207.444 (lr:0.0001)
153630: accuracy:0.31 loss: 196.795 (lr:0.0001)
153640: accuracy:0.25 loss: 224.614 (lr:0.0001)
153650: accuracy:0.37 loss: 205.381 (lr:0.0001)
153660: accuracy:0.34 loss: 191.363 (lr:0.0001)
153670: accuracy:0.36 loss: 197.921 (lr:0.0001)
153680: accuracy:0.41 loss: 192.609 (lr:0.0001)
153690: accuracy:0.46 loss: 204.095 (lr:0.0001)
153700: accuracy:0.4 loss: 190.977 (lr:0.0001)
153710: accuracy:0.31 loss: 195.91 (lr:0.0001)
153720: accuracy:0.34 loss: 212.739 (lr:0.0001)
153730: accuracy:0.42 loss: 201.75 (lr:0.0001)
153740: accuracy:0.34 loss: 214.996 (lr:0.0001)
153750: accuracy:0.38 loss: 187.139 (lr:0.0001)
153760: accuracy:0.38 loss: 211.734 (lr:0.0001)
153770: accuracy:0.29 loss: 219.991 (lr:0.0001)
153780: accuracy:0.41 loss: 200.506 (lr:0.0001)
153790: accuracy:0.41 loss: 216.64 (lr:0.0001)
153800: accuracy:0.36 loss: 207.732 (lr:0.0001)
153810: accuracy:0.37 loss: 211.991 (lr:0.0001)
153820: accuracy:0.4 loss: 179.446 (lr:0.0001)
153830: accuracy:0.32 loss: 201.177 (lr:0.0001)
153840: accuracy:0.33 loss: 208.723 (lr:0.0001)
153850: accuracy:0.35 loss: 216.064 (lr:0.0001)
153860: accuracy:0.32 loss: 211.994 (lr:0.0001)
153870: accuracy:0.39 loss: 202.308 (lr:0.0001)
153880: accuracy:0.27 loss: 215.747 (lr:0.0001)
153890: accuracy:0.33 loss: 223.689 (lr:0.0001)
153900: accuracy:0.35 loss: 209.031 (lr:0.0001)
153910: accuracy:0.33 loss: 210.165 (lr:0.0001)
153920: accuracy:0.35 loss: 218.223 (lr:0.0001)
153930: accuracy:0.45 loss: 183.707 (lr:0.0001)
153940: accuracy:0.38 loss: 194.098 (lr:0.0001)
153950: accuracy:0.37 loss: 190.8 (lr:0.0001)
153960: accuracy:0.35 loss: 190.077 (lr:0.0001)
153970: accuracy:0.28 loss: 214.029 (lr:0.0001)
153980: accuracy:0.42 loss: 184.943 (lr:0.0001)
153990: accuracy:0.29 loss: 225.019 (lr:0.0001)
154000: accuracy:0.34 loss: 207.951 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
154000: ********* epoch 16 ********* test accuracy for all:0.259014 test loss: 256.931
154000: ********* epoch 16 ********* test accuracy for mode 0:0.045 test loss: 448.131
154000: ********* epoch 16 ********* test accuracy for mode 1:0.0315 test loss: 439.59
154000: ********* epoch 16 ********* test accuracy for mode 2:0.0435 test loss: 260.46
154000: ********* epoch 16 ********* test accuracy for mode 24:0.236 test loss: 278.053
154000: ********* epoch 16 ********* test accuracy for mode 25:0.2395 test loss: 258.121
154000: ********* epoch 16 ********* test accuracy for mode 26:0.527 test loss: 156.073
154000: ********* epoch 16 ********* test accuracy for mode 27:0.256 test loss: 259.422
154000: ********* epoch 16 ********* test accuracy for mode 28:0.2945 test loss: 250.511
154000: ********* epoch 16 ********* test accuracy for mode 29:0.2995 test loss: 255.544
154000: ********* epoch 16 ********* test accuracy for mode 30:0.226 test loss: 246.456
154000: ********* epoch 16 ********* test accuracy for mode 31:0.191 test loss: 249.822
154000: ********* epoch 16 ********* test accuracy for mode 32:0.215 test loss: 233.99
154000: ********* epoch 16 ********* test accuracy for mode 33:0.2505 test loss: 234.896
154000: ********* epoch 16 ********* test accuracy for mode 34:0.269 test loss: 230.703
154000: ********* epoch 16 ********* test accuracy for mode 35:0.1045 test loss: 432.785
154000: ********* epoch 16 ********* test accuracy for mode 36:0.19 test loss: 471.051
154010: accuracy:0.34 loss: 212.85 (lr:0.0001)
154020: accuracy:0.41 loss: 206.237 (lr:0.0001)
154030: accuracy:0.35 loss: 207.117 (lr:0.0001)
154040: accuracy:0.32 loss: 212.322 (lr:0.0001)
154050: accuracy:0.39 loss: 183.663 (lr:0.0001)
154060: accuracy:0.36 loss: 199.014 (lr:0.0001)
154070: accuracy:0.33 loss: 210.299 (lr:0.0001)
154080: accuracy:0.44 loss: 196.921 (lr:0.0001)
154090: accuracy:0.29 loss: 218.002 (lr:0.0001)
154100: accuracy:0.35 loss: 201.166 (lr:0.0001)
154110: accuracy:0.35 loss: 206.005 (lr:0.0001)
154120: accuracy:0.39 loss: 211.548 (lr:0.0001)
154130: accuracy:0.38 loss: 200.513 (lr:0.0001)
154140: accuracy:0.29 loss: 213.358 (lr:0.0001)
154150: accuracy:0.35 loss: 205.678 (lr:0.0001)
154160: accuracy:0.32 loss: 212.401 (lr:0.0001)
154170: accuracy:0.28 loss: 235.05 (lr:0.0001)
154180: accuracy:0.3 loss: 193.77 (lr:0.0001)
154190: accuracy:0.31 loss: 208.884 (lr:0.0001)
154200: accuracy:0.43 loss: 198.546 (lr:0.0001)
154210: accuracy:0.4 loss: 211.747 (lr:0.0001)
154220: accuracy:0.33 loss: 197.612 (lr:0.0001)
154230: accuracy:0.34 loss: 214.24 (lr:0.0001)
154240: accuracy:0.4 loss: 198.243 (lr:0.0001)
154250: accuracy:0.39 loss: 195.998 (lr:0.0001)
154260: accuracy:0.36 loss: 219.542 (lr:0.0001)
154270: accuracy:0.39 loss: 199.637 (lr:0.0001)
154280: accuracy:0.37 loss: 207.52 (lr:0.0001)
154290: accuracy:0.31 loss: 204.738 (lr:0.0001)
154300: accuracy:0.3 loss: 231.907 (lr:0.0001)
154310: accuracy:0.46 loss: 188.399 (lr:0.0001)
154320: accuracy:0.36 loss: 191.012 (lr:0.0001)
154330: accuracy:0.41 loss: 186.731 (lr:0.0001)
154340: accuracy:0.44 loss: 186.469 (lr:0.0001)
154350: accuracy:0.4 loss: 195.98 (lr:0.0001)
154360: accuracy:0.28 loss: 218.017 (lr:0.0001)
154370: accuracy:0.35 loss: 198.035 (lr:0.0001)
154380: accuracy:0.39 loss: 196.324 (lr:0.0001)
154390: accuracy:0.28 loss: 205.532 (lr:0.0001)
154400: accuracy:0.41 loss: 192.3 (lr:0.0001)
154410: accuracy:0.34 loss: 198.77 (lr:0.0001)
154420: accuracy:0.35 loss: 188.435 (lr:0.0001)
154430: accuracy:0.29 loss: 238.071 (lr:0.0001)
154440: accuracy:0.36 loss: 206.781 (lr:0.0001)
154450: accuracy:0.4 loss: 190.444 (lr:0.0001)
154460: accuracy:0.39 loss: 202.262 (lr:0.0001)
154470: accuracy:0.42 loss: 189.331 (lr:0.0001)
154480: accuracy:0.46 loss: 193.539 (lr:0.0001)
154490: accuracy:0.38 loss: 194.215 (lr:0.0001)
154500: accuracy:0.36 loss: 190.957 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
154500: ********* epoch 16 ********* test accuracy for all:0.267473 test loss: 254.405
154500: ********* epoch 16 ********* test accuracy for mode 0:0.041 test loss: 453.283
154500: ********* epoch 16 ********* test accuracy for mode 1:0.026 test loss: 437.088
154500: ********* epoch 16 ********* test accuracy for mode 2:0.0465 test loss: 259.775
154500: ********* epoch 16 ********* test accuracy for mode 24:0.2495 test loss: 266.744
154500: ********* epoch 16 ********* test accuracy for mode 25:0.2725 test loss: 241.12
154500: ********* epoch 16 ********* test accuracy for mode 26:0.5375 test loss: 150.294
154500: ********* epoch 16 ********* test accuracy for mode 27:0.306 test loss: 244.661
154500: ********* epoch 16 ********* test accuracy for mode 28:0.281 test loss: 246.525
154500: ********* epoch 16 ********* test accuracy for mode 29:0.306 test loss: 246.878
154500: ********* epoch 16 ********* test accuracy for mode 30:0.268 test loss: 237.121
154500: ********* epoch 16 ********* test accuracy for mode 31:0.183 test loss: 245.679
154500: ********* epoch 16 ********* test accuracy for mode 32:0.214 test loss: 231.309
154500: ********* epoch 16 ********* test accuracy for mode 33:0.3095 test loss: 231.265
154500: ********* epoch 16 ********* test accuracy for mode 34:0.203 test loss: 237.719
154500: ********* epoch 16 ********* test accuracy for mode 35:0.0755 test loss: 448.239
154500: ********* epoch 16 ********* test accuracy for mode 36:0.3595 test loss: 448.425
154510: accuracy:0.34 loss: 202.42 (lr:0.0001)
154520: accuracy:0.4 loss: 199.888 (lr:0.0001)
154530: accuracy:0.37 loss: 178.259 (lr:0.0001)
154540: accuracy:0.35 loss: 198.302 (lr:0.0001)
154550: accuracy:0.32 loss: 206.653 (lr:0.0001)
154560: accuracy:0.42 loss: 208.43 (lr:0.0001)
154570: accuracy:0.31 loss: 206.77 (lr:0.0001)
154580: accuracy:0.31 loss: 206.58 (lr:0.0001)
154590: accuracy:0.32 loss: 204.266 (lr:0.0001)
154600: accuracy:0.41 loss: 186.214 (lr:0.0001)
154610: accuracy:0.42 loss: 204.767 (lr:0.0001)
154620: accuracy:0.35 loss: 211.866 (lr:0.0001)
154630: accuracy:0.33 loss: 210.827 (lr:0.0001)
154640: accuracy:0.33 loss: 205.942 (lr:0.0001)
154650: accuracy:0.31 loss: 222.064 (lr:0.0001)
154660: accuracy:0.34 loss: 201.049 (lr:0.0001)
154670: accuracy:0.35 loss: 213.003 (lr:0.0001)
154680: accuracy:0.4 loss: 204.939 (lr:0.0001)
154690: accuracy:0.44 loss: 193.279 (lr:0.0001)
154700: accuracy:0.33 loss: 212.514 (lr:0.0001)
154710: accuracy:0.33 loss: 190.263 (lr:0.0001)
154720: accuracy:0.3 loss: 208.104 (lr:0.0001)
154730: accuracy:0.38 loss: 196.36 (lr:0.0001)
154740: accuracy:0.48 loss: 180.572 (lr:0.0001)
154750: accuracy:0.43 loss: 190.378 (lr:0.0001)
154760: accuracy:0.28 loss: 213.321 (lr:0.0001)
154770: accuracy:0.34 loss: 200.095 (lr:0.0001)
154780: accuracy:0.41 loss: 207.659 (lr:0.0001)
154790: accuracy:0.38 loss: 198.209 (lr:0.0001)
154800: accuracy:0.35 loss: 211.137 (lr:0.0001)
154810: accuracy:0.39 loss: 218.503 (lr:0.0001)
154820: accuracy:0.41 loss: 208.437 (lr:0.0001)
154830: accuracy:0.35 loss: 196.202 (lr:0.0001)
154840: accuracy:0.3 loss: 222.684 (lr:0.0001)
154850: accuracy:0.25 loss: 233.605 (lr:0.0001)
154860: accuracy:0.34 loss: 207.581 (lr:0.0001)
154870: accuracy:0.29 loss: 206.416 (lr:0.0001)
154880: accuracy:0.34 loss: 210.943 (lr:0.0001)
154890: accuracy:0.33 loss: 218.977 (lr:0.0001)
154900: accuracy:0.38 loss: 187.191 (lr:0.0001)
154910: accuracy:0.35 loss: 204.048 (lr:0.0001)
154920: accuracy:0.32 loss: 218.106 (lr:0.0001)
154930: accuracy:0.37 loss: 195.17 (lr:0.0001)
154940: accuracy:0.38 loss: 193.729 (lr:0.0001)
154950: accuracy:0.35 loss: 196.261 (lr:0.0001)
154960: accuracy:0.33 loss: 213.682 (lr:0.0001)
154970: accuracy:0.41 loss: 195.829 (lr:0.0001)
154980: accuracy:0.39 loss: 188.493 (lr:0.0001)
154990: accuracy:0.48 loss: 165.16 (lr:0.0001)
155000: accuracy:0.36 loss: 208.211 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
155000: ********* epoch 16 ********* test accuracy for all:0.255243 test loss: 259.181
155000: ********* epoch 16 ********* test accuracy for mode 0:0.0445 test loss: 459.458
155000: ********* epoch 16 ********* test accuracy for mode 1:0.0245 test loss: 446.117
155000: ********* epoch 16 ********* test accuracy for mode 2:0.0465 test loss: 251.259
155000: ********* epoch 16 ********* test accuracy for mode 24:0.216 test loss: 287.42
155000: ********* epoch 16 ********* test accuracy for mode 25:0.262 test loss: 257.988
155000: ********* epoch 16 ********* test accuracy for mode 26:0.517 test loss: 159.989
155000: ********* epoch 16 ********* test accuracy for mode 27:0.244 test loss: 271.161
155000: ********* epoch 16 ********* test accuracy for mode 28:0.2795 test loss: 264.356
155000: ********* epoch 16 ********* test accuracy for mode 29:0.239 test loss: 272.495
155000: ********* epoch 16 ********* test accuracy for mode 30:0.2365 test loss: 246.37
155000: ********* epoch 16 ********* test accuracy for mode 31:0.221 test loss: 243.292
155000: ********* epoch 16 ********* test accuracy for mode 32:0.2455 test loss: 224.93
155000: ********* epoch 16 ********* test accuracy for mode 33:0.2935 test loss: 228.715
155000: ********* epoch 16 ********* test accuracy for mode 34:0.2075 test loss: 234.184
155000: ********* epoch 16 ********* test accuracy for mode 35:0.0755 test loss: 442.897
155000: ********* epoch 16 ********* test accuracy for mode 36:0.1185 test loss: 478.408
155010: accuracy:0.35 loss: 206.898 (lr:0.0001)
155020: accuracy:0.36 loss: 193.153 (lr:0.0001)
155030: accuracy:0.46 loss: 187.093 (lr:0.0001)
155040: accuracy:0.33 loss: 208.06 (lr:0.0001)
155050: accuracy:0.45 loss: 193.181 (lr:0.0001)
155060: accuracy:0.39 loss: 207.533 (lr:0.0001)
155070: accuracy:0.35 loss: 210.614 (lr:0.0001)
155080: accuracy:0.35 loss: 219.089 (lr:0.0001)
155090: accuracy:0.35 loss: 198.803 (lr:0.0001)
155100: accuracy:0.29 loss: 215.132 (lr:0.0001)
155110: accuracy:0.32 loss: 206.745 (lr:0.0001)
155120: accuracy:0.33 loss: 207.056 (lr:0.0001)
155130: accuracy:0.32 loss: 202.335 (lr:0.0001)
155140: accuracy:0.27 loss: 211.28 (lr:0.0001)
155150: accuracy:0.37 loss: 205.056 (lr:0.0001)
155160: accuracy:0.38 loss: 198.52 (lr:0.0001)
155170: accuracy:0.3 loss: 212.784 (lr:0.0001)
155180: accuracy:0.42 loss: 187.573 (lr:0.0001)
155190: accuracy:0.31 loss: 215.985 (lr:0.0001)
155200: accuracy:0.35 loss: 191.368 (lr:0.0001)
155210: accuracy:0.33 loss: 195.488 (lr:0.0001)
155220: accuracy:0.3 loss: 222.603 (lr:0.0001)
155230: accuracy:0.34 loss: 204.885 (lr:0.0001)
155240: accuracy:0.37 loss: 188.166 (lr:0.0001)
155250: accuracy:0.36 loss: 210.345 (lr:0.0001)
155260: accuracy:0.4 loss: 201.869 (lr:0.0001)
155270: accuracy:0.31 loss: 227.524 (lr:0.0001)
155280: accuracy:0.3 loss: 212.804 (lr:0.0001)
155290: accuracy:0.32 loss: 209.149 (lr:0.0001)
155300: accuracy:0.37 loss: 203.029 (lr:0.0001)
155310: accuracy:0.38 loss: 199.115 (lr:0.0001)
155320: accuracy:0.36 loss: 193.528 (lr:0.0001)
155330: accuracy:0.34 loss: 203.96 (lr:0.0001)
155340: accuracy:0.38 loss: 192.995 (lr:0.0001)
155350: accuracy:0.29 loss: 211.327 (lr:0.0001)
155360: accuracy:0.36 loss: 202.784 (lr:0.0001)
155370: accuracy:0.4 loss: 209.624 (lr:0.0001)
155380: accuracy:0.43 loss: 184.701 (lr:0.0001)
155390: accuracy:0.37 loss: 206.933 (lr:0.0001)
155400: accuracy:0.35 loss: 205.606 (lr:0.0001)
155410: accuracy:0.29 loss: 207.958 (lr:0.0001)
155420: accuracy:0.31 loss: 204.213 (lr:0.0001)
155430: accuracy:0.36 loss: 214.35 (lr:0.0001)
155440: accuracy:0.4 loss: 207.261 (lr:0.0001)
155450: accuracy:0.36 loss: 199.094 (lr:0.0001)
155460: accuracy:0.29 loss: 208.029 (lr:0.0001)
155470: accuracy:0.3 loss: 208.238 (lr:0.0001)
155480: accuracy:0.35 loss: 223.454 (lr:0.0001)
155490: accuracy:0.41 loss: 189.841 (lr:0.0001)
155500: accuracy:0.35 loss: 203.38 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
155500: ********* epoch 16 ********* test accuracy for all:0.263514 test loss: 256.435
155500: ********* epoch 16 ********* test accuracy for mode 0:0.0385 test loss: 459.807
155500: ********* epoch 16 ********* test accuracy for mode 1:0.0305 test loss: 441.831
155500: ********* epoch 16 ********* test accuracy for mode 2:0.078 test loss: 249.743
155500: ********* epoch 16 ********* test accuracy for mode 24:0.2695 test loss: 264.698
155500: ********* epoch 16 ********* test accuracy for mode 25:0.2685 test loss: 249.055
155500: ********* epoch 16 ********* test accuracy for mode 26:0.4945 test loss: 153.786
155500: ********* epoch 16 ********* test accuracy for mode 27:0.3025 test loss: 253.168
155500: ********* epoch 16 ********* test accuracy for mode 28:0.3255 test loss: 250.047
155500: ********* epoch 16 ********* test accuracy for mode 29:0.2425 test loss: 268.073
155500: ********* epoch 16 ********* test accuracy for mode 30:0.237 test loss: 248.735
155500: ********* epoch 16 ********* test accuracy for mode 31:0.1935 test loss: 251.787
155500: ********* epoch 16 ********* test accuracy for mode 32:0.2425 test loss: 234.324
155500: ********* epoch 16 ********* test accuracy for mode 33:0.249 test loss: 235.088
155500: ********* epoch 16 ********* test accuracy for mode 34:0.226 test loss: 234.554
155500: ********* epoch 16 ********* test accuracy for mode 35:0.068 test loss: 455.896
155500: ********* epoch 16 ********* test accuracy for mode 36:0.2055 test loss: 484.009
155510: accuracy:0.4 loss: 203.218 (lr:0.0001)
155520: accuracy:0.37 loss: 174.196 (lr:0.0001)
155530: accuracy:0.32 loss: 209.234 (lr:0.0001)
155540: accuracy:0.33 loss: 212.539 (lr:0.0001)
155550: accuracy:0.37 loss: 196.35 (lr:0.0001)
155560: accuracy:0.51 loss: 179.142 (lr:0.0001)
155570: accuracy:0.37 loss: 188.555 (lr:0.0001)
155580: accuracy:0.34 loss: 215.302 (lr:0.0001)
155590: accuracy:0.37 loss: 205.288 (lr:0.0001)
155600: accuracy:0.43 loss: 207.507 (lr:0.0001)
155610: accuracy:0.33 loss: 225.524 (lr:0.0001)
155620: accuracy:0.44 loss: 191.963 (lr:0.0001)
155630: accuracy:0.38 loss: 207.895 (lr:0.0001)
155640: accuracy:0.44 loss: 200.093 (lr:0.0001)
155650: accuracy:0.38 loss: 197.854 (lr:0.0001)
155660: accuracy:0.4 loss: 199.529 (lr:0.0001)
155670: accuracy:0.37 loss: 202.694 (lr:0.0001)
155680: accuracy:0.3 loss: 226.686 (lr:0.0001)
155690: accuracy:0.44 loss: 202.85 (lr:0.0001)
155700: accuracy:0.36 loss: 212.028 (lr:0.0001)
155710: accuracy:0.39 loss: 176.782 (lr:0.0001)
155720: accuracy:0.29 loss: 240.626 (lr:0.0001)
155730: accuracy:0.38 loss: 210.968 (lr:0.0001)
155740: accuracy:0.39 loss: 184.892 (lr:0.0001)
155750: accuracy:0.35 loss: 201.515 (lr:0.0001)
155760: accuracy:0.49 loss: 184.915 (lr:0.0001)
155770: accuracy:0.31 loss: 212.9 (lr:0.0001)
155780: accuracy:0.47 loss: 177.292 (lr:0.0001)
155790: accuracy:0.35 loss: 204.703 (lr:0.0001)
155800: accuracy:0.37 loss: 204.163 (lr:0.0001)
155810: accuracy:0.32 loss: 206.947 (lr:0.0001)
155820: accuracy:0.38 loss: 190.787 (lr:0.0001)
155830: accuracy:0.3 loss: 222.479 (lr:0.0001)
155840: accuracy:0.35 loss: 210.856 (lr:0.0001)
155850: accuracy:0.32 loss: 218.396 (lr:0.0001)
155860: accuracy:0.35 loss: 204.746 (lr:0.0001)
155870: accuracy:0.41 loss: 190.163 (lr:0.0001)
155880: accuracy:0.41 loss: 206.503 (lr:0.0001)
155890: accuracy:0.36 loss: 210.178 (lr:0.0001)
155900: accuracy:0.4 loss: 189.037 (lr:0.0001)
155910: accuracy:0.35 loss: 188.384 (lr:0.0001)
155920: accuracy:0.36 loss: 193.019 (lr:0.0001)
155930: accuracy:0.41 loss: 175.629 (lr:0.0001)
155940: accuracy:0.39 loss: 200.941 (lr:0.0001)
155950: accuracy:0.37 loss: 205.679 (lr:0.0001)
155960: accuracy:0.38 loss: 214.402 (lr:0.0001)
155970: accuracy:0.39 loss: 192.512 (lr:0.0001)
155980: accuracy:0.39 loss: 216.21 (lr:0.0001)
155990: accuracy:0.35 loss: 212.044 (lr:0.0001)
156000: accuracy:0.47 loss: 192.054 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
156000: ********* epoch 17 ********* test accuracy for all:0.263297 test loss: 256.336
156000: ********* epoch 17 ********* test accuracy for mode 0:0.051 test loss: 450.524
156000: ********* epoch 17 ********* test accuracy for mode 1:0.0275 test loss: 436.418
156000: ********* epoch 17 ********* test accuracy for mode 2:0.0585 test loss: 259.791
156000: ********* epoch 17 ********* test accuracy for mode 24:0.2435 test loss: 266.095
156000: ********* epoch 17 ********* test accuracy for mode 25:0.2875 test loss: 249.02
156000: ********* epoch 17 ********* test accuracy for mode 26:0.542 test loss: 153.252
156000: ********* epoch 17 ********* test accuracy for mode 27:0.251 test loss: 270.592
156000: ********* epoch 17 ********* test accuracy for mode 28:0.295 test loss: 259.104
156000: ********* epoch 17 ********* test accuracy for mode 29:0.258 test loss: 272.166
156000: ********* epoch 17 ********* test accuracy for mode 30:0.2185 test loss: 256.082
156000: ********* epoch 17 ********* test accuracy for mode 31:0.218 test loss: 252.291
156000: ********* epoch 17 ********* test accuracy for mode 32:0.2015 test loss: 239.702
156000: ********* epoch 17 ********* test accuracy for mode 33:0.2815 test loss: 235.697
156000: ********* epoch 17 ********* test accuracy for mode 34:0.207 test loss: 239.523
156000: ********* epoch 17 ********* test accuracy for mode 35:0.059 test loss: 459.031
156000: ********* epoch 17 ********* test accuracy for mode 36:0.252 test loss: 470.511
156010: accuracy:0.4 loss: 187.247 (lr:0.0001)
156020: accuracy:0.31 loss: 228.15 (lr:0.0001)
156030: accuracy:0.37 loss: 211.174 (lr:0.0001)
156040: accuracy:0.34 loss: 200.224 (lr:0.0001)
156050: accuracy:0.41 loss: 191.812 (lr:0.0001)
156060: accuracy:0.32 loss: 209.224 (lr:0.0001)
156070: accuracy:0.37 loss: 204.098 (lr:0.0001)
156080: accuracy:0.38 loss: 219.225 (lr:0.0001)
156090: accuracy:0.33 loss: 220.704 (lr:0.0001)
156100: accuracy:0.32 loss: 204.236 (lr:0.0001)
156110: accuracy:0.34 loss: 195.281 (lr:0.0001)
156120: accuracy:0.27 loss: 215.821 (lr:0.0001)
156130: accuracy:0.44 loss: 179.532 (lr:0.0001)
156140: accuracy:0.32 loss: 216.04 (lr:0.0001)
156150: accuracy:0.38 loss: 213.683 (lr:0.0001)
156160: accuracy:0.35 loss: 206.31 (lr:0.0001)
156170: accuracy:0.49 loss: 172.532 (lr:0.0001)
156180: accuracy:0.34 loss: 204.423 (lr:0.0001)
156190: accuracy:0.47 loss: 175.089 (lr:0.0001)
156200: accuracy:0.38 loss: 202.219 (lr:0.0001)
156210: accuracy:0.41 loss: 193.808 (lr:0.0001)
156220: accuracy:0.31 loss: 201.223 (lr:0.0001)
156230: accuracy:0.34 loss: 203.911 (lr:0.0001)
156240: accuracy:0.39 loss: 196.379 (lr:0.0001)
156250: accuracy:0.4 loss: 183.274 (lr:0.0001)
156260: accuracy:0.32 loss: 207.697 (lr:0.0001)
156270: accuracy:0.3 loss: 221.604 (lr:0.0001)
156280: accuracy:0.41 loss: 187.928 (lr:0.0001)
156290: accuracy:0.29 loss: 218.793 (lr:0.0001)
156300: accuracy:0.28 loss: 215.499 (lr:0.0001)
156310: accuracy:0.33 loss: 206.161 (lr:0.0001)
156320: accuracy:0.39 loss: 206.283 (lr:0.0001)
156330: accuracy:0.35 loss: 202.802 (lr:0.0001)
156340: accuracy:0.44 loss: 204.023 (lr:0.0001)
156350: accuracy:0.39 loss: 213.634 (lr:0.0001)
156360: accuracy:0.39 loss: 193.1 (lr:0.0001)
156370: accuracy:0.44 loss: 178.31 (lr:0.0001)
156380: accuracy:0.4 loss: 187.389 (lr:0.0001)
156390: accuracy:0.38 loss: 203.143 (lr:0.0001)
156400: accuracy:0.29 loss: 210.821 (lr:0.0001)
156410: accuracy:0.33 loss: 194.3 (lr:0.0001)
156420: accuracy:0.4 loss: 188.379 (lr:0.0001)
156430: accuracy:0.41 loss: 193.785 (lr:0.0001)
156440: accuracy:0.46 loss: 178.325 (lr:0.0001)
156450: accuracy:0.41 loss: 214.766 (lr:0.0001)
156460: accuracy:0.39 loss: 195.167 (lr:0.0001)
156470: accuracy:0.41 loss: 193.548 (lr:0.0001)
156480: accuracy:0.31 loss: 223.619 (lr:0.0001)
156490: accuracy:0.35 loss: 209.149 (lr:0.0001)
156500: accuracy:0.42 loss: 205.526 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
156500: ********* epoch 17 ********* test accuracy for all:0.258473 test loss: 254.607
156500: ********* epoch 17 ********* test accuracy for mode 0:0.042 test loss: 450.987
156500: ********* epoch 17 ********* test accuracy for mode 1:0.0275 test loss: 435.382
156500: ********* epoch 17 ********* test accuracy for mode 2:0.044 test loss: 261.12
156500: ********* epoch 17 ********* test accuracy for mode 24:0.2325 test loss: 270.407
156500: ********* epoch 17 ********* test accuracy for mode 25:0.2545 test loss: 246.793
156500: ********* epoch 17 ********* test accuracy for mode 26:0.567 test loss: 147.85
156500: ********* epoch 17 ********* test accuracy for mode 27:0.252 test loss: 260.916
156500: ********* epoch 17 ********* test accuracy for mode 28:0.2935 test loss: 247.297
156500: ********* epoch 17 ********* test accuracy for mode 29:0.253 test loss: 255.834
156500: ********* epoch 17 ********* test accuracy for mode 30:0.2765 test loss: 237.815
156500: ********* epoch 17 ********* test accuracy for mode 31:0.2095 test loss: 247.331
156500: ********* epoch 17 ********* test accuracy for mode 32:0.223 test loss: 232.12
156500: ********* epoch 17 ********* test accuracy for mode 33:0.258 test loss: 238.45
156500: ********* epoch 17 ********* test accuracy for mode 34:0.2275 test loss: 238.522
156500: ********* epoch 17 ********* test accuracy for mode 35:0.1155 test loss: 425.463
156500: ********* epoch 17 ********* test accuracy for mode 36:0.1335 test loss: 473.037
156510: accuracy:0.28 loss: 236.61 (lr:0.0001)
156520: accuracy:0.33 loss: 207.587 (lr:0.0001)
156530: accuracy:0.37 loss: 189.864 (lr:0.0001)
156540: accuracy:0.4 loss: 188.243 (lr:0.0001)
156550: accuracy:0.36 loss: 198.541 (lr:0.0001)
156560: accuracy:0.4 loss: 190.017 (lr:0.0001)
156570: accuracy:0.38 loss: 190.454 (lr:0.0001)
156580: accuracy:0.41 loss: 208.278 (lr:0.0001)
156590: accuracy:0.43 loss: 200.248 (lr:0.0001)
156600: accuracy:0.29 loss: 200.171 (lr:0.0001)
156610: accuracy:0.43 loss: 176.634 (lr:0.0001)
156620: accuracy:0.36 loss: 203.915 (lr:0.0001)
156630: accuracy:0.29 loss: 207.106 (lr:0.0001)
156640: accuracy:0.29 loss: 208.409 (lr:0.0001)
156650: accuracy:0.36 loss: 191.622 (lr:0.0001)
156660: accuracy:0.25 loss: 244.775 (lr:0.0001)
156670: accuracy:0.37 loss: 192.618 (lr:0.0001)
156680: accuracy:0.37 loss: 192.243 (lr:0.0001)
156690: accuracy:0.33 loss: 213.202 (lr:0.0001)
156700: accuracy:0.41 loss: 188.657 (lr:0.0001)
156710: accuracy:0.32 loss: 198.539 (lr:0.0001)
156720: accuracy:0.33 loss: 196.211 (lr:0.0001)
156730: accuracy:0.37 loss: 218.228 (lr:0.0001)
156740: accuracy:0.4 loss: 195.173 (lr:0.0001)
156750: accuracy:0.42 loss: 203.06 (lr:0.0001)
156760: accuracy:0.32 loss: 214.702 (lr:0.0001)
156770: accuracy:0.33 loss: 203.783 (lr:0.0001)
156780: accuracy:0.3 loss: 205.194 (lr:0.0001)
156790: accuracy:0.39 loss: 190.025 (lr:0.0001)
156800: accuracy:0.27 loss: 204.284 (lr:0.0001)
156810: accuracy:0.31 loss: 202.686 (lr:0.0001)
156820: accuracy:0.34 loss: 211.961 (lr:0.0001)
156830: accuracy:0.3 loss: 211.292 (lr:0.0001)
156840: accuracy:0.32 loss: 208.217 (lr:0.0001)
156850: accuracy:0.29 loss: 220.107 (lr:0.0001)
156860: accuracy:0.3 loss: 208.147 (lr:0.0001)
156870: accuracy:0.46 loss: 191.619 (lr:0.0001)
156880: accuracy:0.3 loss: 207.868 (lr:0.0001)
156890: accuracy:0.36 loss: 212.902 (lr:0.0001)
156900: accuracy:0.3 loss: 206.653 (lr:0.0001)
156910: accuracy:0.4 loss: 201.139 (lr:0.0001)
156920: accuracy:0.37 loss: 211.535 (lr:0.0001)
156930: accuracy:0.41 loss: 213.117 (lr:0.0001)
156940: accuracy:0.42 loss: 204.668 (lr:0.0001)
156950: accuracy:0.35 loss: 208.082 (lr:0.0001)
156960: accuracy:0.47 loss: 179.742 (lr:0.0001)
156970: accuracy:0.46 loss: 184.758 (lr:0.0001)
156980: accuracy:0.37 loss: 210.023 (lr:0.0001)
156990: accuracy:0.31 loss: 208.943 (lr:0.0001)
157000: accuracy:0.35 loss: 203.274 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
157000: ********* epoch 17 ********* test accuracy for all:0.263351 test loss: 253.843
157000: ********* epoch 17 ********* test accuracy for mode 0:0.0455 test loss: 447.806
157000: ********* epoch 17 ********* test accuracy for mode 1:0.031 test loss: 440.536
157000: ********* epoch 17 ********* test accuracy for mode 2:0.067 test loss: 262.499
157000: ********* epoch 17 ********* test accuracy for mode 24:0.292 test loss: 259.951
157000: ********* epoch 17 ********* test accuracy for mode 25:0.2965 test loss: 233.608
157000: ********* epoch 17 ********* test accuracy for mode 26:0.5485 test loss: 151.377
157000: ********* epoch 17 ********* test accuracy for mode 27:0.2425 test loss: 259.911
157000: ********* epoch 17 ********* test accuracy for mode 28:0.289 test loss: 249.366
157000: ********* epoch 17 ********* test accuracy for mode 29:0.3095 test loss: 253.092
157000: ********* epoch 17 ********* test accuracy for mode 30:0.197 test loss: 252.619
157000: ********* epoch 17 ********* test accuracy for mode 31:0.2115 test loss: 255.926
157000: ********* epoch 17 ********* test accuracy for mode 32:0.1915 test loss: 241.549
157000: ********* epoch 17 ********* test accuracy for mode 33:0.2735 test loss: 241.617
157000: ********* epoch 17 ********* test accuracy for mode 34:0.217 test loss: 243.823
157000: ********* epoch 17 ********* test accuracy for mode 35:0.0575 test loss: 441.432
157000: ********* epoch 17 ********* test accuracy for mode 36:0.18 test loss: 476.825
157010: accuracy:0.46 loss: 195.076 (lr:0.0001)
157020: accuracy:0.35 loss: 206.325 (lr:0.0001)
157030: accuracy:0.41 loss: 178.307 (lr:0.0001)
157040: accuracy:0.39 loss: 197.91 (lr:0.0001)
157050: accuracy:0.34 loss: 195.418 (lr:0.0001)
157060: accuracy:0.35 loss: 219.343 (lr:0.0001)
157070: accuracy:0.34 loss: 195.344 (lr:0.0001)
157080: accuracy:0.3 loss: 202.518 (lr:0.0001)
157090: accuracy:0.36 loss: 213.415 (lr:0.0001)
157100: accuracy:0.34 loss: 215.692 (lr:0.0001)
157110: accuracy:0.35 loss: 214.14 (lr:0.0001)
157120: accuracy:0.34 loss: 216.159 (lr:0.0001)
157130: accuracy:0.44 loss: 196.541 (lr:0.0001)
157140: accuracy:0.37 loss: 181.475 (lr:0.0001)
157150: accuracy:0.35 loss: 204.781 (lr:0.0001)
157160: accuracy:0.35 loss: 229.072 (lr:0.0001)
157170: accuracy:0.35 loss: 200.173 (lr:0.0001)
157180: accuracy:0.3 loss: 203.29 (lr:0.0001)
157190: accuracy:0.39 loss: 203.379 (lr:0.0001)
157200: accuracy:0.35 loss: 187.755 (lr:0.0001)
157210: accuracy:0.4 loss: 203.191 (lr:0.0001)
157220: accuracy:0.4 loss: 202.74 (lr:0.0001)
157230: accuracy:0.4 loss: 187.858 (lr:0.0001)
157240: accuracy:0.4 loss: 194.556 (lr:0.0001)
157250: accuracy:0.4 loss: 195.837 (lr:0.0001)
157260: accuracy:0.36 loss: 182.075 (lr:0.0001)
157270: accuracy:0.41 loss: 198.634 (lr:0.0001)
157280: accuracy:0.35 loss: 198.459 (lr:0.0001)
157290: accuracy:0.37 loss: 209.099 (lr:0.0001)
157300: accuracy:0.4 loss: 187.766 (lr:0.0001)
157310: accuracy:0.45 loss: 192.32 (lr:0.0001)
157320: accuracy:0.32 loss: 205.98 (lr:0.0001)
157330: accuracy:0.37 loss: 197.877 (lr:0.0001)
157340: accuracy:0.36 loss: 206.179 (lr:0.0001)
157350: accuracy:0.39 loss: 212.196 (lr:0.0001)
157360: accuracy:0.38 loss: 200.507 (lr:0.0001)
157370: accuracy:0.28 loss: 202.17 (lr:0.0001)
157380: accuracy:0.47 loss: 172.661 (lr:0.0001)
157390: accuracy:0.37 loss: 204.253 (lr:0.0001)
157400: accuracy:0.34 loss: 207.951 (lr:0.0001)
157410: accuracy:0.34 loss: 212.082 (lr:0.0001)
157420: accuracy:0.36 loss: 217.289 (lr:0.0001)
157430: accuracy:0.37 loss: 197.68 (lr:0.0001)
157440: accuracy:0.31 loss: 209.984 (lr:0.0001)
157450: accuracy:0.43 loss: 191.13 (lr:0.0001)
157460: accuracy:0.3 loss: 217.794 (lr:0.0001)
157470: accuracy:0.32 loss: 195.894 (lr:0.0001)
157480: accuracy:0.39 loss: 195.516 (lr:0.0001)
157490: accuracy:0.36 loss: 193.325 (lr:0.0001)
157500: accuracy:0.37 loss: 196.155 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
157500: ********* epoch 17 ********* test accuracy for all:0.260851 test loss: 256.08
157500: ********* epoch 17 ********* test accuracy for mode 0:0.0505 test loss: 454.084
157500: ********* epoch 17 ********* test accuracy for mode 1:0.0325 test loss: 435.834
157500: ********* epoch 17 ********* test accuracy for mode 2:0.058 test loss: 259.808
157500: ********* epoch 17 ********* test accuracy for mode 24:0.2475 test loss: 279.965
157500: ********* epoch 17 ********* test accuracy for mode 25:0.2775 test loss: 254.134
157500: ********* epoch 17 ********* test accuracy for mode 26:0.518 test loss: 157.999
157500: ********* epoch 17 ********* test accuracy for mode 27:0.245 test loss: 271.452
157500: ********* epoch 17 ********* test accuracy for mode 28:0.266 test loss: 265.881
157500: ********* epoch 17 ********* test accuracy for mode 29:0.238 test loss: 272.239
157500: ********* epoch 17 ********* test accuracy for mode 30:0.27 test loss: 248.036
157500: ********* epoch 17 ********* test accuracy for mode 31:0.1735 test loss: 254.386
157500: ********* epoch 17 ********* test accuracy for mode 32:0.2685 test loss: 227.726
157500: ********* epoch 17 ********* test accuracy for mode 33:0.2805 test loss: 232.982
157500: ********* epoch 17 ********* test accuracy for mode 34:0.234 test loss: 235.465
157500: ********* epoch 17 ********* test accuracy for mode 35:0.116 test loss: 440.807
157500: ********* epoch 17 ********* test accuracy for mode 36:0.2265 test loss: 463.9
157510: accuracy:0.35 loss: 194.061 (lr:0.0001)
157520: accuracy:0.36 loss: 190.762 (lr:0.0001)
157530: accuracy:0.39 loss: 193.992 (lr:0.0001)
157540: accuracy:0.38 loss: 187.812 (lr:0.0001)
157550: accuracy:0.37 loss: 194.689 (lr:0.0001)
157560: accuracy:0.35 loss: 209.847 (lr:0.0001)
157570: accuracy:0.34 loss: 197.782 (lr:0.0001)
157580: accuracy:0.33 loss: 192.95 (lr:0.0001)
157590: accuracy:0.37 loss: 195.62 (lr:0.0001)
157600: accuracy:0.37 loss: 194.36 (lr:0.0001)
157610: accuracy:0.32 loss: 197.321 (lr:0.0001)
157620: accuracy:0.35 loss: 203.51 (lr:0.0001)
157630: accuracy:0.35 loss: 205.393 (lr:0.0001)
157640: accuracy:0.37 loss: 207.059 (lr:0.0001)
157650: accuracy:0.41 loss: 201.434 (lr:0.0001)
157660: accuracy:0.34 loss: 191.6 (lr:0.0001)
157670: accuracy:0.44 loss: 191.571 (lr:0.0001)
157680: accuracy:0.38 loss: 208.874 (lr:0.0001)
157690: accuracy:0.4 loss: 199.652 (lr:0.0001)
157700: accuracy:0.42 loss: 194.984 (lr:0.0001)
157710: accuracy:0.37 loss: 210.61 (lr:0.0001)
157720: accuracy:0.36 loss: 209.016 (lr:0.0001)
157730: accuracy:0.33 loss: 210.913 (lr:0.0001)
157740: accuracy:0.37 loss: 186.342 (lr:0.0001)
157750: accuracy:0.32 loss: 221.745 (lr:0.0001)
157760: accuracy:0.39 loss: 208.749 (lr:0.0001)
157770: accuracy:0.4 loss: 206.555 (lr:0.0001)
157780: accuracy:0.4 loss: 197.116 (lr:0.0001)
157790: accuracy:0.38 loss: 208.859 (lr:0.0001)
157800: accuracy:0.43 loss: 177.245 (lr:0.0001)
157810: accuracy:0.3 loss: 203.788 (lr:0.0001)
157820: accuracy:0.41 loss: 201.7 (lr:0.0001)
157830: accuracy:0.37 loss: 200.193 (lr:0.0001)
157840: accuracy:0.26 loss: 225.634 (lr:0.0001)
157850: accuracy:0.33 loss: 193.376 (lr:0.0001)
157860: accuracy:0.26 loss: 185.854 (lr:0.0001)
157870: accuracy:0.4 loss: 194.086 (lr:0.0001)
157880: accuracy:0.36 loss: 223.084 (lr:0.0001)
157890: accuracy:0.4 loss: 189.765 (lr:0.0001)
157900: accuracy:0.35 loss: 188.531 (lr:0.0001)
157910: accuracy:0.39 loss: 204.422 (lr:0.0001)
157920: accuracy:0.36 loss: 193.177 (lr:0.0001)
157930: accuracy:0.33 loss: 207.063 (lr:0.0001)
157940: accuracy:0.33 loss: 222.214 (lr:0.0001)
157950: accuracy:0.36 loss: 200.906 (lr:0.0001)
157960: accuracy:0.43 loss: 205.085 (lr:0.0001)
157970: accuracy:0.38 loss: 196.333 (lr:0.0001)
157980: accuracy:0.35 loss: 209.373 (lr:0.0001)
157990: accuracy:0.27 loss: 219.394 (lr:0.0001)
158000: accuracy:0.36 loss: 187.235 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
158000: ********* epoch 17 ********* test accuracy for all:0.265459 test loss: 253.388
158000: ********* epoch 17 ********* test accuracy for mode 0:0.046 test loss: 449.58
158000: ********* epoch 17 ********* test accuracy for mode 1:0.027 test loss: 436.632
158000: ********* epoch 17 ********* test accuracy for mode 2:0.0695 test loss: 260.287
158000: ********* epoch 17 ********* test accuracy for mode 24:0.264 test loss: 264.528
158000: ********* epoch 17 ********* test accuracy for mode 25:0.282 test loss: 247.893
158000: ********* epoch 17 ********* test accuracy for mode 26:0.5005 test loss: 159.517
158000: ********* epoch 17 ********* test accuracy for mode 27:0.2525 test loss: 264.135
158000: ********* epoch 17 ********* test accuracy for mode 28:0.278 test loss: 258.596
158000: ********* epoch 17 ********* test accuracy for mode 29:0.255 test loss: 266.506
158000: ********* epoch 17 ********* test accuracy for mode 30:0.276 test loss: 251.298
158000: ********* epoch 17 ********* test accuracy for mode 31:0.1435 test loss: 262.678
158000: ********* epoch 17 ********* test accuracy for mode 32:0.2565 test loss: 238.721
158000: ********* epoch 17 ********* test accuracy for mode 33:0.231 test loss: 246.503
158000: ********* epoch 17 ********* test accuracy for mode 34:0.209 test loss: 244.116
158000: ********* epoch 17 ********* test accuracy for mode 35:0.106 test loss: 438.667
158000: ********* epoch 17 ********* test accuracy for mode 36:0.2955 test loss: 451.033
158010: accuracy:0.39 loss: 183.066 (lr:0.0001)
158020: accuracy:0.3 loss: 207.744 (lr:0.0001)
158030: accuracy:0.35 loss: 207.173 (lr:0.0001)
158040: accuracy:0.27 loss: 223.475 (lr:0.0001)
158050: accuracy:0.36 loss: 183.554 (lr:0.0001)
158060: accuracy:0.27 loss: 208.667 (lr:0.0001)
158070: accuracy:0.39 loss: 201.76 (lr:0.0001)
158080: accuracy:0.41 loss: 198.672 (lr:0.0001)
158090: accuracy:0.34 loss: 202.488 (lr:0.0001)
158100: accuracy:0.35 loss: 198.326 (lr:0.0001)
158110: accuracy:0.38 loss: 183.324 (lr:0.0001)
158120: accuracy:0.36 loss: 197.742 (lr:0.0001)
158130: accuracy:0.41 loss: 205.562 (lr:0.0001)
158140: accuracy:0.42 loss: 192.083 (lr:0.0001)
158150: accuracy:0.35 loss: 180.841 (lr:0.0001)
158160: accuracy:0.32 loss: 221.454 (lr:0.0001)
158170: accuracy:0.4 loss: 202.345 (lr:0.0001)
158180: accuracy:0.36 loss: 192.657 (lr:0.0001)
158190: accuracy:0.38 loss: 199.115 (lr:0.0001)
158200: accuracy:0.33 loss: 209.164 (lr:0.0001)
158210: accuracy:0.34 loss: 222.344 (lr:0.0001)
158220: accuracy:0.36 loss: 210.448 (lr:0.0001)
158230: accuracy:0.38 loss: 202.97 (lr:0.0001)
158240: accuracy:0.41 loss: 195.394 (lr:0.0001)
158250: accuracy:0.36 loss: 196.375 (lr:0.0001)
158260: accuracy:0.35 loss: 195.288 (lr:0.0001)
158270: accuracy:0.31 loss: 217.099 (lr:0.0001)
158280: accuracy:0.31 loss: 211.955 (lr:0.0001)
158290: accuracy:0.32 loss: 218.984 (lr:0.0001)
158300: accuracy:0.44 loss: 180.352 (lr:0.0001)
158310: accuracy:0.36 loss: 209.744 (lr:0.0001)
158320: accuracy:0.33 loss: 206.885 (lr:0.0001)
158330: accuracy:0.33 loss: 214.202 (lr:0.0001)
158340: accuracy:0.37 loss: 201.494 (lr:0.0001)
158350: accuracy:0.4 loss: 200.491 (lr:0.0001)
158360: accuracy:0.24 loss: 225.972 (lr:0.0001)
158370: accuracy:0.31 loss: 217.656 (lr:0.0001)
158380: accuracy:0.32 loss: 218.172 (lr:0.0001)
158390: accuracy:0.4 loss: 207.513 (lr:0.0001)
158400: accuracy:0.28 loss: 211.13 (lr:0.0001)
158410: accuracy:0.33 loss: 197.447 (lr:0.0001)
158420: accuracy:0.36 loss: 221.61 (lr:0.0001)
158430: accuracy:0.39 loss: 207.625 (lr:0.0001)
158440: accuracy:0.4 loss: 207.378 (lr:0.0001)
158450: accuracy:0.35 loss: 201.271 (lr:0.0001)
158460: accuracy:0.4 loss: 210.609 (lr:0.0001)
158470: accuracy:0.38 loss: 202.221 (lr:0.0001)
158480: accuracy:0.36 loss: 206.122 (lr:0.0001)
158490: accuracy:0.34 loss: 210.398 (lr:0.0001)
158500: accuracy:0.36 loss: 193.434 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
158500: ********* epoch 17 ********* test accuracy for all:0.263824 test loss: 255.019
158500: ********* epoch 17 ********* test accuracy for mode 0:0.043 test loss: 452.387
158500: ********* epoch 17 ********* test accuracy for mode 1:0.034 test loss: 439.988
158500: ********* epoch 17 ********* test accuracy for mode 2:0.0435 test loss: 263.416
158500: ********* epoch 17 ********* test accuracy for mode 24:0.2405 test loss: 269.184
158500: ********* epoch 17 ********* test accuracy for mode 25:0.2935 test loss: 241.077
158500: ********* epoch 17 ********* test accuracy for mode 26:0.536 test loss: 155.369
158500: ********* epoch 17 ********* test accuracy for mode 27:0.234 test loss: 260.443
158500: ********* epoch 17 ********* test accuracy for mode 28:0.308 test loss: 244.603
158500: ********* epoch 17 ********* test accuracy for mode 29:0.2825 test loss: 250.004
158500: ********* epoch 17 ********* test accuracy for mode 30:0.2245 test loss: 240.238
158500: ********* epoch 17 ********* test accuracy for mode 31:0.226 test loss: 237.948
158500: ********* epoch 17 ********* test accuracy for mode 32:0.2955 test loss: 220.501
158500: ********* epoch 17 ********* test accuracy for mode 33:0.249 test loss: 233.737
158500: ********* epoch 17 ********* test accuracy for mode 34:0.2155 test loss: 237.406
158500: ********* epoch 17 ********* test accuracy for mode 35:0.063 test loss: 465.675
158500: ********* epoch 17 ********* test accuracy for mode 36:0.2335 test loss: 482.864
158510: accuracy:0.39 loss: 183.139 (lr:0.0001)
158520: accuracy:0.41 loss: 189.006 (lr:0.0001)
158530: accuracy:0.4 loss: 203.057 (lr:0.0001)
158540: accuracy:0.3 loss: 220.283 (lr:0.0001)
158550: accuracy:0.34 loss: 218.82 (lr:0.0001)
158560: accuracy:0.38 loss: 201.116 (lr:0.0001)
158570: accuracy:0.37 loss: 195.473 (lr:0.0001)
158580: accuracy:0.28 loss: 225.908 (lr:0.0001)
158590: accuracy:0.37 loss: 195.9 (lr:0.0001)
158600: accuracy:0.37 loss: 200.207 (lr:0.0001)
158610: accuracy:0.38 loss: 205.745 (lr:0.0001)
158620: accuracy:0.4 loss: 196.594 (lr:0.0001)
158630: accuracy:0.37 loss: 194.951 (lr:0.0001)
158640: accuracy:0.33 loss: 220.073 (lr:0.0001)
158650: accuracy:0.4 loss: 194.754 (lr:0.0001)
158660: accuracy:0.3 loss: 221.161 (lr:0.0001)
158670: accuracy:0.4 loss: 193.351 (lr:0.0001)
158680: accuracy:0.42 loss: 211.29 (lr:0.0001)
158690: accuracy:0.38 loss: 209.202 (lr:0.0001)
158700: accuracy:0.39 loss: 201.445 (lr:0.0001)
158710: accuracy:0.38 loss: 203.256 (lr:0.0001)
158720: accuracy:0.32 loss: 204.241 (lr:0.0001)
158730: accuracy:0.26 loss: 203.673 (lr:0.0001)
158740: accuracy:0.29 loss: 222.904 (lr:0.0001)
158750: accuracy:0.35 loss: 202.975 (lr:0.0001)
158760: accuracy:0.44 loss: 182.46 (lr:0.0001)
158770: accuracy:0.44 loss: 189.567 (lr:0.0001)
158780: accuracy:0.37 loss: 181.071 (lr:0.0001)
158790: accuracy:0.36 loss: 195.215 (lr:0.0001)
158800: accuracy:0.38 loss: 200.022 (lr:0.0001)
158810: accuracy:0.36 loss: 191.738 (lr:0.0001)
158820: accuracy:0.39 loss: 202.981 (lr:0.0001)
158830: accuracy:0.37 loss: 208.496 (lr:0.0001)
158840: accuracy:0.35 loss: 198.707 (lr:0.0001)
158850: accuracy:0.37 loss: 208.626 (lr:0.0001)
158860: accuracy:0.31 loss: 221.972 (lr:0.0001)
158870: accuracy:0.37 loss: 214.825 (lr:0.0001)
158880: accuracy:0.46 loss: 184.207 (lr:0.0001)
158890: accuracy:0.4 loss: 204.23 (lr:0.0001)
158900: accuracy:0.29 loss: 200.39 (lr:0.0001)
158910: accuracy:0.36 loss: 191.328 (lr:0.0001)
158920: accuracy:0.33 loss: 226.883 (lr:0.0001)
158930: accuracy:0.33 loss: 212.704 (lr:0.0001)
158940: accuracy:0.35 loss: 197.516 (lr:0.0001)
158950: accuracy:0.41 loss: 191.721 (lr:0.0001)
158960: accuracy:0.31 loss: 212.241 (lr:0.0001)
158970: accuracy:0.31 loss: 196.012 (lr:0.0001)
158980: accuracy:0.38 loss: 187.864 (lr:0.0001)
158990: accuracy:0.37 loss: 208.67 (lr:0.0001)
159000: accuracy:0.29 loss: 225.193 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
159000: ********* epoch 17 ********* test accuracy for all:0.254649 test loss: 260.517
159000: ********* epoch 17 ********* test accuracy for mode 0:0.041 test loss: 458.666
159000: ********* epoch 17 ********* test accuracy for mode 1:0.0365 test loss: 442.568
159000: ********* epoch 17 ********* test accuracy for mode 2:0.055 test loss: 257.511
159000: ********* epoch 17 ********* test accuracy for mode 24:0.2355 test loss: 275.874
159000: ********* epoch 17 ********* test accuracy for mode 25:0.3205 test loss: 242.605
159000: ********* epoch 17 ********* test accuracy for mode 26:0.4785 test loss: 163.82
159000: ********* epoch 17 ********* test accuracy for mode 27:0.2285 test loss: 272.028
159000: ********* epoch 17 ********* test accuracy for mode 28:0.28 test loss: 263.074
159000: ********* epoch 17 ********* test accuracy for mode 29:0.248 test loss: 275.271
159000: ********* epoch 17 ********* test accuracy for mode 30:0.208 test loss: 258.838
159000: ********* epoch 17 ********* test accuracy for mode 31:0.229 test loss: 252.701
159000: ********* epoch 17 ********* test accuracy for mode 32:0.216 test loss: 235.194
159000: ********* epoch 17 ********* test accuracy for mode 33:0.275 test loss: 234.461
159000: ********* epoch 17 ********* test accuracy for mode 34:0.2265 test loss: 233.915
159000: ********* epoch 17 ********* test accuracy for mode 35:0.0885 test loss: 445.384
159000: ********* epoch 17 ********* test accuracy for mode 36:0.0685 test loss: 527.066
159010: accuracy:0.46 loss: 198.24 (lr:0.0001)
159020: accuracy:0.4 loss: 206.168 (lr:0.0001)
159030: accuracy:0.33 loss: 203.148 (lr:0.0001)
159040: accuracy:0.35 loss: 196.9 (lr:0.0001)
159050: accuracy:0.42 loss: 200.639 (lr:0.0001)
159060: accuracy:0.36 loss: 205.466 (lr:0.0001)
159070: accuracy:0.43 loss: 206.472 (lr:0.0001)
159080: accuracy:0.39 loss: 191.096 (lr:0.0001)
159090: accuracy:0.42 loss: 193.433 (lr:0.0001)
159100: accuracy:0.42 loss: 194.236 (lr:0.0001)
159110: accuracy:0.34 loss: 215.148 (lr:0.0001)
159120: accuracy:0.35 loss: 186.753 (lr:0.0001)
159130: accuracy:0.32 loss: 191.621 (lr:0.0001)
159140: accuracy:0.38 loss: 210.86 (lr:0.0001)
159150: accuracy:0.37 loss: 196.53 (lr:0.0001)
159160: accuracy:0.37 loss: 188.564 (lr:0.0001)
159170: accuracy:0.39 loss: 203.687 (lr:0.0001)
159180: accuracy:0.34 loss: 196.885 (lr:0.0001)
159190: accuracy:0.35 loss: 201.072 (lr:0.0001)
159200: accuracy:0.28 loss: 230.87 (lr:0.0001)
159210: accuracy:0.33 loss: 204.885 (lr:0.0001)
159220: accuracy:0.44 loss: 202.824 (lr:0.0001)
159230: accuracy:0.44 loss: 197.377 (lr:0.0001)
159240: accuracy:0.27 loss: 206.288 (lr:0.0001)
159250: accuracy:0.38 loss: 205.317 (lr:0.0001)
159260: accuracy:0.33 loss: 225.151 (lr:0.0001)
159270: accuracy:0.29 loss: 218.801 (lr:0.0001)
159280: accuracy:0.25 loss: 226.876 (lr:0.0001)
159290: accuracy:0.38 loss: 191.33 (lr:0.0001)
159300: accuracy:0.44 loss: 181.064 (lr:0.0001)
159310: accuracy:0.37 loss: 203.125 (lr:0.0001)
159320: accuracy:0.42 loss: 179.712 (lr:0.0001)
159330: accuracy:0.35 loss: 222.162 (lr:0.0001)
159340: accuracy:0.38 loss: 208.951 (lr:0.0001)
159350: accuracy:0.26 loss: 223.172 (lr:0.0001)
159360: accuracy:0.31 loss: 199.767 (lr:0.0001)
159370: accuracy:0.36 loss: 193.198 (lr:0.0001)
159380: accuracy:0.33 loss: 209.208 (lr:0.0001)
159390: accuracy:0.28 loss: 221.489 (lr:0.0001)
159400: accuracy:0.41 loss: 195.403 (lr:0.0001)
159410: accuracy:0.35 loss: 207.728 (lr:0.0001)
159420: accuracy:0.36 loss: 191.183 (lr:0.0001)
159430: accuracy:0.34 loss: 198.289 (lr:0.0001)
159440: accuracy:0.27 loss: 210.535 (lr:0.0001)
159450: accuracy:0.36 loss: 219.506 (lr:0.0001)
159460: accuracy:0.37 loss: 193.55 (lr:0.0001)
159470: accuracy:0.38 loss: 210.121 (lr:0.0001)
159480: accuracy:0.37 loss: 203.708 (lr:0.0001)
159490: accuracy:0.45 loss: 173.659 (lr:0.0001)
159500: accuracy:0.34 loss: 215.312 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
159500: ********* epoch 17 ********* test accuracy for all:0.260608 test loss: 255.924
159500: ********* epoch 17 ********* test accuracy for mode 0:0.0405 test loss: 462.865
159500: ********* epoch 17 ********* test accuracy for mode 1:0.0325 test loss: 447.281
159500: ********* epoch 17 ********* test accuracy for mode 2:0.074 test loss: 255.831
159500: ********* epoch 17 ********* test accuracy for mode 24:0.2495 test loss: 269.953
159500: ********* epoch 17 ********* test accuracy for mode 25:0.3105 test loss: 245.432
159500: ********* epoch 17 ********* test accuracy for mode 26:0.4645 test loss: 163.416
159500: ********* epoch 17 ********* test accuracy for mode 27:0.254 test loss: 266.689
159500: ********* epoch 17 ********* test accuracy for mode 28:0.2665 test loss: 265.215
159500: ********* epoch 17 ********* test accuracy for mode 29:0.228 test loss: 277.472
159500: ********* epoch 17 ********* test accuracy for mode 30:0.253 test loss: 253.366
159500: ********* epoch 17 ********* test accuracy for mode 31:0.1985 test loss: 254.179
159500: ********* epoch 17 ********* test accuracy for mode 32:0.2235 test loss: 231.293
159500: ********* epoch 17 ********* test accuracy for mode 33:0.31 test loss: 228.854
159500: ********* epoch 17 ********* test accuracy for mode 34:0.192 test loss: 236.252
159500: ********* epoch 17 ********* test accuracy for mode 35:0.103 test loss: 434.343
159500: ********* epoch 17 ********* test accuracy for mode 36:0.1975 test loss: 462.966
159510: accuracy:0.33 loss: 196.782 (lr:0.0001)
159520: accuracy:0.32 loss: 214.539 (lr:0.0001)
159530: accuracy:0.38 loss: 191.36 (lr:0.0001)
159540: accuracy:0.34 loss: 182.192 (lr:0.0001)
159550: accuracy:0.33 loss: 212.456 (lr:0.0001)
159560: accuracy:0.38 loss: 190.481 (lr:0.0001)
159570: accuracy:0.46 loss: 174.787 (lr:0.0001)
159580: accuracy:0.25 loss: 237.677 (lr:0.0001)
159590: accuracy:0.36 loss: 202.67 (lr:0.0001)
159600: accuracy:0.42 loss: 191.032 (lr:0.0001)
159610: accuracy:0.39 loss: 193.18 (lr:0.0001)
159620: accuracy:0.3 loss: 223.155 (lr:0.0001)
159630: accuracy:0.36 loss: 193.995 (lr:0.0001)
159640: accuracy:0.43 loss: 190.71 (lr:0.0001)
159650: accuracy:0.35 loss: 193.528 (lr:0.0001)
159660: accuracy:0.41 loss: 181.052 (lr:0.0001)
159670: accuracy:0.33 loss: 207.212 (lr:0.0001)
159680: accuracy:0.35 loss: 204.187 (lr:0.0001)
159690: accuracy:0.41 loss: 188.682 (lr:0.0001)
159700: accuracy:0.29 loss: 206.302 (lr:0.0001)
159710: accuracy:0.32 loss: 210.842 (lr:0.0001)
159720: accuracy:0.44 loss: 195.694 (lr:0.0001)
159730: accuracy:0.35 loss: 219.09 (lr:0.0001)
159740: accuracy:0.42 loss: 173.61 (lr:0.0001)
159750: accuracy:0.43 loss: 180.437 (lr:0.0001)
159760: accuracy:0.31 loss: 205.235 (lr:0.0001)
159770: accuracy:0.37 loss: 204.395 (lr:0.0001)
159780: accuracy:0.34 loss: 192.795 (lr:0.0001)
159790: accuracy:0.37 loss: 198.111 (lr:0.0001)
159800: accuracy:0.37 loss: 193.015 (lr:0.0001)
159810: accuracy:0.31 loss: 214.063 (lr:0.0001)
159820: accuracy:0.45 loss: 213.263 (lr:0.0001)
159830: accuracy:0.32 loss: 197.648 (lr:0.0001)
159840: accuracy:0.36 loss: 195.935 (lr:0.0001)
159850: accuracy:0.38 loss: 189.379 (lr:0.0001)
159860: accuracy:0.34 loss: 204.775 (lr:0.0001)
159870: accuracy:0.35 loss: 178.783 (lr:0.0001)
159880: accuracy:0.37 loss: 193.626 (lr:0.0001)
159890: accuracy:0.4 loss: 176.244 (lr:0.0001)
159900: accuracy:0.28 loss: 204.527 (lr:0.0001)
159910: accuracy:0.33 loss: 182.473 (lr:0.0001)
159920: accuracy:0.35 loss: 190.392 (lr:0.0001)
159930: accuracy:0.28 loss: 216.648 (lr:0.0001)
159940: accuracy:0.39 loss: 194.517 (lr:0.0001)
159950: accuracy:0.34 loss: 189.169 (lr:0.0001)
159960: accuracy:0.35 loss: 195.585 (lr:0.0001)
159970: accuracy:0.31 loss: 210.35 (lr:0.0001)
159980: accuracy:0.48 loss: 187.029 (lr:0.0001)
159990: accuracy:0.41 loss: 193.746 (lr:0.0001)
160000: accuracy:0.29 loss: 216.521 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
160000: ********* epoch 17 ********* test accuracy for all:0.255649 test loss: 258.036
160000: ********* epoch 17 ********* test accuracy for mode 0:0.042 test loss: 456.676
160000: ********* epoch 17 ********* test accuracy for mode 1:0.029 test loss: 439.544
160000: ********* epoch 17 ********* test accuracy for mode 2:0.0575 test loss: 256.761
160000: ********* epoch 17 ********* test accuracy for mode 24:0.2425 test loss: 276.007
160000: ********* epoch 17 ********* test accuracy for mode 25:0.3385 test loss: 243.9
160000: ********* epoch 17 ********* test accuracy for mode 26:0.423 test loss: 166.262
160000: ********* epoch 17 ********* test accuracy for mode 27:0.2575 test loss: 271.105
160000: ********* epoch 17 ********* test accuracy for mode 28:0.256 test loss: 271.837
160000: ********* epoch 17 ********* test accuracy for mode 29:0.256 test loss: 276.871
160000: ********* epoch 17 ********* test accuracy for mode 30:0.2485 test loss: 259.51
160000: ********* epoch 17 ********* test accuracy for mode 31:0.2075 test loss: 260.848
160000: ********* epoch 17 ********* test accuracy for mode 32:0.197 test loss: 242.934
160000: ********* epoch 17 ********* test accuracy for mode 33:0.2605 test loss: 240.256
160000: ********* epoch 17 ********* test accuracy for mode 34:0.2225 test loss: 239.188
160000: ********* epoch 17 ********* test accuracy for mode 35:0.081 test loss: 449.644
160000: ********* epoch 17 ********* test accuracy for mode 36:0.083 test loss: 498.203
160010: accuracy:0.34 loss: 203.955 (lr:0.0001)
160020: accuracy:0.39 loss: 180.457 (lr:0.0001)
160030: accuracy:0.37 loss: 201.715 (lr:0.0001)
160040: accuracy:0.42 loss: 184.03 (lr:0.0001)
160050: accuracy:0.4 loss: 220.273 (lr:0.0001)
160060: accuracy:0.42 loss: 194.564 (lr:0.0001)
160070: accuracy:0.37 loss: 207.581 (lr:0.0001)
160080: accuracy:0.33 loss: 214.604 (lr:0.0001)
160090: accuracy:0.38 loss: 195.014 (lr:0.0001)
160100: accuracy:0.36 loss: 197.326 (lr:0.0001)
160110: accuracy:0.31 loss: 213.384 (lr:0.0001)
160120: accuracy:0.34 loss: 218.193 (lr:0.0001)
160130: accuracy:0.42 loss: 189.774 (lr:0.0001)
160140: accuracy:0.31 loss: 208.867 (lr:0.0001)
160150: accuracy:0.31 loss: 221.457 (lr:0.0001)
160160: accuracy:0.38 loss: 181.477 (lr:0.0001)
160170: accuracy:0.42 loss: 204.901 (lr:0.0001)
160180: accuracy:0.32 loss: 202.525 (lr:0.0001)
160190: accuracy:0.45 loss: 164.051 (lr:0.0001)
160200: accuracy:0.29 loss: 220.363 (lr:0.0001)
160210: accuracy:0.38 loss: 202.33 (lr:0.0001)
160220: accuracy:0.31 loss: 224.375 (lr:0.0001)
160230: accuracy:0.27 loss: 215.756 (lr:0.0001)
160240: accuracy:0.36 loss: 198.335 (lr:0.0001)
160250: accuracy:0.32 loss: 213.237 (lr:0.0001)
160260: accuracy:0.43 loss: 182.02 (lr:0.0001)
160270: accuracy:0.32 loss: 215.25 (lr:0.0001)
160280: accuracy:0.35 loss: 206.771 (lr:0.0001)
160290: accuracy:0.41 loss: 197.27 (lr:0.0001)
160300: accuracy:0.35 loss: 215.826 (lr:0.0001)
160310: accuracy:0.37 loss: 200.821 (lr:0.0001)
160320: accuracy:0.4 loss: 198.069 (lr:0.0001)
160330: accuracy:0.37 loss: 203.006 (lr:0.0001)
160340: accuracy:0.35 loss: 190.408 (lr:0.0001)
160350: accuracy:0.3 loss: 209.007 (lr:0.0001)
160360: accuracy:0.41 loss: 185.284 (lr:0.0001)
160370: accuracy:0.31 loss: 209.864 (lr:0.0001)
160380: accuracy:0.29 loss: 223.43 (lr:0.0001)
160390: accuracy:0.36 loss: 215.971 (lr:0.0001)
160400: accuracy:0.4 loss: 192.29 (lr:0.0001)
160410: accuracy:0.36 loss: 204.602 (lr:0.0001)
160420: accuracy:0.38 loss: 187.424 (lr:0.0001)
160430: accuracy:0.33 loss: 216.389 (lr:0.0001)
160440: accuracy:0.47 loss: 178.0 (lr:0.0001)
160450: accuracy:0.39 loss: 178.579 (lr:0.0001)
160460: accuracy:0.3 loss: 212.429 (lr:0.0001)
160470: accuracy:0.37 loss: 215.567 (lr:0.0001)
160480: accuracy:0.49 loss: 182.475 (lr:0.0001)
160490: accuracy:0.27 loss: 215.314 (lr:0.0001)
160500: accuracy:0.33 loss: 204.931 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
160500: ********* epoch 17 ********* test accuracy for all:0.260919 test loss: 256.173
160500: ********* epoch 17 ********* test accuracy for mode 0:0.0505 test loss: 447.351
160500: ********* epoch 17 ********* test accuracy for mode 1:0.0265 test loss: 442.24
160500: ********* epoch 17 ********* test accuracy for mode 2:0.056 test loss: 258.762
160500: ********* epoch 17 ********* test accuracy for mode 24:0.26 test loss: 263.005
160500: ********* epoch 17 ********* test accuracy for mode 25:0.287 test loss: 244.455
160500: ********* epoch 17 ********* test accuracy for mode 26:0.5105 test loss: 155.08
160500: ********* epoch 17 ********* test accuracy for mode 27:0.272 test loss: 263.489
160500: ********* epoch 17 ********* test accuracy for mode 28:0.263 test loss: 262.757
160500: ********* epoch 17 ********* test accuracy for mode 29:0.254 test loss: 267.001
160500: ********* epoch 17 ********* test accuracy for mode 30:0.246 test loss: 248.756
160500: ********* epoch 17 ********* test accuracy for mode 31:0.198 test loss: 248.439
160500: ********* epoch 17 ********* test accuracy for mode 32:0.2035 test loss: 232.702
160500: ********* epoch 17 ********* test accuracy for mode 33:0.284 test loss: 231.108
160500: ********* epoch 17 ********* test accuracy for mode 34:0.248 test loss: 232.673
160500: ********* epoch 17 ********* test accuracy for mode 35:0.1215 test loss: 439.363
160500: ********* epoch 17 ********* test accuracy for mode 36:0.181 test loss: 462.255
160510: accuracy:0.42 loss: 195.245 (lr:0.0001)
160520: accuracy:0.34 loss: 197.071 (lr:0.0001)
160530: accuracy:0.37 loss: 201.195 (lr:0.0001)
160540: accuracy:0.41 loss: 190.286 (lr:0.0001)
160550: accuracy:0.36 loss: 194.05 (lr:0.0001)
160560: accuracy:0.36 loss: 207.248 (lr:0.0001)
160570: accuracy:0.33 loss: 210.729 (lr:0.0001)
160580: accuracy:0.37 loss: 192.743 (lr:0.0001)
160590: accuracy:0.39 loss: 194.021 (lr:0.0001)
160600: accuracy:0.38 loss: 182.684 (lr:0.0001)
160610: accuracy:0.36 loss: 211.024 (lr:0.0001)
160620: accuracy:0.32 loss: 226.597 (lr:0.0001)
160630: accuracy:0.38 loss: 219.91 (lr:0.0001)
160640: accuracy:0.35 loss: 189.108 (lr:0.0001)
160650: accuracy:0.28 loss: 218.89 (lr:0.0001)
160660: accuracy:0.34 loss: 213.495 (lr:0.0001)
160670: accuracy:0.35 loss: 194.391 (lr:0.0001)
160680: accuracy:0.47 loss: 193.566 (lr:0.0001)
160690: accuracy:0.35 loss: 200.975 (lr:0.0001)
160700: accuracy:0.29 loss: 243.893 (lr:0.0001)
160710: accuracy:0.39 loss: 198.535 (lr:0.0001)
160720: accuracy:0.36 loss: 181.685 (lr:0.0001)
160730: accuracy:0.38 loss: 206.304 (lr:0.0001)
160740: accuracy:0.33 loss: 203.014 (lr:0.0001)
160750: accuracy:0.31 loss: 208.468 (lr:0.0001)
160760: accuracy:0.37 loss: 211.762 (lr:0.0001)
160770: accuracy:0.39 loss: 196.737 (lr:0.0001)
160780: accuracy:0.31 loss: 206.822 (lr:0.0001)
160790: accuracy:0.37 loss: 212.143 (lr:0.0001)
160800: accuracy:0.31 loss: 190.425 (lr:0.0001)
160810: accuracy:0.37 loss: 191.003 (lr:0.0001)
160820: accuracy:0.32 loss: 205.659 (lr:0.0001)
160830: accuracy:0.4 loss: 190.125 (lr:0.0001)
160840: accuracy:0.44 loss: 203.894 (lr:0.0001)
160850: accuracy:0.37 loss: 207.704 (lr:0.0001)
160860: accuracy:0.37 loss: 201.881 (lr:0.0001)
160870: accuracy:0.31 loss: 210.361 (lr:0.0001)
160880: accuracy:0.4 loss: 207.01 (lr:0.0001)
160890: accuracy:0.33 loss: 187.269 (lr:0.0001)
160900: accuracy:0.44 loss: 202.37 (lr:0.0001)
160910: accuracy:0.32 loss: 216.084 (lr:0.0001)
160920: accuracy:0.34 loss: 206.454 (lr:0.0001)
160930: accuracy:0.32 loss: 226.555 (lr:0.0001)
160940: accuracy:0.38 loss: 207.311 (lr:0.0001)
160950: accuracy:0.38 loss: 193.082 (lr:0.0001)
160960: accuracy:0.3 loss: 211.466 (lr:0.0001)
160970: accuracy:0.29 loss: 212.417 (lr:0.0001)
160980: accuracy:0.34 loss: 220.324 (lr:0.0001)
160990: accuracy:0.35 loss: 214.646 (lr:0.0001)
161000: accuracy:0.32 loss: 193.547 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
161000: ********* epoch 17 ********* test accuracy for all:0.262203 test loss: 256.563
161000: ********* epoch 17 ********* test accuracy for mode 0:0.0435 test loss: 463.033
161000: ********* epoch 17 ********* test accuracy for mode 1:0.0255 test loss: 449.954
161000: ********* epoch 17 ********* test accuracy for mode 2:0.0505 test loss: 254.409
161000: ********* epoch 17 ********* test accuracy for mode 24:0.2325 test loss: 273.829
161000: ********* epoch 17 ********* test accuracy for mode 25:0.2805 test loss: 244.035
161000: ********* epoch 17 ********* test accuracy for mode 26:0.49 test loss: 160.497
161000: ********* epoch 17 ********* test accuracy for mode 27:0.253 test loss: 260.285
161000: ********* epoch 17 ********* test accuracy for mode 28:0.2815 test loss: 255.403
161000: ********* epoch 17 ********* test accuracy for mode 29:0.2425 test loss: 262.563
161000: ********* epoch 17 ********* test accuracy for mode 30:0.225 test loss: 247.99
161000: ********* epoch 17 ********* test accuracy for mode 31:0.237 test loss: 243.682
161000: ********* epoch 17 ********* test accuracy for mode 32:0.215 test loss: 230.394
161000: ********* epoch 17 ********* test accuracy for mode 33:0.2915 test loss: 230.537
161000: ********* epoch 17 ********* test accuracy for mode 34:0.236 test loss: 235.193
161000: ********* epoch 17 ********* test accuracy for mode 35:0.131 test loss: 438.005
161000: ********* epoch 17 ********* test accuracy for mode 36:0.252 test loss: 455.499
161010: accuracy:0.39 loss: 205.355 (lr:0.0001)
161020: accuracy:0.32 loss: 192.635 (lr:0.0001)
161030: accuracy:0.36 loss: 196.562 (lr:0.0001)
161040: accuracy:0.36 loss: 210.508 (lr:0.0001)
161050: accuracy:0.26 loss: 220.406 (lr:0.0001)
161060: accuracy:0.4 loss: 192.604 (lr:0.0001)
161070: accuracy:0.34 loss: 213.577 (lr:0.0001)
161080: accuracy:0.31 loss: 197.615 (lr:0.0001)
161090: accuracy:0.35 loss: 190.817 (lr:0.0001)
161100: accuracy:0.28 loss: 210.5 (lr:0.0001)
161110: accuracy:0.39 loss: 183.04 (lr:0.0001)
161120: accuracy:0.39 loss: 196.733 (lr:0.0001)
161130: accuracy:0.38 loss: 208.355 (lr:0.0001)
161140: accuracy:0.41 loss: 172.291 (lr:0.0001)
161150: accuracy:0.33 loss: 217.528 (lr:0.0001)
161160: accuracy:0.42 loss: 186.248 (lr:0.0001)
161170: accuracy:0.39 loss: 194.325 (lr:0.0001)
161180: accuracy:0.39 loss: 183.613 (lr:0.0001)
161190: accuracy:0.32 loss: 220.231 (lr:0.0001)
161200: accuracy:0.35 loss: 186.132 (lr:0.0001)
161210: accuracy:0.27 loss: 212.85 (lr:0.0001)
161220: accuracy:0.37 loss: 186.172 (lr:0.0001)
161230: accuracy:0.33 loss: 199.107 (lr:0.0001)
161240: accuracy:0.39 loss: 201.686 (lr:0.0001)
161250: accuracy:0.38 loss: 209.712 (lr:0.0001)
161260: accuracy:0.31 loss: 194.308 (lr:0.0001)
161270: accuracy:0.3 loss: 208.898 (lr:0.0001)
161280: accuracy:0.39 loss: 193.363 (lr:0.0001)
161290: accuracy:0.35 loss: 204.083 (lr:0.0001)
161300: accuracy:0.33 loss: 206.58 (lr:0.0001)
161310: accuracy:0.39 loss: 198.89 (lr:0.0001)
161320: accuracy:0.29 loss: 205.532 (lr:0.0001)
161330: accuracy:0.37 loss: 200.325 (lr:0.0001)
161340: accuracy:0.4 loss: 208.357 (lr:0.0001)
161350: accuracy:0.39 loss: 183.639 (lr:0.0001)
161360: accuracy:0.43 loss: 189.395 (lr:0.0001)
161370: accuracy:0.26 loss: 219.161 (lr:0.0001)
161380: accuracy:0.36 loss: 219.042 (lr:0.0001)
161390: accuracy:0.4 loss: 204.4 (lr:0.0001)
161400: accuracy:0.3 loss: 216.579 (lr:0.0001)
161410: accuracy:0.37 loss: 200.657 (lr:0.0001)
161420: accuracy:0.33 loss: 199.08 (lr:0.0001)
161430: accuracy:0.4 loss: 194.566 (lr:0.0001)
161440: accuracy:0.34 loss: 198.037 (lr:0.0001)
161450: accuracy:0.36 loss: 214.176 (lr:0.0001)
161460: accuracy:0.44 loss: 181.401 (lr:0.0001)
161470: accuracy:0.35 loss: 200.982 (lr:0.0001)
161480: accuracy:0.37 loss: 191.606 (lr:0.0001)
161490: accuracy:0.42 loss: 177.117 (lr:0.0001)
161500: accuracy:0.41 loss: 178.159 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
161500: ********* epoch 17 ********* test accuracy for all:0.263135 test loss: 253.885
161500: ********* epoch 17 ********* test accuracy for mode 0:0.0395 test loss: 456.146
161500: ********* epoch 17 ********* test accuracy for mode 1:0.0335 test loss: 431.636
161500: ********* epoch 17 ********* test accuracy for mode 2:0.041 test loss: 265.264
161500: ********* epoch 17 ********* test accuracy for mode 24:0.266 test loss: 261.341
161500: ********* epoch 17 ********* test accuracy for mode 25:0.285 test loss: 242.132
161500: ********* epoch 17 ********* test accuracy for mode 26:0.473 test loss: 157.794
161500: ********* epoch 17 ********* test accuracy for mode 27:0.2475 test loss: 259.378
161500: ********* epoch 17 ********* test accuracy for mode 28:0.2895 test loss: 254.878
161500: ********* epoch 17 ********* test accuracy for mode 29:0.243 test loss: 266.368
161500: ********* epoch 17 ********* test accuracy for mode 30:0.217 test loss: 254.689
161500: ********* epoch 17 ********* test accuracy for mode 31:0.1985 test loss: 257.597
161500: ********* epoch 17 ********* test accuracy for mode 32:0.199 test loss: 241.037
161500: ********* epoch 17 ********* test accuracy for mode 33:0.291 test loss: 238.833
161500: ********* epoch 17 ********* test accuracy for mode 34:0.201 test loss: 242.246
161500: ********* epoch 17 ********* test accuracy for mode 35:0.111 test loss: 437.335
161500: ********* epoch 17 ********* test accuracy for mode 36:0.261 test loss: 457.175
161510: accuracy:0.37 loss: 214.962 (lr:0.0001)
161520: accuracy:0.32 loss: 224.315 (lr:0.0001)
161530: accuracy:0.37 loss: 208.268 (lr:0.0001)
161540: accuracy:0.35 loss: 206.612 (lr:0.0001)
161550: accuracy:0.43 loss: 185.435 (lr:0.0001)
161560: accuracy:0.33 loss: 197.217 (lr:0.0001)
161570: accuracy:0.3 loss: 198.3 (lr:0.0001)
161580: accuracy:0.35 loss: 206.231 (lr:0.0001)
161590: accuracy:0.29 loss: 199.557 (lr:0.0001)
161600: accuracy:0.28 loss: 212.258 (lr:0.0001)
161610: accuracy:0.26 loss: 225.289 (lr:0.0001)
161620: accuracy:0.41 loss: 216.358 (lr:0.0001)
161630: accuracy:0.39 loss: 199.314 (lr:0.0001)
161640: accuracy:0.31 loss: 204.296 (lr:0.0001)
161650: accuracy:0.32 loss: 200.33 (lr:0.0001)
161660: accuracy:0.4 loss: 185.46 (lr:0.0001)
161670: accuracy:0.33 loss: 211.233 (lr:0.0001)
161680: accuracy:0.3 loss: 230.097 (lr:0.0001)
161690: accuracy:0.31 loss: 218.906 (lr:0.0001)
161700: accuracy:0.34 loss: 205.723 (lr:0.0001)
161710: accuracy:0.45 loss: 182.488 (lr:0.0001)
161720: accuracy:0.4 loss: 192.975 (lr:0.0001)
161730: accuracy:0.33 loss: 195.938 (lr:0.0001)
161740: accuracy:0.35 loss: 208.306 (lr:0.0001)
161750: accuracy:0.43 loss: 208.986 (lr:0.0001)
161760: accuracy:0.38 loss: 189.794 (lr:0.0001)
161770: accuracy:0.34 loss: 192.919 (lr:0.0001)
161780: accuracy:0.35 loss: 209.201 (lr:0.0001)
161790: accuracy:0.33 loss: 191.578 (lr:0.0001)
161800: accuracy:0.39 loss: 190.875 (lr:0.0001)
161810: accuracy:0.42 loss: 192.299 (lr:0.0001)
161820: accuracy:0.31 loss: 201.567 (lr:0.0001)
161830: accuracy:0.34 loss: 209.632 (lr:0.0001)
161840: accuracy:0.34 loss: 206.734 (lr:0.0001)
161850: accuracy:0.3 loss: 205.08 (lr:0.0001)
161860: accuracy:0.32 loss: 212.788 (lr:0.0001)
161870: accuracy:0.36 loss: 200.399 (lr:0.0001)
161880: accuracy:0.46 loss: 188.58 (lr:0.0001)
161890: accuracy:0.42 loss: 210.024 (lr:0.0001)
161900: accuracy:0.35 loss: 191.938 (lr:0.0001)
161910: accuracy:0.35 loss: 210.11 (lr:0.0001)
161920: accuracy:0.27 loss: 217.708 (lr:0.0001)
161930: accuracy:0.33 loss: 213.868 (lr:0.0001)
161940: accuracy:0.34 loss: 207.988 (lr:0.0001)
161950: accuracy:0.4 loss: 190.638 (lr:0.0001)
161960: accuracy:0.35 loss: 198.637 (lr:0.0001)
161970: accuracy:0.44 loss: 190.121 (lr:0.0001)
161980: accuracy:0.37 loss: 192.759 (lr:0.0001)
161990: accuracy:0.38 loss: 197.873 (lr:0.0001)
162000: accuracy:0.33 loss: 198.418 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
162000: ********* epoch 17 ********* test accuracy for all:0.253041 test loss: 259.265
162000: ********* epoch 17 ********* test accuracy for mode 0:0.054 test loss: 451.378
162000: ********* epoch 17 ********* test accuracy for mode 1:0.0365 test loss: 436.037
162000: ********* epoch 17 ********* test accuracy for mode 2:0.057 test loss: 255.001
162000: ********* epoch 17 ********* test accuracy for mode 24:0.221 test loss: 285.591
162000: ********* epoch 17 ********* test accuracy for mode 25:0.2525 test loss: 264.896
162000: ********* epoch 17 ********* test accuracy for mode 26:0.4615 test loss: 164.404
162000: ********* epoch 17 ********* test accuracy for mode 27:0.231 test loss: 278.029
162000: ********* epoch 17 ********* test accuracy for mode 28:0.271 test loss: 266.138
162000: ********* epoch 17 ********* test accuracy for mode 29:0.2735 test loss: 268.512
162000: ********* epoch 17 ********* test accuracy for mode 30:0.2605 test loss: 245.702
162000: ********* epoch 17 ********* test accuracy for mode 31:0.2005 test loss: 252.932
162000: ********* epoch 17 ********* test accuracy for mode 32:0.2005 test loss: 235.398
162000: ********* epoch 17 ********* test accuracy for mode 33:0.294 test loss: 230.864
162000: ********* epoch 17 ********* test accuracy for mode 34:0.2175 test loss: 233.356
162000: ********* epoch 17 ********* test accuracy for mode 35:0.0755 test loss: 443.852
162000: ********* epoch 17 ********* test accuracy for mode 36:0.066 test loss: 526.109
162010: accuracy:0.39 loss: 195.535 (lr:0.0001)
162020: accuracy:0.45 loss: 190.94 (lr:0.0001)
162030: accuracy:0.29 loss: 210.71 (lr:0.0001)
162040: accuracy:0.34 loss: 212.234 (lr:0.0001)
162050: accuracy:0.46 loss: 180.785 (lr:0.0001)
162060: accuracy:0.39 loss: 189.453 (lr:0.0001)
162070: accuracy:0.36 loss: 193.208 (lr:0.0001)
162080: accuracy:0.37 loss: 204.066 (lr:0.0001)
162090: accuracy:0.41 loss: 190.406 (lr:0.0001)
162100: accuracy:0.31 loss: 228.789 (lr:0.0001)
162110: accuracy:0.38 loss: 203.293 (lr:0.0001)
162120: accuracy:0.41 loss: 187.472 (lr:0.0001)
162130: accuracy:0.36 loss: 201.695 (lr:0.0001)
162140: accuracy:0.43 loss: 193.748 (lr:0.0001)
162150: accuracy:0.27 loss: 224.955 (lr:0.0001)
162160: accuracy:0.36 loss: 208.131 (lr:0.0001)
162170: accuracy:0.3 loss: 210.533 (lr:0.0001)
162180: accuracy:0.36 loss: 221.396 (lr:0.0001)
162190: accuracy:0.39 loss: 204.293 (lr:0.0001)
162200: accuracy:0.31 loss: 205.11 (lr:0.0001)
162210: accuracy:0.49 loss: 174.482 (lr:0.0001)
162220: accuracy:0.37 loss: 198.539 (lr:0.0001)
162230: accuracy:0.38 loss: 193.938 (lr:0.0001)
162240: accuracy:0.43 loss: 188.586 (lr:0.0001)
162250: accuracy:0.4 loss: 181.396 (lr:0.0001)
162260: accuracy:0.41 loss: 207.591 (lr:0.0001)
162270: accuracy:0.41 loss: 195.149 (lr:0.0001)
162280: accuracy:0.38 loss: 193.949 (lr:0.0001)
162290: accuracy:0.35 loss: 201.218 (lr:0.0001)
162300: accuracy:0.34 loss: 210.864 (lr:0.0001)
162310: accuracy:0.4 loss: 195.284 (lr:0.0001)
162320: accuracy:0.38 loss: 199.654 (lr:0.0001)
162330: accuracy:0.34 loss: 225.8 (lr:0.0001)
162340: accuracy:0.36 loss: 212.515 (lr:0.0001)
162350: accuracy:0.39 loss: 198.387 (lr:0.0001)
162360: accuracy:0.38 loss: 197.739 (lr:0.0001)
162370: accuracy:0.35 loss: 205.346 (lr:0.0001)
162380: accuracy:0.37 loss: 213.465 (lr:0.0001)
162390: accuracy:0.35 loss: 221.759 (lr:0.0001)
162400: accuracy:0.35 loss: 193.192 (lr:0.0001)
162410: accuracy:0.36 loss: 204.329 (lr:0.0001)
162420: accuracy:0.3 loss: 226.179 (lr:0.0001)
162430: accuracy:0.37 loss: 194.709 (lr:0.0001)
162440: accuracy:0.34 loss: 207.559 (lr:0.0001)
162450: accuracy:0.32 loss: 220.173 (lr:0.0001)
162460: accuracy:0.41 loss: 206.277 (lr:0.0001)
162470: accuracy:0.4 loss: 195.93 (lr:0.0001)
162480: accuracy:0.35 loss: 204.796 (lr:0.0001)
162490: accuracy:0.4 loss: 214.856 (lr:0.0001)
162500: accuracy:0.36 loss: 211.602 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
162500: ********* epoch 17 ********* test accuracy for all:0.261676 test loss: 258.24
162500: ********* epoch 17 ********* test accuracy for mode 0:0.047 test loss: 463.264
162500: ********* epoch 17 ********* test accuracy for mode 1:0.0345 test loss: 446.397
162500: ********* epoch 17 ********* test accuracy for mode 2:0.0635 test loss: 252.531
162500: ********* epoch 17 ********* test accuracy for mode 24:0.217 test loss: 283.702
162500: ********* epoch 17 ********* test accuracy for mode 25:0.289 test loss: 251.809
162500: ********* epoch 17 ********* test accuracy for mode 26:0.496 test loss: 164.248
162500: ********* epoch 17 ********* test accuracy for mode 27:0.231 test loss: 269.988
162500: ********* epoch 17 ********* test accuracy for mode 28:0.3025 test loss: 255.667
162500: ********* epoch 17 ********* test accuracy for mode 29:0.258 test loss: 266.955
162500: ********* epoch 17 ********* test accuracy for mode 30:0.2505 test loss: 244.909
162500: ********* epoch 17 ********* test accuracy for mode 31:0.244 test loss: 246.333
162500: ********* epoch 17 ********* test accuracy for mode 32:0.211 test loss: 231.619
162500: ********* epoch 17 ********* test accuracy for mode 33:0.297 test loss: 232.545
162500: ********* epoch 17 ********* test accuracy for mode 34:0.1875 test loss: 236.725
162500: ********* epoch 17 ********* test accuracy for mode 35:0.0905 test loss: 440.88
162500: ********* epoch 17 ********* test accuracy for mode 36:0.272 test loss: 462.683
162510: accuracy:0.32 loss: 220.164 (lr:0.0001)
162520: accuracy:0.45 loss: 197.392 (lr:0.0001)
162530: accuracy:0.36 loss: 185.304 (lr:0.0001)
162540: accuracy:0.35 loss: 208.239 (lr:0.0001)
162550: accuracy:0.35 loss: 210.04 (lr:0.0001)
162560: accuracy:0.41 loss: 210.09 (lr:0.0001)
162570: accuracy:0.32 loss: 189.712 (lr:0.0001)
162580: accuracy:0.38 loss: 188.637 (lr:0.0001)
162590: accuracy:0.4 loss: 184.517 (lr:0.0001)
162600: accuracy:0.39 loss: 192.671 (lr:0.0001)
162610: accuracy:0.37 loss: 200.247 (lr:0.0001)
162620: accuracy:0.3 loss: 211.449 (lr:0.0001)
162630: accuracy:0.27 loss: 207.817 (lr:0.0001)
162640: accuracy:0.36 loss: 207.699 (lr:0.0001)
162650: accuracy:0.29 loss: 212.616 (lr:0.0001)
162660: accuracy:0.42 loss: 195.366 (lr:0.0001)
162670: accuracy:0.34 loss: 199.078 (lr:0.0001)
162680: accuracy:0.34 loss: 201.719 (lr:0.0001)
162690: accuracy:0.31 loss: 216.982 (lr:0.0001)
162700: accuracy:0.32 loss: 227.056 (lr:0.0001)
162710: accuracy:0.31 loss: 225.146 (lr:0.0001)
162720: accuracy:0.26 loss: 215.542 (lr:0.0001)
162730: accuracy:0.47 loss: 194.871 (lr:0.0001)
162740: accuracy:0.43 loss: 203.772 (lr:0.0001)
162750: accuracy:0.36 loss: 206.717 (lr:0.0001)
162760: accuracy:0.44 loss: 193.873 (lr:0.0001)
162770: accuracy:0.33 loss: 195.517 (lr:0.0001)
162780: accuracy:0.34 loss: 221.738 (lr:0.0001)
162790: accuracy:0.43 loss: 179.38 (lr:0.0001)
162800: accuracy:0.38 loss: 208.007 (lr:0.0001)
162810: accuracy:0.41 loss: 206.479 (lr:0.0001)
162820: accuracy:0.32 loss: 197.877 (lr:0.0001)
162830: accuracy:0.3 loss: 207.356 (lr:0.0001)
162840: accuracy:0.29 loss: 203.928 (lr:0.0001)
162850: accuracy:0.37 loss: 199.433 (lr:0.0001)
162860: accuracy:0.34 loss: 213.674 (lr:0.0001)
162870: accuracy:0.38 loss: 197.423 (lr:0.0001)
162880: accuracy:0.31 loss: 211.095 (lr:0.0001)
162890: accuracy:0.43 loss: 187.773 (lr:0.0001)
162900: accuracy:0.31 loss: 203.892 (lr:0.0001)
162910: accuracy:0.38 loss: 199.247 (lr:0.0001)
162920: accuracy:0.4 loss: 197.01 (lr:0.0001)
162930: accuracy:0.35 loss: 210.61 (lr:0.0001)
162940: accuracy:0.39 loss: 195.593 (lr:0.0001)
162950: accuracy:0.39 loss: 195.228 (lr:0.0001)
162960: accuracy:0.35 loss: 190.976 (lr:0.0001)
162970: accuracy:0.33 loss: 189.816 (lr:0.0001)
162980: accuracy:0.43 loss: 195.786 (lr:0.0001)
162990: accuracy:0.45 loss: 205.25 (lr:0.0001)
163000: accuracy:0.3 loss: 208.779 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
163000: ********* epoch 17 ********* test accuracy for all:0.260973 test loss: 257.273
163000: ********* epoch 17 ********* test accuracy for mode 0:0.047 test loss: 460.161
163000: ********* epoch 17 ********* test accuracy for mode 1:0.0295 test loss: 444.223
163000: ********* epoch 17 ********* test accuracy for mode 2:0.0565 test loss: 256.244
163000: ********* epoch 17 ********* test accuracy for mode 24:0.252 test loss: 279.129
163000: ********* epoch 17 ********* test accuracy for mode 25:0.282 test loss: 252.226
163000: ********* epoch 17 ********* test accuracy for mode 26:0.509 test loss: 158.845
163000: ********* epoch 17 ********* test accuracy for mode 27:0.204 test loss: 276.883
163000: ********* epoch 17 ********* test accuracy for mode 28:0.289 test loss: 261.794
163000: ********* epoch 17 ********* test accuracy for mode 29:0.2665 test loss: 267.829
163000: ********* epoch 17 ********* test accuracy for mode 30:0.2375 test loss: 252.013
163000: ********* epoch 17 ********* test accuracy for mode 31:0.1785 test loss: 258.613
163000: ********* epoch 17 ********* test accuracy for mode 32:0.247 test loss: 235.644
163000: ********* epoch 17 ********* test accuracy for mode 33:0.2355 test loss: 240.043
163000: ********* epoch 17 ********* test accuracy for mode 34:0.241 test loss: 237.762
163000: ********* epoch 17 ********* test accuracy for mode 35:0.0965 test loss: 438.872
163000: ********* epoch 17 ********* test accuracy for mode 36:0.2865 test loss: 443.304
163010: accuracy:0.38 loss: 178.124 (lr:0.0001)
163020: accuracy:0.41 loss: 170.019 (lr:0.0001)
163030: accuracy:0.44 loss: 182.415 (lr:0.0001)
163040: accuracy:0.38 loss: 194.867 (lr:0.0001)
163050: accuracy:0.29 loss: 211.159 (lr:0.0001)
163060: accuracy:0.29 loss: 213.956 (lr:0.0001)
163070: accuracy:0.33 loss: 202.415 (lr:0.0001)
163080: accuracy:0.31 loss: 204.199 (lr:0.0001)
163090: accuracy:0.39 loss: 206.191 (lr:0.0001)
163100: accuracy:0.32 loss: 223.988 (lr:0.0001)
163110: accuracy:0.21 loss: 218.998 (lr:0.0001)
163120: accuracy:0.35 loss: 214.123 (lr:0.0001)
163130: accuracy:0.28 loss: 204.394 (lr:0.0001)
163140: accuracy:0.35 loss: 195.236 (lr:0.0001)
163150: accuracy:0.37 loss: 190.374 (lr:0.0001)
163160: accuracy:0.36 loss: 213.921 (lr:0.0001)
163170: accuracy:0.37 loss: 219.087 (lr:0.0001)
163180: accuracy:0.23 loss: 228.786 (lr:0.0001)
163190: accuracy:0.32 loss: 221.119 (lr:0.0001)
163200: accuracy:0.46 loss: 179.594 (lr:0.0001)
163210: accuracy:0.41 loss: 196.518 (lr:0.0001)
163220: accuracy:0.33 loss: 198.979 (lr:0.0001)
163230: accuracy:0.33 loss: 199.488 (lr:0.0001)
163240: accuracy:0.32 loss: 204.962 (lr:0.0001)
163250: accuracy:0.38 loss: 204.728 (lr:0.0001)
163260: accuracy:0.44 loss: 183.555 (lr:0.0001)
163270: accuracy:0.35 loss: 210.629 (lr:0.0001)
163280: accuracy:0.39 loss: 193.914 (lr:0.0001)
163290: accuracy:0.32 loss: 214.268 (lr:0.0001)
163300: accuracy:0.35 loss: 203.272 (lr:0.0001)
163310: accuracy:0.29 loss: 211.427 (lr:0.0001)
163320: accuracy:0.39 loss: 178.347 (lr:0.0001)
163330: accuracy:0.3 loss: 217.57 (lr:0.0001)
163340: accuracy:0.34 loss: 199.289 (lr:0.0001)
163350: accuracy:0.33 loss: 210.509 (lr:0.0001)
163360: accuracy:0.38 loss: 197.352 (lr:0.0001)
163370: accuracy:0.34 loss: 196.067 (lr:0.0001)
163380: accuracy:0.34 loss: 214.34 (lr:0.0001)
163390: accuracy:0.43 loss: 174.708 (lr:0.0001)
163400: accuracy:0.42 loss: 195.813 (lr:0.0001)
163410: accuracy:0.34 loss: 186.895 (lr:0.0001)
163420: accuracy:0.32 loss: 211.421 (lr:0.0001)
163430: accuracy:0.35 loss: 190.976 (lr:0.0001)
163440: accuracy:0.36 loss: 211.223 (lr:0.0001)
163450: accuracy:0.38 loss: 208.435 (lr:0.0001)
163460: accuracy:0.4 loss: 183.745 (lr:0.0001)
163470: accuracy:0.43 loss: 193.524 (lr:0.0001)
163480: accuracy:0.42 loss: 200.462 (lr:0.0001)
163490: accuracy:0.38 loss: 206.74 (lr:0.0001)
163500: accuracy:0.33 loss: 224.067 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
163500: ********* epoch 17 ********* test accuracy for all:0.262757 test loss: 256.489
163500: ********* epoch 17 ********* test accuracy for mode 0:0.0405 test loss: 459.975
163500: ********* epoch 17 ********* test accuracy for mode 1:0.028 test loss: 448.453
163500: ********* epoch 17 ********* test accuracy for mode 2:0.0595 test loss: 261.156
163500: ********* epoch 17 ********* test accuracy for mode 24:0.236 test loss: 276.842
163500: ********* epoch 17 ********* test accuracy for mode 25:0.281 test loss: 249.899
163500: ********* epoch 17 ********* test accuracy for mode 26:0.481 test loss: 163.336
163500: ********* epoch 17 ********* test accuracy for mode 27:0.2105 test loss: 272.792
163500: ********* epoch 17 ********* test accuracy for mode 28:0.297 test loss: 256.6
163500: ********* epoch 17 ********* test accuracy for mode 29:0.233 test loss: 273.152
163500: ********* epoch 17 ********* test accuracy for mode 30:0.238 test loss: 249.375
163500: ********* epoch 17 ********* test accuracy for mode 31:0.193 test loss: 252.196
163500: ********* epoch 17 ********* test accuracy for mode 32:0.238 test loss: 234.403
163500: ********* epoch 17 ********* test accuracy for mode 33:0.294 test loss: 233.523
163500: ********* epoch 17 ********* test accuracy for mode 34:0.193 test loss: 238.873
163500: ********* epoch 17 ********* test accuracy for mode 35:0.101 test loss: 439.682
163500: ********* epoch 17 ********* test accuracy for mode 36:0.2725 test loss: 451.535
163510: accuracy:0.38 loss: 189.458 (lr:0.0001)
163520: accuracy:0.39 loss: 207.957 (lr:0.0001)
163530: accuracy:0.32 loss: 200.744 (lr:0.0001)
163540: accuracy:0.35 loss: 216.291 (lr:0.0001)
163550: accuracy:0.36 loss: 186.306 (lr:0.0001)
163560: accuracy:0.43 loss: 196.112 (lr:0.0001)
163570: accuracy:0.38 loss: 193.579 (lr:0.0001)
163580: accuracy:0.33 loss: 203.162 (lr:0.0001)
163590: accuracy:0.38 loss: 187.105 (lr:0.0001)
163600: accuracy:0.35 loss: 209.923 (lr:0.0001)
163610: accuracy:0.32 loss: 187.478 (lr:0.0001)
163620: accuracy:0.38 loss: 185.894 (lr:0.0001)
163630: accuracy:0.43 loss: 198.186 (lr:0.0001)
163640: accuracy:0.36 loss: 215.563 (lr:0.0001)
163650: accuracy:0.42 loss: 170.403 (lr:0.0001)
163660: accuracy:0.3 loss: 217.615 (lr:0.0001)
163670: accuracy:0.31 loss: 211.425 (lr:0.0001)
163680: accuracy:0.39 loss: 204.77 (lr:0.0001)
163690: accuracy:0.32 loss: 212.667 (lr:0.0001)
163700: accuracy:0.47 loss: 200.181 (lr:0.0001)
163710: accuracy:0.36 loss: 182.224 (lr:0.0001)
163720: accuracy:0.31 loss: 202.379 (lr:0.0001)
163730: accuracy:0.4 loss: 187.227 (lr:0.0001)
163740: accuracy:0.31 loss: 226.487 (lr:0.0001)
163750: accuracy:0.35 loss: 189.15 (lr:0.0001)
163760: accuracy:0.33 loss: 209.091 (lr:0.0001)
163770: accuracy:0.36 loss: 204.391 (lr:0.0001)
163780: accuracy:0.36 loss: 206.739 (lr:0.0001)
163790: accuracy:0.35 loss: 182.704 (lr:0.0001)
163800: accuracy:0.32 loss: 218.996 (lr:0.0001)
163810: accuracy:0.41 loss: 189.706 (lr:0.0001)
163820: accuracy:0.31 loss: 221.247 (lr:0.0001)
163830: accuracy:0.33 loss: 204.707 (lr:0.0001)
163840: accuracy:0.39 loss: 197.606 (lr:0.0001)
163850: accuracy:0.37 loss: 219.364 (lr:0.0001)
163860: accuracy:0.32 loss: 205.145 (lr:0.0001)
163870: accuracy:0.43 loss: 194.959 (lr:0.0001)
163880: accuracy:0.38 loss: 191.112 (lr:0.0001)
163890: accuracy:0.44 loss: 192.883 (lr:0.0001)
163900: accuracy:0.34 loss: 213.08 (lr:0.0001)
163910: accuracy:0.32 loss: 213.886 (lr:0.0001)
163920: accuracy:0.38 loss: 211.057 (lr:0.0001)
163930: accuracy:0.24 loss: 237.462 (lr:0.0001)
163940: accuracy:0.27 loss: 219.762 (lr:0.0001)
163950: accuracy:0.37 loss: 212.894 (lr:0.0001)
163960: accuracy:0.28 loss: 211.425 (lr:0.0001)
163970: accuracy:0.33 loss: 219.244 (lr:0.0001)
163980: accuracy:0.34 loss: 220.725 (lr:0.0001)
163990: accuracy:0.35 loss: 210.854 (lr:0.0001)
164000: accuracy:0.37 loss: 197.545 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
164000: ********* epoch 17 ********* test accuracy for all:0.263459 test loss: 256.316
164000: ********* epoch 17 ********* test accuracy for mode 0:0.0435 test loss: 466.268
164000: ********* epoch 17 ********* test accuracy for mode 1:0.036 test loss: 441.375
164000: ********* epoch 17 ********* test accuracy for mode 2:0.076 test loss: 256.14
164000: ********* epoch 17 ********* test accuracy for mode 24:0.2465 test loss: 274.217
164000: ********* epoch 17 ********* test accuracy for mode 25:0.2725 test loss: 247.339
164000: ********* epoch 17 ********* test accuracy for mode 26:0.5315 test loss: 157.198
164000: ********* epoch 17 ********* test accuracy for mode 27:0.256 test loss: 259.43
164000: ********* epoch 17 ********* test accuracy for mode 28:0.294 test loss: 250.2
164000: ********* epoch 17 ********* test accuracy for mode 29:0.2895 test loss: 259.62
164000: ********* epoch 17 ********* test accuracy for mode 30:0.229 test loss: 246.398
164000: ********* epoch 17 ********* test accuracy for mode 31:0.172 test loss: 251.925
164000: ********* epoch 17 ********* test accuracy for mode 32:0.26 test loss: 229.316
164000: ********* epoch 17 ********* test accuracy for mode 33:0.259 test loss: 231.361
164000: ********* epoch 17 ********* test accuracy for mode 34:0.2585 test loss: 232.034
164000: ********* epoch 17 ********* test accuracy for mode 35:0.093 test loss: 459.14
164000: ********* epoch 17 ********* test accuracy for mode 36:0.1735 test loss: 486.061
164010: accuracy:0.43 loss: 179.3 (lr:0.0001)
164020: accuracy:0.35 loss: 208.052 (lr:0.0001)
164030: accuracy:0.33 loss: 191.662 (lr:0.0001)
164040: accuracy:0.32 loss: 203.039 (lr:0.0001)
164050: accuracy:0.26 loss: 216.487 (lr:0.0001)
164060: accuracy:0.37 loss: 205.116 (lr:0.0001)
164070: accuracy:0.36 loss: 197.007 (lr:0.0001)
164080: accuracy:0.29 loss: 210.152 (lr:0.0001)
164090: accuracy:0.37 loss: 192.044 (lr:0.0001)
164100: accuracy:0.39 loss: 189.175 (lr:0.0001)
164110: accuracy:0.38 loss: 197.156 (lr:0.0001)
164120: accuracy:0.41 loss: 194.562 (lr:0.0001)
164130: accuracy:0.36 loss: 198.951 (lr:0.0001)
164140: accuracy:0.4 loss: 205.383 (lr:0.0001)
164150: accuracy:0.43 loss: 184.631 (lr:0.0001)
164160: accuracy:0.35 loss: 207.567 (lr:0.0001)
164170: accuracy:0.4 loss: 206.378 (lr:0.0001)
164180: accuracy:0.33 loss: 204.527 (lr:0.0001)
164190: accuracy:0.4 loss: 178.228 (lr:0.0001)
164200: accuracy:0.3 loss: 202.145 (lr:0.0001)
164210: accuracy:0.34 loss: 207.336 (lr:0.0001)
164220: accuracy:0.32 loss: 215.327 (lr:0.0001)
164230: accuracy:0.34 loss: 190.234 (lr:0.0001)
164240: accuracy:0.32 loss: 218.251 (lr:0.0001)
164250: accuracy:0.43 loss: 196.767 (lr:0.0001)
164260: accuracy:0.32 loss: 214.87 (lr:0.0001)
164270: accuracy:0.3 loss: 213.168 (lr:0.0001)
164280: accuracy:0.3 loss: 201.268 (lr:0.0001)
164290: accuracy:0.35 loss: 189.244 (lr:0.0001)
164300: accuracy:0.37 loss: 198.702 (lr:0.0001)
164310: accuracy:0.32 loss: 187.634 (lr:0.0001)
164320: accuracy:0.45 loss: 177.583 (lr:0.0001)
164330: accuracy:0.33 loss: 209.98 (lr:0.0001)
164340: accuracy:0.39 loss: 203.433 (lr:0.0001)
164350: accuracy:0.38 loss: 197.757 (lr:0.0001)
164360: accuracy:0.33 loss: 209.268 (lr:0.0001)
164370: accuracy:0.3 loss: 209.663 (lr:0.0001)
164380: accuracy:0.4 loss: 204.876 (lr:0.0001)
164390: accuracy:0.4 loss: 184.779 (lr:0.0001)
164400: accuracy:0.33 loss: 206.598 (lr:0.0001)
164410: accuracy:0.38 loss: 203.33 (lr:0.0001)
164420: accuracy:0.4 loss: 193.889 (lr:0.0001)
164430: accuracy:0.37 loss: 215.225 (lr:0.0001)
164440: accuracy:0.37 loss: 184.178 (lr:0.0001)
164450: accuracy:0.37 loss: 181.091 (lr:0.0001)
164460: accuracy:0.3 loss: 217.252 (lr:0.0001)
164470: accuracy:0.27 loss: 211.005 (lr:0.0001)
164480: accuracy:0.4 loss: 189.875 (lr:0.0001)
164490: accuracy:0.36 loss: 192.47 (lr:0.0001)
164500: accuracy:0.39 loss: 197.097 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
164500: ********* epoch 17 ********* test accuracy for all:0.260662 test loss: 257.004
164500: ********* epoch 17 ********* test accuracy for mode 0:0.0445 test loss: 458.533
164500: ********* epoch 17 ********* test accuracy for mode 1:0.0315 test loss: 442.234
164500: ********* epoch 17 ********* test accuracy for mode 2:0.0855 test loss: 258.671
164500: ********* epoch 17 ********* test accuracy for mode 24:0.2315 test loss: 276.296
164500: ********* epoch 17 ********* test accuracy for mode 25:0.265 test loss: 240.427
164500: ********* epoch 17 ********* test accuracy for mode 26:0.5545 test loss: 154.488
164500: ********* epoch 17 ********* test accuracy for mode 27:0.236 test loss: 261.248
164500: ********* epoch 17 ********* test accuracy for mode 28:0.2625 test loss: 264.149
164500: ********* epoch 17 ********* test accuracy for mode 29:0.243 test loss: 273.794
164500: ********* epoch 17 ********* test accuracy for mode 30:0.2175 test loss: 258.349
164500: ********* epoch 17 ********* test accuracy for mode 31:0.1895 test loss: 259.27
164500: ********* epoch 17 ********* test accuracy for mode 32:0.242 test loss: 239.242
164500: ********* epoch 17 ********* test accuracy for mode 33:0.2545 test loss: 240.159
164500: ********* epoch 17 ********* test accuracy for mode 34:0.211 test loss: 243.97
164500: ********* epoch 17 ********* test accuracy for mode 35:0.115 test loss: 428.828
164500: ********* epoch 17 ********* test accuracy for mode 36:0.173 test loss: 470.938
164510: accuracy:0.33 loss: 216.788 (lr:0.0001)
164520: accuracy:0.36 loss: 189.748 (lr:0.0001)
164530: accuracy:0.28 loss: 209.283 (lr:0.0001)
164540: accuracy:0.44 loss: 182.412 (lr:0.0001)
164550: accuracy:0.31 loss: 233.178 (lr:0.0001)
164560: accuracy:0.31 loss: 216.65 (lr:0.0001)
164570: accuracy:0.33 loss: 197.377 (lr:0.0001)
164580: accuracy:0.46 loss: 181.41 (lr:0.0001)
164590: accuracy:0.32 loss: 217.863 (lr:0.0001)
164600: accuracy:0.34 loss: 200.728 (lr:0.0001)
164610: accuracy:0.34 loss: 221.349 (lr:0.0001)
164620: accuracy:0.33 loss: 190.293 (lr:0.0001)
164630: accuracy:0.39 loss: 206.722 (lr:0.0001)
164640: accuracy:0.29 loss: 229.384 (lr:0.0001)
164650: accuracy:0.43 loss: 175.74 (lr:0.0001)
164660: accuracy:0.34 loss: 202.774 (lr:0.0001)
164670: accuracy:0.4 loss: 195.585 (lr:0.0001)
164680: accuracy:0.31 loss: 206.957 (lr:0.0001)
164690: accuracy:0.35 loss: 192.719 (lr:0.0001)
164700: accuracy:0.41 loss: 192.293 (lr:0.0001)
164710: accuracy:0.37 loss: 208.471 (lr:0.0001)
164720: accuracy:0.38 loss: 198.543 (lr:0.0001)
164730: accuracy:0.26 loss: 210.751 (lr:0.0001)
164740: accuracy:0.33 loss: 224.119 (lr:0.0001)
164750: accuracy:0.29 loss: 213.903 (lr:0.0001)
164760: accuracy:0.36 loss: 178.919 (lr:0.0001)
164770: accuracy:0.47 loss: 175.958 (lr:0.0001)
164780: accuracy:0.31 loss: 206.151 (lr:0.0001)
164790: accuracy:0.33 loss: 206.024 (lr:0.0001)
164800: accuracy:0.27 loss: 222.91 (lr:0.0001)
164810: accuracy:0.41 loss: 196.232 (lr:0.0001)
164820: accuracy:0.34 loss: 202.18 (lr:0.0001)
164830: accuracy:0.3 loss: 219.409 (lr:0.0001)
164840: accuracy:0.38 loss: 183.907 (lr:0.0001)
164850: accuracy:0.36 loss: 209.813 (lr:0.0001)
164860: accuracy:0.38 loss: 207.509 (lr:0.0001)
164870: accuracy:0.36 loss: 194.201 (lr:0.0001)
164880: accuracy:0.5 loss: 173.962 (lr:0.0001)
164890: accuracy:0.38 loss: 196.161 (lr:0.0001)
164900: accuracy:0.32 loss: 197.433 (lr:0.0001)
164910: accuracy:0.32 loss: 199.889 (lr:0.0001)
164920: accuracy:0.43 loss: 190.673 (lr:0.0001)
164930: accuracy:0.33 loss: 198.848 (lr:0.0001)
164940: accuracy:0.4 loss: 195.61 (lr:0.0001)
164950: accuracy:0.3 loss: 228.387 (lr:0.0001)
164960: accuracy:0.41 loss: 188.827 (lr:0.0001)
164970: accuracy:0.35 loss: 197.822 (lr:0.0001)
164980: accuracy:0.3 loss: 209.091 (lr:0.0001)
164990: accuracy:0.32 loss: 204.206 (lr:0.0001)
165000: accuracy:0.41 loss: 186.729 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
165000: ********* epoch 17 ********* test accuracy for all:0.266838 test loss: 255.428
165000: ********* epoch 17 ********* test accuracy for mode 0:0.043 test loss: 456.225
165000: ********* epoch 17 ********* test accuracy for mode 1:0.027 test loss: 442.132
165000: ********* epoch 17 ********* test accuracy for mode 2:0.07 test loss: 257.333
165000: ********* epoch 17 ********* test accuracy for mode 24:0.2315 test loss: 278.859
165000: ********* epoch 17 ********* test accuracy for mode 25:0.3065 test loss: 244.833
165000: ********* epoch 17 ********* test accuracy for mode 26:0.5105 test loss: 155.174
165000: ********* epoch 17 ********* test accuracy for mode 27:0.263 test loss: 261.77
165000: ********* epoch 17 ********* test accuracy for mode 28:0.2815 test loss: 259.911
165000: ********* epoch 17 ********* test accuracy for mode 29:0.261 test loss: 269.189
165000: ********* epoch 17 ********* test accuracy for mode 30:0.254 test loss: 246.374
165000: ********* epoch 17 ********* test accuracy for mode 31:0.203 test loss: 252.606
165000: ********* epoch 17 ********* test accuracy for mode 32:0.196 test loss: 240.46
165000: ********* epoch 17 ********* test accuracy for mode 33:0.2375 test loss: 240.385
165000: ********* epoch 17 ********* test accuracy for mode 34:0.233 test loss: 238.037
165000: ********* epoch 17 ********* test accuracy for mode 35:0.1285 test loss: 434.84
165000: ********* epoch 17 ********* test accuracy for mode 36:0.3045 test loss: 438.363
165010: accuracy:0.32 loss: 209.898 (lr:0.0001)
165020: accuracy:0.33 loss: 211.336 (lr:0.0001)
165030: accuracy:0.33 loss: 203.937 (lr:0.0001)
165040: accuracy:0.37 loss: 209.622 (lr:0.0001)
165050: accuracy:0.36 loss: 189.281 (lr:0.0001)
165060: accuracy:0.43 loss: 198.732 (lr:0.0001)
165070: accuracy:0.39 loss: 194.946 (lr:0.0001)
165080: accuracy:0.4 loss: 200.104 (lr:0.0001)
165090: accuracy:0.28 loss: 210.848 (lr:0.0001)
165100: accuracy:0.41 loss: 199.999 (lr:0.0001)
165110: accuracy:0.32 loss: 211.626 (lr:0.0001)
165120: accuracy:0.43 loss: 181.498 (lr:0.0001)
165130: accuracy:0.39 loss: 181.338 (lr:0.0001)
165140: accuracy:0.35 loss: 202.522 (lr:0.0001)
165150: accuracy:0.35 loss: 215.897 (lr:0.0001)
165160: accuracy:0.41 loss: 183.522 (lr:0.0001)
165170: accuracy:0.32 loss: 205.784 (lr:0.0001)
165180: accuracy:0.39 loss: 187.837 (lr:0.0001)
165190: accuracy:0.42 loss: 203.009 (lr:0.0001)
165200: accuracy:0.36 loss: 200.952 (lr:0.0001)
165210: accuracy:0.45 loss: 200.312 (lr:0.0001)
165220: accuracy:0.34 loss: 199.346 (lr:0.0001)
165230: accuracy:0.35 loss: 223.961 (lr:0.0001)
165240: accuracy:0.38 loss: 189.303 (lr:0.0001)
165250: accuracy:0.38 loss: 193.22 (lr:0.0001)
165260: accuracy:0.34 loss: 208.066 (lr:0.0001)
165270: accuracy:0.38 loss: 207.767 (lr:0.0001)
165280: accuracy:0.3 loss: 220.359 (lr:0.0001)
165290: accuracy:0.33 loss: 204.959 (lr:0.0001)
165300: accuracy:0.38 loss: 210.04 (lr:0.0001)
165310: accuracy:0.29 loss: 213.376 (lr:0.0001)
165320: accuracy:0.47 loss: 180.311 (lr:0.0001)
165330: accuracy:0.39 loss: 191.679 (lr:0.0001)
165340: accuracy:0.4 loss: 191.219 (lr:0.0001)
165350: accuracy:0.43 loss: 191.176 (lr:0.0001)
165360: accuracy:0.33 loss: 218.79 (lr:0.0001)
165370: accuracy:0.36 loss: 203.841 (lr:0.0001)
165380: accuracy:0.4 loss: 195.666 (lr:0.0001)
165390: accuracy:0.39 loss: 191.845 (lr:0.0001)
165400: accuracy:0.4 loss: 196.409 (lr:0.0001)
165410: accuracy:0.34 loss: 209.005 (lr:0.0001)
165420: accuracy:0.43 loss: 184.439 (lr:0.0001)
165430: accuracy:0.28 loss: 222.212 (lr:0.0001)
165440: accuracy:0.43 loss: 177.557 (lr:0.0001)
165450: accuracy:0.42 loss: 207.46 (lr:0.0001)
165460: accuracy:0.35 loss: 211.078 (lr:0.0001)
165470: accuracy:0.34 loss: 223.24 (lr:0.0001)
165480: accuracy:0.41 loss: 202.371 (lr:0.0001)
165490: accuracy:0.41 loss: 190.48 (lr:0.0001)
165500: accuracy:0.28 loss: 223.766 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
165500: ********* epoch 18 ********* test accuracy for all:0.263865 test loss: 255.883
165500: ********* epoch 18 ********* test accuracy for mode 0:0.0475 test loss: 460.174
165500: ********* epoch 18 ********* test accuracy for mode 1:0.037 test loss: 448.303
165500: ********* epoch 18 ********* test accuracy for mode 2:0.0475 test loss: 270.207
165500: ********* epoch 18 ********* test accuracy for mode 24:0.2415 test loss: 269.859
165500: ********* epoch 18 ********* test accuracy for mode 25:0.3105 test loss: 235.951
165500: ********* epoch 18 ********* test accuracy for mode 26:0.522 test loss: 151.594
165500: ********* epoch 18 ********* test accuracy for mode 27:0.2695 test loss: 251.324
165500: ********* epoch 18 ********* test accuracy for mode 28:0.3135 test loss: 252.232
165500: ********* epoch 18 ********* test accuracy for mode 29:0.246 test loss: 271.554
165500: ********* epoch 18 ********* test accuracy for mode 30:0.2345 test loss: 255.184
165500: ********* epoch 18 ********* test accuracy for mode 31:0.2215 test loss: 257.05
165500: ********* epoch 18 ********* test accuracy for mode 32:0.195 test loss: 245.505
165500: ********* epoch 18 ********* test accuracy for mode 33:0.2245 test loss: 248.503
165500: ********* epoch 18 ********* test accuracy for mode 34:0.2245 test loss: 244.805
165500: ********* epoch 18 ********* test accuracy for mode 35:0.1105 test loss: 447.332
165500: ********* epoch 18 ********* test accuracy for mode 36:0.1875 test loss: 485.679
165510: accuracy:0.29 loss: 215.42 (lr:0.0001)
165520: accuracy:0.3 loss: 215.49 (lr:0.0001)
165530: accuracy:0.39 loss: 212.662 (lr:0.0001)
165540: accuracy:0.3 loss: 230.437 (lr:0.0001)
165550: accuracy:0.37 loss: 192.56 (lr:0.0001)
165560: accuracy:0.32 loss: 202.512 (lr:0.0001)
165570: accuracy:0.41 loss: 204.143 (lr:0.0001)
165580: accuracy:0.34 loss: 214.475 (lr:0.0001)
165590: accuracy:0.34 loss: 220.189 (lr:0.0001)
165600: accuracy:0.38 loss: 189.647 (lr:0.0001)
165610: accuracy:0.39 loss: 194.426 (lr:0.0001)
165620: accuracy:0.38 loss: 205.714 (lr:0.0001)
165630: accuracy:0.3 loss: 194.473 (lr:0.0001)
165640: accuracy:0.42 loss: 209.498 (lr:0.0001)
165650: accuracy:0.36 loss: 188.13 (lr:0.0001)
165660: accuracy:0.33 loss: 211.34 (lr:0.0001)
165670: accuracy:0.42 loss: 186.419 (lr:0.0001)
165680: accuracy:0.33 loss: 191.069 (lr:0.0001)
165690: accuracy:0.38 loss: 188.695 (lr:0.0001)
165700: accuracy:0.42 loss: 173.864 (lr:0.0001)
165710: accuracy:0.34 loss: 202.39 (lr:0.0001)
165720: accuracy:0.32 loss: 219.907 (lr:0.0001)
165730: accuracy:0.32 loss: 200.52 (lr:0.0001)
165740: accuracy:0.38 loss: 189.212 (lr:0.0001)
165750: accuracy:0.4 loss: 185.425 (lr:0.0001)
165760: accuracy:0.39 loss: 188.525 (lr:0.0001)
165770: accuracy:0.36 loss: 194.871 (lr:0.0001)
165780: accuracy:0.33 loss: 206.126 (lr:0.0001)
165790: accuracy:0.42 loss: 198.736 (lr:0.0001)
165800: accuracy:0.39 loss: 194.535 (lr:0.0001)
165810: accuracy:0.36 loss: 208.684 (lr:0.0001)
165820: accuracy:0.36 loss: 198.585 (lr:0.0001)
165830: accuracy:0.37 loss: 188.907 (lr:0.0001)
165840: accuracy:0.5 loss: 173.653 (lr:0.0001)
165850: accuracy:0.34 loss: 203.223 (lr:0.0001)
165860: accuracy:0.3 loss: 221.185 (lr:0.0001)
165870: accuracy:0.4 loss: 200.958 (lr:0.0001)
165880: accuracy:0.35 loss: 199.503 (lr:0.0001)
165890: accuracy:0.36 loss: 195.477 (lr:0.0001)
165900: accuracy:0.43 loss: 190.671 (lr:0.0001)
165910: accuracy:0.28 loss: 225.614 (lr:0.0001)
165920: accuracy:0.35 loss: 211.958 (lr:0.0001)
165930: accuracy:0.36 loss: 208.466 (lr:0.0001)
165940: accuracy:0.35 loss: 213.923 (lr:0.0001)
165950: accuracy:0.43 loss: 173.101 (lr:0.0001)
165960: accuracy:0.44 loss: 186.185 (lr:0.0001)
165970: accuracy:0.35 loss: 200.447 (lr:0.0001)
165980: accuracy:0.36 loss: 191.309 (lr:0.0001)
165990: accuracy:0.42 loss: 199.541 (lr:0.0001)
166000: accuracy:0.42 loss: 197.749 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
166000: ********* epoch 18 ********* test accuracy for all:0.267595 test loss: 256.564
166000: ********* epoch 18 ********* test accuracy for mode 0:0.0425 test loss: 468.827
166000: ********* epoch 18 ********* test accuracy for mode 1:0.028 test loss: 455.26
166000: ********* epoch 18 ********* test accuracy for mode 2:0.08 test loss: 255.348
166000: ********* epoch 18 ********* test accuracy for mode 24:0.2875 test loss: 261.137
166000: ********* epoch 18 ********* test accuracy for mode 25:0.3275 test loss: 240.526
166000: ********* epoch 18 ********* test accuracy for mode 26:0.4335 test loss: 163.592
166000: ********* epoch 18 ********* test accuracy for mode 27:0.269 test loss: 257.764
166000: ********* epoch 18 ********* test accuracy for mode 28:0.297 test loss: 256.763
166000: ********* epoch 18 ********* test accuracy for mode 29:0.259 test loss: 266.356
166000: ********* epoch 18 ********* test accuracy for mode 30:0.2475 test loss: 247.28
166000: ********* epoch 18 ********* test accuracy for mode 31:0.2385 test loss: 246.448
166000: ********* epoch 18 ********* test accuracy for mode 32:0.187 test loss: 238.215
166000: ********* epoch 18 ********* test accuracy for mode 33:0.2565 test loss: 237.599
166000: ********* epoch 18 ********* test accuracy for mode 34:0.228 test loss: 236.847
166000: ********* epoch 18 ********* test accuracy for mode 35:0.0995 test loss: 465.355
166000: ********* epoch 18 ********* test accuracy for mode 36:0.268 test loss: 475.09
166010: accuracy:0.36 loss: 206.652 (lr:0.0001)
166020: accuracy:0.47 loss: 173.992 (lr:0.0001)
166030: accuracy:0.35 loss: 210.536 (lr:0.0001)
166040: accuracy:0.39 loss: 186.7 (lr:0.0001)
166050: accuracy:0.41 loss: 193.127 (lr:0.0001)
166060: accuracy:0.34 loss: 206.372 (lr:0.0001)
166070: accuracy:0.45 loss: 180.057 (lr:0.0001)
166080: accuracy:0.43 loss: 204.313 (lr:0.0001)
166090: accuracy:0.34 loss: 204.328 (lr:0.0001)
166100: accuracy:0.4 loss: 178.702 (lr:0.0001)
166110: accuracy:0.45 loss: 197.586 (lr:0.0001)
166120: accuracy:0.28 loss: 204.54 (lr:0.0001)
166130: accuracy:0.37 loss: 185.182 (lr:0.0001)
166140: accuracy:0.44 loss: 196.721 (lr:0.0001)
166150: accuracy:0.29 loss: 205.429 (lr:0.0001)
166160: accuracy:0.37 loss: 207.366 (lr:0.0001)
166170: accuracy:0.36 loss: 206.755 (lr:0.0001)
166180: accuracy:0.38 loss: 189.291 (lr:0.0001)
166190: accuracy:0.41 loss: 210.972 (lr:0.0001)
166200: accuracy:0.35 loss: 182.446 (lr:0.0001)
166210: accuracy:0.34 loss: 206.333 (lr:0.0001)
166220: accuracy:0.46 loss: 174.61 (lr:0.0001)
166230: accuracy:0.34 loss: 201.827 (lr:0.0001)
166240: accuracy:0.43 loss: 183.136 (lr:0.0001)
166250: accuracy:0.34 loss: 199.097 (lr:0.0001)
166260: accuracy:0.33 loss: 194.118 (lr:0.0001)
166270: accuracy:0.34 loss: 226.177 (lr:0.0001)
166280: accuracy:0.32 loss: 199.685 (lr:0.0001)
166290: accuracy:0.38 loss: 206.933 (lr:0.0001)
166300: accuracy:0.3 loss: 202.163 (lr:0.0001)
166310: accuracy:0.36 loss: 210.815 (lr:0.0001)
166320: accuracy:0.47 loss: 187.936 (lr:0.0001)
166330: accuracy:0.46 loss: 176.821 (lr:0.0001)
166340: accuracy:0.36 loss: 189.501 (lr:0.0001)
166350: accuracy:0.29 loss: 203.552 (lr:0.0001)
166360: accuracy:0.38 loss: 186.559 (lr:0.0001)
166370: accuracy:0.43 loss: 196.244 (lr:0.0001)
166380: accuracy:0.34 loss: 202.723 (lr:0.0001)
166390: accuracy:0.34 loss: 200.373 (lr:0.0001)
166400: accuracy:0.32 loss: 196.185 (lr:0.0001)
166410: accuracy:0.41 loss: 188.692 (lr:0.0001)
166420: accuracy:0.32 loss: 209.409 (lr:0.0001)
166430: accuracy:0.31 loss: 215.382 (lr:0.0001)
166440: accuracy:0.29 loss: 209.46 (lr:0.0001)
166450: accuracy:0.43 loss: 189.721 (lr:0.0001)
166460: accuracy:0.34 loss: 204.73 (lr:0.0001)
166470: accuracy:0.4 loss: 201.653 (lr:0.0001)
166480: accuracy:0.47 loss: 183.402 (lr:0.0001)
166490: accuracy:0.42 loss: 192.858 (lr:0.0001)
166500: accuracy:0.38 loss: 198.761 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
166500: ********* epoch 18 ********* test accuracy for all:0.260662 test loss: 257.89
166500: ********* epoch 18 ********* test accuracy for mode 0:0.053 test loss: 460.447
166500: ********* epoch 18 ********* test accuracy for mode 1:0.028 test loss: 454.687
166500: ********* epoch 18 ********* test accuracy for mode 2:0.0435 test loss: 260.547
166500: ********* epoch 18 ********* test accuracy for mode 24:0.229 test loss: 272.721
166500: ********* epoch 18 ********* test accuracy for mode 25:0.2855 test loss: 242.376
166500: ********* epoch 18 ********* test accuracy for mode 26:0.497 test loss: 156.872
166500: ********* epoch 18 ********* test accuracy for mode 27:0.228 test loss: 262.717
166500: ********* epoch 18 ********* test accuracy for mode 28:0.308 test loss: 257.572
166500: ********* epoch 18 ********* test accuracy for mode 29:0.2235 test loss: 272.812
166500: ********* epoch 18 ********* test accuracy for mode 30:0.2345 test loss: 248.73
166500: ********* epoch 18 ********* test accuracy for mode 31:0.219 test loss: 247.242
166500: ********* epoch 18 ********* test accuracy for mode 32:0.2205 test loss: 232.421
166500: ********* epoch 18 ********* test accuracy for mode 33:0.2895 test loss: 230.937
166500: ********* epoch 18 ********* test accuracy for mode 34:0.2745 test loss: 231.504
166500: ********* epoch 18 ********* test accuracy for mode 35:0.0985 test loss: 448.822
166500: ********* epoch 18 ********* test accuracy for mode 36:0.1485 test loss: 489.863
166510: accuracy:0.45 loss: 175.697 (lr:0.0001)
166520: accuracy:0.38 loss: 215.539 (lr:0.0001)
166530: accuracy:0.42 loss: 200.068 (lr:0.0001)
166540: accuracy:0.34 loss: 205.748 (lr:0.0001)
166550: accuracy:0.4 loss: 204.53 (lr:0.0001)
166560: accuracy:0.42 loss: 191.448 (lr:0.0001)
166570: accuracy:0.35 loss: 200.862 (lr:0.0001)
166580: accuracy:0.36 loss: 206.931 (lr:0.0001)
166590: accuracy:0.33 loss: 205.01 (lr:0.0001)
166600: accuracy:0.37 loss: 200.563 (lr:0.0001)
166610: accuracy:0.36 loss: 200.893 (lr:0.0001)
166620: accuracy:0.41 loss: 185.229 (lr:0.0001)
166630: accuracy:0.34 loss: 193.664 (lr:0.0001)
166640: accuracy:0.36 loss: 200.39 (lr:0.0001)
166650: accuracy:0.41 loss: 199.666 (lr:0.0001)
166660: accuracy:0.37 loss: 208.644 (lr:0.0001)
166670: accuracy:0.44 loss: 187.722 (lr:0.0001)
166680: accuracy:0.31 loss: 209.275 (lr:0.0001)
166690: accuracy:0.38 loss: 204.798 (lr:0.0001)
166700: accuracy:0.35 loss: 197.489 (lr:0.0001)
166710: accuracy:0.34 loss: 205.186 (lr:0.0001)
166720: accuracy:0.45 loss: 185.353 (lr:0.0001)
166730: accuracy:0.44 loss: 188.55 (lr:0.0001)
166740: accuracy:0.34 loss: 225.774 (lr:0.0001)
166750: accuracy:0.29 loss: 231.423 (lr:0.0001)
166760: accuracy:0.35 loss: 211.152 (lr:0.0001)
166770: accuracy:0.38 loss: 204.275 (lr:0.0001)
166780: accuracy:0.34 loss: 222.288 (lr:0.0001)
166790: accuracy:0.38 loss: 195.407 (lr:0.0001)
166800: accuracy:0.39 loss: 182.593 (lr:0.0001)
166810: accuracy:0.35 loss: 207.177 (lr:0.0001)
166820: accuracy:0.38 loss: 180.532 (lr:0.0001)
166830: accuracy:0.43 loss: 178.843 (lr:0.0001)
166840: accuracy:0.4 loss: 199.346 (lr:0.0001)
166850: accuracy:0.39 loss: 201.946 (lr:0.0001)
166860: accuracy:0.33 loss: 207.803 (lr:0.0001)
166870: accuracy:0.23 loss: 219.384 (lr:0.0001)
166880: accuracy:0.36 loss: 223.504 (lr:0.0001)
166890: accuracy:0.35 loss: 202.878 (lr:0.0001)
166900: accuracy:0.35 loss: 201.814 (lr:0.0001)
166910: accuracy:0.37 loss: 203.243 (lr:0.0001)
166920: accuracy:0.36 loss: 212.527 (lr:0.0001)
166930: accuracy:0.37 loss: 182.341 (lr:0.0001)
166940: accuracy:0.37 loss: 210.369 (lr:0.0001)
166950: accuracy:0.31 loss: 204.616 (lr:0.0001)
166960: accuracy:0.39 loss: 197.042 (lr:0.0001)
166970: accuracy:0.35 loss: 196.542 (lr:0.0001)
166980: accuracy:0.3 loss: 204.279 (lr:0.0001)
166990: accuracy:0.34 loss: 201.729 (lr:0.0001)
167000: accuracy:0.39 loss: 198.129 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
167000: ********* epoch 18 ********* test accuracy for all:0.265689 test loss: 256.415
167000: ********* epoch 18 ********* test accuracy for mode 0:0.04 test loss: 466.711
167000: ********* epoch 18 ********* test accuracy for mode 1:0.031 test loss: 451.286
167000: ********* epoch 18 ********* test accuracy for mode 2:0.0655 test loss: 253.256
167000: ********* epoch 18 ********* test accuracy for mode 24:0.248 test loss: 278.252
167000: ********* epoch 18 ********* test accuracy for mode 25:0.26 test loss: 255.182
167000: ********* epoch 18 ********* test accuracy for mode 26:0.5385 test loss: 159.709
167000: ********* epoch 18 ********* test accuracy for mode 27:0.204 test loss: 272.468
167000: ********* epoch 18 ********* test accuracy for mode 28:0.3155 test loss: 257.203
167000: ********* epoch 18 ********* test accuracy for mode 29:0.2325 test loss: 272.464
167000: ********* epoch 18 ********* test accuracy for mode 30:0.2065 test loss: 254.745
167000: ********* epoch 18 ********* test accuracy for mode 31:0.206 test loss: 250.243
167000: ********* epoch 18 ********* test accuracy for mode 32:0.2405 test loss: 230.347
167000: ********* epoch 18 ********* test accuracy for mode 33:0.268 test loss: 230.542
167000: ********* epoch 18 ********* test accuracy for mode 34:0.262 test loss: 230.392
167000: ********* epoch 18 ********* test accuracy for mode 35:0.128 test loss: 426.568
167000: ********* epoch 18 ********* test accuracy for mode 36:0.2915 test loss: 432.947
167010: accuracy:0.31 loss: 195.75 (lr:0.0001)
167020: accuracy:0.38 loss: 193.709 (lr:0.0001)
167030: accuracy:0.33 loss: 198.998 (lr:0.0001)
167040: accuracy:0.32 loss: 210.008 (lr:0.0001)
167050: accuracy:0.31 loss: 218.117 (lr:0.0001)
167060: accuracy:0.51 loss: 166.627 (lr:0.0001)
167070: accuracy:0.29 loss: 211.034 (lr:0.0001)
167080: accuracy:0.38 loss: 201.781 (lr:0.0001)
167090: accuracy:0.28 loss: 217.981 (lr:0.0001)
167100: accuracy:0.36 loss: 196.538 (lr:0.0001)
167110: accuracy:0.33 loss: 206.11 (lr:0.0001)
167120: accuracy:0.34 loss: 204.021 (lr:0.0001)
167130: accuracy:0.36 loss: 194.829 (lr:0.0001)
167140: accuracy:0.45 loss: 208.685 (lr:0.0001)
167150: accuracy:0.34 loss: 199.879 (lr:0.0001)
167160: accuracy:0.34 loss: 207.27 (lr:0.0001)
167170: accuracy:0.36 loss: 178.216 (lr:0.0001)
167180: accuracy:0.37 loss: 195.126 (lr:0.0001)
167190: accuracy:0.38 loss: 204.387 (lr:0.0001)
167200: accuracy:0.36 loss: 200.573 (lr:0.0001)
167210: accuracy:0.33 loss: 212.548 (lr:0.0001)
167220: accuracy:0.34 loss: 202.538 (lr:0.0001)
167230: accuracy:0.36 loss: 204.268 (lr:0.0001)
167240: accuracy:0.38 loss: 200.374 (lr:0.0001)
167250: accuracy:0.31 loss: 206.185 (lr:0.0001)
167260: accuracy:0.32 loss: 205.383 (lr:0.0001)
167270: accuracy:0.31 loss: 209.563 (lr:0.0001)
167280: accuracy:0.45 loss: 187.269 (lr:0.0001)
167290: accuracy:0.36 loss: 213.744 (lr:0.0001)
167300: accuracy:0.35 loss: 199.503 (lr:0.0001)
167310: accuracy:0.28 loss: 204.81 (lr:0.0001)
167320: accuracy:0.42 loss: 188.052 (lr:0.0001)
167330: accuracy:0.44 loss: 191.496 (lr:0.0001)
167340: accuracy:0.37 loss: 190.185 (lr:0.0001)
167350: accuracy:0.34 loss: 204.597 (lr:0.0001)
167360: accuracy:0.29 loss: 197.827 (lr:0.0001)
167370: accuracy:0.3 loss: 180.465 (lr:0.0001)
167380: accuracy:0.29 loss: 221.88 (lr:0.0001)
167390: accuracy:0.36 loss: 199.935 (lr:0.0001)
167400: accuracy:0.39 loss: 195.679 (lr:0.0001)
167410: accuracy:0.28 loss: 213.745 (lr:0.0001)
167420: accuracy:0.34 loss: 199.333 (lr:0.0001)
167430: accuracy:0.33 loss: 206.72 (lr:0.0001)
167440: accuracy:0.35 loss: 210.064 (lr:0.0001)
167450: accuracy:0.35 loss: 195.999 (lr:0.0001)
167460: accuracy:0.41 loss: 182.861 (lr:0.0001)
167470: accuracy:0.37 loss: 191.401 (lr:0.0001)
167480: accuracy:0.33 loss: 202.523 (lr:0.0001)
167490: accuracy:0.35 loss: 203.267 (lr:0.0001)
167500: accuracy:0.39 loss: 197.9 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
167500: ********* epoch 18 ********* test accuracy for all:0.257203 test loss: 257.389
167500: ********* epoch 18 ********* test accuracy for mode 0:0.044 test loss: 453.106
167500: ********* epoch 18 ********* test accuracy for mode 1:0.03 test loss: 438.978
167500: ********* epoch 18 ********* test accuracy for mode 2:0.039 test loss: 262.527
167500: ********* epoch 18 ********* test accuracy for mode 24:0.246 test loss: 275.439
167500: ********* epoch 18 ********* test accuracy for mode 25:0.2605 test loss: 250.586
167500: ********* epoch 18 ********* test accuracy for mode 26:0.493 test loss: 160.021
167500: ********* epoch 18 ********* test accuracy for mode 27:0.2445 test loss: 263.28
167500: ********* epoch 18 ********* test accuracy for mode 28:0.3065 test loss: 258.37
167500: ********* epoch 18 ********* test accuracy for mode 29:0.265 test loss: 266.098
167500: ********* epoch 18 ********* test accuracy for mode 30:0.24 test loss: 255.364
167500: ********* epoch 18 ********* test accuracy for mode 31:0.1775 test loss: 259.743
167500: ********* epoch 18 ********* test accuracy for mode 32:0.204 test loss: 237.888
167500: ********* epoch 18 ********* test accuracy for mode 33:0.284 test loss: 231.591
167500: ********* epoch 18 ********* test accuracy for mode 34:0.28 test loss: 230.125
167500: ********* epoch 18 ********* test accuracy for mode 35:0.128 test loss: 408.213
167500: ********* epoch 18 ********* test accuracy for mode 36:0.1415 test loss: 447.675
167510: accuracy:0.39 loss: 202.806 (lr:0.0001)
167520: accuracy:0.33 loss: 214.375 (lr:0.0001)
167530: accuracy:0.34 loss: 202.411 (lr:0.0001)
167540: accuracy:0.33 loss: 198.127 (lr:0.0001)
167550: accuracy:0.48 loss: 169.724 (lr:0.0001)
167560: accuracy:0.36 loss: 199.692 (lr:0.0001)
167570: accuracy:0.28 loss: 200.383 (lr:0.0001)
167580: accuracy:0.38 loss: 174.766 (lr:0.0001)
167590: accuracy:0.38 loss: 185.839 (lr:0.0001)
167600: accuracy:0.39 loss: 208.928 (lr:0.0001)
167610: accuracy:0.3 loss: 214.271 (lr:0.0001)
167620: accuracy:0.35 loss: 200.572 (lr:0.0001)
167630: accuracy:0.44 loss: 189.941 (lr:0.0001)
167640: accuracy:0.33 loss: 211.757 (lr:0.0001)
167650: accuracy:0.4 loss: 208.394 (lr:0.0001)
167660: accuracy:0.36 loss: 191.27 (lr:0.0001)
167670: accuracy:0.39 loss: 228.127 (lr:0.0001)
167680: accuracy:0.34 loss: 219.649 (lr:0.0001)
167690: accuracy:0.39 loss: 211.517 (lr:0.0001)
167700: accuracy:0.39 loss: 208.675 (lr:0.0001)
167710: accuracy:0.3 loss: 216.492 (lr:0.0001)
167720: accuracy:0.44 loss: 196.204 (lr:0.0001)
167730: accuracy:0.35 loss: 203.013 (lr:0.0001)
167740: accuracy:0.28 loss: 212.146 (lr:0.0001)
167750: accuracy:0.32 loss: 203.047 (lr:0.0001)
167760: accuracy:0.49 loss: 188.849 (lr:0.0001)
167770: accuracy:0.32 loss: 203.79 (lr:0.0001)
167780: accuracy:0.38 loss: 205.895 (lr:0.0001)
167790: accuracy:0.33 loss: 203.262 (lr:0.0001)
167800: accuracy:0.44 loss: 179.034 (lr:0.0001)
167810: accuracy:0.5 loss: 160.15 (lr:0.0001)
167820: accuracy:0.4 loss: 178.222 (lr:0.0001)
167830: accuracy:0.31 loss: 216.863 (lr:0.0001)
167840: accuracy:0.45 loss: 184.213 (lr:0.0001)
167850: accuracy:0.4 loss: 182.703 (lr:0.0001)
167860: accuracy:0.44 loss: 198.164 (lr:0.0001)
167870: accuracy:0.38 loss: 211.104 (lr:0.0001)
167880: accuracy:0.34 loss: 202.235 (lr:0.0001)
167890: accuracy:0.42 loss: 178.065 (lr:0.0001)
167900: accuracy:0.36 loss: 198.841 (lr:0.0001)
167910: accuracy:0.31 loss: 207.771 (lr:0.0001)
167920: accuracy:0.43 loss: 189.91 (lr:0.0001)
167930: accuracy:0.32 loss: 211.551 (lr:0.0001)
167940: accuracy:0.39 loss: 194.507 (lr:0.0001)
167950: accuracy:0.3 loss: 190.95 (lr:0.0001)
167960: accuracy:0.39 loss: 222.172 (lr:0.0001)
167970: accuracy:0.38 loss: 212.759 (lr:0.0001)
167980: accuracy:0.32 loss: 224.072 (lr:0.0001)
167990: accuracy:0.43 loss: 185.114 (lr:0.0001)
168000: accuracy:0.42 loss: 185.521 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
168000: ********* epoch 18 ********* test accuracy for all:0.257919 test loss: 260.21
168000: ********* epoch 18 ********* test accuracy for mode 0:0.0495 test loss: 468.409
168000: ********* epoch 18 ********* test accuracy for mode 1:0.0375 test loss: 460.965
168000: ********* epoch 18 ********* test accuracy for mode 2:0.0425 test loss: 265.489
168000: ********* epoch 18 ********* test accuracy for mode 24:0.222 test loss: 282.85
168000: ********* epoch 18 ********* test accuracy for mode 25:0.2505 test loss: 251.514
168000: ********* epoch 18 ********* test accuracy for mode 26:0.4845 test loss: 163.789
168000: ********* epoch 18 ********* test accuracy for mode 27:0.242 test loss: 264.013
168000: ********* epoch 18 ********* test accuracy for mode 28:0.299 test loss: 258.147
168000: ********* epoch 18 ********* test accuracy for mode 29:0.2395 test loss: 267.015
168000: ********* epoch 18 ********* test accuracy for mode 30:0.2845 test loss: 244.391
168000: ********* epoch 18 ********* test accuracy for mode 31:0.163 test loss: 255.609
168000: ********* epoch 18 ********* test accuracy for mode 32:0.26 test loss: 232.171
168000: ********* epoch 18 ********* test accuracy for mode 33:0.269 test loss: 234.5
168000: ********* epoch 18 ********* test accuracy for mode 34:0.21 test loss: 239.365
168000: ********* epoch 18 ********* test accuracy for mode 35:0.1115 test loss: 443.676
168000: ********* epoch 18 ********* test accuracy for mode 36:0.156 test loss: 488.32
168010: accuracy:0.37 loss: 190.086 (lr:0.0001)
168020: accuracy:0.4 loss: 190.223 (lr:0.0001)
168030: accuracy:0.45 loss: 185.169 (lr:0.0001)
168040: accuracy:0.43 loss: 192.98 (lr:0.0001)
168050: accuracy:0.42 loss: 200.295 (lr:0.0001)
168060: accuracy:0.4 loss: 188.745 (lr:0.0001)
168070: accuracy:0.37 loss: 187.662 (lr:0.0001)
168080: accuracy:0.29 loss: 215.48 (lr:0.0001)
168090: accuracy:0.39 loss: 215.72 (lr:0.0001)
168100: accuracy:0.36 loss: 188.148 (lr:0.0001)
168110: accuracy:0.41 loss: 198.855 (lr:0.0001)
168120: accuracy:0.37 loss: 219.289 (lr:0.0001)
168130: accuracy:0.45 loss: 189.06 (lr:0.0001)
168140: accuracy:0.36 loss: 207.734 (lr:0.0001)
168150: accuracy:0.37 loss: 201.377 (lr:0.0001)
168160: accuracy:0.44 loss: 177.4 (lr:0.0001)
168170: accuracy:0.39 loss: 186.598 (lr:0.0001)
168180: accuracy:0.43 loss: 187.135 (lr:0.0001)
168190: accuracy:0.42 loss: 202.414 (lr:0.0001)
168200: accuracy:0.36 loss: 194.048 (lr:0.0001)
168210: accuracy:0.3 loss: 213.762 (lr:0.0001)
168220: accuracy:0.35 loss: 181.984 (lr:0.0001)
168230: accuracy:0.36 loss: 197.136 (lr:0.0001)
168240: accuracy:0.33 loss: 212.213 (lr:0.0001)
168250: accuracy:0.27 loss: 234.797 (lr:0.0001)
168260: accuracy:0.37 loss: 204.762 (lr:0.0001)
168270: accuracy:0.38 loss: 207.437 (lr:0.0001)
168280: accuracy:0.33 loss: 212.454 (lr:0.0001)
168290: accuracy:0.34 loss: 189.8 (lr:0.0001)
168300: accuracy:0.3 loss: 215.364 (lr:0.0001)
168310: accuracy:0.32 loss: 200.417 (lr:0.0001)
168320: accuracy:0.29 loss: 222.315 (lr:0.0001)
168330: accuracy:0.37 loss: 186.321 (lr:0.0001)
168340: accuracy:0.37 loss: 200.955 (lr:0.0001)
168350: accuracy:0.32 loss: 217.295 (lr:0.0001)
168360: accuracy:0.4 loss: 192.814 (lr:0.0001)
168370: accuracy:0.39 loss: 191.464 (lr:0.0001)
168380: accuracy:0.42 loss: 198.965 (lr:0.0001)
168390: accuracy:0.44 loss: 195.657 (lr:0.0001)
168400: accuracy:0.36 loss: 180.339 (lr:0.0001)
168410: accuracy:0.33 loss: 209.483 (lr:0.0001)
168420: accuracy:0.35 loss: 215.385 (lr:0.0001)
168430: accuracy:0.39 loss: 209.361 (lr:0.0001)
168440: accuracy:0.37 loss: 207.803 (lr:0.0001)
168450: accuracy:0.38 loss: 175.122 (lr:0.0001)
168460: accuracy:0.33 loss: 191.744 (lr:0.0001)
168470: accuracy:0.41 loss: 199.24 (lr:0.0001)
168480: accuracy:0.42 loss: 182.853 (lr:0.0001)
168490: accuracy:0.33 loss: 221.334 (lr:0.0001)
168500: accuracy:0.35 loss: 190.125 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
168500: ********* epoch 18 ********* test accuracy for all:0.257757 test loss: 258.407
168500: ********* epoch 18 ********* test accuracy for mode 0:0.039 test loss: 463.453
168500: ********* epoch 18 ********* test accuracy for mode 1:0.0245 test loss: 447.861
168500: ********* epoch 18 ********* test accuracy for mode 2:0.066 test loss: 257.907
168500: ********* epoch 18 ********* test accuracy for mode 24:0.2595 test loss: 270.108
168500: ********* epoch 18 ********* test accuracy for mode 25:0.285 test loss: 241.708
168500: ********* epoch 18 ********* test accuracy for mode 26:0.502 test loss: 152.834
168500: ********* epoch 18 ********* test accuracy for mode 27:0.2705 test loss: 253.922
168500: ********* epoch 18 ********* test accuracy for mode 28:0.296 test loss: 258.676
168500: ********* epoch 18 ********* test accuracy for mode 29:0.25 test loss: 270.888
168500: ********* epoch 18 ********* test accuracy for mode 30:0.2445 test loss: 256.1
168500: ********* epoch 18 ********* test accuracy for mode 31:0.196 test loss: 261.87
168500: ********* epoch 18 ********* test accuracy for mode 32:0.179 test loss: 244.483
168500: ********* epoch 18 ********* test accuracy for mode 33:0.2895 test loss: 238.403
168500: ********* epoch 18 ********* test accuracy for mode 34:0.204 test loss: 241.045
168500: ********* epoch 18 ********* test accuracy for mode 35:0.1035 test loss: 455.062
168500: ********* epoch 18 ********* test accuracy for mode 36:0.102 test loss: 506.422
168510: accuracy:0.37 loss: 195.875 (lr:0.0001)
168520: accuracy:0.37 loss: 202.209 (lr:0.0001)
168530: accuracy:0.42 loss: 200.479 (lr:0.0001)
168540: accuracy:0.31 loss: 192.483 (lr:0.0001)
168550: accuracy:0.33 loss: 189.717 (lr:0.0001)
168560: accuracy:0.41 loss: 188.12 (lr:0.0001)
168570: accuracy:0.39 loss: 202.835 (lr:0.0001)
168580: accuracy:0.31 loss: 201.161 (lr:0.0001)
168590: accuracy:0.36 loss: 186.913 (lr:0.0001)
168600: accuracy:0.39 loss: 185.484 (lr:0.0001)
168610: accuracy:0.34 loss: 202.026 (lr:0.0001)
168620: accuracy:0.33 loss: 188.4 (lr:0.0001)
168630: accuracy:0.38 loss: 225.372 (lr:0.0001)
168640: accuracy:0.31 loss: 217.524 (lr:0.0001)
168650: accuracy:0.38 loss: 205.66 (lr:0.0001)
168660: accuracy:0.31 loss: 196.043 (lr:0.0001)
168670: accuracy:0.43 loss: 186.096 (lr:0.0001)
168680: accuracy:0.3 loss: 207.79 (lr:0.0001)
168690: accuracy:0.4 loss: 197.684 (lr:0.0001)
168700: accuracy:0.38 loss: 199.017 (lr:0.0001)
168710: accuracy:0.43 loss: 178.882 (lr:0.0001)
168720: accuracy:0.31 loss: 206.39 (lr:0.0001)
168730: accuracy:0.37 loss: 192.248 (lr:0.0001)
168740: accuracy:0.42 loss: 190.247 (lr:0.0001)
168750: accuracy:0.44 loss: 190.264 (lr:0.0001)
168760: accuracy:0.38 loss: 204.269 (lr:0.0001)
168770: accuracy:0.36 loss: 200.723 (lr:0.0001)
168780: accuracy:0.43 loss: 185.724 (lr:0.0001)
168790: accuracy:0.36 loss: 185.82 (lr:0.0001)
168800: accuracy:0.37 loss: 209.588 (lr:0.0001)
168810: accuracy:0.3 loss: 215.058 (lr:0.0001)
168820: accuracy:0.36 loss: 208.773 (lr:0.0001)
168830: accuracy:0.36 loss: 204.579 (lr:0.0001)
168840: accuracy:0.39 loss: 194.555 (lr:0.0001)
168850: accuracy:0.28 loss: 206.363 (lr:0.0001)
168860: accuracy:0.34 loss: 205.571 (lr:0.0001)
168870: accuracy:0.29 loss: 218.561 (lr:0.0001)
168880: accuracy:0.25 loss: 210.401 (lr:0.0001)
168890: accuracy:0.36 loss: 202.033 (lr:0.0001)
168900: accuracy:0.36 loss: 207.002 (lr:0.0001)
168910: accuracy:0.43 loss: 189.212 (lr:0.0001)
168920: accuracy:0.34 loss: 204.838 (lr:0.0001)
168930: accuracy:0.36 loss: 183.296 (lr:0.0001)
168940: accuracy:0.43 loss: 200.864 (lr:0.0001)
168950: accuracy:0.38 loss: 200.98 (lr:0.0001)
168960: accuracy:0.38 loss: 210.326 (lr:0.0001)
 168970: accuracy:0.28 loss: 217.762 (lr:0.0001)
168980: accuracy:0.43 loss: 173.326 (lr:0.0001)
168990: accuracy:0.26 loss: 210.29 (lr:0.0001)
169000: accuracy:0.28 loss: 208.507 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
169000: ********* epoch 18 ********* test accuracy for all:0.261784 test loss: 255.681
169000: ********* epoch 18 ********* test accuracy for mode 0:0.037 test loss: 460.73
169000: ********* epoch 18 ********* test accuracy for mode 1:0.0315 test loss: 442.486
169000: ********* epoch 18 ********* test accuracy for mode 2:0.058 test loss: 258.952
169000: ********* epoch 18 ********* test accuracy for mode 24:0.259 test loss: 271.711
169000: ********* epoch 18 ********* test accuracy for mode 25:0.2995 test loss: 243.942
169000: ********* epoch 18 ********* test accuracy for mode 26:0.4835 test loss: 158.158
169000: ********* epoch 18 ********* test accuracy for mode 27:0.2355 test loss: 260.843
169000: ********* epoch 18 ********* test accuracy for mode 28:0.29 test loss: 255.951
169000: ********* epoch 18 ********* test accuracy for mode 29:0.2745 test loss: 259.45
169000: ********* epoch 18 ********* test accuracy for mode 30:0.2325 test loss: 247.58
169000: ********* epoch 18 ********* test accuracy for mode 31:0.216 test loss: 247.108
169000: ********* epoch 18 ********* test accuracy for mode 32:0.237 test loss: 228.357
169000: ********* epoch 18 ********* test accuracy for mode 33:0.256 test loss: 233.3
169000: ********* epoch 18 ********* test accuracy for mode 34:0.2445 test loss: 235.831
169000: ********* epoch 18 ********* test accuracy for mode 35:0.1245 test loss: 443.07
169000: ********* epoch 18 ********* test accuracy for mode 36:0.0885 test loss: 491.296
169010: accuracy:0.35 loss: 182.914 (lr:0.0001)
169020: accuracy:0.35 loss: 183.286 (lr:0.0001)
169030: accuracy:0.27 loss: 218.051 (lr:0.0001)
169040: accuracy:0.43 loss: 176.29 (lr:0.0001)
169050: accuracy:0.34 loss: 204.639 (lr:0.0001)
169060: accuracy:0.41 loss: 203.289 (lr:0.0001)
169070: accuracy:0.36 loss: 207.842 (lr:0.0001)
169080: accuracy:0.32 loss: 212.764 (lr:0.0001)
169090: accuracy:0.37 loss: 195.538 (lr:0.0001)
169100: accuracy:0.28 loss: 231.36 (lr:0.0001)
169110: accuracy:0.4 loss: 214.463 (lr:0.0001)
169120: accuracy:0.37 loss: 199.805 (lr:0.0001)
169130: accuracy:0.33 loss: 216.958 (lr:0.0001)
169140: accuracy:0.32 loss: 209.569 (lr:0.0001)
169150: accuracy:0.29 loss: 226.695 (lr:0.0001)
169160: accuracy:0.34 loss: 219.817 (lr:0.0001)
169170: accuracy:0.36 loss: 212.283 (lr:0.0001)
169180: accuracy:0.34 loss: 203.734 (lr:0.0001)
169190: accuracy:0.41 loss: 195.464 (lr:0.0001)
169200: accuracy:0.43 loss: 203.274 (lr:0.0001)
169210: accuracy:0.44 loss: 189.756 (lr:0.0001)
169220: accuracy:0.39 loss: 199.338 (lr:0.0001)
169230: accuracy:0.39 loss: 176.138 (lr:0.0001)
169240: accuracy:0.3 loss: 222.773 (lr:0.0001)
169250: accuracy:0.42 loss: 182.078 (lr:0.0001)
169260: accuracy:0.34 loss: 196.168 (lr:0.0001)
169270: accuracy:0.31 loss: 208.686 (lr:0.0001)
169280: accuracy:0.39 loss: 207.248 (lr:0.0001)
169290: accuracy:0.37 loss: 191.089 (lr:0.0001)
169300: accuracy:0.4 loss: 196.802 (lr:0.0001)
169310: accuracy:0.44 loss: 185.383 (lr:0.0001)
169320: accuracy:0.33 loss: 209.684 (lr:0.0001)
169330: accuracy:0.34 loss: 200.515 (lr:0.0001)
169340: accuracy:0.3 loss: 213.094 (lr:0.0001)
169350: accuracy:0.34 loss: 224.269 (lr:0.0001)
169360: accuracy:0.35 loss: 201.325 (lr:0.0001)
169370: accuracy:0.3 loss: 223.816 (lr:0.0001)
169380: accuracy:0.38 loss: 205.368 (lr:0.0001)
169390: accuracy:0.42 loss: 202.413 (lr:0.0001)
169400: accuracy:0.33 loss: 198.172 (lr:0.0001)
169410: accuracy:0.35 loss: 192.268 (lr:0.0001)
169420: accuracy:0.35 loss: 196.036 (lr:0.0001)
169430: accuracy:0.33 loss: 216.729 (lr:0.0001)
169440: accuracy:0.37 loss: 197.006 (lr:0.0001)
169450: accuracy:0.3 loss: 213.851 (lr:0.0001)
169460: accuracy:0.37 loss: 186.749 (lr:0.0001)
169470: accuracy:0.39 loss: 176.007 (lr:0.0001)
169480: accuracy:0.33 loss: 194.146 (lr:0.0001)
169490: accuracy:0.39 loss: 197.186 (lr:0.0001)
169500: accuracy:0.29 loss: 208.64 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
169500: ********* epoch 18 ********* test accuracy for all:0.260284 test loss: 256.126
169500: ********* epoch 18 ********* test accuracy for mode 0:0.039 test loss: 466.804
169500: ********* epoch 18 ********* test accuracy for mode 1:0.025 test loss: 445.788
169500: ********* epoch 18 ********* test accuracy for mode 2:0.071 test loss: 256.55
169500: ********* epoch 18 ********* test accuracy for mode 24:0.2395 test loss: 276.036
169500: ********* epoch 18 ********* test accuracy for mode 25:0.306 test loss: 246.719
169500: ********* epoch 18 ********* test accuracy for mode 26:0.433 test loss: 166.562
169500: ********* epoch 18 ********* test accuracy for mode 27:0.2285 test loss: 269.074
169500: ********* epoch 18 ********* test accuracy for mode 28:0.285 test loss: 260.167
169500: ********* epoch 18 ********* test accuracy for mode 29:0.2475 test loss: 262.129
169500: ********* epoch 18 ********* test accuracy for mode 30:0.27 test loss: 242.101
169500: ********* epoch 18 ********* test accuracy for mode 31:0.172 test loss: 249.949
169500: ********* epoch 18 ********* test accuracy for mode 32:0.2425 test loss: 226.415
169500: ********* epoch 18 ********* test accuracy for mode 33:0.3015 test loss: 227.708
169500: ********* epoch 18 ********* test accuracy for mode 34:0.204 test loss: 236.564
169500: ********* epoch 18 ********* test accuracy for mode 35:0.106 test loss: 452.442
169500: ********* epoch 18 ********* test accuracy for mode 36:0.166 test loss: 479.886
169510: accuracy:0.35 loss: 197.545 (lr:0.0001)
169520: accuracy:0.48 loss: 170.736 (lr:0.0001)
169530: accuracy:0.37 loss: 197.409 (lr:0.0001)
169540: accuracy:0.32 loss: 199.595 (lr:0.0001)
169550: accuracy:0.29 loss: 229.041 (lr:0.0001)
169560: accuracy:0.28 loss: 223.695 (lr:0.0001)
169570: accuracy:0.33 loss: 211.935 (lr:0.0001)
169580: accuracy:0.33 loss: 210.001 (lr:0.0001)
169590: accuracy:0.37 loss: 173.09 (lr:0.0001)
169600: accuracy:0.38 loss: 199.053 (lr:0.0001)
169610: accuracy:0.43 loss: 188.038 (lr:0.0001)
169620: accuracy:0.35 loss: 183.496 (lr:0.0001)
169630: accuracy:0.39 loss: 199.969 (lr:0.0001)
169640: accuracy:0.34 loss: 200.584 (lr:0.0001)
169650: accuracy:0.36 loss: 203.836 (lr:0.0001)
169660: accuracy:0.3 loss: 222.695 (lr:0.0001)
169670: accuracy:0.32 loss: 204.818 (lr:0.0001)
169680: accuracy:0.3 loss: 210.287 (lr:0.0001)
169690: accuracy:0.39 loss: 197.085 (lr:0.0001)
169700: accuracy:0.33 loss: 196.041 (lr:0.0001)
169710: accuracy:0.34 loss: 221.577 (lr:0.0001)
169720: accuracy:0.5 loss: 166.872 (lr:0.0001)
169730: accuracy:0.36 loss: 193.172 (lr:0.0001)
169740: accuracy:0.31 loss: 207.073 (lr:0.0001)
169750: accuracy:0.32 loss: 207.065 (lr:0.0001)
169760: accuracy:0.36 loss: 205.564 (lr:0.0001)
169770: accuracy:0.4 loss: 194.98 (lr:0.0001)
169780: accuracy:0.3 loss: 220.49 (lr:0.0001)
169790: accuracy:0.41 loss: 191.635 (lr:0.0001)
169800: accuracy:0.27 loss: 217.608 (lr:0.0001)
169810: accuracy:0.4 loss: 171.084 (lr:0.0001)
169820: accuracy:0.37 loss: 199.55 (lr:0.0001)
169830: accuracy:0.41 loss: 187.849 (lr:0.0001)
169840: accuracy:0.44 loss: 186.735 (lr:0.0001)
169850: accuracy:0.39 loss: 184.62 (lr:0.0001)
169860: accuracy:0.31 loss: 199.433 (lr:0.0001)
169870: accuracy:0.34 loss: 204.094 (lr:0.0001)
169880: accuracy:0.35 loss: 214.419 (lr:0.0001)
169890: accuracy:0.38 loss: 197.741 (lr:0.0001)
169900: accuracy:0.4 loss: 194.177 (lr:0.0001)
169910: accuracy:0.38 loss: 196.84 (lr:0.0001)
169920: accuracy:0.34 loss: 208.656 (lr:0.0001)
169930: accuracy:0.4 loss: 208.216 (lr:0.0001)
169940: accuracy:0.37 loss: 190.089 (lr:0.0001)
169950: accuracy:0.43 loss: 184.059 (lr:0.0001)
169960: accuracy:0.36 loss: 213.358 (lr:0.0001)
169970: accuracy:0.43 loss: 212.647 (lr:0.0001)
169980: accuracy:0.41 loss: 202.884 (lr:0.0001)
169990: accuracy:0.4 loss: 189.782 (lr:0.0001)
170000: accuracy:0.47 loss: 168.466 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
170000: ********* epoch 18 ********* test accuracy for all:0.259041 test loss: 257.583
170000: ********* epoch 18 ********* test accuracy for mode 0:0.0505 test loss: 460.473
170000: ********* epoch 18 ********* test accuracy for mode 1:0.0345 test loss: 442.477
170000: ********* epoch 18 ********* test accuracy for mode 2:0.0715 test loss: 252.252
170000: ********* epoch 18 ********* test accuracy for mode 24:0.226 test loss: 283.872
170000: ********* epoch 18 ********* test accuracy for mode 25:0.278 test loss: 254.158
170000: ********* epoch 18 ********* test accuracy for mode 26:0.479 test loss: 164.712
170000: ********* epoch 18 ********* test accuracy for mode 27:0.2665 test loss: 262.741
170000: ********* epoch 18 ********* test accuracy for mode 28:0.273 test loss: 261.565
170000: ********* epoch 18 ********* test accuracy for mode 29:0.2485 test loss: 267.467
170000: ********* epoch 18 ********* test accuracy for mode 30:0.2325 test loss: 250.825
170000: ********* epoch 18 ********* test accuracy for mode 31:0.1675 test loss: 256.288
170000: ********* epoch 18 ********* test accuracy for mode 32:0.2215 test loss: 231.082
170000: ********* epoch 18 ********* test accuracy for mode 33:0.301 test loss: 226.942
170000: ********* epoch 18 ********* test accuracy for mode 34:0.264 test loss: 229.482
170000: ********* epoch 18 ********* test accuracy for mode 35:0.1265 test loss: 446.184
170000: ********* epoch 18 ********* test accuracy for mode 36:0.166 test loss: 475.21
170010: accuracy:0.32 loss: 212.086 (lr:0.0001)
170020: accuracy:0.33 loss: 177.357 (lr:0.0001)
170030: accuracy:0.39 loss: 203.189 (lr:0.0001)
170040: accuracy:0.42 loss: 190.403 (lr:0.0001)
170050: accuracy:0.27 loss: 220.397 (lr:0.0001)
170060: accuracy:0.45 loss: 177.933 (lr:0.0001)
170070: accuracy:0.39 loss: 180.427 (lr:0.0001)
170080: accuracy:0.32 loss: 211.624 (lr:0.0001)
170090: accuracy:0.33 loss: 198.915 (lr:0.0001)
170100: accuracy:0.28 loss: 224.154 (lr:0.0001)
170110: accuracy:0.37 loss: 198.015 (lr:0.0001)
170120: accuracy:0.37 loss: 190.412 (lr:0.0001)
170130: accuracy:0.39 loss: 193.784 (lr:0.0001)
170140: accuracy:0.4 loss: 184.316 (lr:0.0001)
170150: accuracy:0.33 loss: 198.393 (lr:0.0001)
170160: accuracy:0.33 loss: 211.903 (lr:0.0001)
170170: accuracy:0.3 loss: 216.084 (lr:0.0001)
170180: accuracy:0.35 loss: 214.553 (lr:0.0001)
170190: accuracy:0.33 loss: 196.162 (lr:0.0001)
170200: accuracy:0.41 loss: 199.432 (lr:0.0001)
170210: accuracy:0.42 loss: 196.365 (lr:0.0001)
170220: accuracy:0.39 loss: 203.01 (lr:0.0001)
170230: accuracy:0.39 loss: 188.164 (lr:0.0001)
170240: accuracy:0.32 loss: 208.677 (lr:0.0001)
170250: accuracy:0.4 loss: 190.706 (lr:0.0001)
170260: accuracy:0.34 loss: 208.97 (lr:0.0001)
170270: accuracy:0.4 loss: 206.811 (lr:0.0001)
170280: accuracy:0.26 loss: 208.781 (lr:0.0001)
170290: accuracy:0.35 loss: 194.007 (lr:0.0001)
170300: accuracy:0.31 loss: 228.489 (lr:0.0001)
170310: accuracy:0.28 loss: 202.555 (lr:0.0001)
170320: accuracy:0.28 loss: 205.417 (lr:0.0001)
170330: accuracy:0.3 loss: 221.281 (lr:0.0001)
170340: accuracy:0.39 loss: 207.194 (lr:0.0001)
170350: accuracy:0.44 loss: 191.267 (lr:0.0001)
170360: accuracy:0.4 loss: 204.749 (lr:0.0001)
170370: accuracy:0.31 loss: 195.311 (lr:0.0001)
170380: accuracy:0.31 loss: 188.032 (lr:0.0001)
170390: accuracy:0.4 loss: 219.284 (lr:0.0001)
170400: accuracy:0.35 loss: 215.549 (lr:0.0001)
170410: accuracy:0.31 loss: 208.203 (lr:0.0001)
170420: accuracy:0.36 loss: 190.216 (lr:0.0001)
170430: accuracy:0.36 loss: 195.048 (lr:0.0001)
170440: accuracy:0.35 loss: 204.308 (lr:0.0001)
170450: accuracy:0.39 loss: 191.051 (lr:0.0001)
170460: accuracy:0.38 loss: 192.933 (lr:0.0001)
170470: accuracy:0.37 loss: 191.868 (lr:0.0001)
170480: accuracy:0.34 loss: 211.658 (lr:0.0001)
170490: accuracy:0.39 loss: 205.541 (lr:0.0001)
170500: accuracy:0.36 loss: 226.833 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
170500: ********* epoch 18 ********* test accuracy for all:0.255973 test loss: 258.079
170500: ********* epoch 18 ********* test accuracy for mode 0:0.046 test loss: 458.586
170500: ********* epoch 18 ********* test accuracy for mode 1:0.029 test loss: 441.053
170500: ********* epoch 18 ********* test accuracy for mode 2:0.059 test loss: 259.672
170500: ********* epoch 18 ********* test accuracy for mode 24:0.2335 test loss: 280.827
170500: ********* epoch 18 ********* test accuracy for mode 25:0.287 test loss: 253.089
170500: ********* epoch 18 ********* test accuracy for mode 26:0.481 test loss: 166.485
170500: ********* epoch 18 ********* test accuracy for mode 27:0.242 test loss: 268.613
170500: ********* epoch 18 ********* test accuracy for mode 28:0.291 test loss: 262.049
170500: ********* epoch 18 ********* test accuracy for mode 29:0.268 test loss: 272.385
170500: ********* epoch 18 ********* test accuracy for mode 30:0.2305 test loss: 255.026
170500: ********* epoch 18 ********* test accuracy for mode 31:0.1895 test loss: 259.806
170500: ********* epoch 18 ********* test accuracy for mode 32:0.1825 test loss: 241.746
170500: ********* epoch 18 ********* test accuracy for mode 33:0.258 test loss: 238.858
170500: ********* epoch 18 ********* test accuracy for mode 34:0.2415 test loss: 236.871
170500: ********* epoch 18 ********* test accuracy for mode 35:0.117 test loss: 438.818
170500: ********* epoch 18 ********* test accuracy for mode 36:0.088 test loss: 500.392
170510: accuracy:0.31 loss: 218.511 (lr:0.0001)
170520: accuracy:0.37 loss: 194.317 (lr:0.0001)
170530: accuracy:0.38 loss: 206.571 (lr:0.0001)
170540: accuracy:0.42 loss: 191.319 (lr:0.0001)
170550: accuracy:0.43 loss: 194.564 (lr:0.0001)
170560: accuracy:0.41 loss: 199.93 (lr:0.0001)
170570: accuracy:0.39 loss: 196.698 (lr:0.0001)
170580: accuracy:0.39 loss: 202.822 (lr:0.0001)
170590: accuracy:0.4 loss: 177.379 (lr:0.0001)
170600: accuracy:0.33 loss: 210.249 (lr:0.0001)
170610: accuracy:0.39 loss: 206.948 (lr:0.0001)
170620: accuracy:0.37 loss: 197.132 (lr:0.0001)
170630: accuracy:0.4 loss: 184.128 (lr:0.0001)
170640: accuracy:0.36 loss: 192.567 (lr:0.0001)
170650: accuracy:0.29 loss: 193.624 (lr:0.0001)
170660: accuracy:0.39 loss: 193.961 (lr:0.0001)
170670: accuracy:0.3 loss: 187.576 (lr:0.0001)
170680: accuracy:0.41 loss: 184.399 (lr:0.0001)
170690: accuracy:0.33 loss: 200.671 (lr:0.0001)
170700: accuracy:0.33 loss: 221.462 (lr:0.0001)
170710: accuracy:0.37 loss: 189.79 (lr:0.0001)
170720: accuracy:0.33 loss: 210.11 (lr:0.0001)
170730: accuracy:0.3 loss: 213.134 (lr:0.0001)
170740: accuracy:0.35 loss: 202.539 (lr:0.0001)
170750: accuracy:0.36 loss: 222.892 (lr:0.0001)
170760: accuracy:0.29 loss: 211.945 (lr:0.0001)
170770: accuracy:0.29 loss: 219.488 (lr:0.0001)
170780: accuracy:0.32 loss: 190.645 (lr:0.0001)
170790: accuracy:0.29 loss: 211.75 (lr:0.0001)
170800: accuracy:0.33 loss: 231.27 (lr:0.0001)
170810: accuracy:0.39 loss: 210.046 (lr:0.0001)
170820: accuracy:0.28 loss: 221.877 (lr:0.0001)
170830: accuracy:0.34 loss: 210.168 (lr:0.0001)
170840: accuracy:0.37 loss: 195.184 (lr:0.0001)
170850: accuracy:0.35 loss: 186.253 (lr:0.0001)
170860: accuracy:0.31 loss: 203.356 (lr:0.0001)
170870: accuracy:0.39 loss: 195.841 (lr:0.0001)
170880: accuracy:0.36 loss: 208.12 (lr:0.0001)
170890: accuracy:0.44 loss: 198.611 (lr:0.0001)
170900: accuracy:0.26 loss: 212.582 (lr:0.0001)
170910: accuracy:0.35 loss: 206.132 (lr:0.0001)
170920: accuracy:0.28 loss: 216.203 (lr:0.0001)
170930: accuracy:0.32 loss: 205.397 (lr:0.0001)
170940: accuracy:0.38 loss: 204.165 (lr:0.0001)
170950: accuracy:0.37 loss: 202.299 (lr:0.0001)
170960: accuracy:0.33 loss: 210.216 (lr:0.0001)
170970: accuracy:0.35 loss: 184.767 (lr:0.0001)
170980: accuracy:0.43 loss: 192.239 (lr:0.0001)
170990: accuracy:0.36 loss: 188.352 (lr:0.0001)
171000: accuracy:0.31 loss: 204.155 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
171000: ********* epoch 18 ********* test accuracy for all:0.260946 test loss: 257.678
171000: ********* epoch 18 ********* test accuracy for mode 0:0.042 test loss: 468.112
171000: ********* epoch 18 ********* test accuracy for mode 1:0.021 test loss: 449.693
171000: ********* epoch 18 ********* test accuracy for mode 2:0.0565 test loss: 264.925
171000: ********* epoch 18 ********* test accuracy for mode 24:0.292 test loss: 260.528
171000: ********* epoch 18 ********* test accuracy for mode 25:0.2865 test loss: 245.16
171000: ********* epoch 18 ********* test accuracy for mode 26:0.5355 test loss: 155.067
171000: ********* epoch 18 ********* test accuracy for mode 27:0.27 test loss: 255.653
171000: ********* epoch 18 ********* test accuracy for mode 28:0.3425 test loss: 247.848
171000: ********* epoch 18 ********* test accuracy for mode 29:0.253 test loss: 268.808
171000: ********* epoch 18 ********* test accuracy for mode 30:0.2215 test loss: 254.893
171000: ********* epoch 18 ********* test accuracy for mode 31:0.1765 test loss: 255.974
171000: ********* epoch 18 ********* test accuracy for mode 32:0.231 test loss: 233.293
171000: ********* epoch 18 ********* test accuracy for mode 33:0.2875 test loss: 235.125
171000: ********* epoch 18 ********* test accuracy for mode 34:0.2 test loss: 239.952
171000: ********* epoch 18 ********* test accuracy for mode 35:0.067 test loss: 469.561
171000: ********* epoch 18 ********* test accuracy for mode 36:0.0895 test loss: 515.1
171010: accuracy:0.37 loss: 183.731 (lr:0.0001)
171020: accuracy:0.35 loss: 193.362 (lr:0.0001)
171030: accuracy:0.33 loss: 199.743 (lr:0.0001)
171040: accuracy:0.39 loss: 212.778 (lr:0.0001)
171050: accuracy:0.29 loss: 215.531 (lr:0.0001)
171060: accuracy:0.39 loss: 186.161 (lr:0.0001)
171070: accuracy:0.31 loss: 218.23 (lr:0.0001)
171080: accuracy:0.46 loss: 175.253 (lr:0.0001)
171090: accuracy:0.42 loss: 208.051 (lr:0.0001)
171100: accuracy:0.32 loss: 211.101 (lr:0.0001)
171110: accuracy:0.35 loss: 200.856 (lr:0.0001)
171120: accuracy:0.4 loss: 191.674 (lr:0.0001)
171130: accuracy:0.36 loss: 204.062 (lr:0.0001)
171140: accuracy:0.31 loss: 204.187 (lr:0.0001)
171150: accuracy:0.31 loss: 222.379 (lr:0.0001)
171160: accuracy:0.42 loss: 180.887 (lr:0.0001)
171170: accuracy:0.39 loss: 189.034 (lr:0.0001)
171180: accuracy:0.36 loss: 203.398 (lr:0.0001)
171190: accuracy:0.34 loss: 212.284 (lr:0.0001)
171200: accuracy:0.38 loss: 207.093 (lr:0.0001)
171210: accuracy:0.37 loss: 202.123 (lr:0.0001)
171220: accuracy:0.38 loss: 196.559 (lr:0.0001)
171230: accuracy:0.35 loss: 179.016 (lr:0.0001)
171240: accuracy:0.4 loss: 207.974 (lr:0.0001)
171250: accuracy:0.41 loss: 204.395 (lr:0.0001)
171260: accuracy:0.29 loss: 201.618 (lr:0.0001)
171270: accuracy:0.29 loss: 214.566 (lr:0.0001)
171280: accuracy:0.38 loss: 209.439 (lr:0.0001)
171290: accuracy:0.43 loss: 175.595 (lr:0.0001)
171300: accuracy:0.26 loss: 211.581 (lr:0.0001)
171310: accuracy:0.42 loss: 184.394 (lr:0.0001)
171320: accuracy:0.39 loss: 185.101 (lr:0.0001)
171330: accuracy:0.34 loss: 200.515 (lr:0.0001)
171340: accuracy:0.44 loss: 181.814 (lr:0.0001)
171350: accuracy:0.35 loss: 202.651 (lr:0.0001)
171360: accuracy:0.44 loss: 180.669 (lr:0.0001)
171370: accuracy:0.32 loss: 197.624 (lr:0.0001)
171380: accuracy:0.38 loss: 194.501 (lr:0.0001)
171390: accuracy:0.35 loss: 189.909 (lr:0.0001)
171400: accuracy:0.34 loss: 205.938 (lr:0.0001)
171410: accuracy:0.36 loss: 204.482 (lr:0.0001)
171420: accuracy:0.45 loss: 188.902 (lr:0.0001)
171430: accuracy:0.28 loss: 214.576 (lr:0.0001)
171440: accuracy:0.37 loss: 218.262 (lr:0.0001)
171450: accuracy:0.39 loss: 181.837 (lr:0.0001)
171460: accuracy:0.41 loss: 185.412 (lr:0.0001)
171470: accuracy:0.33 loss: 213.825 (lr:0.0001)
171480: accuracy:0.49 loss: 169.704 (lr:0.0001)
171490: accuracy:0.33 loss: 203.001 (lr:0.0001)
171500: accuracy:0.39 loss: 198.619 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
171500: ********* epoch 18 ********* test accuracy for all:0.261432 test loss: 258.993
171500: ********* epoch 18 ********* test accuracy for mode 0:0.0445 test loss: 467.454
171500: ********* epoch 18 ********* test accuracy for mode 1:0.0285 test loss: 456.218
171500: ********* epoch 18 ********* test accuracy for mode 2:0.0705 test loss: 257.667
171500: ********* epoch 18 ********* test accuracy for mode 24:0.271 test loss: 268.53
171500: ********* epoch 18 ********* test accuracy for mode 25:0.2775 test loss: 245.266
171500: ********* epoch 18 ********* test accuracy for mode 26:0.5285 test loss: 155.408
171500: ********* epoch 18 ********* test accuracy for mode 27:0.2135 test loss: 269.297
171500: ********* epoch 18 ********* test accuracy for mode 28:0.2955 test loss: 259.673
171500: ********* epoch 18 ********* test accuracy for mode 29:0.264 test loss: 269.109
171500: ********* epoch 18 ********* test accuracy for mode 30:0.2215 test loss: 255.792
171500: ********* epoch 18 ********* test accuracy for mode 31:0.189 test loss: 258.103
171500: ********* epoch 18 ********* test accuracy for mode 32:0.213 test loss: 236.63
171500: ********* epoch 18 ********* test accuracy for mode 33:0.261 test loss: 236.628
171500: ********* epoch 18 ********* test accuracy for mode 34:0.255 test loss: 234.155
171500: ********* epoch 18 ********* test accuracy for mode 35:0.101 test loss: 460.463
171500: ********* epoch 18 ********* test accuracy for mode 36:0.1735 test loss: 503.233
171510: accuracy:0.35 loss: 210.608 (lr:0.0001)
171520: accuracy:0.39 loss: 210.295 (lr:0.0001)
171530: accuracy:0.34 loss: 196.762 (lr:0.0001)
171540: accuracy:0.33 loss: 214.816 (lr:0.0001)
171550: accuracy:0.34 loss: 233.034 (lr:0.0001)
171560: accuracy:0.41 loss: 195.144 (lr:0.0001)
171570: accuracy:0.33 loss: 207.506 (lr:0.0001)
171580: accuracy:0.41 loss: 189.711 (lr:0.0001)
171590: accuracy:0.35 loss: 210.915 (lr:0.0001)
171600: accuracy:0.39 loss: 204.8 (lr:0.0001)
171610: accuracy:0.38 loss: 198.921 (lr:0.0001)
171620: accuracy:0.32 loss: 212.152 (lr:0.0001)
171630: accuracy:0.39 loss: 202.643 (lr:0.0001)
171640: accuracy:0.33 loss: 220.843 (lr:0.0001)
171650: accuracy:0.41 loss: 207.277 (lr:0.0001)
171660: accuracy:0.42 loss: 210.173 (lr:0.0001)
171670: accuracy:0.37 loss: 197.098 (lr:0.0001)
171680: accuracy:0.39 loss: 208.642 (lr:0.0001)
171690: accuracy:0.45 loss: 186.509 (lr:0.0001)
171700: accuracy:0.32 loss: 194.428 (lr:0.0001)
171710: accuracy:0.3 loss: 215.423 (lr:0.0001)
171720: accuracy:0.32 loss: 221.37 (lr:0.0001)
171730: accuracy:0.36 loss: 205.452 (lr:0.0001)
171740: accuracy:0.41 loss: 201.051 (lr:0.0001)
171750: accuracy:0.44 loss: 185.103 (lr:0.0001)
171760: accuracy:0.33 loss: 191.547 (lr:0.0001)
171770: accuracy:0.29 loss: 219.709 (lr:0.0001)
171780: accuracy:0.3 loss: 207.058 (lr:0.0001)
171790: accuracy:0.47 loss: 171.066 (lr:0.0001)
171800: accuracy:0.32 loss: 213.675 (lr:0.0001)
171810: accuracy:0.3 loss: 220.974 (lr:0.0001)
171820: accuracy:0.32 loss: 216.162 (lr:0.0001)
171830: accuracy:0.37 loss: 209.887 (lr:0.0001)
171840: accuracy:0.37 loss: 189.249 (lr:0.0001)
171850: accuracy:0.38 loss: 202.032 (lr:0.0001)
171860: accuracy:0.37 loss: 188.673 (lr:0.0001)
171870: accuracy:0.4 loss: 195.7 (lr:0.0001)
171880: accuracy:0.28 loss: 208.112 (lr:0.0001)
171890: accuracy:0.39 loss: 194.252 (lr:0.0001)
171900: accuracy:0.35 loss: 210.345 (lr:0.0001)
171910: accuracy:0.4 loss: 183.342 (lr:0.0001)
171920: accuracy:0.29 loss: 217.76 (lr:0.0001)
171930: accuracy:0.44 loss: 183.141 (lr:0.0001)
171940: accuracy:0.35 loss: 227.181 (lr:0.0001)
171950: accuracy:0.47 loss: 192.209 (lr:0.0001)
171960: accuracy:0.43 loss: 188.522 (lr:0.0001)
171970: accuracy:0.37 loss: 192.853 (lr:0.0001)
171980: accuracy:0.4 loss: 182.07 (lr:0.0001)
171990: accuracy:0.36 loss: 193.644 (lr:0.0001)
172000: accuracy:0.43 loss: 187.924 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
172000: ********* epoch 18 ********* test accuracy for all:0.258486 test loss: 257.037
172000: ********* epoch 18 ********* test accuracy for mode 0:0.0435 test loss: 458.834
172000: ********* epoch 18 ********* test accuracy for mode 1:0.0265 test loss: 446.774
172000: ********* epoch 18 ********* test accuracy for mode 2:0.0635 test loss: 256.116
172000: ********* epoch 18 ********* test accuracy for mode 24:0.238 test loss: 277.643
172000: ********* epoch 18 ********* test accuracy for mode 25:0.2385 test loss: 253.983
172000: ********* epoch 18 ********* test accuracy for mode 26:0.512 test loss: 160.571
172000: ********* epoch 18 ********* test accuracy for mode 27:0.2375 test loss: 265.283
172000: ********* epoch 18 ********* test accuracy for mode 28:0.26 test loss: 266.058
172000: ********* epoch 18 ********* test accuracy for mode 29:0.243 test loss: 270.806
172000: ********* epoch 18 ********* test accuracy for mode 30:0.2205 test loss: 254.29
172000: ********* epoch 18 ********* test accuracy for mode 31:0.2045 test loss: 253.361
172000: ********* epoch 18 ********* test accuracy for mode 32:0.1905 test loss: 235.916
172000: ********* epoch 18 ********* test accuracy for mode 33:0.281 test loss: 232.671
172000: ********* epoch 18 ********* test accuracy for mode 34:0.249 test loss: 231.969
172000: ********* epoch 18 ********* test accuracy for mode 35:0.103 test loss: 445.069
172000: ********* epoch 18 ********* test accuracy for mode 36:0.2225 test loss: 479.729
172010: accuracy:0.39 loss: 194.689 (lr:0.0001)
172020: accuracy:0.42 loss: 185.878 (lr:0.0001)
172030: accuracy:0.29 loss: 224.791 (lr:0.0001)
172040: accuracy:0.34 loss: 197.364 (lr:0.0001)
172050: accuracy:0.44 loss: 187.213 (lr:0.0001)
172060: accuracy:0.27 loss: 208.675 (lr:0.0001)
172070: accuracy:0.37 loss: 213.13 (lr:0.0001)
172080: accuracy:0.41 loss: 181.84 (lr:0.0001)
172090: accuracy:0.35 loss: 210.542 (lr:0.0001)
172100: accuracy:0.37 loss: 200.745 (lr:0.0001)
172110: accuracy:0.36 loss: 193.936 (lr:0.0001)
172120: accuracy:0.41 loss: 181.929 (lr:0.0001)
172130: accuracy:0.3 loss: 196.633 (lr:0.0001)
172140: accuracy:0.3 loss: 213.532 (lr:0.0001)
172150: accuracy:0.37 loss: 207.928 (lr:0.0001)
172160: accuracy:0.36 loss: 195.51 (lr:0.0001)
172170: accuracy:0.34 loss: 194.516 (lr:0.0001)
172180: accuracy:0.22 loss: 209.505 (lr:0.0001)
172190: accuracy:0.38 loss: 206.802 (lr:0.0001)
172200: accuracy:0.41 loss: 189.795 (lr:0.0001)
172210: accuracy:0.34 loss: 213.827 (lr:0.0001)
172220: accuracy:0.35 loss: 210.932 (lr:0.0001)
172230: accuracy:0.31 loss: 227.734 (lr:0.0001)
172240: accuracy:0.34 loss: 217.238 (lr:0.0001)
172250: accuracy:0.3 loss: 228.267 (lr:0.0001)
172260: accuracy:0.39 loss: 179.722 (lr:0.0001)
172270: accuracy:0.33 loss: 196.513 (lr:0.0001)
172280: accuracy:0.38 loss: 201.904 (lr:0.0001)
172290: accuracy:0.28 loss: 205.0 (lr:0.0001)
172300: accuracy:0.37 loss: 217.001 (lr:0.0001)
172310: accuracy:0.4 loss: 193.376 (lr:0.0001)
172320: accuracy:0.31 loss: 208.704 (lr:0.0001)
172330: accuracy:0.46 loss: 180.349 (lr:0.0001)
172340: accuracy:0.35 loss: 219.328 (lr:0.0001)
172350: accuracy:0.42 loss: 203.533 (lr:0.0001)
172360: accuracy:0.38 loss: 205.453 (lr:0.0001)
172370: accuracy:0.38 loss: 221.575 (lr:0.0001)
172380: accuracy:0.36 loss: 191.084 (lr:0.0001)
172390: accuracy:0.33 loss: 213.0 (lr:0.0001)
172400: accuracy:0.44 loss: 164.883 (lr:0.0001)
172410: accuracy:0.31 loss: 216.609 (lr:0.0001)
172420: accuracy:0.4 loss: 226.029 (lr:0.0001)
172430: accuracy:0.34 loss: 189.854 (lr:0.0001)
172440: accuracy:0.33 loss: 218.552 (lr:0.0001)
172450: accuracy:0.43 loss: 187.957 (lr:0.0001)
172460: accuracy:0.38 loss: 201.165 (lr:0.0001)
172470: accuracy:0.45 loss: 185.891 (lr:0.0001)
172480: accuracy:0.37 loss: 182.114 (lr:0.0001)
172490: accuracy:0.38 loss: 173.844 (lr:0.0001)
172500: accuracy:0.33 loss: 216.936 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
172500: ********* epoch 18 ********* test accuracy for all:0.261959 test loss: 258.462
172500: ********* epoch 18 ********* test accuracy for mode 0:0.036 test loss: 464.227
172500: ********* epoch 18 ********* test accuracy for mode 1:0.0255 test loss: 452.277
172500: ********* epoch 18 ********* test accuracy for mode 2:0.046 test loss: 257.964
172500: ********* epoch 18 ********* test accuracy for mode 24:0.2725 test loss: 272.151
172500: ********* epoch 18 ********* test accuracy for mode 25:0.272 test loss: 251.707
172500: ********* epoch 18 ********* test accuracy for mode 26:0.5175 test loss: 160.12
172500: ********* epoch 18 ********* test accuracy for mode 27:0.2035 test loss: 273.822
172500: ********* epoch 18 ********* test accuracy for mode 28:0.3095 test loss: 260.579
172500: ********* epoch 18 ********* test accuracy for mode 29:0.241 test loss: 271.823
172500: ********* epoch 18 ********* test accuracy for mode 30:0.255 test loss: 251.138
172500: ********* epoch 18 ********* test accuracy for mode 31:0.177 test loss: 255.98
172500: ********* epoch 18 ********* test accuracy for mode 32:0.197 test loss: 234.603
172500: ********* epoch 18 ********* test accuracy for mode 33:0.2775 test loss: 230.888
172500: ********* epoch 18 ********* test accuracy for mode 34:0.2445 test loss: 230.462
172500: ********* epoch 18 ********* test accuracy for mode 35:0.1245 test loss: 416.917
172500: ********* epoch 18 ********* test accuracy for mode 36:0.295 test loss: 438.429
172510: accuracy:0.33 loss: 195.601 (lr:0.0001)
172520: accuracy:0.4 loss: 174.011 (lr:0.0001)
172530: accuracy:0.42 loss: 189.007 (lr:0.0001)
172540: accuracy:0.48 loss: 165.257 (lr:0.0001)
172550: accuracy:0.35 loss: 217.542 (lr:0.0001)
172560: accuracy:0.36 loss: 195.025 (lr:0.0001)
172570: accuracy:0.29 loss: 216.204 (lr:0.0001)
172580: accuracy:0.24 loss: 215.239 (lr:0.0001)
172590: accuracy:0.38 loss: 196.214 (lr:0.0001)
172600: accuracy:0.35 loss: 203.611 (lr:0.0001)
172610: accuracy:0.38 loss: 197.373 (lr:0.0001)
172620: accuracy:0.32 loss: 205.146 (lr:0.0001)
172630: accuracy:0.35 loss: 195.393 (lr:0.0001)
172640: accuracy:0.33 loss: 204.703 (lr:0.0001)
172650: accuracy:0.37 loss: 194.928 (lr:0.0001)
172660: accuracy:0.41 loss: 189.156 (lr:0.0001)
172670: accuracy:0.3 loss: 196.906 (lr:0.0001)
172680: accuracy:0.34 loss: 226.166 (lr:0.0001)
172690: accuracy:0.32 loss: 200.269 (lr:0.0001)
172700: accuracy:0.35 loss: 218.979 (lr:0.0001)
172710: accuracy:0.31 loss: 210.646 (lr:0.0001)
172720: accuracy:0.36 loss: 191.572 (lr:0.0001)
172730: accuracy:0.5 loss: 187.87 (lr:0.0001)
172740: accuracy:0.28 loss: 218.781 (lr:0.0001)
172750: accuracy:0.39 loss: 200.805 (lr:0.0001)
172760: accuracy:0.35 loss: 198.63 (lr:0.0001)
172770: accuracy:0.39 loss: 190.799 (lr:0.0001)
172780: accuracy:0.45 loss: 174.239 (lr:0.0001)
172790: accuracy:0.44 loss: 182.234 (lr:0.0001)
172800: accuracy:0.36 loss: 208.138 (lr:0.0001)
172810: accuracy:0.32 loss: 197.86 (lr:0.0001)
172820: accuracy:0.26 loss: 239.108 (lr:0.0001)
172830: accuracy:0.45 loss: 190.346 (lr:0.0001)
172840: accuracy:0.35 loss: 224.276 (lr:0.0001)
172850: accuracy:0.44 loss: 180.07 (lr:0.0001)
172860: accuracy:0.43 loss: 184.882 (lr:0.0001)
172870: accuracy:0.41 loss: 195.246 (lr:0.0001)
172880: accuracy:0.32 loss: 230.233 (lr:0.0001)
172890: accuracy:0.35 loss: 214.312 (lr:0.0001)
172900: accuracy:0.33 loss: 225.928 (lr:0.0001)
172910: accuracy:0.3 loss: 217.493 (lr:0.0001)
172920: accuracy:0.37 loss: 214.149 (lr:0.0001)
172930: accuracy:0.41 loss: 192.572 (lr:0.0001)
172940: accuracy:0.35 loss: 203.58 (lr:0.0001)
172950: accuracy:0.3 loss: 203.295 (lr:0.0001)
172960: accuracy:0.41 loss: 198.841 (lr:0.0001)
172970: accuracy:0.47 loss: 169.945 (lr:0.0001)
172980: accuracy:0.39 loss: 200.243 (lr:0.0001)
172990: accuracy:0.32 loss: 218.041 (lr:0.0001)
173000: accuracy:0.35 loss: 197.11 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
173000: ********* epoch 18 ********* test accuracy for all:0.265216 test loss: 255.026
173000: ********* epoch 18 ********* test accuracy for mode 0:0.038 test loss: 466.504
173000: ********* epoch 18 ********* test accuracy for mode 1:0.0245 test loss: 452.059
173000: ********* epoch 18 ********* test accuracy for mode 2:0.0545 test loss: 265.716
173000: ********* epoch 18 ********* test accuracy for mode 24:0.243 test loss: 272.42
173000: ********* epoch 18 ********* test accuracy for mode 25:0.3205 test loss: 239.712
173000: ********* epoch 18 ********* test accuracy for mode 26:0.4545 test loss: 166.806
173000: ********* epoch 18 ********* test accuracy for mode 27:0.254 test loss: 258.744
173000: ********* epoch 18 ********* test accuracy for mode 28:0.315 test loss: 252.624
173000: ********* epoch 18 ********* test accuracy for mode 29:0.2265 test loss: 268.469
173000: ********* epoch 18 ********* test accuracy for mode 30:0.2605 test loss: 245.264
173000: ********* epoch 18 ********* test accuracy for mode 31:0.22 test loss: 246.814
173000: ********* epoch 18 ********* test accuracy for mode 32:0.1925 test loss: 231.516
173000: ********* epoch 18 ********* test accuracy for mode 33:0.299 test loss: 229.17
173000: ********* epoch 18 ********* test accuracy for mode 34:0.2225 test loss: 235.172
173000: ********* epoch 18 ********* test accuracy for mode 35:0.1175 test loss: 439.162
173000: ********* epoch 18 ********* test accuracy for mode 36:0.2335 test loss: 470.507
173010: accuracy:0.37 loss: 192.1 (lr:0.0001)
173020: accuracy:0.38 loss: 190.089 (lr:0.0001)
173030: accuracy:0.38 loss: 195.15 (lr:0.0001)
173040: accuracy:0.33 loss: 212.607 (lr:0.0001)
173050: accuracy:0.39 loss: 192.355 (lr:0.0001)
173060: accuracy:0.3 loss: 201.876 (lr:0.0001)
173070: accuracy:0.41 loss: 192.675 (lr:0.0001)
173080: accuracy:0.23 loss: 216.377 (lr:0.0001)
173090: accuracy:0.38 loss: 193.572 (lr:0.0001)
173100: accuracy:0.3 loss: 208.94 (lr:0.0001)
173110: accuracy:0.4 loss: 183.673 (lr:0.0001)
173120: accuracy:0.33 loss: 192.429 (lr:0.0001)
173130: accuracy:0.37 loss: 193.839 (lr:0.0001)
173140: accuracy:0.37 loss: 195.312 (lr:0.0001)
173150: accuracy:0.39 loss: 188.289 (lr:0.0001)
173160: accuracy:0.32 loss: 208.515 (lr:0.0001)
173170: accuracy:0.34 loss: 194.013 (lr:0.0001)
173180: accuracy:0.34 loss: 203.859 (lr:0.0001)
173190: accuracy:0.38 loss: 191.176 (lr:0.0001)
173200: accuracy:0.41 loss: 199.352 (lr:0.0001)
173210: accuracy:0.46 loss: 190.658 (lr:0.0001)
173220: accuracy:0.35 loss: 199.09 (lr:0.0001)
173230: accuracy:0.33 loss: 202.012 (lr:0.0001)
173240: accuracy:0.35 loss: 211.473 (lr:0.0001)
173250: accuracy:0.36 loss: 222.524 (lr:0.0001)
173260: accuracy:0.34 loss: 186.625 (lr:0.0001)
173270: accuracy:0.39 loss: 193.172 (lr:0.0001)
173280: accuracy:0.33 loss: 218.469 (lr:0.0001)
173290: accuracy:0.39 loss: 213.121 (lr:0.0001)
173300: accuracy:0.33 loss: 195.967 (lr:0.0001)
173310: accuracy:0.35 loss: 194.195 (lr:0.0001)
173320: accuracy:0.37 loss: 184.91 (lr:0.0001)
173330: accuracy:0.38 loss: 193.384 (lr:0.0001)
173340: accuracy:0.49 loss: 169.135 (lr:0.0001)
173350: accuracy:0.39 loss: 184.119 (lr:0.0001)
173360: accuracy:0.42 loss: 193.299 (lr:0.0001)
173370: accuracy:0.33 loss: 197.385 (lr:0.0001)
173380: accuracy:0.37 loss: 209.808 (lr:0.0001)
173390: accuracy:0.36 loss: 203.781 (lr:0.0001)
173400: accuracy:0.39 loss: 186.516 (lr:0.0001)
173410: accuracy:0.36 loss: 205.115 (lr:0.0001)
173420: accuracy:0.37 loss: 211.87 (lr:0.0001)
173430: accuracy:0.27 loss: 212.411 (lr:0.0001)
173440: accuracy:0.36 loss: 191.333 (lr:0.0001)
173450: accuracy:0.31 loss: 208.969 (lr:0.0001)
173460: accuracy:0.37 loss: 210.815 (lr:0.0001)
173470: accuracy:0.31 loss: 212.404 (lr:0.0001)
173480: accuracy:0.31 loss: 201.918 (lr:0.0001)
173490: accuracy:0.25 loss: 205.076 (lr:0.0001)
173500: accuracy:0.37 loss: 205.632 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
173500: ********* epoch 18 ********* test accuracy for all:0.261284 test loss: 256.678
173500: ********* epoch 18 ********* test accuracy for mode 0:0.0375 test loss: 467.427
173500: ********* epoch 18 ********* test accuracy for mode 1:0.0265 test loss: 445.004
173500: ********* epoch 18 ********* test accuracy for mode 2:0.092 test loss: 253.6
173500: ********* epoch 18 ********* test accuracy for mode 24:0.251 test loss: 270.089
173500: ********* epoch 18 ********* test accuracy for mode 25:0.3085 test loss: 238.642
173500: ********* epoch 18 ********* test accuracy for mode 26:0.47 test loss: 160.68
173500: ********* epoch 18 ********* test accuracy for mode 27:0.2125 test loss: 273.684
173500: ********* epoch 18 ********* test accuracy for mode 28:0.268 test loss: 263.06
173500: ********* epoch 18 ********* test accuracy for mode 29:0.2575 test loss: 267.657
173500: ********* epoch 18 ********* test accuracy for mode 30:0.2145 test loss: 256.312
173500: ********* epoch 18 ********* test accuracy for mode 31:0.19 test loss: 257.435
173500: ********* epoch 18 ********* test accuracy for mode 32:0.258 test loss: 234.257
173500: ********* epoch 18 ********* test accuracy for mode 33:0.2695 test loss: 238.961
173500: ********* epoch 18 ********* test accuracy for mode 34:0.197 test loss: 242.374
173500: ********* epoch 18 ********* test accuracy for mode 35:0.115 test loss: 440.125
173500: ********* epoch 18 ********* test accuracy for mode 36:0.116 test loss: 496.055
173510: accuracy:0.28 loss: 208.588 (lr:0.0001)
173520: accuracy:0.43 loss: 209.626 (lr:0.0001)
173530: accuracy:0.32 loss: 185.797 (lr:0.0001)
173540: accuracy:0.33 loss: 216.798 (lr:0.0001)
173550: accuracy:0.44 loss: 173.469 (lr:0.0001)
173560: accuracy:0.42 loss: 182.619 (lr:0.0001)
173570: accuracy:0.32 loss: 217.528 (lr:0.0001)
173580: accuracy:0.46 loss: 182.739 (lr:0.0001)
173590: accuracy:0.39 loss: 186.202 (lr:0.0001)
173600: accuracy:0.39 loss: 195.718 (lr:0.0001)
173610: accuracy:0.42 loss: 192.082 (lr:0.0001)
173620: accuracy:0.34 loss: 198.194 (lr:0.0001)
173630: accuracy:0.4 loss: 186.395 (lr:0.0001)
173640: accuracy:0.37 loss: 197.674 (lr:0.0001)
173650: accuracy:0.39 loss: 190.662 (lr:0.0001)
173660: accuracy:0.45 loss: 180.193 (lr:0.0001)
173670: accuracy:0.34 loss: 229.486 (lr:0.0001)
173680: accuracy:0.39 loss: 184.336 (lr:0.0001)
173690: accuracy:0.42 loss: 191.878 (lr:0.0001)
173700: accuracy:0.31 loss: 203.975 (lr:0.0001)
173710: accuracy:0.44 loss: 176.208 (lr:0.0001)
173720: accuracy:0.39 loss: 191.474 (lr:0.0001)
173730: accuracy:0.34 loss: 217.346 (lr:0.0001)
173740: accuracy:0.4 loss: 197.918 (lr:0.0001)
173750: accuracy:0.29 loss: 212.388 (lr:0.0001)
173760: accuracy:0.4 loss: 175.887 (lr:0.0001)
173770: accuracy:0.37 loss: 199.045 (lr:0.0001)
173780: accuracy:0.36 loss: 206.385 (lr:0.0001)
173790: accuracy:0.32 loss: 232.662 (lr:0.0001)
173800: accuracy:0.38 loss: 185.173 (lr:0.0001)
173810: accuracy:0.35 loss: 207.662 (lr:0.0001)
173820: accuracy:0.33 loss: 198.725 (lr:0.0001)
173830: accuracy:0.37 loss: 217.49 (lr:0.0001)
173840: accuracy:0.32 loss: 212.536 (lr:0.0001)
173850: accuracy:0.38 loss: 206.288 (lr:0.0001)
173860: accuracy:0.29 loss: 205.171 (lr:0.0001)
173870: accuracy:0.44 loss: 205.09 (lr:0.0001)
173880: accuracy:0.38 loss: 199.51 (lr:0.0001)
173890: accuracy:0.3 loss: 203.411 (lr:0.0001)
173900: accuracy:0.34 loss: 188.523 (lr:0.0001)
173910: accuracy:0.38 loss: 204.901 (lr:0.0001)
173920: accuracy:0.32 loss: 189.501 (lr:0.0001)
173930: accuracy:0.33 loss: 200.604 (lr:0.0001)
173940: accuracy:0.44 loss: 199.335 (lr:0.0001)
173950: accuracy:0.4 loss: 203.737 (lr:0.0001)
173960: accuracy:0.38 loss: 216.481 (lr:0.0001)
173970: accuracy:0.36 loss: 204.638 (lr:0.0001)
173980: accuracy:0.29 loss: 217.154 (lr:0.0001)
173990: accuracy:0.37 loss: 224.868 (lr:0.0001)
174000: accuracy:0.33 loss: 205.563 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
174000: ********* epoch 18 ********* test accuracy for all:0.263797 test loss: 257.709
174000: ********* epoch 18 ********* test accuracy for mode 0:0.042 test loss: 462.183
174000: ********* epoch 18 ********* test accuracy for mode 1:0.03 test loss: 449.803
174000: ********* epoch 18 ********* test accuracy for mode 2:0.0465 test loss: 259.544
174000: ********* epoch 18 ********* test accuracy for mode 24:0.221 test loss: 281.576
174000: ********* epoch 18 ********* test accuracy for mode 25:0.276 test loss: 249.425
174000: ********* epoch 18 ********* test accuracy for mode 26:0.479 test loss: 162.844
174000: ********* epoch 18 ********* test accuracy for mode 27:0.2615 test loss: 268.362
174000: ********* epoch 18 ********* test accuracy for mode 28:0.2885 test loss: 258.652
174000: ********* epoch 18 ********* test accuracy for mode 29:0.2585 test loss: 265.429
174000: ********* epoch 18 ********* test accuracy for mode 30:0.2535 test loss: 246.764
174000: ********* epoch 18 ********* test accuracy for mode 31:0.198 test loss: 248.348
174000: ********* epoch 18 ********* test accuracy for mode 32:0.2265 test loss: 230.257
174000: ********* epoch 18 ********* test accuracy for mode 33:0.292 test loss: 228.794
174000: ********* epoch 18 ********* test accuracy for mode 34:0.296 test loss: 227.252
174000: ********* epoch 18 ********* test accuracy for mode 35:0.0595 test loss: 477.335
174000: ********* epoch 18 ********* test accuracy for mode 36:0.227 test loss: 493.173
174010: accuracy:0.34 loss: 209.724 (lr:0.0001)
174020: accuracy:0.4 loss: 197.149 (lr:0.0001)
174030: accuracy:0.35 loss: 210.988 (lr:0.0001)
174040: accuracy:0.4 loss: 194.531 (lr:0.0001)
174050: accuracy:0.34 loss: 203.756 (lr:0.0001)
174060: accuracy:0.42 loss: 181.575 (lr:0.0001)
174070: accuracy:0.34 loss: 214.143 (lr:0.0001)
174080: accuracy:0.43 loss: 193.35 (lr:0.0001)
174090: accuracy:0.41 loss: 205.19 (lr:0.0001)
174100: accuracy:0.4 loss: 210.136 (lr:0.0001)
174110: accuracy:0.41 loss: 198.257 (lr:0.0001)
174120: accuracy:0.31 loss: 215.633 (lr:0.0001)
174130: accuracy:0.37 loss: 184.813 (lr:0.0001)
174140: accuracy:0.36 loss: 210.265 (lr:0.0001)
174150: accuracy:0.4 loss: 183.01 (lr:0.0001)
174160: accuracy:0.38 loss: 191.994 (lr:0.0001)
174170: accuracy:0.42 loss: 192.575 (lr:0.0001)
174180: accuracy:0.36 loss: 199.833 (lr:0.0001)
174190: accuracy:0.41 loss: 183.851 (lr:0.0001)
174200: accuracy:0.4 loss: 186.479 (lr:0.0001)
174210: accuracy:0.4 loss: 194.246 (lr:0.0001)
174220: accuracy:0.29 loss: 244.407 (lr:0.0001)
174230: accuracy:0.36 loss: 201.723 (lr:0.0001)
174240: accuracy:0.31 loss: 200.128 (lr:0.0001)
174250: accuracy:0.35 loss: 174.748 (lr:0.0001)
174260: accuracy:0.37 loss: 188.717 (lr:0.0001)
174270: accuracy:0.37 loss: 178.836 (lr:0.0001)
174280: accuracy:0.3 loss: 192.941 (lr:0.0001)
174290: accuracy:0.3 loss: 214.258 (lr:0.0001)
174300: accuracy:0.46 loss: 189.209 (lr:0.0001)
174310: accuracy:0.34 loss: 189.78 (lr:0.0001)
174320: accuracy:0.33 loss: 200.939 (lr:0.0001)
174330: accuracy:0.31 loss: 207.381 (lr:0.0001)
174340: accuracy:0.44 loss: 175.921 (lr:0.0001)
174350: accuracy:0.33 loss: 209.79 (lr:0.0001)
174360: accuracy:0.27 loss: 205.308 (lr:0.0001)
174370: accuracy:0.41 loss: 205.98 (lr:0.0001)
174380: accuracy:0.39 loss: 187.426 (lr:0.0001)
174390: accuracy:0.31 loss: 199.752 (lr:0.0001)
174400: accuracy:0.39 loss: 201.851 (lr:0.0001)
174410: accuracy:0.37 loss: 200.458 (lr:0.0001)
174420: accuracy:0.4 loss: 209.583 (lr:0.0001)
174430: accuracy:0.36 loss: 213.63 (lr:0.0001)
174440: accuracy:0.48 loss: 184.034 (lr:0.0001)
174450: accuracy:0.34 loss: 215.46 (lr:0.0001)
174460: accuracy:0.35 loss: 197.377 (lr:0.0001)
174470: accuracy:0.38 loss: 196.202 (lr:0.0001)
174480: accuracy:0.28 loss: 224.302 (lr:0.0001)
174490: accuracy:0.38 loss: 204.54 (lr:0.0001)
174500: accuracy:0.33 loss: 208.383 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
174500: ********* epoch 18 ********* test accuracy for all:0.259757 test loss: 255.893
174500: ********* epoch 18 ********* test accuracy for mode 0:0.046 test loss: 463.005
174500: ********* epoch 18 ********* test accuracy for mode 1:0.0335 test loss: 444.717
174500: ********* epoch 18 ********* test accuracy for mode 2:0.056 test loss: 261.365
174500: ********* epoch 18 ********* test accuracy for mode 24:0.2575 test loss: 276.944
174500: ********* epoch 18 ********* test accuracy for mode 25:0.2715 test loss: 248.8
174500: ********* epoch 18 ********* test accuracy for mode 26:0.5115 test loss: 161.349
174500: ********* epoch 18 ********* test accuracy for mode 27:0.2405 test loss: 269.545
174500: ********* epoch 18 ********* test accuracy for mode 28:0.278 test loss: 265.717
174500: ********* epoch 18 ********* test accuracy for mode 29:0.2185 test loss: 275.586
174500: ********* epoch 18 ********* test accuracy for mode 30:0.252 test loss: 253.2
174500: ********* epoch 18 ********* test accuracy for mode 31:0.198 test loss: 252.043
174500: ********* epoch 18 ********* test accuracy for mode 32:0.2195 test loss: 233.839
174500: ********* epoch 18 ********* test accuracy for mode 33:0.287 test loss: 233.921
174500: ********* epoch 18 ********* test accuracy for mode 34:0.2585 test loss: 237.424
174500: ********* epoch 18 ********* test accuracy for mode 35:0.094 test loss: 439.442
174500: ********* epoch 18 ********* test accuracy for mode 36:0.1025 test loss: 477.853
174510: accuracy:0.4 loss: 176.27 (lr:0.0001)
174520: accuracy:0.41 loss: 201.076 (lr:0.0001)
174530: accuracy:0.44 loss: 185.988 (lr:0.0001)
174540: accuracy:0.31 loss: 213.867 (lr:0.0001)
174550: accuracy:0.51 loss: 159.303 (lr:0.0001)
174560: accuracy:0.38 loss: 196.248 (lr:0.0001)
174570: accuracy:0.41 loss: 188.238 (lr:0.0001)
174580: accuracy:0.39 loss: 202.194 (lr:0.0001)
174590: accuracy:0.33 loss: 197.974 (lr:0.0001)
174600: accuracy:0.43 loss: 181.794 (lr:0.0001)
174610: accuracy:0.32 loss: 182.671 (lr:0.0001)
174620: accuracy:0.27 loss: 221.345 (lr:0.0001)
174630: accuracy:0.37 loss: 191.329 (lr:0.0001)
174640: accuracy:0.43 loss: 191.19 (lr:0.0001)
174650: accuracy:0.34 loss: 196.267 (lr:0.0001)
174660: accuracy:0.43 loss: 182.294 (lr:0.0001)
174670: accuracy:0.33 loss: 197.731 (lr:0.0001)
174680: accuracy:0.29 loss: 209.922 (lr:0.0001)
174690: accuracy:0.45 loss: 181.378 (lr:0.0001)
174700: accuracy:0.46 loss: 183.559 (lr:0.0001)
174710: accuracy:0.38 loss: 182.698 (lr:0.0001)
174720: accuracy:0.33 loss: 202.024 (lr:0.0001)
174730: accuracy:0.34 loss: 190.734 (lr:0.0001)
174740: accuracy:0.38 loss: 195.078 (lr:0.0001)
174750: accuracy:0.4 loss: 206.473 (lr:0.0001)
174760: accuracy:0.36 loss: 204.985 (lr:0.0001)
174770: accuracy:0.4 loss: 196.375 (lr:0.0001)
174780: accuracy:0.41 loss: 173.602 (lr:0.0001)
174790: accuracy:0.35 loss: 210.697 (lr:0.0001)
174800: accuracy:0.33 loss: 192.416 (lr:0.0001)
174810: accuracy:0.35 loss: 215.461 (lr:0.0001)
174820: accuracy:0.44 loss: 195.775 (lr:0.0001)
174830: accuracy:0.39 loss: 201.114 (lr:0.0001)
174840: accuracy:0.25 loss: 229.864 (lr:0.0001)
174850: accuracy:0.35 loss: 204.274 (lr:0.0001)
174860: accuracy:0.38 loss: 197.498 (lr:0.0001)
174870: accuracy:0.4 loss: 180.983 (lr:0.0001)
174880: accuracy:0.41 loss: 200.936 (lr:0.0001)
174890: accuracy:0.4 loss: 192.756 (lr:0.0001)
174900: accuracy:0.37 loss: 192.481 (lr:0.0001)
174910: accuracy:0.31 loss: 221.09 (lr:0.0001)
174920: accuracy:0.34 loss: 212.656 (lr:0.0001)
174930: accuracy:0.32 loss: 210.598 (lr:0.0001)
174940: accuracy:0.37 loss: 192.883 (lr:0.0001)
174950: accuracy:0.32 loss: 215.094 (lr:0.0001)
174960: accuracy:0.48 loss: 165.517 (lr:0.0001)
174970: accuracy:0.38 loss: 199.774 (lr:0.0001)
174980: accuracy:0.31 loss: 194.039 (lr:0.0001)
174990: accuracy:0.35 loss: 207.275 (lr:0.0001)
175000: accuracy:0.43 loss: 203.158 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
175000: ********* epoch 18 ********* test accuracy for all:0.257676 test loss: 260.197
175000: ********* epoch 18 ********* test accuracy for mode 0:0.0455 test loss: 472.622
175000: ********* epoch 18 ********* test accuracy for mode 1:0.028 test loss: 456.782
175000: ********* epoch 18 ********* test accuracy for mode 2:0.062 test loss: 255.863
175000: ********* epoch 18 ********* test accuracy for mode 24:0.2455 test loss: 286.45
175000: ********* epoch 18 ********* test accuracy for mode 25:0.2535 test loss: 258.66
175000: ********* epoch 18 ********* test accuracy for mode 26:0.543 test loss: 162.32
175000: ********* epoch 18 ********* test accuracy for mode 27:0.2155 test loss: 279.754
175000: ********* epoch 18 ********* test accuracy for mode 28:0.265 test loss: 273.749
175000: ********* epoch 18 ********* test accuracy for mode 29:0.242 test loss: 276.794
175000: ********* epoch 18 ********* test accuracy for mode 30:0.2055 test loss: 261.49
175000: ********* epoch 18 ********* test accuracy for mode 31:0.216 test loss: 252.798
175000: ********* epoch 18 ********* test accuracy for mode 32:0.2355 test loss: 231.973
175000: ********* epoch 18 ********* test accuracy for mode 33:0.2675 test loss: 228.517
175000: ********* epoch 18 ********* test accuracy for mode 34:0.318 test loss: 223.668
175000: ********* epoch 18 ********* test accuracy for mode 35:0.0995 test loss: 429.405
175000: ********* epoch 18 ********* test accuracy for mode 36:0.099 test loss: 495.835
175010: accuracy:0.45 loss: 184.642 (lr:0.0001)
175020: accuracy:0.35 loss: 186.954 (lr:0.0001)
175030: accuracy:0.4 loss: 198.534 (lr:0.0001)
175040: accuracy:0.43 loss: 171.969 (lr:0.0001)
175050: accuracy:0.35 loss: 199.339 (lr:0.0001)
175060: accuracy:0.38 loss: 196.125 (lr:0.0001)
175070: accuracy:0.33 loss: 205.431 (lr:0.0001)
175080: accuracy:0.41 loss: 211.513 (lr:0.0001)
175090: accuracy:0.46 loss: 178.205 (lr:0.0001)
175100: accuracy:0.32 loss: 224.346 (lr:0.0001)
175110: accuracy:0.31 loss: 214.131 (lr:0.0001)
175120: accuracy:0.3 loss: 216.434 (lr:0.0001)
175130: accuracy:0.39 loss: 190.411 (lr:0.0001)
175140: accuracy:0.35 loss: 181.006 (lr:0.0001)
175150: accuracy:0.33 loss: 202.645 (lr:0.0001)
175160: accuracy:0.41 loss: 195.137 (lr:0.0001)
175170: accuracy:0.28 loss: 210.121 (lr:0.0001)
175180: accuracy:0.37 loss: 189.297 (lr:0.0001)
175190: accuracy:0.41 loss: 182.066 (lr:0.0001)
175200: accuracy:0.37 loss: 197.291 (lr:0.0001)
175210: accuracy:0.41 loss: 188.986 (lr:0.0001)
175220: accuracy:0.38 loss: 207.184 (lr:0.0001)
175230: accuracy:0.32 loss: 205.397 (lr:0.0001)
175240: accuracy:0.42 loss: 186.198 (lr:0.0001)
175250: accuracy:0.31 loss: 201.761 (lr:0.0001)
175260: accuracy:0.43 loss: 206.359 (lr:0.0001)
175270: accuracy:0.39 loss: 183.791 (lr:0.0001)
175280: accuracy:0.43 loss: 193.865 (lr:0.0001)
175290: accuracy:0.43 loss: 188.744 (lr:0.0001)
175300: accuracy:0.35 loss: 208.69 (lr:0.0001)
175310: accuracy:0.41 loss: 181.319 (lr:0.0001)
175320: accuracy:0.49 loss: 161.254 (lr:0.0001)
175330: accuracy:0.45 loss: 190.668 (lr:0.0001)
175340: accuracy:0.4 loss: 188.689 (lr:0.0001)
175350: accuracy:0.29 loss: 213.85 (lr:0.0001)
175360: accuracy:0.38 loss: 193.808 (lr:0.0001)
175370: accuracy:0.34 loss: 196.828 (lr:0.0001)
175380: accuracy:0.42 loss: 204.129 (lr:0.0001)
175390: accuracy:0.38 loss: 204.154 (lr:0.0001)
175400: accuracy:0.36 loss: 205.465 (lr:0.0001)
175410: accuracy:0.44 loss: 185.385 (lr:0.0001)
175420: accuracy:0.33 loss: 213.108 (lr:0.0001)
175430: accuracy:0.46 loss: 160.148 (lr:0.0001)
175440: accuracy:0.39 loss: 202.625 (lr:0.0001)
175450: accuracy:0.41 loss: 178.316 (lr:0.0001)
175460: accuracy:0.37 loss: 184.896 (lr:0.0001)
175470: accuracy:0.48 loss: 180.544 (lr:0.0001)
175480: accuracy:0.37 loss: 178.203 (lr:0.0001)
175490: accuracy:0.37 loss: 217.89 (lr:0.0001)
175500: accuracy:0.47 loss: 178.787 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
175500: ********* epoch 19 ********* test accuracy for all:0.261284 test loss: 256.308
175500: ********* epoch 19 ********* test accuracy for mode 0:0.0395 test loss: 465.401
175500: ********* epoch 19 ********* test accuracy for mode 1:0.0295 test loss: 443.6
175500: ********* epoch 19 ********* test accuracy for mode 2:0.069 test loss: 258.272
175500: ********* epoch 19 ********* test accuracy for mode 24:0.2415 test loss: 282.32
175500: ********* epoch 19 ********* test accuracy for mode 25:0.269 test loss: 251.49
175500: ********* epoch 19 ********* test accuracy for mode 26:0.516 test loss: 160.971
175500: ********* epoch 19 ********* test accuracy for mode 27:0.2375 test loss: 266.238
175500: ********* epoch 19 ********* test accuracy for mode 28:0.313 test loss: 259.245
175500: ********* epoch 19 ********* test accuracy for mode 29:0.2495 test loss: 271.148
175500: ********* epoch 19 ********* test accuracy for mode 30:0.2305 test loss: 260.774
175500: ********* epoch 19 ********* test accuracy for mode 31:0.1775 test loss: 257.368
175500: ********* epoch 19 ********* test accuracy for mode 32:0.279 test loss: 230.76
175500: ********* epoch 19 ********* test accuracy for mode 33:0.2285 test loss: 238.195
175500: ********* epoch 19 ********* test accuracy for mode 34:0.264 test loss: 235.675
175500: ********* epoch 19 ********* test accuracy for mode 35:0.1305 test loss: 433.203
175500: ********* epoch 19 ********* test accuracy for mode 36:0.092 test loss: 486.885
175510: accuracy:0.33 loss: 200.676 (lr:0.0001)
175520: accuracy:0.4 loss: 198.756 (lr:0.0001)
175530: accuracy:0.4 loss: 208.006 (lr:0.0001)
175540: accuracy:0.38 loss: 195.244 (lr:0.0001)
175550: accuracy:0.33 loss: 204.541 (lr:0.0001)
175560: accuracy:0.35 loss: 189.27 (lr:0.0001)
175570: accuracy:0.37 loss: 189.033 (lr:0.0001)
175580: accuracy:0.36 loss: 216.324 (lr:0.0001)
175590: accuracy:0.29 loss: 216.537 (lr:0.0001)
175600: accuracy:0.37 loss: 206.794 (lr:0.0001)
175610: accuracy:0.39 loss: 196.426 (lr:0.0001)
175620: accuracy:0.41 loss: 176.814 (lr:0.0001)
175630: accuracy:0.3 loss: 201.944 (lr:0.0001)
175640: accuracy:0.37 loss: 197.209 (lr:0.0001)
175650: accuracy:0.32 loss: 219.958 (lr:0.0001)
175660: accuracy:0.36 loss: 206.946 (lr:0.0001)
175670: accuracy:0.32 loss: 196.536 (lr:0.0001)
175680: accuracy:0.43 loss: 204.165 (lr:0.0001)
175690: accuracy:0.31 loss: 209.452 (lr:0.0001)
175700: accuracy:0.5 loss: 176.358 (lr:0.0001)
175710: accuracy:0.43 loss: 196.0 (lr:0.0001)
175720: accuracy:0.35 loss: 206.898 (lr:0.0001)
175730: accuracy:0.45 loss: 194.978 (lr:0.0001)
175740: accuracy:0.36 loss: 193.199 (lr:0.0001)
175750: accuracy:0.4 loss: 201.204 (lr:0.0001)
175760: accuracy:0.37 loss: 204.392 (lr:0.0001)
175770: accuracy:0.27 loss: 205.463 (lr:0.0001)
175780: accuracy:0.36 loss: 185.499 (lr:0.0001)
175790: accuracy:0.38 loss: 200.229 (lr:0.0001)
175800: accuracy:0.42 loss: 176.615 (lr:0.0001)
175810: accuracy:0.4 loss: 178.319 (lr:0.0001)
175820: accuracy:0.39 loss: 195.867 (lr:0.0001)
175830: accuracy:0.39 loss: 192.679 (lr:0.0001)
175840: accuracy:0.42 loss: 194.057 (lr:0.0001)
175850: accuracy:0.29 loss: 213.975 (lr:0.0001)
175860: accuracy:0.37 loss: 190.698 (lr:0.0001)
175870: accuracy:0.34 loss: 194.5 (lr:0.0001)
175880: accuracy:0.35 loss: 192.821 (lr:0.0001)
175890: accuracy:0.38 loss: 195.096 (lr:0.0001)
175900: accuracy:0.43 loss: 179.81 (lr:0.0001)
175910: accuracy:0.37 loss: 189.196 (lr:0.0001)
175920: accuracy:0.35 loss: 211.134 (lr:0.0001)
175930: accuracy:0.4 loss: 186.983 (lr:0.0001)
175940: accuracy:0.49 loss: 165.36 (lr:0.0001)
175950: accuracy:0.46 loss: 206.182 (lr:0.0001)
175960: accuracy:0.42 loss: 187.505 (lr:0.0001)
175970: accuracy:0.34 loss: 196.694 (lr:0.0001)
175980: accuracy:0.34 loss: 184.507 (lr:0.0001)
175990: accuracy:0.38 loss: 198.166 (lr:0.0001)
176000: accuracy:0.41 loss: 201.982 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
176000: ********* epoch 19 ********* test accuracy for all:0.258905 test loss: 259.626
176000: ********* epoch 19 ********* test accuracy for mode 0:0.043 test loss: 472.204
176000: ********* epoch 19 ********* test accuracy for mode 1:0.034 test loss: 456.723
176000: ********* epoch 19 ********* test accuracy for mode 2:0.083 test loss: 252.965
176000: ********* epoch 19 ********* test accuracy for mode 24:0.248 test loss: 281.731
176000: ********* epoch 19 ********* test accuracy for mode 25:0.294 test loss: 247.302
176000: ********* epoch 19 ********* test accuracy for mode 26:0.5005 test loss: 160.668
176000: ********* epoch 19 ********* test accuracy for mode 27:0.238 test loss: 267.54
176000: ********* epoch 19 ********* test accuracy for mode 28:0.278 test loss: 265.034
176000: ********* epoch 19 ********* test accuracy for mode 29:0.2275 test loss: 276.247
176000: ********* epoch 19 ********* test accuracy for mode 30:0.2435 test loss: 255.094
176000: ********* epoch 19 ********* test accuracy for mode 31:0.187 test loss: 251.022
176000: ********* epoch 19 ********* test accuracy for mode 32:0.2365 test loss: 230.285
176000: ********* epoch 19 ********* test accuracy for mode 33:0.279 test loss: 228.966
176000: ********* epoch 19 ********* test accuracy for mode 34:0.2625 test loss: 230.234
176000: ********* epoch 19 ********* test accuracy for mode 35:0.095 test loss: 448.691
176000: ********* epoch 19 ********* test accuracy for mode 36:0.1155 test loss: 496.317
176010: accuracy:0.28 loss: 211.479 (lr:0.0001)
176020: accuracy:0.39 loss: 197.57 (lr:0.0001)
176030: accuracy:0.39 loss: 198.113 (lr:0.0001)
176040: accuracy:0.4 loss: 194.072 (lr:0.0001)
176050: accuracy:0.47 loss: 190.01 (lr:0.0001)
176060: accuracy:0.35 loss: 196.373 (lr:0.0001)
176070: accuracy:0.3 loss: 178.472 (lr:0.0001)
176080: accuracy:0.38 loss: 182.944 (lr:0.0001)
176090: accuracy:0.35 loss: 198.256 (lr:0.0001)
176100: accuracy:0.4 loss: 176.582 (lr:0.0001)
176110: accuracy:0.35 loss: 196.517 (lr:0.0001)
176120: accuracy:0.38 loss: 210.185 (lr:0.0001)
176130: accuracy:0.42 loss: 188.517 (lr:0.0001)
176140: accuracy:0.42 loss: 188.15 (lr:0.0001)
176150: accuracy:0.27 loss: 231.063 (lr:0.0001)
176160: accuracy:0.31 loss: 212.56 (lr:0.0001)
176170: accuracy:0.35 loss: 213.952 (lr:0.0001)
176180: accuracy:0.32 loss: 213.929 (lr:0.0001)
176190: accuracy:0.43 loss: 188.814 (lr:0.0001)
176200: accuracy:0.38 loss: 193.301 (lr:0.0001)
176210: accuracy:0.4 loss: 190.896 (lr:0.0001)
176220: accuracy:0.33 loss: 218.695 (lr:0.0001)
176230: accuracy:0.41 loss: 198.09 (lr:0.0001)
176240: accuracy:0.33 loss: 225.913 (lr:0.0001)
176250: accuracy:0.39 loss: 203.938 (lr:0.0001)
176260: accuracy:0.34 loss: 209.3 (lr:0.0001)
176270: accuracy:0.33 loss: 217.693 (lr:0.0001)
176280: accuracy:0.43 loss: 183.78 (lr:0.0001)
176290: accuracy:0.37 loss: 190.771 (lr:0.0001)
176300: accuracy:0.37 loss: 191.91 (lr:0.0001)
176310: accuracy:0.41 loss: 182.403 (lr:0.0001)
176320: accuracy:0.42 loss: 186.509 (lr:0.0001)
176330: accuracy:0.37 loss: 221.528 (lr:0.0001)
176340: accuracy:0.38 loss: 194.336 (lr:0.0001)
176350: accuracy:0.39 loss: 216.189 (lr:0.0001)
176360: accuracy:0.29 loss: 219.204 (lr:0.0001)
176370: accuracy:0.38 loss: 195.71 (lr:0.0001)
176380: accuracy:0.27 loss: 207.315 (lr:0.0001)
176390: accuracy:0.44 loss: 168.859 (lr:0.0001)
176400: accuracy:0.37 loss: 192.256 (lr:0.0001)
176410: accuracy:0.41 loss: 203.851 (lr:0.0001)
176420: accuracy:0.46 loss: 188.054 (lr:0.0001)
176430: accuracy:0.39 loss: 205.494 (lr:0.0001)
176440: accuracy:0.39 loss: 196.021 (lr:0.0001)
176450: accuracy:0.46 loss: 185.469 (lr:0.0001)
176460: accuracy:0.42 loss: 189.659 (lr:0.0001)
176470: accuracy:0.35 loss: 210.89 (lr:0.0001)
176480: accuracy:0.35 loss: 209.083 (lr:0.0001)
176490: accuracy:0.35 loss: 196.104 (lr:0.0001)
176500: accuracy:0.37 loss: 197.211 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
176500: ********* epoch 19 ********* test accuracy for all:0.2635 test loss: 257.147
176500: ********* epoch 19 ********* test accuracy for mode 0:0.044 test loss: 473.661
176500: ********* epoch 19 ********* test accuracy for mode 1:0.028 test loss: 457.06
176500: ********* epoch 19 ********* test accuracy for mode 2:0.0705 test loss: 253.622
176500: ********* epoch 19 ********* test accuracy for mode 24:0.234 test loss: 277.879
176500: ********* epoch 19 ********* test accuracy for mode 25:0.2575 test loss: 253.228
176500: ********* epoch 19 ********* test accuracy for mode 26:0.5335 test loss: 157.022
176500: ********* epoch 19 ********* test accuracy for mode 27:0.2395 test loss: 267.045
176500: ********* epoch 19 ********* test accuracy for mode 28:0.2845 test loss: 261.53
176500: ********* epoch 19 ********* test accuracy for mode 29:0.2415 test loss: 271.918
176500: ********* epoch 19 ********* test accuracy for mode 30:0.261 test loss: 249.233
176500: ********* epoch 19 ********* test accuracy for mode 31:0.1985 test loss: 250.76
176500: ********* epoch 19 ********* test accuracy for mode 32:0.212 test loss: 233.089
176500: ********* epoch 19 ********* test accuracy for mode 33:0.2945 test loss: 230.504
176500: ********* epoch 19 ********* test accuracy for mode 34:0.2345 test loss: 233.64
176500: ********* epoch 19 ********* test accuracy for mode 35:0.0855 test loss: 446.485
176500: ********* epoch 19 ********* test accuracy for mode 36:0.264 test loss: 458.862
176510: accuracy:0.41 loss: 195.293 (lr:0.0001)
176520: accuracy:0.43 loss: 193.218 (lr:0.0001)
176530: accuracy:0.42 loss: 196.274 (lr:0.0001)
176540: accuracy:0.41 loss: 178.285 (lr:0.0001)
176550: accuracy:0.34 loss: 205.645 (lr:0.0001)
176560: accuracy:0.44 loss: 184.964 (lr:0.0001)
176570: accuracy:0.29 loss: 224.192 (lr:0.0001)
176580: accuracy:0.36 loss: 193.857 (lr:0.0001)
176590: accuracy:0.3 loss: 200.283 (lr:0.0001)
176600: accuracy:0.35 loss: 202.695 (lr:0.0001)
176610: accuracy:0.34 loss: 217.962 (lr:0.0001)
176620: accuracy:0.34 loss: 200.274 (lr:0.0001)
176630: accuracy:0.36 loss: 231.047 (lr:0.0001)
176640: accuracy:0.39 loss: 206.458 (lr:0.0001)
176650: accuracy:0.4 loss: 199.143 (lr:0.0001)
176660: accuracy:0.38 loss: 201.39 (lr:0.0001)
176670: accuracy:0.37 loss: 187.982 (lr:0.0001)
176680: accuracy:0.4 loss: 200.755 (lr:0.0001)
176690: accuracy:0.42 loss: 196.109 (lr:0.0001)
176700: accuracy:0.36 loss: 202.567 (lr:0.0001)
176710: accuracy:0.38 loss: 205.553 (lr:0.0001)
176720: accuracy:0.32 loss: 190.901 (lr:0.0001)
176730: accuracy:0.46 loss: 178.158 (lr:0.0001)
176740: accuracy:0.34 loss: 200.229 (lr:0.0001)
176750: accuracy:0.4 loss: 192.457 (lr:0.0001)
176760: accuracy:0.37 loss: 193.022 (lr:0.0001)
176770: accuracy:0.34 loss: 199.798 (lr:0.0001)
176780: accuracy:0.37 loss: 201.715 (lr:0.0001)
176790: accuracy:0.34 loss: 206.106 (lr:0.0001)
176800: accuracy:0.34 loss: 212.616 (lr:0.0001)
176810: accuracy:0.35 loss: 217.934 (lr:0.0001)
176820: accuracy:0.35 loss: 208.535 (lr:0.0001)
176830: accuracy:0.36 loss: 195.944 (lr:0.0001)
176840: accuracy:0.38 loss: 191.76 (lr:0.0001)
176850: accuracy:0.37 loss: 196.316 (lr:0.0001)
176860: accuracy:0.38 loss: 211.21 (lr:0.0001)
176870: accuracy:0.33 loss: 191.625 (lr:0.0001)
176880: accuracy:0.35 loss: 192.175 (lr:0.0001)
176890: accuracy:0.32 loss: 221.724 (lr:0.0001)
176900: accuracy:0.4 loss: 182.3 (lr:0.0001)
176910: accuracy:0.34 loss: 198.225 (lr:0.0001)
176920: accuracy:0.39 loss: 195.269 (lr:0.0001)
176930: accuracy:0.37 loss: 205.227 (lr:0.0001)
176940: accuracy:0.34 loss: 212.354 (lr:0.0001)
176950: accuracy:0.42 loss: 184.861 (lr:0.0001)
176960: accuracy:0.44 loss: 187.619 (lr:0.0001)
176970: accuracy:0.31 loss: 199.689 (lr:0.0001)
176980: accuracy:0.46 loss: 201.746 (lr:0.0001)
176990: accuracy:0.31 loss: 203.468 (lr:0.0001)
177000: accuracy:0.42 loss: 201.382 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
177000: ********* epoch 19 ********* test accuracy for all:0.265027 test loss: 261.112
177000: ********* epoch 19 ********* test accuracy for mode 0:0.042 test loss: 482.353
177000: ********* epoch 19 ********* test accuracy for mode 1:0.022 test loss: 470.751
177000: ********* epoch 19 ********* test accuracy for mode 2:0.074 test loss: 255.035
177000: ********* epoch 19 ********* test accuracy for mode 24:0.251 test loss: 277.028
177000: ********* epoch 19 ********* test accuracy for mode 25:0.2855 test loss: 254.227
177000: ********* epoch 19 ********* test accuracy for mode 26:0.4915 test loss: 161.214
177000: ********* epoch 19 ********* test accuracy for mode 27:0.268 test loss: 266.298
177000: ********* epoch 19 ********* test accuracy for mode 28:0.273 test loss: 267.151
177000: ********* epoch 19 ********* test accuracy for mode 29:0.2365 test loss: 274.282
177000: ********* epoch 19 ********* test accuracy for mode 30:0.2485 test loss: 251.115
177000: ********* epoch 19 ********* test accuracy for mode 31:0.212 test loss: 247.897
177000: ********* epoch 19 ********* test accuracy for mode 32:0.225 test loss: 227.938
177000: ********* epoch 19 ********* test accuracy for mode 33:0.298 test loss: 225.648
177000: ********* epoch 19 ********* test accuracy for mode 34:0.271 test loss: 229.846
177000: ********* epoch 19 ********* test accuracy for mode 35:0.111 test loss: 456.509
177000: ********* epoch 19 ********* test accuracy for mode 36:0.3625 test loss: 451.75
177010: accuracy:0.31 loss: 204.373 (lr:0.0001)
177020: accuracy:0.38 loss: 182.131 (lr:0.0001)
177030: accuracy:0.43 loss: 190.473 (lr:0.0001)
177040: accuracy:0.28 loss: 207.17 (lr:0.0001)
177050: accuracy:0.39 loss: 216.05 (lr:0.0001)
177060: accuracy:0.35 loss: 224.127 (lr:0.0001)
177070: accuracy:0.33 loss: 206.951 (lr:0.0001)
177080: accuracy:0.47 loss: 192.746 (lr:0.0001)
177090: accuracy:0.38 loss: 194.65 (lr:0.0001)
177100: accuracy:0.37 loss: 200.615 (lr:0.0001)
177110: accuracy:0.32 loss: 203.061 (lr:0.0001)
177120: accuracy:0.39 loss: 212.923 (lr:0.0001)
177130: accuracy:0.49 loss: 169.616 (lr:0.0001)
177140: accuracy:0.42 loss: 190.107 (lr:0.0001)
177150: accuracy:0.39 loss: 198.794 (lr:0.0001)
177160: accuracy:0.29 loss: 216.968 (lr:0.0001)
177170: accuracy:0.41 loss: 198.063 (lr:0.0001)
177180: accuracy:0.32 loss: 190.406 (lr:0.0001)
177190: accuracy:0.33 loss: 201.038 (lr:0.0001)
177200: accuracy:0.38 loss: 188.621 (lr:0.0001)
177210: accuracy:0.31 loss: 198.146 (lr:0.0001)
177220: accuracy:0.3 loss: 218.83 (lr:0.0001)
177230: accuracy:0.29 loss: 204.96 (lr:0.0001)
177240: accuracy:0.34 loss: 204.313 (lr:0.0001)
177250: accuracy:0.42 loss: 175.734 (lr:0.0001)
177260: accuracy:0.36 loss: 198.7 (lr:0.0001)
177270: accuracy:0.25 loss: 210.36 (lr:0.0001)
177280: accuracy:0.28 loss: 210.669 (lr:0.0001)
177290: accuracy:0.32 loss: 191.142 (lr:0.0001)
177300: accuracy:0.26 loss: 217.511 (lr:0.0001)
177310: accuracy:0.39 loss: 183.584 (lr:0.0001)
177320: accuracy:0.4 loss: 184.905 (lr:0.0001)
177330: accuracy:0.39 loss: 200.357 (lr:0.0001)
177340: accuracy:0.38 loss: 214.09 (lr:0.0001)
177350: accuracy:0.35 loss: 202.346 (lr:0.0001)
177360: accuracy:0.35 loss: 198.431 (lr:0.0001)
177370: accuracy:0.43 loss: 183.331 (lr:0.0001)
177380: accuracy:0.33 loss: 207.017 (lr:0.0001)
177390: accuracy:0.34 loss: 198.699 (lr:0.0001)
177400: accuracy:0.44 loss: 174.537 (lr:0.0001)
177410: accuracy:0.36 loss: 195.917 (lr:0.0001)
177420: accuracy:0.43 loss: 197.372 (lr:0.0001)
177430: accuracy:0.3 loss: 200.925 (lr:0.0001)
177440: accuracy:0.31 loss: 200.701 (lr:0.0001)
177450: accuracy:0.34 loss: 201.364 (lr:0.0001)
177460: accuracy:0.42 loss: 187.424 (lr:0.0001)
177470: accuracy:0.39 loss: 213.877 (lr:0.0001)
177480: accuracy:0.46 loss: 189.742 (lr:0.0001)
177490: accuracy:0.43 loss: 179.901 (lr:0.0001)
177500: accuracy:0.32 loss: 198.012 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
177500: ********* epoch 19 ********* test accuracy for all:0.265838 test loss: 257.772
177500: ********* epoch 19 ********* test accuracy for mode 0:0.0415 test loss: 469.811
177500: ********* epoch 19 ********* test accuracy for mode 1:0.026 test loss: 455.394
177500: ********* epoch 19 ********* test accuracy for mode 2:0.083 test loss: 256.087
177500: ********* epoch 19 ********* test accuracy for mode 24:0.272 test loss: 265.114
177500: ********* epoch 19 ********* test accuracy for mode 25:0.298 test loss: 248.365
177500: ********* epoch 19 ********* test accuracy for mode 26:0.498 test loss: 156.653
177500: ********* epoch 19 ********* test accuracy for mode 27:0.244 test loss: 271.864
177500: ********* epoch 19 ********* test accuracy for mode 28:0.2715 test loss: 264.879
177500: ********* epoch 19 ********* test accuracy for mode 29:0.2535 test loss: 272.965
177500: ********* epoch 19 ********* test accuracy for mode 30:0.2395 test loss: 254.175
177500: ********* epoch 19 ********* test accuracy for mode 31:0.2315 test loss: 252.809
177500: ********* epoch 19 ********* test accuracy for mode 32:0.1775 test loss: 243.09
177500: ********* epoch 19 ********* test accuracy for mode 33:0.262 test loss: 237.291
177500: ********* epoch 19 ********* test accuracy for mode 34:0.234 test loss: 237.696
177500: ********* epoch 19 ********* test accuracy for mode 35:0.125 test loss: 445.113
177500: ********* epoch 19 ********* test accuracy for mode 36:0.294 test loss: 455.713
177510: accuracy:0.35 loss: 212.941 (lr:0.0001)
177520: accuracy:0.36 loss: 211.541 (lr:0.0001)
177530: accuracy:0.38 loss: 198.916 (lr:0.0001)
177540: accuracy:0.37 loss: 201.11 (lr:0.0001)
177550: accuracy:0.35 loss: 198.514 (lr:0.0001)
177560: accuracy:0.4 loss: 189.837 (lr:0.0001)
177570: accuracy:0.37 loss: 195.576 (lr:0.0001)
177580: accuracy:0.41 loss: 186.496 (lr:0.0001)
177590: accuracy:0.36 loss: 219.159 (lr:0.0001)
177600: accuracy:0.36 loss: 194.111 (lr:0.0001)
177610: accuracy:0.44 loss: 182.342 (lr:0.0001)
177620: accuracy:0.29 loss: 229.57 (lr:0.0001)
177630: accuracy:0.34 loss: 185.831 (lr:0.0001)
177640: accuracy:0.35 loss: 192.062 (lr:0.0001)
177650: accuracy:0.28 loss: 207.045 (lr:0.0001)
177660: accuracy:0.47 loss: 182.002 (lr:0.0001)
177670: accuracy:0.35 loss: 200.606 (lr:0.0001)
177680: accuracy:0.34 loss: 196.863 (lr:0.0001)
177690: accuracy:0.42 loss: 192.186 (lr:0.0001)
177700: accuracy:0.37 loss: 196.462 (lr:0.0001)
177710: accuracy:0.35 loss: 195.621 (lr:0.0001)
177720: accuracy:0.45 loss: 196.428 (lr:0.0001)
177730: accuracy:0.29 loss: 201.605 (lr:0.0001)
177740: accuracy:0.38 loss: 197.976 (lr:0.0001)
177750: accuracy:0.42 loss: 188.056 (lr:0.0001)
177760: accuracy:0.38 loss: 204.565 (lr:0.0001)
177770: accuracy:0.48 loss: 186.242 (lr:0.0001)
177780: accuracy:0.45 loss: 185.181 (lr:0.0001)
177790: accuracy:0.45 loss: 184.51 (lr:0.0001)
177800: accuracy:0.41 loss: 202.908 (lr:0.0001)
177810: accuracy:0.35 loss: 204.715 (lr:0.0001)
177820: accuracy:0.35 loss: 186.949 (lr:0.0001)
177830: accuracy:0.42 loss: 180.216 (lr:0.0001)
177840: accuracy:0.4 loss: 206.293 (lr:0.0001)
177850: accuracy:0.37 loss: 196.264 (lr:0.0001)
177860: accuracy:0.28 loss: 226.344 (lr:0.0001)
177870: accuracy:0.34 loss: 224.569 (lr:0.0001)
177880: accuracy:0.26 loss: 216.216 (lr:0.0001)
177890: accuracy:0.34 loss: 187.074 (lr:0.0001)
177900: accuracy:0.35 loss: 184.666 (lr:0.0001)
177910: accuracy:0.4 loss: 201.971 (lr:0.0001)
177920: accuracy:0.41 loss: 185.53 (lr:0.0001)
177930: accuracy:0.38 loss: 185.53 (lr:0.0001)
177940: accuracy:0.37 loss: 183.687 (lr:0.0001)
177950: accuracy:0.34 loss: 206.037 (lr:0.0001)
177960: accuracy:0.38 loss: 195.138 (lr:0.0001)
177970: accuracy:0.29 loss: 214.899 (lr:0.0001)
177980: accuracy:0.36 loss: 213.698 (lr:0.0001)
177990: accuracy:0.32 loss: 188.371 (lr:0.0001)
178000: accuracy:0.4 loss: 184.084 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
178000: ********* epoch 19 ********* test accuracy for all:0.256743 test loss: 260.356
178000: ********* epoch 19 ********* test accuracy for mode 0:0.0455 test loss: 468.206
178000: ********* epoch 19 ********* test accuracy for mode 1:0.0285 test loss: 449.392
178000: ********* epoch 19 ********* test accuracy for mode 2:0.057 test loss: 257.527
178000: ********* epoch 19 ********* test accuracy for mode 24:0.2565 test loss: 275.755
178000: ********* epoch 19 ********* test accuracy for mode 25:0.261 test loss: 253.524
178000: ********* epoch 19 ********* test accuracy for mode 26:0.477 test loss: 165.856
178000: ********* epoch 19 ********* test accuracy for mode 27:0.2305 test loss: 270.464
178000: ********* epoch 19 ********* test accuracy for mode 28:0.2695 test loss: 265.43
178000: ********* epoch 19 ********* test accuracy for mode 29:0.253 test loss: 273.68
178000: ********* epoch 19 ********* test accuracy for mode 30:0.261 test loss: 253.17
178000: ********* epoch 19 ********* test accuracy for mode 31:0.1745 test loss: 258.249
178000: ********* epoch 19 ********* test accuracy for mode 32:0.214 test loss: 240.202
178000: ********* epoch 19 ********* test accuracy for mode 33:0.254 test loss: 236.567
178000: ********* epoch 19 ********* test accuracy for mode 34:0.274 test loss: 235.964
178000: ********* epoch 19 ********* test accuracy for mode 35:0.102 test loss: 447.878
178000: ********* epoch 19 ********* test accuracy for mode 36:0.1025 test loss: 525.984
178010: accuracy:0.36 loss: 201.443 (lr:0.0001)
178020: accuracy:0.4 loss: 193.146 (lr:0.0001)
178030: accuracy:0.37 loss: 198.004 (lr:0.0001)
178040: accuracy:0.43 loss: 193.271 (lr:0.0001)
178050: accuracy:0.36 loss: 205.528 (lr:0.0001)
178060: accuracy:0.4 loss: 192.85 (lr:0.0001)
178070: accuracy:0.43 loss: 179.764 (lr:0.0001)
178080: accuracy:0.41 loss: 185.533 (lr:0.0001)
178090: accuracy:0.41 loss: 185.437 (lr:0.0001)
178100: accuracy:0.36 loss: 208.016 (lr:0.0001)
178110: accuracy:0.46 loss: 204.59 (lr:0.0001)
178120: accuracy:0.42 loss: 181.679 (lr:0.0001)
178130: accuracy:0.36 loss: 195.478 (lr:0.0001)
178140: accuracy:0.35 loss: 207.345 (lr:0.0001)
178150: accuracy:0.41 loss: 215.63 (lr:0.0001)
178160: accuracy:0.36 loss: 204.769 (lr:0.0001)
178170: accuracy:0.41 loss: 218.176 (lr:0.0001)
178180: accuracy:0.35 loss: 205.73 (lr:0.0001)
178190: accuracy:0.45 loss: 191.669 (lr:0.0001)
178200: accuracy:0.42 loss: 188.386 (lr:0.0001)
178210: accuracy:0.43 loss: 188.691 (lr:0.0001)
178220: accuracy:0.38 loss: 225.897 (lr:0.0001)
178230: accuracy:0.44 loss: 175.007 (lr:0.0001)
178240: accuracy:0.38 loss: 189.787 (lr:0.0001)
178250: accuracy:0.4 loss: 186.147 (lr:0.0001)
178260: accuracy:0.36 loss: 206.834 (lr:0.0001)
178270: accuracy:0.34 loss: 201.231 (lr:0.0001)
178280: accuracy:0.37 loss: 192.765 (lr:0.0001)
178290: accuracy:0.38 loss: 194.641 (lr:0.0001)
178300: accuracy:0.32 loss: 225.035 (lr:0.0001)
178310: accuracy:0.43 loss: 195.662 (lr:0.0001)
178320: accuracy:0.45 loss: 174.699 (lr:0.0001)
178330: accuracy:0.33 loss: 204.258 (lr:0.0001)
178340: accuracy:0.39 loss: 191.092 (lr:0.0001)
178350: accuracy:0.41 loss: 195.52 (lr:0.0001)
178360: accuracy:0.37 loss: 218.093 (lr:0.0001)
178370: accuracy:0.33 loss: 210.769 (lr:0.0001)
178380: accuracy:0.27 loss: 216.231 (lr:0.0001)
178390: accuracy:0.34 loss: 200.649 (lr:0.0001)
178400: accuracy:0.4 loss: 184.401 (lr:0.0001)
178410: accuracy:0.35 loss: 198.977 (lr:0.0001)
178420: accuracy:0.39 loss: 198.512 (lr:0.0001)
178430: accuracy:0.28 loss: 208.634 (lr:0.0001)
178440: accuracy:0.34 loss: 215.169 (lr:0.0001)
178450: accuracy:0.39 loss: 204.74 (lr:0.0001)
178460: accuracy:0.34 loss: 212.564 (lr:0.0001)
178470: accuracy:0.42 loss: 195.961 (lr:0.0001)
178480: accuracy:0.4 loss: 185.143 (lr:0.0001)
178490: accuracy:0.33 loss: 222.821 (lr:0.0001)
178500: accuracy:0.35 loss: 211.928 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
178500: ********* epoch 19 ********* test accuracy for all:0.265365 test loss: 254.93
178500: ********* epoch 19 ********* test accuracy for mode 0:0.043 test loss: 463.316
178500: ********* epoch 19 ********* test accuracy for mode 1:0.029 test loss: 442.7
178500: ********* epoch 19 ********* test accuracy for mode 2:0.097 test loss: 251.81
178500: ********* epoch 19 ********* test accuracy for mode 24:0.2265 test loss: 278.475
178500: ********* epoch 19 ********* test accuracy for mode 25:0.264 test loss: 248.822
178500: ********* epoch 19 ********* test accuracy for mode 26:0.5635 test loss: 154.736
178500: ********* epoch 19 ********* test accuracy for mode 27:0.2305 test loss: 267.429
178500: ********* epoch 19 ********* test accuracy for mode 28:0.2985 test loss: 255.788
178500: ********* epoch 19 ********* test accuracy for mode 29:0.267 test loss: 265.624
178500: ********* epoch 19 ********* test accuracy for mode 30:0.229 test loss: 250.718
178500: ********* epoch 19 ********* test accuracy for mode 31:0.201 test loss: 252.426
178500: ********* epoch 19 ********* test accuracy for mode 32:0.211 test loss: 236.124
178500: ********* epoch 19 ********* test accuracy for mode 33:0.251 test loss: 234.741
178500: ********* epoch 19 ********* test accuracy for mode 34:0.266 test loss: 233.958
178500: ********* epoch 19 ********* test accuracy for mode 35:0.119 test loss: 428.935
178500: ********* epoch 19 ********* test accuracy for mode 36:0.2605 test loss: 453.874
178510: accuracy:0.37 loss: 207.123 (lr:0.0001)
178520: accuracy:0.42 loss: 177.171 (lr:0.0001)
178530: accuracy:0.33 loss: 221.021 (lr:0.0001)
178540: accuracy:0.41 loss: 192.476 (lr:0.0001)
178550: accuracy:0.37 loss: 197.471 (lr:0.0001)
178560: accuracy:0.28 loss: 208.379 (lr:0.0001)
178570: accuracy:0.45 loss: 203.348 (lr:0.0001)
178580: accuracy:0.31 loss: 206.255 (lr:0.0001)
178590: accuracy:0.37 loss: 197.105 (lr:0.0001)
178600: accuracy:0.39 loss: 203.596 (lr:0.0001)
178610: accuracy:0.38 loss: 196.824 (lr:0.0001)
178620: accuracy:0.32 loss: 217.737 (lr:0.0001)
178630: accuracy:0.45 loss: 169.47 (lr:0.0001)
178640: accuracy:0.39 loss: 195.025 (lr:0.0001)
178650: accuracy:0.36 loss: 213.699 (lr:0.0001)
178660: accuracy:0.45 loss: 194.705 (lr:0.0001)
178670: accuracy:0.34 loss: 209.474 (lr:0.0001)
178680: accuracy:0.35 loss: 205.079 (lr:0.0001)
178690: accuracy:0.38 loss: 197.413 (lr:0.0001)
178700: accuracy:0.39 loss: 202.282 (lr:0.0001)
178710: accuracy:0.32 loss: 219.364 (lr:0.0001)
178720: accuracy:0.36 loss: 192.21 (lr:0.0001)
178730: accuracy:0.34 loss: 210.365 (lr:0.0001)
178740: accuracy:0.4 loss: 181.762 (lr:0.0001)
178750: accuracy:0.34 loss: 192.607 (lr:0.0001)
178760: accuracy:0.39 loss: 195.577 (lr:0.0001)
178770: accuracy:0.31 loss: 193.246 (lr:0.0001)
178780: accuracy:0.39 loss: 204.22 (lr:0.0001)
178790: accuracy:0.44 loss: 191.588 (lr:0.0001)
178800: accuracy:0.39 loss: 186.735 (lr:0.0001)
178810: accuracy:0.35 loss: 206.21 (lr:0.0001)
178820: accuracy:0.44 loss: 193.099 (lr:0.0001)
178830: accuracy:0.42 loss: 182.567 (lr:0.0001)
178840: accuracy:0.38 loss: 208.454 (lr:0.0001)
178850: accuracy:0.41 loss: 193.475 (lr:0.0001)
178860: accuracy:0.37 loss: 202.434 (lr:0.0001)
178870: accuracy:0.33 loss: 206.67 (lr:0.0001)
178880: accuracy:0.4 loss: 185.851 (lr:0.0001)
178890: accuracy:0.27 loss: 213.234 (lr:0.0001)
178900: accuracy:0.33 loss: 203.2 (lr:0.0001)
178910: accuracy:0.39 loss: 196.081 (lr:0.0001)
178920: accuracy:0.43 loss: 197.075 (lr:0.0001)
178930: accuracy:0.41 loss: 194.466 (lr:0.0001)
178940: accuracy:0.34 loss: 186.032 (lr:0.0001)
178950: accuracy:0.5 loss: 196.846 (lr:0.0001)
178960: accuracy:0.33 loss: 212.69 (lr:0.0001)
178970: accuracy:0.38 loss: 188.476 (lr:0.0001)
178980: accuracy:0.33 loss: 218.783 (lr:0.0001)
178990: accuracy:0.39 loss: 199.332 (lr:0.0001)
179000: accuracy:0.39 loss: 180.356 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
179000: ********* epoch 19 ********* test accuracy for all:0.260514 test loss: 255.065
179000: ********* epoch 19 ********* test accuracy for mode 0:0.045 test loss: 464.157
179000: ********* epoch 19 ********* test accuracy for mode 1:0.031 test loss: 441.123
179000: ********* epoch 19 ********* test accuracy for mode 2:0.054 test loss: 255.106
179000: ********* epoch 19 ********* test accuracy for mode 24:0.252 test loss: 277.01
179000: ********* epoch 19 ********* test accuracy for mode 25:0.2705 test loss: 245.678
179000: ********* epoch 19 ********* test accuracy for mode 26:0.5245 test loss: 159.714
179000: ********* epoch 19 ********* test accuracy for mode 27:0.238 test loss: 264.717
179000: ********* epoch 19 ********* test accuracy for mode 28:0.29 test loss: 256.588
179000: ********* epoch 19 ********* test accuracy for mode 29:0.2345 test loss: 268.591
179000: ********* epoch 19 ********* test accuracy for mode 30:0.2295 test loss: 251.665
179000: ********* epoch 19 ********* test accuracy for mode 31:0.2095 test loss: 252.221
179000: ********* epoch 19 ********* test accuracy for mode 32:0.165 test loss: 239.028
179000: ********* epoch 19 ********* test accuracy for mode 33:0.3325 test loss: 226.482
179000: ********* epoch 19 ********* test accuracy for mode 34:0.237 test loss: 234.676
179000: ********* epoch 19 ********* test accuracy for mode 35:0.1335 test loss: 421.518
179000: ********* epoch 19 ********* test accuracy for mode 36:0.169 test loss: 472.728
179010: accuracy:0.37 loss: 190.761 (lr:0.0001)
179020: accuracy:0.46 loss: 180.574 (lr:0.0001)
179030: accuracy:0.43 loss: 197.487 (lr:0.0001)
179040: accuracy:0.35 loss: 189.475 (lr:0.0001)
179050: accuracy:0.36 loss: 197.034 (lr:0.0001)
179060: accuracy:0.34 loss: 213.676 (lr:0.0001)
179070: accuracy:0.37 loss: 227.417 (lr:0.0001)
179080: accuracy:0.37 loss: 192.794 (lr:0.0001)
179090: accuracy:0.35 loss: 187.847 (lr:0.0001)
179100: accuracy:0.45 loss: 191.434 (lr:0.0001)
179110: accuracy:0.33 loss: 200.79 (lr:0.0001)
179120: accuracy:0.38 loss: 194.789 (lr:0.0001)
179130: accuracy:0.3 loss: 212.802 (lr:0.0001)
179140: accuracy:0.41 loss: 188.423 (lr:0.0001)
179150: accuracy:0.34 loss: 200.825 (lr:0.0001)
179160: accuracy:0.39 loss: 197.229 (lr:0.0001)
179170: accuracy:0.35 loss: 196.235 (lr:0.0001)
179180: accuracy:0.38 loss: 194.906 (lr:0.0001)
179190: accuracy:0.38 loss: 198.237 (lr:0.0001)
179200: accuracy:0.33 loss: 211.106 (lr:0.0001)
179210: accuracy:0.34 loss: 205.653 (lr:0.0001)
179220: accuracy:0.36 loss: 189.877 (lr:0.0001)
179230: accuracy:0.31 loss: 204.714 (lr:0.0001)
179240: accuracy:0.37 loss: 189.719 (lr:0.0001)
179250: accuracy:0.32 loss: 195.477 (lr:0.0001)
179260: accuracy:0.37 loss: 191.48 (lr:0.0001)
179270: accuracy:0.3 loss: 202.256 (lr:0.0001)
179280: accuracy:0.35 loss: 200.335 (lr:0.0001)
179290: accuracy:0.34 loss: 202.363 (lr:0.0001)
179300: accuracy:0.35 loss: 209.583 (lr:0.0001)
179310: accuracy:0.46 loss: 181.493 (lr:0.0001)
179320: accuracy:0.39 loss: 194.103 (lr:0.0001)
179330: accuracy:0.32 loss: 219.839 (lr:0.0001)
179340: accuracy:0.35 loss: 200.499 (lr:0.0001)
179350: accuracy:0.32 loss: 194.248 (lr:0.0001)
179360: accuracy:0.47 loss: 174.051 (lr:0.0001)
179370: accuracy:0.43 loss: 172.297 (lr:0.0001)
179380: accuracy:0.38 loss: 192.085 (lr:0.0001)
179390: accuracy:0.37 loss: 194.67 (lr:0.0001)
179400: accuracy:0.32 loss: 212.207 (lr:0.0001)
179410: accuracy:0.33 loss: 188.81 (lr:0.0001)
179420: accuracy:0.36 loss: 207.823 (lr:0.0001)
179430: accuracy:0.25 loss: 209.975 (lr:0.0001)
179440: accuracy:0.3 loss: 196.616 (lr:0.0001)
179450: accuracy:0.37 loss: 190.243 (lr:0.0001)
179460: accuracy:0.37 loss: 176.66 (lr:0.0001)
179470: accuracy:0.37 loss: 221.415 (lr:0.0001)
179480: accuracy:0.4 loss: 210.531 (lr:0.0001)
179490: accuracy:0.44 loss: 205.674 (lr:0.0001)
179500: accuracy:0.41 loss: 199.198 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
179500: ********* epoch 19 ********* test accuracy for all:0.259311 test loss: 258.257
179500: ********* epoch 19 ********* test accuracy for mode 0:0.037 test loss: 472.761
179500: ********* epoch 19 ********* test accuracy for mode 1:0.0275 test loss: 447.575
179500: ********* epoch 19 ********* test accuracy for mode 2:0.093 test loss: 252.766
179500: ********* epoch 19 ********* test accuracy for mode 24:0.244 test loss: 272.19
179500: ********* epoch 19 ********* test accuracy for mode 25:0.258 test loss: 246.691
179500: ********* epoch 19 ********* test accuracy for mode 26:0.5175 test loss: 158.031
179500: ********* epoch 19 ********* test accuracy for mode 27:0.2525 test loss: 259.586
179500: ********* epoch 19 ********* test accuracy for mode 28:0.2975 test loss: 255.2
179500: ********* epoch 19 ********* test accuracy for mode 29:0.2665 test loss: 264.457
179500: ********* epoch 19 ********* test accuracy for mode 30:0.2315 test loss: 248.833
179500: ********* epoch 19 ********* test accuracy for mode 31:0.1995 test loss: 248.267
179500: ********* epoch 19 ********* test accuracy for mode 32:0.2355 test loss: 230.325
179500: ********* epoch 19 ********* test accuracy for mode 33:0.263 test loss: 233.238
179500: ********* epoch 19 ********* test accuracy for mode 34:0.229 test loss: 236.366
179500: ********* epoch 19 ********* test accuracy for mode 35:0.101 test loss: 455.559
179500: ********* epoch 19 ********* test accuracy for mode 36:0.0895 test loss: 518.172
179510: accuracy:0.34 loss: 202.928 (lr:0.0001)
179520: accuracy:0.33 loss: 202.548 (lr:0.0001)
179530: accuracy:0.41 loss: 204.056 (lr:0.0001)
179540: accuracy:0.39 loss: 174.882 (lr:0.0001)
179550: accuracy:0.31 loss: 204.368 (lr:0.0001)
179560: accuracy:0.36 loss: 190.681 (lr:0.0001)
179570: accuracy:0.32 loss: 216.88 (lr:0.0001)
179580: accuracy:0.36 loss: 201.693 (lr:0.0001)
179590: accuracy:0.42 loss: 183.731 (lr:0.0001)
179600: accuracy:0.37 loss: 207.858 (lr:0.0001)
179610: accuracy:0.32 loss: 221.173 (lr:0.0001)
179620: accuracy:0.32 loss: 198.203 (lr:0.0001)
179630: accuracy:0.36 loss: 185.072 (lr:0.0001)
179640: accuracy:0.44 loss: 180.636 (lr:0.0001)
179650: accuracy:0.39 loss: 185.532 (lr:0.0001)
179660: accuracy:0.31 loss: 201.304 (lr:0.0001)
179670: accuracy:0.38 loss: 196.219 (lr:0.0001)
179680: accuracy:0.39 loss: 197.967 (lr:0.0001)
179690: accuracy:0.4 loss: 176.853 (lr:0.0001)
179700: accuracy:0.41 loss: 196.231 (lr:0.0001)
179710: accuracy:0.29 loss: 222.31 (lr:0.0001)
179720: accuracy:0.37 loss: 198.774 (lr:0.0001)
179730: accuracy:0.35 loss: 185.324 (lr:0.0001)
179740: accuracy:0.31 loss: 212.419 (lr:0.0001)
179750: accuracy:0.4 loss: 190.548 (lr:0.0001)
179760: accuracy:0.34 loss: 192.654 (lr:0.0001)
179770: accuracy:0.47 loss: 200.824 (lr:0.0001)
179780: accuracy:0.34 loss: 206.045 (lr:0.0001)
179790: accuracy:0.43 loss: 183.974 (lr:0.0001)
179800: accuracy:0.41 loss: 187.688 (lr:0.0001)
179810: accuracy:0.39 loss: 212.794 (lr:0.0001)
179820: accuracy:0.45 loss: 188.361 (lr:0.0001)
179830: accuracy:0.36 loss: 199.316 (lr:0.0001)
179840: accuracy:0.34 loss: 195.263 (lr:0.0001)
179850: accuracy:0.4 loss: 180.4 (lr:0.0001)
179860: accuracy:0.43 loss: 188.676 (lr:0.0001)
179870: accuracy:0.39 loss: 194.452 (lr:0.0001)
179880: accuracy:0.23 loss: 222.663 (lr:0.0001)
179890: accuracy:0.41 loss: 198.99 (lr:0.0001)
179900: accuracy:0.3 loss: 213.343 (lr:0.0001)
179910: accuracy:0.4 loss: 193.331 (lr:0.0001)
179920: accuracy:0.34 loss: 202.408 (lr:0.0001)
179930: accuracy:0.35 loss: 220.277 (lr:0.0001)
179940: accuracy:0.31 loss: 192.655 (lr:0.0001)
179950: accuracy:0.36 loss: 189.039 (lr:0.0001)
179960: accuracy:0.34 loss: 188.042 (lr:0.0001)
179970: accuracy:0.36 loss: 196.752 (lr:0.0001)
179980: accuracy:0.35 loss: 221.257 (lr:0.0001)
179990: accuracy:0.33 loss: 199.939 (lr:0.0001)
180000: accuracy:0.35 loss: 210.996 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
180000: ********* epoch 19 ********* test accuracy for all:0.268351 test loss: 256.136
180000: ********* epoch 19 ********* test accuracy for mode 0:0.0435 test loss: 473.245
180000: ********* epoch 19 ********* test accuracy for mode 1:0.0275 test loss: 457.318
180000: ********* epoch 19 ********* test accuracy for mode 2:0.0685 test loss: 262.075
180000: ********* epoch 19 ********* test accuracy for mode 24:0.251 test loss: 267.899
180000: ********* epoch 19 ********* test accuracy for mode 25:0.2855 test loss: 242.853
180000: ********* epoch 19 ********* test accuracy for mode 26:0.4975 test loss: 160.677
180000: ********* epoch 19 ********* test accuracy for mode 27:0.2855 test loss: 251.239
180000: ********* epoch 19 ********* test accuracy for mode 28:0.27 test loss: 254.916
180000: ********* epoch 19 ********* test accuracy for mode 29:0.261 test loss: 258.134
180000: ********* epoch 19 ********* test accuracy for mode 30:0.263 test loss: 239.826
180000: ********* epoch 19 ********* test accuracy for mode 31:0.222 test loss: 244.507
180000: ********* epoch 19 ********* test accuracy for mode 32:0.1985 test loss: 234.553
180000: ********* epoch 19 ********* test accuracy for mode 33:0.273 test loss: 234.86
180000: ********* epoch 19 ********* test accuracy for mode 34:0.2425 test loss: 238.285
180000: ********* epoch 19 ********* test accuracy for mode 35:0.102 test loss: 447.793
180000: ********* epoch 19 ********* test accuracy for mode 36:0.3305 test loss: 457.382
180010: accuracy:0.36 loss: 194.937 (lr:0.0001)
180020: accuracy:0.34 loss: 208.996 (lr:0.0001)
180030: accuracy:0.4 loss: 202.957 (lr:0.0001)
180040: accuracy:0.42 loss: 177.211 (lr:0.0001)
180050: accuracy:0.42 loss: 194.204 (lr:0.0001)
180060: accuracy:0.35 loss: 195.911 (lr:0.0001)
180070: accuracy:0.42 loss: 192.736 (lr:0.0001)
180080: accuracy:0.31 loss: 203.516 (lr:0.0001)
180090: accuracy:0.26 loss: 202.33 (lr:0.0001)
180100: accuracy:0.38 loss: 191.218 (lr:0.0001)
180110: accuracy:0.34 loss: 199.575 (lr:0.0001)
180120: accuracy:0.37 loss: 196.008 (lr:0.0001)
180130: accuracy:0.36 loss: 205.294 (lr:0.0001)
180140: accuracy:0.37 loss: 189.511 (lr:0.0001)
180150: accuracy:0.44 loss: 178.47 (lr:0.0001)
180160: accuracy:0.37 loss: 211.091 (lr:0.0001)
180170: accuracy:0.42 loss: 174.087 (lr:0.0001)
180180: accuracy:0.28 loss: 212.031 (lr:0.0001)
180190: accuracy:0.39 loss: 180.507 (lr:0.0001)
180200: accuracy:0.3 loss: 225.525 (lr:0.0001)
180210: accuracy:0.34 loss: 201.093 (lr:0.0001)
180220: accuracy:0.51 loss: 165.651 (lr:0.0001)
180230: accuracy:0.45 loss: 185.527 (lr:0.0001)
180240: accuracy:0.37 loss: 194.361 (lr:0.0001)
180250: accuracy:0.34 loss: 214.657 (lr:0.0001)
180260: accuracy:0.3 loss: 198.507 (lr:0.0001)
180270: accuracy:0.31 loss: 212.491 (lr:0.0001)
180280: accuracy:0.41 loss: 191.324 (lr:0.0001)
180290: accuracy:0.3 loss: 211.339 (lr:0.0001)
180300: accuracy:0.4 loss: 205.522 (lr:0.0001)
180310: accuracy:0.46 loss: 185.712 (lr:0.0001)
180320: accuracy:0.36 loss: 197.726 (lr:0.0001)
180330: accuracy:0.33 loss: 214.146 (lr:0.0001)
180340: accuracy:0.33 loss: 183.995 (lr:0.0001)
180350: accuracy:0.37 loss: 190.844 (lr:0.0001)
180360: accuracy:0.36 loss: 218.029 (lr:0.0001)
180370: accuracy:0.32 loss: 185.989 (lr:0.0001)
180380: accuracy:0.35 loss: 195.453 (lr:0.0001)
180390: accuracy:0.42 loss: 178.117 (lr:0.0001)
180400: accuracy:0.36 loss: 198.305 (lr:0.0001)
180410: accuracy:0.26 loss: 218.574 (lr:0.0001)
180420: accuracy:0.28 loss: 207.828 (lr:0.0001)
180430: accuracy:0.41 loss: 193.382 (lr:0.0001)
180440: accuracy:0.37 loss: 207.31 (lr:0.0001)
180450: accuracy:0.34 loss: 206.488 (lr:0.0001)
180460: accuracy:0.4 loss: 207.487 (lr:0.0001)
180470: accuracy:0.43 loss: 191.596 (lr:0.0001)
180480: accuracy:0.44 loss: 205.169 (lr:0.0001)
180490: accuracy:0.31 loss: 202.642 (lr:0.0001)
180500: accuracy:0.38 loss: 196.655 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
180500: ********* epoch 19 ********* test accuracy for all:0.264203 test loss: 258.59
180500: ********* epoch 19 ********* test accuracy for mode 0:0.036 test loss: 483.133
180500: ********* epoch 19 ********* test accuracy for mode 1:0.026 test loss: 458.664
180500: ********* epoch 19 ********* test accuracy for mode 2:0.0535 test loss: 254.276
180500: ********* epoch 19 ********* test accuracy for mode 24:0.2335 test loss: 284.685
180500: ********* epoch 19 ********* test accuracy for mode 25:0.245 test loss: 262.461
180500: ********* epoch 19 ********* test accuracy for mode 26:0.5165 test loss: 161.615
180500: ********* epoch 19 ********* test accuracy for mode 27:0.2545 test loss: 267.118
180500: ********* epoch 19 ********* test accuracy for mode 28:0.289 test loss: 263.849
180500: ********* epoch 19 ********* test accuracy for mode 29:0.281 test loss: 263.25
180500: ********* epoch 19 ********* test accuracy for mode 30:0.236 test loss: 250.532
180500: ********* epoch 19 ********* test accuracy for mode 31:0.211 test loss: 250.592
180500: ********* epoch 19 ********* test accuracy for mode 32:0.192 test loss: 231.542
180500: ********* epoch 19 ********* test accuracy for mode 33:0.3045 test loss: 223.475
180500: ********* epoch 19 ********* test accuracy for mode 34:0.2865 test loss: 224.579
180500: ********* epoch 19 ********* test accuracy for mode 35:0.0945 test loss: 443.692
180500: ********* epoch 19 ********* test accuracy for mode 36:0.3175 test loss: 457.732
180510: accuracy:0.35 loss: 214.301 (lr:0.0001)
180520: accuracy:0.37 loss: 199.505 (lr:0.0001)
180530: accuracy:0.44 loss: 170.704 (lr:0.0001)
180540: accuracy:0.32 loss: 201.289 (lr:0.0001)
180550: accuracy:0.44 loss: 193.146 (lr:0.0001)
180560: accuracy:0.34 loss: 181.726 (lr:0.0001)
180570: accuracy:0.34 loss: 192.769 (lr:0.0001)
180580: accuracy:0.49 loss: 186.005 (lr:0.0001)
180590: accuracy:0.43 loss: 178.729 (lr:0.0001)
180600: accuracy:0.38 loss: 196.178 (lr:0.0001)
180610: accuracy:0.41 loss: 188.234 (lr:0.0001)
180620: accuracy:0.36 loss: 201.856 (lr:0.0001)
180630: accuracy:0.43 loss: 197.12 (lr:0.0001)
180640: accuracy:0.42 loss: 189.049 (lr:0.0001)
180650: accuracy:0.35 loss: 210.352 (lr:0.0001)
180660: accuracy:0.43 loss: 198.791 (lr:0.0001)
180670: accuracy:0.31 loss: 190.822 (lr:0.0001)
180680: accuracy:0.41 loss: 202.514 (lr:0.0001)
180690: accuracy:0.28 loss: 192.498 (lr:0.0001)
180700: accuracy:0.42 loss: 190.226 (lr:0.0001)
180710: accuracy:0.36 loss: 200.113 (lr:0.0001)
180720: accuracy:0.38 loss: 204.943 (lr:0.0001)
180730: accuracy:0.4 loss: 197.518 (lr:0.0001)
180740: accuracy:0.38 loss: 208.667 (lr:0.0001)
180750: accuracy:0.37 loss: 216.593 (lr:0.0001)
180760: accuracy:0.31 loss: 195.814 (lr:0.0001)
180770: accuracy:0.37 loss: 208.643 (lr:0.0001)
180780: accuracy:0.34 loss: 203.798 (lr:0.0001)
180790: accuracy:0.4 loss: 175.515 (lr:0.0001)
180800: accuracy:0.4 loss: 199.248 (lr:0.0001)
180810: accuracy:0.4 loss: 205.159 (lr:0.0001)
180820: accuracy:0.41 loss: 208.632 (lr:0.0001)
180830: accuracy:0.39 loss: 189.677 (lr:0.0001)
180840: accuracy:0.37 loss: 192.454 (lr:0.0001)
180850: accuracy:0.36 loss: 191.329 (lr:0.0001)
180860: accuracy:0.28 loss: 207.478 (lr:0.0001)
180870: accuracy:0.4 loss: 205.512 (lr:0.0001)
180880: accuracy:0.37 loss: 207.878 (lr:0.0001)
180890: accuracy:0.34 loss: 213.923 (lr:0.0001)
180900: accuracy:0.4 loss: 197.818 (lr:0.0001)
180910: accuracy:0.35 loss: 191.716 (lr:0.0001)
180920: accuracy:0.36 loss: 204.818 (lr:0.0001)
180930: accuracy:0.45 loss: 189.793 (lr:0.0001)
180940: accuracy:0.33 loss: 214.905 (lr:0.0001)
180950: accuracy:0.35 loss: 193.156 (lr:0.0001)
180960: accuracy:0.38 loss: 202.824 (lr:0.0001)
180970: accuracy:0.36 loss: 215.316 (lr:0.0001)
180980: accuracy:0.29 loss: 218.32 (lr:0.0001)
180990: accuracy:0.36 loss: 201.992 (lr:0.0001)
181000: accuracy:0.39 loss: 189.614 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
181000: ********* epoch 19 ********* test accuracy for all:0.264041 test loss: 256.914
181000: ********* epoch 19 ********* test accuracy for mode 0:0.0455 test loss: 469.551
181000: ********* epoch 19 ********* test accuracy for mode 1:0.029 test loss: 451.563
181000: ********* epoch 19 ********* test accuracy for mode 2:0.0645 test loss: 260.495
181000: ********* epoch 19 ********* test accuracy for mode 24:0.268 test loss: 271.716
181000: ********* epoch 19 ********* test accuracy for mode 25:0.286 test loss: 246.803
181000: ********* epoch 19 ********* test accuracy for mode 26:0.508 test loss: 160.079
181000: ********* epoch 19 ********* test accuracy for mode 27:0.2265 test loss: 268.58
181000: ********* epoch 19 ********* test accuracy for mode 28:0.308 test loss: 255.97
181000: ********* epoch 19 ********* test accuracy for mode 29:0.2505 test loss: 268.671
181000: ********* epoch 19 ********* test accuracy for mode 30:0.2355 test loss: 252.766
181000: ********* epoch 19 ********* test accuracy for mode 31:0.173 test loss: 255.035
181000: ********* epoch 19 ********* test accuracy for mode 32:0.2415 test loss: 228.658
181000: ********* epoch 19 ********* test accuracy for mode 33:0.268 test loss: 227.335
181000: ********* epoch 19 ********* test accuracy for mode 34:0.3025 test loss: 227.034
181000: ********* epoch 19 ********* test accuracy for mode 35:0.1405 test loss: 437.64
181000: ********* epoch 19 ********* test accuracy for mode 36:0.193 test loss: 470.159
181010: accuracy:0.47 loss: 198.415 (lr:0.0001)
181020: accuracy:0.32 loss: 205.058 (lr:0.0001)
181030: accuracy:0.34 loss: 208.099 (lr:0.0001)
181040: accuracy:0.43 loss: 192.458 (lr:0.0001)
181050: accuracy:0.34 loss: 194.093 (lr:0.0001)
181060: accuracy:0.51 loss: 189.73 (lr:0.0001)
181070: accuracy:0.33 loss: 191.253 (lr:0.0001)
181080: accuracy:0.37 loss: 204.614 (lr:0.0001)
181090: accuracy:0.47 loss: 178.983 (lr:0.0001)
181100: accuracy:0.39 loss: 193.636 (lr:0.0001)
181110: accuracy:0.27 loss: 214.918 (lr:0.0001)
181120: accuracy:0.35 loss: 182.461 (lr:0.0001)
181130: accuracy:0.32 loss: 208.719 (lr:0.0001)
181140: accuracy:0.28 loss: 211.388 (lr:0.0001)
181150: accuracy:0.38 loss: 175.749 (lr:0.0001)
181160: accuracy:0.33 loss: 204.776 (lr:0.0001)
181170: accuracy:0.43 loss: 194.236 (lr:0.0001)
181180: accuracy:0.32 loss: 194.063 (lr:0.0001)
181190: accuracy:0.38 loss: 190.807 (lr:0.0001)
181200: accuracy:0.38 loss: 197.983 (lr:0.0001)
181210: accuracy:0.36 loss: 198.137 (lr:0.0001)
181220: accuracy:0.39 loss: 193.56 (lr:0.0001)
181230: accuracy:0.43 loss: 173.233 (lr:0.0001)
181240: accuracy:0.39 loss: 202.738 (lr:0.0001)
181250: accuracy:0.36 loss: 194.289 (lr:0.0001)
181260: accuracy:0.32 loss: 207.037 (lr:0.0001)
181270: accuracy:0.32 loss: 211.87 (lr:0.0001)
181280: accuracy:0.45 loss: 176.87 (lr:0.0001)
181290: accuracy:0.4 loss: 193.61 (lr:0.0001)
181300: accuracy:0.4 loss: 192.872 (lr:0.0001)
181310: accuracy:0.36 loss: 200.342 (lr:0.0001)
181320: accuracy:0.38 loss: 200.249 (lr:0.0001)
181330: accuracy:0.36 loss: 203.272 (lr:0.0001)
181340: accuracy:0.41 loss: 185.579 (lr:0.0001)
181350: accuracy:0.4 loss: 185.743 (lr:0.0001)
181360: accuracy:0.37 loss: 200.522 (lr:0.0001)
181370: accuracy:0.42 loss: 187.779 (lr:0.0001)
181380: accuracy:0.29 loss: 201.993 (lr:0.0001)
181390: accuracy:0.39 loss: 206.517 (lr:0.0001)
181400: accuracy:0.39 loss: 190.06 (lr:0.0001)
181410: accuracy:0.38 loss: 198.327 (lr:0.0001)
181420: accuracy:0.37 loss: 206.813 (lr:0.0001)
181430: accuracy:0.34 loss: 195.381 (lr:0.0001)
181440: accuracy:0.43 loss: 181.098 (lr:0.0001)
181450: accuracy:0.42 loss: 185.325 (lr:0.0001)
181460: accuracy:0.42 loss: 185.879 (lr:0.0001)
181470: accuracy:0.38 loss: 218.15 (lr:0.0001)
181480: accuracy:0.4 loss: 204.492 (lr:0.0001)
181490: accuracy:0.46 loss: 177.064 (lr:0.0001)
181500: accuracy:0.36 loss: 195.612 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
181500: ********* epoch 19 ********* test accuracy for all:0.26477 test loss: 257.308
181500: ********* epoch 19 ********* test accuracy for mode 0:0.0525 test loss: 468.017
181500: ********* epoch 19 ********* test accuracy for mode 1:0.032 test loss: 456.397
181500: ********* epoch 19 ********* test accuracy for mode 2:0.046 test loss: 267.823
181500: ********* epoch 19 ********* test accuracy for mode 24:0.2595 test loss: 269.066
181500: ********* epoch 19 ********* test accuracy for mode 25:0.2745 test loss: 246.843
181500: ********* epoch 19 ********* test accuracy for mode 26:0.4685 test loss: 161.743
181500: ********* epoch 19 ********* test accuracy for mode 27:0.2545 test loss: 268.064
181500: ********* epoch 19 ********* test accuracy for mode 28:0.295 test loss: 260.879
181500: ********* epoch 19 ********* test accuracy for mode 29:0.2615 test loss: 265.184
181500: ********* epoch 19 ********* test accuracy for mode 30:0.247 test loss: 252.533
181500: ********* epoch 19 ********* test accuracy for mode 31:0.166 test loss: 260.244
181500: ********* epoch 19 ********* test accuracy for mode 32:0.2385 test loss: 235.451
181500: ********* epoch 19 ********* test accuracy for mode 33:0.2585 test loss: 237.227
181500: ********* epoch 19 ********* test accuracy for mode 34:0.2355 test loss: 240.105
181500: ********* epoch 19 ********* test accuracy for mode 35:0.093 test loss: 440.005
181500: ********* epoch 19 ********* test accuracy for mode 36:0.327 test loss: 453.826
181510: accuracy:0.33 loss: 224.557 (lr:0.0001)
181520: accuracy:0.38 loss: 184.84 (lr:0.0001)
181530: accuracy:0.36 loss: 220.986 (lr:0.0001)
181540: accuracy:0.4 loss: 198.284 (lr:0.0001)
181550: accuracy:0.38 loss: 199.062 (lr:0.0001)
181560: accuracy:0.36 loss: 200.157 (lr:0.0001)
181570: accuracy:0.36 loss: 211.632 (lr:0.0001)
181580: accuracy:0.33 loss: 194.759 (lr:0.0001)
181590: accuracy:0.38 loss: 190.664 (lr:0.0001)
181600: accuracy:0.33 loss: 198.395 (lr:0.0001)
181610: accuracy:0.36 loss: 193.671 (lr:0.0001)
181620: accuracy:0.33 loss: 209.712 (lr:0.0001)
181630: accuracy:0.28 loss: 210.07 (lr:0.0001)
181640: accuracy:0.47 loss: 180.265 (lr:0.0001)
181650: accuracy:0.36 loss: 218.029 (lr:0.0001)
181660: accuracy:0.33 loss: 207.0 (lr:0.0001)
181670: accuracy:0.37 loss: 196.951 (lr:0.0001)
181680: accuracy:0.42 loss: 176.658 (lr:0.0001)
181690: accuracy:0.37 loss: 203.318 (lr:0.0001)
181700: accuracy:0.39 loss: 191.078 (lr:0.0001)
181710: accuracy:0.27 loss: 219.406 (lr:0.0001)
181720: accuracy:0.44 loss: 180.819 (lr:0.0001)
181730: accuracy:0.27 loss: 225.735 (lr:0.0001)
181740: accuracy:0.41 loss: 202.979 (lr:0.0001)
181750: accuracy:0.4 loss: 197.458 (lr:0.0001)
181760: accuracy:0.24 loss: 222.691 (lr:0.0001)
181770: accuracy:0.37 loss: 202.119 (lr:0.0001)
181780: accuracy:0.39 loss: 185.684 (lr:0.0001)
181790: accuracy:0.38 loss: 180.291 (lr:0.0001)
181800: accuracy:0.34 loss: 195.515 (lr:0.0001)
181810: accuracy:0.41 loss: 195.021 (lr:0.0001)
181820: accuracy:0.47 loss: 188.327 (lr:0.0001)
181830: accuracy:0.42 loss: 189.69 (lr:0.0001)
181840: accuracy:0.33 loss: 198.276 (lr:0.0001)
181850: accuracy:0.34 loss: 197.974 (lr:0.0001)
181860: accuracy:0.43 loss: 175.478 (lr:0.0001)
181870: accuracy:0.34 loss: 194.438 (lr:0.0001)
181880: accuracy:0.35 loss: 201.038 (lr:0.0001)
181890: accuracy:0.42 loss: 190.911 (lr:0.0001)
181900: accuracy:0.35 loss: 213.1 (lr:0.0001)
181910: accuracy:0.32 loss: 198.07 (lr:0.0001)
181920: accuracy:0.29 loss: 200.74 (lr:0.0001)
181930: accuracy:0.36 loss: 205.187 (lr:0.0001)
181940: accuracy:0.34 loss: 198.537 (lr:0.0001)
181950: accuracy:0.4 loss: 203.25 (lr:0.0001)
181960: accuracy:0.38 loss: 191.857 (lr:0.0001)
181970: accuracy:0.3 loss: 218.708 (lr:0.0001)
181980: accuracy:0.35 loss: 212.066 (lr:0.0001)
181990: accuracy:0.43 loss: 170.334 (lr:0.0001)
182000: accuracy:0.33 loss: 204.465 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
182000: ********* epoch 19 ********* test accuracy for all:0.262878 test loss: 257.556
182000: ********* epoch 19 ********* test accuracy for mode 0:0.0405 test loss: 469.116
182000: ********* epoch 19 ********* test accuracy for mode 1:0.03 test loss: 450.462
182000: ********* epoch 19 ********* test accuracy for mode 2:0.078 test loss: 255.71
182000: ********* epoch 19 ********* test accuracy for mode 24:0.227 test loss: 280.301
182000: ********* epoch 19 ********* test accuracy for mode 25:0.282 test loss: 251.086
182000: ********* epoch 19 ********* test accuracy for mode 26:0.5075 test loss: 159.444
182000: ********* epoch 19 ********* test accuracy for mode 27:0.239 test loss: 269.818
182000: ********* epoch 19 ********* test accuracy for mode 28:0.2755 test loss: 262.503
182000: ********* epoch 19 ********* test accuracy for mode 29:0.2605 test loss: 265.548
182000: ********* epoch 19 ********* test accuracy for mode 30:0.23 test loss: 247.05
182000: ********* epoch 19 ********* test accuracy for mode 31:0.245 test loss: 242.619
182000: ********* epoch 19 ********* test accuracy for mode 32:0.1925 test loss: 229.984
182000: ********* epoch 19 ********* test accuracy for mode 33:0.3115 test loss: 225.198
182000: ********* epoch 19 ********* test accuracy for mode 34:0.256 test loss: 230.371
182000: ********* epoch 19 ********* test accuracy for mode 35:0.1245 test loss: 428.55
182000: ********* epoch 19 ********* test accuracy for mode 36:0.252 test loss: 458.826
182010: accuracy:0.36 loss: 206.564 (lr:0.0001)
182020: accuracy:0.27 loss: 196.211 (lr:0.0001)
182030: accuracy:0.37 loss: 195.206 (lr:0.0001)
182040: accuracy:0.32 loss: 216.44 (lr:0.0001)
182050: accuracy:0.41 loss: 182.883 (lr:0.0001)
182060: accuracy:0.39 loss: 199.204 (lr:0.0001)
182070: accuracy:0.41 loss: 188.929 (lr:0.0001)
182080: accuracy:0.35 loss: 193.32 (lr:0.0001)
182090: accuracy:0.41 loss: 201.521 (lr:0.0001)
182100: accuracy:0.4 loss: 203.627 (lr:0.0001)
182110: accuracy:0.35 loss: 213.212 (lr:0.0001)
182120: accuracy:0.36 loss: 197.497 (lr:0.0001)
182130: accuracy:0.49 loss: 172.217 (lr:0.0001)
182140: accuracy:0.46 loss: 179.329 (lr:0.0001)
182150: accuracy:0.37 loss: 186.753 (lr:0.0001)
182160: accuracy:0.38 loss: 198.143 (lr:0.0001)
182170: accuracy:0.34 loss: 207.863 (lr:0.0001)
182180: accuracy:0.37 loss: 199.861 (lr:0.0001)
182190: accuracy:0.38 loss: 202.863 (lr:0.0001)
182200: accuracy:0.41 loss: 191.364 (lr:0.0001)
182210: accuracy:0.4 loss: 202.769 (lr:0.0001)
182220: accuracy:0.4 loss: 181.205 (lr:0.0001)
182230: accuracy:0.37 loss: 192.871 (lr:0.0001)
182240: accuracy:0.41 loss: 199.062 (lr:0.0001)
182250: accuracy:0.31 loss: 195.857 (lr:0.0001)
182260: accuracy:0.42 loss: 198.962 (lr:0.0001)
182270: accuracy:0.32 loss: 202.849 (lr:0.0001)
182280: accuracy:0.39 loss: 203.158 (lr:0.0001)
182290: accuracy:0.31 loss: 207.418 (lr:0.0001)
182300: accuracy:0.42 loss: 185.823 (lr:0.0001)
182310: accuracy:0.38 loss: 186.551 (lr:0.0001)
182320: accuracy:0.36 loss: 180.335 (lr:0.0001)
182330: accuracy:0.39 loss: 211.165 (lr:0.0001)
182340: accuracy:0.28 loss: 221.766 (lr:0.0001)
182350: accuracy:0.41 loss: 173.875 (lr:0.0001)
182360: accuracy:0.38 loss: 189.456 (lr:0.0001)
182370: accuracy:0.36 loss: 209.266 (lr:0.0001)
182380: accuracy:0.43 loss: 190.304 (lr:0.0001)
182390: accuracy:0.39 loss: 193.068 (lr:0.0001)
182400: accuracy:0.35 loss: 195.796 (lr:0.0001)
182410: accuracy:0.39 loss: 184.732 (lr:0.0001)
182420: accuracy:0.39 loss: 190.031 (lr:0.0001)
182430: accuracy:0.38 loss: 192.203 (lr:0.0001)
182440: accuracy:0.44 loss: 200.145 (lr:0.0001)
182450: accuracy:0.37 loss: 210.399 (lr:0.0001)
182460: accuracy:0.34 loss: 207.591 (lr:0.0001)
182470: accuracy:0.32 loss: 213.528 (lr:0.0001)
182480: accuracy:0.35 loss: 185.924 (lr:0.0001)
182490: accuracy:0.35 loss: 206.172 (lr:0.0001)
182500: accuracy:0.38 loss: 193.556 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
182500: ********* epoch 19 ********* test accuracy for all:0.266311 test loss: 256.312
182500: ********* epoch 19 ********* test accuracy for mode 0:0.0455 test loss: 465.982
182500: ********* epoch 19 ********* test accuracy for mode 1:0.034 test loss: 444.001
182500: ********* epoch 19 ********* test accuracy for mode 2:0.069 test loss: 257.67
182500: ********* epoch 19 ********* test accuracy for mode 24:0.27 test loss: 269.087
182500: ********* epoch 19 ********* test accuracy for mode 25:0.255 test loss: 248.31
182500: ********* epoch 19 ********* test accuracy for mode 26:0.523 test loss: 159.691
182500: ********* epoch 19 ********* test accuracy for mode 27:0.249 test loss: 261.827
182500: ********* epoch 19 ********* test accuracy for mode 28:0.3145 test loss: 249.936
182500: ********* epoch 19 ********* test accuracy for mode 29:0.2845 test loss: 255.831
182500: ********* epoch 19 ********* test accuracy for mode 30:0.25 test loss: 247.824
182500: ********* epoch 19 ********* test accuracy for mode 31:0.195 test loss: 253.825
182500: ********* epoch 19 ********* test accuracy for mode 32:0.214 test loss: 234.77
182500: ********* epoch 19 ********* test accuracy for mode 33:0.2495 test loss: 233.826
182500: ********* epoch 19 ********* test accuracy for mode 34:0.31 test loss: 227.841
182500: ********* epoch 19 ********* test accuracy for mode 35:0.088 test loss: 449.975
182500: ********* epoch 19 ********* test accuracy for mode 36:0.2225 test loss: 487.727
182510: accuracy:0.36 loss: 200.559 (lr:0.0001)
182520: accuracy:0.36 loss: 202.924 (lr:0.0001)
182530: accuracy:0.34 loss: 219.136 (lr:0.0001)
182540: accuracy:0.39 loss: 200.712 (lr:0.0001)
182550: accuracy:0.39 loss: 183.522 (lr:0.0001)
182560: accuracy:0.43 loss: 192.808 (lr:0.0001)
182570: accuracy:0.47 loss: 174.41 (lr:0.0001)
182580: accuracy:0.37 loss: 194.96 (lr:0.0001)
182590: accuracy:0.34 loss: 199.499 (lr:0.0001)
182600: accuracy:0.39 loss: 204.813 (lr:0.0001)
182610: accuracy:0.42 loss: 188.348 (lr:0.0001)
182620: accuracy:0.35 loss: 215.073 (lr:0.0001)
182630: accuracy:0.36 loss: 202.185 (lr:0.0001)
182640: accuracy:0.38 loss: 204.109 (lr:0.0001)
182650: accuracy:0.29 loss: 225.219 (lr:0.0001)
182660: accuracy:0.38 loss: 213.142 (lr:0.0001)
182670: accuracy:0.4 loss: 203.712 (lr:0.0001)
182680: accuracy:0.37 loss: 183.271 (lr:0.0001)
182690: accuracy:0.4 loss: 211.761 (lr:0.0001)
182700: accuracy:0.4 loss: 187.062 (lr:0.0001)
182710: accuracy:0.29 loss: 216.282 (lr:0.0001)
182720: accuracy:0.44 loss: 203.924 (lr:0.0001)
182730: accuracy:0.32 loss: 211.096 (lr:0.0001)
182740: accuracy:0.27 loss: 201.766 (lr:0.0001)
182750: accuracy:0.32 loss: 191.597 (lr:0.0001)
182760: accuracy:0.28 loss: 201.938 (lr:0.0001)
182770: accuracy:0.38 loss: 195.452 (lr:0.0001)
182780: accuracy:0.32 loss: 201.239 (lr:0.0001)
182790: accuracy:0.35 loss: 217.709 (lr:0.0001)
182800: accuracy:0.31 loss: 219.169 (lr:0.0001)
182810: accuracy:0.44 loss: 185.729 (lr:0.0001)
182820: accuracy:0.41 loss: 209.669 (lr:0.0001)
182830: accuracy:0.36 loss: 192.526 (lr:0.0001)
182840: accuracy:0.33 loss: 193.159 (lr:0.0001)
182850: accuracy:0.37 loss: 207.027 (lr:0.0001)
182860: accuracy:0.35 loss: 216.417 (lr:0.0001)
182870: accuracy:0.37 loss: 192.293 (lr:0.0001)
182880: accuracy:0.44 loss: 182.435 (lr:0.0001)
182890: accuracy:0.32 loss: 218.577 (lr:0.0001)
182900: accuracy:0.44 loss: 169.46 (lr:0.0001)
182910: accuracy:0.42 loss: 202.239 (lr:0.0001)
182920: accuracy:0.39 loss: 163.678 (lr:0.0001)
182930: accuracy:0.26 loss: 213.156 (lr:0.0001)
182940: accuracy:0.35 loss: 188.494 (lr:0.0001)
182950: accuracy:0.36 loss: 219.832 (lr:0.0001)
182960: accuracy:0.38 loss: 183.971 (lr:0.0001)
182970: accuracy:0.47 loss: 185.529 (lr:0.0001)
182980: accuracy:0.34 loss: 201.217 (lr:0.0001)
182990: accuracy:0.35 loss: 198.302 (lr:0.0001)
183000: accuracy:0.4 loss: 201.452 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
183000: ********* epoch 19 ********* test accuracy for all:0.26477 test loss: 256.311
183000: ********* epoch 19 ********* test accuracy for mode 0:0.0415 test loss: 467.442
183000: ********* epoch 19 ********* test accuracy for mode 1:0.0255 test loss: 448.88
183000: ********* epoch 19 ********* test accuracy for mode 2:0.071 test loss: 259.945
183000: ********* epoch 19 ********* test accuracy for mode 24:0.272 test loss: 272.613
183000: ********* epoch 19 ********* test accuracy for mode 25:0.251 test loss: 253.831
183000: ********* epoch 19 ********* test accuracy for mode 26:0.487 test loss: 164.343
183000: ********* epoch 19 ********* test accuracy for mode 27:0.2505 test loss: 261.484
183000: ********* epoch 19 ********* test accuracy for mode 28:0.2865 test loss: 255.617
183000: ********* epoch 19 ********* test accuracy for mode 29:0.2765 test loss: 256.866
183000: ********* epoch 19 ********* test accuracy for mode 30:0.258 test loss: 243.9
183000: ********* epoch 19 ********* test accuracy for mode 31:0.1995 test loss: 249.908
183000: ********* epoch 19 ********* test accuracy for mode 32:0.206 test loss: 233.707
183000: ********* epoch 19 ********* test accuracy for mode 33:0.2715 test loss: 233.338
183000: ********* epoch 19 ********* test accuracy for mode 34:0.265 test loss: 232.988
183000: ********* epoch 19 ********* test accuracy for mode 35:0.101 test loss: 416.279
183000: ********* epoch 19 ********* test accuracy for mode 36:0.3595 test loss: 422.29
183010: accuracy:0.32 loss: 193.142 (lr:0.0001)
183020: accuracy:0.38 loss: 200.935 (lr:0.0001)
183030: accuracy:0.41 loss: 196.379 (lr:0.0001)
183040: accuracy:0.44 loss: 188.528 (lr:0.0001)
183050: accuracy:0.38 loss: 194.935 (lr:0.0001)
183060: accuracy:0.45 loss: 175.469 (lr:0.0001)
183070: accuracy:0.31 loss: 185.475 (lr:0.0001)
183080: accuracy:0.36 loss: 220.053 (lr:0.0001)
183090: accuracy:0.29 loss: 205.153 (lr:0.0001)
183100: accuracy:0.36 loss: 204.633 (lr:0.0001)
183110: accuracy:0.33 loss: 193.463 (lr:0.0001)
183120: accuracy:0.41 loss: 203.825 (lr:0.0001)
183130: accuracy:0.35 loss: 188.215 (lr:0.0001)
183140: accuracy:0.37 loss: 208.558 (lr:0.0001)
183150: accuracy:0.45 loss: 192.056 (lr:0.0001)
183160: accuracy:0.33 loss: 198.641 (lr:0.0001)
183170: accuracy:0.37 loss: 210.19 (lr:0.0001)
183180: accuracy:0.4 loss: 192.43 (lr:0.0001)
183190: accuracy:0.42 loss: 197.89 (lr:0.0001)
183200: accuracy:0.35 loss: 192.68 (lr:0.0001)
183210: accuracy:0.42 loss: 191.065 (lr:0.0001)
183220: accuracy:0.37 loss: 195.207 (lr:0.0001)
183230: accuracy:0.38 loss: 207.894 (lr:0.0001)
183240: accuracy:0.38 loss: 199.17 (lr:0.0001)
183250: accuracy:0.39 loss: 195.129 (lr:0.0001)
183260: accuracy:0.4 loss: 192.282 (lr:0.0001)
183270: accuracy:0.46 loss: 184.559 (lr:0.0001)
183280: accuracy:0.48 loss: 172.29 (lr:0.0001)
183290: accuracy:0.35 loss: 199.863 (lr:0.0001)
183300: accuracy:0.45 loss: 186.138 (lr:0.0001)
183310: accuracy:0.42 loss: 185.714 (lr:0.0001)
183320: accuracy:0.39 loss: 188.087 (lr:0.0001)
183330: accuracy:0.38 loss: 203.99 (lr:0.0001)
183340: accuracy:0.33 loss: 213.91 (lr:0.0001)
183350: accuracy:0.38 loss: 189.699 (lr:0.0001)
183360: accuracy:0.35 loss: 208.43 (lr:0.0001)
183370: accuracy:0.36 loss: 184.892 (lr:0.0001)
183380: accuracy:0.45 loss: 186.055 (lr:0.0001)
183390: accuracy:0.4 loss: 220.852 (lr:0.0001)
183400: accuracy:0.35 loss: 197.382 (lr:0.0001)
183410: accuracy:0.35 loss: 205.208 (lr:0.0001)
183420: accuracy:0.48 loss: 177.426 (lr:0.0001)
183430: accuracy:0.45 loss: 159.085 (lr:0.0001)
183440: accuracy:0.28 loss: 219.361 (lr:0.0001)
183450: accuracy:0.27 loss: 185.88 (lr:0.0001)
183460: accuracy:0.39 loss: 197.621 (lr:0.0001)
183470: accuracy:0.36 loss: 200.298 (lr:0.0001)
183480: accuracy:0.44 loss: 193.0 (lr:0.0001)
183490: accuracy:0.45 loss: 172.279 (lr:0.0001)
183500: accuracy:0.42 loss: 222.943 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
183500: ********* epoch 19 ********* test accuracy for all:0.2615 test loss: 258.765
183500: ********* epoch 19 ********* test accuracy for mode 0:0.0435 test loss: 483.78
183500: ********* epoch 19 ********* test accuracy for mode 1:0.0255 test loss: 462.678
183500: ********* epoch 19 ********* test accuracy for mode 2:0.076 test loss: 260.163
183500: ********* epoch 19 ********* test accuracy for mode 24:0.2475 test loss: 280.658
183500: ********* epoch 19 ********* test accuracy for mode 25:0.2675 test loss: 254.644
183500: ********* epoch 19 ********* test accuracy for mode 26:0.492 test loss: 156.914
183500: ********* epoch 19 ********* test accuracy for mode 27:0.255 test loss: 272.341
183500: ********* epoch 19 ********* test accuracy for mode 28:0.2905 test loss: 265.201
183500: ********* epoch 19 ********* test accuracy for mode 29:0.2525 test loss: 273.402
183500: ********* epoch 19 ********* test accuracy for mode 30:0.2385 test loss: 253.097
183500: ********* epoch 19 ********* test accuracy for mode 31:0.209 test loss: 252.637
183500: ********* epoch 19 ********* test accuracy for mode 32:0.2085 test loss: 230.101
183500: ********* epoch 19 ********* test accuracy for mode 33:0.322 test loss: 225.5
183500: ********* epoch 19 ********* test accuracy for mode 34:0.2345 test loss: 234.3
183500: ********* epoch 19 ********* test accuracy for mode 35:0.114 test loss: 428.457
183500: ********* epoch 19 ********* test accuracy for mode 36:0.157 test loss: 466.511
183510: accuracy:0.33 loss: 199.135 (lr:0.0001)
183520: accuracy:0.36 loss: 189.627 (lr:0.0001)
183530: accuracy:0.4 loss: 203.768 (lr:0.0001)
183540: accuracy:0.35 loss: 190.392 (lr:0.0001)
183550: accuracy:0.37 loss: 202.355 (lr:0.0001)
183560: accuracy:0.33 loss: 205.246 (lr:0.0001)
183570: accuracy:0.45 loss: 176.765 (lr:0.0001)
183580: accuracy:0.34 loss: 219.352 (lr:0.0001)
183590: accuracy:0.37 loss: 185.927 (lr:0.0001)
183600: accuracy:0.39 loss: 195.26 (lr:0.0001)
183610: accuracy:0.35 loss: 214.424 (lr:0.0001)
183620: accuracy:0.48 loss: 176.891 (lr:0.0001)
183630: accuracy:0.43 loss: 176.865 (lr:0.0001)
183640: accuracy:0.33 loss: 207.581 (lr:0.0001)
183650: accuracy:0.36 loss: 197.873 (lr:0.0001)
183660: accuracy:0.35 loss: 185.517 (lr:0.0001)
183670: accuracy:0.36 loss: 199.245 (lr:0.0001)
183680: accuracy:0.31 loss: 208.13 (lr:0.0001)
183690: accuracy:0.33 loss: 194.23 (lr:0.0001)
183700: accuracy:0.36 loss: 187.361 (lr:0.0001)
183710: accuracy:0.35 loss: 188.751 (lr:0.0001)
183720: accuracy:0.36 loss: 191.975 (lr:0.0001)
183730: accuracy:0.28 loss: 214.576 (lr:0.0001)
183740: accuracy:0.45 loss: 192.452 (lr:0.0001)
183750: accuracy:0.39 loss: 197.586 (lr:0.0001)
183760: accuracy:0.42 loss: 196.875 (lr:0.0001)
183770: accuracy:0.33 loss: 193.597 (lr:0.0001)
183780: accuracy:0.42 loss: 190.625 (lr:0.0001)
183790: accuracy:0.39 loss: 187.118 (lr:0.0001)
183800: accuracy:0.44 loss: 211.922 (lr:0.0001)
183810: accuracy:0.47 loss: 179.976 (lr:0.0001)
183820: accuracy:0.33 loss: 210.412 (lr:0.0001)
183830: accuracy:0.31 loss: 223.795 (lr:0.0001)
183840: accuracy:0.42 loss: 188.796 (lr:0.0001)
183850: accuracy:0.32 loss: 217.096 (lr:0.0001)
183860: accuracy:0.44 loss: 190.649 (lr:0.0001)
183870: accuracy:0.37 loss: 201.948 (lr:0.0001)
183880: accuracy:0.38 loss: 198.574 (lr:0.0001)
183890: accuracy:0.35 loss: 204.674 (lr:0.0001)
183900: accuracy:0.34 loss: 213.363 (lr:0.0001)
183910: accuracy:0.28 loss: 212.53 (lr:0.0001)
183920: accuracy:0.41 loss: 187.665 (lr:0.0001)
183930: accuracy:0.4 loss: 191.551 (lr:0.0001)
183940: accuracy:0.3 loss: 232.5 (lr:0.0001)
183950: accuracy:0.34 loss: 212.076 (lr:0.0001)
183960: accuracy:0.27 loss: 208.135 (lr:0.0001)
183970: accuracy:0.42 loss: 178.895 (lr:0.0001)
183980: accuracy:0.41 loss: 179.281 (lr:0.0001)
183990: accuracy:0.37 loss: 197.578 (lr:0.0001)
184000: accuracy:0.4 loss: 181.827 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
184000: ********* epoch 19 ********* test accuracy for all:0.266 test loss: 258.025
184000: ********* epoch 19 ********* test accuracy for mode 0:0.028 test loss: 498.196
184000: ********* epoch 19 ********* test accuracy for mode 1:0.0165 test loss: 467.056
184000: ********* epoch 19 ********* test accuracy for mode 2:0.0665 test loss: 258.1
184000: ********* epoch 19 ********* test accuracy for mode 24:0.25 test loss: 269.454
184000: ********* epoch 19 ********* test accuracy for mode 25:0.2805 test loss: 251.316
184000: ********* epoch 19 ********* test accuracy for mode 26:0.4815 test loss: 162.906
184000: ********* epoch 19 ********* test accuracy for mode 27:0.2605 test loss: 266.977
184000: ********* epoch 19 ********* test accuracy for mode 28:0.2785 test loss: 262.802
184000: ********* epoch 19 ********* test accuracy for mode 29:0.262 test loss: 266.509
184000: ********* epoch 19 ********* test accuracy for mode 30:0.2605 test loss: 244.812
184000: ********* epoch 19 ********* test accuracy for mode 31:0.2055 test loss: 249.626
184000: ********* epoch 19 ********* test accuracy for mode 32:0.192 test loss: 232.894
184000: ********* epoch 19 ********* test accuracy for mode 33:0.2935 test loss: 229.281
184000: ********* epoch 19 ********* test accuracy for mode 34:0.256 test loss: 233.663
184000: ********* epoch 19 ********* test accuracy for mode 35:0.094 test loss: 457.372
184000: ********* epoch 19 ********* test accuracy for mode 36:0.2225 test loss: 489.244
184010: accuracy:0.31 loss: 214.708 (lr:0.0001)
184020: accuracy:0.41 loss: 186.43 (lr:0.0001)
184030: accuracy:0.27 loss: 215.825 (lr:0.0001)
184040: accuracy:0.35 loss: 199.691 (lr:0.0001)
184050: accuracy:0.39 loss: 188.754 (lr:0.0001)
184060: accuracy:0.41 loss: 192.916 (lr:0.0001)
184070: accuracy:0.23 loss: 225.915 (lr:0.0001)
184080: accuracy:0.37 loss: 200.5 (lr:0.0001)
184090: accuracy:0.39 loss: 199.056 (lr:0.0001)
184100: accuracy:0.33 loss: 197.551 (lr:0.0001)
184110: accuracy:0.44 loss: 199.418 (lr:0.0001)
184120: accuracy:0.31 loss: 189.184 (lr:0.0001)
184130: accuracy:0.31 loss: 202.417 (lr:0.0001)
184140: accuracy:0.47 loss: 204.792 (lr:0.0001)
184150: accuracy:0.31 loss: 208.227 (lr:0.0001)
184160: accuracy:0.48 loss: 181.749 (lr:0.0001)
184170: accuracy:0.32 loss: 204.669 (lr:0.0001)
184180: accuracy:0.33 loss: 212.738 (lr:0.0001)
184190: accuracy:0.39 loss: 196.228 (lr:0.0001)
184200: accuracy:0.37 loss: 191.759 (lr:0.0001)
184210: accuracy:0.33 loss: 194.035 (lr:0.0001)
184220: accuracy:0.4 loss: 202.648 (lr:0.0001)
184230: accuracy:0.38 loss: 204.055 (lr:0.0001)
184240: accuracy:0.39 loss: 194.907 (lr:0.0001)
184250: accuracy:0.32 loss: 204.393 (lr:0.0001)
184260: accuracy:0.36 loss: 199.352 (lr:0.0001)
184270: accuracy:0.38 loss: 213.42 (lr:0.0001)
184280: accuracy:0.39 loss: 189.607 (lr:0.0001)
184290: accuracy:0.32 loss: 193.057 (lr:0.0001)
184300: accuracy:0.33 loss: 199.511 (lr:0.0001)
184310: accuracy:0.4 loss: 201.717 (lr:0.0001)
184320: accuracy:0.32 loss: 207.599 (lr:0.0001)
184330: accuracy:0.34 loss: 184.617 (lr:0.0001)
184340: accuracy:0.29 loss: 215.332 (lr:0.0001)
184350: accuracy:0.31 loss: 210.232 (lr:0.0001)
184360: accuracy:0.32 loss: 214.282 (lr:0.0001)
184370: accuracy:0.35 loss: 187.112 (lr:0.0001)
184380: accuracy:0.38 loss: 192.981 (lr:0.0001)
184390: accuracy:0.39 loss: 200.038 (lr:0.0001)
184400: accuracy:0.38 loss: 175.213 (lr:0.0001)
184410: accuracy:0.32 loss: 213.231 (lr:0.0001)
184420: accuracy:0.44 loss: 185.995 (lr:0.0001)
184430: accuracy:0.32 loss: 202.436 (lr:0.0001)
184440: accuracy:0.39 loss: 188.155 (lr:0.0001)
184450: accuracy:0.32 loss: 202.783 (lr:0.0001)
184460: accuracy:0.34 loss: 224.237 (lr:0.0001)
184470: accuracy:0.41 loss: 190.448 (lr:0.0001)
184480: accuracy:0.39 loss: 198.506 (lr:0.0001)
184490: accuracy:0.42 loss: 196.65 (lr:0.0001)
184500: accuracy:0.35 loss: 208.816 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
184500: ********* epoch 19 ********* test accuracy for all:0.260635 test loss: 261.455
184500: ********* epoch 19 ********* test accuracy for mode 0:0.037 test loss: 484.952
184500: ********* epoch 19 ********* test accuracy for mode 1:0.0245 test loss: 453.075
184500: ********* epoch 19 ********* test accuracy for mode 2:0.0705 test loss: 258.535
184500: ********* epoch 19 ********* test accuracy for mode 24:0.2255 test loss: 285.6
184500: ********* epoch 19 ********* test accuracy for mode 25:0.2845 test loss: 251.532
184500: ********* epoch 19 ********* test accuracy for mode 26:0.5235 test loss: 156.099
184500: ********* epoch 19 ********* test accuracy for mode 27:0.2575 test loss: 272.355
184500: ********* epoch 19 ********* test accuracy for mode 28:0.2545 test loss: 272.175
184500: ********* epoch 19 ********* test accuracy for mode 29:0.237 test loss: 276.439
184500: ********* epoch 19 ********* test accuracy for mode 30:0.253 test loss: 251.46
184500: ********* epoch 19 ********* test accuracy for mode 31:0.1965 test loss: 260.758
184500: ********* epoch 19 ********* test accuracy for mode 32:0.191 test loss: 240.208
184500: ********* epoch 19 ********* test accuracy for mode 33:0.303 test loss: 233.068
184500: ********* epoch 19 ********* test accuracy for mode 34:0.215 test loss: 240.355
184500: ********* epoch 19 ********* test accuracy for mode 35:0.0985 test loss: 450.499
184500: ********* epoch 19 ********* test accuracy for mode 36:0.235 test loss: 485.641
184510: accuracy:0.29 loss: 220.264 (lr:0.0001)
184520: accuracy:0.37 loss: 191.803 (lr:0.0001)
184530: accuracy:0.36 loss: 196.555 (lr:0.0001)
184540: accuracy:0.35 loss: 179.676 (lr:0.0001)
184550: accuracy:0.35 loss: 198.656 (lr:0.0001)
184560: accuracy:0.36 loss: 195.806 (lr:0.0001)
184570: accuracy:0.42 loss: 200.337 (lr:0.0001)
184580: accuracy:0.33 loss: 205.469 (lr:0.0001)
184590: accuracy:0.44 loss: 188.973 (lr:0.0001)
184600: accuracy:0.34 loss: 196.06 (lr:0.0001)
184610: accuracy:0.31 loss: 220.737 (lr:0.0001)
184620: accuracy:0.34 loss: 195.2 (lr:0.0001)
184630: accuracy:0.4 loss: 194.616 (lr:0.0001)
184640: accuracy:0.39 loss: 198.379 (lr:0.0001)
184650: accuracy:0.3 loss: 193.815 (lr:0.0001)
184660: accuracy:0.4 loss: 209.008 (lr:0.0001)
184670: accuracy:0.37 loss: 179.982 (lr:0.0001)
184680: accuracy:0.39 loss: 211.098 (lr:0.0001)
184690: accuracy:0.33 loss: 209.774 (lr:0.0001)
184700: accuracy:0.41 loss: 188.138 (lr:0.0001)
184710: accuracy:0.45 loss: 190.472 (lr:0.0001)
184720: accuracy:0.36 loss: 194.62 (lr:0.0001)
184730: accuracy:0.34 loss: 198.303 (lr:0.0001)
184740: accuracy:0.44 loss: 171.383 (lr:0.0001)
184750: accuracy:0.31 loss: 210.32 (lr:0.0001)
184760: accuracy:0.34 loss: 217.573 (lr:0.0001)
184770: accuracy:0.37 loss: 199.05 (lr:0.0001)
184780: accuracy:0.42 loss: 178.484 (lr:0.0001)
184790: accuracy:0.43 loss: 170.3 (lr:0.0001)
184800: accuracy:0.38 loss: 190.162 (lr:0.0001)
184810: accuracy:0.29 loss: 219.532 (lr:0.0001)
184820: accuracy:0.41 loss: 181.36 (lr:0.0001)
184830: accuracy:0.36 loss: 202.162 (lr:0.0001)
184840: accuracy:0.35 loss: 195.56 (lr:0.0001)
184850: accuracy:0.41 loss: 197.423 (lr:0.0001)
184860: accuracy:0.44 loss: 195.9 (lr:0.0001)
184870: accuracy:0.42 loss: 203.252 (lr:0.0001)
184880: accuracy:0.43 loss: 171.045 (lr:0.0001)
184890: accuracy:0.42 loss: 177.758 (lr:0.0001)
184900: accuracy:0.4 loss: 195.981 (lr:0.0001)
184910: accuracy:0.34 loss: 195.844 (lr:0.0001)
184920: accuracy:0.46 loss: 178.103 (lr:0.0001)
184930: accuracy:0.45 loss: 182.362 (lr:0.0001)
184940: accuracy:0.38 loss: 196.56 (lr:0.0001)
184950: accuracy:0.36 loss: 214.019 (lr:0.0001)
184960: accuracy:0.31 loss: 193.445 (lr:0.0001)
184970: accuracy:0.47 loss: 176.757 (lr:0.0001)
184980: accuracy:0.43 loss: 172.385 (lr:0.0001)
184990: accuracy:0.37 loss: 203.537 (lr:0.0001)
185000: accuracy:0.36 loss: 207.929 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
185000: ********* epoch 20 ********* test accuracy for all:0.264824 test loss: 258.87
185000: ********* epoch 20 ********* test accuracy for mode 0:0.04 test loss: 483.329
185000: ********* epoch 20 ********* test accuracy for mode 1:0.026 test loss: 459.627
185000: ********* epoch 20 ********* test accuracy for mode 2:0.06 test loss: 256.574
185000: ********* epoch 20 ********* test accuracy for mode 24:0.272 test loss: 270.053
185000: ********* epoch 20 ********* test accuracy for mode 25:0.2845 test loss: 248.083
185000: ********* epoch 20 ********* test accuracy for mode 26:0.4605 test loss: 162.237
185000: ********* epoch 20 ********* test accuracy for mode 27:0.2825 test loss: 261.175
185000: ********* epoch 20 ********* test accuracy for mode 28:0.2875 test loss: 255.417
185000: ********* epoch 20 ********* test accuracy for mode 29:0.249 test loss: 263.273
185000: ********* epoch 20 ********* test accuracy for mode 30:0.2385 test loss: 243.005
185000: ********* epoch 20 ********* test accuracy for mode 31:0.2575 test loss: 242.397
185000: ********* epoch 20 ********* test accuracy for mode 32:0.176 test loss: 232.874
185000: ********* epoch 20 ********* test accuracy for mode 33:0.2735 test loss: 228.978
185000: ********* epoch 20 ********* test accuracy for mode 34:0.265 test loss: 229.162
185000: ********* epoch 20 ********* test accuracy for mode 35:0.1185 test loss: 454.21
185000: ********* epoch 20 ********* test accuracy for mode 36:0.223 test loss: 492.519
185010: accuracy:0.43 loss: 189.34 (lr:0.0001)
185020: accuracy:0.43 loss: 196.228 (lr:0.0001)
185030: accuracy:0.44 loss: 190.302 (lr:0.0001)
185040: accuracy:0.37 loss: 211.335 (lr:0.0001)
185050: accuracy:0.33 loss: 201.56 (lr:0.0001)
185060: accuracy:0.34 loss: 202.371 (lr:0.0001)
185070: accuracy:0.35 loss: 222.152 (lr:0.0001)
185080: accuracy:0.34 loss: 191.94 (lr:0.0001)
185090: accuracy:0.33 loss: 198.236 (lr:0.0001)
185100: accuracy:0.32 loss: 195.439 (lr:0.0001)
185110: accuracy:0.35 loss: 210.326 (lr:0.0001)
185120: accuracy:0.26 loss: 211.625 (lr:0.0001)
185130: accuracy:0.36 loss: 196.432 (lr:0.0001)
185140: accuracy:0.43 loss: 178.884 (lr:0.0001)
185150: accuracy:0.33 loss: 194.366 (lr:0.0001)
185160: accuracy:0.38 loss: 205.878 (lr:0.0001)
185170: accuracy:0.4 loss: 194.304 (lr:0.0001)
185180: accuracy:0.32 loss: 180.275 (lr:0.0001)
185190: accuracy:0.32 loss: 192.925 (lr:0.0001)
185200: accuracy:0.34 loss: 194.032 (lr:0.0001)
185210: accuracy:0.32 loss: 197.441 (lr:0.0001)
185220: accuracy:0.3 loss: 208.617 (lr:0.0001)
185230: accuracy:0.51 loss: 173.739 (lr:0.0001)
185240: accuracy:0.39 loss: 189.291 (lr:0.0001)
185250: accuracy:0.37 loss: 193.444 (lr:0.0001)
185260: accuracy:0.34 loss: 196.874 (lr:0.0001)
185270: accuracy:0.35 loss: 199.396 (lr:0.0001)
185280: accuracy:0.42 loss: 188.201 (lr:0.0001)
185290: accuracy:0.38 loss: 195.851 (lr:0.0001)
185300: accuracy:0.4 loss: 206.953 (lr:0.0001)
185310: accuracy:0.34 loss: 197.978 (lr:0.0001)
185320: accuracy:0.36 loss: 193.797 (lr:0.0001)
185330: accuracy:0.39 loss: 195.322 (lr:0.0001)
185340: accuracy:0.34 loss: 190.679 (lr:0.0001)
185350: accuracy:0.44 loss: 174.351 (lr:0.0001)
185360: accuracy:0.28 loss: 204.721 (lr:0.0001)
185370: accuracy:0.29 loss: 206.403 (lr:0.0001)
185380: accuracy:0.36 loss: 197.975 (lr:0.0001)
185390: accuracy:0.44 loss: 183.352 (lr:0.0001)
185400: accuracy:0.44 loss: 194.823 (lr:0.0001)
185410: accuracy:0.4 loss: 195.314 (lr:0.0001)
185420: accuracy:0.37 loss: 196.562 (lr:0.0001)
185430: accuracy:0.34 loss: 194.601 (lr:0.0001)
185440: accuracy:0.34 loss: 213.167 (lr:0.0001)
185450: accuracy:0.45 loss: 189.759 (lr:0.0001)
185460: accuracy:0.46 loss: 181.87 (lr:0.0001)
185470: accuracy:0.33 loss: 187.653 (lr:0.0001)
185480: accuracy:0.37 loss: 212.167 (lr:0.0001)
185490: accuracy:0.4 loss: 210.391 (lr:0.0001)
185500: accuracy:0.41 loss: 206.78 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
185500: ********* epoch 20 ********* test accuracy for all:0.264 test loss: 261.384
185500: ********* epoch 20 ********* test accuracy for mode 0:0.041 test loss: 491.777
185500: ********* epoch 20 ********* test accuracy for mode 1:0.0225 test loss: 474.776
185500: ********* epoch 20 ********* test accuracy for mode 2:0.1065 test loss: 250.992
185500: ********* epoch 20 ********* test accuracy for mode 24:0.2525 test loss: 277.026
185500: ********* epoch 20 ********* test accuracy for mode 25:0.2535 test loss: 252.99
185500: ********* epoch 20 ********* test accuracy for mode 26:0.5275 test loss: 153.158
185500: ********* epoch 20 ********* test accuracy for mode 27:0.251 test loss: 268.006
185500: ********* epoch 20 ********* test accuracy for mode 28:0.295 test loss: 258.801
185500: ********* epoch 20 ********* test accuracy for mode 29:0.225 test loss: 272.869
185500: ********* epoch 20 ********* test accuracy for mode 30:0.253 test loss: 246.958
185500: ********* epoch 20 ********* test accuracy for mode 31:0.224 test loss: 250.531
185500: ********* epoch 20 ********* test accuracy for mode 32:0.2 test loss: 233.616
185500: ********* epoch 20 ********* test accuracy for mode 33:0.2755 test loss: 233.897
185500: ********* epoch 20 ********* test accuracy for mode 34:0.2085 test loss: 238.716
185500: ********* epoch 20 ********* test accuracy for mode 35:0.106 test loss: 478.579
185500: ********* epoch 20 ********* test accuracy for mode 36:0.1625 test loss: 524.679
185510: accuracy:0.38 loss: 193.048 (lr:0.0001)
185520: accuracy:0.32 loss: 196.806 (lr:0.0001)
185530: accuracy:0.41 loss: 180.787 (lr:0.0001)
185540: accuracy:0.41 loss: 199.616 (lr:0.0001)
185550: accuracy:0.37 loss: 198.21 (lr:0.0001)
185560: accuracy:0.35 loss: 229.157 (lr:0.0001)
185570: accuracy:0.41 loss: 189.894 (lr:0.0001)
185580: accuracy:0.42 loss: 178.221 (lr:0.0001)
185590: accuracy:0.4 loss: 181.405 (lr:0.0001)
185600: accuracy:0.36 loss: 185.461 (lr:0.0001)
185610: accuracy:0.35 loss: 209.018 (lr:0.0001)
185620: accuracy:0.36 loss: 190.593 (lr:0.0001)
185630: accuracy:0.28 loss: 206.555 (lr:0.0001)
185640: accuracy:0.37 loss: 178.285 (lr:0.0001)
185650: accuracy:0.35 loss: 214.956 (lr:0.0001)
185660: accuracy:0.27 loss: 200.969 (lr:0.0001)
185670: accuracy:0.46 loss: 189.387 (lr:0.0001)
185680: accuracy:0.38 loss: 198.55 (lr:0.0001)
185690: accuracy:0.35 loss: 203.941 (lr:0.0001)
185700: accuracy:0.34 loss: 203.203 (lr:0.0001)
185710: accuracy:0.31 loss: 214.166 (lr:0.0001)
185720: accuracy:0.3 loss: 202.105 (lr:0.0001)
185730: accuracy:0.4 loss: 196.411 (lr:0.0001)
185740: accuracy:0.38 loss: 190.796 (lr:0.0001)
185750: accuracy:0.45 loss: 204.378 (lr:0.0001)
185760: accuracy:0.33 loss: 197.688 (lr:0.0001)
185770: accuracy:0.4 loss: 169.875 (lr:0.0001)
185780: accuracy:0.37 loss: 197.941 (lr:0.0001)
185790: accuracy:0.43 loss: 173.818 (lr:0.0001)
185800: accuracy:0.35 loss: 191.409 (lr:0.0001)
185810: accuracy:0.4 loss: 191.568 (lr:0.0001)
185820: accuracy:0.45 loss: 190.717 (lr:0.0001)
185830: accuracy:0.37 loss: 209.678 (lr:0.0001)
185840: accuracy:0.3 loss: 222.539 (lr:0.0001)
185850: accuracy:0.37 loss: 207.64 (lr:0.0001)
185860: accuracy:0.39 loss: 193.391 (lr:0.0001)
185870: accuracy:0.48 loss: 194.948 (lr:0.0001)
185880: accuracy:0.44 loss: 187.565 (lr:0.0001)
185890: accuracy:0.37 loss: 222.334 (lr:0.0001)
185900: accuracy:0.36 loss: 186.445 (lr:0.0001)
185910: accuracy:0.44 loss: 181.61 (lr:0.0001)
185920: accuracy:0.34 loss: 216.926 (lr:0.0001)
185930: accuracy:0.4 loss: 177.988 (lr:0.0001)
185940: accuracy:0.33 loss: 199.29 (lr:0.0001)
185950: accuracy:0.37 loss: 207.485 (lr:0.0001)
185960: accuracy:0.3 loss: 210.736 (lr:0.0001)
185970: accuracy:0.29 loss: 211.249 (lr:0.0001)
185980: accuracy:0.28 loss: 214.636 (lr:0.0001)
185990: accuracy:0.43 loss: 204.175 (lr:0.0001)
186000: accuracy:0.37 loss: 201.016 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
186000: ********* epoch 20 ********* test accuracy for all:0.261878 test loss: 262.439
186000: ********* epoch 20 ********* test accuracy for mode 0:0.0355 test loss: 495.022
186000: ********* epoch 20 ********* test accuracy for mode 1:0.0295 test loss: 470.836
186000: ********* epoch 20 ********* test accuracy for mode 2:0.1255 test loss: 247.556
186000: ********* epoch 20 ********* test accuracy for mode 24:0.2495 test loss: 278.695
186000: ********* epoch 20 ********* test accuracy for mode 25:0.247 test loss: 252.242
186000: ********* epoch 20 ********* test accuracy for mode 26:0.514 test loss: 162.306
186000: ********* epoch 20 ********* test accuracy for mode 27:0.2525 test loss: 267.728
186000: ********* epoch 20 ********* test accuracy for mode 28:0.2895 test loss: 263.201
186000: ********* epoch 20 ********* test accuracy for mode 29:0.2305 test loss: 276.694
186000: ********* epoch 20 ********* test accuracy for mode 30:0.2325 test loss: 252.467
186000: ********* epoch 20 ********* test accuracy for mode 31:0.22 test loss: 251.411
186000: ********* epoch 20 ********* test accuracy for mode 32:0.2775 test loss: 223.621
186000: ********* epoch 20 ********* test accuracy for mode 33:0.2795 test loss: 228.727
186000: ********* epoch 20 ********* test accuracy for mode 34:0.2235 test loss: 234.598
186000: ********* epoch 20 ********* test accuracy for mode 35:0.1015 test loss: 468.636
186000: ********* epoch 20 ********* test accuracy for mode 36:0.114 test loss: 530.869
186010: accuracy:0.37 loss: 181.955 (lr:0.0001)
186020: accuracy:0.34 loss: 207.555 (lr:0.0001)
186030: accuracy:0.45 loss: 193.45 (lr:0.0001)
186040: accuracy:0.4 loss: 201.776 (lr:0.0001)
186050: accuracy:0.37 loss: 205.177 (lr:0.0001)
186060: accuracy:0.38 loss: 195.623 (lr:0.0001)
186070: accuracy:0.33 loss: 198.867 (lr:0.0001)
186080: accuracy:0.49 loss: 191.929 (lr:0.0001)
186090: accuracy:0.37 loss: 203.076 (lr:0.0001)
186100: accuracy:0.34 loss: 204.189 (lr:0.0001)
186110: accuracy:0.38 loss: 192.167 (lr:0.0001)
186120: accuracy:0.47 loss: 185.782 (lr:0.0001)
186130: accuracy:0.38 loss: 200.939 (lr:0.0001)
186140: accuracy:0.41 loss: 188.67 (lr:0.0001)
186150: accuracy:0.41 loss: 188.437 (lr:0.0001)
186160: accuracy:0.36 loss: 201.983 (lr:0.0001)
186170: accuracy:0.41 loss: 194.759 (lr:0.0001)
186180: accuracy:0.32 loss: 223.545 (lr:0.0001)
186190: accuracy:0.37 loss: 196.978 (lr:0.0001)
186200: accuracy:0.39 loss: 196.757 (lr:0.0001)
186210: accuracy:0.32 loss: 204.605 (lr:0.0001)
186220: accuracy:0.4 loss: 187.107 (lr:0.0001)
186230: accuracy:0.37 loss: 193.499 (lr:0.0001)
186240: accuracy:0.42 loss: 191.554 (lr:0.0001)
186250: accuracy:0.32 loss: 210.657 (lr:0.0001)
186260: accuracy:0.42 loss: 192.006 (lr:0.0001)
186270: accuracy:0.44 loss: 182.932 (lr:0.0001)
186280: accuracy:0.43 loss: 169.048 (lr:0.0001)
186290: accuracy:0.43 loss: 176.451 (lr:0.0001)
186300: accuracy:0.42 loss: 188.73 (lr:0.0001)
186310: accuracy:0.36 loss: 205.946 (lr:0.0001)
186320: accuracy:0.39 loss: 200.839 (lr:0.0001)
186330: accuracy:0.32 loss: 201.709 (lr:0.0001)
186340: accuracy:0.3 loss: 215.418 (lr:0.0001)
186350: accuracy:0.31 loss: 188.069 (lr:0.0001)
186360: accuracy:0.4 loss: 198.513 (lr:0.0001)
186370: accuracy:0.36 loss: 191.709 (lr:0.0001)
186380: accuracy:0.35 loss: 195.219 (lr:0.0001)
186390: accuracy:0.37 loss: 185.523 (lr:0.0001)
186400: accuracy:0.36 loss: 213.664 (lr:0.0001)
186410: accuracy:0.29 loss: 205.798 (lr:0.0001)
186420: accuracy:0.37 loss: 198.274 (lr:0.0001)
186430: accuracy:0.41 loss: 195.084 (lr:0.0001)
186440: accuracy:0.37 loss: 206.068 (lr:0.0001)
186450: accuracy:0.36 loss: 201.317 (lr:0.0001)
186460: accuracy:0.48 loss: 176.655 (lr:0.0001)
186470: accuracy:0.41 loss: 200.001 (lr:0.0001)
186480: accuracy:0.39 loss: 211.442 (lr:0.0001)
186490: accuracy:0.4 loss: 200.943 (lr:0.0001)
186500: accuracy:0.42 loss: 193.603 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
186500: ********* epoch 20 ********* test accuracy for all:0.259959 test loss: 261.972
186500: ********* epoch 20 ********* test accuracy for mode 0:0.0355 test loss: 486.512
186500: ********* epoch 20 ********* test accuracy for mode 1:0.024 test loss: 458.804
186500: ********* epoch 20 ********* test accuracy for mode 2:0.0625 test loss: 257.173
186500: ********* epoch 20 ********* test accuracy for mode 24:0.2455 test loss: 285.748
186500: ********* epoch 20 ********* test accuracy for mode 25:0.269 test loss: 255.315
186500: ********* epoch 20 ********* test accuracy for mode 26:0.51 test loss: 160.389
186500: ********* epoch 20 ********* test accuracy for mode 27:0.227 test loss: 282.281
186500: ********* epoch 20 ********* test accuracy for mode 28:0.2625 test loss: 276.414
186500: ********* epoch 20 ********* test accuracy for mode 29:0.2415 test loss: 281.214
186500: ********* epoch 20 ********* test accuracy for mode 30:0.233 test loss: 263.964
186500: ********* epoch 20 ********* test accuracy for mode 31:0.1735 test loss: 267.052
186500: ********* epoch 20 ********* test accuracy for mode 32:0.207 test loss: 234.322
186500: ********* epoch 20 ********* test accuracy for mode 33:0.3005 test loss: 230.775
186500: ********* epoch 20 ********* test accuracy for mode 34:0.2725 test loss: 229.303
186500: ********* epoch 20 ********* test accuracy for mode 35:0.108 test loss: 468.483
186500: ********* epoch 20 ********* test accuracy for mode 36:0.063 test loss: 556.699
186510: accuracy:0.39 loss: 188.925 (lr:0.0001)
186520: accuracy:0.36 loss: 193.521 (lr:0.0001)
186530: accuracy:0.42 loss: 196.428 (lr:0.0001)
186540: accuracy:0.31 loss: 205.129 (lr:0.0001)
186550: accuracy:0.34 loss: 211.42 (lr:0.0001)
186560: accuracy:0.37 loss: 195.234 (lr:0.0001)
186570: accuracy:0.39 loss: 201.803 (lr:0.0001)
186580: accuracy:0.32 loss: 209.784 (lr:0.0001)
186590: accuracy:0.37 loss: 194.788 (lr:0.0001)
186600: accuracy:0.36 loss: 187.812 (lr:0.0001)
186610: accuracy:0.47 loss: 178.254 (lr:0.0001)
186620: accuracy:0.39 loss: 185.961 (lr:0.0001)
186630: accuracy:0.32 loss: 198.237 (lr:0.0001)
186640: accuracy:0.3 loss: 200.997 (lr:0.0001)
186650: accuracy:0.45 loss: 164.573 (lr:0.0001)
186660: accuracy:0.34 loss: 200.536 (lr:0.0001)
186670: accuracy:0.34 loss: 196.702 (lr:0.0001)
186680: accuracy:0.36 loss: 201.649 (lr:0.0001)
186690: accuracy:0.28 loss: 217.712 (lr:0.0001)
186700: accuracy:0.32 loss: 205.933 (lr:0.0001)
186710: accuracy:0.3 loss: 228.15 (lr:0.0001)
186720: accuracy:0.42 loss: 196.378 (lr:0.0001)
186730: accuracy:0.34 loss: 212.924 (lr:0.0001)
186740: accuracy:0.4 loss: 198.994 (lr:0.0001)
186750: accuracy:0.36 loss: 212.801 (lr:0.0001)
186760: accuracy:0.31 loss: 203.958 (lr:0.0001)
186770: accuracy:0.36 loss: 201.046 (lr:0.0001)
186780: accuracy:0.36 loss: 228.386 (lr:0.0001)
186790: accuracy:0.31 loss: 213.607 (lr:0.0001)
186800: accuracy:0.32 loss: 221.675 (lr:0.0001)
186810: accuracy:0.46 loss: 182.276 (lr:0.0001)
186820: accuracy:0.37 loss: 202.054 (lr:0.0001)
186830: accuracy:0.33 loss: 193.348 (lr:0.0001)
186840: accuracy:0.42 loss: 198.811 (lr:0.0001)
186850: accuracy:0.32 loss: 197.762 (lr:0.0001)
186860: accuracy:0.47 loss: 165.987 (lr:0.0001)
186870: accuracy:0.35 loss: 201.696 (lr:0.0001)
186880: accuracy:0.35 loss: 203.404 (lr:0.0001)
186890: accuracy:0.47 loss: 200.46 (lr:0.0001)
186900: accuracy:0.37 loss: 221.655 (lr:0.0001)
186910: accuracy:0.39 loss: 199.081 (lr:0.0001)
186920: accuracy:0.35 loss: 203.626 (lr:0.0001)
186930: accuracy:0.5 loss: 181.536 (lr:0.0001)
186940: accuracy:0.37 loss: 185.329 (lr:0.0001)
186950: accuracy:0.34 loss: 214.859 (lr:0.0001)
186960: accuracy:0.35 loss: 189.047 (lr:0.0001)
186970: accuracy:0.36 loss: 219.198 (lr:0.0001)
186980: accuracy:0.29 loss: 211.241 (lr:0.0001)
186990: accuracy:0.34 loss: 193.791 (lr:0.0001)
187000: accuracy:0.42 loss: 201.582 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
187000: ********* epoch 20 ********* test accuracy for all:0.260554 test loss: 262.482
187000: ********* epoch 20 ********* test accuracy for mode 0:0.04 test loss: 489.94
187000: ********* epoch 20 ********* test accuracy for mode 1:0.025 test loss: 472.19
187000: ********* epoch 20 ********* test accuracy for mode 2:0.053 test loss: 262.969
187000: ********* epoch 20 ********* test accuracy for mode 24:0.2505 test loss: 273.903
187000: ********* epoch 20 ********* test accuracy for mode 25:0.289 test loss: 245.78
187000: ********* epoch 20 ********* test accuracy for mode 26:0.444 test loss: 166.696
187000: ********* epoch 20 ********* test accuracy for mode 27:0.235 test loss: 274.601
187000: ********* epoch 20 ********* test accuracy for mode 28:0.283 test loss: 267.093
187000: ********* epoch 20 ********* test accuracy for mode 29:0.2285 test loss: 278.724
187000: ********* epoch 20 ********* test accuracy for mode 30:0.2395 test loss: 259.527
187000: ********* epoch 20 ********* test accuracy for mode 31:0.1905 test loss: 261.766
187000: ********* epoch 20 ********* test accuracy for mode 32:0.225 test loss: 231.107
187000: ********* epoch 20 ********* test accuracy for mode 33:0.258 test loss: 231.35
187000: ********* epoch 20 ********* test accuracy for mode 34:0.281 test loss: 228.041
187000: ********* epoch 20 ********* test accuracy for mode 35:0.1245 test loss: 455.797
187000: ********* epoch 20 ********* test accuracy for mode 36:0.1695 test loss: 515.172
187010: accuracy:0.35 loss: 200.156 (lr:0.0001)
187020: accuracy:0.36 loss: 214.83 (lr:0.0001)
187030: accuracy:0.41 loss: 188.116 (lr:0.0001)
187040: accuracy:0.38 loss: 189.619 (lr:0.0001)
187050: accuracy:0.41 loss: 204.347 (lr:0.0001)
187060: accuracy:0.34 loss: 195.977 (lr:0.0001)
187070: accuracy:0.29 loss: 207.5 (lr:0.0001)
187080: accuracy:0.34 loss: 202.861 (lr:0.0001)
187090: accuracy:0.39 loss: 179.813 (lr:0.0001)
187100: accuracy:0.39 loss: 200.536 (lr:0.0001)
187110: accuracy:0.36 loss: 192.771 (lr:0.0001)
187120: accuracy:0.39 loss: 199.27 (lr:0.0001)
187130: accuracy:0.31 loss: 205.972 (lr:0.0001)
187140: accuracy:0.32 loss: 210.475 (lr:0.0001)
187150: accuracy:0.39 loss: 183.548 (lr:0.0001)
187160: accuracy:0.35 loss: 179.963 (lr:0.0001)
187170: accuracy:0.35 loss: 209.056 (lr:0.0001)
187180: accuracy:0.38 loss: 198.803 (lr:0.0001)
187190: accuracy:0.28 loss: 222.323 (lr:0.0001)
187200: accuracy:0.46 loss: 168.639 (lr:0.0001)
187210: accuracy:0.38 loss: 220.015 (lr:0.0001)
187220: accuracy:0.38 loss: 196.101 (lr:0.0001)
187230: accuracy:0.41 loss: 186.908 (lr:0.0001)
187240: accuracy:0.4 loss: 182.265 (lr:0.0001)
187250: accuracy:0.38 loss: 191.682 (lr:0.0001)
187260: accuracy:0.33 loss: 199.568 (lr:0.0001)
187270: accuracy:0.31 loss: 222.909 (lr:0.0001)
187280: accuracy:0.37 loss: 198.16 (lr:0.0001)
187290: accuracy:0.37 loss: 207.435 (lr:0.0001)
187300: accuracy:0.35 loss: 198.033 (lr:0.0001)
187310: accuracy:0.5 loss: 168.837 (lr:0.0001)
187320: accuracy:0.43 loss: 193.314 (lr:0.0001)
187330: accuracy:0.39 loss: 205.17 (lr:0.0001)
187340: accuracy:0.38 loss: 197.986 (lr:0.0001)
187350: accuracy:0.44 loss: 190.592 (lr:0.0001)
187360: accuracy:0.47 loss: 194.139 (lr:0.0001)
187370: accuracy:0.35 loss: 194.189 (lr:0.0001)
187380: accuracy:0.35 loss: 206.32 (lr:0.0001)
187390: accuracy:0.39 loss: 178.367 (lr:0.0001)
187400: accuracy:0.37 loss: 198.95 (lr:0.0001)
187410: accuracy:0.38 loss: 196.834 (lr:0.0001)
187420: accuracy:0.37 loss: 197.713 (lr:0.0001)
187430: accuracy:0.37 loss: 199.507 (lr:0.0001)
187440: accuracy:0.4 loss: 166.218 (lr:0.0001)
187450: accuracy:0.3 loss: 208.39 (lr:0.0001)
187460: accuracy:0.38 loss: 187.757 (lr:0.0001)
187470: accuracy:0.37 loss: 190.343 (lr:0.0001)
187480: accuracy:0.45 loss: 188.793 (lr:0.0001)
187490: accuracy:0.34 loss: 201.642 (lr:0.0001)
187500: accuracy:0.38 loss: 198.443 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
187500: ********* epoch 20 ********* test accuracy for all:0.263108 test loss: 259.701
187500: ********* epoch 20 ********* test accuracy for mode 0:0.0395 test loss: 495.301
187500: ********* epoch 20 ********* test accuracy for mode 1:0.026 test loss: 472.331
187500: ********* epoch 20 ********* test accuracy for mode 2:0.0475 test loss: 258.171
187500: ********* epoch 20 ********* test accuracy for mode 24:0.235 test loss: 279.126
187500: ********* epoch 20 ********* test accuracy for mode 25:0.286 test loss: 242.152
187500: ********* epoch 20 ********* test accuracy for mode 26:0.4905 test loss: 160.318
187500: ********* epoch 20 ********* test accuracy for mode 27:0.247 test loss: 266.171
187500: ********* epoch 20 ********* test accuracy for mode 28:0.2935 test loss: 257.081
187500: ********* epoch 20 ********* test accuracy for mode 29:0.2315 test loss: 268.977
187500: ********* epoch 20 ********* test accuracy for mode 30:0.258 test loss: 246.118
187500: ********* epoch 20 ********* test accuracy for mode 31:0.18 test loss: 253.084
187500: ********* epoch 20 ********* test accuracy for mode 32:0.2235 test loss: 227.161
187500: ********* epoch 20 ********* test accuracy for mode 33:0.311 test loss: 226.684
187500: ********* epoch 20 ********* test accuracy for mode 34:0.2255 test loss: 234.704
187500: ********* epoch 20 ********* test accuracy for mode 35:0.1245 test loss: 451.772
187500: ********* epoch 20 ********* test accuracy for mode 36:0.2145 test loss: 489.549
187510: accuracy:0.38 loss: 191.582 (lr:0.0001)
187520: accuracy:0.39 loss: 191.057 (lr:0.0001)
187530: accuracy:0.41 loss: 187.091 (lr:0.0001)
187540: accuracy:0.31 loss: 208.121 (lr:0.0001)
187550: accuracy:0.34 loss: 189.786 (lr:0.0001)
187560: accuracy:0.34 loss: 204.769 (lr:0.0001)
187570: accuracy:0.42 loss: 187.8 (lr:0.0001)
187580: accuracy:0.35 loss: 202.091 (lr:0.0001)
187590: accuracy:0.32 loss: 218.115 (lr:0.0001)
187600: accuracy:0.38 loss: 196.999 (lr:0.0001)
187610: accuracy:0.33 loss: 192.727 (lr:0.0001)
187620: accuracy:0.41 loss: 184.508 (lr:0.0001)
187630: accuracy:0.36 loss: 209.533 (lr:0.0001)
187640: accuracy:0.44 loss: 188.724 (lr:0.0001)
187650: accuracy:0.39 loss: 197.711 (lr:0.0001)
187660: accuracy:0.39 loss: 195.083 (lr:0.0001)
187670: accuracy:0.31 loss: 205.572 (lr:0.0001)
187680: accuracy:0.4 loss: 178.569 (lr:0.0001)
187690: accuracy:0.39 loss: 197.175 (lr:0.0001)
187700: accuracy:0.32 loss: 204.724 (lr:0.0001)
187710: accuracy:0.31 loss: 207.609 (lr:0.0001)
187720: accuracy:0.4 loss: 188.278 (lr:0.0001)
187730: accuracy:0.4 loss: 185.435 (lr:0.0001)
187740: accuracy:0.39 loss: 198.14 (lr:0.0001)
187750: accuracy:0.36 loss: 179.164 (lr:0.0001)
187760: accuracy:0.38 loss: 187.206 (lr:0.0001)
187770: accuracy:0.38 loss: 183.734 (lr:0.0001)
187780: accuracy:0.35 loss: 203.977 (lr:0.0001)
187790: accuracy:0.37 loss: 186.341 (lr:0.0001)
187800: accuracy:0.37 loss: 204.638 (lr:0.0001)
187810: accuracy:0.34 loss: 183.839 (lr:0.0001)
187820: accuracy:0.37 loss: 193.5 (lr:0.0001)
187830: accuracy:0.28 loss: 223.175 (lr:0.0001)
187840: accuracy:0.43 loss: 174.747 (lr:0.0001)
187850: accuracy:0.44 loss: 193.733 (lr:0.0001)
187860: accuracy:0.43 loss: 210.187 (lr:0.0001)
187870: accuracy:0.33 loss: 197.587 (lr:0.0001)
187880: accuracy:0.41 loss: 189.427 (lr:0.0001)
187890: accuracy:0.33 loss: 204.147 (lr:0.0001)
187900: accuracy:0.45 loss: 181.593 (lr:0.0001)
187910: accuracy:0.4 loss: 199.122 (lr:0.0001)
187920: accuracy:0.46 loss: 177.65 (lr:0.0001)
187930: accuracy:0.36 loss: 202.907 (lr:0.0001)
187940: accuracy:0.47 loss: 186.847 (lr:0.0001)
187950: accuracy:0.41 loss: 197.447 (lr:0.0001)
187960: accuracy:0.46 loss: 183.697 (lr:0.0001)
187970: accuracy:0.35 loss: 205.004 (lr:0.0001)
187980: accuracy:0.36 loss: 191.384 (lr:0.0001)
187990: accuracy:0.43 loss: 192.302 (lr:0.0001)
188000: accuracy:0.42 loss: 175.575 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
188000: ********* epoch 20 ********* test accuracy for all:0.258851 test loss: 262.46
188000: ********* epoch 20 ********* test accuracy for mode 0:0.042 test loss: 492.505
188000: ********* epoch 20 ********* test accuracy for mode 1:0.0295 test loss: 471.238
188000: ********* epoch 20 ********* test accuracy for mode 2:0.046 test loss: 259.867
188000: ********* epoch 20 ********* test accuracy for mode 24:0.233 test loss: 286.026
188000: ********* epoch 20 ********* test accuracy for mode 25:0.2425 test loss: 254.227
188000: ********* epoch 20 ********* test accuracy for mode 26:0.4895 test loss: 162.69
188000: ********* epoch 20 ********* test accuracy for mode 27:0.256 test loss: 264.025
188000: ********* epoch 20 ********* test accuracy for mode 28:0.2955 test loss: 261.255
188000: ********* epoch 20 ********* test accuracy for mode 29:0.235 test loss: 275.149
188000: ********* epoch 20 ********* test accuracy for mode 30:0.2195 test loss: 252.695
188000: ********* epoch 20 ********* test accuracy for mode 31:0.224 test loss: 252.053
188000: ********* epoch 20 ********* test accuracy for mode 32:0.222 test loss: 231.096
188000: ********* epoch 20 ********* test accuracy for mode 33:0.2735 test loss: 230.244
188000: ********* epoch 20 ********* test accuracy for mode 34:0.265 test loss: 232.682
188000: ********* epoch 20 ********* test accuracy for mode 35:0.1215 test loss: 475.552
188000: ********* epoch 20 ********* test accuracy for mode 36:0.0645 test loss: 559.152
188010: accuracy:0.35 loss: 182.545 (lr:0.0001)
188020: accuracy:0.4 loss: 176.059 (lr:0.0001)
188030: accuracy:0.34 loss: 210.706 (lr:0.0001)
188040: accuracy:0.38 loss: 180.62 (lr:0.0001)
188050: accuracy:0.46 loss: 192.612 (lr:0.0001)
188060: accuracy:0.42 loss: 197.639 (lr:0.0001)
188070: accuracy:0.46 loss: 185.284 (lr:0.0001)
188080: accuracy:0.44 loss: 181.578 (lr:0.0001)
188090: accuracy:0.38 loss: 181.473 (lr:0.0001)
188100: accuracy:0.32 loss: 203.341 (lr:0.0001)
188110: accuracy:0.4 loss: 191.649 (lr:0.0001)
188120: accuracy:0.3 loss: 226.691 (lr:0.0001)
188130: accuracy:0.43 loss: 193.58 (lr:0.0001)
188140: accuracy:0.39 loss: 175.264 (lr:0.0001)
188150: accuracy:0.38 loss: 192.01 (lr:0.0001)
188160: accuracy:0.39 loss: 186.792 (lr:0.0001)
188170: accuracy:0.38 loss: 210.598 (lr:0.0001)
188180: accuracy:0.36 loss: 184.68 (lr:0.0001)
188190: accuracy:0.43 loss: 184.564 (lr:0.0001)
188200: accuracy:0.4 loss: 190.646 (lr:0.0001)
188210: accuracy:0.4 loss: 199.083 (lr:0.0001)
188220: accuracy:0.36 loss: 181.736 (lr:0.0001)
188230: accuracy:0.44 loss: 196.2 (lr:0.0001)
188240: accuracy:0.42 loss: 187.06 (lr:0.0001)
188250: accuracy:0.35 loss: 208.535 (lr:0.0001)
188260: accuracy:0.37 loss: 200.118 (lr:0.0001)
188270: accuracy:0.42 loss: 181.079 (lr:0.0001)
188280: accuracy:0.42 loss: 172.284 (lr:0.0001)
188290: accuracy:0.45 loss: 191.555 (lr:0.0001)
188300: accuracy:0.35 loss: 194.609 (lr:0.0001)
188310: accuracy:0.38 loss: 184.47 (lr:0.0001)
188320: accuracy:0.35 loss: 201.362 (lr:0.0001)
188330: accuracy:0.39 loss: 189.665 (lr:0.0001)
188340: accuracy:0.37 loss: 181.213 (lr:0.0001)
188350: accuracy:0.29 loss: 226.182 (lr:0.0001)
188360: accuracy:0.27 loss: 223.904 (lr:0.0001)
188370: accuracy:0.31 loss: 189.936 (lr:0.0001)
188380: accuracy:0.35 loss: 194.656 (lr:0.0001)
188390: accuracy:0.35 loss: 195.914 (lr:0.0001)
188400: accuracy:0.34 loss: 198.264 (lr:0.0001)
188410: accuracy:0.39 loss: 183.541 (lr:0.0001)
188420: accuracy:0.41 loss: 175.725 (lr:0.0001)
188430: accuracy:0.41 loss: 194.606 (lr:0.0001)
188440: accuracy:0.39 loss: 203.285 (lr:0.0001)
188450: accuracy:0.42 loss: 183.856 (lr:0.0001)
188460: accuracy:0.34 loss: 195.079 (lr:0.0001)
188470: accuracy:0.37 loss: 214.316 (lr:0.0001)
188480: accuracy:0.38 loss: 210.348 (lr:0.0001)
188490: accuracy:0.38 loss: 190.904 (lr:0.0001)
188500: accuracy:0.26 loss: 224.677 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
188500: ********* epoch 20 ********* test accuracy for all:0.256554 test loss: 262.452
188500: ********* epoch 20 ********* test accuracy for mode 0:0.0415 test loss: 485.956
188500: ********* epoch 20 ********* test accuracy for mode 1:0.026 test loss: 468.895
188500: ********* epoch 20 ********* test accuracy for mode 2:0.059 test loss: 262.796
188500: ********* epoch 20 ********* test accuracy for mode 24:0.255 test loss: 271.177
188500: ********* epoch 20 ********* test accuracy for mode 25:0.2635 test loss: 247.61
188500: ********* epoch 20 ********* test accuracy for mode 26:0.469 test loss: 163.84
188500: ********* epoch 20 ********* test accuracy for mode 27:0.251 test loss: 263.573
188500: ********* epoch 20 ********* test accuracy for mode 28:0.2875 test loss: 260.061
188500: ********* epoch 20 ********* test accuracy for mode 29:0.246 test loss: 272.752
188500: ********* epoch 20 ********* test accuracy for mode 30:0.259 test loss: 250.557
188500: ********* epoch 20 ********* test accuracy for mode 31:0.185 test loss: 258.709
188500: ********* epoch 20 ********* test accuracy for mode 32:0.2405 test loss: 236.294
188500: ********* epoch 20 ********* test accuracy for mode 33:0.216 test loss: 240.181
188500: ********* epoch 20 ********* test accuracy for mode 34:0.286 test loss: 234.377
188500: ********* epoch 20 ********* test accuracy for mode 35:0.1185 test loss: 444.964
188500: ********* epoch 20 ********* test accuracy for mode 36:0.1025 test loss: 502.331
188510: accuracy:0.25 loss: 214.614 (lr:0.0001)
188520: accuracy:0.37 loss: 205.488 (lr:0.0001)
188530: accuracy:0.42 loss: 177.93 (lr:0.0001)
188540: accuracy:0.41 loss: 185.428 (lr:0.0001)
188550: accuracy:0.37 loss: 202.489 (lr:0.0001)
188560: accuracy:0.37 loss: 183.134 (lr:0.0001)
188570: accuracy:0.33 loss: 202.093 (lr:0.0001)
188580: accuracy:0.44 loss: 197.716 (lr:0.0001)
188590: accuracy:0.36 loss: 198.237 (lr:0.0001)
188600: accuracy:0.39 loss: 210.008 (lr:0.0001)
188610: accuracy:0.38 loss: 193.141 (lr:0.0001)
188620: accuracy:0.37 loss: 182.75 (lr:0.0001)
188630: accuracy:0.36 loss: 205.174 (lr:0.0001)
188640: accuracy:0.36 loss: 180.357 (lr:0.0001)
188650: accuracy:0.33 loss: 203.997 (lr:0.0001)
188660: accuracy:0.35 loss: 200.942 (lr:0.0001)
188670: accuracy:0.41 loss: 189.922 (lr:0.0001)
188680: accuracy:0.4 loss: 179.792 (lr:0.0001)
188690: accuracy:0.27 loss: 211.733 (lr:0.0001)
188700: accuracy:0.38 loss: 198.228 (lr:0.0001)
188710: accuracy:0.34 loss: 201.391 (lr:0.0001)
188720: accuracy:0.33 loss: 213.933 (lr:0.0001)
188730: accuracy:0.3 loss: 209.173 (lr:0.0001)
188740: accuracy:0.38 loss: 213.613 (lr:0.0001)
188750: accuracy:0.41 loss: 187.377 (lr:0.0001)
188760: accuracy:0.31 loss: 196.759 (lr:0.0001)
188770: accuracy:0.34 loss: 205.55 (lr:0.0001)
188780: accuracy:0.39 loss: 183.451 (lr:0.0001)
188790: accuracy:0.43 loss: 167.485 (lr:0.0001)
188800: accuracy:0.31 loss: 202.912 (lr:0.0001)
188810: accuracy:0.36 loss: 197.454 (lr:0.0001)
188820: accuracy:0.4 loss: 190.777 (lr:0.0001)
188830: accuracy:0.39 loss: 191.495 (lr:0.0001)
188840: accuracy:0.38 loss: 191.993 (lr:0.0001)
188850: accuracy:0.34 loss: 211.781 (lr:0.0001)
188860: accuracy:0.42 loss: 195.926 (lr:0.0001)
188870: accuracy:0.37 loss: 172.236 (lr:0.0001)
188880: accuracy:0.34 loss: 207.351 (lr:0.0001)
188890: accuracy:0.31 loss: 216.658 (lr:0.0001)
188900: accuracy:0.33 loss: 217.114 (lr:0.0001)
188910: accuracy:0.45 loss: 167.602 (lr:0.0001)
188920: accuracy:0.3 loss: 219.331 (lr:0.0001)
188930: accuracy:0.43 loss: 202.202 (lr:0.0001)
188940: accuracy:0.37 loss: 212.16 (lr:0.0001)
188950: accuracy:0.31 loss: 219.119 (lr:0.0001)
188960: accuracy:0.41 loss: 190.843 (lr:0.0001)
188970: accuracy:0.38 loss: 193.34 (lr:0.0001)
188980: accuracy:0.39 loss: 190.043 (lr:0.0001)
188990: accuracy:0.4 loss: 202.444 (lr:0.0001)
189000: accuracy:0.37 loss: 207.07 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
189000: ********* epoch 20 ********* test accuracy for all:0.265324 test loss: 260.596
189000: ********* epoch 20 ********* test accuracy for mode 0:0.0475 test loss: 487.967
189000: ********* epoch 20 ********* test accuracy for mode 1:0.021 test loss: 473.685
189000: ********* epoch 20 ********* test accuracy for mode 2:0.1075 test loss: 249.544
189000: ********* epoch 20 ********* test accuracy for mode 24:0.2645 test loss: 275.872
189000: ********* epoch 20 ********* test accuracy for mode 25:0.2395 test loss: 254.686
189000: ********* epoch 20 ********* test accuracy for mode 26:0.542 test loss: 155.416
189000: ********* epoch 20 ********* test accuracy for mode 27:0.237 test loss: 268.137
189000: ********* epoch 20 ********* test accuracy for mode 28:0.2855 test loss: 258.714
189000: ********* epoch 20 ********* test accuracy for mode 29:0.275 test loss: 260.329
189000: ********* epoch 20 ********* test accuracy for mode 30:0.2605 test loss: 243.557
189000: ********* epoch 20 ********* test accuracy for mode 31:0.195 test loss: 251.057
189000: ********* epoch 20 ********* test accuracy for mode 32:0.2085 test loss: 233.502
189000: ********* epoch 20 ********* test accuracy for mode 33:0.284 test loss: 229.575
189000: ********* epoch 20 ********* test accuracy for mode 34:0.2405 test loss: 233.86
189000: ********* epoch 20 ********* test accuracy for mode 35:0.076 test loss: 484.646
189000: ********* epoch 20 ********* test accuracy for mode 36:0.172 test loss: 526.043
189010: accuracy:0.32 loss: 204.754 (lr:0.0001)
189020: accuracy:0.39 loss: 183.898 (lr:0.0001)
189030: accuracy:0.37 loss: 205.227 (lr:0.0001)
189040: accuracy:0.36 loss: 192.361 (lr:0.0001)
189050: accuracy:0.28 loss: 218.379 (lr:0.0001)
189060: accuracy:0.44 loss: 193.59 (lr:0.0001)
189070: accuracy:0.39 loss: 199.9 (lr:0.0001)
189080: accuracy:0.29 loss: 207.138 (lr:0.0001)
189090: accuracy:0.34 loss: 192.234 (lr:0.0001)
189100: accuracy:0.42 loss: 183.553 (lr:0.0001)
189110: accuracy:0.37 loss: 195.173 (lr:0.0001)
189120: accuracy:0.47 loss: 166.673 (lr:0.0001)
189130: accuracy:0.36 loss: 199.639 (lr:0.0001)
189140: accuracy:0.36 loss: 209.587 (lr:0.0001)
189150: accuracy:0.33 loss: 189.71 (lr:0.0001)
189160: accuracy:0.38 loss: 184.924 (lr:0.0001)
189170: accuracy:0.36 loss: 189.353 (lr:0.0001)
189180: accuracy:0.41 loss: 180.885 (lr:0.0001)
189190: accuracy:0.41 loss: 205.479 (lr:0.0001)
189200: accuracy:0.29 loss: 218.255 (lr:0.0001)
189210: accuracy:0.33 loss: 216.616 (lr:0.0001)
189220: accuracy:0.37 loss: 177.151 (lr:0.0001)
189230: accuracy:0.29 loss: 204.763 (lr:0.0001)
189240: accuracy:0.44 loss: 188.996 (lr:0.0001)
189250: accuracy:0.48 loss: 170.96 (lr:0.0001)
189260: accuracy:0.43 loss: 173.018 (lr:0.0001)
189270: accuracy:0.38 loss: 178.632 (lr:0.0001)
189280: accuracy:0.35 loss: 197.944 (lr:0.0001)
189290: accuracy:0.37 loss: 203.589 (lr:0.0001)
189300: accuracy:0.35 loss: 204.293 (lr:0.0001)
189310: accuracy:0.4 loss: 185.881 (lr:0.0001)
189320: accuracy:0.41 loss: 195.845 (lr:0.0001)
189330: accuracy:0.41 loss: 189.172 (lr:0.0001)
189340: accuracy:0.43 loss: 196.641 (lr:0.0001)
189350: accuracy:0.36 loss: 221.414 (lr:0.0001)
189360: accuracy:0.36 loss: 202.085 (lr:0.0001)
189370: accuracy:0.36 loss: 201.652 (lr:0.0001)
189380: accuracy:0.41 loss: 187.972 (lr:0.0001)
189390: accuracy:0.38 loss: 211.853 (lr:0.0001)
189400: accuracy:0.37 loss: 196.479 (lr:0.0001)
189410: accuracy:0.47 loss: 204.528 (lr:0.0001)
189420: accuracy:0.37 loss: 202.753 (lr:0.0001)
189430: accuracy:0.28 loss: 207.962 (lr:0.0001)
189440: accuracy:0.3 loss: 201.843 (lr:0.0001)
189450: accuracy:0.39 loss: 196.482 (lr:0.0001)
189460: accuracy:0.37 loss: 214.671 (lr:0.0001)
189470: accuracy:0.37 loss: 202.744 (lr:0.0001)
189480: accuracy:0.35 loss: 197.103 (lr:0.0001)
189490: accuracy:0.34 loss: 206.537 (lr:0.0001)
189500: accuracy:0.47 loss: 179.136 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
189500: ********* epoch 20 ********* test accuracy for all:0.267392 test loss: 257.586
189500: ********* epoch 20 ********* test accuracy for mode 0:0.039 test loss: 479.288
189500: ********* epoch 20 ********* test accuracy for mode 1:0.0255 test loss: 456.255
189500: ********* epoch 20 ********* test accuracy for mode 2:0.0715 test loss: 264.38
189500: ********* epoch 20 ********* test accuracy for mode 24:0.2605 test loss: 268.161
189500: ********* epoch 20 ********* test accuracy for mode 25:0.246 test loss: 249.365
189500: ********* epoch 20 ********* test accuracy for mode 26:0.535 test loss: 153.265
189500: ********* epoch 20 ********* test accuracy for mode 27:0.241 test loss: 263.635
189500: ********* epoch 20 ********* test accuracy for mode 28:0.287 test loss: 257.407
189500: ********* epoch 20 ********* test accuracy for mode 29:0.249 test loss: 266.277
189500: ********* epoch 20 ********* test accuracy for mode 30:0.2485 test loss: 248.057
189500: ********* epoch 20 ********* test accuracy for mode 31:0.1845 test loss: 254.8
189500: ********* epoch 20 ********* test accuracy for mode 32:0.2085 test loss: 236.814
189500: ********* epoch 20 ********* test accuracy for mode 33:0.2675 test loss: 232.23
189500: ********* epoch 20 ********* test accuracy for mode 34:0.275 test loss: 230.778
189500: ********* epoch 20 ********* test accuracy for mode 35:0.0835 test loss: 450.25
189500: ********* epoch 20 ********* test accuracy for mode 36:0.3585 test loss: 451.17
189510: accuracy:0.35 loss: 193.704 (lr:0.0001)
189520: accuracy:0.39 loss: 189.865 (lr:0.0001)
189530: accuracy:0.38 loss: 196.506 (lr:0.0001)
189540: accuracy:0.39 loss: 206.917 (lr:0.0001)
189550: accuracy:0.45 loss: 186.744 (lr:0.0001)
189560: accuracy:0.37 loss: 199.618 (lr:0.0001)
189570: accuracy:0.37 loss: 198.541 (lr:0.0001)
189580: accuracy:0.29 loss: 217.501 (lr:0.0001)
189590: accuracy:0.42 loss: 197.265 (lr:0.0001)
189600: accuracy:0.37 loss: 218.634 (lr:0.0001)
189610: accuracy:0.34 loss: 189.654 (lr:0.0001)
189620: accuracy:0.42 loss: 185.764 (lr:0.0001)
189630: accuracy:0.37 loss: 202.839 (lr:0.0001)
189640: accuracy:0.33 loss: 214.762 (lr:0.0001)
189650: accuracy:0.29 loss: 214.431 (lr:0.0001)
189660: accuracy:0.39 loss: 186.423 (lr:0.0001)
189670: accuracy:0.35 loss: 208.035 (lr:0.0001)
189680: accuracy:0.39 loss: 198.773 (lr:0.0001)
189690: accuracy:0.35 loss: 197.082 (lr:0.0001)
189700: accuracy:0.43 loss: 178.521 (lr:0.0001)
189710: accuracy:0.43 loss: 192.872 (lr:0.0001)
189720: accuracy:0.32 loss: 202.175 (lr:0.0001)
189730: accuracy:0.39 loss: 173.221 (lr:0.0001)
189740: accuracy:0.36 loss: 192.788 (lr:0.0001)
189750: accuracy:0.42 loss: 172.218 (lr:0.0001)
189760: accuracy:0.32 loss: 207.046 (lr:0.0001)
189770: accuracy:0.35 loss: 192.583 (lr:0.0001)
189780: accuracy:0.47 loss: 175.25 (lr:0.0001)
189790: accuracy:0.35 loss: 209.291 (lr:0.0001)
189800: accuracy:0.42 loss: 200.276 (lr:0.0001)
189810: accuracy:0.36 loss: 203.428 (lr:0.0001)
189820: accuracy:0.39 loss: 193.769 (lr:0.0001)
189830: accuracy:0.36 loss: 203.362 (lr:0.0001)
189840: accuracy:0.47 loss: 169.115 (lr:0.0001)
189850: accuracy:0.35 loss: 203.085 (lr:0.0001)
189860: accuracy:0.36 loss: 197.004 (lr:0.0001)
189870: accuracy:0.41 loss: 183.83 (lr:0.0001)
189880: accuracy:0.37 loss: 190.619 (lr:0.0001)
189890: accuracy:0.38 loss: 201.908 (lr:0.0001)
189900: accuracy:0.4 loss: 206.631 (lr:0.0001)
189910: accuracy:0.42 loss: 180.007 (lr:0.0001)
189920: accuracy:0.37 loss: 203.758 (lr:0.0001)
189930: accuracy:0.38 loss: 221.838 (lr:0.0001)
189940: accuracy:0.36 loss: 191.583 (lr:0.0001)
189950: accuracy:0.38 loss: 180.097 (lr:0.0001)
189960: accuracy:0.39 loss: 199.38 (lr:0.0001)
189970: accuracy:0.38 loss: 192.151 (lr:0.0001)
189980: accuracy:0.42 loss: 186.844 (lr:0.0001)
189990: accuracy:0.35 loss: 209.497 (lr:0.0001)
190000: accuracy:0.44 loss: 174.341 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
190000: ********* epoch 20 ********* test accuracy for all:0.26223 test loss: 258.819
190000: ********* epoch 20 ********* test accuracy for mode 0:0.043 test loss: 474.749
190000: ********* epoch 20 ********* test accuracy for mode 1:0.027 test loss: 458.644
190000: ********* epoch 20 ********* test accuracy for mode 2:0.0825 test loss: 257.477
190000: ********* epoch 20 ********* test accuracy for mode 24:0.2325 test loss: 281.431
190000: ********* epoch 20 ********* test accuracy for mode 25:0.267 test loss: 250.408
190000: ********* epoch 20 ********* test accuracy for mode 26:0.456 test loss: 169.799
190000: ********* epoch 20 ********* test accuracy for mode 27:0.243 test loss: 267.437
190000: ********* epoch 20 ********* test accuracy for mode 28:0.2655 test loss: 262.544
190000: ********* epoch 20 ********* test accuracy for mode 29:0.2725 test loss: 258.424
190000: ********* epoch 20 ********* test accuracy for mode 30:0.247 test loss: 246.272
190000: ********* epoch 20 ********* test accuracy for mode 31:0.2025 test loss: 249.097
190000: ********* epoch 20 ********* test accuracy for mode 32:0.1865 test loss: 231.838
190000: ********* epoch 20 ********* test accuracy for mode 33:0.3285 test loss: 223.221
190000: ********* epoch 20 ********* test accuracy for mode 34:0.25 test loss: 230.014
190000: ********* epoch 20 ********* test accuracy for mode 35:0.1275 test loss: 449.475
190000: ********* epoch 20 ********* test accuracy for mode 36:0.289 test loss: 463.331
190010: accuracy:0.41 loss: 201.862 (lr:0.0001)
190020: accuracy:0.36 loss: 212.203 (lr:0.0001)
190030: accuracy:0.4 loss: 191.456 (lr:0.0001)
190040: accuracy:0.44 loss: 194.328 (lr:0.0001)
190050: accuracy:0.33 loss: 194.861 (lr:0.0001)
190060: accuracy:0.4 loss: 182.271 (lr:0.0001)
190070: accuracy:0.34 loss: 192.342 (lr:0.0001)
190080: accuracy:0.39 loss: 192.824 (lr:0.0001)
190090: accuracy:0.4 loss: 213.104 (lr:0.0001)
190100: accuracy:0.3 loss: 205.608 (lr:0.0001)
190110: accuracy:0.32 loss: 197.747 (lr:0.0001)
190120: accuracy:0.35 loss: 199.3 (lr:0.0001)
190130: accuracy:0.43 loss: 166.676 (lr:0.0001)
190140: accuracy:0.31 loss: 185.142 (lr:0.0001)
190150: accuracy:0.39 loss: 201.036 (lr:0.0001)
190160: accuracy:0.41 loss: 211.346 (lr:0.0001)
190170: accuracy:0.37 loss: 191.958 (lr:0.0001)
190180: accuracy:0.28 loss: 203.091 (lr:0.0001)
190190: accuracy:0.35 loss: 195.82 (lr:0.0001)
190200: accuracy:0.36 loss: 211.548 (lr:0.0001)
190210: accuracy:0.43 loss: 181.364 (lr:0.0001)
190220: accuracy:0.36 loss: 202.012 (lr:0.0001)
190230: accuracy:0.4 loss: 205.936 (lr:0.0001)
190240: accuracy:0.34 loss: 194.821 (lr:0.0001)
190250: accuracy:0.35 loss: 198.523 (lr:0.0001)
190260: accuracy:0.37 loss: 169.943 (lr:0.0001)
190270: accuracy:0.33 loss: 190.798 (lr:0.0001)
190280: accuracy:0.44 loss: 188.924 (lr:0.0001)
190290: accuracy:0.36 loss: 220.326 (lr:0.0001)
190300: accuracy:0.29 loss: 209.891 (lr:0.0001)
190310: accuracy:0.29 loss: 223.445 (lr:0.0001)
190320: accuracy:0.37 loss: 195.514 (lr:0.0001)
190330: accuracy:0.33 loss: 189.866 (lr:0.0001)
190340: accuracy:0.35 loss: 193.13 (lr:0.0001)
190350: accuracy:0.44 loss: 199.08 (lr:0.0001)
190360: accuracy:0.35 loss: 197.441 (lr:0.0001)
190370: accuracy:0.36 loss: 183.891 (lr:0.0001)
190380: accuracy:0.41 loss: 198.527 (lr:0.0001)
190390: accuracy:0.31 loss: 196.755 (lr:0.0001)
190400: accuracy:0.39 loss: 193.315 (lr:0.0001)
190410: accuracy:0.36 loss: 202.634 (lr:0.0001)
190420: accuracy:0.42 loss: 189.918 (lr:0.0001)
190430: accuracy:0.4 loss: 176.343 (lr:0.0001)
190440: accuracy:0.32 loss: 212.784 (lr:0.0001)
190450: accuracy:0.44 loss: 180.542 (lr:0.0001)
190460: accuracy:0.35 loss: 201.407 (lr:0.0001)
190470: accuracy:0.35 loss: 194.088 (lr:0.0001)
190480: accuracy:0.34 loss: 210.529 (lr:0.0001)
190490: accuracy:0.42 loss: 190.277 (lr:0.0001)
190500: accuracy:0.33 loss: 199.879 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
190500: ********* epoch 20 ********* test accuracy for all:0.260824 test loss: 260.732
190500: ********* epoch 20 ********* test accuracy for mode 0:0.0435 test loss: 492.393
190500: ********* epoch 20 ********* test accuracy for mode 1:0.0265 test loss: 471.471
190500: ********* epoch 20 ********* test accuracy for mode 2:0.081 test loss: 256.922
190500: ********* epoch 20 ********* test accuracy for mode 24:0.237 test loss: 280.4
190500: ********* epoch 20 ********* test accuracy for mode 25:0.271 test loss: 249.952
190500: ********* epoch 20 ********* test accuracy for mode 26:0.4965 test loss: 161.414
190500: ********* epoch 20 ********* test accuracy for mode 27:0.225 test loss: 271.182
190500: ********* epoch 20 ********* test accuracy for mode 28:0.274 test loss: 264.001
190500: ********* epoch 20 ********* test accuracy for mode 29:0.2375 test loss: 269.373
190500: ********* epoch 20 ********* test accuracy for mode 30:0.2795 test loss: 242.95
190500: ********* epoch 20 ********* test accuracy for mode 31:0.216 test loss: 246.987
190500: ********* epoch 20 ********* test accuracy for mode 32:0.2295 test loss: 228.942
190500: ********* epoch 20 ********* test accuracy for mode 33:0.272 test loss: 231.595
190500: ********* epoch 20 ********* test accuracy for mode 34:0.2215 test loss: 236.487
190500: ********* epoch 20 ********* test accuracy for mode 35:0.124 test loss: 450.112
190500: ********* epoch 20 ********* test accuracy for mode 36:0.1665 test loss: 492.866
190510: accuracy:0.36 loss: 193.42 (lr:0.0001)
190520: accuracy:0.25 loss: 223.893 (lr:0.0001)
190530: accuracy:0.45 loss: 194.044 (lr:0.0001)
190540: accuracy:0.44 loss: 202.337 (lr:0.0001)
190550: accuracy:0.44 loss: 171.219 (lr:0.0001)
190560: accuracy:0.31 loss: 218.942 (lr:0.0001)
190570: accuracy:0.34 loss: 216.937 (lr:0.0001)
190580: accuracy:0.4 loss: 197.158 (lr:0.0001)
190590: accuracy:0.34 loss: 201.088 (lr:0.0001)
190600: accuracy:0.46 loss: 178.439 (lr:0.0001)
190610: accuracy:0.42 loss: 192.275 (lr:0.0001)
190620: accuracy:0.45 loss: 175.87 (lr:0.0001)
190630: accuracy:0.35 loss: 201.238 (lr:0.0001)
190640: accuracy:0.31 loss: 211.801 (lr:0.0001)
190650: accuracy:0.44 loss: 183.659 (lr:0.0001)
190660: accuracy:0.27 loss: 214.838 (lr:0.0001)
190670: accuracy:0.36 loss: 197.111 (lr:0.0001)
190680: accuracy:0.34 loss: 197.607 (lr:0.0001)
190690: accuracy:0.38 loss: 193.861 (lr:0.0001)
190700: accuracy:0.25 loss: 225.252 (lr:0.0001)
190710: accuracy:0.33 loss: 206.951 (lr:0.0001)
190720: accuracy:0.32 loss: 201.5 (lr:0.0001)
190730: accuracy:0.45 loss: 189.616 (lr:0.0001)
190740: accuracy:0.36 loss: 215.167 (lr:0.0001)
190750: accuracy:0.48 loss: 174.116 (lr:0.0001)
190760: accuracy:0.4 loss: 182.189 (lr:0.0001)
190770: accuracy:0.41 loss: 193.409 (lr:0.0001)
190780: accuracy:0.36 loss: 192.34 (lr:0.0001)
190790: accuracy:0.37 loss: 197.394 (lr:0.0001)
190800: accuracy:0.44 loss: 195.796 (lr:0.0001)
190810: accuracy:0.28 loss: 211.842 (lr:0.0001)
190820: accuracy:0.36 loss: 197.561 (lr:0.0001)
190830: accuracy:0.3 loss: 216.305 (lr:0.0001)
190840: accuracy:0.33 loss: 198.063 (lr:0.0001)
190850: accuracy:0.4 loss: 191.581 (lr:0.0001)
190860: accuracy:0.47 loss: 190.229 (lr:0.0001)
190870: accuracy:0.43 loss: 205.325 (lr:0.0001)
190880: accuracy:0.47 loss: 166.463 (lr:0.0001)
190890: accuracy:0.45 loss: 193.047 (lr:0.0001)
190900: accuracy:0.4 loss: 194.003 (lr:0.0001)
190910: accuracy:0.29 loss: 195.343 (lr:0.0001)
190920: accuracy:0.35 loss: 197.092 (lr:0.0001)
190930: accuracy:0.33 loss: 211.682 (lr:0.0001)
190940: accuracy:0.3 loss: 201.627 (lr:0.0001)
190950: accuracy:0.39 loss: 201.843 (lr:0.0001)
190960: accuracy:0.37 loss: 214.252 (lr:0.0001)
190970: accuracy:0.35 loss: 183.957 (lr:0.0001)
190980: accuracy:0.35 loss: 197.209 (lr:0.0001)
190990: accuracy:0.36 loss: 209.927 (lr:0.0001)
191000: accuracy:0.37 loss: 199.784 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
191000: ********* epoch 20 ********* test accuracy for all:0.260595 test loss: 261.152
191000: ********* epoch 20 ********* test accuracy for mode 0:0.033 test loss: 492.275
191000: ********* epoch 20 ********* test accuracy for mode 1:0.026 test loss: 463.881
191000: ********* epoch 20 ********* test accuracy for mode 2:0.0605 test loss: 253.447
191000: ********* epoch 20 ********* test accuracy for mode 24:0.239 test loss: 277.187
191000: ********* epoch 20 ********* test accuracy for mode 25:0.297 test loss: 242.615
191000: ********* epoch 20 ********* test accuracy for mode 26:0.53 test loss: 157.104
191000: ********* epoch 20 ********* test accuracy for mode 27:0.2455 test loss: 263.287
191000: ********* epoch 20 ********* test accuracy for mode 28:0.2815 test loss: 262.847
191000: ********* epoch 20 ********* test accuracy for mode 29:0.2515 test loss: 269.296
191000: ********* epoch 20 ********* test accuracy for mode 30:0.247 test loss: 250.615
191000: ********* epoch 20 ********* test accuracy for mode 31:0.207 test loss: 252.579
191000: ********* epoch 20 ********* test accuracy for mode 32:0.2335 test loss: 230.82
191000: ********* epoch 20 ********* test accuracy for mode 33:0.2445 test loss: 232.353
191000: ********* epoch 20 ********* test accuracy for mode 34:0.29 test loss: 227.416
191000: ********* epoch 20 ********* test accuracy for mode 35:0.0925 test loss: 455.84
191000: ********* epoch 20 ********* test accuracy for mode 36:0.073 test loss: 524.847
191010: accuracy:0.42 loss: 192.501 (lr:0.0001)
191020: accuracy:0.45 loss: 191.267 (lr:0.0001)
191030: accuracy:0.3 loss: 209.646 (lr:0.0001)
191040: accuracy:0.34 loss: 215.385 (lr:0.0001)
191050: accuracy:0.41 loss: 204.168 (lr:0.0001)
191060: accuracy:0.4 loss: 193.7 (lr:0.0001)
191070: accuracy:0.41 loss: 198.206 (lr:0.0001)
191080: accuracy:0.38 loss: 204.972 (lr:0.0001)
191090: accuracy:0.33 loss: 204.154 (lr:0.0001)
191100: accuracy:0.37 loss: 199.644 (lr:0.0001)
191110: accuracy:0.34 loss: 216.837 (lr:0.0001)
191120: accuracy:0.43 loss: 197.895 (lr:0.0001)
191130: accuracy:0.41 loss: 221.172 (lr:0.0001)
191140: accuracy:0.38 loss: 189.332 (lr:0.0001)
191150: accuracy:0.39 loss: 192.436 (lr:0.0001)
191160: accuracy:0.35 loss: 217.104 (lr:0.0001)
191170: accuracy:0.42 loss: 197.541 (lr:0.0001)
191180: accuracy:0.31 loss: 236.661 (lr:0.0001)
191190: accuracy:0.34 loss: 188.147 (lr:0.0001)
191200: accuracy:0.43 loss: 198.235 (lr:0.0001)
191210: accuracy:0.41 loss: 176.487 (lr:0.0001)
191220: accuracy:0.38 loss: 190.689 (lr:0.0001)
191230: accuracy:0.33 loss: 187.515 (lr:0.0001)
191240: accuracy:0.37 loss: 195.697 (lr:0.0001)
191250: accuracy:0.33 loss: 185.635 (lr:0.0001)
191260: accuracy:0.32 loss: 216.474 (lr:0.0001)
191270: accuracy:0.39 loss: 198.987 (lr:0.0001)
191280: accuracy:0.41 loss: 199.435 (lr:0.0001)
191290: accuracy:0.37 loss: 198.735 (lr:0.0001)
191300: accuracy:0.31 loss: 207.548 (lr:0.0001)
191310: accuracy:0.39 loss: 179.198 (lr:0.0001)
191320: accuracy:0.35 loss: 212.329 (lr:0.0001)
191330: accuracy:0.47 loss: 196.305 (lr:0.0001)
191340: accuracy:0.35 loss: 199.101 (lr:0.0001)
191350: accuracy:0.34 loss: 202.338 (lr:0.0001)
191360: accuracy:0.4 loss: 195.548 (lr:0.0001)
191370: accuracy:0.36 loss: 212.107 (lr:0.0001)
191380: accuracy:0.44 loss: 180.127 (lr:0.0001)
191390: accuracy:0.46 loss: 180.341 (lr:0.0001)
191400: accuracy:0.33 loss: 220.94 (lr:0.0001)
191410: accuracy:0.39 loss: 200.254 (lr:0.0001)
191420: accuracy:0.37 loss: 196.423 (lr:0.0001)
191430: accuracy:0.37 loss: 210.176 (lr:0.0001)
191440: accuracy:0.37 loss: 197.58 (lr:0.0001)
191450: accuracy:0.4 loss: 185.563 (lr:0.0001)
191460: accuracy:0.27 loss: 214.652 (lr:0.0001)
191470: accuracy:0.41 loss: 208.897 (lr:0.0001)
191480: accuracy:0.4 loss: 202.488 (lr:0.0001)
191490: accuracy:0.44 loss: 179.904 (lr:0.0001)
191500: accuracy:0.37 loss: 196.284 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
191500: ********* epoch 20 ********* test accuracy for all:0.257608 test loss: 262.752
191500: ********* epoch 20 ********* test accuracy for mode 0:0.0365 test loss: 493.036
191500: ********* epoch 20 ********* test accuracy for mode 1:0.0335 test loss: 465.878
191500: ********* epoch 20 ********* test accuracy for mode 2:0.058 test loss: 262.911
191500: ********* epoch 20 ********* test accuracy for mode 24:0.2285 test loss: 282.177
191500: ********* epoch 20 ********* test accuracy for mode 25:0.2715 test loss: 244.58
191500: ********* epoch 20 ********* test accuracy for mode 26:0.5125 test loss: 160.833
191500: ********* epoch 20 ********* test accuracy for mode 27:0.2395 test loss: 263.669
191500: ********* epoch 20 ********* test accuracy for mode 28:0.298 test loss: 257.902
191500: ********* epoch 20 ********* test accuracy for mode 29:0.2675 test loss: 265.7
191500: ********* epoch 20 ********* test accuracy for mode 30:0.225 test loss: 256.595
191500: ********* epoch 20 ********* test accuracy for mode 31:0.2105 test loss: 256.856
191500: ********* epoch 20 ********* test accuracy for mode 32:0.192 test loss: 237.168
191500: ********* epoch 20 ********* test accuracy for mode 33:0.3415 test loss: 227.221
191500: ********* epoch 20 ********* test accuracy for mode 34:0.223 test loss: 235.932
191500: ********* epoch 20 ********* test accuracy for mode 35:0.1305 test loss: 453.647
191500: ********* epoch 20 ********* test accuracy for mode 36:0.087 test loss: 517.34
191510: accuracy:0.33 loss: 208.232 (lr:0.0001)
191520: accuracy:0.33 loss: 211.841 (lr:0.0001)
191530: accuracy:0.31 loss: 225.318 (lr:0.0001)
191540: accuracy:0.28 loss: 220.597 (lr:0.0001)
191550: accuracy:0.33 loss: 208.516 (lr:0.0001)
191560: accuracy:0.41 loss: 184.221 (lr:0.0001)
191570: accuracy:0.37 loss: 200.532 (lr:0.0001)
191580: accuracy:0.32 loss: 188.26 (lr:0.0001)
191590: accuracy:0.38 loss: 191.059 (lr:0.0001)
191600: accuracy:0.35 loss: 193.346 (lr:0.0001)
191610: accuracy:0.35 loss: 220.375 (lr:0.0001)
191620: accuracy:0.41 loss: 209.667 (lr:0.0001)
191630: accuracy:0.33 loss: 189.607 (lr:0.0001)
191640: accuracy:0.34 loss: 200.063 (lr:0.0001)
191650: accuracy:0.41 loss: 183.262 (lr:0.0001)
191660: accuracy:0.34 loss: 218.74 (lr:0.0001)
191670: accuracy:0.35 loss: 208.13 (lr:0.0001)
191680: accuracy:0.37 loss: 201.202 (lr:0.0001)
191690: accuracy:0.41 loss: 188.676 (lr:0.0001)
191700: accuracy:0.47 loss: 183.635 (lr:0.0001)
191710: accuracy:0.41 loss: 196.495 (lr:0.0001)
191720: accuracy:0.41 loss: 197.806 (lr:0.0001)
191730: accuracy:0.37 loss: 202.937 (lr:0.0001)
191740: accuracy:0.38 loss: 204.43 (lr:0.0001)
191750: accuracy:0.37 loss: 223.856 (lr:0.0001)
191760: accuracy:0.31 loss: 212.651 (lr:0.0001)
191770: accuracy:0.43 loss: 187.091 (lr:0.0001)
191780: accuracy:0.44 loss: 185.418 (lr:0.0001)
191790: accuracy:0.36 loss: 202.841 (lr:0.0001)
191800: accuracy:0.39 loss: 204.886 (lr:0.0001)
191810: accuracy:0.42 loss: 188.088 (lr:0.0001)
191820: accuracy:0.31 loss: 221.417 (lr:0.0001)
191830: accuracy:0.36 loss: 184.453 (lr:0.0001)
191840: accuracy:0.37 loss: 192.576 (lr:0.0001)
191850: accuracy:0.43 loss: 186.939 (lr:0.0001)
191860: accuracy:0.4 loss: 211.627 (lr:0.0001)
191870: accuracy:0.41 loss: 189.092 (lr:0.0001)
191880: accuracy:0.35 loss: 201.047 (lr:0.0001)
191890: accuracy:0.34 loss: 213.974 (lr:0.0001)
191900: accuracy:0.38 loss: 201.222 (lr:0.0001)
191910: accuracy:0.34 loss: 196.235 (lr:0.0001)
191920: accuracy:0.34 loss: 207.525 (lr:0.0001)
191930: accuracy:0.28 loss: 233.703 (lr:0.0001)
191940: accuracy:0.33 loss: 196.328 (lr:0.0001)
191950: accuracy:0.45 loss: 211.043 (lr:0.0001)
191960: accuracy:0.36 loss: 195.368 (lr:0.0001)
191970: accuracy:0.37 loss: 208.135 (lr:0.0001)
191980: accuracy:0.39 loss: 183.702 (lr:0.0001)
191990: accuracy:0.39 loss: 185.354 (lr:0.0001)
192000: accuracy:0.35 loss: 181.311 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
192000: ********* epoch 20 ********* test accuracy for all:0.260311 test loss: 260.118
192000: ********* epoch 20 ********* test accuracy for mode 0:0.0295 test loss: 508.318
192000: ********* epoch 20 ********* test accuracy for mode 1:0.023 test loss: 474.154
192000: ********* epoch 20 ********* test accuracy for mode 2:0.077 test loss: 258.244
192000: ********* epoch 20 ********* test accuracy for mode 24:0.227 test loss: 283.21
192000: ********* epoch 20 ********* test accuracy for mode 25:0.272 test loss: 252.167
192000: ********* epoch 20 ********* test accuracy for mode 26:0.49 test loss: 164.852
192000: ********* epoch 20 ********* test accuracy for mode 27:0.271 test loss: 264.381
192000: ********* epoch 20 ********* test accuracy for mode 28:0.291 test loss: 262.04
192000: ********* epoch 20 ********* test accuracy for mode 29:0.2435 test loss: 270.57
192000: ********* epoch 20 ********* test accuracy for mode 30:0.238 test loss: 249.258
192000: ********* epoch 20 ********* test accuracy for mode 31:0.1895 test loss: 250.612
192000: ********* epoch 20 ********* test accuracy for mode 32:0.267 test loss: 225.867
192000: ********* epoch 20 ********* test accuracy for mode 33:0.1995 test loss: 233.643
192000: ********* epoch 20 ********* test accuracy for mode 34:0.331 test loss: 224.501
192000: ********* epoch 20 ********* test accuracy for mode 35:0.16 test loss: 440.232
192000: ********* epoch 20 ********* test accuracy for mode 36:0.0985 test loss: 494.844
192010: accuracy:0.39 loss: 174.368 (lr:0.0001)
192020: accuracy:0.32 loss: 181.379 (lr:0.0001)
192030: accuracy:0.29 loss: 175.564 (lr:0.0001)
192040: accuracy:0.34 loss: 201.816 (lr:0.0001)
192050: accuracy:0.42 loss: 195.232 (lr:0.0001)
192060: accuracy:0.32 loss: 192.126 (lr:0.0001)
192070: accuracy:0.41 loss: 178.175 (lr:0.0001)
192080: accuracy:0.34 loss: 197.527 (lr:0.0001)
192090: accuracy:0.34 loss: 210.278 (lr:0.0001)
192100: accuracy:0.35 loss: 195.707 (lr:0.0001)
192110: accuracy:0.4 loss: 209.965 (lr:0.0001)
192120: accuracy:0.33 loss: 199.249 (lr:0.0001)
192130: accuracy:0.38 loss: 190.133 (lr:0.0001)
192140: accuracy:0.45 loss: 189.763 (lr:0.0001)
192150: accuracy:0.31 loss: 209.549 (lr:0.0001)
192160: accuracy:0.41 loss: 189.457 (lr:0.0001)
192170: accuracy:0.51 loss: 186.077 (lr:0.0001)
192180: accuracy:0.39 loss: 197.286 (lr:0.0001)
192190: accuracy:0.41 loss: 186.901 (lr:0.0001)
192200: accuracy:0.41 loss: 194.914 (lr:0.0001)
192210: accuracy:0.43 loss: 205.032 (lr:0.0001)
192220: accuracy:0.24 loss: 218.891 (lr:0.0001)
192230: accuracy:0.32 loss: 215.424 (lr:0.0001)
192240: accuracy:0.4 loss: 175.755 (lr:0.0001)
192250: accuracy:0.43 loss: 190.309 (lr:0.0001)
192260: accuracy:0.43 loss: 180.434 (lr:0.0001)
192270: accuracy:0.34 loss: 206.799 (lr:0.0001)
192280: accuracy:0.43 loss: 188.652 (lr:0.0001)
192290: accuracy:0.43 loss: 196.563 (lr:0.0001)
192300: accuracy:0.45 loss: 175.854 (lr:0.0001)
192310: accuracy:0.39 loss: 194.034 (lr:0.0001)
192320: accuracy:0.26 loss: 206.593 (lr:0.0001)
192330: accuracy:0.4 loss: 201.66 (lr:0.0001)
192340: accuracy:0.45 loss: 179.4 (lr:0.0001)
192350: accuracy:0.38 loss: 195.907 (lr:0.0001)
192360: accuracy:0.44 loss: 194.964 (lr:0.0001)
192370: accuracy:0.39 loss: 198.991 (lr:0.0001)
192380: accuracy:0.39 loss: 180.198 (lr:0.0001)
192390: accuracy:0.4 loss: 190.183 (lr:0.0001)
192400: accuracy:0.34 loss: 210.033 (lr:0.0001)
192410: accuracy:0.4 loss: 177.616 (lr:0.0001)
192420: accuracy:0.37 loss: 191.896 (lr:0.0001)
192430: accuracy:0.37 loss: 196.128 (lr:0.0001)
192440: accuracy:0.35 loss: 197.976 (lr:0.0001)
192450: accuracy:0.36 loss: 193.905 (lr:0.0001)
192460: accuracy:0.44 loss: 181.402 (lr:0.0001)
192470: accuracy:0.39 loss: 198.002 (lr:0.0001)
192480: accuracy:0.37 loss: 184.104 (lr:0.0001)
192490: accuracy:0.35 loss: 204.712 (lr:0.0001)
192500: accuracy:0.45 loss: 205.908 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
192500: ********* epoch 20 ********* test accuracy for all:0.263743 test loss: 259.946
192500: ********* epoch 20 ********* test accuracy for mode 0:0.0415 test loss: 486.417
192500: ********* epoch 20 ********* test accuracy for mode 1:0.029 test loss: 459.572
192500: ********* epoch 20 ********* test accuracy for mode 2:0.0855 test loss: 258.499
192500: ********* epoch 20 ********* test accuracy for mode 24:0.2455 test loss: 278.704
192500: ********* epoch 20 ********* test accuracy for mode 25:0.249 test loss: 258.139
192500: ********* epoch 20 ********* test accuracy for mode 26:0.525 test loss: 161.146
192500: ********* epoch 20 ********* test accuracy for mode 27:0.2845 test loss: 265.548
192500: ********* epoch 20 ********* test accuracy for mode 28:0.3055 test loss: 260.634
192500: ********* epoch 20 ********* test accuracy for mode 29:0.2745 test loss: 267.66
192500: ********* epoch 20 ********* test accuracy for mode 30:0.25 test loss: 255.382
192500: ********* epoch 20 ********* test accuracy for mode 31:0.2145 test loss: 258.807
192500: ********* epoch 20 ********* test accuracy for mode 32:0.178 test loss: 245.333
192500: ********* epoch 20 ********* test accuracy for mode 33:0.265 test loss: 241.623
192500: ********* epoch 20 ********* test accuracy for mode 34:0.212 test loss: 243.474
192500: ********* epoch 20 ********* test accuracy for mode 35:0.1245 test loss: 443.056
192500: ********* epoch 20 ********* test accuracy for mode 36:0.1185 test loss: 491.612
192510: accuracy:0.43 loss: 175.854 (lr:0.0001)
192520: accuracy:0.35 loss: 214.835 (lr:0.0001)
192530: accuracy:0.37 loss: 201.895 (lr:0.0001)
192540: accuracy:0.39 loss: 190.521 (lr:0.0001)
192550: accuracy:0.41 loss: 190.837 (lr:0.0001)
192560: accuracy:0.36 loss: 182.943 (lr:0.0001)
192570: accuracy:0.32 loss: 212.813 (lr:0.0001)
192580: accuracy:0.32 loss: 197.171 (lr:0.0001)
192590: accuracy:0.36 loss: 199.874 (lr:0.0001)
192600: accuracy:0.5 loss: 181.134 (lr:0.0001)
192610: accuracy:0.31 loss: 218.434 (lr:0.0001)
192620: accuracy:0.33 loss: 206.284 (lr:0.0001)
192630: accuracy:0.33 loss: 218.927 (lr:0.0001)
192640: accuracy:0.43 loss: 191.487 (lr:0.0001)
192650: accuracy:0.36 loss: 198.449 (lr:0.0001)
192660: accuracy:0.39 loss: 191.783 (lr:0.0001)
192670: accuracy:0.35 loss: 213.292 (lr:0.0001)
192680: accuracy:0.4 loss: 174.856 (lr:0.0001)
192690: accuracy:0.3 loss: 197.735 (lr:0.0001)
192700: accuracy:0.33 loss: 194.462 (lr:0.0001)
192710: accuracy:0.33 loss: 195.534 (lr:0.0001)
192720: accuracy:0.36 loss: 207.711 (lr:0.0001)
192730: accuracy:0.38 loss: 197.307 (lr:0.0001)
192740: accuracy:0.4 loss: 206.491 (lr:0.0001)
192750: accuracy:0.37 loss: 200.207 (lr:0.0001)
192760: accuracy:0.32 loss: 199.338 (lr:0.0001)
192770: accuracy:0.34 loss: 196.849 (lr:0.0001)
192780: accuracy:0.39 loss: 199.607 (lr:0.0001)
192790: accuracy:0.32 loss: 205.98 (lr:0.0001)
192800: accuracy:0.43 loss: 181.741 (lr:0.0001)
192810: accuracy:0.38 loss: 206.526 (lr:0.0001)
192820: accuracy:0.41 loss: 194.459 (lr:0.0001)
192830: accuracy:0.39 loss: 196.834 (lr:0.0001)
192840: accuracy:0.41 loss: 189.042 (lr:0.0001)
192850: accuracy:0.46 loss: 178.801 (lr:0.0001)
192860: accuracy:0.35 loss: 194.445 (lr:0.0001)
192870: accuracy:0.38 loss: 199.022 (lr:0.0001)
192880: accuracy:0.35 loss: 188.71 (lr:0.0001)
192890: accuracy:0.4 loss: 188.188 (lr:0.0001)
192900: accuracy:0.33 loss: 202.224 (lr:0.0001)
192910: accuracy:0.3 loss: 209.451 (lr:0.0001)
192920: accuracy:0.27 loss: 217.579 (lr:0.0001)
192930: accuracy:0.53 loss: 167.755 (lr:0.0001)
192940: accuracy:0.36 loss: 186.906 (lr:0.0001)
192950: accuracy:0.46 loss: 181.183 (lr:0.0001)
192960: accuracy:0.39 loss: 190.993 (lr:0.0001)
192970: accuracy:0.39 loss: 183.837 (lr:0.0001)
192980: accuracy:0.43 loss: 198.422 (lr:0.0001)
192990: accuracy:0.35 loss: 187.259 (lr:0.0001)
193000: accuracy:0.46 loss: 170.536 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
193000: ********* epoch 20 ********* test accuracy for all:0.266959 test loss: 258.597
193000: ********* epoch 20 ********* test accuracy for mode 0:0.044 test loss: 491.01
193000: ********* epoch 20 ********* test accuracy for mode 1:0.026 test loss: 468.705
193000: ********* epoch 20 ********* test accuracy for mode 2:0.0765 test loss: 257.203
193000: ********* epoch 20 ********* test accuracy for mode 24:0.261 test loss: 272.954
193000: ********* epoch 20 ********* test accuracy for mode 25:0.292 test loss: 242.682
193000: ********* epoch 20 ********* test accuracy for mode 26:0.539 test loss: 158.237
193000: ********* epoch 20 ********* test accuracy for mode 27:0.25 test loss: 268.764
193000: ********* epoch 20 ********* test accuracy for mode 28:0.276 test loss: 262.752
193000: ********* epoch 20 ********* test accuracy for mode 29:0.25 test loss: 268.18
193000: ********* epoch 20 ********* test accuracy for mode 30:0.2585 test loss: 248.366
193000: ********* epoch 20 ********* test accuracy for mode 31:0.2085 test loss: 250.322
193000: ********* epoch 20 ********* test accuracy for mode 32:0.196 test loss: 233.829
193000: ********* epoch 20 ********* test accuracy for mode 33:0.269 test loss: 231.019
193000: ********* epoch 20 ********* test accuracy for mode 34:0.25 test loss: 231.972
193000: ********* epoch 20 ********* test accuracy for mode 35:0.1275 test loss: 445.055
193000: ********* epoch 20 ********* test accuracy for mode 36:0.2295 test loss: 480.926
193010: accuracy:0.35 loss: 198.68 (lr:0.0001)
193020: accuracy:0.35 loss: 207.615 (lr:0.0001)
193030: accuracy:0.4 loss: 198.667 (lr:0.0001)
193040: accuracy:0.37 loss: 201.43 (lr:0.0001)
193050: accuracy:0.41 loss: 183.774 (lr:0.0001)
193060: accuracy:0.44 loss: 186.333 (lr:0.0001)
193070: accuracy:0.37 loss: 185.474 (lr:0.0001)
193080: accuracy:0.34 loss: 212.389 (lr:0.0001)
193090: accuracy:0.4 loss: 233.954 (lr:0.0001)
193100: accuracy:0.49 loss: 174.412 (lr:0.0001)
193110: accuracy:0.39 loss: 176.214 (lr:0.0001)
193120: accuracy:0.4 loss: 201.013 (lr:0.0001)
193130: accuracy:0.38 loss: 202.366 (lr:0.0001)
193140: accuracy:0.4 loss: 180.401 (lr:0.0001)
193150: accuracy:0.33 loss: 213.354 (lr:0.0001)
193160: accuracy:0.42 loss: 187.968 (lr:0.0001)
193170: accuracy:0.44 loss: 177.322 (lr:0.0001)
193180: accuracy:0.43 loss: 198.536 (lr:0.0001)
193190: accuracy:0.29 loss: 221.19 (lr:0.0001)
193200: accuracy:0.37 loss: 204.427 (lr:0.0001)
193210: accuracy:0.46 loss: 161.163 (lr:0.0001)
193220: accuracy:0.4 loss: 186.333 (lr:0.0001)
193230: accuracy:0.39 loss: 207.596 (lr:0.0001)
193240: accuracy:0.31 loss: 189.95 (lr:0.0001)
193250: accuracy:0.41 loss: 190.106 (lr:0.0001)
193260: accuracy:0.5 loss: 168.316 (lr:0.0001)
193270: accuracy:0.46 loss: 193.282 (lr:0.0001)
193280: accuracy:0.38 loss: 189.806 (lr:0.0001)
193290: accuracy:0.4 loss: 223.091 (lr:0.0001)
193300: accuracy:0.31 loss: 199.202 (lr:0.0001)
193310: accuracy:0.3 loss: 215.362 (lr:0.0001)
193320: accuracy:0.4 loss: 200.631 (lr:0.0001)
193330: accuracy:0.4 loss: 189.364 (lr:0.0001)
193340: accuracy:0.39 loss: 196.225 (lr:0.0001)
193350: accuracy:0.35 loss: 210.04 (lr:0.0001)
193360: accuracy:0.42 loss: 186.063 (lr:0.0001)
193370: accuracy:0.41 loss: 196.255 (lr:0.0001)
193380: accuracy:0.31 loss: 194.414 (lr:0.0001)
193390: accuracy:0.3 loss: 217.584 (lr:0.0001)
193400: accuracy:0.38 loss: 182.303 (lr:0.0001)
193410: accuracy:0.35 loss: 191.804 (lr:0.0001)
193420: accuracy:0.34 loss: 196.465 (lr:0.0001)
193430: accuracy:0.39 loss: 209.097 (lr:0.0001)
193440: accuracy:0.41 loss: 194.358 (lr:0.0001)
193450: accuracy:0.37 loss: 201.476 (lr:0.0001)
193460: accuracy:0.4 loss: 202.477 (lr:0.0001)
193470: accuracy:0.39 loss: 176.467 (lr:0.0001)
193480: accuracy:0.39 loss: 192.173 (lr:0.0001)
193490: accuracy:0.36 loss: 194.832 (lr:0.0001)
193500: accuracy:0.35 loss: 201.857 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
193500: ********* epoch 20 ********* test accuracy for all:0.263203 test loss: 260.025
193500: ********* epoch 20 ********* test accuracy for mode 0:0.036 test loss: 490.376
193500: ********* epoch 20 ********* test accuracy for mode 1:0.029 test loss: 467.132
193500: ********* epoch 20 ********* test accuracy for mode 2:0.0805 test loss: 254.076
193500: ********* epoch 20 ********* test accuracy for mode 24:0.246 test loss: 283.324
193500: ********* epoch 20 ********* test accuracy for mode 25:0.2555 test loss: 255.82
193500: ********* epoch 20 ********* test accuracy for mode 26:0.5555 test loss: 155.97
193500: ********* epoch 20 ********* test accuracy for mode 27:0.2635 test loss: 266.951
193500: ********* epoch 20 ********* test accuracy for mode 28:0.2915 test loss: 260.649
193500: ********* epoch 20 ********* test accuracy for mode 29:0.2705 test loss: 264.453
193500: ********* epoch 20 ********* test accuracy for mode 30:0.241 test loss: 250.53
193500: ********* epoch 20 ********* test accuracy for mode 31:0.1915 test loss: 254.006
193500: ********* epoch 20 ********* test accuracy for mode 32:0.2005 test loss: 236.253
193500: ********* epoch 20 ********* test accuracy for mode 33:0.2445 test loss: 235.754
193500: ********* epoch 20 ********* test accuracy for mode 34:0.28 test loss: 229.536
193500: ********* epoch 20 ********* test accuracy for mode 35:0.12 test loss: 458.481
193500: ********* epoch 20 ********* test accuracy for mode 36:0.1725 test loss: 487.365
193510: accuracy:0.37 loss: 204.838 (lr:0.0001)
193520: accuracy:0.45 loss: 190.844 (lr:0.0001)
193530: accuracy:0.39 loss: 204.131 (lr:0.0001)
193540: accuracy:0.4 loss: 207.762 (lr:0.0001)
193550: accuracy:0.45 loss: 187.305 (lr:0.0001)
193560: accuracy:0.38 loss: 208.43 (lr:0.0001)
193570: accuracy:0.37 loss: 192.815 (lr:0.0001)
193580: accuracy:0.36 loss: 200.383 (lr:0.0001)
193590: accuracy:0.34 loss: 214.625 (lr:0.0001)
193600: accuracy:0.33 loss: 195.925 (lr:0.0001)
193610: accuracy:0.4 loss: 175.486 (lr:0.0001)
193620: accuracy:0.49 loss: 175.978 (lr:0.0001)
193630: accuracy:0.42 loss: 175.425 (lr:0.0001)
193640: accuracy:0.36 loss: 224.665 (lr:0.0001)
193650: accuracy:0.39 loss: 190.727 (lr:0.0001)
193660: accuracy:0.45 loss: 177.168 (lr:0.0001)
193670: accuracy:0.37 loss: 195.501 (lr:0.0001)
193680: accuracy:0.34 loss: 200.686 (lr:0.0001)
193690: accuracy:0.36 loss: 204.106 (lr:0.0001)
193700: accuracy:0.31 loss: 219.992 (lr:0.0001)
193710: accuracy:0.3 loss: 212.992 (lr:0.0001)
193720: accuracy:0.44 loss: 206.837 (lr:0.0001)
193730: accuracy:0.41 loss: 196.606 (lr:0.0001)
193740: accuracy:0.38 loss: 187.423 (lr:0.0001)
193750: accuracy:0.34 loss: 207.737 (lr:0.0001)
193760: accuracy:0.41 loss: 188.511 (lr:0.0001)
193770: accuracy:0.36 loss: 197.075 (lr:0.0001)
193780: accuracy:0.29 loss: 212.288 (lr:0.0001)
193790: accuracy:0.29 loss: 193.576 (lr:0.0001)
193800: accuracy:0.38 loss: 194.539 (lr:0.0001)
193810: accuracy:0.4 loss: 189.747 (lr:0.0001)
193820: accuracy:0.37 loss: 200.221 (lr:0.0001)
193830: accuracy:0.31 loss: 196.1 (lr:0.0001)
193840: accuracy:0.38 loss: 213.562 (lr:0.0001)
193850: accuracy:0.32 loss: 215.721 (lr:0.0001)
193860: accuracy:0.39 loss: 195.858 (lr:0.0001)
193870: accuracy:0.41 loss: 196.143 (lr:0.0001)
193880: accuracy:0.34 loss: 193.966 (lr:0.0001)
193890: accuracy:0.43 loss: 187.055 (lr:0.0001)
193900: accuracy:0.29 loss: 212.547 (lr:0.0001)
193910: accuracy:0.4 loss: 198.343 (lr:0.0001)
193920: accuracy:0.3 loss: 204.896 (lr:0.0001)
193930: accuracy:0.5 loss: 169.753 (lr:0.0001)
193940: accuracy:0.35 loss: 200.282 (lr:0.0001)
193950: accuracy:0.45 loss: 167.39 (lr:0.0001)
193960: accuracy:0.35 loss: 210.633 (lr:0.0001)
193970: accuracy:0.29 loss: 196.438 (lr:0.0001)
193980: accuracy:0.4 loss: 190.977 (lr:0.0001)
193990: accuracy:0.34 loss: 217.333 (lr:0.0001)
194000: accuracy:0.31 loss: 218.23 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
194000: ********* epoch 20 ********* test accuracy for all:0.262878 test loss: 257.513
194000: ********* epoch 20 ********* test accuracy for mode 0:0.0365 test loss: 481.994
194000: ********* epoch 20 ********* test accuracy for mode 1:0.0265 test loss: 454.859
194000: ********* epoch 20 ********* test accuracy for mode 2:0.0915 test loss: 251.619
194000: ********* epoch 20 ********* test accuracy for mode 24:0.2185 test loss: 279.29
194000: ********* epoch 20 ********* test accuracy for mode 25:0.3055 test loss: 246.516
194000: ********* epoch 20 ********* test accuracy for mode 26:0.441 test loss: 170.066
194000: ********* epoch 20 ********* test accuracy for mode 27:0.2655 test loss: 264.669
194000: ********* epoch 20 ********* test accuracy for mode 28:0.287 test loss: 258.326
194000: ********* epoch 20 ********* test accuracy for mode 29:0.245 test loss: 265.121
194000: ********* epoch 20 ********* test accuracy for mode 30:0.235 test loss: 247.899
194000: ********* epoch 20 ********* test accuracy for mode 31:0.2535 test loss: 243.936
194000: ********* epoch 20 ********* test accuracy for mode 32:0.1775 test loss: 233.923
194000: ********* epoch 20 ********* test accuracy for mode 33:0.262 test loss: 233.841
194000: ********* epoch 20 ********* test accuracy for mode 34:0.284 test loss: 231.071
194000: ********* epoch 20 ********* test accuracy for mode 35:0.1255 test loss: 450.048
194000: ********* epoch 20 ********* test accuracy for mode 36:0.238 test loss: 473.43
194010: accuracy:0.37 loss: 195.661 (lr:0.0001)
194020: accuracy:0.45 loss: 192.113 (lr:0.0001)
194030: accuracy:0.32 loss: 200.854 (lr:0.0001)
194040: accuracy:0.36 loss: 208.293 (lr:0.0001)
194050: accuracy:0.41 loss: 183.309 (lr:0.0001)
194060: accuracy:0.49 loss: 169.446 (lr:0.0001)
194070: accuracy:0.41 loss: 185.365 (lr:0.0001)
194080: accuracy:0.39 loss: 177.583 (lr:0.0001)
194090: accuracy:0.43 loss: 198.226 (lr:0.0001)
194100: accuracy:0.35 loss: 209.704 (lr:0.0001)
194110: accuracy:0.38 loss: 194.483 (lr:0.0001)
194120: accuracy:0.37 loss: 201.81 (lr:0.0001)
194130: accuracy:0.38 loss: 191.575 (lr:0.0001)
194140: accuracy:0.36 loss: 210.243 (lr:0.0001)
194150: accuracy:0.31 loss: 211.242 (lr:0.0001)
194160: accuracy:0.39 loss: 197.508 (lr:0.0001)
194170: accuracy:0.43 loss: 182.364 (lr:0.0001)
194180: accuracy:0.37 loss: 176.986 (lr:0.0001)
194190: accuracy:0.51 loss: 171.353 (lr:0.0001)
194200: accuracy:0.32 loss: 200.516 (lr:0.0001)
194210: accuracy:0.38 loss: 196.714 (lr:0.0001)
194220: accuracy:0.4 loss: 184.297 (lr:0.0001)
194230: accuracy:0.32 loss: 193.453 (lr:0.0001)
194240: accuracy:0.45 loss: 201.739 (lr:0.0001)
194250: accuracy:0.36 loss: 202.779 (lr:0.0001)
194260: accuracy:0.4 loss: 185.112 (lr:0.0001)
194270: accuracy:0.41 loss: 204.106 (lr:0.0001)
194280: accuracy:0.41 loss: 198.611 (lr:0.0001)
194290: accuracy:0.36 loss: 209.196 (lr:0.0001)
194300: accuracy:0.33 loss: 196.95 (lr:0.0001)
194310: accuracy:0.31 loss: 219.562 (lr:0.0001)
194320: accuracy:0.29 loss: 215.121 (lr:0.0001)
194330: accuracy:0.38 loss: 203.227 (lr:0.0001)
194340: accuracy:0.38 loss: 186.974 (lr:0.0001)
194350: accuracy:0.38 loss: 202.197 (lr:0.0001)
194360: accuracy:0.32 loss: 218.46 (lr:0.0001)
194370: accuracy:0.41 loss: 198.788 (lr:0.0001)
194380: accuracy:0.38 loss: 204.748 (lr:0.0001)
194390: accuracy:0.28 loss: 200.978 (lr:0.0001)
194400: accuracy:0.44 loss: 196.906 (lr:0.0001)
194410: accuracy:0.29 loss: 231.076 (lr:0.0001)
194420: accuracy:0.33 loss: 220.698 (lr:0.0001)
194430: accuracy:0.4 loss: 198.154 (lr:0.0001)
194440: accuracy:0.33 loss: 204.039 (lr:0.0001)
194450: accuracy:0.39 loss: 196.338 (lr:0.0001)
194460: accuracy:0.34 loss: 216.59 (lr:0.0001)
194470: accuracy:0.37 loss: 198.288 (lr:0.0001)
194480: accuracy:0.37 loss: 186.263 (lr:0.0001)
194490: accuracy:0.43 loss: 228.123 (lr:0.0001)
194500: accuracy:0.31 loss: 193.025 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
194500: ********* epoch 20 ********* test accuracy for all:0.263378 test loss: 258.506
194500: ********* epoch 20 ********* test accuracy for mode 0:0.039 test loss: 481.232
194500: ********* epoch 20 ********* test accuracy for mode 1:0.029 test loss: 460.453
194500: ********* epoch 20 ********* test accuracy for mode 2:0.0965 test loss: 258.817
194500: ********* epoch 20 ********* test accuracy for mode 24:0.28 test loss: 266.495
194500: ********* epoch 20 ********* test accuracy for mode 25:0.2825 test loss: 237.902
194500: ********* epoch 20 ********* test accuracy for mode 26:0.519 test loss: 155.915
194500: ********* epoch 20 ********* test accuracy for mode 27:0.2525 test loss: 258.076
194500: ********* epoch 20 ********* test accuracy for mode 28:0.2935 test loss: 254.481
194500: ********* epoch 20 ********* test accuracy for mode 29:0.239 test loss: 263.126
194500: ********* epoch 20 ********* test accuracy for mode 30:0.2345 test loss: 244.106
194500: ********* epoch 20 ********* test accuracy for mode 31:0.266 test loss: 242.042
194500: ********* epoch 20 ********* test accuracy for mode 32:0.197 test loss: 229.161
194500: ********* epoch 20 ********* test accuracy for mode 33:0.284 test loss: 228.096
194500: ********* epoch 20 ********* test accuracy for mode 34:0.2565 test loss: 232.622
194500: ********* epoch 20 ********* test accuracy for mode 35:0.097 test loss: 465.675
194500: ********* epoch 20 ********* test accuracy for mode 36:0.171 test loss: 493.569
194510: accuracy:0.41 loss: 196.352 (lr:0.0001)
194520: accuracy:0.37 loss: 187.491 (lr:0.0001)
194530: accuracy:0.34 loss: 198.045 (lr:0.0001)
194540: accuracy:0.44 loss: 171.603 (lr:0.0001)
194550: accuracy:0.38 loss: 208.7 (lr:0.0001)
194560: accuracy:0.39 loss: 180.914 (lr:0.0001)
194570: accuracy:0.35 loss: 188.058 (lr:0.0001)
194580: accuracy:0.36 loss: 198.951 (lr:0.0001)
194590: accuracy:0.46 loss: 171.915 (lr:0.0001)
194600: accuracy:0.46 loss: 183.283 (lr:0.0001)
194610: accuracy:0.41 loss: 203.235 (lr:0.0001)
194620: accuracy:0.41 loss: 201.638 (lr:0.0001)
194630: accuracy:0.37 loss: 194.713 (lr:0.0001)
194640: accuracy:0.43 loss: 183.853 (lr:0.0001)
194650: accuracy:0.33 loss: 208.506 (lr:0.0001)
194660: accuracy:0.33 loss: 190.108 (lr:0.0001)
194670: accuracy:0.44 loss: 173.269 (lr:0.0001)
194680: accuracy:0.33 loss: 215.621 (lr:0.0001)
194690: accuracy:0.33 loss: 187.951 (lr:0.0001)
194700: accuracy:0.38 loss: 196.102 (lr:0.0001)
194710: accuracy:0.32 loss: 210.265 (lr:0.0001)
194720: accuracy:0.42 loss: 185.251 (lr:0.0001)
194730: accuracy:0.37 loss: 187.369 (lr:0.0001)
194740: accuracy:0.45 loss: 186.272 (lr:0.0001)
194750: accuracy:0.42 loss: 204.535 (lr:0.0001)
194760: accuracy:0.51 loss: 180.615 (lr:0.0001)
194770: accuracy:0.43 loss: 189.218 (lr:0.0001)
194780: accuracy:0.37 loss: 189.37 (lr:0.0001)
194790: accuracy:0.45 loss: 183.221 (lr:0.0001)
194800: accuracy:0.41 loss: 189.001 (lr:0.0001)
194810: accuracy:0.38 loss: 195.416 (lr:0.0001)
194820: accuracy:0.35 loss: 217.241 (lr:0.0001)
194830: accuracy:0.4 loss: 199.748 (lr:0.0001)
194840: accuracy:0.36 loss: 210.496 (lr:0.0001)
194850: accuracy:0.39 loss: 190.103 (lr:0.0001)
194860: accuracy:0.34 loss: 196.191 (lr:0.0001)
194870: accuracy:0.31 loss: 196.539 (lr:0.0001)
194880: accuracy:0.42 loss: 184.813 (lr:0.0001)
194890: accuracy:0.46 loss: 187.835 (lr:0.0001)
194900: accuracy:0.42 loss: 190.186 (lr:0.0001)
194910: accuracy:0.36 loss: 204.501 (lr:0.0001)
194920: accuracy:0.31 loss: 196.341 (lr:0.0001)
194930: accuracy:0.44 loss: 179.35 (lr:0.0001)
194940: accuracy:0.39 loss: 189.462 (lr:0.0001)
194950: accuracy:0.5 loss: 177.617 (lr:0.0001)
194960: accuracy:0.35 loss: 198.09 (lr:0.0001)
194970: accuracy:0.43 loss: 179.409 (lr:0.0001)
194980: accuracy:0.39 loss: 205.708 (lr:0.0001)
194990: accuracy:0.34 loss: 211.645 (lr:0.0001)
195000: accuracy:0.4 loss: 190.073 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
195000: ********* epoch 21 ********* test accuracy for all:0.258473 test loss: 263.924
195000: ********* epoch 21 ********* test accuracy for mode 0:0.0365 test loss: 506.51
195000: ********* epoch 21 ********* test accuracy for mode 1:0.021 test loss: 487.043
195000: ********* epoch 21 ********* test accuracy for mode 2:0.0605 test loss: 255.639
195000: ********* epoch 21 ********* test accuracy for mode 24:0.2395 test loss: 282.718
195000: ********* epoch 21 ********* test accuracy for mode 25:0.2715 test loss: 254.315
195000: ********* epoch 21 ********* test accuracy for mode 26:0.462 test loss: 167.701
195000: ********* epoch 21 ********* test accuracy for mode 27:0.248 test loss: 269.921
195000: ********* epoch 21 ********* test accuracy for mode 28:0.28 test loss: 264.296
195000: ********* epoch 21 ********* test accuracy for mode 29:0.2705 test loss: 268.279
195000: ********* epoch 21 ********* test accuracy for mode 30:0.251 test loss: 246.392
195000: ********* epoch 21 ********* test accuracy for mode 31:0.193 test loss: 251.86
195000: ********* epoch 21 ********* test accuracy for mode 32:0.229 test loss: 226.324
195000: ********* epoch 21 ********* test accuracy for mode 33:0.291 test loss: 226.295
195000: ********* epoch 21 ********* test accuracy for mode 34:0.2285 test loss: 230.351
195000: ********* epoch 21 ********* test accuracy for mode 35:0.1275 test loss: 461.99
195000: ********* epoch 21 ********* test accuracy for mode 36:0.1465 test loss: 498.732
195010: accuracy:0.37 loss: 197.83 (lr:0.0001)
195020: accuracy:0.42 loss: 190.23 (lr:0.0001)
195030: accuracy:0.36 loss: 195.761 (lr:0.0001)
195040: accuracy:0.31 loss: 192.024 (lr:0.0001)
195050: accuracy:0.46 loss: 178.586 (lr:0.0001)
195060: accuracy:0.38 loss: 203.231 (lr:0.0001)
195070: accuracy:0.28 loss: 223.519 (lr:0.0001)
195080: accuracy:0.36 loss: 213.514 (lr:0.0001)
195090: accuracy:0.31 loss: 221.217 (lr:0.0001)
195100: accuracy:0.45 loss: 195.14 (lr:0.0001)
195110: accuracy:0.41 loss: 187.118 (lr:0.0001)
195120: accuracy:0.39 loss: 206.546 (lr:0.0001)
195130: accuracy:0.33 loss: 191.778 (lr:0.0001)
195140: accuracy:0.35 loss: 200.498 (lr:0.0001)
195150: accuracy:0.38 loss: 185.992 (lr:0.0001)
195160: accuracy:0.33 loss: 210.092 (lr:0.0001)
195170: accuracy:0.38 loss: 194.815 (lr:0.0001)
195180: accuracy:0.39 loss: 193.291 (lr:0.0001)
195190: accuracy:0.34 loss: 199.079 (lr:0.0001)
195200: accuracy:0.39 loss: 193.108 (lr:0.0001)
195210: accuracy:0.35 loss: 208.934 (lr:0.0001)
195220: accuracy:0.45 loss: 172.822 (lr:0.0001)
195230: accuracy:0.35 loss: 196.053 (lr:0.0001)
195240: accuracy:0.38 loss: 191.549 (lr:0.0001)
195250: accuracy:0.31 loss: 201.617 (lr:0.0001)
195260: accuracy:0.33 loss: 194.874 (lr:0.0001)
195270: accuracy:0.37 loss: 195.682 (lr:0.0001)
195280: accuracy:0.47 loss: 183.333 (lr:0.0001)
195290: accuracy:0.3 loss: 206.232 (lr:0.0001)
195300: accuracy:0.37 loss: 218.484 (lr:0.0001)
195310: accuracy:0.32 loss: 202.51 (lr:0.0001)
195320: accuracy:0.43 loss: 178.501 (lr:0.0001)
195330: accuracy:0.38 loss: 202.974 (lr:0.0001)
195340: accuracy:0.34 loss: 182.959 (lr:0.0001)
195350: accuracy:0.39 loss: 177.169 (lr:0.0001)
195360: accuracy:0.3 loss: 202.488 (lr:0.0001)
195370: accuracy:0.35 loss: 194.047 (lr:0.0001)
195380: accuracy:0.4 loss: 193.378 (lr:0.0001)
195390: accuracy:0.43 loss: 178.127 (lr:0.0001)
195400: accuracy:0.43 loss: 181.098 (lr:0.0001)
195410: accuracy:0.36 loss: 191.893 (lr:0.0001)
195420: accuracy:0.38 loss: 193.442 (lr:0.0001)
195430: accuracy:0.41 loss: 185.891 (lr:0.0001)
195440: accuracy:0.48 loss: 183.405 (lr:0.0001)
195450: accuracy:0.39 loss: 184.989 (lr:0.0001)
195460: accuracy:0.44 loss: 189.273 (lr:0.0001)
195470: accuracy:0.43 loss: 183.817 (lr:0.0001)
195480: accuracy:0.45 loss: 183.784 (lr:0.0001)
195490: accuracy:0.37 loss: 201.215 (lr:0.0001)
195500: accuracy:0.35 loss: 186.542 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
195500: ********* epoch 21 ********* test accuracy for all:0.263135 test loss: 260.831
195500: ********* epoch 21 ********* test accuracy for mode 0:0.036 test loss: 495.983
195500: ********* epoch 21 ********* test accuracy for mode 1:0.0295 test loss: 470.424
195500: ********* epoch 21 ********* test accuracy for mode 2:0.0495 test loss: 258.693
195500: ********* epoch 21 ********* test accuracy for mode 24:0.229 test loss: 284.453
195500: ********* epoch 21 ********* test accuracy for mode 25:0.266 test loss: 253.56
195500: ********* epoch 21 ********* test accuracy for mode 26:0.5205 test loss: 159.338
195500: ********* epoch 21 ********* test accuracy for mode 27:0.2475 test loss: 266.671
195500: ********* epoch 21 ********* test accuracy for mode 28:0.2845 test loss: 264.644
195500: ********* epoch 21 ********* test accuracy for mode 29:0.2305 test loss: 277.65
195500: ********* epoch 21 ********* test accuracy for mode 30:0.2385 test loss: 255.616
195500: ********* epoch 21 ********* test accuracy for mode 31:0.1895 test loss: 259.69
195500: ********* epoch 21 ********* test accuracy for mode 32:0.213 test loss: 237.109
195500: ********* epoch 21 ********* test accuracy for mode 33:0.245 test loss: 240.353
195500: ********* epoch 21 ********* test accuracy for mode 34:0.277 test loss: 232.851
195500: ********* epoch 21 ********* test accuracy for mode 35:0.1145 test loss: 455.892
195500: ********* epoch 21 ********* test accuracy for mode 36:0.323 test loss: 456.402
195510: accuracy:0.38 loss: 207.95 (lr:0.0001)
195520: accuracy:0.34 loss: 208.01 (lr:0.0001)
195530: accuracy:0.41 loss: 195.135 (lr:0.0001)
195540: accuracy:0.41 loss: 182.97 (lr:0.0001)
195550: accuracy:0.31 loss: 196.512 (lr:0.0001)
195560: accuracy:0.44 loss: 176.854 (lr:0.0001)
195570: accuracy:0.46 loss: 171.034 (lr:0.0001)
195580: accuracy:0.33 loss: 209.743 (lr:0.0001)
195590: accuracy:0.37 loss: 207.059 (lr:0.0001)
195600: accuracy:0.44 loss: 179.909 (lr:0.0001)
195610: accuracy:0.43 loss: 175.749 (lr:0.0001)
195620: accuracy:0.42 loss: 179.963 (lr:0.0001)
195630: accuracy:0.41 loss: 201.053 (lr:0.0001)
195640: accuracy:0.37 loss: 207.644 (lr:0.0001)
195650: accuracy:0.38 loss: 170.464 (lr:0.0001)
195660: accuracy:0.38 loss: 182.27 (lr:0.0001)
195670: accuracy:0.41 loss: 200.979 (lr:0.0001)
195680: accuracy:0.37 loss: 196.898 (lr:0.0001)
195690: accuracy:0.35 loss: 202.483 (lr:0.0001)
195700: accuracy:0.4 loss: 204.285 (lr:0.0001)
195710: accuracy:0.46 loss: 177.673 (lr:0.0001)
195720: accuracy:0.26 loss: 203.221 (lr:0.0001)
195730: accuracy:0.38 loss: 186.689 (lr:0.0001)
195740: accuracy:0.43 loss: 200.781 (lr:0.0001)
195750: accuracy:0.43 loss: 189.074 (lr:0.0001)
195760: accuracy:0.52 loss: 177.56 (lr:0.0001)
195770: accuracy:0.42 loss: 190.457 (lr:0.0001)
195780: accuracy:0.34 loss: 210.606 (lr:0.0001)
195790: accuracy:0.44 loss: 195.966 (lr:0.0001)
195800: accuracy:0.39 loss: 190.441 (lr:0.0001)
195810: accuracy:0.32 loss: 195.522 (lr:0.0001)
195820: accuracy:0.39 loss: 205.123 (lr:0.0001)
195830: accuracy:0.39 loss: 192.172 (lr:0.0001)
195840: accuracy:0.44 loss: 184.322 (lr:0.0001)
195850: accuracy:0.43 loss: 195.567 (lr:0.0001)
195860: accuracy:0.26 loss: 214.768 (lr:0.0001)
195870: accuracy:0.33 loss: 208.863 (lr:0.0001)
195880: accuracy:0.3 loss: 208.414 (lr:0.0001)
195890: accuracy:0.39 loss: 185.37 (lr:0.0001)
195900: accuracy:0.41 loss: 186.456 (lr:0.0001)
195910: accuracy:0.43 loss: 197.998 (lr:0.0001)
195920: accuracy:0.34 loss: 188.047 (lr:0.0001)
195930: accuracy:0.38 loss: 186.973 (lr:0.0001)
195940: accuracy:0.42 loss: 196.975 (lr:0.0001)
195950: accuracy:0.33 loss: 212.411 (lr:0.0001)
195960: accuracy:0.34 loss: 192.198 (lr:0.0001)
195970: accuracy:0.33 loss: 180.893 (lr:0.0001)
195980: accuracy:0.43 loss: 197.377 (lr:0.0001)
195990: accuracy:0.38 loss: 187.102 (lr:0.0001)
196000: accuracy:0.46 loss: 170.254 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
196000: ********* epoch 21 ********* test accuracy for all:0.263365 test loss: 261.354
196000: ********* epoch 21 ********* test accuracy for mode 0:0.0325 test loss: 504.909
196000: ********* epoch 21 ********* test accuracy for mode 1:0.0315 test loss: 475.258
196000: ********* epoch 21 ********* test accuracy for mode 2:0.0475 test loss: 260.371
196000: ********* epoch 21 ********* test accuracy for mode 24:0.2525 test loss: 277.876
196000: ********* epoch 21 ********* test accuracy for mode 25:0.2905 test loss: 244.284
196000: ********* epoch 21 ********* test accuracy for mode 26:0.478 test loss: 164.511
196000: ********* epoch 21 ********* test accuracy for mode 27:0.2645 test loss: 258.659
196000: ********* epoch 21 ********* test accuracy for mode 28:0.291 test loss: 257.497
196000: ********* epoch 21 ********* test accuracy for mode 29:0.243 test loss: 267.046
196000: ********* epoch 21 ********* test accuracy for mode 30:0.2625 test loss: 244.888
196000: ********* epoch 21 ********* test accuracy for mode 31:0.211 test loss: 250.233
196000: ********* epoch 21 ********* test accuracy for mode 32:0.251 test loss: 229.837
196000: ********* epoch 21 ********* test accuracy for mode 33:0.215 test loss: 238.314
196000: ********* epoch 21 ********* test accuracy for mode 34:0.2985 test loss: 228.775
196000: ********* epoch 21 ********* test accuracy for mode 35:0.138 test loss: 462.789
196000: ********* epoch 21 ********* test accuracy for mode 36:0.1925 test loss: 495.993
196010: accuracy:0.38 loss: 202.964 (lr:0.0001)
196020: accuracy:0.35 loss: 196.766 (lr:0.0001)
196030: accuracy:0.3 loss: 200.984 (lr:0.0001)
196040: accuracy:0.39 loss: 183.608 (lr:0.0001)
196050: accuracy:0.37 loss: 184.117 (lr:0.0001)
196060: accuracy:0.4 loss: 200.928 (lr:0.0001)
196070: accuracy:0.36 loss: 206.452 (lr:0.0001)
196080: accuracy:0.32 loss: 206.097 (lr:0.0001)
196090: accuracy:0.37 loss: 198.237 (lr:0.0001)
196100: accuracy:0.4 loss: 179.865 (lr:0.0001)
196110: accuracy:0.35 loss: 211.444 (lr:0.0001)
196120: accuracy:0.33 loss: 181.072 (lr:0.0001)
196130: accuracy:0.4 loss: 187.799 (lr:0.0001)
196140: accuracy:0.41 loss: 178.748 (lr:0.0001)
196150: accuracy:0.33 loss: 215.135 (lr:0.0001)
196160: accuracy:0.4 loss: 215.203 (lr:0.0001)
196170: accuracy:0.44 loss: 196.782 (lr:0.0001)
196180: accuracy:0.38 loss: 201.48 (lr:0.0001)
196190: accuracy:0.34 loss: 199.864 (lr:0.0001)
196200: accuracy:0.44 loss: 200.649 (lr:0.0001)
196210: accuracy:0.39 loss: 193.324 (lr:0.0001)
196220: accuracy:0.27 loss: 230.236 (lr:0.0001)
196230: accuracy:0.43 loss: 182.894 (lr:0.0001)
196240: accuracy:0.43 loss: 201.371 (lr:0.0001)
196250: accuracy:0.4 loss: 212.477 (lr:0.0001)
196260: accuracy:0.4 loss: 179.422 (lr:0.0001)
196270: accuracy:0.32 loss: 186.507 (lr:0.0001)
196280: accuracy:0.46 loss: 194.394 (lr:0.0001)
196290: accuracy:0.37 loss: 204.671 (lr:0.0001)
196300: accuracy:0.45 loss: 187.961 (lr:0.0001)
196310: accuracy:0.51 loss: 171.846 (lr:0.0001)
196320: accuracy:0.37 loss: 198.564 (lr:0.0001)
196330: accuracy:0.39 loss: 202.703 (lr:0.0001)
196340: accuracy:0.42 loss: 197.809 (lr:0.0001)
196350: accuracy:0.36 loss: 192.099 (lr:0.0001)
196360: accuracy:0.33 loss: 190.316 (lr:0.0001)
196370: accuracy:0.36 loss: 199.143 (lr:0.0001)
196380: accuracy:0.36 loss: 201.37 (lr:0.0001)
196390: accuracy:0.31 loss: 181.714 (lr:0.0001)
196400: accuracy:0.35 loss: 207.993 (lr:0.0001)
196410: accuracy:0.35 loss: 198.24 (lr:0.0001)
196420: accuracy:0.4 loss: 197.323 (lr:0.0001)
196430: accuracy:0.41 loss: 181.857 (lr:0.0001)
196440: accuracy:0.34 loss: 184.405 (lr:0.0001)
196450: accuracy:0.3 loss: 204.474 (lr:0.0001)
196460: accuracy:0.32 loss: 204.476 (lr:0.0001)
196470: accuracy:0.38 loss: 201.509 (lr:0.0001)
196480: accuracy:0.4 loss: 179.798 (lr:0.0001)
196490: accuracy:0.3 loss: 205.556 (lr:0.0001)
196500: accuracy:0.4 loss: 171.3 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
196500: ********* epoch 21 ********* test accuracy for all:0.266257 test loss: 258.276
196500: ********* epoch 21 ********* test accuracy for mode 0:0.045 test loss: 485.226
196500: ********* epoch 21 ********* test accuracy for mode 1:0.0325 test loss: 462.622
196500: ********* epoch 21 ********* test accuracy for mode 2:0.064 test loss: 257.263
196500: ********* epoch 21 ********* test accuracy for mode 24:0.271 test loss: 271.068
196500: ********* epoch 21 ********* test accuracy for mode 25:0.256 test loss: 255.331
196500: ********* epoch 21 ********* test accuracy for mode 26:0.477 test loss: 164.367
196500: ********* epoch 21 ********* test accuracy for mode 27:0.269 test loss: 260.186
196500: ********* epoch 21 ********* test accuracy for mode 28:0.2945 test loss: 256.144
196500: ********* epoch 21 ********* test accuracy for mode 29:0.2455 test loss: 263.621
196500: ********* epoch 21 ********* test accuracy for mode 30:0.2505 test loss: 246.743
196500: ********* epoch 21 ********* test accuracy for mode 31:0.2135 test loss: 249.719
196500: ********* epoch 21 ********* test accuracy for mode 32:0.194 test loss: 232.512
196500: ********* epoch 21 ********* test accuracy for mode 33:0.286 test loss: 231.833
196500: ********* epoch 21 ********* test accuracy for mode 34:0.2465 test loss: 231.428
196500: ********* epoch 21 ********* test accuracy for mode 35:0.163 test loss: 425.936
196500: ********* epoch 21 ********* test accuracy for mode 36:0.2795 test loss: 455.681
196510: accuracy:0.42 loss: 181.486 (lr:0.0001)
196520: accuracy:0.33 loss: 216.616 (lr:0.0001)
196530: accuracy:0.39 loss: 200.206 (lr:0.0001)
196540: accuracy:0.37 loss: 191.66 (lr:0.0001)
196550: accuracy:0.34 loss: 206.16 (lr:0.0001)
196560: accuracy:0.39 loss: 198.616 (lr:0.0001)
196570: accuracy:0.42 loss: 186.908 (lr:0.0001)
196580: accuracy:0.38 loss: 198.005 (lr:0.0001)
196590: accuracy:0.38 loss: 195.542 (lr:0.0001)
196600: accuracy:0.33 loss: 196.629 (lr:0.0001)
196610: accuracy:0.38 loss: 204.567 (lr:0.0001)
196620: accuracy:0.36 loss: 194.786 (lr:0.0001)
196630: accuracy:0.49 loss: 171.189 (lr:0.0001)
196640: accuracy:0.48 loss: 182.497 (lr:0.0001)
196650: accuracy:0.35 loss: 205.317 (lr:0.0001)
196660: accuracy:0.44 loss: 191.622 (lr:0.0001)
196670: accuracy:0.44 loss: 190.271 (lr:0.0001)
196680: accuracy:0.32 loss: 214.828 (lr:0.0001)
196690: accuracy:0.42 loss: 174.407 (lr:0.0001)
196700: accuracy:0.35 loss: 208.813 (lr:0.0001)
196710: accuracy:0.34 loss: 203.082 (lr:0.0001)
196720: accuracy:0.31 loss: 219.598 (lr:0.0001)
196730: accuracy:0.36 loss: 179.961 (lr:0.0001)
196740: accuracy:0.38 loss: 204.233 (lr:0.0001)
196750: accuracy:0.33 loss: 187.229 (lr:0.0001)
196760: accuracy:0.43 loss: 185.809 (lr:0.0001)
196770: accuracy:0.35 loss: 202.957 (lr:0.0001)
196780: accuracy:0.32 loss: 207.858 (lr:0.0001)
196790: accuracy:0.35 loss: 192.294 (lr:0.0001)
196800: accuracy:0.33 loss: 203.293 (lr:0.0001)
196810: accuracy:0.4 loss: 201.687 (lr:0.0001)
196820: accuracy:0.33 loss: 198.909 (lr:0.0001)
196830: accuracy:0.38 loss: 214.176 (lr:0.0001)
196840: accuracy:0.43 loss: 197.733 (lr:0.0001)
196850: accuracy:0.44 loss: 193.565 (lr:0.0001)
196860: accuracy:0.37 loss: 206.493 (lr:0.0001)
196870: accuracy:0.34 loss: 195.94 (lr:0.0001)
196880: accuracy:0.42 loss: 193.743 (lr:0.0001)
196890: accuracy:0.41 loss: 194.011 (lr:0.0001)
196900: accuracy:0.4 loss: 183.835 (lr:0.0001)
196910: accuracy:0.4 loss: 194.763 (lr:0.0001)
196920: accuracy:0.46 loss: 176.181 (lr:0.0001)
196930: accuracy:0.38 loss: 200.803 (lr:0.0001)
196940: accuracy:0.33 loss: 208.432 (lr:0.0001)
196950: accuracy:0.34 loss: 203.208 (lr:0.0001)
196960: accuracy:0.37 loss: 198.212 (lr:0.0001)
196970: accuracy:0.38 loss: 204.151 (lr:0.0001)
196980: accuracy:0.47 loss: 175.477 (lr:0.0001)
196990: accuracy:0.46 loss: 167.205 (lr:0.0001)
197000: accuracy:0.46 loss: 161.497 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
197000: ********* epoch 21 ********* test accuracy for all:0.260838 test loss: 262.051
197000: ********* epoch 21 ********* test accuracy for mode 0:0.04 test loss: 492.422
197000: ********* epoch 21 ********* test accuracy for mode 1:0.024 test loss: 473.804
197000: ********* epoch 21 ********* test accuracy for mode 2:0.072 test loss: 262.007
197000: ********* epoch 21 ********* test accuracy for mode 24:0.2295 test loss: 278.328
197000: ********* epoch 21 ********* test accuracy for mode 25:0.2665 test loss: 256.275
197000: ********* epoch 21 ********* test accuracy for mode 26:0.507 test loss: 159.615
197000: ********* epoch 21 ********* test accuracy for mode 27:0.234 test loss: 271.326
197000: ********* epoch 21 ********* test accuracy for mode 28:0.2875 test loss: 262.317
197000: ********* epoch 21 ********* test accuracy for mode 29:0.264 test loss: 270.467
197000: ********* epoch 21 ********* test accuracy for mode 30:0.2335 test loss: 250.214
197000: ********* epoch 21 ********* test accuracy for mode 31:0.185 test loss: 253.892
197000: ********* epoch 21 ********* test accuracy for mode 32:0.268 test loss: 225.819
197000: ********* epoch 21 ********* test accuracy for mode 33:0.2165 test loss: 238.079
197000: ********* epoch 21 ********* test accuracy for mode 34:0.259 test loss: 232.39
197000: ********* epoch 21 ********* test accuracy for mode 35:0.1305 test loss: 465.586
197000: ********* epoch 21 ********* test accuracy for mode 36:0.0635 test loss: 546.981
197010: accuracy:0.37 loss: 192.408 (lr:0.0001)
197020: accuracy:0.35 loss: 195.017 (lr:0.0001)
197030: accuracy:0.39 loss: 189.723 (lr:0.0001)
197040: accuracy:0.41 loss: 192.163 (lr:0.0001)
197050: accuracy:0.44 loss: 181.878 (lr:0.0001)
197060: accuracy:0.49 loss: 170.666 (lr:0.0001)
197070: accuracy:0.35 loss: 204.515 (lr:0.0001)
197080: accuracy:0.49 loss: 179.864 (lr:0.0001)
197090: accuracy:0.41 loss: 198.007 (lr:0.0001)
197100: accuracy:0.34 loss: 204.85 (lr:0.0001)
197110: accuracy:0.44 loss: 188.844 (lr:0.0001)
197120: accuracy:0.4 loss: 190.059 (lr:0.0001)
197130: accuracy:0.29 loss: 204.547 (lr:0.0001)
197140: accuracy:0.46 loss: 183.339 (lr:0.0001)
197150: accuracy:0.4 loss: 178.139 (lr:0.0001)
197160: accuracy:0.35 loss: 198.616 (lr:0.0001)
197170: accuracy:0.27 loss: 199.973 (lr:0.0001)
197180: accuracy:0.34 loss: 206.849 (lr:0.0001)
197190: accuracy:0.37 loss: 204.638 (lr:0.0001)
197200: accuracy:0.34 loss: 188.76 (lr:0.0001)
197210: accuracy:0.43 loss: 183.213 (lr:0.0001)
197220: accuracy:0.48 loss: 184.813 (lr:0.0001)
197230: accuracy:0.37 loss: 189.877 (lr:0.0001)
197240: accuracy:0.36 loss: 195.389 (lr:0.0001)
197250: accuracy:0.47 loss: 180.006 (lr:0.0001)
197260: accuracy:0.41 loss: 198.79 (lr:0.0001)
197270: accuracy:0.3 loss: 211.808 (lr:0.0001)
197280: accuracy:0.41 loss: 193.752 (lr:0.0001)
197290: accuracy:0.32 loss: 216.685 (lr:0.0001)
197300: accuracy:0.4 loss: 202.693 (lr:0.0001)
197310: accuracy:0.37 loss: 203.835 (lr:0.0001)
197320: accuracy:0.33 loss: 202.038 (lr:0.0001)
197330: accuracy:0.28 loss: 209.701 (lr:0.0001)
197340: accuracy:0.34 loss: 193.184 (lr:0.0001)
197350: accuracy:0.34 loss: 201.588 (lr:0.0001)
197360: accuracy:0.33 loss: 200.093 (lr:0.0001)
197370: accuracy:0.26 loss: 209.114 (lr:0.0001)
197380: accuracy:0.33 loss: 238.012 (lr:0.0001)
197390: accuracy:0.31 loss: 215.037 (lr:0.0001)
197400: accuracy:0.33 loss: 187.296 (lr:0.0001)
197410: accuracy:0.35 loss: 199.341 (lr:0.0001)
197420: accuracy:0.29 loss: 186.971 (lr:0.0001)
197430: accuracy:0.35 loss: 204.731 (lr:0.0001)
197440: accuracy:0.44 loss: 186.336 (lr:0.0001)
197450: accuracy:0.33 loss: 208.043 (lr:0.0001)
197460: accuracy:0.37 loss: 200.877 (lr:0.0001)
197470: accuracy:0.36 loss: 200.062 (lr:0.0001)
197480: accuracy:0.42 loss: 204.655 (lr:0.0001)
197490: accuracy:0.41 loss: 174.48 (lr:0.0001)
197500: accuracy:0.37 loss: 202.188 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
197500: ********* epoch 21 ********* test accuracy for all:0.260703 test loss: 263.239
197500: ********* epoch 21 ********* test accuracy for mode 0:0.038 test loss: 500.551
197500: ********* epoch 21 ********* test accuracy for mode 1:0.027 test loss: 475.283
197500: ********* epoch 21 ********* test accuracy for mode 2:0.058 test loss: 257.813
197500: ********* epoch 21 ********* test accuracy for mode 24:0.237 test loss: 282.569
197500: ********* epoch 21 ********* test accuracy for mode 25:0.31 test loss: 247.489
197500: ********* epoch 21 ********* test accuracy for mode 26:0.437 test loss: 168.596
197500: ********* epoch 21 ********* test accuracy for mode 27:0.245 test loss: 279.082
197500: ********* epoch 21 ********* test accuracy for mode 28:0.269 test loss: 268.878
197500: ********* epoch 21 ********* test accuracy for mode 29:0.2345 test loss: 276.635
197500: ********* epoch 21 ********* test accuracy for mode 30:0.247 test loss: 255.067
197500: ********* epoch 21 ********* test accuracy for mode 31:0.218 test loss: 255.261
197500: ********* epoch 21 ********* test accuracy for mode 32:0.197 test loss: 235.686
197500: ********* epoch 21 ********* test accuracy for mode 33:0.2565 test loss: 233.037
197500: ********* epoch 21 ********* test accuracy for mode 34:0.272 test loss: 229.36
197500: ********* epoch 21 ********* test accuracy for mode 35:0.1235 test loss: 466.242
197500: ********* epoch 21 ********* test accuracy for mode 36:0.2115 test loss: 509.082
197510: accuracy:0.38 loss: 172.93 (lr:0.0001)
197520: accuracy:0.43 loss: 186.346 (lr:0.0001)
197530: accuracy:0.35 loss: 191.723 (lr:0.0001)
197540: accuracy:0.34 loss: 227.799 (lr:0.0001)
197550: accuracy:0.37 loss: 213.052 (lr:0.0001)
197560: accuracy:0.39 loss: 201.367 (lr:0.0001)
197570: accuracy:0.36 loss: 181.956 (lr:0.0001)
197580: accuracy:0.36 loss: 196.102 (lr:0.0001)
197590: accuracy:0.45 loss: 174.303 (lr:0.0001)
197600: accuracy:0.37 loss: 192.05 (lr:0.0001)
197610: accuracy:0.44 loss: 180.516 (lr:0.0001)
197620: accuracy:0.47 loss: 170.896 (lr:0.0001)
197630: accuracy:0.37 loss: 186.088 (lr:0.0001)
197640: accuracy:0.32 loss: 188.998 (lr:0.0001)
197650: accuracy:0.4 loss: 205.394 (lr:0.0001)
197660: accuracy:0.35 loss: 185.285 (lr:0.0001)
197670: accuracy:0.36 loss: 201.614 (lr:0.0001)
197680: accuracy:0.38 loss: 202.657 (lr:0.0001)
197690: accuracy:0.25 loss: 210.919 (lr:0.0001)
197700: accuracy:0.33 loss: 210.157 (lr:0.0001)
197710: accuracy:0.39 loss: 188.865 (lr:0.0001)
197720: accuracy:0.36 loss: 221.955 (lr:0.0001)
197730: accuracy:0.41 loss: 182.228 (lr:0.0001)
197740: accuracy:0.38 loss: 193.826 (lr:0.0001)
197750: accuracy:0.33 loss: 203.887 (lr:0.0001)
197760: accuracy:0.42 loss: 193.55 (lr:0.0001)
197770: accuracy:0.43 loss: 186.467 (lr:0.0001)
197780: accuracy:0.33 loss: 194.438 (lr:0.0001)
197790: accuracy:0.35 loss: 208.112 (lr:0.0001)
197800: accuracy:0.35 loss: 183.71 (lr:0.0001)
197810: accuracy:0.41 loss: 187.301 (lr:0.0001)
197820: accuracy:0.4 loss: 191.563 (lr:0.0001)
197830: accuracy:0.33 loss: 215.415 (lr:0.0001)
197840: accuracy:0.39 loss: 194.861 (lr:0.0001)
197850: accuracy:0.36 loss: 189.05 (lr:0.0001)
197860: accuracy:0.33 loss: 198.334 (lr:0.0001)
197870: accuracy:0.45 loss: 199.465 (lr:0.0001)
197880: accuracy:0.39 loss: 191.046 (lr:0.0001)
197890: accuracy:0.41 loss: 186.082 (lr:0.0001)
197900: accuracy:0.25 loss: 226.466 (lr:0.0001)
197910: accuracy:0.37 loss: 195.023 (lr:0.0001)
197920: accuracy:0.41 loss: 210.792 (lr:0.0001)
197930: accuracy:0.39 loss: 184.432 (lr:0.0001)
197940: accuracy:0.34 loss: 195.956 (lr:0.0001)
197950: accuracy:0.4 loss: 214.44 (lr:0.0001)
197960: accuracy:0.41 loss: 192.261 (lr:0.0001)
197970: accuracy:0.34 loss: 206.337 (lr:0.0001)
197980: accuracy:0.35 loss: 196.216 (lr:0.0001)
197990: accuracy:0.38 loss: 202.816 (lr:0.0001)
198000: accuracy:0.37 loss: 200.453 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
198000: ********* epoch 21 ********* test accuracy for all:0.260959 test loss: 262.692
198000: ********* epoch 21 ********* test accuracy for mode 0:0.0345 test loss: 503.506
198000: ********* epoch 21 ********* test accuracy for mode 1:0.02 test loss: 480.62
198000: ********* epoch 21 ********* test accuracy for mode 2:0.088 test loss: 256.105
198000: ********* epoch 21 ********* test accuracy for mode 24:0.2325 test loss: 281.12
198000: ********* epoch 21 ********* test accuracy for mode 25:0.2955 test loss: 251.285
198000: ********* epoch 21 ********* test accuracy for mode 26:0.422 test loss: 172.895
198000: ********* epoch 21 ********* test accuracy for mode 27:0.2195 test loss: 285.025
198000: ********* epoch 21 ********* test accuracy for mode 28:0.2865 test loss: 267.335
198000: ********* epoch 21 ********* test accuracy for mode 29:0.2355 test loss: 275.578
198000: ********* epoch 21 ********* test accuracy for mode 30:0.2195 test loss: 252.439
198000: ********* epoch 21 ********* test accuracy for mode 31:0.232 test loss: 247.749
198000: ********* epoch 21 ********* test accuracy for mode 32:0.2355 test loss: 228.624
198000: ********* epoch 21 ********* test accuracy for mode 33:0.2585 test loss: 233.477
198000: ********* epoch 21 ********* test accuracy for mode 34:0.249 test loss: 233.443
198000: ********* epoch 21 ********* test accuracy for mode 35:0.109 test loss: 466.192
198000: ********* epoch 21 ********* test accuracy for mode 36:0.23 test loss: 493.911
198010: accuracy:0.35 loss: 203.414 (lr:0.0001)
198020: accuracy:0.37 loss: 184.336 (lr:0.0001)
198030: accuracy:0.35 loss: 199.014 (lr:0.0001)
198040: accuracy:0.41 loss: 183.889 (lr:0.0001)
198050: accuracy:0.35 loss: 190.904 (lr:0.0001)
198060: accuracy:0.41 loss: 192.028 (lr:0.0001)
198070: accuracy:0.39 loss: 200.394 (lr:0.0001)
198080: accuracy:0.37 loss: 197.412 (lr:0.0001)
198090: accuracy:0.33 loss: 198.575 (lr:0.0001)
198100: accuracy:0.32 loss: 196.467 (lr:0.0001)
198110: accuracy:0.44 loss: 173.562 (lr:0.0001)
198120: accuracy:0.39 loss: 213.445 (lr:0.0001)
198130: accuracy:0.41 loss: 175.193 (lr:0.0001)
198140: accuracy:0.38 loss: 193.263 (lr:0.0001)
198150: accuracy:0.38 loss: 201.45 (lr:0.0001)
198160: accuracy:0.39 loss: 203.877 (lr:0.0001)
198170: accuracy:0.45 loss: 214.254 (lr:0.0001)
198180: accuracy:0.47 loss: 185.357 (lr:0.0001)
198190: accuracy:0.36 loss: 187.722 (lr:0.0001)
198200: accuracy:0.33 loss: 215.072 (lr:0.0001)
198210: accuracy:0.36 loss: 191.052 (lr:0.0001)
198220: accuracy:0.3 loss: 212.937 (lr:0.0001)
198230: accuracy:0.31 loss: 205.267 (lr:0.0001)
198240: accuracy:0.4 loss: 172.804 (lr:0.0001)
198250: accuracy:0.35 loss: 201.734 (lr:0.0001)
198260: accuracy:0.36 loss: 191.007 (lr:0.0001)
198270: accuracy:0.31 loss: 219.84 (lr:0.0001)
198280: accuracy:0.38 loss: 184.288 (lr:0.0001)
198290: accuracy:0.41 loss: 174.838 (lr:0.0001)
198300: accuracy:0.43 loss: 178.794 (lr:0.0001)
198310: accuracy:0.41 loss: 196.678 (lr:0.0001)
198320: accuracy:0.41 loss: 196.207 (lr:0.0001)
198330: accuracy:0.46 loss: 171.67 (lr:0.0001)
198340: accuracy:0.38 loss: 196.044 (lr:0.0001)
198350: accuracy:0.35 loss: 208.999 (lr:0.0001)
198360: accuracy:0.36 loss: 216.909 (lr:0.0001)
198370: accuracy:0.35 loss: 194.835 (lr:0.0001)
198380: accuracy:0.49 loss: 176.371 (lr:0.0001)
198390: accuracy:0.42 loss: 178.191 (lr:0.0001)
198400: accuracy:0.34 loss: 190.782 (lr:0.0001)
198410: accuracy:0.34 loss: 207.912 (lr:0.0001)
198420: accuracy:0.4 loss: 196.374 (lr:0.0001)
198430: accuracy:0.42 loss: 190.309 (lr:0.0001)
198440: accuracy:0.38 loss: 202.768 (lr:0.0001)
198450: accuracy:0.34 loss: 193.609 (lr:0.0001)
198460: accuracy:0.44 loss: 186.138 (lr:0.0001)
198470: accuracy:0.32 loss: 209.153 (lr:0.0001)
198480: accuracy:0.42 loss: 180.302 (lr:0.0001)
198490: accuracy:0.44 loss: 177.702 (lr:0.0001)
198500: accuracy:0.39 loss: 186.097 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
198500: ********* epoch 21 ********* test accuracy for all:0.259568 test loss: 262.288
198500: ********* epoch 21 ********* test accuracy for mode 0:0.0465 test loss: 498.804
198500: ********* epoch 21 ********* test accuracy for mode 1:0.0255 test loss: 473.363
198500: ********* epoch 21 ********* test accuracy for mode 2:0.0785 test loss: 254.994
198500: ********* epoch 21 ********* test accuracy for mode 24:0.2485 test loss: 280.532
198500: ********* epoch 21 ********* test accuracy for mode 25:0.2935 test loss: 246.824
198500: ********* epoch 21 ********* test accuracy for mode 26:0.501 test loss: 159.32
198500: ********* epoch 21 ********* test accuracy for mode 27:0.251 test loss: 265.891
198500: ********* epoch 21 ********* test accuracy for mode 28:0.294 test loss: 259.72
198500: ********* epoch 21 ********* test accuracy for mode 29:0.238 test loss: 272.599
198500: ********* epoch 21 ********* test accuracy for mode 30:0.249 test loss: 249.203
198500: ********* epoch 21 ********* test accuracy for mode 31:0.1925 test loss: 252.63
198500: ********* epoch 21 ********* test accuracy for mode 32:0.197 test loss: 233.681
198500: ********* epoch 21 ********* test accuracy for mode 33:0.305 test loss: 225.488
198500: ********* epoch 21 ********* test accuracy for mode 34:0.2465 test loss: 229.151
198500: ********* epoch 21 ********* test accuracy for mode 35:0.1145 test loss: 472.239
198500: ********* epoch 21 ********* test accuracy for mode 36:0.111 test loss: 508.607
198510: accuracy:0.28 loss: 202.549 (lr:0.0001)
198520: accuracy:0.33 loss: 192.509 (lr:0.0001)
198530: accuracy:0.35 loss: 199.823 (lr:0.0001)
198540: accuracy:0.4 loss: 190.407 (lr:0.0001)
198550: accuracy:0.34 loss: 214.777 (lr:0.0001)
198560: accuracy:0.27 loss: 190.003 (lr:0.0001)
198570: accuracy:0.35 loss: 194.949 (lr:0.0001)
198580: accuracy:0.4 loss: 199.071 (lr:0.0001)
198590: accuracy:0.36 loss: 202.433 (lr:0.0001)
198600: accuracy:0.37 loss: 182.686 (lr:0.0001)
198610: accuracy:0.43 loss: 179.917 (lr:0.0001)
198620: accuracy:0.39 loss: 190.191 (lr:0.0001)
198630: accuracy:0.47 loss: 182.521 (lr:0.0001)
198640: accuracy:0.38 loss: 181.786 (lr:0.0001)
198650: accuracy:0.39 loss: 206.796 (lr:0.0001)
198660: accuracy:0.42 loss: 194.687 (lr:0.0001)
198670: accuracy:0.36 loss: 196.635 (lr:0.0001)
198680: accuracy:0.36 loss: 202.019 (lr:0.0001)
198690: accuracy:0.33 loss: 204.208 (lr:0.0001)
198700: accuracy:0.36 loss: 195.566 (lr:0.0001)
198710: accuracy:0.33 loss: 209.913 (lr:0.0001)
198720: accuracy:0.36 loss: 207.579 (lr:0.0001)
198730: accuracy:0.37 loss: 182.443 (lr:0.0001)
198740: accuracy:0.4 loss: 196.501 (lr:0.0001)
198750: accuracy:0.4 loss: 179.628 (lr:0.0001)
198760: accuracy:0.34 loss: 202.999 (lr:0.0001)
198770: accuracy:0.3 loss: 192.84 (lr:0.0001)
198780: accuracy:0.36 loss: 203.597 (lr:0.0001)
198790: accuracy:0.34 loss: 221.871 (lr:0.0001)
198800: accuracy:0.39 loss: 178.93 (lr:0.0001)
198810: accuracy:0.35 loss: 202.942 (lr:0.0001)
198820: accuracy:0.4 loss: 182.211 (lr:0.0001)
198830: accuracy:0.37 loss: 183.176 (lr:0.0001)
198840: accuracy:0.26 loss: 215.486 (lr:0.0001)
198850: accuracy:0.45 loss: 196.46 (lr:0.0001)
198860: accuracy:0.47 loss: 187.092 (lr:0.0001)
198870: accuracy:0.38 loss: 197.497 (lr:0.0001)
198880: accuracy:0.37 loss: 191.995 (lr:0.0001)
198890: accuracy:0.39 loss: 177.741 (lr:0.0001)
198900: accuracy:0.42 loss: 205.936 (lr:0.0001)
198910: accuracy:0.37 loss: 205.743 (lr:0.0001)
198920: accuracy:0.28 loss: 185.633 (lr:0.0001)
198930: accuracy:0.36 loss: 190.214 (lr:0.0001)
198940: accuracy:0.39 loss: 179.499 (lr:0.0001)
198950: accuracy:0.35 loss: 196.113 (lr:0.0001)
198960: accuracy:0.38 loss: 185.523 (lr:0.0001)
198970: accuracy:0.41 loss: 194.308 (lr:0.0001)
198980: accuracy:0.38 loss: 195.567 (lr:0.0001)
198990: accuracy:0.39 loss: 184.268 (lr:0.0001)
199000: accuracy:0.33 loss: 185.896 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
199000: ********* epoch 21 ********* test accuracy for all:0.263662 test loss: 262.824
199000: ********* epoch 21 ********* test accuracy for mode 0:0.037 test loss: 508.457
199000: ********* epoch 21 ********* test accuracy for mode 1:0.0275 test loss: 480.831
199000: ********* epoch 21 ********* test accuracy for mode 2:0.06 test loss: 259.445
199000: ********* epoch 21 ********* test accuracy for mode 24:0.218 test loss: 288.373
199000: ********* epoch 21 ********* test accuracy for mode 25:0.255 test loss: 259.329
199000: ********* epoch 21 ********* test accuracy for mode 26:0.523 test loss: 159.029
199000: ********* epoch 21 ********* test accuracy for mode 27:0.277 test loss: 268.996
199000: ********* epoch 21 ********* test accuracy for mode 28:0.299 test loss: 268.209
199000: ********* epoch 21 ********* test accuracy for mode 29:0.234 test loss: 283.025
199000: ********* epoch 21 ********* test accuracy for mode 30:0.245 test loss: 253.985
199000: ********* epoch 21 ********* test accuracy for mode 31:0.1975 test loss: 256.716
199000: ********* epoch 21 ********* test accuracy for mode 32:0.202 test loss: 237.251
199000: ********* epoch 21 ********* test accuracy for mode 33:0.3105 test loss: 227.491
199000: ********* epoch 21 ********* test accuracy for mode 34:0.213 test loss: 233.441
199000: ********* epoch 21 ********* test accuracy for mode 35:0.1155 test loss: 467.906
199000: ********* epoch 21 ********* test accuracy for mode 36:0.2975 test loss: 481.731
199010: accuracy:0.36 loss: 215.581 (lr:0.0001)
199020: accuracy:0.35 loss: 200.68 (lr:0.0001)
199030: accuracy:0.39 loss: 184.787 (lr:0.0001)
199040: accuracy:0.36 loss: 212.689 (lr:0.0001)
199050: accuracy:0.34 loss: 173.356 (lr:0.0001)
199060: accuracy:0.44 loss: 192.192 (lr:0.0001)
199070: accuracy:0.39 loss: 202.392 (lr:0.0001)
199080: accuracy:0.45 loss: 204.43 (lr:0.0001)
199090: accuracy:0.36 loss: 192.235 (lr:0.0001)
199100: accuracy:0.48 loss: 184.372 (lr:0.0001)
199110: accuracy:0.36 loss: 187.272 (lr:0.0001)
199120: accuracy:0.4 loss: 193.985 (lr:0.0001)
199130: accuracy:0.39 loss: 199.505 (lr:0.0001)
199140: accuracy:0.29 loss: 217.195 (lr:0.0001)
199150: accuracy:0.48 loss: 196.417 (lr:0.0001)
199160: accuracy:0.31 loss: 223.321 (lr:0.0001)
199170: accuracy:0.29 loss: 203.273 (lr:0.0001)
199180: accuracy:0.37 loss: 190.388 (lr:0.0001)
199190: accuracy:0.41 loss: 186.342 (lr:0.0001)
199200: accuracy:0.41 loss: 187.617 (lr:0.0001)
199210: accuracy:0.4 loss: 208.152 (lr:0.0001)
199220: accuracy:0.32 loss: 201.698 (lr:0.0001)
199230: accuracy:0.39 loss: 174.838 (lr:0.0001)
199240: accuracy:0.43 loss: 188.418 (lr:0.0001)
199250: accuracy:0.34 loss: 201.432 (lr:0.0001)
199260: accuracy:0.45 loss: 178.837 (lr:0.0001)
199270: accuracy:0.45 loss: 176.326 (lr:0.0001)
199280: accuracy:0.45 loss: 171.157 (lr:0.0001)
199290: accuracy:0.38 loss: 202.32 (lr:0.0001)
199300: accuracy:0.48 loss: 182.647 (lr:0.0001)
199310: accuracy:0.45 loss: 181.725 (lr:0.0001)
199320: accuracy:0.38 loss: 198.758 (lr:0.0001)
199330: accuracy:0.46 loss: 184.16 (lr:0.0001)
199340: accuracy:0.37 loss: 194.86 (lr:0.0001)
199350: accuracy:0.37 loss: 206.93 (lr:0.0001)
199360: accuracy:0.36 loss: 205.72 (lr:0.0001)
199370: accuracy:0.42 loss: 194.474 (lr:0.0001)
199380: accuracy:0.32 loss: 215.504 (lr:0.0001)
199390: accuracy:0.36 loss: 203.74 (lr:0.0001)
199400: accuracy:0.3 loss: 214.979 (lr:0.0001)
199410: accuracy:0.41 loss: 188.206 (lr:0.0001)
199420: accuracy:0.45 loss: 206.138 (lr:0.0001)
199430: accuracy:0.39 loss: 181.139 (lr:0.0001)
199440: accuracy:0.37 loss: 198.619 (lr:0.0001)
199450: accuracy:0.38 loss: 197.765 (lr:0.0001)
199460: accuracy:0.32 loss: 210.315 (lr:0.0001)
199470: accuracy:0.39 loss: 196.827 (lr:0.0001)
199480: accuracy:0.45 loss: 188.647 (lr:0.0001)
199490: accuracy:0.4 loss: 181.231 (lr:0.0001)
199500: accuracy:0.29 loss: 201.47 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
199500: ********* epoch 21 ********* test accuracy for all:0.266135 test loss: 260.796
199500: ********* epoch 21 ********* test accuracy for mode 0:0.03 test loss: 505.261
199500: ********* epoch 21 ********* test accuracy for mode 1:0.0245 test loss: 473.167
199500: ********* epoch 21 ********* test accuracy for mode 2:0.095 test loss: 255.457
199500: ********* epoch 21 ********* test accuracy for mode 24:0.255 test loss: 275.092
199500: ********* epoch 21 ********* test accuracy for mode 25:0.2835 test loss: 251.812
199500: ********* epoch 21 ********* test accuracy for mode 26:0.4835 test loss: 163.085
199500: ********* epoch 21 ********* test accuracy for mode 27:0.2665 test loss: 267.785
199500: ********* epoch 21 ********* test accuracy for mode 28:0.2725 test loss: 267.246
199500: ********* epoch 21 ********* test accuracy for mode 29:0.236 test loss: 274.975
199500: ********* epoch 21 ********* test accuracy for mode 30:0.2445 test loss: 248.403
199500: ********* epoch 21 ********* test accuracy for mode 31:0.2285 test loss: 246.686
199500: ********* epoch 21 ********* test accuracy for mode 32:0.235 test loss: 227.274
199500: ********* epoch 21 ********* test accuracy for mode 33:0.288 test loss: 229.287
199500: ********* epoch 21 ********* test accuracy for mode 34:0.2365 test loss: 233.236
199500: ********* epoch 21 ********* test accuracy for mode 35:0.1335 test loss: 463.711
199500: ********* epoch 21 ********* test accuracy for mode 36:0.224 test loss: 497.25
199510: accuracy:0.35 loss: 200.31 (lr:0.0001)
199520: accuracy:0.41 loss: 193.168 (lr:0.0001)
199530: accuracy:0.4 loss: 195.029 (lr:0.0001)
199540: accuracy:0.28 loss: 202.858 (lr:0.0001)
199550: accuracy:0.3 loss: 219.239 (lr:0.0001)
199560: accuracy:0.43 loss: 195.62 (lr:0.0001)
199570: accuracy:0.34 loss: 209.137 (lr:0.0001)
199580: accuracy:0.29 loss: 234.633 (lr:0.0001)
199590: accuracy:0.43 loss: 169.068 (lr:0.0001)
199600: accuracy:0.32 loss: 204.005 (lr:0.0001)
199610: accuracy:0.29 loss: 208.074 (lr:0.0001)
199620: accuracy:0.42 loss: 175.596 (lr:0.0001)
199630: accuracy:0.4 loss: 187.865 (lr:0.0001)
199640: accuracy:0.4 loss: 201.652 (lr:0.0001)
199650: accuracy:0.3 loss: 208.694 (lr:0.0001)
199660: accuracy:0.31 loss: 211.616 (lr:0.0001)
199670: accuracy:0.41 loss: 198.139 (lr:0.0001)
199680: accuracy:0.45 loss: 182.587 (lr:0.0001)
199690: accuracy:0.42 loss: 186.2 (lr:0.0001)
199700: accuracy:0.37 loss: 195.92 (lr:0.0001)
199710: accuracy:0.41 loss: 180.377 (lr:0.0001)
199720: accuracy:0.33 loss: 209.878 (lr:0.0001)
199730: accuracy:0.29 loss: 225.465 (lr:0.0001)
199740: accuracy:0.39 loss: 189.495 (lr:0.0001)
199750: accuracy:0.4 loss: 169.997 (lr:0.0001)
199760: accuracy:0.42 loss: 202.101 (lr:0.0001)
199770: accuracy:0.36 loss: 204.865 (lr:0.0001)
199780: accuracy:0.4 loss: 179.823 (lr:0.0001)
199790: accuracy:0.4 loss: 194.242 (lr:0.0001)
199800: accuracy:0.43 loss: 183.118 (lr:0.0001)
199810: accuracy:0.36 loss: 194.387 (lr:0.0001)
199820: accuracy:0.36 loss: 191.89 (lr:0.0001)
199830: accuracy:0.42 loss: 180.522 (lr:0.0001)
199840: accuracy:0.38 loss: 191.005 (lr:0.0001)
199850: accuracy:0.4 loss: 181.221 (lr:0.0001)
199860: accuracy:0.37 loss: 185.306 (lr:0.0001)
199870: accuracy:0.45 loss: 178.63 (lr:0.0001)
199880: accuracy:0.39 loss: 183.998 (lr:0.0001)
199890: accuracy:0.39 loss: 192.226 (lr:0.0001)
199900: accuracy:0.41 loss: 201.463 (lr:0.0001)
199910: accuracy:0.4 loss: 196.175 (lr:0.0001)
199920: accuracy:0.31 loss: 205.698 (lr:0.0001)
199930: accuracy:0.33 loss: 188.908 (lr:0.0001)
199940: accuracy:0.33 loss: 195.841 (lr:0.0001)
199950: accuracy:0.41 loss: 196.191 (lr:0.0001)
199960: accuracy:0.44 loss: 206.514 (lr:0.0001)
199970: accuracy:0.37 loss: 201.69 (lr:0.0001)
199980: accuracy:0.49 loss: 190.654 (lr:0.0001)
199990: accuracy:0.33 loss: 191.82 (lr:0.0001)
200000: accuracy:0.36 loss: 207.055 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
200000: ********* epoch 21 ********* test accuracy for all:0.265824 test loss: 260.457
200000: ********* epoch 21 ********* test accuracy for mode 0:0.0415 test loss: 486.271
200000: ********* epoch 21 ********* test accuracy for mode 1:0.029 test loss: 470.816
200000: ********* epoch 21 ********* test accuracy for mode 2:0.113 test loss: 253.831
200000: ********* epoch 21 ********* test accuracy for mode 24:0.2295 test loss: 285.957
200000: ********* epoch 21 ********* test accuracy for mode 25:0.2725 test loss: 260.342
200000: ********* epoch 21 ********* test accuracy for mode 26:0.4895 test loss: 162.826
200000: ********* epoch 21 ********* test accuracy for mode 27:0.2355 test loss: 278.235
200000: ********* epoch 21 ********* test accuracy for mode 28:0.2935 test loss: 264.532
200000: ********* epoch 21 ********* test accuracy for mode 29:0.2525 test loss: 270.363
200000: ********* epoch 21 ********* test accuracy for mode 30:0.2455 test loss: 246.804
200000: ********* epoch 21 ********* test accuracy for mode 31:0.237 test loss: 245.421
200000: ********* epoch 21 ********* test accuracy for mode 32:0.2235 test loss: 232.156
200000: ********* epoch 21 ********* test accuracy for mode 33:0.213 test loss: 238.914
200000: ********* epoch 21 ********* test accuracy for mode 34:0.26 test loss: 234.242
200000: ********* epoch 21 ********* test accuracy for mode 35:0.131 test loss: 448.605
200000: ********* epoch 21 ********* test accuracy for mode 36:0.292 test loss: 461.322
200010: accuracy:0.35 loss: 200.747 (lr:0.0001)
200020: accuracy:0.4 loss: 179.582 (lr:0.0001)
200030: accuracy:0.54 loss: 166.727 (lr:0.0001)
200040: accuracy:0.41 loss: 186.78 (lr:0.0001)
200050: accuracy:0.43 loss: 168.675 (lr:0.0001)
200060: accuracy:0.35 loss: 190.678 (lr:0.0001)
200070: accuracy:0.41 loss: 185.92 (lr:0.0001)
200080: accuracy:0.31 loss: 203.878 (lr:0.0001)
200090: accuracy:0.38 loss: 211.71 (lr:0.0001)
200100: accuracy:0.44 loss: 190.251 (lr:0.0001)
200110: accuracy:0.39 loss: 197.396 (lr:0.0001)
200120: accuracy:0.36 loss: 200.139 (lr:0.0001)
200130: accuracy:0.3 loss: 216.605 (lr:0.0001)
200140: accuracy:0.42 loss: 178.402 (lr:0.0001)
200150: accuracy:0.43 loss: 190.631 (lr:0.0001)
200160: accuracy:0.42 loss: 184.258 (lr:0.0001)
200170: accuracy:0.28 loss: 221.282 (lr:0.0001)
200180: accuracy:0.32 loss: 191.423 (lr:0.0001)
200190: accuracy:0.46 loss: 173.167 (lr:0.0001)
200200: accuracy:0.38 loss: 201.352 (lr:0.0001)
200210: accuracy:0.36 loss: 204.792 (lr:0.0001)
200220: accuracy:0.4 loss: 190.464 (lr:0.0001)
200230: accuracy:0.43 loss: 187.796 (lr:0.0001)
200240: accuracy:0.39 loss: 191.665 (lr:0.0001)
200250: accuracy:0.37 loss: 188.072 (lr:0.0001)
200260: accuracy:0.48 loss: 189.236 (lr:0.0001)
200270: accuracy:0.35 loss: 205.763 (lr:0.0001)
200280: accuracy:0.32 loss: 196.647 (lr:0.0001)
200290: accuracy:0.41 loss: 196.626 (lr:0.0001)
200300: accuracy:0.39 loss: 189.289 (lr:0.0001)
200310: accuracy:0.32 loss: 197.83 (lr:0.0001)
200320: accuracy:0.32 loss: 201.326 (lr:0.0001)
200330: accuracy:0.43 loss: 176.901 (lr:0.0001)
200340: accuracy:0.27 loss: 210.123 (lr:0.0001)
200350: accuracy:0.39 loss: 202.693 (lr:0.0001)
200360: accuracy:0.38 loss: 196.622 (lr:0.0001)
200370: accuracy:0.4 loss: 182.372 (lr:0.0001)
200380: accuracy:0.35 loss: 207.032 (lr:0.0001)
200390: accuracy:0.33 loss: 210.778 (lr:0.0001)
200400: accuracy:0.33 loss: 208.441 (lr:0.0001)
200410: accuracy:0.47 loss: 175.222 (lr:0.0001)
200420: accuracy:0.45 loss: 174.101 (lr:0.0001)
200430: accuracy:0.36 loss: 202.385 (lr:0.0001)
200440: accuracy:0.35 loss: 191.372 (lr:0.0001)
200450: accuracy:0.36 loss: 198.933 (lr:0.0001)
200460: accuracy:0.35 loss: 182.83 (lr:0.0001)
200470: accuracy:0.29 loss: 225.883 (lr:0.0001)
200480: accuracy:0.47 loss: 183.504 (lr:0.0001)
200490: accuracy:0.35 loss: 203.645 (lr:0.0001)
200500: accuracy:0.28 loss: 205.557 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
200500: ********* epoch 21 ********* test accuracy for all:0.261905 test loss: 263.401
200500: ********* epoch 21 ********* test accuracy for mode 0:0.0335 test loss: 500.02
200500: ********* epoch 21 ********* test accuracy for mode 1:0.025 test loss: 483.022
200500: ********* epoch 21 ********* test accuracy for mode 2:0.062 test loss: 263.741
200500: ********* epoch 21 ********* test accuracy for mode 24:0.2525 test loss: 275.317
200500: ********* epoch 21 ********* test accuracy for mode 25:0.2915 test loss: 248.337
200500: ********* epoch 21 ********* test accuracy for mode 26:0.469 test loss: 163.121
200500: ********* epoch 21 ********* test accuracy for mode 27:0.2695 test loss: 264.587
200500: ********* epoch 21 ********* test accuracy for mode 28:0.295 test loss: 259.104
200500: ********* epoch 21 ********* test accuracy for mode 29:0.2525 test loss: 267.798
200500: ********* epoch 21 ********* test accuracy for mode 30:0.269 test loss: 245.896
200500: ********* epoch 21 ********* test accuracy for mode 31:0.1945 test loss: 253.732
200500: ********* epoch 21 ********* test accuracy for mode 32:0.2175 test loss: 236.008
200500: ********* epoch 21 ********* test accuracy for mode 33:0.2395 test loss: 236.131
200500: ********* epoch 21 ********* test accuracy for mode 34:0.2825 test loss: 231.397
200500: ********* epoch 21 ********* test accuracy for mode 35:0.12 test loss: 470.776
200500: ********* epoch 21 ********* test accuracy for mode 36:0.193 test loss: 502.266
200510: accuracy:0.36 loss: 194.364 (lr:0.0001)
200520: accuracy:0.35 loss: 195.515 (lr:0.0001)
200530: accuracy:0.36 loss: 204.044 (lr:0.0001)
200540: accuracy:0.3 loss: 213.004 (lr:0.0001)
200550: accuracy:0.46 loss: 168.297 (lr:0.0001)
200560: accuracy:0.34 loss: 212.672 (lr:0.0001)
200570: accuracy:0.37 loss: 197.991 (lr:0.0001)
200580: accuracy:0.42 loss: 176.087 (lr:0.0001)
200590: accuracy:0.4 loss: 176.808 (lr:0.0001)
200600: accuracy:0.38 loss: 194.755 (lr:0.0001)
200610: accuracy:0.47 loss: 182.969 (lr:0.0001)
200620: accuracy:0.35 loss: 195.683 (lr:0.0001)
200630: accuracy:0.39 loss: 189.8 (lr:0.0001)
200640: accuracy:0.37 loss: 222.483 (lr:0.0001)
200650: accuracy:0.36 loss: 207.786 (lr:0.0001)
200660: accuracy:0.36 loss: 202.183 (lr:0.0001)
200670: accuracy:0.45 loss: 175.299 (lr:0.0001)
200680: accuracy:0.41 loss: 194.568 (lr:0.0001)
200690: accuracy:0.31 loss: 208.543 (lr:0.0001)
200700: accuracy:0.43 loss: 201.177 (lr:0.0001)
200710: accuracy:0.32 loss: 199.425 (lr:0.0001)
200720: accuracy:0.41 loss: 189.603 (lr:0.0001)
200730: accuracy:0.33 loss: 193.867 (lr:0.0001)
200740: accuracy:0.36 loss: 202.863 (lr:0.0001)
200750: accuracy:0.36 loss: 197.188 (lr:0.0001)
200760: accuracy:0.39 loss: 192.301 (lr:0.0001)
200770: accuracy:0.38 loss: 185.612 (lr:0.0001)
200780: accuracy:0.43 loss: 189.553 (lr:0.0001)
200790: accuracy:0.41 loss: 190.181 (lr:0.0001)
200800: accuracy:0.47 loss: 181.288 (lr:0.0001)
200810: accuracy:0.38 loss: 214.551 (lr:0.0001)
200820: accuracy:0.36 loss: 200.889 (lr:0.0001)
200830: accuracy:0.38 loss: 188.149 (lr:0.0001)
200840: accuracy:0.34 loss: 201.145 (lr:0.0001)
200850: accuracy:0.34 loss: 193.311 (lr:0.0001)
200860: accuracy:0.32 loss: 212.814 (lr:0.0001)
200870: accuracy:0.39 loss: 190.578 (lr:0.0001)
200880: accuracy:0.41 loss: 200.146 (lr:0.0001)
200890: accuracy:0.4 loss: 194.357 (lr:0.0001)
200900: accuracy:0.32 loss: 217.469 (lr:0.0001)
200910: accuracy:0.43 loss: 179.608 (lr:0.0001)
200920: accuracy:0.43 loss: 198.715 (lr:0.0001)
200930: accuracy:0.36 loss: 208.341 (lr:0.0001)
200940: accuracy:0.41 loss: 188.247 (lr:0.0001)
200950: accuracy:0.38 loss: 197.726 (lr:0.0001)
200960: accuracy:0.29 loss: 215.856 (lr:0.0001)
200970: accuracy:0.45 loss: 185.913 (lr:0.0001)
200980: accuracy:0.39 loss: 193.234 (lr:0.0001)
200990: accuracy:0.33 loss: 209.534 (lr:0.0001)
201000: accuracy:0.36 loss: 183.275 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
201000: ********* epoch 21 ********* test accuracy for all:0.260176 test loss: 263.532
201000: ********* epoch 21 ********* test accuracy for mode 0:0.043 test loss: 496.085
201000: ********* epoch 21 ********* test accuracy for mode 1:0.029 test loss: 481.365
201000: ********* epoch 21 ********* test accuracy for mode 2:0.0695 test loss: 262.541
201000: ********* epoch 21 ********* test accuracy for mode 24:0.263 test loss: 273.544
201000: ********* epoch 21 ********* test accuracy for mode 25:0.2765 test loss: 244.194
201000: ********* epoch 21 ********* test accuracy for mode 26:0.525 test loss: 159.954
201000: ********* epoch 21 ********* test accuracy for mode 27:0.2455 test loss: 261.529
201000: ********* epoch 21 ********* test accuracy for mode 28:0.3065 test loss: 254.169
201000: ********* epoch 21 ********* test accuracy for mode 29:0.2365 test loss: 266.144
201000: ********* epoch 21 ********* test accuracy for mode 30:0.248 test loss: 248.001
201000: ********* epoch 21 ********* test accuracy for mode 31:0.202 test loss: 248.603
201000: ********* epoch 21 ********* test accuracy for mode 32:0.227 test loss: 230.961
201000: ********* epoch 21 ********* test accuracy for mode 33:0.263 test loss: 233.971
201000: ********* epoch 21 ********* test accuracy for mode 34:0.241 test loss: 236.091
201000: ********* epoch 21 ********* test accuracy for mode 35:0.095 test loss: 489.732
201000: ********* epoch 21 ********* test accuracy for mode 36:0.072 test loss: 575.068
201010: accuracy:0.39 loss: 199.824 (lr:0.0001)
201020: accuracy:0.41 loss: 186.37 (lr:0.0001)
201030: accuracy:0.46 loss: 189.244 (lr:0.0001)
201040: accuracy:0.38 loss: 190.683 (lr:0.0001)
201050: accuracy:0.41 loss: 180.948 (lr:0.0001)
201060: accuracy:0.47 loss: 191.76 (lr:0.0001)
201070: accuracy:0.42 loss: 178.696 (lr:0.0001)
201080: accuracy:0.42 loss: 197.825 (lr:0.0001)
201090: accuracy:0.36 loss: 210.37 (lr:0.0001)
201100: accuracy:0.4 loss: 188.587 (lr:0.0001)
201110: accuracy:0.35 loss: 205.649 (lr:0.0001)
201120: accuracy:0.42 loss: 207.96 (lr:0.0001)
201130: accuracy:0.43 loss: 180.488 (lr:0.0001)
201140: accuracy:0.45 loss: 201.611 (lr:0.0001)
201150: accuracy:0.35 loss: 189.943 (lr:0.0001)
201160: accuracy:0.41 loss: 202.486 (lr:0.0001)
201170: accuracy:0.38 loss: 208.038 (lr:0.0001)
201180: accuracy:0.42 loss: 184.436 (lr:0.0001)
201190: accuracy:0.42 loss: 201.927 (lr:0.0001)
201200: accuracy:0.37 loss: 203.264 (lr:0.0001)
201210: accuracy:0.36 loss: 191.756 (lr:0.0001)
201220: accuracy:0.39 loss: 189.725 (lr:0.0001)
201230: accuracy:0.42 loss: 195.365 (lr:0.0001)
201240: accuracy:0.38 loss: 195.277 (lr:0.0001)
201250: accuracy:0.41 loss: 201.774 (lr:0.0001)
201260: accuracy:0.42 loss: 190.07 (lr:0.0001)
201270: accuracy:0.35 loss: 219.715 (lr:0.0001)
201280: accuracy:0.39 loss: 199.379 (lr:0.0001)
201290: accuracy:0.46 loss: 181.033 (lr:0.0001)
201300: accuracy:0.38 loss: 188.463 (lr:0.0001)
201310: accuracy:0.39 loss: 189.614 (lr:0.0001)
201320: accuracy:0.41 loss: 181.707 (lr:0.0001)
201330: accuracy:0.31 loss: 208.164 (lr:0.0001)
201340: accuracy:0.35 loss: 193.395 (lr:0.0001)
201350: accuracy:0.38 loss: 194.089 (lr:0.0001)
201360: accuracy:0.42 loss: 197.64 (lr:0.0001)
201370: accuracy:0.4 loss: 203.921 (lr:0.0001)
201380: accuracy:0.35 loss: 221.741 (lr:0.0001)
201390: accuracy:0.38 loss: 197.298 (lr:0.0001)
201400: accuracy:0.38 loss: 196.669 (lr:0.0001)
201410: accuracy:0.41 loss: 181.06 (lr:0.0001)
201420: accuracy:0.4 loss: 198.284 (lr:0.0001)
201430: accuracy:0.44 loss: 200.971 (lr:0.0001)
201440: accuracy:0.37 loss: 193.919 (lr:0.0001)
201450: accuracy:0.4 loss: 195.646 (lr:0.0001)
201460: accuracy:0.35 loss: 201.605 (lr:0.0001)
201470: accuracy:0.42 loss: 188.826 (lr:0.0001)
201480: accuracy:0.28 loss: 196.355 (lr:0.0001)
201490: accuracy:0.37 loss: 199.374 (lr:0.0001)
201500: accuracy:0.39 loss: 182.698 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
201500: ********* epoch 21 ********* test accuracy for all:0.260959 test loss: 260.204
201500: ********* epoch 21 ********* test accuracy for mode 0:0.04 test loss: 497.272
201500: ********* epoch 21 ********* test accuracy for mode 1:0.023 test loss: 469.998
201500: ********* epoch 21 ********* test accuracy for mode 2:0.1 test loss: 254.231
201500: ********* epoch 21 ********* test accuracy for mode 24:0.232 test loss: 276.814
201500: ********* epoch 21 ********* test accuracy for mode 25:0.2865 test loss: 244.641
201500: ********* epoch 21 ********* test accuracy for mode 26:0.454 test loss: 164.539
201500: ********* epoch 21 ********* test accuracy for mode 27:0.2535 test loss: 264.925
201500: ********* epoch 21 ********* test accuracy for mode 28:0.3035 test loss: 258.383
201500: ********* epoch 21 ********* test accuracy for mode 29:0.2415 test loss: 270.153
201500: ********* epoch 21 ********* test accuracy for mode 30:0.2435 test loss: 251.585
201500: ********* epoch 21 ********* test accuracy for mode 31:0.226 test loss: 250.279
201500: ********* epoch 21 ********* test accuracy for mode 32:0.1835 test loss: 236.462
201500: ********* epoch 21 ********* test accuracy for mode 33:0.3125 test loss: 227.314
201500: ********* epoch 21 ********* test accuracy for mode 34:0.2195 test loss: 235.617
201500: ********* epoch 21 ********* test accuracy for mode 35:0.122 test loss: 471.276
201500: ********* epoch 21 ********* test accuracy for mode 36:0.1015 test loss: 521.087
201510: accuracy:0.36 loss: 209.438 (lr:0.0001)
201520: accuracy:0.32 loss: 215.975 (lr:0.0001)
201530: accuracy:0.41 loss: 198.07 (lr:0.0001)
201540: accuracy:0.38 loss: 181.273 (lr:0.0001)
201550: accuracy:0.35 loss: 212.578 (lr:0.0001)
201560: accuracy:0.36 loss: 204.828 (lr:0.0001)
201570: accuracy:0.39 loss: 186.497 (lr:0.0001)
201580: accuracy:0.36 loss: 207.97 (lr:0.0001)
201590: accuracy:0.29 loss: 207.571 (lr:0.0001)
201600: accuracy:0.4 loss: 177.172 (lr:0.0001)
201610: accuracy:0.38 loss: 195.366 (lr:0.0001)
201620: accuracy:0.4 loss: 187.33 (lr:0.0001)
201630: accuracy:0.39 loss: 194.263 (lr:0.0001)
201640: accuracy:0.35 loss: 181.148 (lr:0.0001)
201650: accuracy:0.43 loss: 174.031 (lr:0.0001)
201660: accuracy:0.36 loss: 197.3 (lr:0.0001)
201670: accuracy:0.39 loss: 173.683 (lr:0.0001)
201680: accuracy:0.33 loss: 216.612 (lr:0.0001)
201690: accuracy:0.44 loss: 198.771 (lr:0.0001)
201700: accuracy:0.42 loss: 208.075 (lr:0.0001)
201710: accuracy:0.46 loss: 169.41 (lr:0.0001)
201720: accuracy:0.44 loss: 183.308 (lr:0.0001)
201730: accuracy:0.34 loss: 202.865 (lr:0.0001)
201740: accuracy:0.47 loss: 183.959 (lr:0.0001)
201750: accuracy:0.4 loss: 184.993 (lr:0.0001)
201760: accuracy:0.39 loss: 195.439 (lr:0.0001)
201770: accuracy:0.35 loss: 198.081 (lr:0.0001)
201780: accuracy:0.33 loss: 185.543 (lr:0.0001)
201790: accuracy:0.38 loss: 187.257 (lr:0.0001)
201800: accuracy:0.4 loss: 197.318 (lr:0.0001)
201810: accuracy:0.36 loss: 193.858 (lr:0.0001)
201820: accuracy:0.41 loss: 188.377 (lr:0.0001)
201830: accuracy:0.39 loss: 179.19 (lr:0.0001)
201840: accuracy:0.38 loss: 202.859 (lr:0.0001)
201850: accuracy:0.32 loss: 205.935 (lr:0.0001)
201860: accuracy:0.37 loss: 205.511 (lr:0.0001)
201870: accuracy:0.45 loss: 184.205 (lr:0.0001)
201880: accuracy:0.3 loss: 209.798 (lr:0.0001)
201890: accuracy:0.31 loss: 201.279 (lr:0.0001)
201900: accuracy:0.41 loss: 190.454 (lr:0.0001)
201910: accuracy:0.41 loss: 196.875 (lr:0.0001)
201920: accuracy:0.4 loss: 187.622 (lr:0.0001)
201930: accuracy:0.38 loss: 178.947 (lr:0.0001)
201940: accuracy:0.33 loss: 205.653 (lr:0.0001)
201950: accuracy:0.42 loss: 188.741 (lr:0.0001)
201960: accuracy:0.35 loss: 201.354 (lr:0.0001)
201970: accuracy:0.38 loss: 184.031 (lr:0.0001)
201980: accuracy:0.37 loss: 201.858 (lr:0.0001)
201990: accuracy:0.39 loss: 205.568 (lr:0.0001)
202000: accuracy:0.47 loss: 170.57 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
202000: ********* epoch 21 ********* test accuracy for all:0.260811 test loss: 261.869
202000: ********* epoch 21 ********* test accuracy for mode 0:0.04 test loss: 504.891
202000: ********* epoch 21 ********* test accuracy for mode 1:0.024 test loss: 480.222
202000: ********* epoch 21 ********* test accuracy for mode 2:0.0765 test loss: 257.589
202000: ********* epoch 21 ********* test accuracy for mode 24:0.235 test loss: 282.171
202000: ********* epoch 21 ********* test accuracy for mode 25:0.2505 test loss: 259.702
202000: ********* epoch 21 ********* test accuracy for mode 26:0.433 test loss: 168.098
202000: ********* epoch 21 ********* test accuracy for mode 27:0.269 test loss: 270.592
202000: ********* epoch 21 ********* test accuracy for mode 28:0.2575 test loss: 265.057
202000: ********* epoch 21 ********* test accuracy for mode 29:0.2645 test loss: 267.819
202000: ********* epoch 21 ********* test accuracy for mode 30:0.2445 test loss: 248.839
202000: ********* epoch 21 ********* test accuracy for mode 31:0.216 test loss: 250.121
202000: ********* epoch 21 ********* test accuracy for mode 32:0.202 test loss: 233.054
202000: ********* epoch 21 ********* test accuracy for mode 33:0.278 test loss: 228.459
202000: ********* epoch 21 ********* test accuracy for mode 34:0.2795 test loss: 229.256
202000: ********* epoch 21 ********* test accuracy for mode 35:0.1665 test loss: 460.327
202000: ********* epoch 21 ********* test accuracy for mode 36:0.175 test loss: 497.275
202010: accuracy:0.38 loss: 195.666 (lr:0.0001)
202020: accuracy:0.35 loss: 192.475 (lr:0.0001)
202030: accuracy:0.49 loss: 177.286 (lr:0.0001)
202040: accuracy:0.41 loss: 200.526 (lr:0.0001)
202050: accuracy:0.31 loss: 213.974 (lr:0.0001)
202060: accuracy:0.32 loss: 200.529 (lr:0.0001)
202070: accuracy:0.33 loss: 205.09 (lr:0.0001)
202080: accuracy:0.28 loss: 210.506 (lr:0.0001)
202090: accuracy:0.39 loss: 206.243 (lr:0.0001)
202100: accuracy:0.46 loss: 190.295 (lr:0.0001)
202110: accuracy:0.37 loss: 192.065 (lr:0.0001)
202120: accuracy:0.32 loss: 229.555 (lr:0.0001)
202130: accuracy:0.38 loss: 189.464 (lr:0.0001)
202140: accuracy:0.38 loss: 176.398 (lr:0.0001)
202150: accuracy:0.49 loss: 162.356 (lr:0.0001)
202160: accuracy:0.47 loss: 181.122 (lr:0.0001)
202170: accuracy:0.4 loss: 189.119 (lr:0.0001)
202180: accuracy:0.41 loss: 185.494 (lr:0.0001)
202190: accuracy:0.38 loss: 190.893 (lr:0.0001)
202200: accuracy:0.45 loss: 169.123 (lr:0.0001)
202210: accuracy:0.4 loss: 190.423 (lr:0.0001)
202220: accuracy:0.47 loss: 170.96 (lr:0.0001)
202230: accuracy:0.33 loss: 199.73 (lr:0.0001)
202240: accuracy:0.4 loss: 185.486 (lr:0.0001)
202250: accuracy:0.39 loss: 193.839 (lr:0.0001)
202260: accuracy:0.41 loss: 186.536 (lr:0.0001)
202270: accuracy:0.41 loss: 187.84 (lr:0.0001)
202280: accuracy:0.4 loss: 177.76 (lr:0.0001)
202290: accuracy:0.36 loss: 205.748 (lr:0.0001)
202300: accuracy:0.39 loss: 179.807 (lr:0.0001)
202310: accuracy:0.44 loss: 178.374 (lr:0.0001)
202320: accuracy:0.4 loss: 197.412 (lr:0.0001)
202330: accuracy:0.42 loss: 166.319 (lr:0.0001)
202340: accuracy:0.47 loss: 202.282 (lr:0.0001)
202350: accuracy:0.46 loss: 188.65 (lr:0.0001)
202360: accuracy:0.41 loss: 177.787 (lr:0.0001)
202370: accuracy:0.43 loss: 203.594 (lr:0.0001)
202380: accuracy:0.36 loss: 195.091 (lr:0.0001)
202390: accuracy:0.33 loss: 198.151 (lr:0.0001)
202400: accuracy:0.39 loss: 207.199 (lr:0.0001)
202410: accuracy:0.32 loss: 198.612 (lr:0.0001)
202420: accuracy:0.37 loss: 176.113 (lr:0.0001)
202430: accuracy:0.36 loss: 197.615 (lr:0.0001)
202440: accuracy:0.37 loss: 180.78 (lr:0.0001)
202450: accuracy:0.32 loss: 212.384 (lr:0.0001)
202460: accuracy:0.38 loss: 184.667 (lr:0.0001)
202470: accuracy:0.35 loss: 191.538 (lr:0.0001)
202480: accuracy:0.33 loss: 221.123 (lr:0.0001)
202490: accuracy:0.45 loss: 171.775 (lr:0.0001)
202500: accuracy:0.37 loss: 192.402 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
202500: ********* epoch 21 ********* test accuracy for all:0.257068 test loss: 265.101
202500: ********* epoch 21 ********* test accuracy for mode 0:0.038 test loss: 505.255
202500: ********* epoch 21 ********* test accuracy for mode 1:0.032 test loss: 480.393
202500: ********* epoch 21 ********* test accuracy for mode 2:0.0565 test loss: 259.047
202500: ********* epoch 21 ********* test accuracy for mode 24:0.226 test loss: 291.398
202500: ********* epoch 21 ********* test accuracy for mode 25:0.2835 test loss: 251.987
202500: ********* epoch 21 ********* test accuracy for mode 26:0.5055 test loss: 158.837
202500: ********* epoch 21 ********* test accuracy for mode 27:0.2295 test loss: 276.951
202500: ********* epoch 21 ********* test accuracy for mode 28:0.2775 test loss: 268.431
202500: ********* epoch 21 ********* test accuracy for mode 29:0.2265 test loss: 279.522
202500: ********* epoch 21 ********* test accuracy for mode 30:0.2575 test loss: 249.476
202500: ********* epoch 21 ********* test accuracy for mode 31:0.233 test loss: 247.322
202500: ********* epoch 21 ********* test accuracy for mode 32:0.2205 test loss: 229.508
202500: ********* epoch 21 ********* test accuracy for mode 33:0.257 test loss: 228.887
202500: ********* epoch 21 ********* test accuracy for mode 34:0.2925 test loss: 226.005
202500: ********* epoch 21 ********* test accuracy for mode 35:0.108 test loss: 472.062
202500: ********* epoch 21 ********* test accuracy for mode 36:0.0965 test loss: 540.544
202510: accuracy:0.43 loss: 176.694 (lr:0.0001)
202520: accuracy:0.34 loss: 187.629 (lr:0.0001)
202530: accuracy:0.34 loss: 209.214 (lr:0.0001)
202540: accuracy:0.39 loss: 193.715 (lr:0.0001)
202550: accuracy:0.37 loss: 208.932 (lr:0.0001)
202560: accuracy:0.36 loss: 206.61 (lr:0.0001)
202570: accuracy:0.36 loss: 210.283 (lr:0.0001)
202580: accuracy:0.34 loss: 192.671 (lr:0.0001)
202590: accuracy:0.42 loss: 183.034 (lr:0.0001)
202600: accuracy:0.35 loss: 178.319 (lr:0.0001)
202610: accuracy:0.34 loss: 200.98 (lr:0.0001)
202620: accuracy:0.41 loss: 196.066 (lr:0.0001)
202630: accuracy:0.38 loss: 182.235 (lr:0.0001)
202640: accuracy:0.36 loss: 195.607 (lr:0.0001)
202650: accuracy:0.35 loss: 206.747 (lr:0.0001)
202660: accuracy:0.41 loss: 180.747 (lr:0.0001)
202670: accuracy:0.41 loss: 182.628 (lr:0.0001)
202680: accuracy:0.36 loss: 193.228 (lr:0.0001)
202690: accuracy:0.5 loss: 179.244 (lr:0.0001)
202700: accuracy:0.36 loss: 195.54 (lr:0.0001)
202710: accuracy:0.41 loss: 184.959 (lr:0.0001)
202720: accuracy:0.44 loss: 175.036 (lr:0.0001)
202730: accuracy:0.39 loss: 198.003 (lr:0.0001)
202740: accuracy:0.4 loss: 189.562 (lr:0.0001)
202750: accuracy:0.41 loss: 198.844 (lr:0.0001)
202760: accuracy:0.36 loss: 195.803 (lr:0.0001)
202770: accuracy:0.36 loss: 204.567 (lr:0.0001)
202780: accuracy:0.36 loss: 186.127 (lr:0.0001)
202790: accuracy:0.32 loss: 197.484 (lr:0.0001)
202800: accuracy:0.43 loss: 182.695 (lr:0.0001)
202810: accuracy:0.36 loss: 202.184 (lr:0.0001)
202820: accuracy:0.32 loss: 221.543 (lr:0.0001)
202830: accuracy:0.35 loss: 193.21 (lr:0.0001)
202840: accuracy:0.39 loss: 186.779 (lr:0.0001)
202850: accuracy:0.48 loss: 195.878 (lr:0.0001)
202860: accuracy:0.33 loss: 202.807 (lr:0.0001)
202870: accuracy:0.41 loss: 185.538 (lr:0.0001)
202880: accuracy:0.37 loss: 187.695 (lr:0.0001)
202890: accuracy:0.36 loss: 182.015 (lr:0.0001)
202900: accuracy:0.46 loss: 184.565 (lr:0.0001)
202910: accuracy:0.35 loss: 194.795 (lr:0.0001)
202920: accuracy:0.4 loss: 202.209 (lr:0.0001)
202930: accuracy:0.35 loss: 204.179 (lr:0.0001)
202940: accuracy:0.38 loss: 201.964 (lr:0.0001)
202950: accuracy:0.4 loss: 195.606 (lr:0.0001)
202960: accuracy:0.33 loss: 199.461 (lr:0.0001)
202970: accuracy:0.36 loss: 216.545 (lr:0.0001)
202980: accuracy:0.41 loss: 193.9 (lr:0.0001)
202990: accuracy:0.42 loss: 183.032 (lr:0.0001)
203000: accuracy:0.33 loss: 205.631 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
203000: ********* epoch 21 ********* test accuracy for all:0.26077 test loss: 262.117
203000: ********* epoch 21 ********* test accuracy for mode 0:0.042 test loss: 494.145
203000: ********* epoch 21 ********* test accuracy for mode 1:0.03 test loss: 486.665
203000: ********* epoch 21 ********* test accuracy for mode 2:0.108 test loss: 254.121
203000: ********* epoch 21 ********* test accuracy for mode 24:0.2595 test loss: 271.805
203000: ********* epoch 21 ********* test accuracy for mode 25:0.2785 test loss: 246.761
203000: ********* epoch 21 ********* test accuracy for mode 26:0.4935 test loss: 163.323
203000: ********* epoch 21 ********* test accuracy for mode 27:0.2275 test loss: 271.452
203000: ********* epoch 21 ********* test accuracy for mode 28:0.301 test loss: 257.199
203000: ********* epoch 21 ********* test accuracy for mode 29:0.2425 test loss: 266.106
203000: ********* epoch 21 ********* test accuracy for mode 30:0.283 test loss: 242.441
203000: ********* epoch 21 ********* test accuracy for mode 31:0.224 test loss: 243.996
203000: ********* epoch 21 ********* test accuracy for mode 32:0.213 test loss: 230.348
203000: ********* epoch 21 ********* test accuracy for mode 33:0.2655 test loss: 233.05
203000: ********* epoch 21 ********* test accuracy for mode 34:0.2545 test loss: 233.297
203000: ********* epoch 21 ********* test accuracy for mode 35:0.095 test loss: 480.821
203000: ********* epoch 21 ********* test accuracy for mode 36:0.089 test loss: 540.672
203010: accuracy:0.39 loss: 189.702 (lr:0.0001)
203020: accuracy:0.28 loss: 209.775 (lr:0.0001)
203030: accuracy:0.48 loss: 181.104 (lr:0.0001)
203040: accuracy:0.43 loss: 192.931 (lr:0.0001)
203050: accuracy:0.33 loss: 211.843 (lr:0.0001)
203060: accuracy:0.43 loss: 185.539 (lr:0.0001)
203070: accuracy:0.35 loss: 211.468 (lr:0.0001)
203080: accuracy:0.42 loss: 197.616 (lr:0.0001)
203090: accuracy:0.43 loss: 186.186 (lr:0.0001)
203100: accuracy:0.44 loss: 196.115 (lr:0.0001)
203110: accuracy:0.33 loss: 207.363 (lr:0.0001)
203120: accuracy:0.37 loss: 209.756 (lr:0.0001)
203130: accuracy:0.29 loss: 205.404 (lr:0.0001)
203140: accuracy:0.49 loss: 175.491 (lr:0.0001)
203150: accuracy:0.37 loss: 184.515 (lr:0.0001)
203160: accuracy:0.36 loss: 198.87 (lr:0.0001)
203170: accuracy:0.29 loss: 208.413 (lr:0.0001)
203180: accuracy:0.42 loss: 194.901 (lr:0.0001)
203190: accuracy:0.25 loss: 221.648 (lr:0.0001)
203200: accuracy:0.33 loss: 199.914 (lr:0.0001)
203210: accuracy:0.39 loss: 204.282 (lr:0.0001)
203220: accuracy:0.38 loss: 197.872 (lr:0.0001)
203230: accuracy:0.4 loss: 199.559 (lr:0.0001)
203240: accuracy:0.32 loss: 210.848 (lr:0.0001)
203250: accuracy:0.43 loss: 179.156 (lr:0.0001)
203260: accuracy:0.45 loss: 190.602 (lr:0.0001)
203270: accuracy:0.35 loss: 203.254 (lr:0.0001)
203280: accuracy:0.35 loss: 199.192 (lr:0.0001)
203290: accuracy:0.29 loss: 221.534 (lr:0.0001)
203300: accuracy:0.42 loss: 191.073 (lr:0.0001)
203310: accuracy:0.45 loss: 163.971 (lr:0.0001)
203320: accuracy:0.39 loss: 194.835 (lr:0.0001)
203330: accuracy:0.4 loss: 189.498 (lr:0.0001)
203340: accuracy:0.42 loss: 178.061 (lr:0.0001)
203350: accuracy:0.38 loss: 193.027 (lr:0.0001)
203360: accuracy:0.35 loss: 197.833 (lr:0.0001)
203370: accuracy:0.46 loss: 182.722 (lr:0.0001)
203380: accuracy:0.36 loss: 186.194 (lr:0.0001)
203390: accuracy:0.3 loss: 214.901 (lr:0.0001)
203400: accuracy:0.34 loss: 190.325 (lr:0.0001)
203410: accuracy:0.36 loss: 222.109 (lr:0.0001)
203420: accuracy:0.38 loss: 195.99 (lr:0.0001)
203430: accuracy:0.44 loss: 175.467 (lr:0.0001)
203440: accuracy:0.36 loss: 192.764 (lr:0.0001)
203450: accuracy:0.39 loss: 194.114 (lr:0.0001)
203460: accuracy:0.38 loss: 195.784 (lr:0.0001)
203470: accuracy:0.36 loss: 185.661 (lr:0.0001)
203480: accuracy:0.4 loss: 194.697 (lr:0.0001)
203490: accuracy:0.41 loss: 195.986 (lr:0.0001)
203500: accuracy:0.29 loss: 209.503 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
203500: ********* epoch 21 ********* test accuracy for all:0.266838 test loss: 259.831
203500: ********* epoch 21 ********* test accuracy for mode 0:0.036 test loss: 505.349
203500: ********* epoch 21 ********* test accuracy for mode 1:0.028 test loss: 485.687
203500: ********* epoch 21 ********* test accuracy for mode 2:0.1 test loss: 255.944
203500: ********* epoch 21 ********* test accuracy for mode 24:0.2585 test loss: 269.935
203500: ********* epoch 21 ********* test accuracy for mode 25:0.2775 test loss: 245.461
203500: ********* epoch 21 ********* test accuracy for mode 26:0.4745 test loss: 163.409
203500: ********* epoch 21 ********* test accuracy for mode 27:0.2505 test loss: 262.167
203500: ********* epoch 21 ********* test accuracy for mode 28:0.3035 test loss: 256.076
203500: ********* epoch 21 ********* test accuracy for mode 29:0.238 test loss: 264.915
203500: ********* epoch 21 ********* test accuracy for mode 30:0.2695 test loss: 242.307
203500: ********* epoch 21 ********* test accuracy for mode 31:0.2325 test loss: 243.131
203500: ********* epoch 21 ********* test accuracy for mode 32:0.199 test loss: 229.299
203500: ********* epoch 21 ********* test accuracy for mode 33:0.2955 test loss: 228.345
203500: ********* epoch 21 ********* test accuracy for mode 34:0.2225 test loss: 233.197
203500: ********* epoch 21 ********* test accuracy for mode 35:0.145 test loss: 473.549
203500: ********* epoch 21 ********* test accuracy for mode 36:0.241 test loss: 498.219
203510: accuracy:0.4 loss: 173.901 (lr:0.0001)
203520: accuracy:0.36 loss: 215.42 (lr:0.0001)
203530: accuracy:0.34 loss: 227.694 (lr:0.0001)
203540: accuracy:0.33 loss: 223.173 (lr:0.0001)
203550: accuracy:0.35 loss: 200.594 (lr:0.0001)
203560: accuracy:0.48 loss: 189.719 (lr:0.0001)
203570: accuracy:0.38 loss: 203.972 (lr:0.0001)
203580: accuracy:0.45 loss: 175.031 (lr:0.0001)
203590: accuracy:0.38 loss: 208.71 (lr:0.0001)
203600: accuracy:0.37 loss: 186.744 (lr:0.0001)
203610: accuracy:0.43 loss: 189.161 (lr:0.0001)
203620: accuracy:0.36 loss: 219.764 (lr:0.0001)
203630: accuracy:0.35 loss: 209.102 (lr:0.0001)
203640: accuracy:0.46 loss: 179.675 (lr:0.0001)
203650: accuracy:0.29 loss: 212.406 (lr:0.0001)
203660: accuracy:0.35 loss: 198.162 (lr:0.0001)
203670: accuracy:0.42 loss: 209.278 (lr:0.0001)
203680: accuracy:0.35 loss: 192.422 (lr:0.0001)
203690: accuracy:0.45 loss: 204.717 (lr:0.0001)
203700: accuracy:0.44 loss: 183.467 (lr:0.0001)
203710: accuracy:0.47 loss: 189.244 (lr:0.0001)
203720: accuracy:0.39 loss: 188.165 (lr:0.0001)
203730: accuracy:0.27 loss: 215.863 (lr:0.0001)
203740: accuracy:0.38 loss: 189.904 (lr:0.0001)
203750: accuracy:0.36 loss: 201.659 (lr:0.0001)
203760: accuracy:0.3 loss: 198.672 (lr:0.0001)
203770: accuracy:0.37 loss: 200.06 (lr:0.0001)
203780: accuracy:0.35 loss: 229.477 (lr:0.0001)
203790: accuracy:0.4 loss: 186.328 (lr:0.0001)
203800: accuracy:0.39 loss: 191.202 (lr:0.0001)
203810: accuracy:0.31 loss: 193.934 (lr:0.0001)
203820: accuracy:0.44 loss: 185.923 (lr:0.0001)
203830: accuracy:0.35 loss: 196.055 (lr:0.0001)
203840: accuracy:0.38 loss: 184.319 (lr:0.0001)
203850: accuracy:0.4 loss: 210.156 (lr:0.0001)
203860: accuracy:0.42 loss: 184.504 (lr:0.0001)
203870: accuracy:0.43 loss: 191.166 (lr:0.0001)
203880: accuracy:0.38 loss: 190.99 (lr:0.0001)
203890: accuracy:0.38 loss: 203.313 (lr:0.0001)
203900: accuracy:0.37 loss: 193.396 (lr:0.0001)
203910: accuracy:0.35 loss: 207.08 (lr:0.0001)
203920: accuracy:0.45 loss: 171.343 (lr:0.0001)
203930: accuracy:0.39 loss: 192.416 (lr:0.0001)
203940: accuracy:0.36 loss: 199.496 (lr:0.0001)
203950: accuracy:0.37 loss: 184.676 (lr:0.0001)
203960: accuracy:0.34 loss: 217.731 (lr:0.0001)
203970: accuracy:0.38 loss: 196.229 (lr:0.0001)
203980: accuracy:0.42 loss: 190.508 (lr:0.0001)
203990: accuracy:0.38 loss: 174.163 (lr:0.0001)
204000: accuracy:0.38 loss: 178.75 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
204000: ********* epoch 21 ********* test accuracy for all:0.257973 test loss: 263.587
204000: ********* epoch 21 ********* test accuracy for mode 0:0.0415 test loss: 501.011
204000: ********* epoch 21 ********* test accuracy for mode 1:0.0255 test loss: 481.083
204000: ********* epoch 21 ********* test accuracy for mode 2:0.0725 test loss: 259.676
204000: ********* epoch 21 ********* test accuracy for mode 24:0.236 test loss: 281.481
204000: ********* epoch 21 ********* test accuracy for mode 25:0.278 test loss: 243.917
204000: ********* epoch 21 ********* test accuracy for mode 26:0.5455 test loss: 150.203
204000: ********* epoch 21 ********* test accuracy for mode 27:0.239 test loss: 261.239
204000: ********* epoch 21 ********* test accuracy for mode 28:0.294 test loss: 257.814
204000: ********* epoch 21 ********* test accuracy for mode 29:0.2545 test loss: 265.279
204000: ********* epoch 21 ********* test accuracy for mode 30:0.2465 test loss: 251.986
204000: ********* epoch 21 ********* test accuracy for mode 31:0.1775 test loss: 257.889
204000: ********* epoch 21 ********* test accuracy for mode 32:0.2445 test loss: 232.072
204000: ********* epoch 21 ********* test accuracy for mode 33:0.231 test loss: 239.25
204000: ********* epoch 21 ********* test accuracy for mode 34:0.2435 test loss: 237.393
204000: ********* epoch 21 ********* test accuracy for mode 35:0.117 test loss: 468.016
204000: ********* epoch 21 ********* test accuracy for mode 36:0.078 test loss: 569.036
204010: accuracy:0.31 loss: 212.831 (lr:0.0001)
204020: accuracy:0.4 loss: 185.561 (lr:0.0001)
204030: accuracy:0.37 loss: 207.477 (lr:0.0001)
204040: accuracy:0.34 loss: 216.197 (lr:0.0001)
204050: accuracy:0.32 loss: 194.891 (lr:0.0001)
204060: accuracy:0.35 loss: 184.933 (lr:0.0001)
204070: accuracy:0.35 loss: 213.364 (lr:0.0001)
204080: accuracy:0.25 loss: 219.852 (lr:0.0001)
204090: accuracy:0.44 loss: 189.047 (lr:0.0001)
204100: accuracy:0.33 loss: 200.552 (lr:0.0001)
204110: accuracy:0.4 loss: 177.796 (lr:0.0001)
204120: accuracy:0.31 loss: 210.667 (lr:0.0001)
204130: accuracy:0.38 loss: 203.004 (lr:0.0001)
204140: accuracy:0.45 loss: 176.866 (lr:0.0001)
204150: accuracy:0.3 loss: 213.002 (lr:0.0001)
204160: accuracy:0.37 loss: 202.563 (lr:0.0001)
204170: accuracy:0.41 loss: 200.894 (lr:0.0001)
204180: accuracy:0.39 loss: 203.3 (lr:0.0001)
204190: accuracy:0.4 loss: 198.926 (lr:0.0001)
204200: accuracy:0.39 loss: 193.917 (lr:0.0001)
204210: accuracy:0.41 loss: 188.056 (lr:0.0001)
204220: accuracy:0.39 loss: 197.562 (lr:0.0001)
204230: accuracy:0.33 loss: 202.723 (lr:0.0001)
204240: accuracy:0.4 loss: 184.816 (lr:0.0001)
204250: accuracy:0.4 loss: 181.377 (lr:0.0001)
204260: accuracy:0.41 loss: 181.303 (lr:0.0001)
204270: accuracy:0.34 loss: 204.784 (lr:0.0001)
204280: accuracy:0.4 loss: 200.083 (lr:0.0001)
204290: accuracy:0.39 loss: 190.314 (lr:0.0001)
204300: accuracy:0.33 loss: 197.424 (lr:0.0001)
204310: accuracy:0.39 loss: 189.583 (lr:0.0001)
204320: accuracy:0.36 loss: 206.67 (lr:0.0001)
204330: accuracy:0.39 loss: 179.613 (lr:0.0001)
204340: accuracy:0.37 loss: 214.202 (lr:0.0001)
204350: accuracy:0.35 loss: 204.913 (lr:0.0001)
204360: accuracy:0.37 loss: 199.394 (lr:0.0001)
204370: accuracy:0.37 loss: 208.255 (lr:0.0001)
204380: accuracy:0.36 loss: 207.602 (lr:0.0001)
204390: accuracy:0.4 loss: 197.976 (lr:0.0001)
204400: accuracy:0.31 loss: 210.565 (lr:0.0001)
204410: accuracy:0.38 loss: 194.476 (lr:0.0001)
204420: accuracy:0.42 loss: 186.797 (lr:0.0001)
204430: accuracy:0.36 loss: 196.078 (lr:0.0001)
204440: accuracy:0.39 loss: 179.33 (lr:0.0001)
204450: accuracy:0.4 loss: 203.36 (lr:0.0001)
204460: accuracy:0.35 loss: 206.338 (lr:0.0001)
204470: accuracy:0.37 loss: 177.676 (lr:0.0001)
204480: accuracy:0.37 loss: 198.15 (lr:0.0001)
204490: accuracy:0.49 loss: 183.287 (lr:0.0001)
204500: accuracy:0.4 loss: 188.732 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
204500: ********* epoch 22 ********* test accuracy for all:0.260649 test loss: 263.792
204500: ********* epoch 22 ********* test accuracy for mode 0:0.037 test loss: 512.524
204500: ********* epoch 22 ********* test accuracy for mode 1:0.0325 test loss: 482.893
204500: ********* epoch 22 ********* test accuracy for mode 2:0.1225 test loss: 255.319
204500: ********* epoch 22 ********* test accuracy for mode 24:0.229 test loss: 283.188
204500: ********* epoch 22 ********* test accuracy for mode 25:0.2355 test loss: 254.077
204500: ********* epoch 22 ********* test accuracy for mode 26:0.544 test loss: 154.321
204500: ********* epoch 22 ********* test accuracy for mode 27:0.26 test loss: 262.981
204500: ********* epoch 22 ********* test accuracy for mode 28:0.2925 test loss: 260.071
204500: ********* epoch 22 ********* test accuracy for mode 29:0.2285 test loss: 270.158
204500: ********* epoch 22 ********* test accuracy for mode 30:0.255 test loss: 249.257
204500: ********* epoch 22 ********* test accuracy for mode 31:0.1975 test loss: 250.841
204500: ********* epoch 22 ********* test accuracy for mode 32:0.238 test loss: 226.663
204500: ********* epoch 22 ********* test accuracy for mode 33:0.328 test loss: 225.858
204500: ********* epoch 22 ********* test accuracy for mode 34:0.18 test loss: 237.19
204500: ********* epoch 22 ********* test accuracy for mode 35:0.1285 test loss: 468.197
204500: ********* epoch 22 ********* test accuracy for mode 36:0.0955 test loss: 547.21
204510: accuracy:0.36 loss: 192.696 (lr:0.0001)
204520: accuracy:0.36 loss: 192.154 (lr:0.0001)
204530: accuracy:0.36 loss: 196.029 (lr:0.0001)
204540: accuracy:0.34 loss: 200.381 (lr:0.0001)
204550: accuracy:0.34 loss: 209.08 (lr:0.0001)
204560: accuracy:0.4 loss: 191.111 (lr:0.0001)
204570: accuracy:0.34 loss: 193.565 (lr:0.0001)
204580: accuracy:0.35 loss: 203.947 (lr:0.0001)
204590: accuracy:0.42 loss: 203.414 (lr:0.0001)
204600: accuracy:0.37 loss: 188.157 (lr:0.0001)
204610: accuracy:0.4 loss: 183.033 (lr:0.0001)
204620: accuracy:0.29 loss: 219.531 (lr:0.0001)
204630: accuracy:0.42 loss: 197.476 (lr:0.0001)
204640: accuracy:0.47 loss: 198.826 (lr:0.0001)
204650: accuracy:0.37 loss: 201.608 (lr:0.0001)
204660: accuracy:0.43 loss: 189.572 (lr:0.0001)
204670: accuracy:0.33 loss: 187.409 (lr:0.0001)
204680: accuracy:0.41 loss: 189.115 (lr:0.0001)
204690: accuracy:0.34 loss: 215.381 (lr:0.0001)
204700: accuracy:0.36 loss: 202.691 (lr:0.0001)
204710: accuracy:0.35 loss: 185.936 (lr:0.0001)
204720: accuracy:0.44 loss: 190.513 (lr:0.0001)
204730: accuracy:0.39 loss: 177.761 (lr:0.0001)
204740: accuracy:0.36 loss: 215.058 (lr:0.0001)
204750: accuracy:0.43 loss: 175.447 (lr:0.0001)
204760: accuracy:0.3 loss: 213.26 (lr:0.0001)
204770: accuracy:0.35 loss: 194.934 (lr:0.0001)
204780: accuracy:0.41 loss: 195.93 (lr:0.0001)
204790: accuracy:0.37 loss: 213.996 (lr:0.0001)
204800: accuracy:0.34 loss: 218.173 (lr:0.0001)
204810: accuracy:0.34 loss: 195.022 (lr:0.0001)
204820: accuracy:0.4 loss: 181.259 (lr:0.0001)
204830: accuracy:0.42 loss: 180.282 (lr:0.0001)
204840: accuracy:0.43 loss: 179.064 (lr:0.0001)
204850: accuracy:0.34 loss: 191.624 (lr:0.0001)
204860: accuracy:0.34 loss: 195.227 (lr:0.0001)
204870: accuracy:0.41 loss: 193.516 (lr:0.0001)
204880: accuracy:0.41 loss: 198.629 (lr:0.0001)
204890: accuracy:0.47 loss: 196.679 (lr:0.0001)
204900: accuracy:0.29 loss: 184.795 (lr:0.0001)
204910: accuracy:0.43 loss: 191.864 (lr:0.0001)
204920: accuracy:0.36 loss: 188.286 (lr:0.0001)
204930: accuracy:0.37 loss: 192.907 (lr:0.0001)
204940: accuracy:0.35 loss: 193.683 (lr:0.0001)
204950: accuracy:0.31 loss: 205.111 (lr:0.0001)
204960: accuracy:0.46 loss: 193.457 (lr:0.0001)
204970: accuracy:0.37 loss: 184.027 (lr:0.0001)
204980: accuracy:0.45 loss: 177.152 (lr:0.0001)
204990: accuracy:0.31 loss: 197.079 (lr:0.0001)
205000: accuracy:0.38 loss: 183.875 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
205000: ********* epoch 22 ********* test accuracy for all:0.266649 test loss: 260.67
205000: ********* epoch 22 ********* test accuracy for mode 0:0.038 test loss: 498.498
205000: ********* epoch 22 ********* test accuracy for mode 1:0.0215 test loss: 473.529
205000: ********* epoch 22 ********* test accuracy for mode 2:0.0915 test loss: 257.943
205000: ********* epoch 22 ********* test accuracy for mode 24:0.217 test loss: 284.826
205000: ********* epoch 22 ********* test accuracy for mode 25:0.2625 test loss: 252.634
205000: ********* epoch 22 ********* test accuracy for mode 26:0.514 test loss: 156.258
205000: ********* epoch 22 ********* test accuracy for mode 27:0.272 test loss: 267.462
205000: ********* epoch 22 ********* test accuracy for mode 28:0.317 test loss: 255.842
205000: ********* epoch 22 ********* test accuracy for mode 29:0.2575 test loss: 267.189
205000: ********* epoch 22 ********* test accuracy for mode 30:0.245 test loss: 252.382
205000: ********* epoch 22 ********* test accuracy for mode 31:0.2365 test loss: 246.326
205000: ********* epoch 22 ********* test accuracy for mode 32:0.2255 test loss: 229.42
205000: ********* epoch 22 ********* test accuracy for mode 33:0.2525 test loss: 232.532
205000: ********* epoch 22 ********* test accuracy for mode 34:0.2295 test loss: 234.344
205000: ********* epoch 22 ********* test accuracy for mode 35:0.1065 test loss: 470.937
205000: ********* epoch 22 ********* test accuracy for mode 36:0.2685 test loss: 498.46
205010: accuracy:0.43 loss: 191.875 (lr:0.0001)
205020: accuracy:0.32 loss: 221.163 (lr:0.0001)
205030: accuracy:0.4 loss: 188.377 (lr:0.0001)
205040: accuracy:0.36 loss: 191.203 (lr:0.0001)
205050: accuracy:0.33 loss: 193.538 (lr:0.0001)
205060: accuracy:0.38 loss: 191.079 (lr:0.0001)
205070: accuracy:0.4 loss: 196.98 (lr:0.0001)
205080: accuracy:0.38 loss: 199.425 (lr:0.0001)
205090: accuracy:0.49 loss: 185.474 (lr:0.0001)
205100: accuracy:0.36 loss: 187.921 (lr:0.0001)
205110: accuracy:0.39 loss: 193.328 (lr:0.0001)
205120: accuracy:0.38 loss: 190.153 (lr:0.0001)
205130: accuracy:0.38 loss: 178.892 (lr:0.0001)
205140: accuracy:0.4 loss: 192.45 (lr:0.0001)
205150: accuracy:0.53 loss: 160.704 (lr:0.0001)
205160: accuracy:0.34 loss: 206.085 (lr:0.0001)
205170: accuracy:0.38 loss: 184.413 (lr:0.0001)
205180: accuracy:0.3 loss: 215.881 (lr:0.0001)
205190: accuracy:0.41 loss: 180.432 (lr:0.0001)
205200: accuracy:0.38 loss: 187.926 (lr:0.0001)
205210: accuracy:0.41 loss: 181.8 (lr:0.0001)
205220: accuracy:0.33 loss: 199.602 (lr:0.0001)
205230: accuracy:0.33 loss: 206.192 (lr:0.0001)
205240: accuracy:0.44 loss: 191.788 (lr:0.0001)
205250: accuracy:0.36 loss: 166.35 (lr:0.0001)
205260: accuracy:0.47 loss: 165.707 (lr:0.0001)
205270: accuracy:0.28 loss: 222.496 (lr:0.0001)
205280: accuracy:0.32 loss: 194.011 (lr:0.0001)
205290: accuracy:0.41 loss: 202.709 (lr:0.0001)
205300: accuracy:0.34 loss: 201.78 (lr:0.0001)
205310: accuracy:0.46 loss: 154.583 (lr:0.0001)
205320: accuracy:0.32 loss: 217.976 (lr:0.0001)
205330: accuracy:0.45 loss: 196.794 (lr:0.0001)
205340: accuracy:0.48 loss: 177.582 (lr:0.0001)
205350: accuracy:0.35 loss: 208.043 (lr:0.0001)
205360: accuracy:0.45 loss: 182.231 (lr:0.0001)
205370: accuracy:0.39 loss: 186.911 (lr:0.0001)
205380: accuracy:0.43 loss: 173.541 (lr:0.0001)
205390: accuracy:0.37 loss: 183.543 (lr:0.0001)
205400: accuracy:0.33 loss: 197.96 (lr:0.0001)
205410: accuracy:0.34 loss: 196.066 (lr:0.0001)
205420: accuracy:0.31 loss: 200.312 (lr:0.0001)
205430: accuracy:0.35 loss: 221.095 (lr:0.0001)
205440: accuracy:0.45 loss: 182.636 (lr:0.0001)
205450: accuracy:0.37 loss: 207.468 (lr:0.0001)
205460: accuracy:0.4 loss: 200.67 (lr:0.0001)
205470: accuracy:0.43 loss: 196.034 (lr:0.0001)
205480: accuracy:0.38 loss: 185.196 (lr:0.0001)
205490: accuracy:0.39 loss: 195.551 (lr:0.0001)
205500: accuracy:0.42 loss: 187.904 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
205500: ********* epoch 22 ********* test accuracy for all:0.260824 test loss: 263.441
205500: ********* epoch 22 ********* test accuracy for mode 0:0.0405 test loss: 509.538
205500: ********* epoch 22 ********* test accuracy for mode 1:0.0275 test loss: 488.643
205500: ********* epoch 22 ********* test accuracy for mode 2:0.091 test loss: 256.756
205500: ********* epoch 22 ********* test accuracy for mode 24:0.267 test loss: 277.487
205500: ********* epoch 22 ********* test accuracy for mode 25:0.2755 test loss: 247.546
205500: ********* epoch 22 ********* test accuracy for mode 26:0.484 test loss: 156.913
205500: ********* epoch 22 ********* test accuracy for mode 27:0.2275 test loss: 274.959
205500: ********* epoch 22 ********* test accuracy for mode 28:0.28 test loss: 268.914
205500: ********* epoch 22 ********* test accuracy for mode 29:0.2435 test loss: 276.603
205500: ********* epoch 22 ********* test accuracy for mode 30:0.2065 test loss: 262.019
205500: ********* epoch 22 ********* test accuracy for mode 31:0.2195 test loss: 255.917
205500: ********* epoch 22 ********* test accuracy for mode 32:0.2025 test loss: 237.574
205500: ********* epoch 22 ********* test accuracy for mode 33:0.248 test loss: 233.953
205500: ********* epoch 22 ********* test accuracy for mode 34:0.2415 test loss: 229.641
205500: ********* epoch 22 ********* test accuracy for mode 35:0.15 test loss: 465.021
205500: ********* epoch 22 ********* test accuracy for mode 36:0.1135 test loss: 511.686
205510: accuracy:0.33 loss: 205.321 (lr:0.0001)
205520: accuracy:0.38 loss: 189.741 (lr:0.0001)
205530: accuracy:0.44 loss: 178.219 (lr:0.0001)
205540: accuracy:0.39 loss: 193.333 (lr:0.0001)
205550: accuracy:0.38 loss: 200.465 (lr:0.0001)
205560: accuracy:0.32 loss: 212.359 (lr:0.0001)
205570: accuracy:0.35 loss: 208.875 (lr:0.0001)
205580: accuracy:0.36 loss: 191.367 (lr:0.0001)
205590: accuracy:0.42 loss: 198.911 (lr:0.0001)
205600: accuracy:0.3 loss: 207.12 (lr:0.0001)
205610: accuracy:0.31 loss: 196.834 (lr:0.0001)
205620: accuracy:0.38 loss: 187.274 (lr:0.0001)
205630: accuracy:0.42 loss: 193.546 (lr:0.0001)
205640: accuracy:0.37 loss: 200.403 (lr:0.0001)
205650: accuracy:0.39 loss: 185.658 (lr:0.0001)
205660: accuracy:0.42 loss: 182.302 (lr:0.0001)
205670: accuracy:0.36 loss: 196.077 (lr:0.0001)
205680: accuracy:0.39 loss: 203.749 (lr:0.0001)
205690: accuracy:0.36 loss: 192.614 (lr:0.0001)
205700: accuracy:0.37 loss: 202.473 (lr:0.0001)
205710: accuracy:0.38 loss: 172.716 (lr:0.0001)
205720: accuracy:0.45 loss: 176.54 (lr:0.0001)
205730: accuracy:0.33 loss: 220.576 (lr:0.0001)
205740: accuracy:0.34 loss: 192.546 (lr:0.0001)
205750: accuracy:0.39 loss: 195.386 (lr:0.0001)
205760: accuracy:0.39 loss: 186.98 (lr:0.0001)
205770: accuracy:0.38 loss: 193.781 (lr:0.0001)
205780: accuracy:0.32 loss: 207.773 (lr:0.0001)
205790: accuracy:0.44 loss: 187.138 (lr:0.0001)
205800: accuracy:0.43 loss: 177.282 (lr:0.0001)
205810: accuracy:0.45 loss: 199.952 (lr:0.0001)
205820: accuracy:0.4 loss: 185.238 (lr:0.0001)
205830: accuracy:0.38 loss: 186.722 (lr:0.0001)
205840: accuracy:0.45 loss: 165.923 (lr:0.0001)
205850: accuracy:0.45 loss: 172.566 (lr:0.0001)
205860: accuracy:0.41 loss: 180.397 (lr:0.0001)
205870: accuracy:0.43 loss: 191.979 (lr:0.0001)
205880: accuracy:0.38 loss: 189.826 (lr:0.0001)
205890: accuracy:0.3 loss: 205.314 (lr:0.0001)
205900: accuracy:0.36 loss: 190.692 (lr:0.0001)
205910: accuracy:0.41 loss: 184.149 (lr:0.0001)
205920: accuracy:0.36 loss: 186.035 (lr:0.0001)
205930: accuracy:0.39 loss: 190.299 (lr:0.0001)
205940: accuracy:0.37 loss: 182.338 (lr:0.0001)
205950: accuracy:0.38 loss: 195.93 (lr:0.0001)
205960: accuracy:0.34 loss: 197.6 (lr:0.0001)
205970: accuracy:0.38 loss: 180.196 (lr:0.0001)
205980: accuracy:0.39 loss: 170.448 (lr:0.0001)
205990: accuracy:0.45 loss: 172.332 (lr:0.0001)
206000: accuracy:0.32 loss: 200.675 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
206000: ********* epoch 22 ********* test accuracy for all:0.260797 test loss: 262.183
206000: ********* epoch 22 ********* test accuracy for mode 0:0.035 test loss: 488.361
206000: ********* epoch 22 ********* test accuracy for mode 1:0.033 test loss: 462.543
206000: ********* epoch 22 ********* test accuracy for mode 2:0.067 test loss: 260.641
206000: ********* epoch 22 ********* test accuracy for mode 24:0.225 test loss: 280.471
206000: ********* epoch 22 ********* test accuracy for mode 25:0.3075 test loss: 238.84
206000: ********* epoch 22 ********* test accuracy for mode 26:0.429 test loss: 164.052
206000: ********* epoch 22 ********* test accuracy for mode 27:0.2415 test loss: 266.007
206000: ********* epoch 22 ********* test accuracy for mode 28:0.3105 test loss: 253.855
206000: ********* epoch 22 ********* test accuracy for mode 29:0.241 test loss: 264.935
206000: ********* epoch 22 ********* test accuracy for mode 30:0.251 test loss: 252.707
206000: ********* epoch 22 ********* test accuracy for mode 31:0.202 test loss: 253.542
206000: ********* epoch 22 ********* test accuracy for mode 32:0.2215 test loss: 229.681
206000: ********* epoch 22 ********* test accuracy for mode 33:0.275 test loss: 230.65
206000: ********* epoch 22 ********* test accuracy for mode 34:0.2605 test loss: 231.25
206000: ********* epoch 22 ********* test accuracy for mode 35:0.1615 test loss: 459.548
206000: ********* epoch 22 ********* test accuracy for mode 36:0.161 test loss: 505.116
206010: accuracy:0.36 loss: 202.951 (lr:0.0001)
206020: accuracy:0.36 loss: 220.311 (lr:0.0001)
206030: accuracy:0.41 loss: 195.448 (lr:0.0001)
206040: accuracy:0.3 loss: 207.035 (lr:0.0001)
206050: accuracy:0.43 loss: 191.773 (lr:0.0001)
206060: accuracy:0.26 loss: 204.21 (lr:0.0001)
206070: accuracy:0.39 loss: 193.041 (lr:0.0001)
206080: accuracy:0.33 loss: 191.416 (lr:0.0001)
206090: accuracy:0.33 loss: 192.023 (lr:0.0001)
206100: accuracy:0.41 loss: 190.354 (lr:0.0001)
206110: accuracy:0.37 loss: 202.755 (lr:0.0001)
206120: accuracy:0.38 loss: 184.009 (lr:0.0001)
206130: accuracy:0.47 loss: 178.47 (lr:0.0001)
206140: accuracy:0.39 loss: 185.881 (lr:0.0001)
206150: accuracy:0.4 loss: 180.064 (lr:0.0001)
206160: accuracy:0.42 loss: 171.319 (lr:0.0001)
206170: accuracy:0.42 loss: 181.088 (lr:0.0001)
206180: accuracy:0.44 loss: 178.261 (lr:0.0001)
206190: accuracy:0.32 loss: 202.21 (lr:0.0001)
206200: accuracy:0.43 loss: 193.161 (lr:0.0001)
206210: accuracy:0.38 loss: 188.465 (lr:0.0001)
206220: accuracy:0.34 loss: 203.291 (lr:0.0001)
206230: accuracy:0.51 loss: 163.021 (lr:0.0001)
206240: accuracy:0.36 loss: 195.273 (lr:0.0001)
206250: accuracy:0.31 loss: 189.501 (lr:0.0001)
206260: accuracy:0.38 loss: 193.572 (lr:0.0001)
206270: accuracy:0.43 loss: 184.547 (lr:0.0001)
206280: accuracy:0.42 loss: 187.724 (lr:0.0001)
206290: accuracy:0.31 loss: 203.929 (lr:0.0001)
206300: accuracy:0.38 loss: 181.966 (lr:0.0001)
206310: accuracy:0.43 loss: 188.642 (lr:0.0001)
206320: accuracy:0.33 loss: 199.321 (lr:0.0001)
206330: accuracy:0.39 loss: 198.081 (lr:0.0001)
206340: accuracy:0.36 loss: 189.004 (lr:0.0001)
206350: accuracy:0.36 loss: 203.757 (lr:0.0001)
206360: accuracy:0.32 loss: 190.766 (lr:0.0001)
206370: accuracy:0.44 loss: 190.899 (lr:0.0001)
206380: accuracy:0.49 loss: 181.528 (lr:0.0001)
206390: accuracy:0.32 loss: 218.907 (lr:0.0001)
206400: accuracy:0.35 loss: 197.785 (lr:0.0001)
206410: accuracy:0.36 loss: 193.128 (lr:0.0001)
206420: accuracy:0.28 loss: 190.612 (lr:0.0001)
206430: accuracy:0.36 loss: 204.118 (lr:0.0001)
206440: accuracy:0.38 loss: 193.737 (lr:0.0001)
206450: accuracy:0.37 loss: 203.795 (lr:0.0001)
206460: accuracy:0.45 loss: 172.835 (lr:0.0001)
206470: accuracy:0.41 loss: 192.666 (lr:0.0001)
206480: accuracy:0.4 loss: 170.444 (lr:0.0001)
206490: accuracy:0.3 loss: 184.909 (lr:0.0001)
206500: accuracy:0.41 loss: 177.455 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
206500: ********* epoch 22 ********* test accuracy for all:0.260243 test loss: 266.713
206500: ********* epoch 22 ********* test accuracy for mode 0:0.04 test loss: 516.525
206500: ********* epoch 22 ********* test accuracy for mode 1:0.0245 test loss: 500.481
206500: ********* epoch 22 ********* test accuracy for mode 2:0.079 test loss: 258.476
206500: ********* epoch 22 ********* test accuracy for mode 24:0.2405 test loss: 290.615
206500: ********* epoch 22 ********* test accuracy for mode 25:0.2825 test loss: 255.845
206500: ********* epoch 22 ********* test accuracy for mode 26:0.4765 test loss: 162.306
206500: ********* epoch 22 ********* test accuracy for mode 27:0.2305 test loss: 277.664
206500: ********* epoch 22 ********* test accuracy for mode 28:0.2855 test loss: 265.762
206500: ********* epoch 22 ********* test accuracy for mode 29:0.234 test loss: 276.577
206500: ********* epoch 22 ********* test accuracy for mode 30:0.2525 test loss: 251.131
206500: ********* epoch 22 ********* test accuracy for mode 31:0.207 test loss: 249.561
206500: ********* epoch 22 ********* test accuracy for mode 32:0.231 test loss: 223.873
206500: ********* epoch 22 ********* test accuracy for mode 33:0.3195 test loss: 219.374
206500: ********* epoch 22 ********* test accuracy for mode 34:0.2355 test loss: 225.863
206500: ********* epoch 22 ********* test accuracy for mode 35:0.1135 test loss: 500.156
206500: ********* epoch 22 ********* test accuracy for mode 36:0.063 test loss: 563.195
206510: accuracy:0.42 loss: 200.466 (lr:0.0001)
206520: accuracy:0.35 loss: 191.237 (lr:0.0001)
206530: accuracy:0.35 loss: 197.523 (lr:0.0001)
206540: accuracy:0.36 loss: 167.361 (lr:0.0001)
206550: accuracy:0.37 loss: 196.434 (lr:0.0001)
206560: accuracy:0.34 loss: 196.45 (lr:0.0001)
206570: accuracy:0.36 loss: 197.496 (lr:0.0001)
206580: accuracy:0.37 loss: 194.831 (lr:0.0001)
206590: accuracy:0.35 loss: 198.268 (lr:0.0001)
206600: accuracy:0.38 loss: 203.912 (lr:0.0001)
206610: accuracy:0.35 loss: 195.468 (lr:0.0001)
206620: accuracy:0.33 loss: 198.288 (lr:0.0001)
206630: accuracy:0.42 loss: 190.064 (lr:0.0001)
206640: accuracy:0.36 loss: 198.254 (lr:0.0001)
206650: accuracy:0.33 loss: 202.441 (lr:0.0001)
206660: accuracy:0.38 loss: 185.734 (lr:0.0001)
206670: accuracy:0.32 loss: 212.47 (lr:0.0001)
206680: accuracy:0.41 loss: 191.083 (lr:0.0001)
206690: accuracy:0.27 loss: 212.929 (lr:0.0001)
206700: accuracy:0.33 loss: 187.647 (lr:0.0001)
206710: accuracy:0.41 loss: 189.055 (lr:0.0001)
206720: accuracy:0.37 loss: 209.731 (lr:0.0001)
206730: accuracy:0.3 loss: 190.497 (lr:0.0001)
206740: accuracy:0.36 loss: 188.616 (lr:0.0001)
206750: accuracy:0.46 loss: 183.039 (lr:0.0001)
206760: accuracy:0.44 loss: 196.72 (lr:0.0001)
206770: accuracy:0.36 loss: 194.187 (lr:0.0001)
206780: accuracy:0.36 loss: 224.346 (lr:0.0001)
206790: accuracy:0.34 loss: 190.698 (lr:0.0001)
206800: accuracy:0.35 loss: 194.781 (lr:0.0001)
206810: accuracy:0.38 loss: 196.712 (lr:0.0001)
206820: accuracy:0.41 loss: 190.597 (lr:0.0001)
206830: accuracy:0.42 loss: 176.977 (lr:0.0001)
206840: accuracy:0.38 loss: 194.927 (lr:0.0001)
206850: accuracy:0.41 loss: 190.709 (lr:0.0001)
206860: accuracy:0.32 loss: 193.717 (lr:0.0001)
206870: accuracy:0.42 loss: 188.838 (lr:0.0001)
206880: accuracy:0.37 loss: 202.801 (lr:0.0001)
206890: accuracy:0.4 loss: 199.542 (lr:0.0001)
206900: accuracy:0.51 loss: 164.282 (lr:0.0001)
206910: accuracy:0.41 loss: 173.54 (lr:0.0001)
206920: accuracy:0.38 loss: 198.794 (lr:0.0001)
206930: accuracy:0.36 loss: 205.836 (lr:0.0001)
206940: accuracy:0.4 loss: 180.588 (lr:0.0001)
206950: accuracy:0.28 loss: 207.91 (lr:0.0001)
206960: accuracy:0.4 loss: 194.342 (lr:0.0001)
206970: accuracy:0.35 loss: 191.791 (lr:0.0001)
206980: accuracy:0.36 loss: 191.835 (lr:0.0001)
206990: accuracy:0.4 loss: 178.81 (lr:0.0001)
207000: accuracy:0.34 loss: 212.198 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
207000: ********* epoch 22 ********* test accuracy for all:0.260635 test loss: 260.299
207000: ********* epoch 22 ********* test accuracy for mode 0:0.04 test loss: 489.94
207000: ********* epoch 22 ********* test accuracy for mode 1:0.0285 test loss: 476.082
207000: ********* epoch 22 ********* test accuracy for mode 2:0.073 test loss: 264.613
207000: ********* epoch 22 ********* test accuracy for mode 24:0.2435 test loss: 275.118
207000: ********* epoch 22 ********* test accuracy for mode 25:0.2705 test loss: 239.543
207000: ********* epoch 22 ********* test accuracy for mode 26:0.4965 test loss: 158.078
207000: ********* epoch 22 ********* test accuracy for mode 27:0.2475 test loss: 261.956
207000: ********* epoch 22 ********* test accuracy for mode 28:0.2685 test loss: 260.137
207000: ********* epoch 22 ********* test accuracy for mode 29:0.2485 test loss: 266.133
207000: ********* epoch 22 ********* test accuracy for mode 30:0.247 test loss: 248.339
207000: ********* epoch 22 ********* test accuracy for mode 31:0.2155 test loss: 250.68
207000: ********* epoch 22 ********* test accuracy for mode 32:0.212 test loss: 233.158
207000: ********* epoch 22 ********* test accuracy for mode 33:0.275 test loss: 234.626
207000: ********* epoch 22 ********* test accuracy for mode 34:0.2285 test loss: 236.552
207000: ********* epoch 22 ********* test accuracy for mode 35:0.16 test loss: 444.515
207000: ********* epoch 22 ********* test accuracy for mode 36:0.1495 test loss: 510.968
207010: accuracy:0.29 loss: 201.587 (lr:0.0001)
207020: accuracy:0.34 loss: 209.797 (lr:0.0001)
207030: accuracy:0.34 loss: 202.31 (lr:0.0001)
207040: accuracy:0.39 loss: 188.784 (lr:0.0001)
207050: accuracy:0.31 loss: 179.575 (lr:0.0001)
207060: accuracy:0.39 loss: 192.241 (lr:0.0001)
207070: accuracy:0.33 loss: 208.662 (lr:0.0001)
207080: accuracy:0.39 loss: 188.456 (lr:0.0001)
207090: accuracy:0.38 loss: 200.895 (lr:0.0001)
207100: accuracy:0.36 loss: 196.504 (lr:0.0001)
207110: accuracy:0.37 loss: 199.057 (lr:0.0001)
207120: accuracy:0.31 loss: 213.751 (lr:0.0001)
207130: accuracy:0.37 loss: 199.923 (lr:0.0001)
207140: accuracy:0.32 loss: 206.444 (lr:0.0001)
207150: accuracy:0.28 loss: 210.067 (lr:0.0001)
207160: accuracy:0.39 loss: 198.14 (lr:0.0001)
207170: accuracy:0.3 loss: 222.377 (lr:0.0001)
207180: accuracy:0.48 loss: 168.287 (lr:0.0001)
207190: accuracy:0.38 loss: 191.868 (lr:0.0001)
207200: accuracy:0.42 loss: 197.557 (lr:0.0001)
207210: accuracy:0.33 loss: 215.819 (lr:0.0001)
207220: accuracy:0.26 loss: 197.884 (lr:0.0001)
207230: accuracy:0.33 loss: 195.227 (lr:0.0001)
207240: accuracy:0.39 loss: 193.04 (lr:0.0001)
207250: accuracy:0.31 loss: 211.587 (lr:0.0001)
207260: accuracy:0.33 loss: 210.217 (lr:0.0001)
207270: accuracy:0.32 loss: 207.699 (lr:0.0001)
207280: accuracy:0.38 loss: 195.295 (lr:0.0001)
207290: accuracy:0.38 loss: 186.764 (lr:0.0001)
207300: accuracy:0.37 loss: 195.052 (lr:0.0001)
207310: accuracy:0.4 loss: 186.252 (lr:0.0001)
207320: accuracy:0.3 loss: 221.301 (lr:0.0001)
207330: accuracy:0.41 loss: 177.252 (lr:0.0001)
207340: accuracy:0.38 loss: 195.762 (lr:0.0001)
207350: accuracy:0.42 loss: 198.867 (lr:0.0001)
207360: accuracy:0.5 loss: 179.614 (lr:0.0001)
207370: accuracy:0.35 loss: 196.114 (lr:0.0001)
207380: accuracy:0.33 loss: 202.903 (lr:0.0001)
207390: accuracy:0.36 loss: 192.69 (lr:0.0001)
207400: accuracy:0.38 loss: 204.266 (lr:0.0001)
207410: accuracy:0.39 loss: 170.57 (lr:0.0001)
207420: accuracy:0.42 loss: 211.292 (lr:0.0001)
207430: accuracy:0.35 loss: 189.105 (lr:0.0001)
207440: accuracy:0.41 loss: 178.064 (lr:0.0001)
207450: accuracy:0.35 loss: 200.319 (lr:0.0001)
207460: accuracy:0.36 loss: 217.084 (lr:0.0001)
207470: accuracy:0.37 loss: 192.495 (lr:0.0001)
207480: accuracy:0.42 loss: 193.652 (lr:0.0001)
207490: accuracy:0.41 loss: 198.875 (lr:0.0001)
207500: accuracy:0.42 loss: 184.96 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
207500: ********* epoch 22 ********* test accuracy for all:0.260689 test loss: 261.035
207500: ********* epoch 22 ********* test accuracy for mode 0:0.0395 test loss: 495.079
207500: ********* epoch 22 ********* test accuracy for mode 1:0.0275 test loss: 478.903
207500: ********* epoch 22 ********* test accuracy for mode 2:0.076 test loss: 260.837
207500: ********* epoch 22 ********* test accuracy for mode 24:0.2495 test loss: 274.85
207500: ********* epoch 22 ********* test accuracy for mode 25:0.261 test loss: 249.889
207500: ********* epoch 22 ********* test accuracy for mode 26:0.471 test loss: 165.214
207500: ********* epoch 22 ********* test accuracy for mode 27:0.245 test loss: 266.931
207500: ********* epoch 22 ********* test accuracy for mode 28:0.278 test loss: 264.26
207500: ********* epoch 22 ********* test accuracy for mode 29:0.2575 test loss: 272.519
207500: ********* epoch 22 ********* test accuracy for mode 30:0.225 test loss: 263.103
207500: ********* epoch 22 ********* test accuracy for mode 31:0.1925 test loss: 261.657
207500: ********* epoch 22 ********* test accuracy for mode 32:0.1945 test loss: 238.1
207500: ********* epoch 22 ********* test accuracy for mode 33:0.25 test loss: 235.936
207500: ********* epoch 22 ********* test accuracy for mode 34:0.2665 test loss: 228.249
207500: ********* epoch 22 ********* test accuracy for mode 35:0.1455 test loss: 453.278
207500: ********* epoch 22 ********* test accuracy for mode 36:0.1765 test loss: 481.595
207510: accuracy:0.42 loss: 204.616 (lr:0.0001)
207520: accuracy:0.33 loss: 200.31 (lr:0.0001)
207530: accuracy:0.4 loss: 200.927 (lr:0.0001)
207540: accuracy:0.35 loss: 200.4 (lr:0.0001)
207550: accuracy:0.35 loss: 192.356 (lr:0.0001)
207560: accuracy:0.34 loss: 196.287 (lr:0.0001)
207570: accuracy:0.41 loss: 178.435 (lr:0.0001)
207580: accuracy:0.39 loss: 190.161 (lr:0.0001)
207590: accuracy:0.4 loss: 188.035 (lr:0.0001)
207600: accuracy:0.47 loss: 181.909 (lr:0.0001)
207610: accuracy:0.34 loss: 198.27 (lr:0.0001)
207620: accuracy:0.34 loss: 211.596 (lr:0.0001)
207630: accuracy:0.39 loss: 185.852 (lr:0.0001)
207640: accuracy:0.35 loss: 207.6 (lr:0.0001)
207650: accuracy:0.45 loss: 176.259 (lr:0.0001)
207660: accuracy:0.44 loss: 180.983 (lr:0.0001)
207670: accuracy:0.4 loss: 182.608 (lr:0.0001)
207680: accuracy:0.42 loss: 178.317 (lr:0.0001)
207690: accuracy:0.45 loss: 175.6 (lr:0.0001)
207700: accuracy:0.38 loss: 191.204 (lr:0.0001)
207710: accuracy:0.4 loss: 191.9 (lr:0.0001)
207720: accuracy:0.39 loss: 190.161 (lr:0.0001)
207730: accuracy:0.37 loss: 202.662 (lr:0.0001)
207740: accuracy:0.38 loss: 199.24 (lr:0.0001)
207750: accuracy:0.27 loss: 205.486 (lr:0.0001)
207760: accuracy:0.46 loss: 179.017 (lr:0.0001)
207770: accuracy:0.36 loss: 206.864 (lr:0.0001)
207780: accuracy:0.54 loss: 184.477 (lr:0.0001)
207790: accuracy:0.36 loss: 201.712 (lr:0.0001)
207800: accuracy:0.34 loss: 195.173 (lr:0.0001)
207810: accuracy:0.41 loss: 176.957 (lr:0.0001)
207820: accuracy:0.34 loss: 184.642 (lr:0.0001)
207830: accuracy:0.36 loss: 198.816 (lr:0.0001)
207840: accuracy:0.44 loss: 196.954 (lr:0.0001)
207850: accuracy:0.38 loss: 203.514 (lr:0.0001)
207860: accuracy:0.39 loss: 193.783 (lr:0.0001)
207870: accuracy:0.34 loss: 223.855 (lr:0.0001)
207880: accuracy:0.34 loss: 206.638 (lr:0.0001)
207890: accuracy:0.29 loss: 208.609 (lr:0.0001)
207900: accuracy:0.44 loss: 188.704 (lr:0.0001)
207910: accuracy:0.38 loss: 206.591 (lr:0.0001)
207920: accuracy:0.34 loss: 201.432 (lr:0.0001)
207930: accuracy:0.32 loss: 216.551 (lr:0.0001)
207940: accuracy:0.43 loss: 196.354 (lr:0.0001)
207950: accuracy:0.36 loss: 194.764 (lr:0.0001)
207960: accuracy:0.39 loss: 199.571 (lr:0.0001)
207970: accuracy:0.35 loss: 207.257 (lr:0.0001)
207980: accuracy:0.38 loss: 211.267 (lr:0.0001)
207990: accuracy:0.46 loss: 176.967 (lr:0.0001)
208000: accuracy:0.43 loss: 181.649 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
208000: ********* epoch 22 ********* test accuracy for all:0.264676 test loss: 262.091
208000: ********* epoch 22 ********* test accuracy for mode 0:0.04 test loss: 496.227
208000: ********* epoch 22 ********* test accuracy for mode 1:0.027 test loss: 472.274
208000: ********* epoch 22 ********* test accuracy for mode 2:0.0975 test loss: 252.91
208000: ********* epoch 22 ********* test accuracy for mode 24:0.243 test loss: 283.083
208000: ********* epoch 22 ********* test accuracy for mode 25:0.2765 test loss: 256.296
208000: ********* epoch 22 ********* test accuracy for mode 26:0.4695 test loss: 166.991
208000: ********* epoch 22 ********* test accuracy for mode 27:0.25 test loss: 273.31
208000: ********* epoch 22 ********* test accuracy for mode 28:0.2735 test loss: 265.741
208000: ********* epoch 22 ********* test accuracy for mode 29:0.2685 test loss: 261.802
208000: ********* epoch 22 ********* test accuracy for mode 30:0.2475 test loss: 248.415
208000: ********* epoch 22 ********* test accuracy for mode 31:0.2045 test loss: 246.67
208000: ********* epoch 22 ********* test accuracy for mode 32:0.2215 test loss: 227.442
208000: ********* epoch 22 ********* test accuracy for mode 33:0.2615 test loss: 231.219
208000: ********* epoch 22 ********* test accuracy for mode 34:0.243 test loss: 230.089
208000: ********* epoch 22 ********* test accuracy for mode 35:0.136 test loss: 453.618
208000: ********* epoch 22 ********* test accuracy for mode 36:0.2655 test loss: 473.346
208010: accuracy:0.35 loss: 204.146 (lr:0.0001)
208020: accuracy:0.35 loss: 209.401 (lr:0.0001)
208030: accuracy:0.37 loss: 200.519 (lr:0.0001)
208040: accuracy:0.34 loss: 206.365 (lr:0.0001)
208050: accuracy:0.44 loss: 192.045 (lr:0.0001)
208060: accuracy:0.43 loss: 187.2 (lr:0.0001)
208070: accuracy:0.45 loss: 185.409 (lr:0.0001)
208080: accuracy:0.39 loss: 174.905 (lr:0.0001)
208090: accuracy:0.35 loss: 195.927 (lr:0.0001)
208100: accuracy:0.35 loss: 205.786 (lr:0.0001)
208110: accuracy:0.36 loss: 198.413 (lr:0.0001)
208120: accuracy:0.44 loss: 180.12 (lr:0.0001)
208130: accuracy:0.32 loss: 217.514 (lr:0.0001)
208140: accuracy:0.34 loss: 202.591 (lr:0.0001)
208150: accuracy:0.36 loss: 223.001 (lr:0.0001)
208160: accuracy:0.4 loss: 193.589 (lr:0.0001)
208170: accuracy:0.35 loss: 189.039 (lr:0.0001)
208180: accuracy:0.41 loss: 180.899 (lr:0.0001)
208190: accuracy:0.36 loss: 202.286 (lr:0.0001)
208200: accuracy:0.36 loss: 193.771 (lr:0.0001)
208210: accuracy:0.43 loss: 185.881 (lr:0.0001)
208220: accuracy:0.38 loss: 196.734 (lr:0.0001)
208230: accuracy:0.38 loss: 187.142 (lr:0.0001)
208240: accuracy:0.33 loss: 195.905 (lr:0.0001)
208250: accuracy:0.41 loss: 196.273 (lr:0.0001)
208260: accuracy:0.33 loss: 205.126 (lr:0.0001)
208270: accuracy:0.44 loss: 182.655 (lr:0.0001)
208280: accuracy:0.32 loss: 219.246 (lr:0.0001)
208290: accuracy:0.32 loss: 201.506 (lr:0.0001)
208300: accuracy:0.38 loss: 198.973 (lr:0.0001)
208310: accuracy:0.4 loss: 197.224 (lr:0.0001)
208320: accuracy:0.41 loss: 195.536 (lr:0.0001)
208330: accuracy:0.38 loss: 205.688 (lr:0.0001)
208340: accuracy:0.42 loss: 179.705 (lr:0.0001)
208350: accuracy:0.42 loss: 180.278 (lr:0.0001)
208360: accuracy:0.42 loss: 184.243 (lr:0.0001)
208370: accuracy:0.4 loss: 192.774 (lr:0.0001)
208380: accuracy:0.31 loss: 211.894 (lr:0.0001)
208390: accuracy:0.38 loss: 197.731 (lr:0.0001)
208400: accuracy:0.4 loss: 176.048 (lr:0.0001)
208410: accuracy:0.39 loss: 192.145 (lr:0.0001)
208420: accuracy:0.45 loss: 184.671 (lr:0.0001)
208430: accuracy:0.43 loss: 184.852 (lr:0.0001)
208440: accuracy:0.28 loss: 209.376 (lr:0.0001)
208450: accuracy:0.38 loss: 192.478 (lr:0.0001)
208460: accuracy:0.38 loss: 208.175 (lr:0.0001)
208470: accuracy:0.35 loss: 199.211 (lr:0.0001)
208480: accuracy:0.46 loss: 187.96 (lr:0.0001)
208490: accuracy:0.38 loss: 203.766 (lr:0.0001)
208500: accuracy:0.44 loss: 186.332 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
208500: ********* epoch 22 ********* test accuracy for all:0.260405 test loss: 263.31
208500: ********* epoch 22 ********* test accuracy for mode 0:0.0365 test loss: 504.093
208500: ********* epoch 22 ********* test accuracy for mode 1:0.0235 test loss: 480.985
208500: ********* epoch 22 ********* test accuracy for mode 2:0.092 test loss: 255.624
208500: ********* epoch 22 ********* test accuracy for mode 24:0.2165 test loss: 288.061
208500: ********* epoch 22 ********* test accuracy for mode 25:0.266 test loss: 245.39
208500: ********* epoch 22 ********* test accuracy for mode 26:0.4955 test loss: 163.064
208500: ********* epoch 22 ********* test accuracy for mode 27:0.2575 test loss: 254.548
208500: ********* epoch 22 ********* test accuracy for mode 28:0.322 test loss: 249.277
208500: ********* epoch 22 ********* test accuracy for mode 29:0.2505 test loss: 261.805
208500: ********* epoch 22 ********* test accuracy for mode 30:0.253 test loss: 248.201
208500: ********* epoch 22 ********* test accuracy for mode 31:0.226 test loss: 246.216
208500: ********* epoch 22 ********* test accuracy for mode 32:0.2145 test loss: 230.812
208500: ********* epoch 22 ********* test accuracy for mode 33:0.2505 test loss: 233.181
208500: ********* epoch 22 ********* test accuracy for mode 34:0.2875 test loss: 228.149
208500: ********* epoch 22 ********* test accuracy for mode 35:0.1205 test loss: 470.774
208500: ********* epoch 22 ********* test accuracy for mode 36:0.0815 test loss: 543.395
208510: accuracy:0.4 loss: 204.249 (lr:0.0001)
208520: accuracy:0.34 loss: 211.903 (lr:0.0001)
208530: accuracy:0.4 loss: 201.208 (lr:0.0001)
208540: accuracy:0.44 loss: 182.018 (lr:0.0001)
208550: accuracy:0.41 loss: 195.219 (lr:0.0001)
208560: accuracy:0.32 loss: 199.577 (lr:0.0001)
208570: accuracy:0.28 loss: 218.25 (lr:0.0001)
208580: accuracy:0.34 loss: 207.508 (lr:0.0001)
208590: accuracy:0.39 loss: 211.124 (lr:0.0001)
208600: accuracy:0.3 loss: 215.028 (lr:0.0001)
208610: accuracy:0.42 loss: 178.728 (lr:0.0001)
208620: accuracy:0.42 loss: 184.4 (lr:0.0001)
208630: accuracy:0.38 loss: 181.673 (lr:0.0001)
208640: accuracy:0.4 loss: 175.804 (lr:0.0001)
208650: accuracy:0.36 loss: 199.359 (lr:0.0001)
208660: accuracy:0.31 loss: 198.942 (lr:0.0001)
208670: accuracy:0.39 loss: 176.056 (lr:0.0001)
208680: accuracy:0.46 loss: 182.803 (lr:0.0001)
208690: accuracy:0.32 loss: 206.049 (lr:0.0001)
208700: accuracy:0.41 loss: 198.879 (lr:0.0001)
208710: accuracy:0.44 loss: 195.523 (lr:0.0001)
208720: accuracy:0.36 loss: 199.596 (lr:0.0001)
208730: accuracy:0.43 loss: 194.098 (lr:0.0001)
208740: accuracy:0.4 loss: 196.973 (lr:0.0001)
208750: accuracy:0.45 loss: 182.677 (lr:0.0001)
208760: accuracy:0.39 loss: 197.823 (lr:0.0001)
208770: accuracy:0.39 loss: 178.015 (lr:0.0001)
208780: accuracy:0.34 loss: 199.764 (lr:0.0001)
208790: accuracy:0.36 loss: 200.801 (lr:0.0001)
208800: accuracy:0.35 loss: 215.591 (lr:0.0001)
208810: accuracy:0.38 loss: 185.983 (lr:0.0001)
208820: accuracy:0.35 loss: 184.201 (lr:0.0001)
208830: accuracy:0.39 loss: 174.172 (lr:0.0001)
208840: accuracy:0.35 loss: 186.864 (lr:0.0001)
208850: accuracy:0.34 loss: 204.932 (lr:0.0001)
208860: accuracy:0.33 loss: 206.894 (lr:0.0001)
208870: accuracy:0.32 loss: 216.529 (lr:0.0001)
208880: accuracy:0.43 loss: 183.963 (lr:0.0001)
208890: accuracy:0.37 loss: 190.261 (lr:0.0001)
208900: accuracy:0.34 loss: 204.412 (lr:0.0001)
208910: accuracy:0.41 loss: 195.917 (lr:0.0001)
208920: accuracy:0.44 loss: 188.283 (lr:0.0001)
208930: accuracy:0.44 loss: 192.663 (lr:0.0001)
208940: accuracy:0.43 loss: 202.041 (lr:0.0001)
208950: accuracy:0.34 loss: 213.486 (lr:0.0001)
208960: accuracy:0.44 loss: 187.624 (lr:0.0001)
208970: accuracy:0.42 loss: 192.46 (lr:0.0001)
208980: accuracy:0.44 loss: 189.916 (lr:0.0001)
208990: accuracy:0.34 loss: 205.204 (lr:0.0001)
209000: accuracy:0.41 loss: 181.151 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
209000: ********* epoch 22 ********* test accuracy for all:0.263811 test loss: 260.922
209000: ********* epoch 22 ********* test accuracy for mode 0:0.041 test loss: 500.12
209000: ********* epoch 22 ********* test accuracy for mode 1:0.021 test loss: 481.692
209000: ********* epoch 22 ********* test accuracy for mode 2:0.096 test loss: 255.59
209000: ********* epoch 22 ********* test accuracy for mode 24:0.2395 test loss: 278.343
209000: ********* epoch 22 ********* test accuracy for mode 25:0.298 test loss: 243.987
209000: ********* epoch 22 ********* test accuracy for mode 26:0.4765 test loss: 165.745
209000: ********* epoch 22 ********* test accuracy for mode 27:0.2335 test loss: 272.869
209000: ********* epoch 22 ********* test accuracy for mode 28:0.2805 test loss: 265.91
209000: ********* epoch 22 ********* test accuracy for mode 29:0.239 test loss: 273.559
209000: ********* epoch 22 ********* test accuracy for mode 30:0.2285 test loss: 256.301
209000: ********* epoch 22 ********* test accuracy for mode 31:0.1995 test loss: 251.187
209000: ********* epoch 22 ********* test accuracy for mode 32:0.2535 test loss: 223.25
209000: ********* epoch 22 ********* test accuracy for mode 33:0.279 test loss: 229.75
209000: ********* epoch 22 ********* test accuracy for mode 34:0.237 test loss: 231.646
209000: ********* epoch 22 ********* test accuracy for mode 35:0.142 test loss: 451.723
209000: ********* epoch 22 ********* test accuracy for mode 36:0.1575 test loss: 498.643
209010: accuracy:0.38 loss: 190.676 (lr:0.0001)
209020: accuracy:0.36 loss: 209.601 (lr:0.0001)
209030: accuracy:0.44 loss: 195.14 (lr:0.0001)
209040: accuracy:0.31 loss: 197.557 (lr:0.0001)
209050: accuracy:0.26 loss: 214.602 (lr:0.0001)
209060: accuracy:0.46 loss: 185.836 (lr:0.0001)
209070: accuracy:0.39 loss: 192.979 (lr:0.0001)
209080: accuracy:0.4 loss: 192.004 (lr:0.0001)
209090: accuracy:0.36 loss: 202.17 (lr:0.0001)
209100: accuracy:0.45 loss: 181.434 (lr:0.0001)
209110: accuracy:0.38 loss: 199.913 (lr:0.0001)
209120: accuracy:0.45 loss: 155.923 (lr:0.0001)
209130: accuracy:0.42 loss: 195.636 (lr:0.0001)
209140: accuracy:0.37 loss: 198.026 (lr:0.0001)
209150: accuracy:0.42 loss: 184.925 (lr:0.0001)
209160: accuracy:0.36 loss: 209.886 (lr:0.0001)
209170: accuracy:0.37 loss: 207.609 (lr:0.0001)
209180: accuracy:0.39 loss: 193.499 (lr:0.0001)
209190: accuracy:0.39 loss: 191.541 (lr:0.0001)
209200: accuracy:0.49 loss: 167.918 (lr:0.0001)
209210: accuracy:0.45 loss: 195.88 (lr:0.0001)
209220: accuracy:0.41 loss: 190.072 (lr:0.0001)
209230: accuracy:0.27 loss: 231.207 (lr:0.0001)
209240: accuracy:0.35 loss: 218.126 (lr:0.0001)
209250: accuracy:0.38 loss: 189.263 (lr:0.0001)
209260: accuracy:0.39 loss: 181.778 (lr:0.0001)
209270: accuracy:0.27 loss: 191.24 (lr:0.0001)
209280: accuracy:0.44 loss: 195.593 (lr:0.0001)
209290: accuracy:0.44 loss: 189.567 (lr:0.0001)
209300: accuracy:0.34 loss: 208.074 (lr:0.0001)
209310: accuracy:0.53 loss: 166.28 (lr:0.0001)
209320: accuracy:0.4 loss: 187.771 (lr:0.0001)
209330: accuracy:0.41 loss: 203.108 (lr:0.0001)
209340: accuracy:0.44 loss: 203.61 (lr:0.0001)
209350: accuracy:0.36 loss: 195.384 (lr:0.0001)
209360: accuracy:0.45 loss: 186.609 (lr:0.0001)
209370: accuracy:0.34 loss: 204.285 (lr:0.0001)
209380: accuracy:0.4 loss: 207.496 (lr:0.0001)
209390: accuracy:0.39 loss: 202.465 (lr:0.0001)
209400: accuracy:0.44 loss: 173.078 (lr:0.0001)
209410: accuracy:0.39 loss: 178.937 (lr:0.0001)
209420: accuracy:0.51 loss: 170.173 (lr:0.0001)
209430: accuracy:0.36 loss: 188.825 (lr:0.0001)
209440: accuracy:0.41 loss: 199.066 (lr:0.0001)
209450: accuracy:0.31 loss: 212.739 (lr:0.0001)
209460: accuracy:0.4 loss: 175.99 (lr:0.0001)
209470: accuracy:0.41 loss: 192.073 (lr:0.0001)
209480: accuracy:0.5 loss: 163.006 (lr:0.0001)
209490: accuracy:0.41 loss: 179.326 (lr:0.0001)
209500: accuracy:0.39 loss: 182.235 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
209500: ********* epoch 22 ********* test accuracy for all:0.261338 test loss: 263.278
209500: ********* epoch 22 ********* test accuracy for mode 0:0.041 test loss: 502.734
209500: ********* epoch 22 ********* test accuracy for mode 1:0.021 test loss: 487.934
209500: ********* epoch 22 ********* test accuracy for mode 2:0.078 test loss: 257.254
209500: ********* epoch 22 ********* test accuracy for mode 24:0.25 test loss: 277.645
209500: ********* epoch 22 ********* test accuracy for mode 25:0.2755 test loss: 249.69
209500: ********* epoch 22 ********* test accuracy for mode 26:0.524 test loss: 156.914
209500: ********* epoch 22 ********* test accuracy for mode 27:0.252 test loss: 264.737
209500: ********* epoch 22 ********* test accuracy for mode 28:0.2635 test loss: 265.126
209500: ********* epoch 22 ********* test accuracy for mode 29:0.261 test loss: 268.339
209500: ********* epoch 22 ********* test accuracy for mode 30:0.229 test loss: 252.558
209500: ********* epoch 22 ********* test accuracy for mode 31:0.245 test loss: 247.065
209500: ********* epoch 22 ********* test accuracy for mode 32:0.205 test loss: 230.477
209500: ********* epoch 22 ********* test accuracy for mode 33:0.2175 test loss: 237.562
209500: ********* epoch 22 ********* test accuracy for mode 34:0.302 test loss: 228.214
209500: ********* epoch 22 ********* test accuracy for mode 35:0.106 test loss: 478.673
209500: ********* epoch 22 ********* test accuracy for mode 36:0.1415 test loss: 535.081
209510: accuracy:0.34 loss: 200.839 (lr:0.0001)
209520: accuracy:0.44 loss: 180.159 (lr:0.0001)
209530: accuracy:0.37 loss: 181.121 (lr:0.0001)
209540: accuracy:0.4 loss: 186.042 (lr:0.0001)
209550: accuracy:0.34 loss: 191.898 (lr:0.0001)
209560: accuracy:0.36 loss: 182.719 (lr:0.0001)
209570: accuracy:0.45 loss: 197.545 (lr:0.0001)
209580: accuracy:0.38 loss: 210.132 (lr:0.0001)
209590: accuracy:0.38 loss: 196.227 (lr:0.0001)
209600: accuracy:0.31 loss: 191.179 (lr:0.0001)
209610: accuracy:0.39 loss: 181.278 (lr:0.0001)
209620: accuracy:0.37 loss: 206.812 (lr:0.0001)
209630: accuracy:0.31 loss: 193.244 (lr:0.0001)
209640: accuracy:0.38 loss: 186.115 (lr:0.0001)
209650: accuracy:0.37 loss: 194.449 (lr:0.0001)
209660: accuracy:0.34 loss: 206.16 (lr:0.0001)
209670: accuracy:0.33 loss: 211.148 (lr:0.0001)
209680: accuracy:0.41 loss: 198.798 (lr:0.0001)
209690: accuracy:0.39 loss: 192.871 (lr:0.0001)
209700: accuracy:0.41 loss: 182.135 (lr:0.0001)
209710: accuracy:0.42 loss: 203.832 (lr:0.0001)
209720: accuracy:0.27 loss: 215.971 (lr:0.0001)
209730: accuracy:0.24 loss: 196.625 (lr:0.0001)
209740: accuracy:0.34 loss: 201.93 (lr:0.0001)
209750: accuracy:0.45 loss: 195.562 (lr:0.0001)
209760: accuracy:0.38 loss: 188.742 (lr:0.0001)
209770: accuracy:0.38 loss: 193.624 (lr:0.0001)
209780: accuracy:0.32 loss: 210.375 (lr:0.0001)
209790: accuracy:0.37 loss: 203.063 (lr:0.0001)
209800: accuracy:0.39 loss: 198.662 (lr:0.0001)
209810: accuracy:0.29 loss: 216.914 (lr:0.0001)
209820: accuracy:0.48 loss: 162.248 (lr:0.0001)
209830: accuracy:0.4 loss: 196.824 (lr:0.0001)
209840: accuracy:0.43 loss: 192.33 (lr:0.0001)
209850: accuracy:0.36 loss: 193.885 (lr:0.0001)
209860: accuracy:0.35 loss: 192.706 (lr:0.0001)
209870: accuracy:0.44 loss: 169.724 (lr:0.0001)
209880: accuracy:0.44 loss: 191.388 (lr:0.0001)
209890: accuracy:0.41 loss: 186.864 (lr:0.0001)
209900: accuracy:0.41 loss: 198.682 (lr:0.0001)
209910: accuracy:0.36 loss: 178.451 (lr:0.0001)
209920: accuracy:0.41 loss: 191.564 (lr:0.0001)
209930: accuracy:0.36 loss: 206.45 (lr:0.0001)
209940: accuracy:0.38 loss: 205.414 (lr:0.0001)
209950: accuracy:0.36 loss: 188.822 (lr:0.0001)
209960: accuracy:0.35 loss: 197.183 (lr:0.0001)
209970: accuracy:0.32 loss: 189.692 (lr:0.0001)
209980: accuracy:0.41 loss: 173.57 (lr:0.0001)
209990: accuracy:0.33 loss: 210.781 (lr:0.0001)
210000: accuracy:0.45 loss: 175.5 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
210000: ********* epoch 22 ********* test accuracy for all:0.258541 test loss: 265.667
210000: ********* epoch 22 ********* test accuracy for mode 0:0.0375 test loss: 513.236
210000: ********* epoch 22 ********* test accuracy for mode 1:0.0235 test loss: 500.586
210000: ********* epoch 22 ********* test accuracy for mode 2:0.0845 test loss: 253.55
210000: ********* epoch 22 ********* test accuracy for mode 24:0.229 test loss: 278.43
210000: ********* epoch 22 ********* test accuracy for mode 25:0.3085 test loss: 248.649
210000: ********* epoch 22 ********* test accuracy for mode 26:0.4845 test loss: 160.66
210000: ********* epoch 22 ********* test accuracy for mode 27:0.2485 test loss: 275.792
210000: ********* epoch 22 ********* test accuracy for mode 28:0.2585 test loss: 278.869
210000: ********* epoch 22 ********* test accuracy for mode 29:0.23 test loss: 286.931
210000: ********* epoch 22 ********* test accuracy for mode 30:0.2155 test loss: 265.896
210000: ********* epoch 22 ********* test accuracy for mode 31:0.1745 test loss: 265.434
210000: ********* epoch 22 ********* test accuracy for mode 32:0.2405 test loss: 234.488
210000: ********* epoch 22 ********* test accuracy for mode 33:0.252 test loss: 234.053
210000: ********* epoch 22 ********* test accuracy for mode 34:0.2645 test loss: 230.873
210000: ********* epoch 22 ********* test accuracy for mode 35:0.1235 test loss: 458.324
210000: ********* epoch 22 ********* test accuracy for mode 36:0.1515 test loss: 508.283
210010: accuracy:0.36 loss: 204.165 (lr:0.0001)
210020: accuracy:0.44 loss: 190.855 (lr:0.0001)
210030: accuracy:0.39 loss: 181.983 (lr:0.0001)
210040: accuracy:0.39 loss: 196.11 (lr:0.0001)
210050: accuracy:0.42 loss: 180.773 (lr:0.0001)
210060: accuracy:0.45 loss: 186.232 (lr:0.0001)
210070: accuracy:0.38 loss: 183.998 (lr:0.0001)
210080: accuracy:0.37 loss: 180.782 (lr:0.0001)
210090: accuracy:0.39 loss: 191.673 (lr:0.0001)
210100: accuracy:0.36 loss: 194.585 (lr:0.0001)
210110: accuracy:0.43 loss: 183.42 (lr:0.0001)
210120: accuracy:0.39 loss: 190.29 (lr:0.0001)
210130: accuracy:0.33 loss: 182.939 (lr:0.0001)
210140: accuracy:0.34 loss: 195.942 (lr:0.0001)
210150: accuracy:0.4 loss: 199.46 (lr:0.0001)
210160: accuracy:0.45 loss: 182.193 (lr:0.0001)
210170: accuracy:0.35 loss: 196.247 (lr:0.0001)
210180: accuracy:0.39 loss: 198.435 (lr:0.0001)
210190: accuracy:0.31 loss: 197.253 (lr:0.0001)
210200: accuracy:0.39 loss: 194.095 (lr:0.0001)
210210: accuracy:0.43 loss: 174.191 (lr:0.0001)
210220: accuracy:0.43 loss: 179.345 (lr:0.0001)
210230: accuracy:0.38 loss: 178.695 (lr:0.0001)
210240: accuracy:0.29 loss: 211.977 (lr:0.0001)
210250: accuracy:0.34 loss: 185.793 (lr:0.0001)
210260: accuracy:0.31 loss: 224.273 (lr:0.0001)
210270: accuracy:0.38 loss: 188.8 (lr:0.0001)
210280: accuracy:0.41 loss: 200.934 (lr:0.0001)
210290: accuracy:0.42 loss: 187.782 (lr:0.0001)
210300: accuracy:0.37 loss: 211.593 (lr:0.0001)
210310: accuracy:0.5 loss: 173.852 (lr:0.0001)
210320: accuracy:0.33 loss: 214.077 (lr:0.0001)
210330: accuracy:0.41 loss: 190.976 (lr:0.0001)
210340: accuracy:0.37 loss: 201.627 (lr:0.0001)
210350: accuracy:0.41 loss: 195.984 (lr:0.0001)
210360: accuracy:0.47 loss: 180.489 (lr:0.0001)
210370: accuracy:0.33 loss: 203.494 (lr:0.0001)
210380: accuracy:0.42 loss: 190.641 (lr:0.0001)
210390: accuracy:0.37 loss: 207.902 (lr:0.0001)
210400: accuracy:0.44 loss: 177.092 (lr:0.0001)
210410: accuracy:0.28 loss: 205.515 (lr:0.0001)
210420: accuracy:0.4 loss: 192.486 (lr:0.0001)
210430: accuracy:0.37 loss: 195.051 (lr:0.0001)
210440: accuracy:0.34 loss: 221.736 (lr:0.0001)
210450: accuracy:0.36 loss: 191.115 (lr:0.0001)
210460: accuracy:0.39 loss: 186.989 (lr:0.0001)
210470: accuracy:0.41 loss: 192.947 (lr:0.0001)
210480: accuracy:0.41 loss: 183.652 (lr:0.0001)
210490: accuracy:0.41 loss: 173.99 (lr:0.0001)
210500: accuracy:0.4 loss: 195.369 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
210500: ********* epoch 22 ********* test accuracy for all:0.262608 test loss: 261.992
210500: ********* epoch 22 ********* test accuracy for mode 0:0.038 test loss: 506.255
210500: ********* epoch 22 ********* test accuracy for mode 1:0.023 test loss: 482.365
210500: ********* epoch 22 ********* test accuracy for mode 2:0.074 test loss: 252.95
210500: ********* epoch 22 ********* test accuracy for mode 24:0.2255 test loss: 285.495
210500: ********* epoch 22 ********* test accuracy for mode 25:0.2865 test loss: 251.544
210500: ********* epoch 22 ********* test accuracy for mode 26:0.434 test loss: 164.254
210500: ********* epoch 22 ********* test accuracy for mode 27:0.243 test loss: 273.995
210500: ********* epoch 22 ********* test accuracy for mode 28:0.2715 test loss: 269.109
210500: ********* epoch 22 ********* test accuracy for mode 29:0.213 test loss: 276.029
210500: ********* epoch 22 ********* test accuracy for mode 30:0.265 test loss: 241.827
210500: ********* epoch 22 ********* test accuracy for mode 31:0.231 test loss: 243.52
210500: ********* epoch 22 ********* test accuracy for mode 32:0.2065 test loss: 226.671
210500: ********* epoch 22 ********* test accuracy for mode 33:0.277 test loss: 225.292
210500: ********* epoch 22 ********* test accuracy for mode 34:0.302 test loss: 221.953
210500: ********* epoch 22 ********* test accuracy for mode 35:0.156 test loss: 440.015
210500: ********* epoch 22 ********* test accuracy for mode 36:0.3655 test loss: 452.79
210510: accuracy:0.42 loss: 197.564 (lr:0.0001)
210520: accuracy:0.37 loss: 206.035 (lr:0.0001)
210530: accuracy:0.31 loss: 191.569 (lr:0.0001)
210540: accuracy:0.38 loss: 190.613 (lr:0.0001)
210550: accuracy:0.44 loss: 174.779 (lr:0.0001)
210560: accuracy:0.35 loss: 214.235 (lr:0.0001)
210570: accuracy:0.36 loss: 193.542 (lr:0.0001)
210580: accuracy:0.33 loss: 194.121 (lr:0.0001)
210590: accuracy:0.34 loss: 213.329 (lr:0.0001)
210600: accuracy:0.45 loss: 184.102 (lr:0.0001)
210610: accuracy:0.43 loss: 180.67 (lr:0.0001)
210620: accuracy:0.28 loss: 206.351 (lr:0.0001)
210630: accuracy:0.36 loss: 196.179 (lr:0.0001)
210640: accuracy:0.44 loss: 197.831 (lr:0.0001)
210650: accuracy:0.38 loss: 195.041 (lr:0.0001)
210660: accuracy:0.49 loss: 193.273 (lr:0.0001)
210670: accuracy:0.4 loss: 195.25 (lr:0.0001)
210680: accuracy:0.41 loss: 190.645 (lr:0.0001)
210690: accuracy:0.45 loss: 195.498 (lr:0.0001)
210700: accuracy:0.33 loss: 199.333 (lr:0.0001)
210710: accuracy:0.47 loss: 191.016 (lr:0.0001)
210720: accuracy:0.42 loss: 192.096 (lr:0.0001)
210730: accuracy:0.37 loss: 194.842 (lr:0.0001)
210740: accuracy:0.44 loss: 181.079 (lr:0.0001)
210750: accuracy:0.33 loss: 206.001 (lr:0.0001)
210760: accuracy:0.41 loss: 200.37 (lr:0.0001)
210770: accuracy:0.37 loss: 185.712 (lr:0.0001)
210780: accuracy:0.4 loss: 189.094 (lr:0.0001)
210790: accuracy:0.34 loss: 216.394 (lr:0.0001)
210800: accuracy:0.47 loss: 189.135 (lr:0.0001)
210810: accuracy:0.42 loss: 193.041 (lr:0.0001)
210820: accuracy:0.38 loss: 188.265 (lr:0.0001)
210830: accuracy:0.37 loss: 185.194 (lr:0.0001)
210840: accuracy:0.47 loss: 173.277 (lr:0.0001)
210850: accuracy:0.44 loss: 175.683 (lr:0.0001)
210860: accuracy:0.39 loss: 201.237 (lr:0.0001)
210870: accuracy:0.42 loss: 188.018 (lr:0.0001)
210880: accuracy:0.34 loss: 180.553 (lr:0.0001)
210890: accuracy:0.33 loss: 199.33 (lr:0.0001)
210900: accuracy:0.37 loss: 192.756 (lr:0.0001)
210910: accuracy:0.38 loss: 196.25 (lr:0.0001)
210920: accuracy:0.3 loss: 197.18 (lr:0.0001)
210930: accuracy:0.3 loss: 200.403 (lr:0.0001)
210940: accuracy:0.35 loss: 187.27 (lr:0.0001)
210950: accuracy:0.42 loss: 185.258 (lr:0.0001)
210960: accuracy:0.33 loss: 194.069 (lr:0.0001)
210970: accuracy:0.43 loss: 173.944 (lr:0.0001)
210980: accuracy:0.41 loss: 170.296 (lr:0.0001)
210990: accuracy:0.39 loss: 197.281 (lr:0.0001)
211000: accuracy:0.33 loss: 197.854 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
211000: ********* epoch 22 ********* test accuracy for all:0.265351 test loss: 260.726
211000: ********* epoch 22 ********* test accuracy for mode 0:0.0405 test loss: 505.215
211000: ********* epoch 22 ********* test accuracy for mode 1:0.022 test loss: 485.267
211000: ********* epoch 22 ********* test accuracy for mode 2:0.073 test loss: 261.142
211000: ********* epoch 22 ********* test accuracy for mode 24:0.2505 test loss: 277.288
211000: ********* epoch 22 ********* test accuracy for mode 25:0.2635 test loss: 252.608
211000: ********* epoch 22 ********* test accuracy for mode 26:0.5065 test loss: 157.209
211000: ********* epoch 22 ********* test accuracy for mode 27:0.2275 test loss: 268.041
211000: ********* epoch 22 ********* test accuracy for mode 28:0.305 test loss: 255.699
211000: ********* epoch 22 ********* test accuracy for mode 29:0.254 test loss: 265.788
211000: ********* epoch 22 ********* test accuracy for mode 30:0.2375 test loss: 248.103
211000: ********* epoch 22 ********* test accuracy for mode 31:0.2425 test loss: 245.801
211000: ********* epoch 22 ********* test accuracy for mode 32:0.198 test loss: 230.747
211000: ********* epoch 22 ********* test accuracy for mode 33:0.256 test loss: 233.544
211000: ********* epoch 22 ********* test accuracy for mode 34:0.2445 test loss: 232.744
211000: ********* epoch 22 ********* test accuracy for mode 35:0.1345 test loss: 452.662
211000: ********* epoch 22 ********* test accuracy for mode 36:0.2525 test loss: 477.619
211010: accuracy:0.42 loss: 177.261 (lr:0.0001)
211020: accuracy:0.36 loss: 188.721 (lr:0.0001)
211030: accuracy:0.36 loss: 215.037 (lr:0.0001)
211040: accuracy:0.39 loss: 186.922 (lr:0.0001)
211050: accuracy:0.42 loss: 184.378 (lr:0.0001)
211060: accuracy:0.44 loss: 188.263 (lr:0.0001)
211070: accuracy:0.38 loss: 181.024 (lr:0.0001)
211080: accuracy:0.35 loss: 218.314 (lr:0.0001)
211090: accuracy:0.44 loss: 186.962 (lr:0.0001)
211100: accuracy:0.33 loss: 188.351 (lr:0.0001)
211110: accuracy:0.42 loss: 195.808 (lr:0.0001)
211120: accuracy:0.36 loss: 185.579 (lr:0.0001)
211130: accuracy:0.43 loss: 167.82 (lr:0.0001)
211140: accuracy:0.37 loss: 200.718 (lr:0.0001)
211150: accuracy:0.34 loss: 208.162 (lr:0.0001)
211160: accuracy:0.39 loss: 185.556 (lr:0.0001)
211170: accuracy:0.32 loss: 214.307 (lr:0.0001)
211180: accuracy:0.31 loss: 204.993 (lr:0.0001)
211190: accuracy:0.46 loss: 188.194 (lr:0.0001)
211200: accuracy:0.44 loss: 180.891 (lr:0.0001)
211210: accuracy:0.34 loss: 191.712 (lr:0.0001)
211220: accuracy:0.49 loss: 191.343 (lr:0.0001)
211230: accuracy:0.31 loss: 206.011 (lr:0.0001)
211240: accuracy:0.37 loss: 207.706 (lr:0.0001)
211250: accuracy:0.37 loss: 205.14 (lr:0.0001)
211260: accuracy:0.39 loss: 190.384 (lr:0.0001)
211270: accuracy:0.44 loss: 185.566 (lr:0.0001)
211280: accuracy:0.38 loss: 193.725 (lr:0.0001)
211290: accuracy:0.31 loss: 214.578 (lr:0.0001)
211300: accuracy:0.4 loss: 188.365 (lr:0.0001)
211310: accuracy:0.39 loss: 175.918 (lr:0.0001)
211320: accuracy:0.36 loss: 190.712 (lr:0.0001)
211330: accuracy:0.35 loss: 218.036 (lr:0.0001)
211340: accuracy:0.47 loss: 182.213 (lr:0.0001)
211350: accuracy:0.43 loss: 206.799 (lr:0.0001)
211360: accuracy:0.33 loss: 200.31 (lr:0.0001)
211370: accuracy:0.36 loss: 190.997 (lr:0.0001)
211380: accuracy:0.35 loss: 217.809 (lr:0.0001)
211390: accuracy:0.28 loss: 206.264 (lr:0.0001)
211400: accuracy:0.39 loss: 194.377 (lr:0.0001)
211410: accuracy:0.29 loss: 199.943 (lr:0.0001)
211420: accuracy:0.37 loss: 195.956 (lr:0.0001)
211430: accuracy:0.36 loss: 199.083 (lr:0.0001)
211440: accuracy:0.34 loss: 230.135 (lr:0.0001)
211450: accuracy:0.41 loss: 196.953 (lr:0.0001)
211460: accuracy:0.4 loss: 205.293 (lr:0.0001)
211470: accuracy:0.38 loss: 195.547 (lr:0.0001)
211480: accuracy:0.44 loss: 185.656 (lr:0.0001)
211490: accuracy:0.42 loss: 191.903 (lr:0.0001)
211500: accuracy:0.43 loss: 183.215 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
211500: ********* epoch 22 ********* test accuracy for all:0.269338 test loss: 259.538
211500: ********* epoch 22 ********* test accuracy for mode 0:0.044 test loss: 497.786
211500: ********* epoch 22 ********* test accuracy for mode 1:0.029 test loss: 479.603
211500: ********* epoch 22 ********* test accuracy for mode 2:0.0875 test loss: 255.583
211500: ********* epoch 22 ********* test accuracy for mode 24:0.267 test loss: 271.715
211500: ********* epoch 22 ********* test accuracy for mode 25:0.3015 test loss: 245.083
211500: ********* epoch 22 ********* test accuracy for mode 26:0.522 test loss: 157.621
211500: ********* epoch 22 ********* test accuracy for mode 27:0.248 test loss: 269.372
211500: ********* epoch 22 ********* test accuracy for mode 28:0.2715 test loss: 266.63
211500: ********* epoch 22 ********* test accuracy for mode 29:0.2385 test loss: 270.918
211500: ********* epoch 22 ********* test accuracy for mode 30:0.255 test loss: 250.44
211500: ********* epoch 22 ********* test accuracy for mode 31:0.207 test loss: 249.845
211500: ********* epoch 22 ********* test accuracy for mode 32:0.26 test loss: 225.081
211500: ********* epoch 22 ********* test accuracy for mode 33:0.243 test loss: 236.392
211500: ********* epoch 22 ********* test accuracy for mode 34:0.2425 test loss: 234.18
211500: ********* epoch 22 ********* test accuracy for mode 35:0.0885 test loss: 468.556
211500: ********* epoch 22 ********* test accuracy for mode 36:0.25 test loss: 487.196
211510: accuracy:0.3 loss: 207.862 (lr:0.0001)
211520: accuracy:0.43 loss: 188.196 (lr:0.0001)
211530: accuracy:0.45 loss: 184.706 (lr:0.0001)
211540: accuracy:0.38 loss: 206.273 (lr:0.0001)
211550: accuracy:0.4 loss: 184.328 (lr:0.0001)
211560: accuracy:0.35 loss: 212.413 (lr:0.0001)
211570: accuracy:0.27 loss: 206.959 (lr:0.0001)
211580: accuracy:0.38 loss: 207.883 (lr:0.0001)
211590: accuracy:0.4 loss: 199.873 (lr:0.0001)
211600: accuracy:0.51 loss: 175.022 (lr:0.0001)
211610: accuracy:0.36 loss: 188.85 (lr:0.0001)
211620: accuracy:0.45 loss: 189.489 (lr:0.0001)
211630: accuracy:0.33 loss: 206.591 (lr:0.0001)
211640: accuracy:0.4 loss: 200.858 (lr:0.0001)
211650: accuracy:0.36 loss: 180.587 (lr:0.0001)
211660: accuracy:0.36 loss: 192.947 (lr:0.0001)
211670: accuracy:0.34 loss: 192.443 (lr:0.0001)
211680: accuracy:0.35 loss: 209.049 (lr:0.0001)
211690: accuracy:0.33 loss: 201.876 (lr:0.0001)
211700: accuracy:0.35 loss: 183.486 (lr:0.0001)
211710: accuracy:0.32 loss: 202.877 (lr:0.0001)
211720: accuracy:0.42 loss: 185.48 (lr:0.0001)
211730: accuracy:0.37 loss: 194.107 (lr:0.0001)
211740: accuracy:0.41 loss: 173.821 (lr:0.0001)
211750: accuracy:0.41 loss: 204.601 (lr:0.0001)
211760: accuracy:0.35 loss: 194.192 (lr:0.0001)
211770: accuracy:0.33 loss: 193.231 (lr:0.0001)
211780: accuracy:0.37 loss: 186.749 (lr:0.0001)
211790: accuracy:0.3 loss: 197.542 (lr:0.0001)
211800: accuracy:0.35 loss: 192.647 (lr:0.0001)
211810: accuracy:0.39 loss: 180.348 (lr:0.0001)
211820: accuracy:0.38 loss: 197.737 (lr:0.0001)
211830: accuracy:0.35 loss: 192.566 (lr:0.0001)
211840: accuracy:0.3 loss: 208.03 (lr:0.0001)
211850: accuracy:0.4 loss: 198.765 (lr:0.0001)
211860: accuracy:0.32 loss: 194.137 (lr:0.0001)
211870: accuracy:0.38 loss: 176.027 (lr:0.0001)
211880: accuracy:0.33 loss: 207.531 (lr:0.0001)
211890: accuracy:0.45 loss: 181.243 (lr:0.0001)
211900: accuracy:0.4 loss: 198.41 (lr:0.0001)
211910: accuracy:0.41 loss: 191.905 (lr:0.0001)
211920: accuracy:0.37 loss: 194.28 (lr:0.0001)
211930: accuracy:0.45 loss: 167.931 (lr:0.0001)
211940: accuracy:0.39 loss: 205.532 (lr:0.0001)
211950: accuracy:0.38 loss: 198.756 (lr:0.0001)
211960: accuracy:0.31 loss: 209.114 (lr:0.0001)
211970: accuracy:0.26 loss: 240.468 (lr:0.0001)
211980: accuracy:0.37 loss: 200.376 (lr:0.0001)
211990: accuracy:0.34 loss: 193.705 (lr:0.0001)
212000: accuracy:0.36 loss: 197.517 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
212000: ********* epoch 22 ********* test accuracy for all:0.258568 test loss: 264.767
212000: ********* epoch 22 ********* test accuracy for mode 0:0.0385 test loss: 519.741
212000: ********* epoch 22 ********* test accuracy for mode 1:0.02 test loss: 498.65
212000: ********* epoch 22 ********* test accuracy for mode 2:0.114 test loss: 252.974
212000: ********* epoch 22 ********* test accuracy for mode 24:0.249 test loss: 282.504
212000: ********* epoch 22 ********* test accuracy for mode 25:0.308 test loss: 246.752
212000: ********* epoch 22 ********* test accuracy for mode 26:0.4545 test loss: 167.301
212000: ********* epoch 22 ********* test accuracy for mode 27:0.2225 test loss: 277.505
212000: ********* epoch 22 ********* test accuracy for mode 28:0.2685 test loss: 270.507
212000: ********* epoch 22 ********* test accuracy for mode 29:0.2215 test loss: 277.297
212000: ********* epoch 22 ********* test accuracy for mode 30:0.2495 test loss: 246.397
212000: ********* epoch 22 ********* test accuracy for mode 31:0.232 test loss: 245.234
212000: ********* epoch 22 ********* test accuracy for mode 32:0.2005 test loss: 229.31
212000: ********* epoch 22 ********* test accuracy for mode 33:0.2865 test loss: 228.395
212000: ********* epoch 22 ********* test accuracy for mode 34:0.204 test loss: 233.598
212000: ********* epoch 22 ********* test accuracy for mode 35:0.146 test loss: 476.735
212000: ********* epoch 22 ********* test accuracy for mode 36:0.0945 test loss: 541.053
212010: accuracy:0.4 loss: 197.82 (lr:0.0001)
212020: accuracy:0.39 loss: 204.472 (lr:0.0001)
212030: accuracy:0.36 loss: 204.769 (lr:0.0001)
212040: accuracy:0.36 loss: 190.559 (lr:0.0001)
212050: accuracy:0.49 loss: 185.895 (lr:0.0001)
212060: accuracy:0.46 loss: 184.419 (lr:0.0001)
212070: accuracy:0.41 loss: 164.264 (lr:0.0001)
212080: accuracy:0.35 loss: 208.451 (lr:0.0001)
212090: accuracy:0.42 loss: 199.641 (lr:0.0001)
212100: accuracy:0.41 loss: 200.058 (lr:0.0001)
212110: accuracy:0.34 loss: 189.946 (lr:0.0001)
212120: accuracy:0.35 loss: 186.354 (lr:0.0001)
212130: accuracy:0.29 loss: 202.702 (lr:0.0001)
212140: accuracy:0.48 loss: 177.54 (lr:0.0001)
212150: accuracy:0.33 loss: 199.032 (lr:0.0001)
212160: accuracy:0.43 loss: 180.52 (lr:0.0001)
212170: accuracy:0.35 loss: 202.011 (lr:0.0001)
212180: accuracy:0.36 loss: 200.802 (lr:0.0001)
212190: accuracy:0.43 loss: 163.36 (lr:0.0001)
212200: accuracy:0.37 loss: 205.493 (lr:0.0001)
212210: accuracy:0.33 loss: 232.373 (lr:0.0001)
212220: accuracy:0.4 loss: 187.954 (lr:0.0001)
212230: accuracy:0.37 loss: 203.486 (lr:0.0001)
212240: accuracy:0.32 loss: 223.208 (lr:0.0001)
212250: accuracy:0.26 loss: 224.984 (lr:0.0001)
212260: accuracy:0.35 loss: 191.092 (lr:0.0001)
212270: accuracy:0.46 loss: 187.48 (lr:0.0001)
212280: accuracy:0.39 loss: 200.887 (lr:0.0001)
212290: accuracy:0.38 loss: 205.445 (lr:0.0001)
212300: accuracy:0.37 loss: 197.898 (lr:0.0001)
212310: accuracy:0.39 loss: 185.671 (lr:0.0001)
212320: accuracy:0.41 loss: 178.077 (lr:0.0001)
212330: accuracy:0.4 loss: 175.573 (lr:0.0001)
212340: accuracy:0.37 loss: 205.951 (lr:0.0001)
212350: accuracy:0.44 loss: 190.28 (lr:0.0001)
212360: accuracy:0.42 loss: 183.832 (lr:0.0001)
212370: accuracy:0.4 loss: 189.666 (lr:0.0001)
212380: accuracy:0.36 loss: 214.441 (lr:0.0001)
212390: accuracy:0.46 loss: 176.253 (lr:0.0001)
212400: accuracy:0.4 loss: 192.114 (lr:0.0001)
212410: accuracy:0.33 loss: 196.557 (lr:0.0001)
212420: accuracy:0.33 loss: 196.94 (lr:0.0001)
212430: accuracy:0.44 loss: 192.29 (lr:0.0001)
212440: accuracy:0.4 loss: 211.163 (lr:0.0001)
212450: accuracy:0.37 loss: 185.826 (lr:0.0001)
212460: accuracy:0.36 loss: 199.874 (lr:0.0001)
212470: accuracy:0.39 loss: 198.447 (lr:0.0001)
212480: accuracy:0.35 loss: 197.759 (lr:0.0001)
212490: accuracy:0.36 loss: 206.421 (lr:0.0001)
212500: accuracy:0.44 loss: 197.875 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
212500: ********* epoch 22 ********* test accuracy for all:0.257838 test loss: 266.006
212500: ********* epoch 22 ********* test accuracy for mode 0:0.031 test loss: 518.884
212500: ********* epoch 22 ********* test accuracy for mode 1:0.0265 test loss: 487.652
212500: ********* epoch 22 ********* test accuracy for mode 2:0.0675 test loss: 261.314
212500: ********* epoch 22 ********* test accuracy for mode 24:0.245 test loss: 281.003
212500: ********* epoch 22 ********* test accuracy for mode 25:0.2665 test loss: 250.283
212500: ********* epoch 22 ********* test accuracy for mode 26:0.554 test loss: 156.048
212500: ********* epoch 22 ********* test accuracy for mode 27:0.2455 test loss: 262.229
212500: ********* epoch 22 ********* test accuracy for mode 28:0.31 test loss: 262.018
212500: ********* epoch 22 ********* test accuracy for mode 29:0.211 test loss: 283.071
212500: ********* epoch 22 ********* test accuracy for mode 30:0.252 test loss: 256.619
212500: ********* epoch 22 ********* test accuracy for mode 31:0.168 test loss: 262.413
212500: ********* epoch 22 ********* test accuracy for mode 32:0.2275 test loss: 237.101
212500: ********* epoch 22 ********* test accuracy for mode 33:0.2635 test loss: 237.066
212500: ********* epoch 22 ********* test accuracy for mode 34:0.247 test loss: 237.61
212500: ********* epoch 22 ********* test accuracy for mode 35:0.123 test loss: 490.444
212500: ********* epoch 22 ********* test accuracy for mode 36:0.0555 test loss: 600.932
212510: accuracy:0.46 loss: 170.101 (lr:0.0001)
212520: accuracy:0.39 loss: 197.976 (lr:0.0001)
212530: accuracy:0.39 loss: 190.49 (lr:0.0001)
212540: accuracy:0.33 loss: 211.437 (lr:0.0001)
212550: accuracy:0.35 loss: 186.11 (lr:0.0001)
212560: accuracy:0.42 loss: 166.077 (lr:0.0001)
212570: accuracy:0.42 loss: 179.721 (lr:0.0001)
212580: accuracy:0.41 loss: 182.336 (lr:0.0001)
212590: accuracy:0.31 loss: 206.463 (lr:0.0001)
212600: accuracy:0.35 loss: 207.226 (lr:0.0001)
212610: accuracy:0.38 loss: 191.595 (lr:0.0001)
212620: accuracy:0.31 loss: 199.01 (lr:0.0001)
212630: accuracy:0.44 loss: 190.721 (lr:0.0001)
212640: accuracy:0.41 loss: 182.728 (lr:0.0001)
212650: accuracy:0.34 loss: 196.382 (lr:0.0001)
212660: accuracy:0.4 loss: 204.234 (lr:0.0001)
212670: accuracy:0.44 loss: 199.332 (lr:0.0001)
212680: accuracy:0.47 loss: 199.648 (lr:0.0001)
212690: accuracy:0.34 loss: 190.272 (lr:0.0001)
212700: accuracy:0.38 loss: 194.736 (lr:0.0001)
212710: accuracy:0.4 loss: 208.115 (lr:0.0001)
212720: accuracy:0.32 loss: 193.413 (lr:0.0001)
212730: accuracy:0.41 loss: 196.379 (lr:0.0001)
212740: accuracy:0.44 loss: 185.673 (lr:0.0001)
212750: accuracy:0.38 loss: 204.267 (lr:0.0001)
212760: accuracy:0.42 loss: 191.805 (lr:0.0001)
212770: accuracy:0.36 loss: 196.604 (lr:0.0001)
212780: accuracy:0.42 loss: 188.23 (lr:0.0001)
212790: accuracy:0.35 loss: 200.471 (lr:0.0001)
212800: accuracy:0.39 loss: 195.164 (lr:0.0001)
212810: accuracy:0.42 loss: 190.541 (lr:0.0001)
212820: accuracy:0.42 loss: 200.878 (lr:0.0001)
212830: accuracy:0.35 loss: 190.611 (lr:0.0001)
212840: accuracy:0.39 loss: 208.173 (lr:0.0001)
212850: accuracy:0.29 loss: 215.213 (lr:0.0001)
212860: accuracy:0.45 loss: 182.57 (lr:0.0001)
212870: accuracy:0.43 loss: 198.933 (lr:0.0001)
212880: accuracy:0.41 loss: 192.822 (lr:0.0001)
212890: accuracy:0.46 loss: 180.165 (lr:0.0001)
212900: accuracy:0.38 loss: 191.788 (lr:0.0001)
212910: accuracy:0.27 loss: 214.295 (lr:0.0001)
212920: accuracy:0.41 loss: 184.004 (lr:0.0001)
212930: accuracy:0.49 loss: 177.239 (lr:0.0001)
212940: accuracy:0.4 loss: 215.909 (lr:0.0001)
212950: accuracy:0.49 loss: 172.772 (lr:0.0001)
212960: accuracy:0.35 loss: 213.34 (lr:0.0001)
212970: accuracy:0.4 loss: 187.231 (lr:0.0001)
212980: accuracy:0.38 loss: 185.594 (lr:0.0001)
212990: accuracy:0.48 loss: 192.933 (lr:0.0001)
213000: accuracy:0.38 loss: 205.421 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
213000: ********* epoch 22 ********* test accuracy for all:0.26027 test loss: 261.05
213000: ********* epoch 22 ********* test accuracy for mode 0:0.0355 test loss: 513.478
213000: ********* epoch 22 ********* test accuracy for mode 1:0.0245 test loss: 476.705
213000: ********* epoch 22 ********* test accuracy for mode 2:0.061 test loss: 262.888
213000: ********* epoch 22 ********* test accuracy for mode 24:0.264 test loss: 270.054
213000: ********* epoch 22 ********* test accuracy for mode 25:0.3165 test loss: 235.227
213000: ********* epoch 22 ********* test accuracy for mode 26:0.4535 test loss: 167.34
213000: ********* epoch 22 ********* test accuracy for mode 27:0.2195 test loss: 269.244
213000: ********* epoch 22 ********* test accuracy for mode 28:0.269 test loss: 267.18
213000: ********* epoch 22 ********* test accuracy for mode 29:0.234 test loss: 274.062
213000: ********* epoch 22 ********* test accuracy for mode 30:0.2155 test loss: 253.514
213000: ********* epoch 22 ********* test accuracy for mode 31:0.245 test loss: 253.117
213000: ********* epoch 22 ********* test accuracy for mode 32:0.176 test loss: 245.324
213000: ********* epoch 22 ********* test accuracy for mode 33:0.2775 test loss: 237.513
213000: ********* epoch 22 ********* test accuracy for mode 34:0.2575 test loss: 239.52
213000: ********* epoch 22 ********* test accuracy for mode 35:0.1105 test loss: 478.596
213000: ********* epoch 22 ********* test accuracy for mode 36:0.094 test loss: 534.686
213010: accuracy:0.43 loss: 185.827 (lr:0.0001)
213020: accuracy:0.39 loss: 195.227 (lr:0.0001)
213030: accuracy:0.46 loss: 173.795 (lr:0.0001)
213040: accuracy:0.47 loss: 183.124 (lr:0.0001)
213050: accuracy:0.41 loss: 198.015 (lr:0.0001)
213060: accuracy:0.51 loss: 169.744 (lr:0.0001)
213070: accuracy:0.37 loss: 203.275 (lr:0.0001)
213080: accuracy:0.33 loss: 210.984 (lr:0.0001)
213090: accuracy:0.45 loss: 187.462 (lr:0.0001)
213100: accuracy:0.38 loss: 183.851 (lr:0.0001)
213110: accuracy:0.42 loss: 175.874 (lr:0.0001)
213120: accuracy:0.38 loss: 203.864 (lr:0.0001)
213130: accuracy:0.4 loss: 179.109 (lr:0.0001)
213140: accuracy:0.38 loss: 197.671 (lr:0.0001)
213150: accuracy:0.34 loss: 208.532 (lr:0.0001)
213160: accuracy:0.37 loss: 187.136 (lr:0.0001)
213170: accuracy:0.41 loss: 194.037 (lr:0.0001)
213180: accuracy:0.42 loss: 186.173 (lr:0.0001)
213190: accuracy:0.37 loss: 196.368 (lr:0.0001)
213200: accuracy:0.45 loss: 185.787 (lr:0.0001)
213210: accuracy:0.28 loss: 201.143 (lr:0.0001)
213220: accuracy:0.39 loss: 193.547 (lr:0.0001)
213230: accuracy:0.38 loss: 183.015 (lr:0.0001)
213240: accuracy:0.44 loss: 189.67 (lr:0.0001)
213250: accuracy:0.47 loss: 179.958 (lr:0.0001)
213260: accuracy:0.36 loss: 197.27 (lr:0.0001)
213270: accuracy:0.37 loss: 188.736 (lr:0.0001)
213280: accuracy:0.37 loss: 199.184 (lr:0.0001)
213290: accuracy:0.3 loss: 222.44 (lr:0.0001)
213300: accuracy:0.36 loss: 172.483 (lr:0.0001)
213310: accuracy:0.38 loss: 181.094 (lr:0.0001)
213320: accuracy:0.34 loss: 227.937 (lr:0.0001)
213330: accuracy:0.33 loss: 195.904 (lr:0.0001)
213340: accuracy:0.41 loss: 186.43 (lr:0.0001)
213350: accuracy:0.33 loss: 198.953 (lr:0.0001)
213360: accuracy:0.41 loss: 176.131 (lr:0.0001)
213370: accuracy:0.38 loss: 188.541 (lr:0.0001)
213380: accuracy:0.46 loss: 182.321 (lr:0.0001)
213390: accuracy:0.44 loss: 187.588 (lr:0.0001)
213400: accuracy:0.4 loss: 191.922 (lr:0.0001)
213410: accuracy:0.43 loss: 178.637 (lr:0.0001)
213420: accuracy:0.34 loss: 207.585 (lr:0.0001)
213430: accuracy:0.45 loss: 181.597 (lr:0.0001)
213440: accuracy:0.35 loss: 211.546 (lr:0.0001)
213450: accuracy:0.36 loss: 181.769 (lr:0.0001)
213460: accuracy:0.38 loss: 198.626 (lr:0.0001)
213470: accuracy:0.36 loss: 186.674 (lr:0.0001)
213480: accuracy:0.34 loss: 202.218 (lr:0.0001)
213490: accuracy:0.41 loss: 189.305 (lr:0.0001)
213500: accuracy:0.39 loss: 190.349 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
213500: ********* epoch 22 ********* test accuracy for all:0.263027 test loss: 259.464
213500: ********* epoch 22 ********* test accuracy for mode 0:0.0375 test loss: 499.935
213500: ********* epoch 22 ********* test accuracy for mode 1:0.031 test loss: 474.06
213500: ********* epoch 22 ********* test accuracy for mode 2:0.077 test loss: 258.73
213500: ********* epoch 22 ********* test accuracy for mode 24:0.2315 test loss: 275.811
213500: ********* epoch 22 ********* test accuracy for mode 25:0.291 test loss: 237.253
213500: ********* epoch 22 ********* test accuracy for mode 26:0.4895 test loss: 161.143
213500: ********* epoch 22 ********* test accuracy for mode 27:0.243 test loss: 260.941
213500: ********* epoch 22 ********* test accuracy for mode 28:0.29 test loss: 258.38
213500: ********* epoch 22 ********* test accuracy for mode 29:0.234 test loss: 268.763
213500: ********* epoch 22 ********* test accuracy for mode 30:0.2455 test loss: 248.525
213500: ********* epoch 22 ********* test accuracy for mode 31:0.1905 test loss: 253.274
213500: ********* epoch 22 ********* test accuracy for mode 32:0.215 test loss: 235.312
213500: ********* epoch 22 ********* test accuracy for mode 33:0.266 test loss: 234.203
213500: ********* epoch 22 ********* test accuracy for mode 34:0.225 test loss: 235.446
213500: ********* epoch 22 ********* test accuracy for mode 35:0.1535 test loss: 439.756
213500: ********* epoch 22 ********* test accuracy for mode 36:0.0935 test loss: 510.584
213510: accuracy:0.34 loss: 207.749 (lr:0.0001)
213520: accuracy:0.45 loss: 190.329 (lr:0.0001)
213530: accuracy:0.37 loss: 194.409 (lr:0.0001)
213540: accuracy:0.37 loss: 194.089 (lr:0.0001)
213550: accuracy:0.4 loss: 182.087 (lr:0.0001)
213560: accuracy:0.41 loss: 171.61 (lr:0.0001)
213570: accuracy:0.41 loss: 182.385 (lr:0.0001)
213580: accuracy:0.35 loss: 210.129 (lr:0.0001)
213590: accuracy:0.4 loss: 204.861 (lr:0.0001)
213600: accuracy:0.34 loss: 200.114 (lr:0.0001)
213610: accuracy:0.32 loss: 194.314 (lr:0.0001)
213620: accuracy:0.29 loss: 222.73 (lr:0.0001)
213630: accuracy:0.51 loss: 171.863 (lr:0.0001)
213640: accuracy:0.39 loss: 191.625 (lr:0.0001)
213650: accuracy:0.4 loss: 178.008 (lr:0.0001)
213660: accuracy:0.39 loss: 197.205 (lr:0.0001)
213670: accuracy:0.34 loss: 203.038 (lr:0.0001)
213680: accuracy:0.36 loss: 212.195 (lr:0.0001)
213690: accuracy:0.4 loss: 187.382 (lr:0.0001)
213700: accuracy:0.43 loss: 202.428 (lr:0.0001)
213710: accuracy:0.41 loss: 196.531 (lr:0.0001)
213720: accuracy:0.37 loss: 186.891 (lr:0.0001)
213730: accuracy:0.39 loss: 193.487 (lr:0.0001)
213740: accuracy:0.36 loss: 197.102 (lr:0.0001)
213750: accuracy:0.33 loss: 199.032 (lr:0.0001)
213760: accuracy:0.37 loss: 200.308 (lr:0.0001)
213770: accuracy:0.38 loss: 196.335 (lr:0.0001)
213780: accuracy:0.38 loss: 193.85 (lr:0.0001)
213790: accuracy:0.46 loss: 185.687 (lr:0.0001)
213800: accuracy:0.42 loss: 186.387 (lr:0.0001)
213810: accuracy:0.48 loss: 175.755 (lr:0.0001)
213820: accuracy:0.25 loss: 198.151 (lr:0.0001)
213830: accuracy:0.37 loss: 185.01 (lr:0.0001)
213840: accuracy:0.41 loss: 179.207 (lr:0.0001)
213850: accuracy:0.37 loss: 193.474 (lr:0.0001)
213860: accuracy:0.37 loss: 197.634 (lr:0.0001)
213870: accuracy:0.4 loss: 208.276 (lr:0.0001)
213880: accuracy:0.38 loss: 197.891 (lr:0.0001)
213890: accuracy:0.37 loss: 184.352 (lr:0.0001)
213900: accuracy:0.36 loss: 201.019 (lr:0.0001)
213910: accuracy:0.44 loss: 173.475 (lr:0.0001)
213920: accuracy:0.33 loss: 212.589 (lr:0.0001)
213930: accuracy:0.4 loss: 181.956 (lr:0.0001)
213940: accuracy:0.41 loss: 189.595 (lr:0.0001)
213950: accuracy:0.38 loss: 197.133 (lr:0.0001)
213960: accuracy:0.32 loss: 207.966 (lr:0.0001)
213970: accuracy:0.37 loss: 185.761 (lr:0.0001)
213980: accuracy:0.37 loss: 204.035 (lr:0.0001)
213990: accuracy:0.4 loss: 175.096 (lr:0.0001)
214000: accuracy:0.29 loss: 215.75 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
214000: ********* epoch 23 ********* test accuracy for all:0.258514 test loss: 264.218
214000: ********* epoch 23 ********* test accuracy for mode 0:0.033 test loss: 521.933
214000: ********* epoch 23 ********* test accuracy for mode 1:0.0295 test loss: 492.338
214000: ********* epoch 23 ********* test accuracy for mode 2:0.0705 test loss: 262.42
214000: ********* epoch 23 ********* test accuracy for mode 24:0.247 test loss: 276.796
214000: ********* epoch 23 ********* test accuracy for mode 25:0.304 test loss: 231.682
214000: ********* epoch 23 ********* test accuracy for mode 26:0.4895 test loss: 163.823
214000: ********* epoch 23 ********* test accuracy for mode 27:0.256 test loss: 257.399
214000: ********* epoch 23 ********* test accuracy for mode 28:0.2475 test loss: 268.477
214000: ********* epoch 23 ********* test accuracy for mode 29:0.2585 test loss: 266.739
214000: ********* epoch 23 ********* test accuracy for mode 30:0.2385 test loss: 250.63
214000: ********* epoch 23 ********* test accuracy for mode 31:0.213 test loss: 253.43
214000: ********* epoch 23 ********* test accuracy for mode 32:0.208 test loss: 237.925
214000: ********* epoch 23 ********* test accuracy for mode 33:0.2955 test loss: 234.538
214000: ********* epoch 23 ********* test accuracy for mode 34:0.207 test loss: 242.029
214000: ********* epoch 23 ********* test accuracy for mode 35:0.1195 test loss: 464.318
214000: ********* epoch 23 ********* test accuracy for mode 36:0.0695 test loss: 558.084
214010: accuracy:0.36 loss: 203.055 (lr:0.0001)
214020: accuracy:0.37 loss: 183.012 (lr:0.0001)
214030: accuracy:0.4 loss: 192.688 (lr:0.0001)
214040: accuracy:0.34 loss: 198.837 (lr:0.0001)
214050: accuracy:0.33 loss: 197.795 (lr:0.0001)
214060: accuracy:0.4 loss: 176.263 (lr:0.0001)
214070: accuracy:0.46 loss: 193.522 (lr:0.0001)
214080: accuracy:0.31 loss: 197.984 (lr:0.0001)
214090: accuracy:0.34 loss: 217.902 (lr:0.0001)
214100: accuracy:0.34 loss: 189.751 (lr:0.0001)
214110: accuracy:0.39 loss: 185.449 (lr:0.0001)
214120: accuracy:0.37 loss: 207.825 (lr:0.0001)
214130: accuracy:0.32 loss: 198.773 (lr:0.0001)
214140: accuracy:0.41 loss: 187.821 (lr:0.0001)
214150: accuracy:0.37 loss: 194.651 (lr:0.0001)
214160: accuracy:0.45 loss: 182.673 (lr:0.0001)
214170: accuracy:0.48 loss: 196.083 (lr:0.0001)
214180: accuracy:0.4 loss: 180.019 (lr:0.0001)
214190: accuracy:0.54 loss: 173.328 (lr:0.0001)
214200: accuracy:0.42 loss: 191.999 (lr:0.0001)
214210: accuracy:0.35 loss: 218.062 (lr:0.0001)
214220: accuracy:0.37 loss: 208.524 (lr:0.0001)
214230: accuracy:0.41 loss: 189.936 (lr:0.0001)
214240: accuracy:0.4 loss: 184.245 (lr:0.0001)
214250: accuracy:0.34 loss: 214.982 (lr:0.0001)
214260: accuracy:0.33 loss: 199.107 (lr:0.0001)
214270: accuracy:0.43 loss: 192.827 (lr:0.0001)
214280: accuracy:0.34 loss: 205.66 (lr:0.0001)
214290: accuracy:0.41 loss: 183.868 (lr:0.0001)
214300: accuracy:0.46 loss: 171.866 (lr:0.0001)
214310: accuracy:0.33 loss: 219.042 (lr:0.0001)
214320: accuracy:0.41 loss: 173.512 (lr:0.0001)
214330: accuracy:0.44 loss: 176.289 (lr:0.0001)
214340: accuracy:0.48 loss: 202.813 (lr:0.0001)
214350: accuracy:0.43 loss: 192.484 (lr:0.0001)
214360: accuracy:0.5 loss: 165.974 (lr:0.0001)
214370: accuracy:0.42 loss: 190.56 (lr:0.0001)
214380: accuracy:0.35 loss: 192.054 (lr:0.0001)
214390: accuracy:0.36 loss: 202.207 (lr:0.0001)
214400: accuracy:0.44 loss: 180.969 (lr:0.0001)
214410: accuracy:0.45 loss: 176.432 (lr:0.0001)
214420: accuracy:0.48 loss: 186.279 (lr:0.0001)
214430: accuracy:0.3 loss: 208.801 (lr:0.0001)
214440: accuracy:0.32 loss: 195.343 (lr:0.0001)
214450: accuracy:0.45 loss: 177.311 (lr:0.0001)
214460: accuracy:0.41 loss: 192.045 (lr:0.0001)
214470: accuracy:0.38 loss: 196.239 (lr:0.0001)
214480: accuracy:0.45 loss: 196.133 (lr:0.0001)
214490: accuracy:0.43 loss: 186.447 (lr:0.0001)
214500: accuracy:0.37 loss: 187.559 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
214500: ********* epoch 23 ********* test accuracy for all:0.261514 test loss: 267.215
214500: ********* epoch 23 ********* test accuracy for mode 0:0.042 test loss: 522.478
214500: ********* epoch 23 ********* test accuracy for mode 1:0.027 test loss: 504.852
214500: ********* epoch 23 ********* test accuracy for mode 2:0.0805 test loss: 256.865
214500: ********* epoch 23 ********* test accuracy for mode 24:0.2555 test loss: 281.691
214500: ********* epoch 23 ********* test accuracy for mode 25:0.267 test loss: 256.884
214500: ********* epoch 23 ********* test accuracy for mode 26:0.45 test loss: 171.838
214500: ********* epoch 23 ********* test accuracy for mode 27:0.2305 test loss: 279.313
214500: ********* epoch 23 ********* test accuracy for mode 28:0.285 test loss: 267.181
214500: ********* epoch 23 ********* test accuracy for mode 29:0.2265 test loss: 273.629
214500: ********* epoch 23 ********* test accuracy for mode 30:0.271 test loss: 247.235
214500: ********* epoch 23 ********* test accuracy for mode 31:0.177 test loss: 251.473
214500: ********* epoch 23 ********* test accuracy for mode 32:0.2615 test loss: 227.018
214500: ********* epoch 23 ********* test accuracy for mode 33:0.28 test loss: 230.495
214500: ********* epoch 23 ********* test accuracy for mode 34:0.233 test loss: 232.004
214500: ********* epoch 23 ********* test accuracy for mode 35:0.1355 test loss: 485.859
214500: ********* epoch 23 ********* test accuracy for mode 36:0.1775 test loss: 534.824
214510: accuracy:0.41 loss: 194.701 (lr:0.0001)
214520: accuracy:0.4 loss: 200.285 (lr:0.0001)
214530: accuracy:0.35 loss: 180.726 (lr:0.0001)
214540: accuracy:0.43 loss: 173.955 (lr:0.0001)
214550: accuracy:0.42 loss: 171.655 (lr:0.0001)
214560: accuracy:0.3 loss: 204.369 (lr:0.0001)
214570: accuracy:0.37 loss: 178.613 (lr:0.0001)
214580: accuracy:0.42 loss: 184.502 (lr:0.0001)
214590: accuracy:0.33 loss: 210.359 (lr:0.0001)
214600: accuracy:0.37 loss: 201.998 (lr:0.0001)
214610: accuracy:0.36 loss: 209.361 (lr:0.0001)
214620: accuracy:0.43 loss: 178.774 (lr:0.0001)
214630: accuracy:0.45 loss: 186.733 (lr:0.0001)
214640: accuracy:0.45 loss: 180.529 (lr:0.0001)
214650: accuracy:0.28 loss: 196.947 (lr:0.0001)
214660: accuracy:0.38 loss: 178.843 (lr:0.0001)
214670: accuracy:0.43 loss: 191.016 (lr:0.0001)
214680: accuracy:0.27 loss: 223.747 (lr:0.0001)
214690: accuracy:0.38 loss: 180.853 (lr:0.0001)
214700: accuracy:0.36 loss: 195.588 (lr:0.0001)
214710: accuracy:0.45 loss: 179.861 (lr:0.0001)
214720: accuracy:0.41 loss: 187.555 (lr:0.0001)
214730: accuracy:0.47 loss: 170.544 (lr:0.0001)
214740: accuracy:0.37 loss: 197.571 (lr:0.0001)
214750: accuracy:0.33 loss: 192.651 (lr:0.0001)
214760: accuracy:0.35 loss: 183.763 (lr:0.0001)
214770: accuracy:0.4 loss: 194.501 (lr:0.0001)
214780: accuracy:0.41 loss: 195.623 (lr:0.0001)
214790: accuracy:0.3 loss: 206.95 (lr:0.0001)
214800: accuracy:0.33 loss: 186.953 (lr:0.0001)
214810: accuracy:0.48 loss: 171.358 (lr:0.0001)
214820: accuracy:0.43 loss: 185.091 (lr:0.0001)
214830: accuracy:0.45 loss: 188.698 (lr:0.0001)
214840: accuracy:0.3 loss: 222.123 (lr:0.0001)
214850: accuracy:0.34 loss: 200.621 (lr:0.0001)
214860: accuracy:0.42 loss: 182.94 (lr:0.0001)
214870: accuracy:0.44 loss: 186.995 (lr:0.0001)
214880: accuracy:0.37 loss: 195.94 (lr:0.0001)
214890: accuracy:0.4 loss: 186.168 (lr:0.0001)
214900: accuracy:0.45 loss: 172.287 (lr:0.0001)
214910: accuracy:0.33 loss: 204.911 (lr:0.0001)
214920: accuracy:0.38 loss: 195.608 (lr:0.0001)
214930: accuracy:0.44 loss: 176.906 (lr:0.0001)
214940: accuracy:0.37 loss: 207.018 (lr:0.0001)
214950: accuracy:0.35 loss: 200.128 (lr:0.0001)
214960: accuracy:0.36 loss: 204.675 (lr:0.0001)
214970: accuracy:0.34 loss: 203.452 (lr:0.0001)
214980: accuracy:0.42 loss: 194.825 (lr:0.0001)
214990: accuracy:0.35 loss: 191.243 (lr:0.0001)
215000: accuracy:0.35 loss: 196.404 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
215000: ********* epoch 23 ********* test accuracy for all:0.259608 test loss: 263.949
215000: ********* epoch 23 ********* test accuracy for mode 0:0.038 test loss: 505.573
215000: ********* epoch 23 ********* test accuracy for mode 1:0.026 test loss: 481.545
215000: ********* epoch 23 ********* test accuracy for mode 2:0.1035 test loss: 253.359
215000: ********* epoch 23 ********* test accuracy for mode 24:0.268 test loss: 275.861
215000: ********* epoch 23 ********* test accuracy for mode 25:0.245 test loss: 258.528
215000: ********* epoch 23 ********* test accuracy for mode 26:0.481 test loss: 164.86
215000: ********* epoch 23 ********* test accuracy for mode 27:0.2425 test loss: 273.517
215000: ********* epoch 23 ********* test accuracy for mode 28:0.28 test loss: 269.477
215000: ********* epoch 23 ********* test accuracy for mode 29:0.242 test loss: 277.354
215000: ********* epoch 23 ********* test accuracy for mode 30:0.239 test loss: 257.345
215000: ********* epoch 23 ********* test accuracy for mode 31:0.1905 test loss: 257.965
215000: ********* epoch 23 ********* test accuracy for mode 32:0.203 test loss: 235.999
215000: ********* epoch 23 ********* test accuracy for mode 33:0.2765 test loss: 230.61
215000: ********* epoch 23 ********* test accuracy for mode 34:0.227 test loss: 232.609
215000: ********* epoch 23 ********* test accuracy for mode 35:0.156 test loss: 465.351
215000: ********* epoch 23 ********* test accuracy for mode 36:0.107 test loss: 505.6
215010: accuracy:0.43 loss: 186.699 (lr:0.0001)
215020: accuracy:0.38 loss: 205.703 (lr:0.0001)
215030: accuracy:0.34 loss: 197.539 (lr:0.0001)
215040: accuracy:0.4 loss: 188.796 (lr:0.0001)
215050: accuracy:0.42 loss: 191.412 (lr:0.0001)
215060: accuracy:0.41 loss: 193.339 (lr:0.0001)
215070: accuracy:0.48 loss: 176.455 (lr:0.0001)
215080: accuracy:0.4 loss: 201.491 (lr:0.0001)
215090: accuracy:0.31 loss: 234.144 (lr:0.0001)
215100: accuracy:0.34 loss: 192.067 (lr:0.0001)
215110: accuracy:0.28 loss: 221.776 (lr:0.0001)
215120: accuracy:0.38 loss: 189.377 (lr:0.0001)
215130: accuracy:0.42 loss: 183.372 (lr:0.0001)
215140: accuracy:0.54 loss: 175.201 (lr:0.0001)
215150: accuracy:0.43 loss: 185.946 (lr:0.0001)
215160: accuracy:0.32 loss: 185.581 (lr:0.0001)
215170: accuracy:0.34 loss: 208.282 (lr:0.0001)
215180: accuracy:0.48 loss: 190.911 (lr:0.0001)
215190: accuracy:0.34 loss: 200.643 (lr:0.0001)
215200: accuracy:0.31 loss: 206.71 (lr:0.0001)
215210: accuracy:0.42 loss: 193.584 (lr:0.0001)
215220: accuracy:0.4 loss: 200.715 (lr:0.0001)
215230: accuracy:0.39 loss: 193.031 (lr:0.0001)
215240: accuracy:0.39 loss: 185.084 (lr:0.0001)
215250: accuracy:0.34 loss: 197.689 (lr:0.0001)
215260: accuracy:0.42 loss: 194.098 (lr:0.0001)
215270: accuracy:0.48 loss: 165.224 (lr:0.0001)
215280: accuracy:0.38 loss: 182.633 (lr:0.0001)
215290: accuracy:0.44 loss: 197.626 (lr:0.0001)
215300: accuracy:0.33 loss: 185.403 (lr:0.0001)
215310: accuracy:0.44 loss: 191.173 (lr:0.0001)
215320: accuracy:0.34 loss: 199.985 (lr:0.0001)
215330: accuracy:0.43 loss: 197.505 (lr:0.0001)
215340: accuracy:0.32 loss: 199.149 (lr:0.0001)
215350: accuracy:0.43 loss: 178.202 (lr:0.0001)
215360: accuracy:0.43 loss: 187.364 (lr:0.0001)
215370: accuracy:0.48 loss: 167.783 (lr:0.0001)
215380: accuracy:0.36 loss: 194.62 (lr:0.0001)
215390: accuracy:0.36 loss: 197.587 (lr:0.0001)
215400: accuracy:0.4 loss: 189.284 (lr:0.0001)
215410: accuracy:0.33 loss: 198.414 (lr:0.0001)
215420: accuracy:0.38 loss: 199.273 (lr:0.0001)
215430: accuracy:0.41 loss: 192.224 (lr:0.0001)
215440: accuracy:0.38 loss: 196.771 (lr:0.0001)
215450: accuracy:0.41 loss: 185.284 (lr:0.0001)
215460: accuracy:0.35 loss: 194.115 (lr:0.0001)
215470: accuracy:0.37 loss: 181.261 (lr:0.0001)
215480: accuracy:0.34 loss: 206.29 (lr:0.0001)
215490: accuracy:0.43 loss: 183.658 (lr:0.0001)
215500: accuracy:0.33 loss: 213.72 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
215500: ********* epoch 23 ********* test accuracy for all:0.264162 test loss: 263.442
215500: ********* epoch 23 ********* test accuracy for mode 0:0.0365 test loss: 518.409
215500: ********* epoch 23 ********* test accuracy for mode 1:0.0225 test loss: 487.584
215500: ********* epoch 23 ********* test accuracy for mode 2:0.08 test loss: 259.548
215500: ********* epoch 23 ********* test accuracy for mode 24:0.2355 test loss: 281.874
215500: ********* epoch 23 ********* test accuracy for mode 25:0.3 test loss: 243.212
215500: ********* epoch 23 ********* test accuracy for mode 26:0.458 test loss: 162.041
215500: ********* epoch 23 ********* test accuracy for mode 27:0.2425 test loss: 263.564
215500: ********* epoch 23 ********* test accuracy for mode 28:0.29 test loss: 261.983
215500: ********* epoch 23 ********* test accuracy for mode 29:0.2375 test loss: 275.264
215500: ********* epoch 23 ********* test accuracy for mode 30:0.252 test loss: 252.68
215500: ********* epoch 23 ********* test accuracy for mode 31:0.203 test loss: 252.819
215500: ********* epoch 23 ********* test accuracy for mode 32:0.216 test loss: 229.71
215500: ********* epoch 23 ********* test accuracy for mode 33:0.302 test loss: 224.529
215500: ********* epoch 23 ********* test accuracy for mode 34:0.2595 test loss: 227.699
215500: ********* epoch 23 ********* test accuracy for mode 35:0.1515 test loss: 470.01
215500: ********* epoch 23 ********* test accuracy for mode 36:0.2415 test loss: 502.616
215510: accuracy:0.48 loss: 169.987 (lr:0.0001)
215520: accuracy:0.3 loss: 212.603 (lr:0.0001)
215530: accuracy:0.4 loss: 174.334 (lr:0.0001)
215540: accuracy:0.38 loss: 199.17 (lr:0.0001)
215550: accuracy:0.42 loss: 193.889 (lr:0.0001)
215560: accuracy:0.32 loss: 216.964 (lr:0.0001)
215570: accuracy:0.4 loss: 191.28 (lr:0.0001)
215580: accuracy:0.34 loss: 210.346 (lr:0.0001)
215590: accuracy:0.33 loss: 201.62 (lr:0.0001)
215600: accuracy:0.32 loss: 221.368 (lr:0.0001)
215610: accuracy:0.37 loss: 188.232 (lr:0.0001)
215620: accuracy:0.35 loss: 206.159 (lr:0.0001)
215630: accuracy:0.38 loss: 183.295 (lr:0.0001)
215640: accuracy:0.53 loss: 174.887 (lr:0.0001)
215650: accuracy:0.36 loss: 201.176 (lr:0.0001)
215660: accuracy:0.43 loss: 184.257 (lr:0.0001)
215670: accuracy:0.38 loss: 200.189 (lr:0.0001)
215680: accuracy:0.45 loss: 194.419 (lr:0.0001)
215690: accuracy:0.41 loss: 164.309 (lr:0.0001)
215700: accuracy:0.34 loss: 199.665 (lr:0.0001)
215710: accuracy:0.32 loss: 190.816 (lr:0.0001)
215720: accuracy:0.33 loss: 199.985 (lr:0.0001)
215730: accuracy:0.28 loss: 204.322 (lr:0.0001)
215740: accuracy:0.43 loss: 185.831 (lr:0.0001)
215750: accuracy:0.35 loss: 227.721 (lr:0.0001)
215760: accuracy:0.38 loss: 192.282 (lr:0.0001)
215770: accuracy:0.37 loss: 203.188 (lr:0.0001)
215780: accuracy:0.39 loss: 201.763 (lr:0.0001)
215790: accuracy:0.39 loss: 188.221 (lr:0.0001)
215800: accuracy:0.44 loss: 186.109 (lr:0.0001)
215810: accuracy:0.43 loss: 188.332 (lr:0.0001)
215820: accuracy:0.41 loss: 191.633 (lr:0.0001)
215830: accuracy:0.5 loss: 179.722 (lr:0.0001)
215840: accuracy:0.3 loss: 198.779 (lr:0.0001)
215850: accuracy:0.4 loss: 201.017 (lr:0.0001)
215860: accuracy:0.32 loss: 220.109 (lr:0.0001)
215870: accuracy:0.39 loss: 197.997 (lr:0.0001)
215880: accuracy:0.38 loss: 193.965 (lr:0.0001)
215890: accuracy:0.39 loss: 188.054 (lr:0.0001)
215900: accuracy:0.41 loss: 185.352 (lr:0.0001)
215910: accuracy:0.31 loss: 201.362 (lr:0.0001)
215920: accuracy:0.47 loss: 178.324 (lr:0.0001)
215930: accuracy:0.45 loss: 185.204 (lr:0.0001)
215940: accuracy:0.38 loss: 196.747 (lr:0.0001)
215950: accuracy:0.31 loss: 189.728 (lr:0.0001)
215960: accuracy:0.41 loss: 168.13 (lr:0.0001)
215970: accuracy:0.45 loss: 184.981 (lr:0.0001)
215980: accuracy:0.43 loss: 183.829 (lr:0.0001)
215990: accuracy:0.43 loss: 176.256 (lr:0.0001)
216000: accuracy:0.41 loss: 202.808 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
216000: ********* epoch 23 ********* test accuracy for all:0.258527 test loss: 263.267
216000: ********* epoch 23 ********* test accuracy for mode 0:0.039 test loss: 511.433
216000: ********* epoch 23 ********* test accuracy for mode 1:0.025 test loss: 484.739
216000: ********* epoch 23 ********* test accuracy for mode 2:0.141 test loss: 252.516
216000: ********* epoch 23 ********* test accuracy for mode 24:0.234 test loss: 275.038
216000: ********* epoch 23 ********* test accuracy for mode 25:0.256 test loss: 247.709
216000: ********* epoch 23 ********* test accuracy for mode 26:0.4605 test loss: 163.094
216000: ********* epoch 23 ********* test accuracy for mode 27:0.2165 test loss: 271.909
216000: ********* epoch 23 ********* test accuracy for mode 28:0.2705 test loss: 263.847
216000: ********* epoch 23 ********* test accuracy for mode 29:0.24 test loss: 272.959
216000: ********* epoch 23 ********* test accuracy for mode 30:0.2265 test loss: 253.074
216000: ********* epoch 23 ********* test accuracy for mode 31:0.211 test loss: 253.404
216000: ********* epoch 23 ********* test accuracy for mode 32:0.218 test loss: 234.143
216000: ********* epoch 23 ********* test accuracy for mode 33:0.2365 test loss: 237.383
216000: ********* epoch 23 ********* test accuracy for mode 34:0.215 test loss: 236.076
216000: ********* epoch 23 ********* test accuracy for mode 35:0.1895 test loss: 437.619
216000: ********* epoch 23 ********* test accuracy for mode 36:0.222 test loss: 477.234
216010: accuracy:0.47 loss: 175.704 (lr:0.0001)
216020: accuracy:0.33 loss: 201.656 (lr:0.0001)
216030: accuracy:0.36 loss: 195.253 (lr:0.0001)
216040: accuracy:0.38 loss: 206.86 (lr:0.0001)
216050: accuracy:0.34 loss: 195.056 (lr:0.0001)
216060: accuracy:0.39 loss: 209.433 (lr:0.0001)
216070: accuracy:0.39 loss: 198.425 (lr:0.0001)
216080: accuracy:0.4 loss: 186.941 (lr:0.0001)
216090: accuracy:0.36 loss: 183.557 (lr:0.0001)
216100: accuracy:0.51 loss: 159.646 (lr:0.0001)
216110: accuracy:0.38 loss: 196.031 (lr:0.0001)
216120: accuracy:0.35 loss: 201.055 (lr:0.0001)
216130: accuracy:0.44 loss: 195.859 (lr:0.0001)
216140: accuracy:0.37 loss: 195.743 (lr:0.0001)
216150: accuracy:0.45 loss: 189.553 (lr:0.0001)
216160: accuracy:0.36 loss: 179.764 (lr:0.0001)
216170: accuracy:0.42 loss: 174.975 (lr:0.0001)
216180: accuracy:0.37 loss: 186.614 (lr:0.0001)
216190: accuracy:0.44 loss: 173.744 (lr:0.0001)
216200: accuracy:0.37 loss: 201.221 (lr:0.0001)
216210: accuracy:0.45 loss: 181.465 (lr:0.0001)
216220: accuracy:0.43 loss: 172.351 (lr:0.0001)
216230: accuracy:0.33 loss: 216.45 (lr:0.0001)
216240: accuracy:0.42 loss: 196.942 (lr:0.0001)
216250: accuracy:0.43 loss: 186.566 (lr:0.0001)
216260: accuracy:0.39 loss: 182.335 (lr:0.0001)
216270: accuracy:0.48 loss: 188.591 (lr:0.0001)
216280: accuracy:0.41 loss: 179.519 (lr:0.0001)
216290: accuracy:0.35 loss: 210.157 (lr:0.0001)
216300: accuracy:0.42 loss: 210.754 (lr:0.0001)
216310: accuracy:0.44 loss: 178.805 (lr:0.0001)
216320: accuracy:0.36 loss: 201.415 (lr:0.0001)
216330: accuracy:0.43 loss: 181.645 (lr:0.0001)
216340: accuracy:0.39 loss: 190.061 (lr:0.0001)
216350: accuracy:0.44 loss: 161.318 (lr:0.0001)
216360: accuracy:0.48 loss: 187.119 (lr:0.0001)
216370: accuracy:0.38 loss: 202.535 (lr:0.0001)
216380: accuracy:0.28 loss: 190.66 (lr:0.0001)
216390: accuracy:0.34 loss: 207.662 (lr:0.0001)
216400: accuracy:0.37 loss: 199.993 (lr:0.0001)
216410: accuracy:0.46 loss: 175.196 (lr:0.0001)
216420: accuracy:0.39 loss: 191.9 (lr:0.0001)
216430: accuracy:0.4 loss: 181.633 (lr:0.0001)
216440: accuracy:0.38 loss: 190.112 (lr:0.0001)
216450: accuracy:0.33 loss: 207.215 (lr:0.0001)
216460: accuracy:0.43 loss: 180.26 (lr:0.0001)
216470: accuracy:0.4 loss: 185.323 (lr:0.0001)
216480: accuracy:0.41 loss: 182.063 (lr:0.0001)
216490: accuracy:0.44 loss: 177.992 (lr:0.0001)
216500: accuracy:0.46 loss: 181.45 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
216500: ********* epoch 23 ********* test accuracy for all:0.265432 test loss: 262.991
216500: ********* epoch 23 ********* test accuracy for mode 0:0.031 test loss: 520.288
216500: ********* epoch 23 ********* test accuracy for mode 1:0.02 test loss: 496.478
216500: ********* epoch 23 ********* test accuracy for mode 2:0.1165 test loss: 255.947
216500: ********* epoch 23 ********* test accuracy for mode 24:0.27 test loss: 266.362
216500: ********* epoch 23 ********* test accuracy for mode 25:0.3085 test loss: 239.564
216500: ********* epoch 23 ********* test accuracy for mode 26:0.5425 test loss: 155.008
216500: ********* epoch 23 ********* test accuracy for mode 27:0.252 test loss: 263.879
216500: ********* epoch 23 ********* test accuracy for mode 28:0.282 test loss: 259.227
216500: ********* epoch 23 ********* test accuracy for mode 29:0.257 test loss: 268.045
216500: ********* epoch 23 ********* test accuracy for mode 30:0.2545 test loss: 248.817
216500: ********* epoch 23 ********* test accuracy for mode 31:0.2175 test loss: 253.338
216500: ********* epoch 23 ********* test accuracy for mode 32:0.2175 test loss: 235.529
216500: ********* epoch 23 ********* test accuracy for mode 33:0.2385 test loss: 238.308
216500: ********* epoch 23 ********* test accuracy for mode 34:0.2395 test loss: 236.152
216500: ********* epoch 23 ********* test accuracy for mode 35:0.137 test loss: 480.694
216500: ********* epoch 23 ********* test accuracy for mode 36:0.1355 test loss: 537.549
216510: accuracy:0.41 loss: 192.956 (lr:0.0001)
216520: accuracy:0.39 loss: 187.09 (lr:0.0001)
216530: accuracy:0.35 loss: 194.721 (lr:0.0001)
216540: accuracy:0.39 loss: 194.273 (lr:0.0001)
216550: accuracy:0.33 loss: 217.539 (lr:0.0001)
216560: accuracy:0.4 loss: 203.672 (lr:0.0001)
216570: accuracy:0.38 loss: 205.658 (lr:0.0001)
216580: accuracy:0.4 loss: 185.199 (lr:0.0001)
216590: accuracy:0.29 loss: 204.912 (lr:0.0001)
216600: accuracy:0.37 loss: 195.56 (lr:0.0001)
216610: accuracy:0.46 loss: 183.846 (lr:0.0001)
216620: accuracy:0.37 loss: 200.458 (lr:0.0001)
216630: accuracy:0.35 loss: 201.055 (lr:0.0001)
216640: accuracy:0.43 loss: 168.921 (lr:0.0001)
216650: accuracy:0.39 loss: 176.344 (lr:0.0001)
216660: accuracy:0.4 loss: 179.339 (lr:0.0001)
216670: accuracy:0.37 loss: 212.528 (lr:0.0001)
216680: accuracy:0.36 loss: 190.512 (lr:0.0001)
216690: accuracy:0.35 loss: 195.74 (lr:0.0001)
216700: accuracy:0.3 loss: 213.704 (lr:0.0001)
216710: accuracy:0.37 loss: 181.944 (lr:0.0001)
216720: accuracy:0.36 loss: 187.988 (lr:0.0001)
216730: accuracy:0.4 loss: 194.564 (lr:0.0001)
216740: accuracy:0.31 loss: 200.847 (lr:0.0001)
216750: accuracy:0.43 loss: 194.993 (lr:0.0001)
216760: accuracy:0.39 loss: 189.342 (lr:0.0001)
216770: accuracy:0.43 loss: 187.794 (lr:0.0001)
216780: accuracy:0.33 loss: 202.355 (lr:0.0001)
216790: accuracy:0.37 loss: 201.354 (lr:0.0001)
216800: accuracy:0.44 loss: 183.47 (lr:0.0001)
216810: accuracy:0.31 loss: 197.072 (lr:0.0001)
216820: accuracy:0.34 loss: 181.859 (lr:0.0001)
216830: accuracy:0.36 loss: 204.662 (lr:0.0001)
216840: accuracy:0.37 loss: 202.564 (lr:0.0001)
216850: accuracy:0.4 loss: 188.846 (lr:0.0001)
216860: accuracy:0.39 loss: 191.694 (lr:0.0001)
216870: accuracy:0.38 loss: 195.73 (lr:0.0001)
216880: accuracy:0.38 loss: 198.516 (lr:0.0001)
216890: accuracy:0.34 loss: 179.28 (lr:0.0001)
216900: accuracy:0.44 loss: 163.075 (lr:0.0001)
216910: accuracy:0.39 loss: 193.679 (lr:0.0001)
216920: accuracy:0.38 loss: 187.761 (lr:0.0001)
216930: accuracy:0.36 loss: 183.116 (lr:0.0001)
216940: accuracy:0.49 loss: 176.517 (lr:0.0001)
216950: accuracy:0.37 loss: 188.248 (lr:0.0001)
216960: accuracy:0.43 loss: 173.813 (lr:0.0001)
216970: accuracy:0.45 loss: 192.264 (lr:0.0001)
216980: accuracy:0.37 loss: 197.814 (lr:0.0001)
216990: accuracy:0.47 loss: 185.546 (lr:0.0001)
217000: accuracy:0.39 loss: 189.918 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
217000: ********* epoch 23 ********* test accuracy for all:0.2625 test loss: 262.082
217000: ********* epoch 23 ********* test accuracy for mode 0:0.041 test loss: 493.561
217000: ********* epoch 23 ********* test accuracy for mode 1:0.0275 test loss: 471.528
217000: ********* epoch 23 ********* test accuracy for mode 2:0.1065 test loss: 260.203
217000: ********* epoch 23 ********* test accuracy for mode 24:0.247 test loss: 276.57
217000: ********* epoch 23 ********* test accuracy for mode 25:0.2645 test loss: 253.06
217000: ********* epoch 23 ********* test accuracy for mode 26:0.43 test loss: 170.115
217000: ********* epoch 23 ********* test accuracy for mode 27:0.2405 test loss: 276.678
217000: ********* epoch 23 ********* test accuracy for mode 28:0.281 test loss: 270.253
217000: ********* epoch 23 ********* test accuracy for mode 29:0.2555 test loss: 271.001
217000: ********* epoch 23 ********* test accuracy for mode 30:0.2255 test loss: 255.459
217000: ********* epoch 23 ********* test accuracy for mode 31:0.219 test loss: 254.659
217000: ********* epoch 23 ********* test accuracy for mode 32:0.2095 test loss: 236.487
217000: ********* epoch 23 ********* test accuracy for mode 33:0.2425 test loss: 238.383
217000: ********* epoch 23 ********* test accuracy for mode 34:0.2395 test loss: 235.851
217000: ********* epoch 23 ********* test accuracy for mode 35:0.1565 test loss: 442.83
217000: ********* epoch 23 ********* test accuracy for mode 36:0.2835 test loss: 466.826
217010: accuracy:0.41 loss: 197.2 (lr:0.0001)
217020: accuracy:0.39 loss: 210.583 (lr:0.0001)
217030: accuracy:0.4 loss: 200.94 (lr:0.0001)
217040: accuracy:0.28 loss: 215.915 (lr:0.0001)
217050: accuracy:0.34 loss: 206.407 (lr:0.0001)
217060: accuracy:0.36 loss: 206.814 (lr:0.0001)
217070: accuracy:0.41 loss: 195.43 (lr:0.0001)
217080: accuracy:0.39 loss: 195.32 (lr:0.0001)
217090: accuracy:0.41 loss: 185.86 (lr:0.0001)
217100: accuracy:0.42 loss: 182.364 (lr:0.0001)
217110: accuracy:0.36 loss: 180.939 (lr:0.0001)
217120: accuracy:0.34 loss: 185.078 (lr:0.0001)
217130: accuracy:0.3 loss: 206.814 (lr:0.0001)
217140: accuracy:0.36 loss: 192.702 (lr:0.0001)
217150: accuracy:0.35 loss: 192.127 (lr:0.0001)
217160: accuracy:0.42 loss: 174.55 (lr:0.0001)
217170: accuracy:0.34 loss: 194.48 (lr:0.0001)
217180: accuracy:0.38 loss: 201.974 (lr:0.0001)
217190: accuracy:0.34 loss: 215.069 (lr:0.0001)
217200: accuracy:0.38 loss: 194.438 (lr:0.0001)
217210: accuracy:0.41 loss: 188.281 (lr:0.0001)
217220: accuracy:0.39 loss: 193.008 (lr:0.0001)
217230: accuracy:0.36 loss: 181.192 (lr:0.0001)
217240: accuracy:0.43 loss: 195.39 (lr:0.0001)
217250: accuracy:0.48 loss: 165.762 (lr:0.0001)
217260: accuracy:0.39 loss: 196.115 (lr:0.0001)
217270: accuracy:0.36 loss: 193.381 (lr:0.0001)
217280: accuracy:0.42 loss: 181.805 (lr:0.0001)
217290: accuracy:0.43 loss: 184.769 (lr:0.0001)
217300: accuracy:0.38 loss: 192.901 (lr:0.0001)
217310: accuracy:0.33 loss: 188.167 (lr:0.0001)
217320: accuracy:0.37 loss: 204.356 (lr:0.0001)
217330: accuracy:0.39 loss: 200.222 (lr:0.0001)
217340: accuracy:0.38 loss: 199.041 (lr:0.0001)
217350: accuracy:0.37 loss: 196.357 (lr:0.0001)
217360: accuracy:0.45 loss: 170.785 (lr:0.0001)
217370: accuracy:0.38 loss: 216.136 (lr:0.0001)
217380: accuracy:0.41 loss: 189.073 (lr:0.0001)
217390: accuracy:0.45 loss: 161.67 (lr:0.0001)
217400: accuracy:0.42 loss: 182.556 (lr:0.0001)
217410: accuracy:0.39 loss: 181.329 (lr:0.0001)
217420: accuracy:0.35 loss: 206.959 (lr:0.0001)
217430: accuracy:0.33 loss: 191.043 (lr:0.0001)
217440: accuracy:0.36 loss: 201.773 (lr:0.0001)
217450: accuracy:0.4 loss: 187.89 (lr:0.0001)
217460: accuracy:0.41 loss: 177.691 (lr:0.0001)
217470: accuracy:0.36 loss: 194.668 (lr:0.0001)
217480: accuracy:0.36 loss: 192.931 (lr:0.0001)
217490: accuracy:0.44 loss: 190.648 (lr:0.0001)
217500: accuracy:0.34 loss: 218.752 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
217500: ********* epoch 23 ********* test accuracy for all:0.263986 test loss: 265.284
217500: ********* epoch 23 ********* test accuracy for mode 0:0.035 test loss: 514.036
217500: ********* epoch 23 ********* test accuracy for mode 1:0.025 test loss: 490.488
217500: ********* epoch 23 ********* test accuracy for mode 2:0.0795 test loss: 254.051
217500: ********* epoch 23 ********* test accuracy for mode 24:0.2405 test loss: 286.889
217500: ********* epoch 23 ********* test accuracy for mode 25:0.2655 test loss: 257.51
217500: ********* epoch 23 ********* test accuracy for mode 26:0.5045 test loss: 164.057
217500: ********* epoch 23 ********* test accuracy for mode 27:0.2385 test loss: 278.009
217500: ********* epoch 23 ********* test accuracy for mode 28:0.2845 test loss: 274.862
217500: ********* epoch 23 ********* test accuracy for mode 29:0.239 test loss: 283.576
217500: ********* epoch 23 ********* test accuracy for mode 30:0.2275 test loss: 263.968
217500: ********* epoch 23 ********* test accuracy for mode 31:0.2045 test loss: 262.255
217500: ********* epoch 23 ********* test accuracy for mode 32:0.2015 test loss: 238.641
217500: ********* epoch 23 ********* test accuracy for mode 33:0.2605 test loss: 235.544
217500: ********* epoch 23 ********* test accuracy for mode 34:0.2555 test loss: 231.87
217500: ********* epoch 23 ********* test accuracy for mode 35:0.1365 test loss: 465.599
217500: ********* epoch 23 ********* test accuracy for mode 36:0.262 test loss: 486.507
217510: accuracy:0.42 loss: 180.144 (lr:0.0001)
217520: accuracy:0.4 loss: 185.416 (lr:0.0001)
217530: accuracy:0.41 loss: 173.852 (lr:0.0001)
217540: accuracy:0.46 loss: 159.992 (lr:0.0001)
217550: accuracy:0.42 loss: 173.227 (lr:0.0001)
217560: accuracy:0.28 loss: 192.147 (lr:0.0001)
217570: accuracy:0.34 loss: 192.051 (lr:0.0001)
217580: accuracy:0.4 loss: 202.842 (lr:0.0001)
217590: accuracy:0.41 loss: 198.402 (lr:0.0001)
217600: accuracy:0.42 loss: 188.634 (lr:0.0001)
217610: accuracy:0.38 loss: 186.622 (lr:0.0001)
217620: accuracy:0.41 loss: 176.951 (lr:0.0001)
217630: accuracy:0.31 loss: 221.396 (lr:0.0001)
217640: accuracy:0.36 loss: 201.779 (lr:0.0001)
217650: accuracy:0.43 loss: 189.24 (lr:0.0001)
217660: accuracy:0.45 loss: 174.04 (lr:0.0001)
217670: accuracy:0.37 loss: 207.711 (lr:0.0001)
217680: accuracy:0.38 loss: 189.707 (lr:0.0001)
217690: accuracy:0.47 loss: 174.361 (lr:0.0001)
217700: accuracy:0.4 loss: 184.381 (lr:0.0001)
217710: accuracy:0.47 loss: 181.465 (lr:0.0001)
217720: accuracy:0.42 loss: 182.979 (lr:0.0001)
217730: accuracy:0.39 loss: 189.985 (lr:0.0001)
217740: accuracy:0.42 loss: 188.02 (lr:0.0001)
217750: accuracy:0.42 loss: 189.364 (lr:0.0001)
217760: accuracy:0.35 loss: 197.923 (lr:0.0001)
217770: accuracy:0.42 loss: 195.533 (lr:0.0001)
217780: accuracy:0.37 loss: 189.505 (lr:0.0001)
217790: accuracy:0.43 loss: 164.654 (lr:0.0001)
217800: accuracy:0.39 loss: 187.42 (lr:0.0001)
217810: accuracy:0.35 loss: 202.667 (lr:0.0001)
217820: accuracy:0.38 loss: 185.67 (lr:0.0001)
217830: accuracy:0.39 loss: 204.733 (lr:0.0001)
217840: accuracy:0.37 loss: 199.124 (lr:0.0001)
217850: accuracy:0.38 loss: 187.819 (lr:0.0001)
217860: accuracy:0.35 loss: 201.884 (lr:0.0001)
217870: accuracy:0.42 loss: 182.082 (lr:0.0001)
217880: accuracy:0.37 loss: 203.279 (lr:0.0001)
217890: accuracy:0.4 loss: 192.183 (lr:0.0001)
217900: accuracy:0.44 loss: 192.127 (lr:0.0001)
217910: accuracy:0.41 loss: 164.918 (lr:0.0001)
217920: accuracy:0.43 loss: 179.799 (lr:0.0001)
217930: accuracy:0.31 loss: 209.4 (lr:0.0001)
217940: accuracy:0.41 loss: 182.664 (lr:0.0001)
217950: accuracy:0.41 loss: 199.814 (lr:0.0001)
217960: accuracy:0.44 loss: 180.716 (lr:0.0001)
217970: accuracy:0.46 loss: 189.734 (lr:0.0001)
217980: accuracy:0.43 loss: 178.12 (lr:0.0001)
217990: accuracy:0.38 loss: 182.925 (lr:0.0001)
218000: accuracy:0.44 loss: 204.276 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
218000: ********* epoch 23 ********* test accuracy for all:0.261689 test loss: 263.015
218000: ********* epoch 23 ********* test accuracy for mode 0:0.0355 test loss: 516.325
218000: ********* epoch 23 ********* test accuracy for mode 1:0.0265 test loss: 489.826
218000: ********* epoch 23 ********* test accuracy for mode 2:0.0795 test loss: 256.739
218000: ********* epoch 23 ********* test accuracy for mode 24:0.2375 test loss: 286.285
218000: ********* epoch 23 ********* test accuracy for mode 25:0.2345 test loss: 257.116
218000: ********* epoch 23 ********* test accuracy for mode 26:0.4785 test loss: 169.162
218000: ********* epoch 23 ********* test accuracy for mode 27:0.232 test loss: 269.678
218000: ********* epoch 23 ********* test accuracy for mode 28:0.297 test loss: 256.347
218000: ********* epoch 23 ********* test accuracy for mode 29:0.2565 test loss: 261.369
218000: ********* epoch 23 ********* test accuracy for mode 30:0.264 test loss: 245.098
218000: ********* epoch 23 ********* test accuracy for mode 31:0.202 test loss: 249.788
218000: ********* epoch 23 ********* test accuracy for mode 32:0.2255 test loss: 226.264
218000: ********* epoch 23 ********* test accuracy for mode 33:0.289 test loss: 223.227
218000: ********* epoch 23 ********* test accuracy for mode 34:0.2635 test loss: 225.208
218000: ********* epoch 23 ********* test accuracy for mode 35:0.1735 test loss: 441.264
218000: ********* epoch 23 ********* test accuracy for mode 36:0.1615 test loss: 477.966
218010: accuracy:0.41 loss: 196.186 (lr:0.0001)
218020: accuracy:0.46 loss: 178.687 (lr:0.0001)
218030: accuracy:0.39 loss: 188.798 (lr:0.0001)
218040: accuracy:0.42 loss: 180.039 (lr:0.0001)
218050: accuracy:0.32 loss: 187.245 (lr:0.0001)
218060: accuracy:0.46 loss: 177.38 (lr:0.0001)
218070: accuracy:0.28 loss: 212.297 (lr:0.0001)
218080: accuracy:0.29 loss: 234.217 (lr:0.0001)
218090: accuracy:0.34 loss: 197.111 (lr:0.0001)
218100: accuracy:0.3 loss: 207.384 (lr:0.0001)
218110: accuracy:0.42 loss: 186.378 (lr:0.0001)
218120: accuracy:0.34 loss: 198.0 (lr:0.0001)
218130: accuracy:0.42 loss: 209.926 (lr:0.0001)
218140: accuracy:0.37 loss: 178.989 (lr:0.0001)
218150: accuracy:0.41 loss: 184.032 (lr:0.0001)
218160: accuracy:0.39 loss: 204.96 (lr:0.0001)
218170: accuracy:0.39 loss: 184.906 (lr:0.0001)
218180: accuracy:0.44 loss: 166.649 (lr:0.0001)
218190: accuracy:0.42 loss: 164.79 (lr:0.0001)
218200: accuracy:0.4 loss: 181.072 (lr:0.0001)
218210: accuracy:0.33 loss: 208.202 (lr:0.0001)
218220: accuracy:0.33 loss: 186.567 (lr:0.0001)
218230: accuracy:0.32 loss: 207.555 (lr:0.0001)
218240: accuracy:0.38 loss: 182.684 (lr:0.0001)
218250: accuracy:0.35 loss: 197.47 (lr:0.0001)
218260: accuracy:0.37 loss: 199.807 (lr:0.0001)
218270: accuracy:0.43 loss: 188.01 (lr:0.0001)
218280: accuracy:0.34 loss: 188.604 (lr:0.0001)
218290: accuracy:0.37 loss: 190.996 (lr:0.0001)
218300: accuracy:0.32 loss: 203.573 (lr:0.0001)
218310: accuracy:0.4 loss: 195.847 (lr:0.0001)
218320: accuracy:0.37 loss: 200.486 (lr:0.0001)
218330: accuracy:0.41 loss: 193.281 (lr:0.0001)
218340: accuracy:0.34 loss: 205.698 (lr:0.0001)
218350: accuracy:0.39 loss: 187.247 (lr:0.0001)
218360: accuracy:0.31 loss: 193.95 (lr:0.0001)
218370: accuracy:0.39 loss: 194.595 (lr:0.0001)
218380: accuracy:0.35 loss: 188.268 (lr:0.0001)
218390: accuracy:0.39 loss: 193.658 (lr:0.0001)
218400: accuracy:0.33 loss: 188.446 (lr:0.0001)
218410: accuracy:0.38 loss: 178.699 (lr:0.0001)
218420: accuracy:0.38 loss: 208.032 (lr:0.0001)
218430: accuracy:0.42 loss: 175.833 (lr:0.0001)
218440: accuracy:0.37 loss: 191.651 (lr:0.0001)
218450: accuracy:0.38 loss: 172.544 (lr:0.0001)
218460: accuracy:0.4 loss: 170.741 (lr:0.0001)
218470: accuracy:0.4 loss: 190.752 (lr:0.0001)
218480: accuracy:0.33 loss: 187.644 (lr:0.0001)
218490: accuracy:0.44 loss: 184.471 (lr:0.0001)
218500: accuracy:0.41 loss: 203.88 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
218500: ********* epoch 23 ********* test accuracy for all:0.265973 test loss: 262.618
218500: ********* epoch 23 ********* test accuracy for mode 0:0.044 test loss: 504.236
218500: ********* epoch 23 ********* test accuracy for mode 1:0.025 test loss: 481.932
218500: ********* epoch 23 ********* test accuracy for mode 2:0.105 test loss: 252.401
218500: ********* epoch 23 ********* test accuracy for mode 24:0.231 test loss: 288.505
218500: ********* epoch 23 ********* test accuracy for mode 25:0.2805 test loss: 253.491
218500: ********* epoch 23 ********* test accuracy for mode 26:0.476 test loss: 165.751
218500: ********* epoch 23 ********* test accuracy for mode 27:0.267 test loss: 269.558
218500: ********* epoch 23 ********* test accuracy for mode 28:0.2775 test loss: 269.052
218500: ********* epoch 23 ********* test accuracy for mode 29:0.2395 test loss: 271.998
218500: ********* epoch 23 ********* test accuracy for mode 30:0.246 test loss: 248.882
218500: ********* epoch 23 ********* test accuracy for mode 31:0.2215 test loss: 247.972
218500: ********* epoch 23 ********* test accuracy for mode 32:0.2115 test loss: 226.705
218500: ********* epoch 23 ********* test accuracy for mode 33:0.3315 test loss: 219.054
218500: ********* epoch 23 ********* test accuracy for mode 34:0.2355 test loss: 225.441
218500: ********* epoch 23 ********* test accuracy for mode 35:0.134 test loss: 463.658
218500: ********* epoch 23 ********* test accuracy for mode 36:0.2435 test loss: 484.157
218510: accuracy:0.37 loss: 207.265 (lr:0.0001)
218520: accuracy:0.39 loss: 182.161 (lr:0.0001)
218530: accuracy:0.48 loss: 175.785 (lr:0.0001)
218540: accuracy:0.42 loss: 173.767 (lr:0.0001)
218550: accuracy:0.48 loss: 177.726 (lr:0.0001)
218560: accuracy:0.32 loss: 197.813 (lr:0.0001)
218570: accuracy:0.38 loss: 197.262 (lr:0.0001)
218580: accuracy:0.43 loss: 190.852 (lr:0.0001)
218590: accuracy:0.36 loss: 188.872 (lr:0.0001)
218600: accuracy:0.28 loss: 217.237 (lr:0.0001)
218610: accuracy:0.34 loss: 203.397 (lr:0.0001)
218620: accuracy:0.41 loss: 184.162 (lr:0.0001)
218630: accuracy:0.4 loss: 206.26 (lr:0.0001)
218640: accuracy:0.37 loss: 177.86 (lr:0.0001)
218650: accuracy:0.41 loss: 180.211 (lr:0.0001)
218660: accuracy:0.42 loss: 183.461 (lr:0.0001)
218670: accuracy:0.41 loss: 196.352 (lr:0.0001)
218680: accuracy:0.4 loss: 188.261 (lr:0.0001)
218690: accuracy:0.42 loss: 198.443 (lr:0.0001)
218700: accuracy:0.37 loss: 197.007 (lr:0.0001)
218710: accuracy:0.41 loss: 200.912 (lr:0.0001)
218720: accuracy:0.39 loss: 184.346 (lr:0.0001)
218730: accuracy:0.44 loss: 180.079 (lr:0.0001)
218740: accuracy:0.3 loss: 213.527 (lr:0.0001)
218750: accuracy:0.49 loss: 181.488 (lr:0.0001)
218760: accuracy:0.45 loss: 171.326 (lr:0.0001)
218770: accuracy:0.36 loss: 190.371 (lr:0.0001)
218780: accuracy:0.35 loss: 184.161 (lr:0.0001)
218790: accuracy:0.4 loss: 201.456 (lr:0.0001)
218800: accuracy:0.27 loss: 208.353 (lr:0.0001)
218810: accuracy:0.43 loss: 164.385 (lr:0.0001)
218820: accuracy:0.4 loss: 188.391 (lr:0.0001)
218830: accuracy:0.35 loss: 216.024 (lr:0.0001)
218840: accuracy:0.4 loss: 183.856 (lr:0.0001)
218850: accuracy:0.37 loss: 173.932 (lr:0.0001)
218860: accuracy:0.34 loss: 210.169 (lr:0.0001)
218870: accuracy:0.35 loss: 205.962 (lr:0.0001)
218880: accuracy:0.47 loss: 198.603 (lr:0.0001)
218890: accuracy:0.28 loss: 220.557 (lr:0.0001)
218900: accuracy:0.4 loss: 200.057 (lr:0.0001)
218910: accuracy:0.53 loss: 184.303 (lr:0.0001)
218920: accuracy:0.42 loss: 182.196 (lr:0.0001)
218930: accuracy:0.41 loss: 178.557 (lr:0.0001)
218940: accuracy:0.43 loss: 174.703 (lr:0.0001)
218950: accuracy:0.29 loss: 198.846 (lr:0.0001)
218960: accuracy:0.41 loss: 174.437 (lr:0.0001)
218970: accuracy:0.41 loss: 214.04 (lr:0.0001)
218980: accuracy:0.41 loss: 193.905 (lr:0.0001)
218990: accuracy:0.38 loss: 188.288 (lr:0.0001)
219000: accuracy:0.41 loss: 189.476 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
219000: ********* epoch 23 ********* test accuracy for all:0.26173 test loss: 263.797
219000: ********* epoch 23 ********* test accuracy for mode 0:0.0345 test loss: 515.782
219000: ********* epoch 23 ********* test accuracy for mode 1:0.0235 test loss: 484.741
219000: ********* epoch 23 ********* test accuracy for mode 2:0.076 test loss: 257.992
219000: ********* epoch 23 ********* test accuracy for mode 24:0.2575 test loss: 282.336
219000: ********* epoch 23 ********* test accuracy for mode 25:0.249 test loss: 253.42
219000: ********* epoch 23 ********* test accuracy for mode 26:0.507 test loss: 163.128
219000: ********* epoch 23 ********* test accuracy for mode 27:0.27 test loss: 265.17
219000: ********* epoch 23 ********* test accuracy for mode 28:0.282 test loss: 266.933
219000: ********* epoch 23 ********* test accuracy for mode 29:0.2295 test loss: 275.237
219000: ********* epoch 23 ********* test accuracy for mode 30:0.238 test loss: 251.368
219000: ********* epoch 23 ********* test accuracy for mode 31:0.244 test loss: 247.89
219000: ********* epoch 23 ********* test accuracy for mode 32:0.2075 test loss: 232.636
219000: ********* epoch 23 ********* test accuracy for mode 33:0.2695 test loss: 228.328
219000: ********* epoch 23 ********* test accuracy for mode 34:0.246 test loss: 230.042
219000: ********* epoch 23 ********* test accuracy for mode 35:0.151 test loss: 463.97
219000: ********* epoch 23 ********* test accuracy for mode 36:0.2395 test loss: 498.253
219010: accuracy:0.42 loss: 181.57 (lr:0.0001)
219020: accuracy:0.41 loss: 200.774 (lr:0.0001)
219030: accuracy:0.42 loss: 185.328 (lr:0.0001)
219040: accuracy:0.41 loss: 182.41 (lr:0.0001)
219050: accuracy:0.42 loss: 180.636 (lr:0.0001)
219060: accuracy:0.41 loss: 188.952 (lr:0.0001)
219070: accuracy:0.29 loss: 217.983 (lr:0.0001)
219080: accuracy:0.34 loss: 197.35 (lr:0.0001)
219090: accuracy:0.39 loss: 204.282 (lr:0.0001)
219100: accuracy:0.36 loss: 200.343 (lr:0.0001)
219110: accuracy:0.39 loss: 185.809 (lr:0.0001)
219120: accuracy:0.31 loss: 210.995 (lr:0.0001)
219130: accuracy:0.38 loss: 177.516 (lr:0.0001)
219140: accuracy:0.37 loss: 196.672 (lr:0.0001)
219150: accuracy:0.3 loss: 193.877 (lr:0.0001)
219160: accuracy:0.31 loss: 194.895 (lr:0.0001)
219170: accuracy:0.38 loss: 188.921 (lr:0.0001)
219180: accuracy:0.41 loss: 191.918 (lr:0.0001)
219190: accuracy:0.44 loss: 179.334 (lr:0.0001)
219200: accuracy:0.32 loss: 209.122 (lr:0.0001)
219210: accuracy:0.35 loss: 195.346 (lr:0.0001)
219220: accuracy:0.35 loss: 199.164 (lr:0.0001)
219230: accuracy:0.43 loss: 195.661 (lr:0.0001)
219240: accuracy:0.38 loss: 174.158 (lr:0.0001)
219250: accuracy:0.44 loss: 192.703 (lr:0.0001)
219260: accuracy:0.42 loss: 186.398 (lr:0.0001)
219270: accuracy:0.39 loss: 181.111 (lr:0.0001)
219280: accuracy:0.4 loss: 189.512 (lr:0.0001)
219290: accuracy:0.36 loss: 182.059 (lr:0.0001)
219300: accuracy:0.42 loss: 192.269 (lr:0.0001)
219310: accuracy:0.41 loss: 197.157 (lr:0.0001)
219320: accuracy:0.4 loss: 192.491 (lr:0.0001)
219330: accuracy:0.29 loss: 204.576 (lr:0.0001)
219340: accuracy:0.33 loss: 210.229 (lr:0.0001)
219350: accuracy:0.4 loss: 176.529 (lr:0.0001)
219360: accuracy:0.43 loss: 185.538 (lr:0.0001)
219370: accuracy:0.36 loss: 178.848 (lr:0.0001)
219380: accuracy:0.46 loss: 174.53 (lr:0.0001)
219390: accuracy:0.37 loss: 201.575 (lr:0.0001)
219400: accuracy:0.38 loss: 190.393 (lr:0.0001)
219410: accuracy:0.34 loss: 211.333 (lr:0.0001)
219420: accuracy:0.32 loss: 203.003 (lr:0.0001)
219430: accuracy:0.4 loss: 187.877 (lr:0.0001)
219440: accuracy:0.47 loss: 181.638 (lr:0.0001)
219450: accuracy:0.41 loss: 193.452 (lr:0.0001)
219460: accuracy:0.37 loss: 202.736 (lr:0.0001)
219470: accuracy:0.4 loss: 189.717 (lr:0.0001)
219480: accuracy:0.37 loss: 189.205 (lr:0.0001)
219490: accuracy:0.4 loss: 211.02 (lr:0.0001)
219500: accuracy:0.46 loss: 172.466 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
219500: ********* epoch 23 ********* test accuracy for all:0.258568 test loss: 264.451
219500: ********* epoch 23 ********* test accuracy for mode 0:0.045 test loss: 496.682
219500: ********* epoch 23 ********* test accuracy for mode 1:0.03 test loss: 481.846
219500: ********* epoch 23 ********* test accuracy for mode 2:0.113 test loss: 252.368
219500: ********* epoch 23 ********* test accuracy for mode 24:0.2375 test loss: 288.374
219500: ********* epoch 23 ********* test accuracy for mode 25:0.269 test loss: 248.941
219500: ********* epoch 23 ********* test accuracy for mode 26:0.503 test loss: 159.979
219500: ********* epoch 23 ********* test accuracy for mode 27:0.251 test loss: 267.878
219500: ********* epoch 23 ********* test accuracy for mode 28:0.2525 test loss: 276.221
219500: ********* epoch 23 ********* test accuracy for mode 29:0.228 test loss: 279.645
219500: ********* epoch 23 ********* test accuracy for mode 30:0.246 test loss: 252.798
219500: ********* epoch 23 ********* test accuracy for mode 31:0.192 test loss: 255.337
219500: ********* epoch 23 ********* test accuracy for mode 32:0.2315 test loss: 227.509
219500: ********* epoch 23 ********* test accuracy for mode 33:0.2945 test loss: 223.168
219500: ********* epoch 23 ********* test accuracy for mode 34:0.259 test loss: 227.168
219500: ********* epoch 23 ********* test accuracy for mode 35:0.138 test loss: 446.559
219500: ********* epoch 23 ********* test accuracy for mode 36:0.1985 test loss: 493.407
219510: accuracy:0.41 loss: 191.133 (lr:0.0001)
219520: accuracy:0.4 loss: 210.465 (lr:0.0001)
219530: accuracy:0.35 loss: 196.93 (lr:0.0001)
219540: accuracy:0.29 loss: 202.974 (lr:0.0001)
219550: accuracy:0.42 loss: 189.176 (lr:0.0001)
219560: accuracy:0.36 loss: 183.756 (lr:0.0001)
219570: accuracy:0.36 loss: 186.285 (lr:0.0001)
219580: accuracy:0.4 loss: 201.661 (lr:0.0001)
219590: accuracy:0.36 loss: 200.41 (lr:0.0001)
219600: accuracy:0.38 loss: 195.831 (lr:0.0001)
219610: accuracy:0.41 loss: 183.26 (lr:0.0001)
219620: accuracy:0.42 loss: 186.288 (lr:0.0001)
219630: accuracy:0.43 loss: 167.263 (lr:0.0001)
219640: accuracy:0.36 loss: 183.195 (lr:0.0001)
219650: accuracy:0.43 loss: 195.473 (lr:0.0001)
219660: accuracy:0.37 loss: 200.569 (lr:0.0001)
219670: accuracy:0.37 loss: 225.443 (lr:0.0001)
219680: accuracy:0.32 loss: 201.648 (lr:0.0001)
219690: accuracy:0.41 loss: 202.441 (lr:0.0001)
219700: accuracy:0.42 loss: 182.421 (lr:0.0001)
219710: accuracy:0.38 loss: 197.72 (lr:0.0001)
219720: accuracy:0.4 loss: 187.962 (lr:0.0001)
219730: accuracy:0.38 loss: 223.304 (lr:0.0001)
219740: accuracy:0.4 loss: 169.434 (lr:0.0001)
219750: accuracy:0.32 loss: 196.936 (lr:0.0001)
219760: accuracy:0.35 loss: 195.053 (lr:0.0001)
219770: accuracy:0.38 loss: 189.981 (lr:0.0001)
219780: accuracy:0.37 loss: 170.154 (lr:0.0001)
219790: accuracy:0.42 loss: 194.223 (lr:0.0001)
219800: accuracy:0.4 loss: 187.076 (lr:0.0001)
219810: accuracy:0.44 loss: 194.913 (lr:0.0001)
219820: accuracy:0.35 loss: 202.561 (lr:0.0001)
219830: accuracy:0.34 loss: 184.722 (lr:0.0001)
219840: accuracy:0.35 loss: 198.923 (lr:0.0001)
219850: accuracy:0.34 loss: 199.236 (lr:0.0001)
219860: accuracy:0.37 loss: 190.413 (lr:0.0001)
219870: accuracy:0.32 loss: 212.441 (lr:0.0001)
219880: accuracy:0.37 loss: 184.223 (lr:0.0001)
219890: accuracy:0.32 loss: 205.187 (lr:0.0001)
219900: accuracy:0.46 loss: 179.468 (lr:0.0001)
219910: accuracy:0.47 loss: 166.037 (lr:0.0001)
219920: accuracy:0.5 loss: 169.306 (lr:0.0001)
219930: accuracy:0.38 loss: 211.563 (lr:0.0001)
219940: accuracy:0.38 loss: 207.384 (lr:0.0001)
219950: accuracy:0.47 loss: 175.85 (lr:0.0001)
219960: accuracy:0.38 loss: 187.138 (lr:0.0001)
219970: accuracy:0.29 loss: 209.011 (lr:0.0001)
219980: accuracy:0.48 loss: 202.209 (lr:0.0001)
219990: accuracy:0.36 loss: 194.517 (lr:0.0001)
220000: accuracy:0.39 loss: 191.931 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
220000: ********* epoch 23 ********* test accuracy for all:0.26123 test loss: 264.308
220000: ********* epoch 23 ********* test accuracy for mode 0:0.0315 test loss: 512.341
220000: ********* epoch 23 ********* test accuracy for mode 1:0.0285 test loss: 485.01
220000: ********* epoch 23 ********* test accuracy for mode 2:0.095 test loss: 259.617
220000: ********* epoch 23 ********* test accuracy for mode 24:0.249 test loss: 276.009
220000: ********* epoch 23 ********* test accuracy for mode 25:0.283 test loss: 246.81
220000: ********* epoch 23 ********* test accuracy for mode 26:0.4875 test loss: 161.005
220000: ********* epoch 23 ********* test accuracy for mode 27:0.2205 test loss: 275.461
220000: ********* epoch 23 ********* test accuracy for mode 28:0.295 test loss: 266.985
220000: ********* epoch 23 ********* test accuracy for mode 29:0.2155 test loss: 276.516
220000: ********* epoch 23 ********* test accuracy for mode 30:0.245 test loss: 250.465
220000: ********* epoch 23 ********* test accuracy for mode 31:0.2155 test loss: 250.794
220000: ********* epoch 23 ********* test accuracy for mode 32:0.2345 test loss: 228.607
220000: ********* epoch 23 ********* test accuracy for mode 33:0.262 test loss: 229.385
220000: ********* epoch 23 ********* test accuracy for mode 34:0.279 test loss: 228.544
220000: ********* epoch 23 ********* test accuracy for mode 35:0.123 test loss: 494.106
220000: ********* epoch 23 ********* test accuracy for mode 36:0.0805 test loss: 556.124
220010: accuracy:0.31 loss: 209.439 (lr:0.0001)
220020: accuracy:0.29 loss: 224.909 (lr:0.0001)
220030: accuracy:0.37 loss: 179.77 (lr:0.0001)
220040: accuracy:0.36 loss: 173.098 (lr:0.0001)
220050: accuracy:0.44 loss: 184.682 (lr:0.0001)
220060: accuracy:0.25 loss: 215.086 (lr:0.0001)
220070: accuracy:0.37 loss: 197.246 (lr:0.0001)
220080: accuracy:0.38 loss: 192.97 (lr:0.0001)
220090: accuracy:0.32 loss: 199.261 (lr:0.0001)
220100: accuracy:0.44 loss: 195.509 (lr:0.0001)
220110: accuracy:0.37 loss: 198.06 (lr:0.0001)
220120: accuracy:0.44 loss: 181.144 (lr:0.0001)
220130: accuracy:0.47 loss: 175.791 (lr:0.0001)
220140: accuracy:0.38 loss: 202.958 (lr:0.0001)
220150: accuracy:0.41 loss: 178.544 (lr:0.0001)
220160: accuracy:0.45 loss: 177.386 (lr:0.0001)
220170: accuracy:0.39 loss: 192.014 (lr:0.0001)
220180: accuracy:0.37 loss: 217.529 (lr:0.0001)
220190: accuracy:0.41 loss: 192.105 (lr:0.0001)
220200: accuracy:0.33 loss: 223.206 (lr:0.0001)
220210: accuracy:0.33 loss: 208.862 (lr:0.0001)
220220: accuracy:0.34 loss: 211.821 (lr:0.0001)
220230: accuracy:0.42 loss: 183.284 (lr:0.0001)
220240: accuracy:0.39 loss: 186.248 (lr:0.0001)
220250: accuracy:0.37 loss: 208.955 (lr:0.0001)
220260: accuracy:0.45 loss: 176.468 (lr:0.0001)
220270: accuracy:0.43 loss: 191.114 (lr:0.0001)
220280: accuracy:0.33 loss: 218.606 (lr:0.0001)
220290: accuracy:0.4 loss: 177.073 (lr:0.0001)
220300: accuracy:0.32 loss: 187.351 (lr:0.0001)
220310: accuracy:0.36 loss: 188.342 (lr:0.0001)
220320: accuracy:0.44 loss: 169.206 (lr:0.0001)
220330: accuracy:0.44 loss: 189.916 (lr:0.0001)
220340: accuracy:0.4 loss: 180.08 (lr:0.0001)
220350: accuracy:0.38 loss: 200.91 (lr:0.0001)
220360: accuracy:0.34 loss: 195.189 (lr:0.0001)
220370: accuracy:0.39 loss: 188.512 (lr:0.0001)
220380: accuracy:0.38 loss: 189.887 (lr:0.0001)
220390: accuracy:0.3 loss: 204.118 (lr:0.0001)
220400: accuracy:0.38 loss: 191.94 (lr:0.0001)
220410: accuracy:0.43 loss: 181.0 (lr:0.0001)
220420: accuracy:0.41 loss: 186.983 (lr:0.0001)
220430: accuracy:0.42 loss: 180.045 (lr:0.0001)
220440: accuracy:0.52 loss: 181.608 (lr:0.0001)
220450: accuracy:0.39 loss: 180.58 (lr:0.0001)
220460: accuracy:0.34 loss: 212.839 (lr:0.0001)
220470: accuracy:0.39 loss: 187.256 (lr:0.0001)
220480: accuracy:0.43 loss: 197.137 (lr:0.0001)
220490: accuracy:0.32 loss: 207.572 (lr:0.0001)
220500: accuracy:0.45 loss: 185.029 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
220500: ********* epoch 23 ********* test accuracy for all:0.263257 test loss: 265.031
220500: ********* epoch 23 ********* test accuracy for mode 0:0.034 test loss: 514.059
220500: ********* epoch 23 ********* test accuracy for mode 1:0.0265 test loss: 492.423
220500: ********* epoch 23 ********* test accuracy for mode 2:0.084 test loss: 251.417
220500: ********* epoch 23 ********* test accuracy for mode 24:0.26 test loss: 280.284
220500: ********* epoch 23 ********* test accuracy for mode 25:0.247 test loss: 252.674
220500: ********* epoch 23 ********* test accuracy for mode 26:0.5295 test loss: 155.977
220500: ********* epoch 23 ********* test accuracy for mode 27:0.2495 test loss: 261.326
220500: ********* epoch 23 ********* test accuracy for mode 28:0.2975 test loss: 258.89
220500: ********* epoch 23 ********* test accuracy for mode 29:0.254 test loss: 265.837
220500: ********* epoch 23 ********* test accuracy for mode 30:0.232 test loss: 249.376
220500: ********* epoch 23 ********* test accuracy for mode 31:0.19 test loss: 252.714
220500: ********* epoch 23 ********* test accuracy for mode 32:0.2655 test loss: 222.96
220500: ********* epoch 23 ********* test accuracy for mode 33:0.2535 test loss: 226.903
220500: ********* epoch 23 ********* test accuracy for mode 34:0.265 test loss: 224.627
220500: ********* epoch 23 ********* test accuracy for mode 35:0.1495 test loss: 463.487
220500: ********* epoch 23 ********* test accuracy for mode 36:0.2435 test loss: 497.739
220510: accuracy:0.43 loss: 192.623 (lr:0.0001)
220520: accuracy:0.4 loss: 175.342 (lr:0.0001)
220530: accuracy:0.41 loss: 202.674 (lr:0.0001)
220540: accuracy:0.45 loss: 184.478 (lr:0.0001)
220550: accuracy:0.51 loss: 161.46 (lr:0.0001)
220560: accuracy:0.47 loss: 184.414 (lr:0.0001)
220570: accuracy:0.39 loss: 187.62 (lr:0.0001)
220580: accuracy:0.34 loss: 196.47 (lr:0.0001)
220590: accuracy:0.3 loss: 196.653 (lr:0.0001)
220600: accuracy:0.4 loss: 166.474 (lr:0.0001)
220610: accuracy:0.44 loss: 167.038 (lr:0.0001)
220620: accuracy:0.41 loss: 189.527 (lr:0.0001)
220630: accuracy:0.39 loss: 192.426 (lr:0.0001)
220640: accuracy:0.38 loss: 172.909 (lr:0.0001)
220650: accuracy:0.34 loss: 213.43 (lr:0.0001)
220660: accuracy:0.41 loss: 185.219 (lr:0.0001)
220670: accuracy:0.32 loss: 196.396 (lr:0.0001)
220680: accuracy:0.37 loss: 190.551 (lr:0.0001)
220690: accuracy:0.48 loss: 175.782 (lr:0.0001)
220700: accuracy:0.37 loss: 207.624 (lr:0.0001)
220710: accuracy:0.41 loss: 167.641 (lr:0.0001)
220720: accuracy:0.31 loss: 186.98 (lr:0.0001)
220730: accuracy:0.41 loss: 187.773 (lr:0.0001)
220740: accuracy:0.4 loss: 175.49 (lr:0.0001)
220750: accuracy:0.4 loss: 176.912 (lr:0.0001)
220760: accuracy:0.41 loss: 192.253 (lr:0.0001)
220770: accuracy:0.46 loss: 183.596 (lr:0.0001)
220780: accuracy:0.38 loss: 189.106 (lr:0.0001)
220790: accuracy:0.36 loss: 208.824 (lr:0.0001)
220800: accuracy:0.41 loss: 184.632 (lr:0.0001)
220810: accuracy:0.34 loss: 211.929 (lr:0.0001)
220820: accuracy:0.49 loss: 193.258 (lr:0.0001)
220830: accuracy:0.43 loss: 186.522 (lr:0.0001)
220840: accuracy:0.26 loss: 225.687 (lr:0.0001)
220850: accuracy:0.36 loss: 191.342 (lr:0.0001)
220860: accuracy:0.52 loss: 170.075 (lr:0.0001)
220870: accuracy:0.33 loss: 197.387 (lr:0.0001)
220880: accuracy:0.33 loss: 199.463 (lr:0.0001)
220890: accuracy:0.41 loss: 193.897 (lr:0.0001)
220900: accuracy:0.37 loss: 190.646 (lr:0.0001)
220910: accuracy:0.42 loss: 171.166 (lr:0.0001)
220920: accuracy:0.33 loss: 201.019 (lr:0.0001)
220930: accuracy:0.36 loss: 204.733 (lr:0.0001)
220940: accuracy:0.44 loss: 175.408 (lr:0.0001)
220950: accuracy:0.43 loss: 174.231 (lr:0.0001)
220960: accuracy:0.39 loss: 193.124 (lr:0.0001)
220970: accuracy:0.37 loss: 205.656 (lr:0.0001)
220980: accuracy:0.38 loss: 211.909 (lr:0.0001)
220990: accuracy:0.37 loss: 202.05 (lr:0.0001)
221000: accuracy:0.32 loss: 221.029 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
221000: ********* epoch 23 ********* test accuracy for all:0.262595 test loss: 263.711
221000: ********* epoch 23 ********* test accuracy for mode 0:0.033 test loss: 520.7
221000: ********* epoch 23 ********* test accuracy for mode 1:0.0195 test loss: 485.636
221000: ********* epoch 23 ********* test accuracy for mode 2:0.106 test loss: 252.913
221000: ********* epoch 23 ********* test accuracy for mode 24:0.2515 test loss: 274.902
221000: ********* epoch 23 ********* test accuracy for mode 25:0.324 test loss: 238.888
221000: ********* epoch 23 ********* test accuracy for mode 26:0.5515 test loss: 152.284
221000: ********* epoch 23 ********* test accuracy for mode 27:0.261 test loss: 263.446
221000: ********* epoch 23 ********* test accuracy for mode 28:0.277 test loss: 268.646
221000: ********* epoch 23 ********* test accuracy for mode 29:0.256 test loss: 271.431
221000: ********* epoch 23 ********* test accuracy for mode 30:0.21 test loss: 255.998
221000: ********* epoch 23 ********* test accuracy for mode 31:0.216 test loss: 251.713
221000: ********* epoch 23 ********* test accuracy for mode 32:0.218 test loss: 232.967
221000: ********* epoch 23 ********* test accuracy for mode 33:0.265 test loss: 230.286
221000: ********* epoch 23 ********* test accuracy for mode 34:0.273 test loss: 227.454
221000: ********* epoch 23 ********* test accuracy for mode 35:0.1055 test loss: 479.218
221000: ********* epoch 23 ********* test accuracy for mode 36:0.1015 test loss: 537.234
221010: accuracy:0.34 loss: 206.158 (lr:0.0001)
221020: accuracy:0.38 loss: 191.625 (lr:0.0001)
221030: accuracy:0.41 loss: 172.934 (lr:0.0001)
221040: accuracy:0.42 loss: 190.515 (lr:0.0001)
221050: accuracy:0.4 loss: 184.188 (lr:0.0001)
221060: accuracy:0.33 loss: 189.176 (lr:0.0001)
221070: accuracy:0.37 loss: 192.006 (lr:0.0001)
221080: accuracy:0.38 loss: 185.719 (lr:0.0001)
221090: accuracy:0.34 loss: 219.847 (lr:0.0001)
221100: accuracy:0.42 loss: 198.563 (lr:0.0001)
221110: accuracy:0.36 loss: 193.584 (lr:0.0001)
221120: accuracy:0.4 loss: 192.356 (lr:0.0001)
221130: accuracy:0.32 loss: 196.626 (lr:0.0001)
221140: accuracy:0.34 loss: 196.063 (lr:0.0001)
221150: accuracy:0.41 loss: 182.412 (lr:0.0001)
221160: accuracy:0.4 loss: 197.033 (lr:0.0001)
221170: accuracy:0.27 loss: 220.204 (lr:0.0001)
221180: accuracy:0.33 loss: 205.408 (lr:0.0001)
221190: accuracy:0.42 loss: 179.583 (lr:0.0001)
221200: accuracy:0.39 loss: 192.79 (lr:0.0001)
221210: accuracy:0.31 loss: 195.961 (lr:0.0001)
221220: accuracy:0.46 loss: 196.743 (lr:0.0001)
221230: accuracy:0.43 loss: 163.637 (lr:0.0001)
221240: accuracy:0.42 loss: 190.521 (lr:0.0001)
221250: accuracy:0.42 loss: 191.279 (lr:0.0001)
221260: accuracy:0.34 loss: 177.496 (lr:0.0001)
221270: accuracy:0.43 loss: 183.492 (lr:0.0001)
221280: accuracy:0.33 loss: 203.309 (lr:0.0001)
221290: accuracy:0.37 loss: 193.262 (lr:0.0001)
221300: accuracy:0.38 loss: 203.578 (lr:0.0001)
221310: accuracy:0.35 loss: 203.492 (lr:0.0001)
221320: accuracy:0.39 loss: 174.76 (lr:0.0001)
221330: accuracy:0.42 loss: 193.375 (lr:0.0001)
221340: accuracy:0.33 loss: 188.066 (lr:0.0001)
221350: accuracy:0.26 loss: 218.042 (lr:0.0001)
221360: accuracy:0.44 loss: 183.974 (lr:0.0001)
221370: accuracy:0.35 loss: 202.32 (lr:0.0001)
221380: accuracy:0.46 loss: 186.388 (lr:0.0001)
221390: accuracy:0.36 loss: 208.985 (lr:0.0001)
221400: accuracy:0.38 loss: 192.642 (lr:0.0001)
221410: accuracy:0.45 loss: 185.789 (lr:0.0001)
221420: accuracy:0.29 loss: 204.736 (lr:0.0001)
221430: accuracy:0.33 loss: 224.277 (lr:0.0001)
221440: accuracy:0.38 loss: 214.416 (lr:0.0001)
221450: accuracy:0.35 loss: 214.877 (lr:0.0001)
221460: accuracy:0.37 loss: 191.692 (lr:0.0001)
221470: accuracy:0.36 loss: 205.235 (lr:0.0001)
221480: accuracy:0.41 loss: 180.543 (lr:0.0001)
221490: accuracy:0.37 loss: 202.48 (lr:0.0001)
221500: accuracy:0.51 loss: 175.226 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
221500: ********* epoch 23 ********* test accuracy for all:0.265041 test loss: 262.621
221500: ********* epoch 23 ********* test accuracy for mode 0:0.0385 test loss: 502.091
221500: ********* epoch 23 ********* test accuracy for mode 1:0.0285 test loss: 479.96
221500: ********* epoch 23 ********* test accuracy for mode 2:0.0975 test loss: 254.806
221500: ********* epoch 23 ********* test accuracy for mode 24:0.2405 test loss: 286.98
221500: ********* epoch 23 ********* test accuracy for mode 25:0.2845 test loss: 254.762
221500: ********* epoch 23 ********* test accuracy for mode 26:0.5045 test loss: 164.996
221500: ********* epoch 23 ********* test accuracy for mode 27:0.2605 test loss: 273.055
221500: ********* epoch 23 ********* test accuracy for mode 28:0.28 test loss: 270.927
221500: ********* epoch 23 ********* test accuracy for mode 29:0.257 test loss: 272.256
221500: ********* epoch 23 ********* test accuracy for mode 30:0.256 test loss: 253.539
221500: ********* epoch 23 ********* test accuracy for mode 31:0.1995 test loss: 255.355
221500: ********* epoch 23 ********* test accuracy for mode 32:0.213 test loss: 232.464
221500: ********* epoch 23 ********* test accuracy for mode 33:0.278 test loss: 229.77
221500: ********* epoch 23 ********* test accuracy for mode 34:0.25 test loss: 229.818
221500: ********* epoch 23 ********* test accuracy for mode 35:0.1085 test loss: 463.871
221500: ********* epoch 23 ********* test accuracy for mode 36:0.2525 test loss: 486.529
221510: accuracy:0.43 loss: 187.044 (lr:0.0001)
221520: accuracy:0.4 loss: 192.411 (lr:0.0001)
221530: accuracy:0.39 loss: 202.598 (lr:0.0001)
221540: accuracy:0.41 loss: 170.626 (lr:0.0001)
221550: accuracy:0.36 loss: 176.662 (lr:0.0001)
221560: accuracy:0.41 loss: 222.426 (lr:0.0001)
221570: accuracy:0.47 loss: 178.216 (lr:0.0001)
221580: accuracy:0.38 loss: 213.155 (lr:0.0001)
221590: accuracy:0.38 loss: 191.988 (lr:0.0001)
221600: accuracy:0.37 loss: 187.378 (lr:0.0001)
221610: accuracy:0.33 loss: 201.048 (lr:0.0001)
221620: accuracy:0.41 loss: 208.678 (lr:0.0001)
221630: accuracy:0.39 loss: 197.648 (lr:0.0001)
221640: accuracy:0.29 loss: 211.395 (lr:0.0001)
221650: accuracy:0.43 loss: 183.203 (lr:0.0001)
221660: accuracy:0.44 loss: 180.633 (lr:0.0001)
221670: accuracy:0.42 loss: 177.806 (lr:0.0001)
221680: accuracy:0.5 loss: 183.294 (lr:0.0001)
221690: accuracy:0.3 loss: 199.225 (lr:0.0001)
221700: accuracy:0.38 loss: 195.341 (lr:0.0001)
221710: accuracy:0.46 loss: 180.517 (lr:0.0001)
221720: accuracy:0.43 loss: 185.222 (lr:0.0001)
221730: accuracy:0.36 loss: 208.701 (lr:0.0001)
221740: accuracy:0.39 loss: 179.632 (lr:0.0001)
221750: accuracy:0.36 loss: 199.586 (lr:0.0001)
221760: accuracy:0.41 loss: 181.827 (lr:0.0001)
221770: accuracy:0.47 loss: 178.126 (lr:0.0001)
221780: accuracy:0.27 loss: 211.485 (lr:0.0001)
221790: accuracy:0.4 loss: 185.076 (lr:0.0001)
221800: accuracy:0.34 loss: 189.028 (lr:0.0001)
221810: accuracy:0.47 loss: 175.866 (lr:0.0001)
221820: accuracy:0.31 loss: 204.256 (lr:0.0001)
221830: accuracy:0.4 loss: 182.9 (lr:0.0001)
221840: accuracy:0.38 loss: 195.567 (lr:0.0001)
221850: accuracy:0.41 loss: 186.971 (lr:0.0001)
221860: accuracy:0.38 loss: 193.361 (lr:0.0001)
221870: accuracy:0.37 loss: 207.781 (lr:0.0001)
221880: accuracy:0.35 loss: 193.376 (lr:0.0001)
221890: accuracy:0.48 loss: 173.627 (lr:0.0001)
221900: accuracy:0.41 loss: 181.23 (lr:0.0001)
221910: accuracy:0.4 loss: 190.299 (lr:0.0001)
221920: accuracy:0.37 loss: 220.374 (lr:0.0001)
221930: accuracy:0.38 loss: 184.571 (lr:0.0001)
221940: accuracy:0.36 loss: 212.916 (lr:0.0001)
221950: accuracy:0.37 loss: 209.186 (lr:0.0001)
221960: accuracy:0.37 loss: 200.408 (lr:0.0001)
221970: accuracy:0.39 loss: 202.705 (lr:0.0001)
221980: accuracy:0.36 loss: 211.542 (lr:0.0001)
221990: accuracy:0.42 loss: 193.214 (lr:0.0001)
222000: accuracy:0.43 loss: 174.645 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
222000: ********* epoch 23 ********* test accuracy for all:0.262959 test loss: 259.854
222000: ********* epoch 23 ********* test accuracy for mode 0:0.029 test loss: 503.988
222000: ********* epoch 23 ********* test accuracy for mode 1:0.0265 test loss: 472.26
222000: ********* epoch 23 ********* test accuracy for mode 2:0.0825 test loss: 262.264
222000: ********* epoch 23 ********* test accuracy for mode 24:0.2455 test loss: 280.291
222000: ********* epoch 23 ********* test accuracy for mode 25:0.2415 test loss: 252.73
222000: ********* epoch 23 ********* test accuracy for mode 26:0.4905 test loss: 166.247
222000: ********* epoch 23 ********* test accuracy for mode 27:0.2195 test loss: 274.86
222000: ********* epoch 23 ********* test accuracy for mode 28:0.307 test loss: 260.338
222000: ********* epoch 23 ********* test accuracy for mode 29:0.239 test loss: 267.882
222000: ********* epoch 23 ********* test accuracy for mode 30:0.2695 test loss: 242.203
222000: ********* epoch 23 ********* test accuracy for mode 31:0.2295 test loss: 246.765
222000: ********* epoch 23 ********* test accuracy for mode 32:0.177 test loss: 235.259
222000: ********* epoch 23 ********* test accuracy for mode 33:0.304 test loss: 229.26
222000: ********* epoch 23 ********* test accuracy for mode 34:0.2225 test loss: 235.106
222000: ********* epoch 23 ********* test accuracy for mode 35:0.1445 test loss: 455.712
222000: ********* epoch 23 ********* test accuracy for mode 36:0.1715 test loss: 486.21
222010: accuracy:0.42 loss: 190.791 (lr:0.0001)
222020: accuracy:0.43 loss: 186.084 (lr:0.0001)
222030: accuracy:0.4 loss: 198.711 (lr:0.0001)
222040: accuracy:0.41 loss: 206.163 (lr:0.0001)
222050: accuracy:0.38 loss: 208.909 (lr:0.0001)
222060: accuracy:0.41 loss: 167.496 (lr:0.0001)
222070: accuracy:0.38 loss: 186.536 (lr:0.0001)
222080: accuracy:0.34 loss: 204.785 (lr:0.0001)
222090: accuracy:0.3 loss: 191.219 (lr:0.0001)
222100: accuracy:0.4 loss: 183.486 (lr:0.0001)
222110: accuracy:0.39 loss: 190.665 (lr:0.0001)
222120: accuracy:0.35 loss: 215.99 (lr:0.0001)
222130: accuracy:0.36 loss: 195.194 (lr:0.0001)
222140: accuracy:0.33 loss: 182.324 (lr:0.0001)
222150: accuracy:0.41 loss: 179.648 (lr:0.0001)
222160: accuracy:0.36 loss: 211.166 (lr:0.0001)
222170: accuracy:0.37 loss: 219.031 (lr:0.0001)
222180: accuracy:0.43 loss: 172.069 (lr:0.0001)
222190: accuracy:0.3 loss: 206.637 (lr:0.0001)
222200: accuracy:0.31 loss: 203.249 (lr:0.0001)
222210: accuracy:0.35 loss: 196.675 (lr:0.0001)
222220: accuracy:0.39 loss: 202.298 (lr:0.0001)
222230: accuracy:0.33 loss: 183.157 (lr:0.0001)
222240: accuracy:0.35 loss: 180.316 (lr:0.0001)
222250: accuracy:0.38 loss: 197.317 (lr:0.0001)
222260: accuracy:0.38 loss: 202.555 (lr:0.0001)
222270: accuracy:0.36 loss: 178.796 (lr:0.0001)
222280: accuracy:0.36 loss: 191.38 (lr:0.0001)
222290: accuracy:0.42 loss: 180.218 (lr:0.0001)
222300: accuracy:0.46 loss: 192.777 (lr:0.0001)
222310: accuracy:0.35 loss: 201.594 (lr:0.0001)
222320: accuracy:0.31 loss: 204.058 (lr:0.0001)
222330: accuracy:0.42 loss: 193.079 (lr:0.0001)
222340: accuracy:0.34 loss: 189.054 (lr:0.0001)
222350: accuracy:0.42 loss: 182.101 (lr:0.0001)
222360: accuracy:0.35 loss: 201.398 (lr:0.0001)
222370: accuracy:0.41 loss: 194.246 (lr:0.0001)
222380: accuracy:0.46 loss: 185.465 (lr:0.0001)
222390: accuracy:0.47 loss: 164.725 (lr:0.0001)
222400: accuracy:0.34 loss: 193.415 (lr:0.0001)
222410: accuracy:0.51 loss: 165.937 (lr:0.0001)
222420: accuracy:0.34 loss: 202.334 (lr:0.0001)
222430: accuracy:0.34 loss: 213.798 (lr:0.0001)
222440: accuracy:0.37 loss: 185.005 (lr:0.0001)
222450: accuracy:0.29 loss: 203.888 (lr:0.0001)
222460: accuracy:0.4 loss: 175.768 (lr:0.0001)
222470: accuracy:0.31 loss: 205.321 (lr:0.0001)
222480: accuracy:0.54 loss: 182.694 (lr:0.0001)
222490: accuracy:0.47 loss: 178.947 (lr:0.0001)
222500: accuracy:0.36 loss: 208.247 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
222500: ********* epoch 23 ********* test accuracy for all:0.259865 test loss: 265.588
222500: ********* epoch 23 ********* test accuracy for mode 0:0.0355 test loss: 511.655
222500: ********* epoch 23 ********* test accuracy for mode 1:0.0215 test loss: 487.753
222500: ********* epoch 23 ********* test accuracy for mode 2:0.119 test loss: 253.048
222500: ********* epoch 23 ********* test accuracy for mode 24:0.24 test loss: 281.225
222500: ********* epoch 23 ********* test accuracy for mode 25:0.2515 test loss: 255.498
222500: ********* epoch 23 ********* test accuracy for mode 26:0.513 test loss: 160.718
222500: ********* epoch 23 ********* test accuracy for mode 27:0.235 test loss: 275.74
222500: ********* epoch 23 ********* test accuracy for mode 28:0.292 test loss: 269.165
222500: ********* epoch 23 ********* test accuracy for mode 29:0.2145 test loss: 277.94
222500: ********* epoch 23 ********* test accuracy for mode 30:0.247 test loss: 250.141
222500: ********* epoch 23 ********* test accuracy for mode 31:0.2115 test loss: 251.284
222500: ********* epoch 23 ********* test accuracy for mode 32:0.212 test loss: 235.663
222500: ********* epoch 23 ********* test accuracy for mode 33:0.2045 test loss: 240.055
222500: ********* epoch 23 ********* test accuracy for mode 34:0.2895 test loss: 229.681
222500: ********* epoch 23 ********* test accuracy for mode 35:0.1565 test loss: 468.463
222500: ********* epoch 23 ********* test accuracy for mode 36:0.0665 test loss: 573.016
222510: accuracy:0.45 loss: 179.017 (lr:0.0001)
222520: accuracy:0.43 loss: 170.411 (lr:0.0001)
222530: accuracy:0.39 loss: 188.69 (lr:0.0001)
222540: accuracy:0.46 loss: 169.602 (lr:0.0001)
222550: accuracy:0.43 loss: 184.87 (lr:0.0001)
222560: accuracy:0.42 loss: 180.748 (lr:0.0001)
222570: accuracy:0.42 loss: 183.552 (lr:0.0001)
222580: accuracy:0.39 loss: 175.774 (lr:0.0001)
222590: accuracy:0.36 loss: 187.406 (lr:0.0001)
222600: accuracy:0.37 loss: 199.011 (lr:0.0001)
222610: accuracy:0.33 loss: 188.587 (lr:0.0001)
222620: accuracy:0.34 loss: 178.022 (lr:0.0001)
222630: accuracy:0.41 loss: 178.077 (lr:0.0001)
222640: accuracy:0.32 loss: 202.289 (lr:0.0001)
222650: accuracy:0.39 loss: 195.24 (lr:0.0001)
222660: accuracy:0.42 loss: 184.839 (lr:0.0001)
222670: accuracy:0.44 loss: 201.513 (lr:0.0001)
222680: accuracy:0.38 loss: 186.888 (lr:0.0001)
222690: accuracy:0.42 loss: 182.321 (lr:0.0001)
222700: accuracy:0.45 loss: 191.606 (lr:0.0001)
222710: accuracy:0.47 loss: 182.211 (lr:0.0001)
222720: accuracy:0.41 loss: 198.329 (lr:0.0001)
222730: accuracy:0.35 loss: 188.951 (lr:0.0001)
222740: accuracy:0.43 loss: 186.485 (lr:0.0001)
222750: accuracy:0.35 loss: 187.924 (lr:0.0001)
222760: accuracy:0.39 loss: 183.108 (lr:0.0001)
222770: accuracy:0.32 loss: 216.432 (lr:0.0001)
222780: accuracy:0.35 loss: 202.947 (lr:0.0001)
222790: accuracy:0.43 loss: 206.311 (lr:0.0001)
222800: accuracy:0.37 loss: 201.493 (lr:0.0001)
222810: accuracy:0.46 loss: 181.027 (lr:0.0001)
222820: accuracy:0.38 loss: 189.638 (lr:0.0001)
222830: accuracy:0.38 loss: 213.842 (lr:0.0001)
222840: accuracy:0.41 loss: 184.755 (lr:0.0001)
222850: accuracy:0.41 loss: 187.871 (lr:0.0001)
222860: accuracy:0.4 loss: 183.574 (lr:0.0001)
222870: accuracy:0.41 loss: 173.63 (lr:0.0001)
222880: accuracy:0.3 loss: 208.263 (lr:0.0001)
222890: accuracy:0.36 loss: 183.849 (lr:0.0001)
222900: accuracy:0.35 loss: 198.725 (lr:0.0001)
222910: accuracy:0.34 loss: 210.431 (lr:0.0001)
222920: accuracy:0.39 loss: 191.428 (lr:0.0001)
222930: accuracy:0.44 loss: 211.726 (lr:0.0001)
222940: accuracy:0.4 loss: 177.624 (lr:0.0001)
222950: accuracy:0.4 loss: 181.721 (lr:0.0001)
222960: accuracy:0.39 loss: 207.511 (lr:0.0001)
222970: accuracy:0.43 loss: 198.933 (lr:0.0001)
222980: accuracy:0.44 loss: 175.435 (lr:0.0001)
222990: accuracy:0.41 loss: 178.226 (lr:0.0001)
223000: accuracy:0.37 loss: 195.634 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
223000: ********* epoch 23 ********* test accuracy for all:0.256311 test loss: 267.412
223000: ********* epoch 23 ********* test accuracy for mode 0:0.0315 test loss: 522.157
223000: ********* epoch 23 ********* test accuracy for mode 1:0.025 test loss: 497.411
223000: ********* epoch 23 ********* test accuracy for mode 2:0.0775 test loss: 256.433
223000: ********* epoch 23 ********* test accuracy for mode 24:0.213 test loss: 301.788
223000: ********* epoch 23 ********* test accuracy for mode 25:0.247 test loss: 256.374
223000: ********* epoch 23 ********* test accuracy for mode 26:0.4835 test loss: 167.079
223000: ********* epoch 23 ********* test accuracy for mode 27:0.2405 test loss: 276.863
223000: ********* epoch 23 ********* test accuracy for mode 28:0.276 test loss: 267.008
223000: ********* epoch 23 ********* test accuracy for mode 29:0.245 test loss: 265.635
223000: ********* epoch 23 ********* test accuracy for mode 30:0.2605 test loss: 238.476
223000: ********* epoch 23 ********* test accuracy for mode 31:0.2545 test loss: 237.933
223000: ********* epoch 23 ********* test accuracy for mode 32:0.2095 test loss: 224.981
223000: ********* epoch 23 ********* test accuracy for mode 33:0.303 test loss: 223.58
223000: ********* epoch 23 ********* test accuracy for mode 34:0.2475 test loss: 227.535
223000: ********* epoch 23 ********* test accuracy for mode 35:0.13 test loss: 490.777
223000: ********* epoch 23 ********* test accuracy for mode 36:0.1295 test loss: 550.526
223010: accuracy:0.32 loss: 217.014 (lr:0.0001)
223020: accuracy:0.38 loss: 193.836 (lr:0.0001)
223030: accuracy:0.38 loss: 182.747 (lr:0.0001)
223040: accuracy:0.41 loss: 199.149 (lr:0.0001)
223050: accuracy:0.35 loss: 189.108 (lr:0.0001)
223060: accuracy:0.34 loss: 203.503 (lr:0.0001)
223070: accuracy:0.45 loss: 190.467 (lr:0.0001)
223080: accuracy:0.39 loss: 190.123 (lr:0.0001)
223090: accuracy:0.31 loss: 193.187 (lr:0.0001)
223100: accuracy:0.37 loss: 192.111 (lr:0.0001)
223110: accuracy:0.43 loss: 180.508 (lr:0.0001)
223120: accuracy:0.3 loss: 213.801 (lr:0.0001)
223130: accuracy:0.38 loss: 201.04 (lr:0.0001)
223140: accuracy:0.31 loss: 187.709 (lr:0.0001)
223150: accuracy:0.26 loss: 221.043 (lr:0.0001)
223160: accuracy:0.34 loss: 195.17 (lr:0.0001)
223170: accuracy:0.45 loss: 196.369 (lr:0.0001)
223180: accuracy:0.34 loss: 214.947 (lr:0.0001)
223190: accuracy:0.3 loss: 198.126 (lr:0.0001)
223200: accuracy:0.4 loss: 183.742 (lr:0.0001)
223210: accuracy:0.44 loss: 182.599 (lr:0.0001)
223220: accuracy:0.38 loss: 185.139 (lr:0.0001)
223230: accuracy:0.37 loss: 177.465 (lr:0.0001)
223240: accuracy:0.38 loss: 206.787 (lr:0.0001)
223250: accuracy:0.43 loss: 185.563 (lr:0.0001)
223260: accuracy:0.37 loss: 193.663 (lr:0.0001)
223270: accuracy:0.45 loss: 178.913 (lr:0.0001)
223280: accuracy:0.44 loss: 187.407 (lr:0.0001)
223290: accuracy:0.47 loss: 164.889 (lr:0.0001)
223300: accuracy:0.3 loss: 212.592 (lr:0.0001)
223310: accuracy:0.39 loss: 197.18 (lr:0.0001)
223320: accuracy:0.4 loss: 188.327 (lr:0.0001)
223330: accuracy:0.44 loss: 178.076 (lr:0.0001)
223340: accuracy:0.36 loss: 200.031 (lr:0.0001)
223350: accuracy:0.33 loss: 206.15 (lr:0.0001)
223360: accuracy:0.42 loss: 181.755 (lr:0.0001)
223370: accuracy:0.43 loss: 185.551 (lr:0.0001)
223380: accuracy:0.38 loss: 194.919 (lr:0.0001)
223390: accuracy:0.36 loss: 189.52 (lr:0.0001)
223400: accuracy:0.39 loss: 195.862 (lr:0.0001)
223410: accuracy:0.38 loss: 196.32 (lr:0.0001)
223420: accuracy:0.39 loss: 195.964 (lr:0.0001)
223430: accuracy:0.35 loss: 189.206 (lr:0.0001)
223440: accuracy:0.44 loss: 187.726 (lr:0.0001)
223450: accuracy:0.34 loss: 193.696 (lr:0.0001)
223460: accuracy:0.37 loss: 195.45 (lr:0.0001)
223470: accuracy:0.46 loss: 185.093 (lr:0.0001)
223480: accuracy:0.42 loss: 161.867 (lr:0.0001)
223490: accuracy:0.35 loss: 207.294 (lr:0.0001)
223500: accuracy:0.39 loss: 192.015 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
223500: ********* epoch 23 ********* test accuracy for all:0.265716 test loss: 263.956
223500: ********* epoch 23 ********* test accuracy for mode 0:0.03 test loss: 524.205
223500: ********* epoch 23 ********* test accuracy for mode 1:0.0225 test loss: 490.926
223500: ********* epoch 23 ********* test accuracy for mode 2:0.0945 test loss: 254.236
223500: ********* epoch 23 ********* test accuracy for mode 24:0.2395 test loss: 282.939
223500: ********* epoch 23 ********* test accuracy for mode 25:0.293 test loss: 245.385
223500: ********* epoch 23 ********* test accuracy for mode 26:0.5145 test loss: 160.792
223500: ********* epoch 23 ********* test accuracy for mode 27:0.2205 test loss: 275.747
223500: ********* epoch 23 ********* test accuracy for mode 28:0.276 test loss: 266.422
223500: ********* epoch 23 ********* test accuracy for mode 29:0.222 test loss: 275.58
223500: ********* epoch 23 ********* test accuracy for mode 30:0.24 test loss: 252.089
223500: ********* epoch 23 ********* test accuracy for mode 31:0.2225 test loss: 250.941
223500: ********* epoch 23 ********* test accuracy for mode 32:0.208 test loss: 235.898
223500: ********* epoch 23 ********* test accuracy for mode 33:0.2665 test loss: 234.554
223500: ********* epoch 23 ********* test accuracy for mode 34:0.2605 test loss: 231.208
223500: ********* epoch 23 ********* test accuracy for mode 35:0.1465 test loss: 476.472
223500: ********* epoch 23 ********* test accuracy for mode 36:0.1945 test loss: 513.999
223510: accuracy:0.35 loss: 211.2 (lr:0.0001)
223520: accuracy:0.34 loss: 207.73 (lr:0.0001)
223530: accuracy:0.26 loss: 207.286 (lr:0.0001)
223540: accuracy:0.37 loss: 190.921 (lr:0.0001)
223550: accuracy:0.29 loss: 206.355 (lr:0.0001)
223560: accuracy:0.45 loss: 176.581 (lr:0.0001)
223570: accuracy:0.37 loss: 198.845 (lr:0.0001)
223580: accuracy:0.44 loss: 202.906 (lr:0.0001)
223590: accuracy:0.39 loss: 185.679 (lr:0.0001)
223600: accuracy:0.36 loss: 206.482 (lr:0.0001)
223610: accuracy:0.4 loss: 178.962 (lr:0.0001)
223620: accuracy:0.39 loss: 182.267 (lr:0.0001)
223630: accuracy:0.39 loss: 187.607 (lr:0.0001)
223640: accuracy:0.37 loss: 194.051 (lr:0.0001)
223650: accuracy:0.45 loss: 171.799 (lr:0.0001)
223660: accuracy:0.38 loss: 208.621 (lr:0.0001)
223670: accuracy:0.45 loss: 172.858 (lr:0.0001)
223680: accuracy:0.37 loss: 207.056 (lr:0.0001)
223690: accuracy:0.46 loss: 190.627 (lr:0.0001)
223700: accuracy:0.32 loss: 184.951 (lr:0.0001)
223710: accuracy:0.4 loss: 183.971 (lr:0.0001)
223720: accuracy:0.43 loss: 175.032 (lr:0.0001)
223730: accuracy:0.36 loss: 200.892 (lr:0.0001)
223740: accuracy:0.36 loss: 194.999 (lr:0.0001)
223750: accuracy:0.41 loss: 186.523 (lr:0.0001)
223760: accuracy:0.34 loss: 178.407 (lr:0.0001)
223770: accuracy:0.38 loss: 214.171 (lr:0.0001)
223780: accuracy:0.33 loss: 210.539 (lr:0.0001)
223790: accuracy:0.44 loss: 181.421 (lr:0.0001)
223800: accuracy:0.35 loss: 185.023 (lr:0.0001)
223810: accuracy:0.38 loss: 188.072 (lr:0.0001)
223820: accuracy:0.45 loss: 169.163 (lr:0.0001)
223830: accuracy:0.33 loss: 204.904 (lr:0.0001)
223840: accuracy:0.31 loss: 194.246 (lr:0.0001)
223850: accuracy:0.52 loss: 164.446 (lr:0.0001)
223860: accuracy:0.48 loss: 166.577 (lr:0.0001)
223870: accuracy:0.33 loss: 191.462 (lr:0.0001)
223880: accuracy:0.42 loss: 177.587 (lr:0.0001)
223890: accuracy:0.39 loss: 200.753 (lr:0.0001)
223900: accuracy:0.41 loss: 180.312 (lr:0.0001)
223910: accuracy:0.4 loss: 181.625 (lr:0.0001)
223920: accuracy:0.44 loss: 179.949 (lr:0.0001)
223930: accuracy:0.35 loss: 190.748 (lr:0.0001)
223940: accuracy:0.49 loss: 167.48 (lr:0.0001)
223950: accuracy:0.46 loss: 200.679 (lr:0.0001)
223960: accuracy:0.36 loss: 202.702 (lr:0.0001)
223970: accuracy:0.41 loss: 177.847 (lr:0.0001)
223980: accuracy:0.47 loss: 167.888 (lr:0.0001)
223990: accuracy:0.37 loss: 178.44 (lr:0.0001)
224000: accuracy:0.38 loss: 196.081 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
224000: ********* epoch 24 ********* test accuracy for all:0.264581 test loss: 265.298
224000: ********* epoch 24 ********* test accuracy for mode 0:0.0405 test loss: 521.772
224000: ********* epoch 24 ********* test accuracy for mode 1:0.0195 test loss: 493.869
224000: ********* epoch 24 ********* test accuracy for mode 2:0.1145 test loss: 253.815
224000: ********* epoch 24 ********* test accuracy for mode 24:0.197 test loss: 293.745
224000: ********* epoch 24 ********* test accuracy for mode 25:0.301 test loss: 249.418
224000: ********* epoch 24 ********* test accuracy for mode 26:0.4535 test loss: 168.673
224000: ********* epoch 24 ********* test accuracy for mode 27:0.2555 test loss: 276.769
224000: ********* epoch 24 ********* test accuracy for mode 28:0.2835 test loss: 270.155
224000: ********* epoch 24 ********* test accuracy for mode 29:0.2445 test loss: 275.229
224000: ********* epoch 24 ********* test accuracy for mode 30:0.251 test loss: 251.795
224000: ********* epoch 24 ********* test accuracy for mode 31:0.232 test loss: 248.881
224000: ********* epoch 24 ********* test accuracy for mode 32:0.2095 test loss: 232.224
224000: ********* epoch 24 ********* test accuracy for mode 33:0.26 test loss: 229.384
224000: ********* epoch 24 ********* test accuracy for mode 34:0.2995 test loss: 223.482
224000: ********* epoch 24 ********* test accuracy for mode 35:0.109 test loss: 483.755
224000: ********* epoch 24 ********* test accuracy for mode 36:0.266 test loss: 509.587
224010: accuracy:0.32 loss: 209.85 (lr:0.0001)
224020: accuracy:0.32 loss: 199.971 (lr:0.0001)
224030: accuracy:0.41 loss: 180.522 (lr:0.0001)
224040: accuracy:0.4 loss: 190.639 (lr:0.0001)
224050: accuracy:0.34 loss: 193.905 (lr:0.0001)
224060: accuracy:0.37 loss: 199.4 (lr:0.0001)
224070: accuracy:0.37 loss: 207.663 (lr:0.0001)
224080: accuracy:0.47 loss: 186.13 (lr:0.0001)
224090: accuracy:0.43 loss: 189.039 (lr:0.0001)
224100: accuracy:0.39 loss: 189.111 (lr:0.0001)
224110: accuracy:0.43 loss: 180.393 (lr:0.0001)
224120: accuracy:0.49 loss: 175.518 (lr:0.0001)
224130: accuracy:0.47 loss: 155.035 (lr:0.0001)
224140: accuracy:0.36 loss: 207.311 (lr:0.0001)
224150: accuracy:0.42 loss: 201.275 (lr:0.0001)
224160: accuracy:0.44 loss: 193.527 (lr:0.0001)
224170: accuracy:0.43 loss: 208.685 (lr:0.0001)
224180: accuracy:0.38 loss: 219.281 (lr:0.0001)
224190: accuracy:0.4 loss: 193.197 (lr:0.0001)
224200: accuracy:0.41 loss: 202.171 (lr:0.0001)
224210: accuracy:0.39 loss: 182.216 (lr:0.0001)
224220: accuracy:0.42 loss: 187.526 (lr:0.0001)
224230: accuracy:0.4 loss: 202.257 (lr:0.0001)
224240: accuracy:0.42 loss: 172.42 (lr:0.0001)
224250: accuracy:0.33 loss: 196.658 (lr:0.0001)
224260: accuracy:0.39 loss: 188.072 (lr:0.0001)
224270: accuracy:0.31 loss: 191.876 (lr:0.0001)
224280: accuracy:0.35 loss: 200.799 (lr:0.0001)
224290: accuracy:0.35 loss: 202.822 (lr:0.0001)
224300: accuracy:0.34 loss: 198.256 (lr:0.0001)
224310: accuracy:0.41 loss: 175.242 (lr:0.0001)
224320: accuracy:0.4 loss: 179.139 (lr:0.0001)
224330: accuracy:0.28 loss: 207.649 (lr:0.0001)
224340: accuracy:0.32 loss: 201.8 (lr:0.0001)
224350: accuracy:0.42 loss: 174.846 (lr:0.0001)
224360: accuracy:0.45 loss: 176.846 (lr:0.0001)
224370: accuracy:0.45 loss: 176.997 (lr:0.0001)
224380: accuracy:0.4 loss: 184.121 (lr:0.0001)
224390: accuracy:0.45 loss: 194.613 (lr:0.0001)
224400: accuracy:0.44 loss: 175.173 (lr:0.0001)
224410: accuracy:0.32 loss: 206.002 (lr:0.0001)
224420: accuracy:0.4 loss: 194.496 (lr:0.0001)
224430: accuracy:0.37 loss: 201.148 (lr:0.0001)
224440: accuracy:0.4 loss: 192.299 (lr:0.0001)
224450: accuracy:0.41 loss: 196.217 (lr:0.0001)
224460: accuracy:0.43 loss: 190.193 (lr:0.0001)
224470: accuracy:0.44 loss: 179.234 (lr:0.0001)
224480: accuracy:0.35 loss: 176.997 (lr:0.0001)
224490: accuracy:0.47 loss: 167.665 (lr:0.0001)
224500: accuracy:0.4 loss: 182.085 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
224500: ********* epoch 24 ********* test accuracy for all:0.260662 test loss: 266.468
224500: ********* epoch 24 ********* test accuracy for mode 0:0.041 test loss: 522.996
224500: ********* epoch 24 ********* test accuracy for mode 1:0.022 test loss: 495.306
224500: ********* epoch 24 ********* test accuracy for mode 2:0.079 test loss: 264.675
224500: ********* epoch 24 ********* test accuracy for mode 24:0.2615 test loss: 271.625
224500: ********* epoch 24 ********* test accuracy for mode 25:0.3485 test loss: 234.625
224500: ********* epoch 24 ********* test accuracy for mode 26:0.443 test loss: 160.078
224500: ********* epoch 24 ********* test accuracy for mode 27:0.2475 test loss: 268.293
224500: ********* epoch 24 ********* test accuracy for mode 28:0.278 test loss: 267.476
224500: ********* epoch 24 ********* test accuracy for mode 29:0.2535 test loss: 276.256
224500: ********* epoch 24 ********* test accuracy for mode 30:0.223 test loss: 258.593
224500: ********* epoch 24 ********* test accuracy for mode 31:0.2105 test loss: 257.177
224500: ********* epoch 24 ********* test accuracy for mode 32:0.202 test loss: 237.099
224500: ********* epoch 24 ********* test accuracy for mode 33:0.2925 test loss: 231.183
224500: ********* epoch 24 ********* test accuracy for mode 34:0.245 test loss: 234.937
224500: ********* epoch 24 ********* test accuracy for mode 35:0.0905 test loss: 508.601
224500: ********* epoch 24 ********* test accuracy for mode 36:0.067 test loss: 595.77
224510: accuracy:0.47 loss: 189.299 (lr:0.0001)
224520: accuracy:0.34 loss: 212.276 (lr:0.0001)
224530: accuracy:0.35 loss: 214.96 (lr:0.0001)
224540: accuracy:0.38 loss: 179.607 (lr:0.0001)
224550: accuracy:0.46 loss: 181.61 (lr:0.0001)
224560: accuracy:0.44 loss: 187.868 (lr:0.0001)
224570: accuracy:0.38 loss: 181.029 (lr:0.0001)
224580: accuracy:0.36 loss: 180.563 (lr:0.0001)
224590: accuracy:0.39 loss: 198.92 (lr:0.0001)
224600: accuracy:0.4 loss: 182.031 (lr:0.0001)
224610: accuracy:0.33 loss: 193.262 (lr:0.0001)
224620: accuracy:0.39 loss: 181.795 (lr:0.0001)
224630: accuracy:0.33 loss: 202.553 (lr:0.0001)
224640: accuracy:0.39 loss: 199.19 (lr:0.0001)
224650: accuracy:0.45 loss: 195.598 (lr:0.0001)
224660: accuracy:0.45 loss: 183.661 (lr:0.0001)
224670: accuracy:0.35 loss: 193.728 (lr:0.0001)
224680: accuracy:0.47 loss: 174.665 (lr:0.0001)
224690: accuracy:0.36 loss: 194.445 (lr:0.0001)
224700: accuracy:0.35 loss: 193.063 (lr:0.0001)
224710: accuracy:0.44 loss: 179.248 (lr:0.0001)
224720: accuracy:0.37 loss: 187.838 (lr:0.0001)
224730: accuracy:0.34 loss: 199.311 (lr:0.0001)
224740: accuracy:0.41 loss: 182.719 (lr:0.0001)
224750: accuracy:0.35 loss: 195.594 (lr:0.0001)
224760: accuracy:0.48 loss: 178.107 (lr:0.0001)
224770: accuracy:0.34 loss: 216.483 (lr:0.0001)
224780: accuracy:0.42 loss: 184.96 (lr:0.0001)
224790: accuracy:0.38 loss: 180.315 (lr:0.0001)
224800: accuracy:0.43 loss: 187.192 (lr:0.0001)
224810: accuracy:0.34 loss: 189.034 (lr:0.0001)
224820: accuracy:0.4 loss: 195.311 (lr:0.0001)
224830: accuracy:0.37 loss: 179.202 (lr:0.0001)
224840: accuracy:0.36 loss: 187.877 (lr:0.0001)
224850: accuracy:0.45 loss: 164.669 (lr:0.0001)
224860: accuracy:0.38 loss: 184.169 (lr:0.0001)
224870: accuracy:0.37 loss: 177.538 (lr:0.0001)
224880: accuracy:0.52 loss: 174.478 (lr:0.0001)
224890: accuracy:0.39 loss: 173.831 (lr:0.0001)
224900: accuracy:0.41 loss: 201.182 (lr:0.0001)
224910: accuracy:0.4 loss: 191.222 (lr:0.0001)
224920: accuracy:0.41 loss: 182.899 (lr:0.0001)
224930: accuracy:0.45 loss: 188.698 (lr:0.0001)
224940: accuracy:0.36 loss: 197.13 (lr:0.0001)
224950: accuracy:0.41 loss: 201.647 (lr:0.0001)
224960: accuracy:0.29 loss: 211.175 (lr:0.0001)
224970: accuracy:0.35 loss: 193.43 (lr:0.0001)
224980: accuracy:0.42 loss: 183.908 (lr:0.0001)
224990: accuracy:0.42 loss: 175.162 (lr:0.0001)
225000: accuracy:0.42 loss: 192.805 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
225000: ********* epoch 24 ********* test accuracy for all:0.261541 test loss: 262.855
225000: ********* epoch 24 ********* test accuracy for mode 0:0.038 test loss: 517.356
225000: ********* epoch 24 ********* test accuracy for mode 1:0.0265 test loss: 487.258
225000: ********* epoch 24 ********* test accuracy for mode 2:0.093 test loss: 256.92
225000: ********* epoch 24 ********* test accuracy for mode 24:0.2525 test loss: 274.857
225000: ********* epoch 24 ********* test accuracy for mode 25:0.275 test loss: 248.346
225000: ********* epoch 24 ********* test accuracy for mode 26:0.45 test loss: 163.862
225000: ********* epoch 24 ********* test accuracy for mode 27:0.2185 test loss: 273.234
225000: ********* epoch 24 ********* test accuracy for mode 28:0.2945 test loss: 263.984
225000: ********* epoch 24 ********* test accuracy for mode 29:0.242 test loss: 271.491
225000: ********* epoch 24 ********* test accuracy for mode 30:0.24 test loss: 252.033
225000: ********* epoch 24 ********* test accuracy for mode 31:0.2125 test loss: 254.246
225000: ********* epoch 24 ********* test accuracy for mode 32:0.211 test loss: 236.28
225000: ********* epoch 24 ********* test accuracy for mode 33:0.2385 test loss: 239.59
225000: ********* epoch 24 ********* test accuracy for mode 34:0.2485 test loss: 234.045
225000: ********* epoch 24 ********* test accuracy for mode 35:0.1645 test loss: 467.164
225000: ********* epoch 24 ********* test accuracy for mode 36:0.1235 test loss: 517.919
225010: accuracy:0.47 loss: 185.583 (lr:0.0001)
225020: accuracy:0.36 loss: 204.634 (lr:0.0001)
225030: accuracy:0.39 loss: 204.07 (lr:0.0001)
225040: accuracy:0.45 loss: 182.092 (lr:0.0001)
225050: accuracy:0.42 loss: 180.863 (lr:0.0001)
225060: accuracy:0.36 loss: 196.954 (lr:0.0001)
225070: accuracy:0.45 loss: 179.792 (lr:0.0001)
225080: accuracy:0.36 loss: 196.665 (lr:0.0001)
225090: accuracy:0.35 loss: 218.014 (lr:0.0001)
225100: accuracy:0.32 loss: 210.13 (lr:0.0001)
225110: accuracy:0.42 loss: 186.669 (lr:0.0001)
225120: accuracy:0.49 loss: 171.013 (lr:0.0001)
225130: accuracy:0.43 loss: 177.684 (lr:0.0001)
225140: accuracy:0.46 loss: 181.488 (lr:0.0001)
225150: accuracy:0.3 loss: 228.848 (lr:0.0001)
225160: accuracy:0.4 loss: 201.389 (lr:0.0001)
225170: accuracy:0.32 loss: 197.036 (lr:0.0001)
225180: accuracy:0.48 loss: 162.024 (lr:0.0001)
225190: accuracy:0.36 loss: 193.836 (lr:0.0001)
225200: accuracy:0.28 loss: 196.217 (lr:0.0001)
225210: accuracy:0.35 loss: 187.534 (lr:0.0001)
225220: accuracy:0.43 loss: 174.688 (lr:0.0001)
225230: accuracy:0.37 loss: 191.076 (lr:0.0001)
225240: accuracy:0.41 loss: 195.147 (lr:0.0001)
225250: accuracy:0.47 loss: 176.704 (lr:0.0001)
225260: accuracy:0.38 loss: 186.874 (lr:0.0001)
225270: accuracy:0.34 loss: 219.381 (lr:0.0001)
225280: accuracy:0.44 loss: 169.916 (lr:0.0001)
225290: accuracy:0.31 loss: 178.817 (lr:0.0001)
225300: accuracy:0.38 loss: 189.745 (lr:0.0001)
225310: accuracy:0.41 loss: 191.209 (lr:0.0001)
225320: accuracy:0.39 loss: 185.027 (lr:0.0001)
225330: accuracy:0.39 loss: 187.534 (lr:0.0001)
225340: accuracy:0.34 loss: 194.85 (lr:0.0001)
225350: accuracy:0.41 loss: 198.152 (lr:0.0001)
225360: accuracy:0.43 loss: 177.33 (lr:0.0001)
225370: accuracy:0.39 loss: 203.545 (lr:0.0001)
225380: accuracy:0.39 loss: 188.335 (lr:0.0001)
225390: accuracy:0.31 loss: 196.255 (lr:0.0001)
225400: accuracy:0.43 loss: 182.313 (lr:0.0001)
225410: accuracy:0.41 loss: 194.389 (lr:0.0001)
225420: accuracy:0.42 loss: 184.473 (lr:0.0001)
225430: accuracy:0.35 loss: 205.913 (lr:0.0001)
225440: accuracy:0.36 loss: 202.194 (lr:0.0001)
225450: accuracy:0.41 loss: 184.049 (lr:0.0001)
225460: accuracy:0.43 loss: 184.613 (lr:0.0001)
225470: accuracy:0.35 loss: 191.974 (lr:0.0001)
225480: accuracy:0.39 loss: 196.245 (lr:0.0001)
225490: accuracy:0.33 loss: 199.454 (lr:0.0001)
225500: accuracy:0.42 loss: 184.582 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
225500: ********* epoch 24 ********* test accuracy for all:0.26327 test loss: 264.482
225500: ********* epoch 24 ********* test accuracy for mode 0:0.037 test loss: 522.471
225500: ********* epoch 24 ********* test accuracy for mode 1:0.025 test loss: 498.722
225500: ********* epoch 24 ********* test accuracy for mode 2:0.094 test loss: 257.478
225500: ********* epoch 24 ********* test accuracy for mode 24:0.2145 test loss: 292.19
225500: ********* epoch 24 ********* test accuracy for mode 25:0.2485 test loss: 263.572
225500: ********* epoch 24 ********* test accuracy for mode 26:0.5365 test loss: 160.813
225500: ********* epoch 24 ********* test accuracy for mode 27:0.2135 test loss: 284.474
225500: ********* epoch 24 ********* test accuracy for mode 28:0.256 test loss: 281.763
225500: ********* epoch 24 ********* test accuracy for mode 29:0.239 test loss: 282.284
225500: ********* epoch 24 ********* test accuracy for mode 30:0.238 test loss: 254.627
225500: ********* epoch 24 ********* test accuracy for mode 31:0.202 test loss: 252.721
225500: ********* epoch 24 ********* test accuracy for mode 32:0.253 test loss: 229.03
225500: ********* epoch 24 ********* test accuracy for mode 33:0.2625 test loss: 235.263
225500: ********* epoch 24 ********* test accuracy for mode 34:0.2565 test loss: 235.443
225500: ********* epoch 24 ********* test accuracy for mode 35:0.114 test loss: 473.72
225500: ********* epoch 24 ********* test accuracy for mode 36:0.184 test loss: 518.088
225510: accuracy:0.3 loss: 198.917 (lr:0.0001)
225520: accuracy:0.43 loss: 163.973 (lr:0.0001)
225530: accuracy:0.37 loss: 188.069 (lr:0.0001)
225540: accuracy:0.26 loss: 229.873 (lr:0.0001)
225550: accuracy:0.43 loss: 188.864 (lr:0.0001)
225560: accuracy:0.35 loss: 195.074 (lr:0.0001)
225570: accuracy:0.37 loss: 188.522 (lr:0.0001)
225580: accuracy:0.43 loss: 183.684 (lr:0.0001)
225590: accuracy:0.4 loss: 192.188 (lr:0.0001)
225600: accuracy:0.36 loss: 210.806 (lr:0.0001)
225610: accuracy:0.49 loss: 179.418 (lr:0.0001)
225620: accuracy:0.44 loss: 156.552 (lr:0.0001)
225630: accuracy:0.33 loss: 210.034 (lr:0.0001)
225640: accuracy:0.38 loss: 193.452 (lr:0.0001)
225650: accuracy:0.42 loss: 182.642 (lr:0.0001)
225660: accuracy:0.45 loss: 185.5 (lr:0.0001)
225670: accuracy:0.47 loss: 165.433 (lr:0.0001)
225680: accuracy:0.33 loss: 201.042 (lr:0.0001)
225690: accuracy:0.34 loss: 196.878 (lr:0.0001)
225700: accuracy:0.39 loss: 193.632 (lr:0.0001)
225710: accuracy:0.45 loss: 171.475 (lr:0.0001)
225720: accuracy:0.3 loss: 204.947 (lr:0.0001)
225730: accuracy:0.33 loss: 212.555 (lr:0.0001)
225740: accuracy:0.38 loss: 169.883 (lr:0.0001)
225750: accuracy:0.4 loss: 178.109 (lr:0.0001)
225760: accuracy:0.42 loss: 189.284 (lr:0.0001)
225770: accuracy:0.41 loss: 203.146 (lr:0.0001)
225780: accuracy:0.46 loss: 188.984 (lr:0.0001)
225790: accuracy:0.37 loss: 189.768 (lr:0.0001)
225800: accuracy:0.37 loss: 196.899 (lr:0.0001)
225810: accuracy:0.47 loss: 167.634 (lr:0.0001)
225820: accuracy:0.35 loss: 182.068 (lr:0.0001)
225830: accuracy:0.37 loss: 199.383 (lr:0.0001)
225840: accuracy:0.36 loss: 198.376 (lr:0.0001)
225850: accuracy:0.26 loss: 215.648 (lr:0.0001)
225860: accuracy:0.33 loss: 205.146 (lr:0.0001)
225870: accuracy:0.4 loss: 179.867 (lr:0.0001)
225880: accuracy:0.39 loss: 206.46 (lr:0.0001)
225890: accuracy:0.32 loss: 191.547 (lr:0.0001)
225900: accuracy:0.4 loss: 185.243 (lr:0.0001)
225910: accuracy:0.44 loss: 196.156 (lr:0.0001)
225920: accuracy:0.38 loss: 198.612 (lr:0.0001)
225930: accuracy:0.46 loss: 177.574 (lr:0.0001)
225940: accuracy:0.46 loss: 174.979 (lr:0.0001)
225950: accuracy:0.43 loss: 170.868 (lr:0.0001)
225960: accuracy:0.42 loss: 189.446 (lr:0.0001)
225970: accuracy:0.41 loss: 183.714 (lr:0.0001)
225980: accuracy:0.47 loss: 172.04 (lr:0.0001)
225990: accuracy:0.36 loss: 186.965 (lr:0.0001)
226000: accuracy:0.34 loss: 190.328 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
226000: ********* epoch 24 ********* test accuracy for all:0.258216 test loss: 267.555
226000: ********* epoch 24 ********* test accuracy for mode 0:0.0355 test loss: 527.2
226000: ********* epoch 24 ********* test accuracy for mode 1:0.0205 test loss: 498.45
226000: ********* epoch 24 ********* test accuracy for mode 2:0.1105 test loss: 251.903
226000: ********* epoch 24 ********* test accuracy for mode 24:0.245 test loss: 286.655
226000: ********* epoch 24 ********* test accuracy for mode 25:0.2735 test loss: 255.016
226000: ********* epoch 24 ********* test accuracy for mode 26:0.426 test loss: 172.28
226000: ********* epoch 24 ********* test accuracy for mode 27:0.2415 test loss: 280.915
226000: ********* epoch 24 ********* test accuracy for mode 28:0.278 test loss: 272.86
226000: ********* epoch 24 ********* test accuracy for mode 29:0.229 test loss: 281.442
226000: ********* epoch 24 ********* test accuracy for mode 30:0.236 test loss: 256.791
226000: ********* epoch 24 ********* test accuracy for mode 31:0.196 test loss: 253.438
226000: ********* epoch 24 ********* test accuracy for mode 32:0.2295 test loss: 227.694
226000: ********* epoch 24 ********* test accuracy for mode 33:0.2955 test loss: 223.523
226000: ********* epoch 24 ********* test accuracy for mode 34:0.264 test loss: 224.954
226000: ********* epoch 24 ********* test accuracy for mode 35:0.1335 test loss: 481.189
226000: ********* epoch 24 ********* test accuracy for mode 36:0.11 test loss: 526.216
226010: accuracy:0.38 loss: 201.673 (lr:0.0001)
226020: accuracy:0.44 loss: 183.864 (lr:0.0001)
226030: accuracy:0.37 loss: 178.661 (lr:0.0001)
226040: accuracy:0.36 loss: 205.048 (lr:0.0001)
226050: accuracy:0.41 loss: 178.418 (lr:0.0001)
226060: accuracy:0.36 loss: 181.836 (lr:0.0001)
226070: accuracy:0.49 loss: 174.604 (lr:0.0001)
226080: accuracy:0.31 loss: 197.103 (lr:0.0001)
226090: accuracy:0.44 loss: 185.786 (lr:0.0001)
226100: accuracy:0.42 loss: 185.992 (lr:0.0001)
226110: accuracy:0.36 loss: 201.103 (lr:0.0001)
226120: accuracy:0.34 loss: 199.452 (lr:0.0001)
226130: accuracy:0.39 loss: 184.378 (lr:0.0001)
226140: accuracy:0.4 loss: 174.291 (lr:0.0001)
226150: accuracy:0.29 loss: 206.907 (lr:0.0001)
226160: accuracy:0.43 loss: 186.599 (lr:0.0001)
226170: accuracy:0.45 loss: 174.477 (lr:0.0001)
226180: accuracy:0.34 loss: 189.285 (lr:0.0001)
226190: accuracy:0.36 loss: 192.574 (lr:0.0001)
226200: accuracy:0.3 loss: 210.632 (lr:0.0001)
226210: accuracy:0.37 loss: 186.367 (lr:0.0001)
226220: accuracy:0.36 loss: 186.098 (lr:0.0001)
226230: accuracy:0.29 loss: 194.806 (lr:0.0001)
226240: accuracy:0.39 loss: 179.197 (lr:0.0001)
226250: accuracy:0.39 loss: 186.656 (lr:0.0001)
226260: accuracy:0.45 loss: 193.823 (lr:0.0001)
226270: accuracy:0.34 loss: 205.564 (lr:0.0001)
226280: accuracy:0.38 loss: 208.567 (lr:0.0001)
226290: accuracy:0.37 loss: 209.201 (lr:0.0001)
226300: accuracy:0.4 loss: 196.012 (lr:0.0001)
226310: accuracy:0.33 loss: 194.946 (lr:0.0001)
226320: accuracy:0.32 loss: 211.591 (lr:0.0001)
226330: accuracy:0.41 loss: 170.401 (lr:0.0001)
226340: accuracy:0.38 loss: 183.958 (lr:0.0001)
226350: accuracy:0.38 loss: 201.441 (lr:0.0001)
226360: accuracy:0.43 loss: 176.535 (lr:0.0001)
226370: accuracy:0.42 loss: 200.591 (lr:0.0001)
226380: accuracy:0.39 loss: 185.297 (lr:0.0001)
226390: accuracy:0.42 loss: 186.858 (lr:0.0001)
226400: accuracy:0.39 loss: 182.13 (lr:0.0001)
226410: accuracy:0.44 loss: 184.803 (lr:0.0001)
226420: accuracy:0.4 loss: 208.812 (lr:0.0001)
226430: accuracy:0.44 loss: 183.57 (lr:0.0001)
226440: accuracy:0.42 loss: 194.332 (lr:0.0001)
226450: accuracy:0.36 loss: 190.775 (lr:0.0001)
226460: accuracy:0.37 loss: 200.117 (lr:0.0001)
226470: accuracy:0.45 loss: 190.946 (lr:0.0001)
226480: accuracy:0.4 loss: 185.117 (lr:0.0001)
226490: accuracy:0.39 loss: 182.558 (lr:0.0001)
226500: accuracy:0.35 loss: 194.652 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
226500: ********* epoch 24 ********* test accuracy for all:0.25777 test loss: 269.629
226500: ********* epoch 24 ********* test accuracy for mode 0:0.0465 test loss: 517.653
226500: ********* epoch 24 ********* test accuracy for mode 1:0.023 test loss: 499.534
226500: ********* epoch 24 ********* test accuracy for mode 2:0.1 test loss: 251.082
226500: ********* epoch 24 ********* test accuracy for mode 24:0.247 test loss: 288.31
226500: ********* epoch 24 ********* test accuracy for mode 25:0.269 test loss: 258.86
226500: ********* epoch 24 ********* test accuracy for mode 26:0.441 test loss: 170.516
226500: ********* epoch 24 ********* test accuracy for mode 27:0.2485 test loss: 279.818
226500: ********* epoch 24 ********* test accuracy for mode 28:0.2775 test loss: 275.16
226500: ********* epoch 24 ********* test accuracy for mode 29:0.2255 test loss: 286.205
226500: ********* epoch 24 ********* test accuracy for mode 30:0.2575 test loss: 255.973
226500: ********* epoch 24 ********* test accuracy for mode 31:0.217 test loss: 255.152
226500: ********* epoch 24 ********* test accuracy for mode 32:0.195 test loss: 235.434
226500: ********* epoch 24 ********* test accuracy for mode 33:0.2965 test loss: 228.391
226500: ********* epoch 24 ********* test accuracy for mode 34:0.265 test loss: 226.548
226500: ********* epoch 24 ********* test accuracy for mode 35:0.1205 test loss: 482.869
226500: ********* epoch 24 ********* test accuracy for mode 36:0.1105 test loss: 545.375
226510: accuracy:0.36 loss: 188.752 (lr:0.0001)
226520: accuracy:0.45 loss: 181.527 (lr:0.0001)
226530: accuracy:0.4 loss: 192.961 (lr:0.0001)
226540: accuracy:0.41 loss: 189.013 (lr:0.0001)
226550: accuracy:0.43 loss: 182.654 (lr:0.0001)
226560: accuracy:0.43 loss: 155.396 (lr:0.0001)
226570: accuracy:0.5 loss: 172.109 (lr:0.0001)
226580: accuracy:0.43 loss: 185.994 (lr:0.0001)
226590: accuracy:0.38 loss: 198.873 (lr:0.0001)
226600: accuracy:0.46 loss: 167.159 (lr:0.0001)
226610: accuracy:0.5 loss: 175.771 (lr:0.0001)
226620: accuracy:0.42 loss: 174.39 (lr:0.0001)
226630: accuracy:0.5 loss: 177.053 (lr:0.0001)
226640: accuracy:0.45 loss: 187.612 (lr:0.0001)
226650: accuracy:0.5 loss: 162.593 (lr:0.0001)
226660: accuracy:0.4 loss: 173.99 (lr:0.0001)
226670: accuracy:0.37 loss: 200.686 (lr:0.0001)
226680: accuracy:0.32 loss: 194.886 (lr:0.0001)
226690: accuracy:0.32 loss: 195.021 (lr:0.0001)
226700: accuracy:0.42 loss: 196.111 (lr:0.0001)
226710: accuracy:0.38 loss: 184.185 (lr:0.0001)
226720: accuracy:0.41 loss: 198.55 (lr:0.0001)
226730: accuracy:0.41 loss: 181.967 (lr:0.0001)
226740: accuracy:0.35 loss: 209.495 (lr:0.0001)
226750: accuracy:0.4 loss: 211.76 (lr:0.0001)
226760: accuracy:0.46 loss: 174.981 (lr:0.0001)
226770: accuracy:0.43 loss: 178.897 (lr:0.0001)
226780: accuracy:0.43 loss: 165.602 (lr:0.0001)
226790: accuracy:0.39 loss: 203.774 (lr:0.0001)
226800: accuracy:0.44 loss: 181.932 (lr:0.0001)
226810: accuracy:0.42 loss: 208.174 (lr:0.0001)
226820: accuracy:0.44 loss: 189.812 (lr:0.0001)
226830: accuracy:0.36 loss: 207.724 (lr:0.0001)
226840: accuracy:0.44 loss: 158.97 (lr:0.0001)
226850: accuracy:0.41 loss: 192.072 (lr:0.0001)
226860: accuracy:0.44 loss: 177.335 (lr:0.0001)
226870: accuracy:0.34 loss: 200.45 (lr:0.0001)
226880: accuracy:0.34 loss: 191.961 (lr:0.0001)
226890: accuracy:0.43 loss: 174.594 (lr:0.0001)
226900: accuracy:0.42 loss: 170.164 (lr:0.0001)
226910: accuracy:0.32 loss: 196.292 (lr:0.0001)
226920: accuracy:0.34 loss: 193.925 (lr:0.0001)
226930: accuracy:0.39 loss: 188.89 (lr:0.0001)
226940: accuracy:0.29 loss: 182.966 (lr:0.0001)
226950: accuracy:0.38 loss: 187.98 (lr:0.0001)
226960: accuracy:0.37 loss: 195.01 (lr:0.0001)
226970: accuracy:0.43 loss: 187.786 (lr:0.0001)
226980: accuracy:0.45 loss: 201.446 (lr:0.0001)
226990: accuracy:0.43 loss: 171.251 (lr:0.0001)
227000: accuracy:0.28 loss: 186.695 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
227000: ********* epoch 24 ********* test accuracy for all:0.263135 test loss: 265.771
227000: ********* epoch 24 ********* test accuracy for mode 0:0.0355 test loss: 527.825
227000: ********* epoch 24 ********* test accuracy for mode 1:0.0235 test loss: 501.708
227000: ********* epoch 24 ********* test accuracy for mode 2:0.1 test loss: 254.584
227000: ********* epoch 24 ********* test accuracy for mode 24:0.2465 test loss: 281.694
227000: ********* epoch 24 ********* test accuracy for mode 25:0.2835 test loss: 249.599
227000: ********* epoch 24 ********* test accuracy for mode 26:0.4485 test loss: 169.888
227000: ********* epoch 24 ********* test accuracy for mode 27:0.275 test loss: 265.301
227000: ********* epoch 24 ********* test accuracy for mode 28:0.296 test loss: 261.686
227000: ********* epoch 24 ********* test accuracy for mode 29:0.237 test loss: 272.765
227000: ********* epoch 24 ********* test accuracy for mode 30:0.278 test loss: 245.329
227000: ********* epoch 24 ********* test accuracy for mode 31:0.213 test loss: 247.227
227000: ********* epoch 24 ********* test accuracy for mode 32:0.2285 test loss: 226.14
227000: ********* epoch 24 ********* test accuracy for mode 33:0.286 test loss: 226.413
227000: ********* epoch 24 ********* test accuracy for mode 34:0.2315 test loss: 230.059
227000: ********* epoch 24 ********* test accuracy for mode 35:0.1375 test loss: 488.872
227000: ********* epoch 24 ********* test accuracy for mode 36:0.0895 test loss: 546.122
227010: accuracy:0.32 loss: 210.813 (lr:0.0001)
227020: accuracy:0.4 loss: 184.154 (lr:0.0001)
227030: accuracy:0.36 loss: 194.433 (lr:0.0001)
227040: accuracy:0.38 loss: 195.294 (lr:0.0001)
227050: accuracy:0.26 loss: 219.575 (lr:0.0001)
227060: accuracy:0.42 loss: 182.655 (lr:0.0001)
227070: accuracy:0.34 loss: 182.767 (lr:0.0001)
227080: accuracy:0.33 loss: 205.228 (lr:0.0001)
227090: accuracy:0.45 loss: 176.31 (lr:0.0001)
227100: accuracy:0.42 loss: 189.374 (lr:0.0001)
227110: accuracy:0.32 loss: 196.346 (lr:0.0001)
227120: accuracy:0.36 loss: 203.704 (lr:0.0001)
227130: accuracy:0.37 loss: 184.817 (lr:0.0001)
227140: accuracy:0.42 loss: 195.835 (lr:0.0001)
227150: accuracy:0.44 loss: 171.389 (lr:0.0001)
227160: accuracy:0.49 loss: 191.926 (lr:0.0001)
227170: accuracy:0.45 loss: 177.95 (lr:0.0001)
227180: accuracy:0.37 loss: 182.517 (lr:0.0001)
227190: accuracy:0.55 loss: 165.637 (lr:0.0001)
227200: accuracy:0.45 loss: 175.929 (lr:0.0001)
227210: accuracy:0.36 loss: 187.824 (lr:0.0001)
227220: accuracy:0.48 loss: 167.391 (lr:0.0001)
227230: accuracy:0.34 loss: 204.459 (lr:0.0001)
227240: accuracy:0.36 loss: 187.532 (lr:0.0001)
227250: accuracy:0.41 loss: 203.816 (lr:0.0001)
227260: accuracy:0.39 loss: 183.483 (lr:0.0001)
227270: accuracy:0.4 loss: 198.216 (lr:0.0001)
227280: accuracy:0.4 loss: 193.559 (lr:0.0001)
227290: accuracy:0.39 loss: 188.906 (lr:0.0001)
227300: accuracy:0.31 loss: 207.03 (lr:0.0001)
227310: accuracy:0.42 loss: 187.669 (lr:0.0001)
227320: accuracy:0.42 loss: 182.057 (lr:0.0001)
227330: accuracy:0.31 loss: 187.81 (lr:0.0001)
227340: accuracy:0.38 loss: 194.984 (lr:0.0001)
227350: accuracy:0.37 loss: 193.638 (lr:0.0001)
227360: accuracy:0.5 loss: 187.962 (lr:0.0001)
227370: accuracy:0.33 loss: 228.643 (lr:0.0001)
227380: accuracy:0.42 loss: 167.958 (lr:0.0001)
227390: accuracy:0.48 loss: 159.115 (lr:0.0001)
227400: accuracy:0.33 loss: 202.969 (lr:0.0001)
227410: accuracy:0.41 loss: 212.057 (lr:0.0001)
227420: accuracy:0.4 loss: 200.591 (lr:0.0001)
227430: accuracy:0.46 loss: 177.562 (lr:0.0001)
227440: accuracy:0.37 loss: 182.333 (lr:0.0001)
227450: accuracy:0.4 loss: 193.459 (lr:0.0001)
227460: accuracy:0.39 loss: 187.791 (lr:0.0001)
227470: accuracy:0.33 loss: 204.021 (lr:0.0001)
227480: accuracy:0.47 loss: 171.116 (lr:0.0001)
227490: accuracy:0.38 loss: 193.365 (lr:0.0001)
227500: accuracy:0.38 loss: 206.772 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
227500: ********* epoch 24 ********* test accuracy for all:0.259986 test loss: 267.724
227500: ********* epoch 24 ********* test accuracy for mode 0:0.0305 test loss: 520.375
227500: ********* epoch 24 ********* test accuracy for mode 1:0.0285 test loss: 488.625
227500: ********* epoch 24 ********* test accuracy for mode 2:0.105 test loss: 258.328
227500: ********* epoch 24 ********* test accuracy for mode 24:0.2315 test loss: 290.744
227500: ********* epoch 24 ********* test accuracy for mode 25:0.296 test loss: 252.998
227500: ********* epoch 24 ********* test accuracy for mode 26:0.462 test loss: 167.152
227500: ********* epoch 24 ********* test accuracy for mode 27:0.2315 test loss: 289.691
227500: ********* epoch 24 ********* test accuracy for mode 28:0.279 test loss: 283.749
227500: ********* epoch 24 ********* test accuracy for mode 29:0.2155 test loss: 296.726
227500: ********* epoch 24 ********* test accuracy for mode 30:0.2335 test loss: 270.711
227500: ********* epoch 24 ********* test accuracy for mode 31:0.1805 test loss: 272.217
227500: ********* epoch 24 ********* test accuracy for mode 32:0.2185 test loss: 242.056
227500: ********* epoch 24 ********* test accuracy for mode 33:0.2735 test loss: 238.976
227500: ********* epoch 24 ********* test accuracy for mode 34:0.249 test loss: 235.847
227500: ********* epoch 24 ********* test accuracy for mode 35:0.136 test loss: 485.385
227500: ********* epoch 24 ********* test accuracy for mode 36:0.1 test loss: 556.659
227510: accuracy:0.36 loss: 208.672 (lr:0.0001)
227520: accuracy:0.35 loss: 208.344 (lr:0.0001)
227530: accuracy:0.42 loss: 210.083 (lr:0.0001)
227540: accuracy:0.36 loss: 179.486 (lr:0.0001)
227550: accuracy:0.39 loss: 192.682 (lr:0.0001)
227560: accuracy:0.3 loss: 209.684 (lr:0.0001)
227570: accuracy:0.38 loss: 174.062 (lr:0.0001)
227580: accuracy:0.23 loss: 224.412 (lr:0.0001)
227590: accuracy:0.55 loss: 156.547 (lr:0.0001)
227600: accuracy:0.35 loss: 204.837 (lr:0.0001)
227610: accuracy:0.41 loss: 198.344 (lr:0.0001)
227620: accuracy:0.45 loss: 178.669 (lr:0.0001)
227630: accuracy:0.32 loss: 214.017 (lr:0.0001)
227640: accuracy:0.42 loss: 201.852 (lr:0.0001)
227650: accuracy:0.43 loss: 191.311 (lr:0.0001)
227660: accuracy:0.44 loss: 186.63 (lr:0.0001)
227670: accuracy:0.33 loss: 204.639 (lr:0.0001)
227680: accuracy:0.35 loss: 190.059 (lr:0.0001)
227690: accuracy:0.35 loss: 188.705 (lr:0.0001)
227700: accuracy:0.38 loss: 185.355 (lr:0.0001)
227710: accuracy:0.38 loss: 192.166 (lr:0.0001)
227720: accuracy:0.37 loss: 198.146 (lr:0.0001)
227730: accuracy:0.46 loss: 185.683 (lr:0.0001)
227740: accuracy:0.44 loss: 176.505 (lr:0.0001)
227750: accuracy:0.45 loss: 173.947 (lr:0.0001)
227760: accuracy:0.42 loss: 197.46 (lr:0.0001)
227770: accuracy:0.36 loss: 205.436 (lr:0.0001)
227780: accuracy:0.41 loss: 192.981 (lr:0.0001)
227790: accuracy:0.28 loss: 208.451 (lr:0.0001)
227800: accuracy:0.45 loss: 167.904 (lr:0.0001)
227810: accuracy:0.38 loss: 187.765 (lr:0.0001)
227820: accuracy:0.42 loss: 188.206 (lr:0.0001)
227830: accuracy:0.35 loss: 194.24 (lr:0.0001)
227840: accuracy:0.43 loss: 183.18 (lr:0.0001)
227850: accuracy:0.29 loss: 203.959 (lr:0.0001)
227860: accuracy:0.42 loss: 197.981 (lr:0.0001)
227870: accuracy:0.37 loss: 215.257 (lr:0.0001)
227880: accuracy:0.41 loss: 181.142 (lr:0.0001)
227890: accuracy:0.38 loss: 189.274 (lr:0.0001)
227900: accuracy:0.31 loss: 198.674 (lr:0.0001)
227910: accuracy:0.31 loss: 204.302 (lr:0.0001)
227920: accuracy:0.43 loss: 176.331 (lr:0.0001)
227930: accuracy:0.43 loss: 176.802 (lr:0.0001)
227940: accuracy:0.36 loss: 199.251 (lr:0.0001)
227950: accuracy:0.46 loss: 183.411 (lr:0.0001)
227960: accuracy:0.38 loss: 190.565 (lr:0.0001)
227970: accuracy:0.4 loss: 201.569 (lr:0.0001)
227980: accuracy:0.27 loss: 202.967 (lr:0.0001)
227990: accuracy:0.36 loss: 203.801 (lr:0.0001)
228000: accuracy:0.28 loss: 222.514 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
228000: ********* epoch 24 ********* test accuracy for all:0.263811 test loss: 263.463
228000: ********* epoch 24 ********* test accuracy for mode 0:0.0385 test loss: 517.973
228000: ********* epoch 24 ********* test accuracy for mode 1:0.023 test loss: 491.897
228000: ********* epoch 24 ********* test accuracy for mode 2:0.1355 test loss: 253.06
228000: ********* epoch 24 ********* test accuracy for mode 24:0.241 test loss: 282.516
228000: ********* epoch 24 ********* test accuracy for mode 25:0.289 test loss: 247.095
228000: ********* epoch 24 ********* test accuracy for mode 26:0.449 test loss: 167.779
228000: ********* epoch 24 ********* test accuracy for mode 27:0.25 test loss: 273.98
228000: ********* epoch 24 ********* test accuracy for mode 28:0.2905 test loss: 264.559
228000: ********* epoch 24 ********* test accuracy for mode 29:0.234 test loss: 274.171
228000: ********* epoch 24 ********* test accuracy for mode 30:0.258 test loss: 251.745
228000: ********* epoch 24 ********* test accuracy for mode 31:0.192 test loss: 255.199
228000: ********* epoch 24 ********* test accuracy for mode 32:0.233 test loss: 230.618
228000: ********* epoch 24 ********* test accuracy for mode 33:0.277 test loss: 230.048
228000: ********* epoch 24 ********* test accuracy for mode 34:0.265 test loss: 228.196
228000: ********* epoch 24 ********* test accuracy for mode 35:0.1555 test loss: 465.068
228000: ********* epoch 24 ********* test accuracy for mode 36:0.1045 test loss: 523.945
228010: accuracy:0.41 loss: 187.104 (lr:0.0001)
228020: accuracy:0.33 loss: 214.0 (lr:0.0001)
228030: accuracy:0.48 loss: 173.623 (lr:0.0001)
228040: accuracy:0.45 loss: 187.351 (lr:0.0001)
228050: accuracy:0.38 loss: 179.712 (lr:0.0001)
228060: accuracy:0.4 loss: 199.152 (lr:0.0001)
228070: accuracy:0.46 loss: 182.119 (lr:0.0001)
228080: accuracy:0.46 loss: 166.914 (lr:0.0001)
228090: accuracy:0.35 loss: 199.96 (lr:0.0001)
228100: accuracy:0.44 loss: 183.409 (lr:0.0001)
228110: accuracy:0.42 loss: 183.032 (lr:0.0001)
228120: accuracy:0.42 loss: 181.157 (lr:0.0001)
228130: accuracy:0.28 loss: 223.474 (lr:0.0001)
228140: accuracy:0.39 loss: 205.776 (lr:0.0001)
228150: accuracy:0.42 loss: 188.565 (lr:0.0001)
228160: accuracy:0.33 loss: 199.385 (lr:0.0001)
228170: accuracy:0.42 loss: 191.24 (lr:0.0001)
228180: accuracy:0.31 loss: 207.528 (lr:0.0001)
228190: accuracy:0.37 loss: 194.686 (lr:0.0001)
228200: accuracy:0.34 loss: 199.199 (lr:0.0001)
228210: accuracy:0.41 loss: 187.554 (lr:0.0001)
228220: accuracy:0.41 loss: 193.536 (lr:0.0001)
228230: accuracy:0.49 loss: 188.19 (lr:0.0001)
228240: accuracy:0.49 loss: 172.864 (lr:0.0001)
228250: accuracy:0.41 loss: 184.644 (lr:0.0001)
228260: accuracy:0.36 loss: 198.131 (lr:0.0001)
228270: accuracy:0.36 loss: 199.235 (lr:0.0001)
228280: accuracy:0.37 loss: 191.841 (lr:0.0001)
228290: accuracy:0.43 loss: 164.683 (lr:0.0001)
228300: accuracy:0.44 loss: 182.16 (lr:0.0001)
228310: accuracy:0.32 loss: 190.272 (lr:0.0001)
228320: accuracy:0.43 loss: 183.323 (lr:0.0001)
228330: accuracy:0.32 loss: 209.02 (lr:0.0001)
228340: accuracy:0.33 loss: 194.901 (lr:0.0001)
228350: accuracy:0.42 loss: 186.481 (lr:0.0001)
228360: accuracy:0.39 loss: 196.807 (lr:0.0001)
228370: accuracy:0.47 loss: 181.732 (lr:0.0001)
228380: accuracy:0.35 loss: 188.614 (lr:0.0001)
228390: accuracy:0.31 loss: 199.627 (lr:0.0001)
228400: accuracy:0.36 loss: 190.765 (lr:0.0001)
228410: accuracy:0.47 loss: 184.457 (lr:0.0001)
228420: accuracy:0.48 loss: 179.424 (lr:0.0001)
228430: accuracy:0.45 loss: 185.343 (lr:0.0001)
228440: accuracy:0.4 loss: 199.426 (lr:0.0001)
228450: accuracy:0.35 loss: 204.872 (lr:0.0001)
228460: accuracy:0.38 loss: 204.07 (lr:0.0001)
228470: accuracy:0.34 loss: 185.024 (lr:0.0001)
228480: accuracy:0.39 loss: 189.835 (lr:0.0001)
228490: accuracy:0.38 loss: 203.848 (lr:0.0001)
228500: accuracy:0.46 loss: 184.155 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
228500: ********* epoch 24 ********* test accuracy for all:0.260689 test loss: 269.082
228500: ********* epoch 24 ********* test accuracy for mode 0:0.0415 test loss: 530.269
228500: ********* epoch 24 ********* test accuracy for mode 1:0.0255 test loss: 514.453
228500: ********* epoch 24 ********* test accuracy for mode 2:0.1065 test loss: 250.628
228500: ********* epoch 24 ********* test accuracy for mode 24:0.233 test loss: 290.76
228500: ********* epoch 24 ********* test accuracy for mode 25:0.253 test loss: 262.384
228500: ********* epoch 24 ********* test accuracy for mode 26:0.476 test loss: 171.835
228500: ********* epoch 24 ********* test accuracy for mode 27:0.248 test loss: 274.583
228500: ********* epoch 24 ********* test accuracy for mode 28:0.302 test loss: 267.673
228500: ********* epoch 24 ********* test accuracy for mode 29:0.236 test loss: 278.341
228500: ********* epoch 24 ********* test accuracy for mode 30:0.2385 test loss: 254.573
228500: ********* epoch 24 ********* test accuracy for mode 31:0.214 test loss: 250.465
228500: ********* epoch 24 ********* test accuracy for mode 32:0.1965 test loss: 229.57
228500: ********* epoch 24 ********* test accuracy for mode 33:0.322 test loss: 221.935
228500: ********* epoch 24 ********* test accuracy for mode 34:0.2925 test loss: 220.217
228500: ********* epoch 24 ********* test accuracy for mode 35:0.13 test loss: 495.689
228500: ********* epoch 24 ********* test accuracy for mode 36:0.0765 test loss: 555.239
228510: accuracy:0.34 loss: 206.27 (lr:0.0001)
228520: accuracy:0.41 loss: 186.083 (lr:0.0001)
228530: accuracy:0.28 loss: 192.601 (lr:0.0001)
228540: accuracy:0.46 loss: 182.668 (lr:0.0001)
228550: accuracy:0.43 loss: 196.585 (lr:0.0001)
228560: accuracy:0.37 loss: 184.404 (lr:0.0001)
228570: accuracy:0.4 loss: 193.194 (lr:0.0001)
228580: accuracy:0.43 loss: 166.798 (lr:0.0001)
228590: accuracy:0.4 loss: 163.818 (lr:0.0001)
228600: accuracy:0.42 loss: 171.21 (lr:0.0001)
228610: accuracy:0.43 loss: 203.218 (lr:0.0001)
228620: accuracy:0.45 loss: 183.131 (lr:0.0001)
228630: accuracy:0.44 loss: 166.975 (lr:0.0001)
228640: accuracy:0.28 loss: 213.282 (lr:0.0001)
228650: accuracy:0.3 loss: 205.508 (lr:0.0001)
228660: accuracy:0.37 loss: 199.303 (lr:0.0001)
228670: accuracy:0.52 loss: 172.484 (lr:0.0001)
228680: accuracy:0.38 loss: 195.038 (lr:0.0001)
228690: accuracy:0.44 loss: 168.771 (lr:0.0001)
228700: accuracy:0.52 loss: 174.789 (lr:0.0001)
228710: accuracy:0.39 loss: 189.458 (lr:0.0001)
228720: accuracy:0.49 loss: 170.345 (lr:0.0001)
228730: accuracy:0.4 loss: 191.319 (lr:0.0001)
228740: accuracy:0.35 loss: 190.737 (lr:0.0001)
228750: accuracy:0.31 loss: 219.248 (lr:0.0001)
228760: accuracy:0.35 loss: 199.65 (lr:0.0001)
228770: accuracy:0.41 loss: 177.218 (lr:0.0001)
228780: accuracy:0.3 loss: 198.64 (lr:0.0001)
228790: accuracy:0.35 loss: 193.013 (lr:0.0001)
228800: accuracy:0.5 loss: 169.675 (lr:0.0001)
228810: accuracy:0.33 loss: 196.711 (lr:0.0001)
228820: accuracy:0.41 loss: 197.94 (lr:0.0001)
228830: accuracy:0.37 loss: 198.617 (lr:0.0001)
228840: accuracy:0.43 loss: 180.714 (lr:0.0001)
228850: accuracy:0.48 loss: 174.837 (lr:0.0001)
228860: accuracy:0.38 loss: 194.752 (lr:0.0001)
228870: accuracy:0.43 loss: 182.017 (lr:0.0001)
228880: accuracy:0.37 loss: 181.366 (lr:0.0001)
228890: accuracy:0.4 loss: 177.462 (lr:0.0001)
228900: accuracy:0.4 loss: 183.636 (lr:0.0001)
228910: accuracy:0.44 loss: 197.364 (lr:0.0001)
228920: accuracy:0.41 loss: 197.61 (lr:0.0001)
228930: accuracy:0.38 loss: 194.345 (lr:0.0001)
228940: accuracy:0.47 loss: 180.839 (lr:0.0001)
228950: accuracy:0.34 loss: 187.231 (lr:0.0001)
228960: accuracy:0.31 loss: 198.458 (lr:0.0001)
228970: accuracy:0.4 loss: 201.152 (lr:0.0001)
228980: accuracy:0.39 loss: 208.212 (lr:0.0001)
228990: accuracy:0.41 loss: 181.983 (lr:0.0001)
229000: accuracy:0.37 loss: 184.257 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
229000: ********* epoch 24 ********* test accuracy for all:0.258203 test loss: 270.098
229000: ********* epoch 24 ********* test accuracy for mode 0:0.0245 test loss: 537.742
229000: ********* epoch 24 ********* test accuracy for mode 1:0.0225 test loss: 508.294
229000: ********* epoch 24 ********* test accuracy for mode 2:0.0935 test loss: 254.588
229000: ********* epoch 24 ********* test accuracy for mode 24:0.2365 test loss: 285.587
229000: ********* epoch 24 ********* test accuracy for mode 25:0.282 test loss: 249.265
229000: ********* epoch 24 ********* test accuracy for mode 26:0.474 test loss: 167.506
229000: ********* epoch 24 ********* test accuracy for mode 27:0.2475 test loss: 274.656
229000: ********* epoch 24 ********* test accuracy for mode 28:0.26 test loss: 274.348
229000: ********* epoch 24 ********* test accuracy for mode 29:0.2345 test loss: 279.423
229000: ********* epoch 24 ********* test accuracy for mode 30:0.273 test loss: 252.85
229000: ********* epoch 24 ********* test accuracy for mode 31:0.206 test loss: 260.786
229000: ********* epoch 24 ********* test accuracy for mode 32:0.2195 test loss: 237.446
229000: ********* epoch 24 ********* test accuracy for mode 33:0.2725 test loss: 233.08
229000: ********* epoch 24 ********* test accuracy for mode 34:0.273 test loss: 230.945
229000: ********* epoch 24 ********* test accuracy for mode 35:0.11 test loss: 503.337
229000: ********* epoch 24 ********* test accuracy for mode 36:0.068 test loss: 604.688
229010: accuracy:0.41 loss: 193.393 (lr:0.0001)
229020: accuracy:0.39 loss: 193.713 (lr:0.0001)
229030: accuracy:0.42 loss: 182.629 (lr:0.0001)
229040: accuracy:0.39 loss: 183.696 (lr:0.0001)
229050: accuracy:0.38 loss: 198.052 (lr:0.0001)
229060: accuracy:0.42 loss: 188.913 (lr:0.0001)
229070: accuracy:0.36 loss: 195.223 (lr:0.0001)
229080: accuracy:0.41 loss: 178.332 (lr:0.0001)
229090: accuracy:0.36 loss: 193.31 (lr:0.0001)
229100: accuracy:0.38 loss: 187.639 (lr:0.0001)
229110: accuracy:0.39 loss: 182.509 (lr:0.0001)
229120: accuracy:0.42 loss: 191.563 (lr:0.0001)
229130: accuracy:0.36 loss: 187.891 (lr:0.0001)
229140: accuracy:0.37 loss: 196.074 (lr:0.0001)
229150: accuracy:0.44 loss: 165.628 (lr:0.0001)
229160: accuracy:0.32 loss: 208.803 (lr:0.0001)
229170: accuracy:0.36 loss: 179.102 (lr:0.0001)
229180: accuracy:0.36 loss: 194.619 (lr:0.0001)
229190: accuracy:0.36 loss: 177.825 (lr:0.0001)
229200: accuracy:0.35 loss: 188.447 (lr:0.0001)
229210: accuracy:0.38 loss: 190.582 (lr:0.0001)
229220: accuracy:0.37 loss: 196.001 (lr:0.0001)
229230: accuracy:0.39 loss: 189.821 (lr:0.0001)
229240: accuracy:0.42 loss: 183.424 (lr:0.0001)
229250: accuracy:0.36 loss: 187.284 (lr:0.0001)
229260: accuracy:0.42 loss: 186.388 (lr:0.0001)
229270: accuracy:0.43 loss: 187.999 (lr:0.0001)
229280: accuracy:0.3 loss: 215.129 (lr:0.0001)
229290: accuracy:0.34 loss: 201.394 (lr:0.0001)
229300: accuracy:0.39 loss: 208.671 (lr:0.0001)
229310: accuracy:0.44 loss: 190.469 (lr:0.0001)
229320: accuracy:0.38 loss: 189.065 (lr:0.0001)
229330: accuracy:0.4 loss: 202.982 (lr:0.0001)
229340: accuracy:0.37 loss: 195.417 (lr:0.0001)
229350: accuracy:0.39 loss: 194.194 (lr:0.0001)
229360: accuracy:0.44 loss: 184.76 (lr:0.0001)
229370: accuracy:0.34 loss: 204.418 (lr:0.0001)
229380: accuracy:0.41 loss: 177.211 (lr:0.0001)
229390: accuracy:0.46 loss: 186.226 (lr:0.0001)
229400: accuracy:0.38 loss: 193.919 (lr:0.0001)
229410: accuracy:0.38 loss: 188.833 (lr:0.0001)
229420: accuracy:0.42 loss: 190.434 (lr:0.0001)
229430: accuracy:0.32 loss: 191.147 (lr:0.0001)
229440: accuracy:0.28 loss: 215.66 (lr:0.0001)
229450: accuracy:0.42 loss: 184.61 (lr:0.0001)
229460: accuracy:0.27 loss: 218.303 (lr:0.0001)
229470: accuracy:0.34 loss: 194.451 (lr:0.0001)
229480: accuracy:0.35 loss: 186.414 (lr:0.0001)
229490: accuracy:0.43 loss: 201.83 (lr:0.0001)
229500: accuracy:0.39 loss: 187.716 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
229500: ********* epoch 24 ********* test accuracy for all:0.260662 test loss: 265.411
229500: ********* epoch 24 ********* test accuracy for mode 0:0.0295 test loss: 525.305
229500: ********* epoch 24 ********* test accuracy for mode 1:0.0245 test loss: 488.386
229500: ********* epoch 24 ********* test accuracy for mode 2:0.123 test loss: 246.762
229500: ********* epoch 24 ********* test accuracy for mode 24:0.2295 test loss: 284.054
229500: ********* epoch 24 ********* test accuracy for mode 25:0.2995 test loss: 248.264
229500: ********* epoch 24 ********* test accuracy for mode 26:0.496 test loss: 161.516
229500: ********* epoch 24 ********* test accuracy for mode 27:0.249 test loss: 268.546
229500: ********* epoch 24 ********* test accuracy for mode 28:0.2935 test loss: 260.693
229500: ********* epoch 24 ********* test accuracy for mode 29:0.242 test loss: 269.308
229500: ********* epoch 24 ********* test accuracy for mode 30:0.248 test loss: 246.493
229500: ********* epoch 24 ********* test accuracy for mode 31:0.263 test loss: 239.483
229500: ********* epoch 24 ********* test accuracy for mode 32:0.1875 test loss: 230.47
229500: ********* epoch 24 ********* test accuracy for mode 33:0.2785 test loss: 226.985
229500: ********* epoch 24 ********* test accuracy for mode 34:0.254 test loss: 225.147
229500: ********* epoch 24 ********* test accuracy for mode 35:0.0935 test loss: 482.761
229500: ********* epoch 24 ********* test accuracy for mode 36:0.1315 test loss: 520.496
229510: accuracy:0.36 loss: 218.545 (lr:0.0001)
229520: accuracy:0.36 loss: 211.942 (lr:0.0001)
229530: accuracy:0.44 loss: 188.59 (lr:0.0001)
229540: accuracy:0.38 loss: 196.382 (lr:0.0001)
229550: accuracy:0.44 loss: 191.642 (lr:0.0001)
229560: accuracy:0.37 loss: 196.099 (lr:0.0001)
229570: accuracy:0.4 loss: 193.03 (lr:0.0001)
229580: accuracy:0.34 loss: 200.058 (lr:0.0001)
229590: accuracy:0.45 loss: 179.241 (lr:0.0001)
229600: accuracy:0.43 loss: 171.05 (lr:0.0001)
229610: accuracy:0.37 loss: 181.078 (lr:0.0001)
229620: accuracy:0.37 loss: 185.496 (lr:0.0001)
229630: accuracy:0.38 loss: 182.496 (lr:0.0001)
229640: accuracy:0.4 loss: 174.295 (lr:0.0001)
229650: accuracy:0.36 loss: 177.638 (lr:0.0001)
229660: accuracy:0.36 loss: 186.771 (lr:0.0001)
229670: accuracy:0.43 loss: 184.527 (lr:0.0001)
229680: accuracy:0.35 loss: 213.666 (lr:0.0001)
229690: accuracy:0.4 loss: 172.895 (lr:0.0001)
229700: accuracy:0.46 loss: 170.668 (lr:0.0001)
229710: accuracy:0.41 loss: 187.979 (lr:0.0001)
229720: accuracy:0.42 loss: 197.495 (lr:0.0001)
229730: accuracy:0.36 loss: 194.279 (lr:0.0001)
229740: accuracy:0.29 loss: 217.63 (lr:0.0001)
229750: accuracy:0.44 loss: 198.244 (lr:0.0001)
229760: accuracy:0.43 loss: 184.995 (lr:0.0001)
229770: accuracy:0.38 loss: 180.5 (lr:0.0001)
229780: accuracy:0.4 loss: 169.697 (lr:0.0001)
229790: accuracy:0.33 loss: 213.109 (lr:0.0001)
229800: accuracy:0.4 loss: 205.708 (lr:0.0001)
229810: accuracy:0.27 loss: 215.667 (lr:0.0001)
229820: accuracy:0.43 loss: 186.874 (lr:0.0001)
229830: accuracy:0.47 loss: 183.46 (lr:0.0001)
229840: accuracy:0.36 loss: 198.212 (lr:0.0001)
229850: accuracy:0.36 loss: 194.991 (lr:0.0001)
229860: accuracy:0.34 loss: 214.07 (lr:0.0001)
229870: accuracy:0.43 loss: 168.177 (lr:0.0001)
229880: accuracy:0.34 loss: 190.73 (lr:0.0001)
229890: accuracy:0.35 loss: 191.048 (lr:0.0001)
229900: accuracy:0.43 loss: 180.896 (lr:0.0001)
229910: accuracy:0.33 loss: 188.514 (lr:0.0001)
229920: accuracy:0.35 loss: 180.773 (lr:0.0001)
229930: accuracy:0.43 loss: 180.787 (lr:0.0001)
229940: accuracy:0.4 loss: 172.55 (lr:0.0001)
229950: accuracy:0.35 loss: 179.74 (lr:0.0001)
229960: accuracy:0.43 loss: 184.145 (lr:0.0001)
229970: accuracy:0.39 loss: 208.325 (lr:0.0001)
229980: accuracy:0.34 loss: 211.891 (lr:0.0001)
229990: accuracy:0.37 loss: 193.685 (lr:0.0001)
230000: accuracy:0.37 loss: 203.834 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
230000: ********* epoch 24 ********* test accuracy for all:0.259662 test loss: 266.681
230000: ********* epoch 24 ********* test accuracy for mode 0:0.0305 test loss: 524.542
230000: ********* epoch 24 ********* test accuracy for mode 1:0.028 test loss: 483.655
230000: ********* epoch 24 ********* test accuracy for mode 2:0.077 test loss: 254.725
230000: ********* epoch 24 ********* test accuracy for mode 24:0.2345 test loss: 289.832
230000: ********* epoch 24 ********* test accuracy for mode 25:0.2945 test loss: 248.456
230000: ********* epoch 24 ********* test accuracy for mode 26:0.4855 test loss: 158.906
230000: ********* epoch 24 ********* test accuracy for mode 27:0.258 test loss: 271.034
230000: ********* epoch 24 ********* test accuracy for mode 28:0.2725 test loss: 269.831
230000: ********* epoch 24 ********* test accuracy for mode 29:0.222 test loss: 280.612
230000: ********* epoch 24 ********* test accuracy for mode 30:0.26 test loss: 249.423
230000: ********* epoch 24 ********* test accuracy for mode 31:0.203 test loss: 251.381
230000: ********* epoch 24 ********* test accuracy for mode 32:0.2275 test loss: 228.403
230000: ********* epoch 24 ********* test accuracy for mode 33:0.2925 test loss: 222.86
230000: ********* epoch 24 ********* test accuracy for mode 34:0.283 test loss: 224.071
230000: ********* epoch 24 ********* test accuracy for mode 35:0.1345 test loss: 487.109
230000: ********* epoch 24 ********* test accuracy for mode 36:0.1485 test loss: 533.386
230010: accuracy:0.47 loss: 181.23 (lr:0.0001)
230020: accuracy:0.34 loss: 203.789 (lr:0.0001)
230030: accuracy:0.38 loss: 187.454 (lr:0.0001)
230040: accuracy:0.31 loss: 218.461 (lr:0.0001)
230050: accuracy:0.27 loss: 198.329 (lr:0.0001)
230060: accuracy:0.34 loss: 200.643 (lr:0.0001)
230070: accuracy:0.36 loss: 211.299 (lr:0.0001)
230080: accuracy:0.45 loss: 168.038 (lr:0.0001)
230090: accuracy:0.39 loss: 182.669 (lr:0.0001)
230100: accuracy:0.38 loss: 186.653 (lr:0.0001)
230110: accuracy:0.27 loss: 217.282 (lr:0.0001)
230120: accuracy:0.5 loss: 172.191 (lr:0.0001)
230130: accuracy:0.29 loss: 215.135 (lr:0.0001)
230140: accuracy:0.37 loss: 199.194 (lr:0.0001)
230150: accuracy:0.46 loss: 176.094 (lr:0.0001)
230160: accuracy:0.35 loss: 185.534 (lr:0.0001)
230170: accuracy:0.39 loss: 181.474 (lr:0.0001)
230180: accuracy:0.45 loss: 166.087 (lr:0.0001)
230190: accuracy:0.45 loss: 186.329 (lr:0.0001)
230200: accuracy:0.49 loss: 176.448 (lr:0.0001)
230210: accuracy:0.43 loss: 175.916 (lr:0.0001)
230220: accuracy:0.43 loss: 184.546 (lr:0.0001)
230230: accuracy:0.41 loss: 182.318 (lr:0.0001)
230240: accuracy:0.33 loss: 208.758 (lr:0.0001)
230250: accuracy:0.34 loss: 190.814 (lr:0.0001)
230260: accuracy:0.36 loss: 187.723 (lr:0.0001)
230270: accuracy:0.32 loss: 206.676 (lr:0.0001)
230280: accuracy:0.43 loss: 190.21 (lr:0.0001)
230290: accuracy:0.44 loss: 182.352 (lr:0.0001)
230300: accuracy:0.3 loss: 208.086 (lr:0.0001)
230310: accuracy:0.45 loss: 167.384 (lr:0.0001)
230320: accuracy:0.38 loss: 197.876 (lr:0.0001)
230330: accuracy:0.39 loss: 186.09 (lr:0.0001)
230340: accuracy:0.32 loss: 218.07 (lr:0.0001)
230350: accuracy:0.48 loss: 189.222 (lr:0.0001)
230360: accuracy:0.41 loss: 184.294 (lr:0.0001)
230370: accuracy:0.36 loss: 179.583 (lr:0.0001)
230380: accuracy:0.45 loss: 186.989 (lr:0.0001)
230390: accuracy:0.36 loss: 203.359 (lr:0.0001)
230400: accuracy:0.37 loss: 200.641 (lr:0.0001)
230410: accuracy:0.43 loss: 188.192 (lr:0.0001)
230420: accuracy:0.37 loss: 194.263 (lr:0.0001)
230430: accuracy:0.32 loss: 211.754 (lr:0.0001)
230440: accuracy:0.42 loss: 182.838 (lr:0.0001)
230450: accuracy:0.39 loss: 179.314 (lr:0.0001)
230460: accuracy:0.37 loss: 190.657 (lr:0.0001)
230470: accuracy:0.44 loss: 193.55 (lr:0.0001)
230480: accuracy:0.46 loss: 195.992 (lr:0.0001)
230490: accuracy:0.34 loss: 206.541 (lr:0.0001)
230500: accuracy:0.49 loss: 184.343 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
230500: ********* epoch 24 ********* test accuracy for all:0.2605 test loss: 265.716
230500: ********* epoch 24 ********* test accuracy for mode 0:0.025 test loss: 521.424
230500: ********* epoch 24 ********* test accuracy for mode 1:0.0205 test loss: 486.612
230500: ********* epoch 24 ********* test accuracy for mode 2:0.132 test loss: 250.877
230500: ********* epoch 24 ********* test accuracy for mode 24:0.233 test loss: 289.361
230500: ********* epoch 24 ********* test accuracy for mode 25:0.27 test loss: 262.182
230500: ********* epoch 24 ********* test accuracy for mode 26:0.4795 test loss: 168.08
230500: ********* epoch 24 ********* test accuracy for mode 27:0.2575 test loss: 278.544
230500: ********* epoch 24 ********* test accuracy for mode 28:0.274 test loss: 272.938
230500: ********* epoch 24 ********* test accuracy for mode 29:0.2335 test loss: 277.52
230500: ********* epoch 24 ********* test accuracy for mode 30:0.232 test loss: 252.826
230500: ********* epoch 24 ********* test accuracy for mode 31:0.204 test loss: 249.195
230500: ********* epoch 24 ********* test accuracy for mode 32:0.2435 test loss: 224.832
230500: ********* epoch 24 ********* test accuracy for mode 33:0.2885 test loss: 222.185
230500: ********* epoch 24 ********* test accuracy for mode 34:0.3125 test loss: 221.204
230500: ********* epoch 24 ********* test accuracy for mode 35:0.127 test loss: 475.136
230500: ********* epoch 24 ********* test accuracy for mode 36:0.083 test loss: 566.388
230510: accuracy:0.41 loss: 200.545 (lr:0.0001)
230520: accuracy:0.36 loss: 205.79 (lr:0.0001)
230530: accuracy:0.37 loss: 187.391 (lr:0.0001)
230540: accuracy:0.42 loss: 175.868 (lr:0.0001)
230550: accuracy:0.38 loss: 195.473 (lr:0.0001)
230560: accuracy:0.42 loss: 178.674 (lr:0.0001)
230570: accuracy:0.38 loss: 195.205 (lr:0.0001)
230580: accuracy:0.46 loss: 180.041 (lr:0.0001)
230590: accuracy:0.42 loss: 180.507 (lr:0.0001)
230600: accuracy:0.37 loss: 192.224 (lr:0.0001)
230610: accuracy:0.4 loss: 186.994 (lr:0.0001)
230620: accuracy:0.42 loss: 191.523 (lr:0.0001)
230630: accuracy:0.38 loss: 218.156 (lr:0.0001)
230640: accuracy:0.37 loss: 196.09 (lr:0.0001)
230650: accuracy:0.31 loss: 196.921 (lr:0.0001)
230660: accuracy:0.35 loss: 194.271 (lr:0.0001)
230670: accuracy:0.49 loss: 187.638 (lr:0.0001)
230680: accuracy:0.34 loss: 191.631 (lr:0.0001)
230690: accuracy:0.4 loss: 187.199 (lr:0.0001)
230700: accuracy:0.42 loss: 177.324 (lr:0.0001)
230710: accuracy:0.45 loss: 175.905 (lr:0.0001)
230720: accuracy:0.38 loss: 194.077 (lr:0.0001)
230730: accuracy:0.38 loss: 184.807 (lr:0.0001)
230740: accuracy:0.35 loss: 192.076 (lr:0.0001)
230750: accuracy:0.47 loss: 176.121 (lr:0.0001)
230760: accuracy:0.35 loss: 201.319 (lr:0.0001)
230770: accuracy:0.29 loss: 216.357 (lr:0.0001)
230780: accuracy:0.47 loss: 166.211 (lr:0.0001)
230790: accuracy:0.41 loss: 198.24 (lr:0.0001)
230800: accuracy:0.36 loss: 187.956 (lr:0.0001)
230810: accuracy:0.33 loss: 187.371 (lr:0.0001)
230820: accuracy:0.42 loss: 196.293 (lr:0.0001)
230830: accuracy:0.37 loss: 193.272 (lr:0.0001)
230840: accuracy:0.47 loss: 185.968 (lr:0.0001)
230850: accuracy:0.43 loss: 190.926 (lr:0.0001)
230860: accuracy:0.39 loss: 197.657 (lr:0.0001)
230870: accuracy:0.34 loss: 204.956 (lr:0.0001)
230880: accuracy:0.39 loss: 215.907 (lr:0.0001)
230890: accuracy:0.4 loss: 174.779 (lr:0.0001)
230900: accuracy:0.38 loss: 192.014 (lr:0.0001)
230910: accuracy:0.4 loss: 183.561 (lr:0.0001)
230920: accuracy:0.43 loss: 176.9 (lr:0.0001)
230930: accuracy:0.43 loss: 188.743 (lr:0.0001)
230940: accuracy:0.38 loss: 209.619 (lr:0.0001)
230950: accuracy:0.35 loss: 204.267 (lr:0.0001)
230960: accuracy:0.37 loss: 204.375 (lr:0.0001)
230970: accuracy:0.36 loss: 187.0 (lr:0.0001)
230980: accuracy:0.44 loss: 193.84 (lr:0.0001)
230990: accuracy:0.38 loss: 201.483 (lr:0.0001)
231000: accuracy:0.43 loss: 187.482 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
231000: ********* epoch 24 ********* test accuracy for all:0.260568 test loss: 264.876
231000: ********* epoch 24 ********* test accuracy for mode 0:0.035 test loss: 513.643
231000: ********* epoch 24 ********* test accuracy for mode 1:0.0265 test loss: 481.003
231000: ********* epoch 24 ********* test accuracy for mode 2:0.1025 test loss: 252.779
231000: ********* epoch 24 ********* test accuracy for mode 24:0.2455 test loss: 280.569
231000: ********* epoch 24 ********* test accuracy for mode 25:0.3095 test loss: 247.88
231000: ********* epoch 24 ********* test accuracy for mode 26:0.479 test loss: 166.129
231000: ********* epoch 24 ********* test accuracy for mode 27:0.2525 test loss: 275.484
231000: ********* epoch 24 ********* test accuracy for mode 28:0.2795 test loss: 269.835
231000: ********* epoch 24 ********* test accuracy for mode 29:0.218 test loss: 278.576
231000: ********* epoch 24 ********* test accuracy for mode 30:0.276 test loss: 249.8
231000: ********* epoch 24 ********* test accuracy for mode 31:0.189 test loss: 254.524
231000: ********* epoch 24 ********* test accuracy for mode 32:0.2485 test loss: 229.301
231000: ********* epoch 24 ********* test accuracy for mode 33:0.241 test loss: 233.61
231000: ********* epoch 24 ********* test accuracy for mode 34:0.259 test loss: 230.236
231000: ********* epoch 24 ********* test accuracy for mode 35:0.1225 test loss: 474.879
231000: ********* epoch 24 ********* test accuracy for mode 36:0.115 test loss: 517.229
231010: accuracy:0.38 loss: 178.307 (lr:0.0001)
231020: accuracy:0.42 loss: 189.862 (lr:0.0001)
231030: accuracy:0.42 loss: 174.731 (lr:0.0001)
231040: accuracy:0.41 loss: 176.747 (lr:0.0001)
231050: accuracy:0.44 loss: 176.776 (lr:0.0001)
231060: accuracy:0.4 loss: 188.931 (lr:0.0001)
231070: accuracy:0.38 loss: 177.939 (lr:0.0001)
231080: accuracy:0.28 loss: 219.466 (lr:0.0001)
231090: accuracy:0.41 loss: 195.856 (lr:0.0001)
231100: accuracy:0.4 loss: 196.796 (lr:0.0001)
231110: accuracy:0.42 loss: 179.633 (lr:0.0001)
231120: accuracy:0.44 loss: 174.338 (lr:0.0001)
231130: accuracy:0.42 loss: 201.667 (lr:0.0001)
231140: accuracy:0.45 loss: 181.855 (lr:0.0001)
231150: accuracy:0.41 loss: 182.69 (lr:0.0001)
231160: accuracy:0.32 loss: 203.305 (lr:0.0001)
231170: accuracy:0.38 loss: 191.275 (lr:0.0001)
231180: accuracy:0.33 loss: 191.337 (lr:0.0001)
231190: accuracy:0.44 loss: 185.59 (lr:0.0001)
231200: accuracy:0.37 loss: 191.634 (lr:0.0001)
231210: accuracy:0.42 loss: 196.774 (lr:0.0001)
231220: accuracy:0.39 loss: 199.862 (lr:0.0001)
231230: accuracy:0.39 loss: 193.56 (lr:0.0001)
231240: accuracy:0.39 loss: 200.528 (lr:0.0001)
231250: accuracy:0.34 loss: 194.138 (lr:0.0001)
231260: accuracy:0.41 loss: 177.016 (lr:0.0001)
231270: accuracy:0.34 loss: 204.812 (lr:0.0001)
231280: accuracy:0.42 loss: 177.9 (lr:0.0001)
231290: accuracy:0.48 loss: 179.051 (lr:0.0001)
231300: accuracy:0.35 loss: 197.668 (lr:0.0001)
231310: accuracy:0.32 loss: 215.617 (lr:0.0001)
231320: accuracy:0.38 loss: 187.894 (lr:0.0001)
231330: accuracy:0.42 loss: 169.996 (lr:0.0001)
231340: accuracy:0.38 loss: 201.802 (lr:0.0001)
231350: accuracy:0.41 loss: 191.061 (lr:0.0001)
231360: accuracy:0.44 loss: 175.245 (lr:0.0001)
231370: accuracy:0.43 loss: 176.148 (lr:0.0001)
231380: accuracy:0.43 loss: 185.869 (lr:0.0001)
231390: accuracy:0.37 loss: 194.924 (lr:0.0001)
231400: accuracy:0.38 loss: 196.469 (lr:0.0001)
231410: accuracy:0.43 loss: 179.719 (lr:0.0001)
231420: accuracy:0.41 loss: 199.359 (lr:0.0001)
231430: accuracy:0.37 loss: 194.282 (lr:0.0001)
231440: accuracy:0.35 loss: 204.808 (lr:0.0001)
231450: accuracy:0.42 loss: 181.553 (lr:0.0001)
231460: accuracy:0.44 loss: 176.273 (lr:0.0001)
231470: accuracy:0.44 loss: 168.87 (lr:0.0001)
231480: accuracy:0.42 loss: 163.475 (lr:0.0001)
231490: accuracy:0.48 loss: 178.166 (lr:0.0001)
231500: accuracy:0.44 loss: 194.935 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
231500: ********* epoch 24 ********* test accuracy for all:0.259257 test loss: 265.93
231500: ********* epoch 24 ********* test accuracy for mode 0:0.0255 test loss: 524.528
231500: ********* epoch 24 ********* test accuracy for mode 1:0.028 test loss: 487.749
231500: ********* epoch 24 ********* test accuracy for mode 2:0.0995 test loss: 257.982
231500: ********* epoch 24 ********* test accuracy for mode 24:0.2435 test loss: 278.534
231500: ********* epoch 24 ********* test accuracy for mode 25:0.2875 test loss: 247.148
231500: ********* epoch 24 ********* test accuracy for mode 26:0.4885 test loss: 165.541
231500: ********* epoch 24 ********* test accuracy for mode 27:0.247 test loss: 266.156
231500: ********* epoch 24 ********* test accuracy for mode 28:0.2815 test loss: 262.2
231500: ********* epoch 24 ********* test accuracy for mode 29:0.257 test loss: 264.434
231500: ********* epoch 24 ********* test accuracy for mode 30:0.262 test loss: 249.547
231500: ********* epoch 24 ********* test accuracy for mode 31:0.2235 test loss: 253.197
231500: ********* epoch 24 ********* test accuracy for mode 32:0.1905 test loss: 239.731
231500: ********* epoch 24 ********* test accuracy for mode 33:0.233 test loss: 236.741
231500: ********* epoch 24 ********* test accuracy for mode 34:0.265 test loss: 235.925
231500: ********* epoch 24 ********* test accuracy for mode 35:0.133 test loss: 484.77
231500: ********* epoch 24 ********* test accuracy for mode 36:0.106 test loss: 535.168
231510: accuracy:0.38 loss: 198.536 (lr:0.0001)
231520: accuracy:0.43 loss: 200.293 (lr:0.0001)
231530: accuracy:0.34 loss: 221.277 (lr:0.0001)
231540: accuracy:0.33 loss: 196.902 (lr:0.0001)
231550: accuracy:0.45 loss: 191.82 (lr:0.0001)
231560: accuracy:0.37 loss: 188.872 (lr:0.0001)
231570: accuracy:0.36 loss: 199.13 (lr:0.0001)
231580: accuracy:0.43 loss: 172.619 (lr:0.0001)
231590: accuracy:0.44 loss: 186.363 (lr:0.0001)
231600: accuracy:0.45 loss: 183.839 (lr:0.0001)
231610: accuracy:0.4 loss: 196.424 (lr:0.0001)
231620: accuracy:0.34 loss: 200.825 (lr:0.0001)
231630: accuracy:0.4 loss: 199.961 (lr:0.0001)
231640: accuracy:0.34 loss: 202.258 (lr:0.0001)
231650: accuracy:0.42 loss: 191.069 (lr:0.0001)
231660: accuracy:0.28 loss: 210.184 (lr:0.0001)
231670: accuracy:0.42 loss: 179.864 (lr:0.0001)
231680: accuracy:0.39 loss: 175.422 (lr:0.0001)
231690: accuracy:0.31 loss: 202.673 (lr:0.0001)
231700: accuracy:0.33 loss: 202.904 (lr:0.0001)
231710: accuracy:0.37 loss: 203.341 (lr:0.0001)
231720: accuracy:0.41 loss: 196.352 (lr:0.0001)
231730: accuracy:0.43 loss: 193.139 (lr:0.0001)
231740: accuracy:0.37 loss: 185.836 (lr:0.0001)
231750: accuracy:0.33 loss: 192.594 (lr:0.0001)
231760: accuracy:0.5 loss: 165.5 (lr:0.0001)
231770: accuracy:0.42 loss: 173.194 (lr:0.0001)
231780: accuracy:0.31 loss: 201.917 (lr:0.0001)
231790: accuracy:0.47 loss: 165.852 (lr:0.0001)
231800: accuracy:0.44 loss: 189.114 (lr:0.0001)
231810: accuracy:0.44 loss: 173.813 (lr:0.0001)
231820: accuracy:0.36 loss: 202.152 (lr:0.0001)
231830: accuracy:0.39 loss: 169.953 (lr:0.0001)
231840: accuracy:0.39 loss: 189.383 (lr:0.0001)
231850: accuracy:0.37 loss: 200.921 (lr:0.0001)
231860: accuracy:0.37 loss: 201.12 (lr:0.0001)
231870: accuracy:0.27 loss: 195.192 (lr:0.0001)
231880: accuracy:0.4 loss: 193.696 (lr:0.0001)
231890: accuracy:0.32 loss: 206.372 (lr:0.0001)
231900: accuracy:0.35 loss: 182.674 (lr:0.0001)
231910: accuracy:0.41 loss: 178.682 (lr:0.0001)
231920: accuracy:0.33 loss: 183.225 (lr:0.0001)
231930: accuracy:0.35 loss: 198.489 (lr:0.0001)
231940: accuracy:0.5 loss: 185.059 (lr:0.0001)
231950: accuracy:0.37 loss: 203.599 (lr:0.0001)
231960: accuracy:0.42 loss: 193.798 (lr:0.0001)
231970: accuracy:0.36 loss: 190.121 (lr:0.0001)
231980: accuracy:0.47 loss: 164.085 (lr:0.0001)
231990: accuracy:0.35 loss: 206.968 (lr:0.0001)
232000: accuracy:0.41 loss: 190.601 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_5_conv_dropout_model.ckpt
232000: ********* epoch 24 ********* test accuracy for all:0.256905 test loss: 268.443
232000: ********* epoch 24 ********* test accuracy for mode 0:0.026 test loss: 518.114
232000: ********* epoch 24 ********* test accuracy for mode 1:0.018 test loss: 488.71
232000: ********* epoch 24 ********* test accuracy for mode 2:0.0755 test loss: 259.053
232000: ********* epoch 24 ********* test accuracy for mode 24:0.2245 test loss: 289.128
232000: ********* epoch 24 ********* test accuracy for mode 25:0.2655 test loss: 258.541
232000: ********* epoch 24 ********* test accuracy for mode 26:0.4885 test loss: 165.41
232000: ********* epoch 24 ********* test accuracy for mode 27:0.2525 test loss: 274.615
232000: ********* epoch 24 ********* test accuracy for mode 28:0.278 test loss: 271.541
232000: ********* epoch 24 ********* test accuracy for mode 29:0.228 test loss: 282.509
232000: ********* epoch 24 ********* test accuracy for mode 30:0.243 test loss: 258.383
232000: ********* epoch 24 ********* test accuracy for mode 31:0.214 test loss: 256.926
232000: ********* epoch 24 ********* test accuracy for mode 32:0.212 test loss: 235.106
232000: ********* epoch 24 ********* test accuracy for mode 33:0.2875 test loss: 227.776
232000: ********* epoch 24 ********* test accuracy for mode 34:0.268 test loss: 229.516
232000: ********* epoch 24 ********* test accuracy for mode 35:0.144 test loss: 466.215
232000: ********* epoch 24 ********* test accuracy for mode 36:0.068 test loss: 590.855
232010: accuracy:0.49 loss: 174.319 (lr:0.0001)
232020: accuracy:0.41 loss: 183.042 (lr:0.0001)
232030: accuracy:0.4 loss: 199.055 (lr:0.0001)
232040: accuracy:0.42 loss: 195.085 (lr:0.0001)
232050: accuracy:0.41 loss: 202.215 (lr:0.0001)
232060: accuracy:0.37 loss: 200.776 (lr:0.0001)
232070: accuracy:0.35 loss: 196.255 (lr:0.0001)
232080: accuracy:0.37 loss: 187.68 (lr:0.0001)
232090: accuracy:0.52 loss: 166.047 (lr:0.0001)
232100: accuracy:0.36 loss: 196.625 (lr:0.0001)
232110: accuracy:0.4 loss: 191.206 (lr:0.0001)
232120: accuracy:0.4 loss: 201.103 (lr:0.0001)
232130: accuracy:0.37 loss: 186.496 (lr:0.0001)
232140: accuracy:0.39 loss: 202.023 (lr:0.0001)
232150: accuracy:0.46 loss: 176.992 (lr:0.0001)
232160: accuracy:0.44 loss: 195.159 (lr:0.0001)
232170: accuracy:0.33 loss: 210.923 (lr:0.0001)
232180: accuracy:0.49 loss: 167.481 (lr:0.0001)
232190: accuracy:0.36 loss: 200.233 (lr:0.0001)
232200: accuracy:0.41 loss: 200.493 (lr:0.0001)
232210: accuracy:0.4 loss: 179.259 (lr:0.0001)
232220: accuracy:0.42 loss: 162.608 (lr:0.0001)
232230: accuracy:0.36 loss: 182.505 (lr:0.0001)
^X232240: accuracy:0.31 loss: 206.875 (lr:0.0001)
^Z
[1]+  Stopped                 python3 md_5.0_conv.py
Pharrell-WANGs-MacBook-Pro:proj_vcmd Pharrell_WANG$ 
