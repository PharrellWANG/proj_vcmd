Pharrell-WANGs-MacBook-Pro:proj_vcmd Pharrell_WANG$ 
Pharrell-WANGs-MacBook-Pro:proj_vcmd Pharrell_WANG$ 
Pharrell-WANGs-MacBook-Pro:proj_vcmd Pharrell_WANG$ clear

















































Pharrell-WANGs-MacBook-Pro:proj_vcmd Pharrell_WANG$ python3 md_6.0_BN_conv_relu_dropout.py 
2017-05-01 19:23:15.407041 >>>>-------> start reading the training csv file.
duration for reading training csv: 0:00:00.000131
row_count of the training csv file: 972582
duration for row counting of training csv: 0:00:25.708430
number of labels : 972582
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (972582, 37)
2017-05-01 19:25:02.686148   ***-------> now end reading the training csv file.
duration for loading_csv_without_header: 0:01:21.570546
2017-05-01 19:25:02.686213   ***-------> now start reading the testing csv file 1.
number of labels : 74000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (74000, 37)
2017-05-01 19:25:10.221154   ***-------> now start reading the testing csv file 2.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 19:25:10.441545   ***-------> now start reading the testing csv file 3.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 19:25:10.658278   ***-------> now start reading the testing csv file 4.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 19:25:10.857582   ***-------> now start reading the testing csv file 5.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 19:25:11.072574   ***-------> now start reading the testing csv file 6.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 19:25:11.284796   ***-------> now start reading the testing csv file 7.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 19:25:11.493939   ***-------> now start reading the testing csv file 8.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 19:25:11.696037   ***-------> now start reading the testing csv file 9.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 19:25:11.911314   ***-------> now start reading the testing csv file 10.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 19:25:12.117916   ***-------> now start reading the testing csv file 11.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 19:25:12.322452   ***-------> now start reading the testing csv file 12.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 19:25:12.531636   ***-------> now start reading the testing csv file 13.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 19:25:12.735239   ***-------> now start reading the testing csv file 14.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 19:25:12.945916   ***-------> now start reading the testing csv file 15.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 19:25:13.150215   ***-------> now start reading the testing csv file 16.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
2017-05-01 19:25:13.347741   ***-------> now start reading the testing csv file 17.
number of labels : 2000
type of labels_one_hot :     <class 'numpy.ndarray'>
shape of labels_one_hot :     (2000, 37)
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
======------------>>>>>>>    972582
0: accuracy:0.01 loss: 373.523 (lr:0.05)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
0: ********* epoch 1 ********* test accuracy for all:0.0262432 test loss: 1.96618e+25
0: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 2.96786e+25
0: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 1.60726e+25
0: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 4.0143e+25
0: ********* epoch 1 ********* test accuracy for mode 24:0.008 test loss: 7.51555e+24
0: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 1.74311e+25
0: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 2.94393e+25
0: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 3.67281e+25
0: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 1.49625e+25
0: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 1.40762e+25
0: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 9.6978e+24
0: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 3.32463e+25
0: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 2.64218e+25
0: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 1.83024e+25
0: ********* epoch 1 ********* test accuracy for mode 34:0.0005 test loss: 1.22644e+25
0: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 2.22394e+25
0: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 1.76492e+25
20: accuracy:0.24 loss: 322.177 (lr:0.04901191379800709)
40: accuracy:0.22 loss: 329.578 (lr:0.048043393013700926)
60: accuracy:0.34 loss: 315.932 (lr:0.047094050225854014)
80: accuracy:0.28 loss: 320.782 (lr:0.04616350568469313)
100: accuracy:0.32 loss: 272.416 (lr:0.04525138715999438)
120: accuracy:0.51 loss: 243.842 (lr:0.04435732979218616)
140: accuracy:0.06 loss: 231.326 (lr:0.043480975946400414)
160: accuracy:0.0 loss: 279.84 (lr:0.042621975069413946)
180: accuracy:0.0 loss: 377.091 (lr:0.04177998354942247)
200: accuracy:0.4 loss: 302.361 (lr:0.040954664578591295)
220: accuracy:0.84 loss: 160.485 (lr:0.04014568801832768)
240: accuracy:0.65 loss: 181.003 (lr:0.03935273026722102)
260: accuracy:0.0 loss: 327.89 (lr:0.03857547413159796)
280: accuracy:0.3 loss: 285.54 (lr:0.037813608698640706)
300: accuracy:0.39 loss: 292.605 (lr:0.037066829212017725)
320: accuracy:0.25 loss: 348.228 (lr:0.03633483694997718)
340: accuracy:0.29 loss: 248.241 (lr:0.035617339105854226)
360: accuracy:0.03 loss: 289.771 (lr:0.03491404867094445)
380: accuracy:0.13 loss: 245.071 (lr:0.03422468431969656)
400: accuracy:0.35 loss: 320.541 (lr:0.033548970297178404)
420: accuracy:0.03 loss: 180.157 (lr:0.03288663630877133)
440: accuracy:0.0 loss: 267.872 (lr:0.03223741741204876)
460: accuracy:0.68 loss: 168.06 (lr:0.03160105391079561)
480: accuracy:0.0 loss: 348.339 (lr:0.030977291251126426)
500: accuracy:0.0 loss: 304.159 (lr:0.03036587991966041)
520: accuracy:0.74 loss: 177.465 (lr:0.029766575343712697)
540: accuracy:0.58 loss: 206.701 (lr:0.02917913779346208)
560: accuracy:0.65 loss: 179.709 (lr:0.02860333228605586)
580: accuracy:0.0 loss: 391.006 (lr:0.02803892849161356)
600: accuracy:0.33 loss: 289.752 (lr:0.02748570064109192)
620: accuracy:0.27 loss: 319.5 (lr:0.026943427435974256)
640: accuracy:0.5 loss: 268.903 (lr:0.02641189195974812)
660: accuracy:0.29 loss: 281.819 (lr:0.025890881591135787)
680: accuracy:0.32 loss: 310.332 (lr:0.025380187919042917)
700: accuracy:0.28 loss: 327.783 (lr:0.024879606659191335)
720: accuracy:0.87 loss: 163.539 (lr:0.024388937572402587)
740: accuracy:0.0 loss: 350.32 (lr:0.023907984384499616)
760: accuracy:0.18 loss: 303.803 (lr:0.02343655470779447)
780: accuracy:0.01 loss: 327.403 (lr:0.022974459964130653)
800: accuracy:0.01 loss: 328.925 (lr:0.022521515309449354)
820: accuracy:0.0 loss: 339.626 (lr:0.022077539559849365)
840: accuracy:0.74 loss: 152.32 (lr:0.021642355119111077)
860: accuracy:0.0 loss: 329.775 (lr:0.021215787907655666)
880: accuracy:0.0 loss: 346.545 (lr:0.02079766729291091)
900: accuracy:0.0 loss: 342.206 (lr:0.020387826021055894)
920: accuracy:0.01 loss: 300.098 (lr:0.019986100150117255)
940: accuracy:0.07 loss: 307.269 (lr:0.019592328984390204)
960: accuracy:0.92 loss: 109.77 (lr:0.01920635501015809)
980: accuracy:0.0 loss: 390.752 (lr:0.018828023832684837)
1000: accuracy:0.0 loss: 332.643 (lr:0.01845718411445497)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
1000: ********* epoch 1 ********* test accuracy for all:0.0275 test loss: 437.584
1000: ********* epoch 1 ********* test accuracy for mode 0:0.0175 test loss: 161.897
1000: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 325.09
1000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 460.199
1000: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 437.657
1000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 432.786
1000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 369.332
1000: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 433.8
1000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 404.807
1000: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 431.876
1000: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 460.181
1000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 450.406
1000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 488.925
1000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 497.6
1000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 501.391
1000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 347.313
1000: ********* epoch 1 ********* test accuracy for mode 36:1.0 test loss: 92.1264
1020: accuracy:0.06 loss: 356.006 (lr:0.01809368751463661)
1040: accuracy:0.01 loss: 374.283 (lr:0.01773738862974313)
1060: accuracy:0.02 loss: 332.389 (lr:0.017388144935469863)
1080: accuracy:0.0 loss: 378.069 (lr:0.017045816729682462)
1100: accuracy:0.0 loss: 318.316 (lr:0.01671026707653417)
1120: accuracy:0.0 loss: 375.488 (lr:0.01638136175168967)
1140: accuracy:0.0 loss: 346.116 (lr:0.016058969188633566)
1160: accuracy:0.0 loss: 337.813 (lr:0.015742960426042004)
1180: accuracy:0.0 loss: 385.492 (lr:0.015433209056196448)
1200: accuracy:0.21 loss: 340.746 (lr:0.015129591174418887)
1220: accuracy:0.02 loss: 365.48 (lr:0.014831985329508308)
1240: accuracy:0.08 loss: 359.61 (lr:0.014540272475158624)
1260: accuracy:0.0 loss: 383.362 (lr:0.014254335922338542)
1280: accuracy:0.03 loss: 367.599 (lr:0.013974061292614387)
1300: accuracy:0.0 loss: 350.653 (lr:0.013699336472397228)
1320: accuracy:0.08 loss: 357.024 (lr:0.013430051568095932)
1340: accuracy:0.0 loss: 358.5 (lr:0.013166098862158266)
1360: accuracy:0.0 loss: 354.715 (lr:0.012907372769982437)
1380: accuracy:0.03 loss: 366.006 (lr:0.01265376979768185)
1400: accuracy:0.06 loss: 347.177 (lr:0.012405188500686164)
1420: accuracy:0.11 loss: 350.093 (lr:0.012161529443162119)
1440: accuracy:0.05 loss: 356.507 (lr:0.011922695158237875)
1460: accuracy:0.05 loss: 358.94 (lr:0.011688590109014964)
1480: accuracy:0.29 loss: 321.581 (lr:0.011459120650352254)
1500: accuracy:0.0 loss: 361.373 (lr:0.011234194991406647)
1520: accuracy:0.09 loss: 363.717 (lr:0.011013723158915516)
1540: accuracy:0.01 loss: 372.694 (lr:0.0107976169612062)
1560: accuracy:0.0 loss: 370.638 (lr:0.01058578995291816)
1580: accuracy:0.0 loss: 368.539 (lr:0.010378157400423683)
1600: accuracy:0.0 loss: 348.066 (lr:0.010174636247933303)
1620: accuracy:0.09 loss: 358.556 (lr:0.00997514508427237)
1640: accuracy:0.09 loss: 360.091 (lr:0.009779604110315506)
1660: accuracy:0.07 loss: 357.491 (lr:0.009587935107065876)
1680: accuracy:0.0 loss: 347.636 (lr:0.009400061404366557)
1700: accuracy:0.08 loss: 362.96 (lr:0.009215907850231459)
1720: accuracy:0.21 loss: 337.528 (lr:0.009035400780783511)
1740: accuracy:0.0 loss: 366.149 (lr:0.008858467990788143)
1760: accuracy:0.08 loss: 355.022 (lr:0.00868503870477022)
1780: accuracy:0.0 loss: 333.156 (lr:0.008515043548702915)
1800: accuracy:0.09 loss: 354.319 (lr:0.008348414522257167)
1820: accuracy:0.11 loss: 356.186 (lr:0.00818508497160065)
1840: accuracy:0.04 loss: 333.73 (lr:0.00802498956273534)
1860: accuracy:0.05 loss: 326.399 (lr:0.007868064255363065)
1880: accuracy:0.17 loss: 338.935 (lr:0.007714246277268507)
1900: accuracy:0.2 loss: 340.032 (lr:0.00756347409920949)
1920: accuracy:0.09 loss: 357.442 (lr:0.007415687410304473)
1940: accuracy:0.08 loss: 356.094 (lr:0.007270827093907376)
1960: accuracy:0.29 loss: 322.912 (lr:0.007128835203960146)
1980: accuracy:0.08 loss: 359.643 (lr:0.006989654941813552)
2000: accuracy:0.1 loss: 357.069 (lr:0.006853230633506974)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
2000: ********* epoch 1 ********* test accuracy for all:0.0266081 test loss: 375.526
2000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 489.393
2000: ********* epoch 1 ********* test accuracy for mode 1:0.9835 test loss: 217.269
2000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 395.719
2000: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 379.562
2000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 388.087
2000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 288.303
2000: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 390.42
2000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 353.911
2000: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 352.471
2000: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 366.955
2000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 386.211
2000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 375.069
2000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 402.039
2000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 392.584
2000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 235.914
2000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 413.223
2020: accuracy:0.08 loss: 363.363 (lr:0.006719507707498074)
2040: accuracy:0.1 loss: 355.622 (lr:0.006588432672833453)
2060: accuracy:0.07 loss: 327.771 (lr:0.006459953097751555)
2080: accuracy:0.17 loss: 351.595 (lr:0.006334017588709263)
2100: accuracy:0.08 loss: 352.871 (lr:0.006210575769823797)
2120: accuracy:0.08 loss: 340.816 (lr:0.006089578262721691)
2140: accuracy:0.11 loss: 355.265 (lr:0.005970976666786781)
2160: accuracy:0.2 loss: 296.508 (lr:0.00585472353979932)
2180: accuracy:0.24 loss: 289.391 (lr:0.005740772378958448)
2200: accuracy:0.1 loss: 369.038 (lr:0.0056290776022804604)
2220: accuracy:0.08 loss: 307.881 (lr:0.005519594530365403)
2240: accuracy:0.04 loss: 348.666 (lr:0.005412279368524715)
2260: accuracy:0.03 loss: 320.197 (lr:0.005307089189262776)
2280: accuracy:0.07 loss: 360.048 (lr:0.00520398191510532)
2300: accuracy:0.21 loss: 345.695 (lr:0.005102916301767907)
2320: accuracy:0.12 loss: 354.343 (lr:0.005003851921657641)
2340: accuracy:0.11 loss: 355.756 (lr:0.004906749147701603)
2360: accuracy:0.14 loss: 327.215 (lr:0.004811569137495487)
2380: accuracy:0.14 loss: 351.597 (lr:0.00471827381776613)
2400: accuracy:0.06 loss: 349.213 (lr:0.004626825869141684)
2420: accuracy:0.21 loss: 344.885 (lr:0.004537188711223379)
2440: accuracy:0.17 loss: 321.63 (lr:0.004449326487952867)
2460: accuracy:0.01 loss: 369.17 (lr:0.00436320405326933)
2480: accuracy:0.24 loss: 326.487 (lr:0.004278786957050579)
2500: accuracy:0.07 loss: 359.701 (lr:0.004196041431332551)
2520: accuracy:0.19 loss: 304.643 (lr:0.004114934376801669)
2540: accuracy:0.02 loss: 374.329 (lr:0.00403543334955468)
2560: accuracy:0.05 loss: 358.802 (lr:0.003957506548120657)
2580: accuracy:0.05 loss: 339.851 (lr:0.0038811228007399894)
2600: accuracy:0.08 loss: 356.981 (lr:0.0038062515528952605)
2620: accuracy:0.12 loss: 301.945 (lr:0.0037328628550890356)
2640: accuracy:0.23 loss: 339.998 (lr:0.003660927350863664)
2660: accuracy:0.21 loss: 302.966 (lr:0.003590416265058302)
2680: accuracy:0.11 loss: 355.779 (lr:0.0035213013922984677)
2700: accuracy:0.05 loss: 354.739 (lr:0.0034535550857135128)
2720: accuracy:0.16 loss: 347.334 (lr:0.003387150245877507)
2740: accuracy:0.07 loss: 347.212 (lr:0.0033220603099691063)
2760: accuracy:0.04 loss: 359.27 (lr:0.003258259241146072)
2780: accuracy:0.14 loss: 341.176 (lr:0.0031957215181301797)
2800: accuracy:0.15 loss: 333.859 (lr:0.0031344221249983767)
2820: accuracy:0.44 loss: 290.065 (lr:0.0030743365411760744)
2840: accuracy:0.42 loss: 286.549 (lr:0.0030154407316285914)
2860: accuracy:0.11 loss: 337.327 (lr:0.002957711137246821)
2880: accuracy:0.07 loss: 321.475 (lr:0.0029011246654232726)
2900: accuracy:0.1 loss: 304.224 (lr:0.0028456586808147206)
2920: accuracy:0.01 loss: 347.207 (lr:0.002791290996287765)
2940: accuracy:0.0 loss: 352.677 (lr:0.002737999864043683)
2960: accuracy:0.03 loss: 312.9 (lr:0.0026857639669190187)
2980: accuracy:0.01 loss: 343.575 (lr:0.002634562409858435)
3000: accuracy:0.0 loss: 360.654 (lr:0.0025843747115564105)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
3000: ********* epoch 1 ********* test accuracy for all:0.0333514 test loss: 389.363
3000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 566.291
3000: ********* epoch 1 ********* test accuracy for mode 1:0.788 test loss: 229.484
3000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 411.504
3000: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 373.966
3000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 395.09
3000: ********* epoch 1 ********* test accuracy for mode 26:0.439 test loss: 243.0
3000: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 323.066
3000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 361.264
3000: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 402.789
3000: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 415.842
3000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 410.98
3000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 422.366
3000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 434.443
3000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 429.568
3000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 248.655
3000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 668.816
3020: accuracy:0.02 loss: 306.006 (lr:0.0025351807962644465)
3040: accuracy:0.1 loss: 327.248 (lr:0.0024869609857604983)
3060: accuracy:0.11 loss: 299.738 (lr:0.0024396959914774253)
3080: accuracy:0.04 loss: 354.025 (lr:0.0023933669067873055)
3100: accuracy:0.17 loss: 299.068 (lr:0.002347955199438534)
3120: accuracy:0.09 loss: 296.301 (lr:0.0023034427041426736)
3140: accuracy:0.29 loss: 285.109 (lr:0.002259811615308098)
3160: accuracy:0.26 loss: 285.233 (lr:0.002217044479917518)
3180: accuracy:0.12 loss: 302.815 (lr:0.0021751241905465404)
3200: accuracy:0.15 loss: 346.73 (lr:0.002134033978520474)
3220: accuracy:0.22 loss: 305.815 (lr:0.0020937574072066294)
3240: accuracy:0.16 loss: 272.411 (lr:0.0020542783654394544)
3260: accuracy:0.05 loss: 324.723 (lr:0.0020155810610758486)
3280: accuracy:0.06 loss: 339.221 (lr:0.0019776500146780934)
3300: accuracy:0.29 loss: 270.737 (lr:0.0019404700533218768)
3320: accuracy:0.43 loss: 257.386 (lr:0.0019040263045269168)
3340: accuracy:0.31 loss: 277.197 (lr:0.0018683041903077722)
3360: accuracy:0.36 loss: 257.598 (lr:0.0018332894213424543)
3380: accuracy:0.25 loss: 281.673 (lr:0.0017989679912565073)
3400: accuracy:0.1 loss: 333.329 (lr:0.0017653261710202715)
3420: accuracy:0.2 loss: 316.95 (lr:0.001732350503457089)
3440: accuracy:0.18 loss: 312.535 (lr:0.0017000277978602525)
3460: accuracy:0.33 loss: 255.481 (lr:0.0016683451247165488)
3480: accuracy:0.06 loss: 291.852 (lr:0.0016372898105342787)
3500: accuracy:0.2 loss: 299.048 (lr:0.0016068494327736932)
3520: accuracy:0.2 loss: 290.068 (lr:0.0015770118148778108)
3540: accuracy:0.16 loss: 278.251 (lr:0.001547765021401633)
3560: accuracy:0.24 loss: 283.307 (lr:0.001519097353237807)
3580: accuracy:0.23 loss: 305.228 (lr:0.001490997342936826)
3600: accuracy:0.02 loss: 333.97 (lr:0.0014634537501198987)
3620: accuracy:0.32 loss: 263.52 (lr:0.001436455556982645)
3640: accuracy:0.1 loss: 341.41 (lr:0.0014099919638878293)
3660: accuracy:0.2 loss: 326.072 (lr:0.001384052385045361)
3680: accuracy:0.29 loss: 303.767 (lr:0.001358626444277838)
3700: accuracy:0.27 loss: 304.181 (lr:0.0013337039708699355)
3720: accuracy:0.09 loss: 275.644 (lr:0.0013092749954999865)
3740: accuracy:0.0 loss: 364.087 (lr:0.0012853297462521193)
3760: accuracy:0.05 loss: 338.317 (lr:0.0012618586447073609)
3780: accuracy:0.24 loss: 294.435 (lr:0.0012388523021121397)
3800: accuracy:0.13 loss: 318.644 (lr:0.0012163015156226636)
3820: accuracy:0.24 loss: 292.17 (lr:0.001194197264623655)
3840: accuracy:0.27 loss: 255.989 (lr:0.001172530707119987)
3860: accuracy:0.35 loss: 269.142 (lr:0.0011512931761997675)
3880: accuracy:0.15 loss: 293.643 (lr:0.001130476176567457)
3900: accuracy:0.01 loss: 384.011 (lr:0.0011100713811456392)
3920: accuracy:0.13 loss: 328.539 (lr:0.0010900706277440775)
3940: accuracy:0.43 loss: 244.596 (lr:0.001070465915794731)
3960: accuracy:0.19 loss: 300.87 (lr:0.0010512494031514206)
3980: accuracy:0.22 loss: 312.884 (lr:0.0010324134029528653)
4000: accuracy:0.06 loss: 272.976 (lr:0.0010139503805478354)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
4000: ********* epoch 1 ********* test accuracy for all:0.0339459 test loss: 448.586
4000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 757.089
4000: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 909.783
4000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 429.474
4000: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 412.401
4000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 341.99
4000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 362.792
4000: ********* epoch 1 ********* test accuracy for mode 27:0.2935 test loss: 331.324
4000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 374.025
4000: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 476.589
4000: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 525.878
4000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 529.609
4000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 538.053
4000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 527.891
4000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 477.53
4000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 487.94
4000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 1008.25
4020: accuracy:0.24 loss: 311.64 (lr:0.000995852950481193)
4040: accuracy:0.32 loss: 253.107 (lr:0.0009781138735396073)
4060: accuracy:0.07 loss: 308.274 (lr:0.0009607260538557794)
4080: accuracy:0.13 loss: 302.289 (lr:0.0009436825360699935)
4100: accuracy:0.01 loss: 277.285 (lr:0.0009269765025478867)
4120: accuracy:0.18 loss: 262.408 (lr:0.0009106012706532986)
4140: accuracy:0.09 loss: 332.33 (lr:0.0008945502900751338)
4160: accuracy:0.47 loss: 235.827 (lr:0.0008788171402071433)
4180: accuracy:0.08 loss: 311.072 (lr:0.0008633955275796034)
4200: accuracy:0.21 loss: 264.793 (lr:0.0008482792833418375)
4220: accuracy:0.0 loss: 358.878 (lr:0.000833462360794599)
4240: accuracy:0.2 loss: 253.105 (lr:0.0008189388329713063)
4260: accuracy:0.13 loss: 288.971 (lr:0.0008047028902671817)
4280: accuracy:0.36 loss: 247.43 (lr:0.0007907488381153271)
4300: accuracy:0.33 loss: 253.415 (lr:0.0007770710947088267)
4320: accuracy:0.24 loss: 261.951 (lr:0.000763664188767944)
4340: accuracy:0.26 loss: 263.903 (lr:0.000750522757351543)
4360: accuracy:0.17 loss: 328.117 (lr:0.0007376415437118345)
4380: accuracy:0.2 loss: 299.033 (lr:0.0007250153951916118)
4400: accuracy:0.14 loss: 276.615 (lr:0.000712639261163115)
4420: accuracy:0.13 loss: 311.986 (lr:0.0007005081910077164)
4440: accuracy:0.1 loss: 305.815 (lr:0.000688617332135603)
4460: accuracy:0.04 loss: 277.88 (lr:0.00067696192804468)
4480: accuracy:0.06 loss: 270.987 (lr:0.0006655373164179026)
4500: accuracy:0.22 loss: 290.431 (lr:0.0006543389272582912)
4520: accuracy:0.14 loss: 280.688 (lr:0.0006433622810608672)
4540: accuracy:0.18 loss: 300.407 (lr:0.000632602987020794)
4560: accuracy:0.1 loss: 253.926 (lr:0.0006220567412769975)
4580: accuracy:0.03 loss: 352.657 (lr:0.0006117193251905607)
4600: accuracy:0.05 loss: 278.987 (lr:0.000601586603657216)
4620: accuracy:0.03 loss: 331.601 (lr:0.0005916545234532441)
4640: accuracy:0.17 loss: 267.404 (lr:0.0005819191116141351)
4660: accuracy:0.03 loss: 303.541 (lr:0.0005723764738453451)
4680: accuracy:0.12 loss: 313.657 (lr:0.0005630227929645308)
4700: accuracy:0.19 loss: 275.36 (lr:0.0005538543273746212)
4720: accuracy:0.23 loss: 241.146 (lr:0.0005448674095671338)
4740: accuracy:0.2 loss: 274.868 (lr:0.0005360584446551173)
4760: accuracy:0.19 loss: 302.153 (lr:0.0005274239089351532)
4780: accuracy:0.35 loss: 243.171 (lr:0.0005189603484778245)
4800: accuracy:0.08 loss: 327.111 (lr:0.0005106643777460996)
4820: accuracy:0.18 loss: 285.731 (lr:0.0005025326782410708)
4840: accuracy:0.16 loss: 307.417 (lr:0.0004945619971745128)
4860: accuracy:0.3 loss: 251.999 (lr:0.0004867491461677209)
4880: accuracy:0.05 loss: 336.071 (lr:0.00047909099997612057)
4900: accuracy:0.22 loss: 258.921 (lr:0.00047158449523912444)
4920: accuracy:0.14 loss: 254.845 (lr:0.0004642266292547503)
4940: accuracy:0.08 loss: 339.897 (lr:0.0004570144587784975)
4960: accuracy:0.02 loss: 330.343 (lr:0.0004499450988460127)
4980: accuracy:0.29 loss: 271.399 (lr:0.0004430157216190628)
5000: accuracy:0.21 loss: 252.143 (lr:0.0004362235552543648)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
5000: ********* epoch 1 ********* test accuracy for all:0.0458919 test loss: 416.027
5000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 780.703
5000: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 813.814
5000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 380.804
5000: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 326.282
5000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 249.741
5000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 554.151
5000: ********* epoch 1 ********* test accuracy for mode 27:0.718 test loss: 208.738
5000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 309.469
5000: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 386.956
5000: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 423.519
5000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 450.977
5000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 469.516
5000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 461.989
5000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 431.851
5000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 603.535
5000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 1057.13
5020: accuracy:0.06 loss: 338.308 (lr:0.00042956588279480907)
5040: accuracy:0.14 loss: 305.931 (lr:0.0004230400410826413)
5060: accuracy:0.11 loss: 312.016 (lr:0.00041664341969416485)
5080: accuracy:0.31 loss: 255.492 (lr:0.00041037345989553437)
5100: accuracy:0.26 loss: 244.878 (lr:0.0004042276536192303)
5120: accuracy:0.05 loss: 370.041 (lr:0.0003982035424607965)
5140: accuracy:0.1 loss: 308.136 (lr:0.0003922987166954475)
5160: accuracy:0.2 loss: 276.443 (lr:0.00038651081431414466)
5180: accuracy:0.15 loss: 272.292 (lr:0.00038083752007876285)
5200: accuracy:0.18 loss: 293.607 (lr:0.0003752765645959625)
5220: accuracy:0.12 loss: 297.626 (lr:0.0003698257234094039)
5240: accuracy:0.11 loss: 304.336 (lr:0.00036448281610993306)
5260: accuracy:0.4 loss: 262.723 (lr:0.000359245705463391)
5280: accuracy:0.2 loss: 288.814 (lr:0.0003541122965556896)
5300: accuracy:0.08 loss: 341.398 (lr:0.00034908053595481984)
5320: accuracy:0.11 loss: 340.271 (lr:0.0003441484108894498)
5340: accuracy:0.07 loss: 319.802 (lr:0.00033931394844379144)
5360: accuracy:0.22 loss: 313.427 (lr:0.00033457521476840547)
5380: accuracy:0.04 loss: 366.978 (lr:0.0003299303143066383)
5400: accuracy:0.23 loss: 320.538 (lr:0.00032537738903637203)
5420: accuracy:0.05 loss: 368.453 (lr:0.0003209146177267924)
5440: accuracy:0.02 loss: 329.375 (lr:0.00031654021520987084)
5460: accuracy:0.03 loss: 348.783 (lr:0.0003122524316662748)
5480: accuracy:0.02 loss: 348.875 (lr:0.00030804955192541517)
5500: accuracy:0.04 loss: 324.824 (lr:0.00030392989477935693)
5520: accuracy:0.11 loss: 324.807 (lr:0.000299891812310312)
5540: accuracy:0.04 loss: 345.384 (lr:0.0002959336892314506)
5560: accuracy:0.03 loss: 351.22 (lr:0.0002920539422407661)
5580: accuracy:0.06 loss: 327.428 (lr:0.00028825101938773106)
5600: accuracy:0.09 loss: 320.69 (lr:0.00028452339945249833)
5620: accuracy:0.01 loss: 337.906 (lr:0.0002808695913373912)
5640: accuracy:0.02 loss: 346.806 (lr:0.00027728813347044595)
5660: accuracy:0.01 loss: 352.513 (lr:0.000273777593220762)
5680: accuracy:0.0 loss: 350.409 (lr:0.00027033656632543195)
5700: accuracy:0.05 loss: 324.532 (lr:0.0002669636763278165)
5720: accuracy:0.05 loss: 338.52 (lr:0.0002636575740269443)
5740: accuracy:0.1 loss: 321.349 (lr:0.00026041693693781284)
5760: accuracy:0.04 loss: 344.921 (lr:0.00025724046876237765)
5780: accuracy:0.12 loss: 311.682 (lr:0.00025412689887101476)
5800: accuracy:0.04 loss: 326.711 (lr:0.0002510749817942532)
5820: accuracy:0.01 loss: 314.058 (lr:0.0002480834967245691)
5840: accuracy:0.04 loss: 336.159 (lr:0.00024515124702804796)
5860: accuracy:0.03 loss: 319.146 (lr:0.00024227705976571364)
5880: accuracy:0.04 loss: 345.198 (lr:0.00023945978522433848)
5900: accuracy:0.04 loss: 324.846 (lr:0.00023669829645654158)
5920: accuracy:0.05 loss: 305.71 (lr:0.00023399148882999565)
5940: accuracy:0.05 loss: 334.371 (lr:0.00023133827958555858)
5960: accuracy:0.04 loss: 325.221 (lr:0.00022873760740415628)
5980: accuracy:0.04 loss: 319.947 (lr:0.00022618843198223985)
6000: accuracy:0.06 loss: 316.604 (lr:0.0002236897336156513)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
6000: ********* epoch 1 ********* test accuracy for all:0.049527 test loss: 399.705
6000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 827.53
6000: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 862.512
6000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 360.879
6000: ********* epoch 1 ********* test accuracy for mode 24:0.001 test loss: 245.395
6000: ********* epoch 1 ********* test accuracy for mode 25:0.9705 test loss: 220.352
6000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 694.995
6000: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 252.527
6000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 242.723
6000: ********* epoch 1 ********* test accuracy for mode 29:0.0 test loss: 296.782
6000: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 327.914
6000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 368.484
6000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 408.45
6000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 407.037
6000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 391.57
6000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 723.716
6000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 1174.93
6020: accuracy:0.04 loss: 320.812 (lr:0.00022124051279172742)
6040: accuracy:0.03 loss: 303.935 (lr:0.00021883978978948186)
6060: accuracy:0.09 loss: 305.98 (lr:0.00021648660428770386)
6080: accuracy:0.08 loss: 301.824 (lr:0.00021418001498081624)
6100: accuracy:0.08 loss: 296.591 (lr:0.00021191909920234157)
6120: accuracy:0.14 loss: 290.831 (lr:0.0002097029525558223)
6140: accuracy:0.05 loss: 312.087 (lr:0.000207530688553051)
6160: accuracy:0.07 loss: 301.316 (lr:0.00020540143825946243)
6180: accuracy:0.01 loss: 352.153 (lr:0.00020331434994654902)
6200: accuracy:0.04 loss: 329.735 (lr:0.00020126858875115715)
6220: accuracy:0.08 loss: 297.693 (lr:0.00019926333634153165)
6240: accuracy:0.06 loss: 327.116 (lr:0.0001972977905899715)
6260: accuracy:0.1 loss: 303.8 (lr:0.00019537116525196864)
6280: accuracy:0.11 loss: 305.791 (lr:0.00019348268965169892)
6300: accuracy:0.01 loss: 308.984 (lr:0.00019163160837374246)
6320: accuracy:0.03 loss: 314.147 (lr:0.0001898171809609065)
6340: accuracy:0.06 loss: 301.539 (lr:0.00018803868161803336)
6360: accuracy:0.07 loss: 343.384 (lr:0.00018629539892167207)
6380: accuracy:0.38 loss: 289.542 (lr:0.0001845866355355002)
6400: accuracy:0.07 loss: 311.949 (lr:0.0001829117079313793)
6420: accuracy:0.03 loss: 339.868 (lr:0.0001812699461159352)
6440: accuracy:0.08 loss: 320.926 (lr:0.00017966069336255116)
6460: accuracy:0.08 loss: 319.524 (lr:0.0001780833059486689)
6480: accuracy:0.15 loss: 294.621 (lr:0.0001765371528982907)
6500: accuracy:0.12 loss: 302.906 (lr:0.00017502161572958085)
6520: accuracy:0.08 loss: 300.466 (lr:0.0001735360882074644)
6540: accuracy:0.06 loss: 322.528 (lr:0.00017207997610112512)
6560: accuracy:0.13 loss: 298.481 (lr:0.0001706526969463055)
6580: accuracy:0.11 loss: 312.055 (lr:0.00016925367981231285)
6600: accuracy:0.07 loss: 315.562 (lr:0.00016788236507363991)
6620: accuracy:0.05 loss: 316.081 (lr:0.00016653820418610665)
6640: accuracy:0.12 loss: 326.387 (lr:0.00016522065946743573)
6660: accuracy:0.06 loss: 318.96 (lr:0.00016392920388217215)
6680: accuracy:0.12 loss: 305.046 (lr:0.00016266332083086224)
6700: accuracy:0.12 loss: 326.577 (lr:0.0001614225039434067)
6720: accuracy:0.1 loss: 313.033 (lr:0.0001602062568765062)
6740: accuracy:0.13 loss: 290.516 (lr:0.0001590140931151171)
6760: accuracy:0.19 loss: 306.755 (lr:0.0001578455357778391)
6780: accuracy:0.06 loss: 332.943 (lr:0.00015670011742615632)
6800: accuracy:0.11 loss: 304.08 (lr:0.0001555773798774557)
6820: accuracy:0.1 loss: 312.914 (lr:0.0001544768740217476)
6840: accuracy:0.06 loss: 314.598 (lr:0.00015339815964201625)
6860: accuracy:0.08 loss: 322.107 (lr:0.00015234080523812663)
6880: accuracy:0.06 loss: 326.256 (lr:0.000151304387854219)
6900: accuracy:0.06 loss: 320.187 (lr:0.00015028849290952068)
6920: accuracy:0.07 loss: 321.359 (lr:0.00014929271403250837)
6940: accuracy:0.07 loss: 310.631 (lr:0.00014831665289835396)
6960: accuracy:0.07 loss: 322.183 (lr:0.00014735991906958954)
6980: accuracy:0.09 loss: 308.354 (lr:0.00014642212983992695)
7000: accuracy:0.1 loss: 299.638 (lr:0.00014550291008117035)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
7000: ********* epoch 1 ********* test accuracy for all:0.0483649 test loss: 412.246
7000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 946.66
7000: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 1090.79
7000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 364.215
7000: ********* epoch 1 ********* test accuracy for mode 24:0.8345 test loss: 242.824
7000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 293.932
7000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 854.986
7000: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 354.781
7000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 264.028
7000: ********* epoch 1 ********* test accuracy for mode 29:0.0515 test loss: 268.763
7000: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 308.41
7000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 348.059
7000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 379.479
7000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 388.822
7000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 380.859
7000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 815.249
7000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 1209.93
7020: accuracy:0.14 loss: 296.061 (lr:0.0001446018920931598)
7040: accuracy:0.11 loss: 314.707 (lr:0.00014371871545668625)
7060: accuracy:0.13 loss: 302.796 (lr:0.00014285302688931943)
7080: accuracy:0.0 loss: 326.378 (lr:0.0001420044801040896)
7100: accuracy:0.03 loss: 313.747 (lr:0.00014117273567096865)
7120: accuracy:0.07 loss: 314.205 (lr:0.00014035746088109316)
7140: accuracy:0.13 loss: 299.517 (lr:0.00013955832961367681)
7160: accuracy:0.07 loss: 311.502 (lr:0.00013877502220555732)
7180: accuracy:0.11 loss: 296.388 (lr:0.0001380072253233273)
7200: accuracy:0.08 loss: 322.636 (lr:0.0001372546318379963)
7220: accuracy:0.21 loss: 298.785 (lr:0.0001365169407021356)
7240: accuracy:0.1 loss: 308.204 (lr:0.00013579385682945474)
7260: accuracy:0.15 loss: 308.368 (lr:0.00013508509097676352)
7280: accuracy:0.11 loss: 317.087 (lr:0.00013439035962827038)
7300: accuracy:0.17 loss: 326.726 (lr:0.00013370938488217285)
7320: accuracy:0.24 loss: 293.86 (lr:0.0001330418943394926)
7340: accuracy:0.14 loss: 301.952 (lr:0.00013238762099511265)
7360: accuracy:0.08 loss: 323.706 (lr:0.0001317463031309714)
7380: accuracy:0.14 loss: 309.256 (lr:0.00013111768421137228)
7400: accuracy:0.05 loss: 320.152 (lr:0.00013050151278036566)
7420: accuracy:0.12 loss: 295.565 (lr:0.0001298975423611635)
7440: accuracy:0.09 loss: 329.361 (lr:0.00012930553135754496)
7460: accuracy:0.06 loss: 313.03 (lr:0.00012872524295721508)
7480: accuracy:0.12 loss: 312.784 (lr:0.00012815644503707643)
7500: accuracy:0.09 loss: 322.075 (lr:0.0001275989100703769)
7520: accuracy:0.05 loss: 328.809 (lr:0.0001270524150356959)
7540: accuracy:0.15 loss: 317.264 (lr:0.00012651674132773284)
7560: accuracy:0.13 loss: 287.77 (lr:0.00012599167466986213)
7580: accuracy:0.11 loss: 300.289 (lr:0.00012547700502841966)
7600: accuracy:0.04 loss: 303.362 (lr:0.00012497252652868648)
7620: accuracy:0.06 loss: 299.355 (lr:0.00012447803737253624)
7640: accuracy:0.11 loss: 298.815 (lr:0.0001239933397577132)
7660: accuracy:0.11 loss: 315.501 (lr:0.0001235182397987087)
7680: accuracy:0.04 loss: 330.592 (lr:0.00012305254744920442)
7700: accuracy:0.02 loss: 304.956 (lr:0.0001225960764260512)
7720: accuracy:0.08 loss: 292.743 (lr:0.0001221486441347534)
7740: accuracy:0.05 loss: 331.279 (lr:0.00012171007159642874)
7760: accuracy:0.05 loss: 301.906 (lr:0.00012128018337621413)
7780: accuracy:0.02 loss: 339.456 (lr:0.00012085880751308955)
7800: accuracy:0.04 loss: 304.046 (lr:0.00012044577545109136)
7820: accuracy:0.04 loss: 322.314 (lr:0.00012004092197188757)
7840: accuracy:0.06 loss: 327.354 (lr:0.00011964408512868841)
7860: accuracy:0.03 loss: 304.22 (lr:0.00011925510618146534)
7880: accuracy:0.26 loss: 307.138 (lr:0.00011887382953345302)
7900: accuracy:0.05 loss: 323.548 (lr:0.00011850010266890851)
7920: accuracy:0.17 loss: 296.904 (lr:0.00011813377609210288)
7940: accuracy:0.0 loss: 352.398 (lr:0.000117774703267521)
7960: accuracy:0.05 loss: 324.442 (lr:0.00011742274056124534)
7980: accuracy:0.22 loss: 314.504 (lr:0.00011707774718350047)
8000: accuracy:0.15 loss: 293.274 (lr:0.00011673958513233535)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
8000: ********* epoch 1 ********* test accuracy for all:0.056973 test loss: 423.722
8000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 943.975
8000: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 1088.45
8000: ********* epoch 1 ********* test accuracy for mode 2:0.0 test loss: 341.143
8000: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 295.621
8000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 345.714
8000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 1096.19
8000: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 413.868
8000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 316.835
8000: ********* epoch 1 ********* test accuracy for mode 29:0.203 test loss: 254.061
8000: ********* epoch 1 ********* test accuracy for mode 30:0.0 test loss: 278.197
8000: ********* epoch 1 ********* test accuracy for mode 31:0.0 test loss: 311.263
8000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 345.365
8000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 344.801
8000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 348.916
8000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 929.419
8000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 1351.5
8020: accuracy:0.04 loss: 334.57 (lr:0.00011640811913842059)
8040: accuracy:0.11 loss: 295.261 (lr:0.00011608321661093906)
8060: accuracy:0.1 loss: 289.507 (lr:0.00011576474758454761)
8080: accuracy:0.13 loss: 288.385 (lr:0.00011545258466738945)
8100: accuracy:0.05 loss: 326.06 (lr:0.00011514660299013546)
8120: accuracy:0.05 loss: 315.317 (lr:0.00011484668015603492)
8140: accuracy:0.06 loss: 317.27 (lr:0.00011455269619195513)
8160: accuracy:0.13 loss: 314.103 (lr:0.0001142645335003907)
8180: accuracy:0.07 loss: 297.262 (lr:0.00011398207681242274)
8200: accuracy:0.27 loss: 289.505 (lr:0.00011370521314160992)
8220: accuracy:0.07 loss: 312.082 (lr:0.00011343383173879234)
8240: accuracy:0.01 loss: 334.805 (lr:0.00011316782404779044)
8260: accuracy:0.05 loss: 312.204 (lr:0.00011290708366198097)
8280: accuracy:0.07 loss: 304.504 (lr:0.00011265150628173305)
8300: accuracy:0.04 loss: 336.551 (lr:0.0001124009896726868)
8320: accuracy:0.05 loss: 296.907 (lr:0.00011215543362485838)
8340: accuracy:0.08 loss: 318.652 (lr:0.00011191473991255451)
8360: accuracy:0.12 loss: 289.221 (lr:0.00011167881225508098)
8380: accuracy:0.11 loss: 305.904 (lr:0.00011144755627822904)
8400: accuracy:0.11 loss: 310.864 (lr:0.00011122087947652453)
8420: accuracy:0.11 loss: 289.427 (lr:0.00011099869117622435)
8440: accuracy:0.06 loss: 324.903 (lr:0.00011078090249904583)
8460: accuracy:0.02 loss: 313.037 (lr:0.00011056742632661419)
8480: accuracy:0.13 loss: 300.807 (lr:0.00011035817726561411)
8500: accuracy:0.07 loss: 311.368 (lr:0.00011015307161363115)
8520: accuracy:0.12 loss: 295.166 (lr:0.00010995202732566973)
8540: accuracy:0.15 loss: 310.29 (lr:0.00010975496398133405)
8560: accuracy:0.1 loss: 317.426 (lr:0.00010956180275265881)
8580: accuracy:0.16 loss: 308.289 (lr:0.00010937246637257705)
8600: accuracy:0.14 loss: 291.705 (lr:0.00010918687910401221)
8620: accuracy:0.16 loss: 301.099 (lr:0.00010900496670958233)
8640: accuracy:0.11 loss: 304.303 (lr:0.00010882665642190407)
8660: accuracy:0.04 loss: 325.322 (lr:0.00010865187691448493)
8680: accuracy:0.08 loss: 302.103 (lr:0.00010848055827319147)
8700: accuracy:0.18 loss: 310.362 (lr:0.00010831263196828292)
8720: accuracy:0.04 loss: 314.364 (lr:0.00010814803082699823)
8740: accuracy:0.13 loss: 285.718 (lr:0.00010798668900668621)
8760: accuracy:0.15 loss: 307.781 (lr:0.00010782854196846747)
8780: accuracy:0.14 loss: 299.47 (lr:0.00010767352645141807)
8800: accuracy:0.02 loss: 332.576 (lr:0.00010752158044726429)
8820: accuracy:0.21 loss: 279.854 (lr:0.00010737264317557849)
8840: accuracy:0.03 loss: 297.4 (lr:0.00010722665505946614)
8860: accuracy:0.0 loss: 310.366 (lr:0.00010708355770173426)
8880: accuracy:0.0 loss: 326.947 (lr:0.00010694329386153176)
8900: accuracy:0.02 loss: 311.428 (lr:0.00010680580743145238)
8920: accuracy:0.0 loss: 306.846 (lr:0.00010667104341509088)
8940: accuracy:0.02 loss: 314.909 (lr:0.00010653894790504385)
8960: accuracy:0.03 loss: 319.242 (lr:0.00010640946806134595)
8980: accuracy:0.02 loss: 304.055 (lr:0.00010628255209033333)
9000: accuracy:0.01 loss: 322.106 (lr:0.00010615814922392531)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
9000: ********* epoch 1 ********* test accuracy for all:0.0573649 test loss: 440.471
9000: ********* epoch 1 ********* test accuracy for mode 0:0.0 test loss: 984.743
9000: ********* epoch 1 ********* test accuracy for mode 1:0.0 test loss: 1171.27
9000: ********* epoch 1 ********* test accuracy for mode 2:0.108 test loss: 308.381
9000: ********* epoch 1 ********* test accuracy for mode 24:0.0 test loss: 349.739
9000: ********* epoch 1 ********* test accuracy for mode 25:0.0 test loss: 390.232
9000: ********* epoch 1 ********* test accuracy for mode 26:0.0 test loss: 1102.15
9000: ********* epoch 1 ********* test accuracy for mode 27:0.0 test loss: 438.114
9000: ********* epoch 1 ********* test accuracy for mode 28:0.0 test loss: 369.982
9000: ********* epoch 1 ********* test accuracy for mode 29:0.004 test loss: 311.154
9000: ********* epoch 1 ********* test accuracy for mode 30:0.437 test loss: 279.893
9000: ********* epoch 1 ********* test accuracy for mode 31:0.021 test loss: 300.797
9000: ********* epoch 1 ********* test accuracy for mode 32:0.0 test loss: 320.306
9000: ********* epoch 1 ********* test accuracy for mode 33:0.0 test loss: 328.979
9000: ********* epoch 1 ********* test accuracy for mode 34:0.0 test loss: 331.67
9000: ********* epoch 1 ********* test accuracy for mode 35:0.0 test loss: 969.562
9000: ********* epoch 1 ********* test accuracy for mode 36:0.0 test loss: 1349.77
9020: accuracy:0.03 loss: 305.685 (lr:0.00010603620969931663)
9040: accuracy:0.03 loss: 307.014 (lr:0.00010591668473907152)
9060: accuracy:0.09 loss: 301.095 (lr:0.00010579952653161222)
9080: accuracy:0.03 loss: 282.064 (lr:0.00010568468821209364)
9100: accuracy:0.15 loss: 299.733 (lr:0.00010557212384365674)
9120: accuracy:0.04 loss: 313.568 (lr:0.00010546178839905328)
9140: accuracy:0.14 loss: 290.808 (lr:0.00010535363774263423)
9160: accuracy:0.08 loss: 297.201 (lr:0.00010524762861269505)
9180: accuracy:0.18 loss: 315.036 (lr:0.00010514371860417026)
9200: accuracy:0.1 loss: 310.209 (lr:0.00010504186615167096)
9220: accuracy:0.09 loss: 295.432 (lr:0.00010494203051285811)
9240: accuracy:0.04 loss: 303.211 (lr:0.00010484417175214503)
9260: accuracy:0.06 loss: 314.589 (lr:0.00010474825072472262)
9280: accuracy:0.12 loss: 310.832 (lr:0.00010465422906090095)
9300: accuracy:0.1 loss: 304.727 (lr:0.00010456206915076085)
9320: accuracy:0.08 loss: 300.105 (lr:0.00010447173412910947)
9340: accuracy:0.13 loss: 308.398 (lr:0.00010438318786073364)
9360: accuracy:0.08 loss: 310.523 (lr:0.00010429639492594539)
9380: accuracy:0.04 loss: 299.357 (lr:0.00010421132060641354)
9400: accuracy:0.02 loss: 307.661 (lr:0.00010412793087127595)
9420: accuracy:0.07 loss: 300.459 (lr:0.00010404619236352669)
9440: accuracy:0.04 loss: 296.234 (lr:0.00010396607238667279)
9460: accuracy:0.07 loss: 299.67 (lr:0.00010388753889165522)
9480: accuracy:0.04 loss: 305.707 (lr:0.00010381056046402886)
9500: accuracy:0.08 loss: 292.713 (lr:0.00010373510631139626)
9520: accuracy:0.15 loss: 291.625 (lr:0.00010366114625109031)
9540: accuracy:0.08 loss: 289.844 (lr:0.00010358865069810072)
9560: accuracy:0.15 loss: 287.568 (lr:0.00010351759065323969)
9580: accuracy:0.21 loss: 277.884 (lr:0.00010344793769154178)
9600: accuracy:0.11 loss: 292.341 (lr:0.00010337966395089361)
9620: accuracy:0.1 loss: 290.528 (lr:0.00010331274212088859)
9640: accuracy:0.16 loss: 284.914 (lr:0.0001032471454319024)
9660: accuracy:0.07 loss: 283.17 (lr:0.00010318284764438482)
9680: accuracy:0.17 loss: 281.014 (lr:0.00010311982303836354)
9700: accuracy:0.06 loss: 288.521 (lr:0.00010305804640315579)
9720: accuracy:0.0 loss: 288.937 (lr:0.0001029974930272838)
9740: accuracy:0.02 loss: 444.42 (lr:0.00010293813868858982)
9760: accuracy:0.04 loss: 454.983 (lr:0.000102879959644547)
9780: accuracy:0.07 loss: 448.84 (lr:0.00010282293262276196)
9800: accuracy:0.05 loss: 468.81 (lr:0.00010276703481166564)
9820: accuracy:0.02 loss: 442.164 (lr:0.00010271224385138826)
9840: accuracy:0.05 loss: 411.972 (lr:0.00010265853782481518)
9860: accuracy:0.02 loss: 450.671 (lr:0.00010260589524881967)
9880: accuracy:0.03 loss: 437.788 (lr:0.00010255429506566942)
9900: accuracy:0.01 loss: 427.444 (lr:0.00010250371663460315)
9920: accuracy:0.04 loss: 428.289 (lr:0.00010245413972357407)
9940: accuracy:0.03 loss: 433.133 (lr:0.00010240554450115671)
9960: accuracy:0.03 loss: 437.597 (lr:0.00010235791152861415)
9980: accuracy:0.05 loss: 422.435 (lr:0.00010231122175212231)
10000: accuracy:0.0 loss: 462.448 (lr:0.000102265456495148)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
10000: ********* epoch 2 ********* test accuracy for all:0.0597838 test loss: 419.563
10000: ********* epoch 2 ********* test accuracy for mode 0:0.0 test loss: 932.361
10000: ********* epoch 2 ********* test accuracy for mode 1:0.0 test loss: 1104.26
10000: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 299.806
10000: ********* epoch 2 ********* test accuracy for mode 24:0.0 test loss: 355.522
10000: ********* epoch 2 ********* test accuracy for mode 25:0.0 test loss: 382.335
10000: ********* epoch 2 ********* test accuracy for mode 26:0.0 test loss: 942.635
10000: ********* epoch 2 ********* test accuracy for mode 27:0.0 test loss: 404.855
10000: ********* epoch 2 ********* test accuracy for mode 28:0.0 test loss: 368.566
10000: ********* epoch 2 ********* test accuracy for mode 29:0.001 test loss: 328.166
10000: ********* epoch 2 ********* test accuracy for mode 30:0.0 test loss: 307.084
10000: ********* epoch 2 ********* test accuracy for mode 31:0.3165 test loss: 299.096
10000: ********* epoch 2 ********* test accuracy for mode 32:0.005 test loss: 301.84
10000: ********* epoch 2 ********* test accuracy for mode 33:0.4285 test loss: 281.05
10000: ********* epoch 2 ********* test accuracy for mode 34:0.173 test loss: 290.703
10000: ********* epoch 2 ********* test accuracy for mode 35:0.0 test loss: 895.325
10000: ********* epoch 2 ********* test accuracy for mode 36:0.0 test loss: 1185.34
10020: accuracy:0.05 loss: 427.741 (lr:0.00010222059745097824)
10040: accuracy:0.02 loss: 421.433 (lr:0.00010217662667539724)
10060: accuracy:0.05 loss: 397.742 (lr:0.00010213352657950847)
10080: accuracy:0.03 loss: 383.632 (lr:0.0001020912799226989)
10100: accuracy:0.01 loss: 440.269 (lr:0.00010204986980574251)
10120: accuracy:0.01 loss: 413.014 (lr:0.00010200927966404038)
10140: accuracy:0.09 loss: 391.916 (lr:0.00010196949326099463)
10160: accuracy:0.06 loss: 380.87 (lr:0.00010193049468151353)
10180: accuracy:0.02 loss: 427.376 (lr:0.0001018922683256453)
10200: accuracy:0.04 loss: 398.094 (lr:0.00010185479890233792)
10220: accuracy:0.03 loss: 387.015 (lr:0.00010181807142332246)
10240: accuracy:0.07 loss: 383.515 (lr:0.0001017820711971176)
10260: accuracy:0.04 loss: 393.351 (lr:0.00010174678382315285)
10280: accuracy:0.05 loss: 373.041 (lr:0.00010171219518600814)
10300: accuracy:0.04 loss: 384.754 (lr:0.00010167829144976738)
10320: accuracy:0.07 loss: 379.547 (lr:0.00010164505905248406)
10340: accuracy:0.02 loss: 361.943 (lr:0.00010161248470075614)
10360: accuracy:0.0 loss: 389.193 (lr:0.00010158055536440861)
10380: accuracy:0.06 loss: 381.441 (lr:0.00010154925827128119)
10400: accuracy:0.04 loss: 373.519 (lr:0.00010151858090211935)
10420: accuracy:0.03 loss: 399.667 (lr:0.00010148851098556636)
10440: accuracy:0.04 loss: 400.437 (lr:0.00010145903649325467)
10460: accuracy:0.06 loss: 366.322 (lr:0.00010143014563499438)
10480: accuracy:0.04 loss: 398.027 (lr:0.00010140182685405693)
10500: accuracy:0.05 loss: 406.555 (lr:0.00010137406882255239)
10520: accuracy:0.09 loss: 351.685 (lr:0.00010134686043689803)
10540: accuracy:0.07 loss: 379.187 (lr:0.0001013201908133768)
10560: accuracy:0.1 loss: 357.841 (lr:0.0001012940492837837)
10580: accuracy:0.05 loss: 383.455 (lr:0.00010126842539115834)
10600: accuracy:0.08 loss: 343.545 (lr:0.00010124330888560201)
10620: accuracy:0.05 loss: 400.733 (lr:0.0001012186897201776)
10640: accuracy:0.03 loss: 375.896 (lr:0.00010119455804689066)
10660: accuracy:0.05 loss: 361.551 (lr:0.00010117090421275013)
10680: accuracy:0.05 loss: 369.781 (lr:0.00010114771875590698)
10700: accuracy:0.04 loss: 377.273 (lr:0.00010112499240186929)
10720: accuracy:0.04 loss: 374.871 (lr:0.00010110271605979246)
10740: accuracy:0.07 loss: 369.931 (lr:0.00010108088081884263)
10760: accuracy:0.08 loss: 389.994 (lr:0.00010105947794463226)
10780: accuracy:0.08 loss: 381.159 (lr:0.00010103849887572631)
10800: accuracy:0.08 loss: 353.51 (lr:0.00010101793522021748)
10820: accuracy:0.04 loss: 375.178 (lr:0.0001009977787523694)
10840: accuracy:0.11 loss: 389.092 (lr:0.00010097802140932616)
10860: accuracy:0.08 loss: 336.808 (lr:0.0001009586552878871)
10880: accuracy:0.04 loss: 355.11 (lr:0.00010093967264134544)
10900: accuracy:0.09 loss: 356.985 (lr:0.00010092106587638946)
10920: accuracy:0.07 loss: 341.695 (lr:0.00010090282755006507)
10940: accuracy:0.05 loss: 367.57 (lr:0.00010088495036679857)
10960: accuracy:0.11 loss: 341.584 (lr:0.00010086742717547828)
10980: accuracy:0.08 loss: 381.514 (lr:0.00010085025096659404)
11000: accuracy:0.03 loss: 394.171 (lr:0.00010083341486943327)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
11000: ********* epoch 2 ********* test accuracy for all:0.064473 test loss: 394.21
11000: ********* epoch 2 ********* test accuracy for mode 0:0.0 test loss: 902.599
11000: ********* epoch 2 ********* test accuracy for mode 1:0.0025 test loss: 1028.77
11000: ********* epoch 2 ********* test accuracy for mode 2:0.0785 test loss: 313.087
11000: ********* epoch 2 ********* test accuracy for mode 24:0.0785 test loss: 331.125
11000: ********* epoch 2 ********* test accuracy for mode 25:0.003 test loss: 325.958
11000: ********* epoch 2 ********* test accuracy for mode 26:0.0 test loss: 721.124
11000: ********* epoch 2 ********* test accuracy for mode 27:0.1975 test loss: 331.257
11000: ********* epoch 2 ********* test accuracy for mode 28:0.0 test loss: 328.67
11000: ********* epoch 2 ********* test accuracy for mode 29:0.0515 test loss: 324.998
11000: ********* epoch 2 ********* test accuracy for mode 30:0.054 test loss: 326.014
11000: ********* epoch 2 ********* test accuracy for mode 31:0.0835 test loss: 320.792
11000: ********* epoch 2 ********* test accuracy for mode 32:0.0 test loss: 315.216
11000: ********* epoch 2 ********* test accuracy for mode 33:0.211 test loss: 304.661
11000: ********* epoch 2 ********* test accuracy for mode 34:0.003 test loss: 306.363
11000: ********* epoch 2 ********* test accuracy for mode 35:0.0 test loss: 745.954
11000: ********* epoch 2 ********* test accuracy for mode 36:0.0 test loss: 975.421
11020: accuracy:0.1 loss: 348.771 (lr:0.0001008169121493326)
11040: accuracy:0.07 loss: 357.011 (lr:0.00010080073620498399)
11060: accuracy:0.11 loss: 379.129 (lr:0.00010078488056579399)
11080: accuracy:0.04 loss: 354.039 (lr:0.00010076933888929553)
11100: accuracy:0.06 loss: 382.984 (lr:0.00010075410495861078)
11120: accuracy:0.03 loss: 363.631 (lr:0.00010073917267996432)
11140: accuracy:0.13 loss: 341.162 (lr:0.00010072453608024563)
11160: accuracy:0.04 loss: 368.772 (lr:0.00010071018930461964)
11180: accuracy:0.06 loss: 330.112 (lr:0.00010069612661418482)
11200: accuracy:0.08 loss: 359.778 (lr:0.00010068234238367749)
11220: accuracy:0.09 loss: 349.399 (lr:0.00010066883109922163)
11240: accuracy:0.06 loss: 407.466 (lr:0.00010065558735612335)
11260: accuracy:0.12 loss: 331.876 (lr:0.00010064260585670879)
11280: accuracy:0.1 loss: 344.908 (lr:0.0001006298814082051)
11300: accuracy:0.1 loss: 351.369 (lr:0.00010061740892066324)
11320: accuracy:0.1 loss: 370.21 (lr:0.00010060518340492185)
11340: accuracy:0.11 loss: 349.842 (lr:0.00010059319997061167)
11360: accuracy:0.1 loss: 358.06 (lr:0.00010058145382419917)
11380: accuracy:0.11 loss: 326.233 (lr:0.00010056994026706917)
11400: accuracy:0.09 loss: 395.95 (lr:0.0001005586546936453)
11420: accuracy:0.04 loss: 348.461 (lr:0.0001005475925895477)
11440: accuracy:0.09 loss: 362.262 (lr:0.00010053674952978728)
11460: accuracy:0.09 loss: 348.77 (lr:0.00010052612117699551)
11480: accuracy:0.09 loss: 344.841 (lr:0.0001005157032796896)
11500: accuracy:0.04 loss: 340.314 (lr:0.00010050549167057168)
11520: accuracy:0.1 loss: 348.413 (lr:0.00010049548226486198)
11540: accuracy:0.08 loss: 345.253 (lr:0.00010048567105866473)
11560: accuracy:0.09 loss: 336.127 (lr:0.00010047605412736666)
11580: accuracy:0.08 loss: 369.1 (lr:0.000100466627624067)
11600: accuracy:0.07 loss: 338.556 (lr:0.00010045738777803876)
11620: accuracy:0.05 loss: 396.808 (lr:0.00010044833089322032)
11640: accuracy:0.12 loss: 317.162 (lr:0.00010043945334673699)
11660: accuracy:0.06 loss: 343.387 (lr:0.0001004307515874518)
11680: accuracy:0.12 loss: 332.271 (lr:0.00010042222213454505)
11700: accuracy:0.1 loss: 337.836 (lr:0.0001004138615761218)
11720: accuracy:0.07 loss: 356.792 (lr:0.00010040566656784722)
11740: accuracy:0.05 loss: 363.77 (lr:0.00010039763383160876)
11760: accuracy:0.04 loss: 347.955 (lr:0.00010038976015420479)
11780: accuracy:0.04 loss: 349.249 (lr:0.00010038204238605937)
11800: accuracy:0.12 loss: 355.709 (lr:0.00010037447743996235)
11820: accuracy:0.08 loss: 350.754 (lr:0.00010036706228983439)
11840: accuracy:0.06 loss: 347.805 (lr:0.00010035979396951662)
11860: accuracy:0.1 loss: 363.126 (lr:0.00010035266957158396)
11880: accuracy:0.07 loss: 357.004 (lr:0.00010034568624618225)
11900: accuracy:0.09 loss: 316.767 (lr:0.00010033884119988824)
11920: accuracy:0.08 loss: 356.092 (lr:0.00010033213169459212)
11940: accuracy:0.06 loss: 340.173 (lr:0.00010032555504640233)
11960: accuracy:0.04 loss: 342.551 (lr:0.00010031910862457187)
11980: accuracy:0.04 loss: 343.399 (lr:0.0001003127898504461)
12000: accuracy:0.12 loss: 338.931 (lr:0.00010030659619643108)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
12000: ********* epoch 2 ********* test accuracy for all:0.0706486 test loss: 383.331
12000: ********* epoch 2 ********* test accuracy for mode 0:0.0 test loss: 844.183
12000: ********* epoch 2 ********* test accuracy for mode 1:0.0665 test loss: 1000.37
12000: ********* epoch 2 ********* test accuracy for mode 2:0.0465 test loss: 322.036
12000: ********* epoch 2 ********* test accuracy for mode 24:0.0575 test loss: 328.166
12000: ********* epoch 2 ********* test accuracy for mode 25:0.099 test loss: 315.157
12000: ********* epoch 2 ********* test accuracy for mode 26:0.0 test loss: 653.469
12000: ********* epoch 2 ********* test accuracy for mode 27:0.151 test loss: 318.642
12000: ********* epoch 2 ********* test accuracy for mode 28:0.0105 test loss: 319.772
12000: ********* epoch 2 ********* test accuracy for mode 29:0.056 test loss: 328.876
12000: ********* epoch 2 ********* test accuracy for mode 30:0.001 test loss: 334.566
12000: ********* epoch 2 ********* test accuracy for mode 31:0.0395 test loss: 330.498
12000: ********* epoch 2 ********* test accuracy for mode 32:0.0 test loss: 324.795
12000: ********* epoch 2 ********* test accuracy for mode 33:0.117 test loss: 316.832
12000: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 316.215
12000: ********* epoch 2 ********* test accuracy for mode 35:0.0 test loss: 695.353
12000: ********* epoch 2 ********* test accuracy for mode 36:0.0 test loss: 935.012
12020: accuracy:0.07 loss: 349.967 (lr:0.00010030052518498265)
12040: accuracy:0.11 loss: 386.809 (lr:0.00010029457438761526)
12060: accuracy:0.06 loss: 384.189 (lr:0.00010028874142393062)
12080: accuracy:0.09 loss: 341.783 (lr:0.0001002830239606655)
12100: accuracy:0.15 loss: 326.669 (lr:0.00010027741971075835)
12120: accuracy:0.06 loss: 348.544 (lr:0.00010027192643243447)
12140: accuracy:0.04 loss: 348.696 (lr:0.00010026654192830931)
12160: accuracy:0.03 loss: 326.648 (lr:0.00010026126404450941)
12180: accuracy:0.07 loss: 331.593 (lr:0.00010025609066981089)
12200: accuracy:0.06 loss: 331.815 (lr:0.00010025101973479487)
12220: accuracy:0.05 loss: 331.61 (lr:0.00010024604921101974)
12240: accuracy:0.09 loss: 355.629 (lr:0.00010024117711020972)
12260: accuracy:0.1 loss: 350.819 (lr:0.00010023640148345952)
12280: accuracy:0.09 loss: 330.642 (lr:0.00010023172042045477)
12300: accuracy:0.09 loss: 320.948 (lr:0.00010022713204870785)
12320: accuracy:0.07 loss: 331.478 (lr:0.00010022263453280888)
12340: accuracy:0.08 loss: 319.284 (lr:0.00010021822607369154)
12360: accuracy:0.12 loss: 341.789 (lr:0.0001002139049079134)
12380: accuracy:0.15 loss: 334.376 (lr:0.00010020966930695051)
12400: accuracy:0.1 loss: 325.655 (lr:0.00010020551757650603)
12420: accuracy:0.05 loss: 335.637 (lr:0.00010020144805583244)
12440: accuracy:0.06 loss: 342.669 (lr:0.00010019745911706718)
12460: accuracy:0.09 loss: 336.626 (lr:0.00010019354916458157)
12480: accuracy:0.08 loss: 350.596 (lr:0.00010018971663434248)
12500: accuracy:0.14 loss: 320.901 (lr:0.00010018595999328673)
12520: accuracy:0.15 loss: 325.644 (lr:0.00010018227773870779)
12540: accuracy:0.08 loss: 351.129 (lr:0.00010017866839765473)
12560: accuracy:0.09 loss: 333.118 (lr:0.00010017513052634301)
12580: accuracy:0.09 loss: 359.662 (lr:0.00010017166270957693)
12600: accuracy:0.09 loss: 331.756 (lr:0.00010016826356018355)
12620: accuracy:0.06 loss: 360.602 (lr:0.00010016493171845778)
12640: accuracy:0.14 loss: 323.607 (lr:0.00010016166585161853)
12660: accuracy:0.03 loss: 342.538 (lr:0.00010015846465327549)
12680: accuracy:0.09 loss: 339.092 (lr:0.00010015532684290664)
12700: accuracy:0.05 loss: 338.673 (lr:0.00010015225116534602)
12720: accuracy:0.06 loss: 381.055 (lr:0.00010014923639028158)
12740: accuracy:0.07 loss: 328.025 (lr:0.0001001462813117631)
12760: accuracy:0.05 loss: 335.743 (lr:0.00010014338474771976)
12780: accuracy:0.08 loss: 342.878 (lr:0.00010014054553948732)
12800: accuracy:0.07 loss: 325.902 (lr:0.00010013776255134467)
12820: accuracy:0.1 loss: 315.434 (lr:0.00010013503467005939)
12840: accuracy:0.14 loss: 326.982 (lr:0.00010013236080444263)
12860: accuracy:0.13 loss: 331.467 (lr:0.00010012973988491248)
12880: accuracy:0.07 loss: 327.175 (lr:0.00010012717086306618)
12900: accuracy:0.06 loss: 335.531 (lr:0.00010012465271126075)
12920: accuracy:0.06 loss: 354.748 (lr:0.00010012218442220188)
12940: accuracy:0.06 loss: 353.394 (lr:0.00010011976500854103)
12960: accuracy:0.08 loss: 328.832 (lr:0.0001001173935024805)
12980: accuracy:0.06 loss: 325.204 (lr:0.00010011506895538621)
13000: accuracy:0.09 loss: 343.779 (lr:0.00010011279043740836)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
13000: ********* epoch 2 ********* test accuracy for all:0.0775811 test loss: 373.986
13000: ********* epoch 2 ********* test accuracy for mode 0:0.0 test loss: 744.666
13000: ********* epoch 2 ********* test accuracy for mode 1:0.0455 test loss: 923.442
13000: ********* epoch 2 ********* test accuracy for mode 2:0.0245 test loss: 329.677
13000: ********* epoch 2 ********* test accuracy for mode 24:0.033 test loss: 336.341
13000: ********* epoch 2 ********* test accuracy for mode 25:0.0855 test loss: 323.233
13000: ********* epoch 2 ********* test accuracy for mode 26:0.001 test loss: 602.559
13000: ********* epoch 2 ********* test accuracy for mode 27:0.1775 test loss: 323.783
13000: ********* epoch 2 ********* test accuracy for mode 28:0.0125 test loss: 325.316
13000: ********* epoch 2 ********* test accuracy for mode 29:0.0485 test loss: 341.128
13000: ********* epoch 2 ********* test accuracy for mode 30:0.0 test loss: 339.106
13000: ********* epoch 2 ********* test accuracy for mode 31:0.0215 test loss: 337.177
13000: ********* epoch 2 ********* test accuracy for mode 32:0.005 test loss: 328.634
13000: ********* epoch 2 ********* test accuracy for mode 33:0.08 test loss: 318.973
13000: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 321.0
13000: ********* epoch 2 ********* test accuracy for mode 35:0.0 test loss: 655.346
13000: ********* epoch 2 ********* test accuracy for mode 36:0.0 test loss: 941.105
13020: accuracy:0.07 loss: 325.772 (lr:0.00010011055703710937)
13040: accuracy:0.09 loss: 355.188 (lr:0.00010010836786109933)
13060: accuracy:0.1 loss: 351.22 (lr:0.00010010622203367864)
13080: accuracy:0.15 loss: 323.45 (lr:0.00010010411869648775)
13100: accuracy:0.05 loss: 353.706 (lr:0.00010010205700816373)
13120: accuracy:0.09 loss: 322.214 (lr:0.00010010003614400375)
13140: accuracy:0.11 loss: 317.278 (lr:0.00010009805529563519)
13160: accuracy:0.13 loss: 345.743 (lr:0.00010009611367069231)
13180: accuracy:0.06 loss: 344.547 (lr:0.00010009421049249925)
13200: accuracy:0.09 loss: 365.631 (lr:0.00010009234499975934)
13220: accuracy:0.06 loss: 318.902 (lr:0.00010009051644625062)
13240: accuracy:0.06 loss: 330.458 (lr:0.0001000887241005273)
13260: accuracy:0.08 loss: 333.67 (lr:0.0001000869672456272)
13280: accuracy:0.07 loss: 337.452 (lr:0.00010008524517878492)
13300: accuracy:0.11 loss: 339.432 (lr:0.00010008355721115078)
13320: accuracy:0.11 loss: 340.455 (lr:0.0001000819026675152)
13340: accuracy:0.05 loss: 351.831 (lr:0.00010008028088603869)
13360: accuracy:0.06 loss: 350.124 (lr:0.00010007869121798701)
13380: accuracy:0.08 loss: 336.142 (lr:0.00010007713302747177)
13400: accuracy:0.06 loss: 349.879 (lr:0.00010007560569119595)
13420: accuracy:0.12 loss: 314.345 (lr:0.00010007410859820472)
13440: accuracy:0.07 loss: 339.291 (lr:0.00010007264114964088)
13460: accuracy:0.13 loss: 330.256 (lr:0.00010007120275850547)
13480: accuracy:0.12 loss: 329.105 (lr:0.00010006979284942284)
13500: accuracy:0.07 loss: 335.838 (lr:0.00010006841085841057)
13520: accuracy:0.09 loss: 344.114 (lr:0.00010006705623265382)
13540: accuracy:0.12 loss: 317.787 (lr:0.00010006572843028422)
13560: accuracy:0.12 loss: 334.971 (lr:0.00010006442692016313)
13580: accuracy:0.07 loss: 325.34 (lr:0.00010006315118166913)
13600: accuracy:0.09 loss: 314.932 (lr:0.00010006190070448985)
13620: accuracy:0.1 loss: 336.796 (lr:0.0001000606749884177)
13640: accuracy:0.05 loss: 334.059 (lr:0.00010005947354314994)
13660: accuracy:0.09 loss: 329.33 (lr:0.00010005829588809241)
13680: accuracy:0.15 loss: 342.838 (lr:0.00010005714155216743)
13700: accuracy:0.06 loss: 347.747 (lr:0.0001000560100736252)
13720: accuracy:0.06 loss: 322.849 (lr:0.00010005490099985924)
13740: accuracy:0.09 loss: 333.902 (lr:0.00010005381388722523)
13760: accuracy:0.12 loss: 324.527 (lr:0.00010005274830086365)
13780: accuracy:0.13 loss: 316.196 (lr:0.00010005170381452574)
13800: accuracy:0.09 loss: 330.662 (lr:0.00010005068001040303)
13820: accuracy:0.07 loss: 329.566 (lr:0.00010004967647896023)
13840: accuracy:0.06 loss: 343.532 (lr:0.00010004869281877136)
13860: accuracy:0.07 loss: 348.858 (lr:0.00010004772863635926)
13880: accuracy:0.14 loss: 302.119 (lr:0.00010004678354603808)
13900: accuracy:0.15 loss: 332.617 (lr:0.00010004585716975912)
13920: accuracy:0.07 loss: 328.961 (lr:0.00010004494913695949)
13940: accuracy:0.08 loss: 339.443 (lr:0.00010004405908441398)
13960: accuracy:0.07 loss: 328.122 (lr:0.00010004318665608969)
13980: accuracy:0.1 loss: 327.393 (lr:0.00010004233150300367)
14000: accuracy:0.05 loss: 364.138 (lr:0.00010004149328308327)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
14000: ********* epoch 2 ********* test accuracy for all:0.0820405 test loss: 359.427
14000: ********* epoch 2 ********* test accuracy for mode 0:0.002 test loss: 632.27
14000: ********* epoch 2 ********* test accuracy for mode 1:0.0735 test loss: 776.385
14000: ********* epoch 2 ********* test accuracy for mode 2:0.0165 test loss: 334.709
14000: ********* epoch 2 ********* test accuracy for mode 24:0.0145 test loss: 329.323
14000: ********* epoch 2 ********* test accuracy for mode 25:0.053 test loss: 313.164
14000: ********* epoch 2 ********* test accuracy for mode 26:0.0005 test loss: 517.012
14000: ********* epoch 2 ********* test accuracy for mode 27:0.2385 test loss: 314.886
14000: ********* epoch 2 ********* test accuracy for mode 28:0.0395 test loss: 315.191
14000: ********* epoch 2 ********* test accuracy for mode 29:0.0615 test loss: 333.649
14000: ********* epoch 2 ********* test accuracy for mode 30:0.0015 test loss: 339.173
14000: ********* epoch 2 ********* test accuracy for mode 31:0.0285 test loss: 335.142
14000: ********* epoch 2 ********* test accuracy for mode 32:0.0075 test loss: 329.394
14000: ********* epoch 2 ********* test accuracy for mode 33:0.0565 test loss: 321.358
14000: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 322.896
14000: ********* epoch 2 ********* test accuracy for mode 35:0.0015 test loss: 604.256
14000: ********* epoch 2 ********* test accuracy for mode 36:0.0 test loss: 852.273
14020: accuracy:0.09 loss: 329.211 (lr:0.00010004067166102936)
14040: accuracy:0.17 loss: 328.276 (lr:0.00010003986630818217)
14060: accuracy:0.12 loss: 346.893 (lr:0.00010003907690238979)
14080: accuracy:0.1 loss: 323.159 (lr:0.00010003830312787941)
14100: accuracy:0.07 loss: 327.17 (lr:0.0001000375446751309)
14120: accuracy:0.14 loss: 323.739 (lr:0.00010003680124075304)
14140: accuracy:0.06 loss: 318.565 (lr:0.00010003607252736218)
14160: accuracy:0.08 loss: 335.594 (lr:0.00010003535824346323)
14180: accuracy:0.08 loss: 315.784 (lr:0.00010003465810333311)
14200: accuracy:0.09 loss: 323.724 (lr:0.00010003397182690645)
14220: accuracy:0.03 loss: 337.235 (lr:0.0001000332991396635)
14240: accuracy:0.08 loss: 326.658 (lr:0.00010003263977252042)
14260: accuracy:0.08 loss: 324.383 (lr:0.00010003199346172156)
14280: accuracy:0.09 loss: 334.271 (lr:0.00010003135994873396)
14300: accuracy:0.09 loss: 326.482 (lr:0.000100030738980144)
14320: accuracy:0.07 loss: 327.941 (lr:0.00010003013030755594)
14340: accuracy:0.04 loss: 358.232 (lr:0.00010002953368749266)
14360: accuracy:0.06 loss: 336.648 (lr:0.00010002894888129816)
14380: accuracy:0.07 loss: 325.06 (lr:0.00010002837565504217)
14400: accuracy:0.07 loss: 335.562 (lr:0.00010002781377942655)
14420: accuracy:0.05 loss: 326.829 (lr:0.00010002726302969355)
14440: accuracy:0.11 loss: 310.456 (lr:0.00010002672318553595)
14460: accuracy:0.15 loss: 316.7 (lr:0.00010002619403100886)
14480: accuracy:0.07 loss: 340.518 (lr:0.00010002567535444344)
14500: accuracy:0.09 loss: 330.159 (lr:0.00010002516694836214)
14520: accuracy:0.08 loss: 329.952 (lr:0.00010002466860939576)
14540: accuracy:0.12 loss: 316.076 (lr:0.00010002418013820203)
14560: accuracy:0.09 loss: 323.068 (lr:0.00010002370133938601)
14580: accuracy:0.12 loss: 332.503 (lr:0.00010002323202142176)
14600: accuracy:0.1 loss: 343.073 (lr:0.00010002277199657585)
14620: accuracy:0.13 loss: 330.581 (lr:0.0001000223210808322)
14640: accuracy:0.02 loss: 326.358 (lr:0.00010002187909381849)
14660: accuracy:0.13 loss: 319.855 (lr:0.00010002144585873403)
14680: accuracy:0.07 loss: 325.103 (lr:0.00010002102120227902)
14700: accuracy:0.1 loss: 315.491 (lr:0.00010002060495458521)
14720: accuracy:0.08 loss: 326.355 (lr:0.00010002019694914797)
14740: accuracy:0.05 loss: 334.507 (lr:0.00010001979702275969)
14760: accuracy:0.1 loss: 319.73 (lr:0.00010001940501544447)
14780: accuracy:0.07 loss: 327.331 (lr:0.00010001902077039416)
14800: accuracy:0.08 loss: 325.199 (lr:0.00010001864413390563)
14820: accuracy:0.1 loss: 323.898 (lr:0.00010001827495531926)
14840: accuracy:0.14 loss: 327.958 (lr:0.00010001791308695868)
14860: accuracy:0.12 loss: 315.427 (lr:0.00010001755838407172)
14880: accuracy:0.11 loss: 326.99 (lr:0.0001000172107047725)
14900: accuracy:0.07 loss: 335.183 (lr:0.00010001686990998469)
14920: accuracy:0.13 loss: 317.874 (lr:0.0001000165358633858)
14940: accuracy:0.08 loss: 325.145 (lr:0.00010001620843135274)
14960: accuracy:0.15 loss: 334.419 (lr:0.00010001588748290834)
14980: accuracy:0.07 loss: 319.419 (lr:0.00010001557288966894)
15000: accuracy:0.05 loss: 321.932 (lr:0.00010001526452579304)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
15000: ********* epoch 2 ********* test accuracy for all:0.0851486 test loss: 352.742
15000: ********* epoch 2 ********* test accuracy for mode 0:0.042 test loss: 592.803
15000: ********* epoch 2 ********* test accuracy for mode 1:0.0795 test loss: 733.693
15000: ********* epoch 2 ********* test accuracy for mode 2:0.0015 test loss: 337.511
15000: ********* epoch 2 ********* test accuracy for mode 24:0.015 test loss: 338.265
15000: ********* epoch 2 ********* test accuracy for mode 25:0.18 test loss: 319.182
15000: ********* epoch 2 ********* test accuracy for mode 26:0.0015 test loss: 450.89
15000: ********* epoch 2 ********* test accuracy for mode 27:0.094 test loss: 322.135
15000: ********* epoch 2 ********* test accuracy for mode 28:0.047 test loss: 322.002
15000: ********* epoch 2 ********* test accuracy for mode 29:0.0725 test loss: 342.929
15000: ********* epoch 2 ********* test accuracy for mode 30:0.0035 test loss: 347.271
15000: ********* epoch 2 ********* test accuracy for mode 31:0.0255 test loss: 344.435
15000: ********* epoch 2 ********* test accuracy for mode 32:0.0035 test loss: 335.672
15000: ********* epoch 2 ********* test accuracy for mode 33:0.0185 test loss: 328.002
15000: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 326.233
15000: ********* epoch 2 ********* test accuracy for mode 35:0.015 test loss: 563.535
15000: ********* epoch 2 ********* test accuracy for mode 36:0.0 test loss: 816.127
15020: accuracy:0.07 loss: 317.724 (lr:0.000100014962267931)
15040: accuracy:0.15 loss: 323.97 (lr:0.00010001466599517563)
15060: accuracy:0.08 loss: 333.431 (lr:0.00010001437558901388)
15080: accuracy:0.09 loss: 336.634 (lr:0.0001000140909332794)
15100: accuracy:0.07 loss: 319.903 (lr:0.00010001381191410613)
15120: accuracy:0.09 loss: 330.082 (lr:0.00010001353841988265)
15140: accuracy:0.09 loss: 326.876 (lr:0.00010001327034120764)
15160: accuracy:0.09 loss: 322.295 (lr:0.00010001300757084606)
15180: accuracy:0.09 loss: 317.082 (lr:0.00010001275000368625)
15200: accuracy:0.08 loss: 324.352 (lr:0.00010001249753669792)
15220: accuracy:0.13 loss: 316.463 (lr:0.0001000122500688909)
15240: accuracy:0.05 loss: 326.532 (lr:0.00010001200750127478)
15260: accuracy:0.11 loss: 318.273 (lr:0.00010001176973681928)
15280: accuracy:0.07 loss: 317.144 (lr:0.00010001153668041542)
15300: accuracy:0.16 loss: 326.965 (lr:0.00010001130823883756)
15320: accuracy:0.13 loss: 305.784 (lr:0.000100011084320706)
15340: accuracy:0.08 loss: 322.872 (lr:0.00010001086483645054)
15360: accuracy:0.15 loss: 324.812 (lr:0.00010001064969827451)
15380: accuracy:0.13 loss: 311.076 (lr:0.0001000104388201198)
15400: accuracy:0.11 loss: 311.959 (lr:0.00010001023211763231)
15420: accuracy:0.05 loss: 320.458 (lr:0.00010001002950812831)
15440: accuracy:0.09 loss: 311.057 (lr:0.00010000983091056129)
15460: accuracy:0.1 loss: 321.72 (lr:0.00010000963624548957)
15480: accuracy:0.1 loss: 316.793 (lr:0.00010000944543504453)
15500: accuracy:0.11 loss: 320.505 (lr:0.00010000925840289946)
15520: accuracy:0.1 loss: 335.437 (lr:0.00010000907507423899)
15540: accuracy:0.11 loss: 321.065 (lr:0.00010000889537572922)
15560: accuracy:0.12 loss: 312.324 (lr:0.00010000871923548834)
15580: accuracy:0.08 loss: 305.594 (lr:0.00010000854658305793)
15600: accuracy:0.07 loss: 320.075 (lr:0.00010000837734937468)
15620: accuracy:0.09 loss: 325.004 (lr:0.00010000821146674289)
15640: accuracy:0.11 loss: 328.299 (lr:0.00010000804886880728)
15660: accuracy:0.04 loss: 327.642 (lr:0.00010000788949052652)
15680: accuracy:0.07 loss: 326.828 (lr:0.00010000773326814716)
15700: accuracy:0.08 loss: 326.855 (lr:0.00010000758013917817)
15720: accuracy:0.16 loss: 314.998 (lr:0.00010000743004236593)
15740: accuracy:0.09 loss: 337.596 (lr:0.0001000072829176697)
15760: accuracy:0.08 loss: 331.206 (lr:0.00010000713870623764)
15780: accuracy:0.15 loss: 317.057 (lr:0.00010000699735038326)
15800: accuracy:0.08 loss: 311.643 (lr:0.00010000685879356234)
15820: accuracy:0.13 loss: 319.163 (lr:0.00010000672298035029)
15840: accuracy:0.05 loss: 314.043 (lr:0.00010000658985642002)
15860: accuracy:0.08 loss: 307.858 (lr:0.00010000645936852018)
15880: accuracy:0.1 loss: 320.635 (lr:0.00010000633146445388)
15900: accuracy:0.12 loss: 325.732 (lr:0.00010000620609305779)
15920: accuracy:0.09 loss: 305.519 (lr:0.00010000608320418165)
15940: accuracy:0.08 loss: 315.78 (lr:0.00010000596274866832)
15960: accuracy:0.14 loss: 324.689 (lr:0.00010000584467833394)
15980: accuracy:0.1 loss: 319.718 (lr:0.00010000572894594884)
16000: accuracy:0.06 loss: 341.793 (lr:0.00010000561550521849)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
16000: ********* epoch 2 ********* test accuracy for all:0.0879054 test loss: 344.093
16000: ********* epoch 2 ********* test accuracy for mode 0:0.074 test loss: 536.512
16000: ********* epoch 2 ********* test accuracy for mode 1:0.075 test loss: 655.803
16000: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 344.752
16000: ********* epoch 2 ********* test accuracy for mode 24:0.0165 test loss: 335.333
16000: ********* epoch 2 ********* test accuracy for mode 25:0.2335 test loss: 314.152
16000: ********* epoch 2 ********* test accuracy for mode 26:0.025 test loss: 364.78
16000: ********* epoch 2 ********* test accuracy for mode 27:0.0585 test loss: 321.004
16000: ********* epoch 2 ********* test accuracy for mode 28:0.0845 test loss: 319.642
16000: ********* epoch 2 ********* test accuracy for mode 29:0.0785 test loss: 342.785
16000: ********* epoch 2 ********* test accuracy for mode 30:0.0025 test loss: 349.704
16000: ********* epoch 2 ********* test accuracy for mode 31:0.0265 test loss: 349.371
16000: ********* epoch 2 ********* test accuracy for mode 32:0.002 test loss: 339.966
16000: ********* epoch 2 ********* test accuracy for mode 33:0.013 test loss: 330.772
16000: ********* epoch 2 ********* test accuracy for mode 34:0.0 test loss: 325.56
16000: ********* epoch 2 ********* test accuracy for mode 35:0.034 test loss: 529.242
16000: ********* epoch 2 ********* test accuracy for mode 36:0.0015 test loss: 779.407
16020: accuracy:0.13 loss: 316.471 (lr:0.00010000550431076512)
16040: accuracy:0.07 loss: 321.751 (lr:0.00010000539531810944)
16060: accuracy:0.12 loss: 325.723 (lr:0.00010000528848365294)
16080: accuracy:0.02 loss: 341.015 (lr:0.00010000518376466042)
16100: accuracy:0.07 loss: 325.889 (lr:0.00010000508111924288)
16120: accuracy:0.11 loss: 293.682 (lr:0.00010000498050634078)
16140: accuracy:0.11 loss: 315.978 (lr:0.00010000488188570762)
16160: accuracy:0.13 loss: 321.321 (lr:0.00010000478521789385)
16180: accuracy:0.14 loss: 331.652 (lr:0.00010000469046423104)
16200: accuracy:0.09 loss: 321.451 (lr:0.00010000459758681646)
16220: accuracy:0.14 loss: 329.922 (lr:0.0001000045065484979)
16240: accuracy:0.11 loss: 311.694 (lr:0.00010000441731285883)
16260: accuracy:0.13 loss: 308.565 (lr:0.00010000432984420382)
16280: accuracy:0.1 loss: 330.147 (lr:0.0001000042441075442)
16300: accuracy:0.11 loss: 313.993 (lr:0.0001000041600685842)
16320: accuracy:0.11 loss: 311.373 (lr:0.0001000040776937071)
16340: accuracy:0.11 loss: 332.137 (lr:0.00010000399694996185)
16360: accuracy:0.07 loss: 317.711 (lr:0.00010000391780504988)
16380: accuracy:0.09 loss: 316.713 (lr:0.00010000384022731216)
16400: accuracy:0.12 loss: 298.053 (lr:0.00010000376418571658)
16420: accuracy:0.12 loss: 314.383 (lr:0.00010000368964984548)
16440: accuracy:0.15 loss: 317.861 (lr:0.00010000361658988349)
16460: accuracy:0.08 loss: 327.06 (lr:0.0001000035449766057)
16480: accuracy:0.12 loss: 302.795 (lr:0.0001000034747813658)
16500: accuracy:0.09 loss: 317.446 (lr:0.00010000340597608479)
16520: accuracy:0.17 loss: 315.518 (lr:0.00010000333853323963)
16540: accuracy:0.11 loss: 310.307 (lr:0.00010000327242585227)
16560: accuracy:0.12 loss: 330.742 (lr:0.0001000032076274789)
16580: accuracy:0.08 loss: 318.447 (lr:0.00010000314411219928)
16600: accuracy:0.11 loss: 313.781 (lr:0.00010000308185460646)
16620: accuracy:0.07 loss: 307.025 (lr:0.00010000302082979657)
16640: accuracy:0.06 loss: 323.131 (lr:0.0001000029610133589)
16660: accuracy:0.11 loss: 324.423 (lr:0.00010000290238136602)
16680: accuracy:0.1 loss: 303.628 (lr:0.0001000028449103644)
16700: accuracy:0.06 loss: 315.391 (lr:0.00010000278857736487)
16720: accuracy:0.1 loss: 302.958 (lr:0.00010000273335983345)
16740: accuracy:0.08 loss: 327.774 (lr:0.00010000267923568242)
16760: accuracy:0.12 loss: 312.583 (lr:0.0001000026261832614)
16780: accuracy:0.11 loss: 322.042 (lr:0.00010000257418134868)
16800: accuracy:0.1 loss: 324.13 (lr:0.00010000252320914282)
16820: accuracy:0.1 loss: 320.483 (lr:0.00010000247324625427)
16840: accuracy:0.17 loss: 323.395 (lr:0.0001000024242726972)
16860: accuracy:0.17 loss: 314.9 (lr:0.00010000237626888153)
16880: accuracy:0.13 loss: 321.068 (lr:0.00010000232921560509)
16900: accuracy:0.12 loss: 301.104 (lr:0.00010000228309404596)
16920: accuracy:0.11 loss: 309.552 (lr:0.00010000223788575489)
16940: accuracy:0.13 loss: 308.555 (lr:0.00010000219357264795)
16960: accuracy:0.08 loss: 317.848 (lr:0.00010000215013699932)
16980: accuracy:0.09 loss: 316.64 (lr:0.00010000210756143416)
17000: accuracy:0.15 loss: 314.233 (lr:0.00010000206582892168)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
17000: ********* epoch 2 ********* test accuracy for all:0.0993514 test loss: 332.336
17000: ********* epoch 2 ********* test accuracy for mode 0:0.096 test loss: 495.028
17000: ********* epoch 2 ********* test accuracy for mode 1:0.0615 test loss: 607.043
17000: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 342.177
17000: ********* epoch 2 ********* test accuracy for mode 24:0.007 test loss: 324.326
17000: ********* epoch 2 ********* test accuracy for mode 25:0.2 test loss: 305.301
17000: ********* epoch 2 ********* test accuracy for mode 26:0.2175 test loss: 301.053
17000: ********* epoch 2 ********* test accuracy for mode 27:0.0785 test loss: 318.2
17000: ********* epoch 2 ********* test accuracy for mode 28:0.0735 test loss: 309.375
17000: ********* epoch 2 ********* test accuracy for mode 29:0.096 test loss: 329.063
17000: ********* epoch 2 ********* test accuracy for mode 30:0.001 test loss: 339.001
17000: ********* epoch 2 ********* test accuracy for mode 31:0.0415 test loss: 340.104
17000: ********* epoch 2 ********* test accuracy for mode 32:0.0015 test loss: 332.494
17000: ********* epoch 2 ********* test accuracy for mode 33:0.0235 test loss: 324.422
17000: ********* epoch 2 ********* test accuracy for mode 34:0.0005 test loss: 319.553
17000: ********* epoch 2 ********* test accuracy for mode 35:0.0645 test loss: 496.836
17000: ********* epoch 2 ********* test accuracy for mode 36:0.0035 test loss: 712.674
17020: accuracy:0.18 loss: 317.532 (lr:0.00010000202492276831)
17040: accuracy:0.12 loss: 307.116 (lr:0.00010000198482661104)
17060: accuracy:0.07 loss: 301.076 (lr:0.00010000194552441089)
17080: accuracy:0.15 loss: 316.681 (lr:0.00010000190700044644)
17100: accuracy:0.1 loss: 323.96 (lr:0.0001000018692393076)
17120: accuracy:0.09 loss: 314.377 (lr:0.00010000183222588939)
17140: accuracy:0.11 loss: 309.636 (lr:0.00010000179594538598)
17160: accuracy:0.06 loss: 317.552 (lr:0.00010000176038328468)
17180: accuracy:0.11 loss: 298.989 (lr:0.00010000172552536015)
17200: accuracy:0.1 loss: 314.035 (lr:0.00010000169135766878)
17220: accuracy:0.08 loss: 312.094 (lr:0.00010000165786654303)
17240: accuracy:0.07 loss: 317.0 (lr:0.00010000162503858599)
17260: accuracy:0.09 loss: 297.387 (lr:0.00010000159286066606)
17280: accuracy:0.18 loss: 301.38 (lr:0.00010000156131991163)
17300: accuracy:0.15 loss: 318.575 (lr:0.00010000153040370599)
17320: accuracy:0.11 loss: 300.792 (lr:0.00010000150009968224)
17340: accuracy:0.15 loss: 327.105 (lr:0.00010000147039571836)
17360: accuracy:0.12 loss: 310.631 (lr:0.00010000144127993237)
17380: accuracy:0.08 loss: 308.913 (lr:0.00010000141274067757)
17400: accuracy:0.07 loss: 313.604 (lr:0.00010000138476653788)
17420: accuracy:0.04 loss: 319.377 (lr:0.00010000135734632327)
17440: accuracy:0.12 loss: 302.786 (lr:0.00010000133046906529)
17460: accuracy:0.11 loss: 320.79 (lr:0.00010000130412401267)
17480: accuracy:0.17 loss: 298.906 (lr:0.00010000127830062704)
17500: accuracy:0.07 loss: 323.473 (lr:0.00010000125298857872)
17520: accuracy:0.11 loss: 297.445 (lr:0.00010000122817774254)
17540: accuracy:0.07 loss: 298.652 (lr:0.00010000120385819381)
17560: accuracy:0.1 loss: 309.938 (lr:0.00010000118002020443)
17580: accuracy:0.14 loss: 298.6 (lr:0.00010000115665423885)
17600: accuracy:0.12 loss: 312.11 (lr:0.0001000011337509504)
17620: accuracy:0.09 loss: 301.089 (lr:0.00010000111130117744)
17640: accuracy:0.11 loss: 325.623 (lr:0.00010000108929593978)
17660: accuracy:0.15 loss: 312.489 (lr:0.00010000106772643501)
17680: accuracy:0.11 loss: 301.328 (lr:0.00010000104658403504)
17700: accuracy:0.13 loss: 306.432 (lr:0.00010000102586028266)
17720: accuracy:0.11 loss: 325.173 (lr:0.00010000100554688806)
17740: accuracy:0.12 loss: 295.681 (lr:0.00010000098563572562)
17760: accuracy:0.13 loss: 315.157 (lr:0.00010000096611883061)
17780: accuracy:0.13 loss: 305.233 (lr:0.00010000094698839603)
17800: accuracy:0.17 loss: 303.45 (lr:0.00010000092823676942)
17820: accuracy:0.24 loss: 283.139 (lr:0.0001000009098564499)
17840: accuracy:0.13 loss: 296.359 (lr:0.00010000089184008509)
17860: accuracy:0.06 loss: 294.994 (lr:0.00010000087418046821)
17880: accuracy:0.07 loss: 314.89 (lr:0.00010000085687053517)
17900: accuracy:0.08 loss: 309.02 (lr:0.00010000083990336178)
17920: accuracy:0.13 loss: 315.065 (lr:0.00010000082327216091)
17940: accuracy:0.12 loss: 312.267 (lr:0.0001000008069702799)
17960: accuracy:0.12 loss: 311.26 (lr:0.00010000079099119776)
17980: accuracy:0.1 loss: 301.137 (lr:0.00010000077532852263)
18000: accuracy:0.17 loss: 303.738 (lr:0.00010000075997598926)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
18000: ********* epoch 2 ********* test accuracy for all:0.111662 test loss: 321.916
18000: ********* epoch 2 ********* test accuracy for mode 0:0.0745 test loss: 463.394
18000: ********* epoch 2 ********* test accuracy for mode 1:0.03 test loss: 565.499
18000: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 338.354
18000: ********* epoch 2 ********* test accuracy for mode 24:0.001 test loss: 313.993
18000: ********* epoch 2 ********* test accuracy for mode 25:0.1465 test loss: 295.803
18000: ********* epoch 2 ********* test accuracy for mode 26:0.3995 test loss: 264.957
18000: ********* epoch 2 ********* test accuracy for mode 27:0.057 test loss: 315.648
18000: ********* epoch 2 ********* test accuracy for mode 28:0.0425 test loss: 299.164
18000: ********* epoch 2 ********* test accuracy for mode 29:0.119 test loss: 314.055
18000: ********* epoch 2 ********* test accuracy for mode 30:0.001 test loss: 328.624
18000: ********* epoch 2 ********* test accuracy for mode 31:0.066 test loss: 326.848
18000: ********* epoch 2 ********* test accuracy for mode 32:0.0045 test loss: 320.091
18000: ********* epoch 2 ********* test accuracy for mode 33:0.0645 test loss: 310.221
18000: ********* epoch 2 ********* test accuracy for mode 34:0.0005 test loss: 309.71
18000: ********* epoch 2 ********* test accuracy for mode 35:0.087 test loss: 485.158
18000: ********* epoch 2 ********* test accuracy for mode 36:0.019 test loss: 662.889
18020: accuracy:0.09 loss: 316.27 (lr:0.00010000074492745642)
18040: accuracy:0.12 loss: 311.447 (lr:0.0001000007301769045)
18060: accuracy:0.15 loss: 299.587 (lr:0.00010000071571843307)
18080: accuracy:0.18 loss: 307.314 (lr:0.00010000070154625855)
18100: accuracy:0.12 loss: 310.027 (lr:0.00010000068765471189)
18120: accuracy:0.13 loss: 296.117 (lr:0.0001000006740382363)
18140: accuracy:0.2 loss: 303.236 (lr:0.00010000066069138497)
18160: accuracy:0.13 loss: 306.19 (lr:0.00010000064760881902)
18180: accuracy:0.19 loss: 303.023 (lr:0.00010000063478530522)
18200: accuracy:0.15 loss: 304.13 (lr:0.00010000062221571402)
18220: accuracy:0.14 loss: 286.009 (lr:0.00010000060989501739)
18240: accuracy:0.07 loss: 308.314 (lr:0.0001000005978182869)
18260: accuracy:0.08 loss: 312.442 (lr:0.0001000005859806917)
18280: accuracy:0.1 loss: 307.815 (lr:0.00010000057437749658)
18300: accuracy:0.11 loss: 303.072 (lr:0.00010000056300406013)
18320: accuracy:0.1 loss: 293.265 (lr:0.0001000005518558328)
18340: accuracy:0.12 loss: 305.986 (lr:0.00010000054092835517)
18360: accuracy:0.1 loss: 313.237 (lr:0.00010000053021725609)
18380: accuracy:0.09 loss: 303.248 (lr:0.00010000051971825098)
18400: accuracy:0.13 loss: 291.682 (lr:0.00010000050942714011)
18420: accuracy:0.11 loss: 312.161 (lr:0.00010000049933980688)
18440: accuracy:0.11 loss: 298.486 (lr:0.00010000048945221624)
18460: accuracy:0.21 loss: 307.39 (lr:0.000100000479760413)
18480: accuracy:0.16 loss: 298.599 (lr:0.00010000047026052033)
18500: accuracy:0.1 loss: 316.051 (lr:0.00010000046094873814)
18520: accuracy:0.2 loss: 295.075 (lr:0.00010000045182134159)
18540: accuracy:0.14 loss: 292.101 (lr:0.00010000044287467959)
18560: accuracy:0.16 loss: 308.982 (lr:0.00010000043410517338)
18580: accuracy:0.12 loss: 297.132 (lr:0.00010000042550931502)
18600: accuracy:0.14 loss: 299.28 (lr:0.00010000041708366606)
18620: accuracy:0.09 loss: 303.248 (lr:0.00010000040882485613)
18640: accuracy:0.12 loss: 294.907 (lr:0.0001000004007295816)
18660: accuracy:0.13 loss: 307.085 (lr:0.00010000039279460423)
18680: accuracy:0.12 loss: 294.856 (lr:0.00010000038501674996)
18700: accuracy:0.13 loss: 290.679 (lr:0.00010000037739290751)
18720: accuracy:0.13 loss: 295.393 (lr:0.00010000036992002726)
18740: accuracy:0.11 loss: 296.17 (lr:0.00010000036259511995)
18760: accuracy:0.13 loss: 301.767 (lr:0.00010000035541525551)
18780: accuracy:0.14 loss: 286.346 (lr:0.00010000034837756192)
18800: accuracy:0.12 loss: 321.681 (lr:0.00010000034147922401)
18820: accuracy:0.07 loss: 310.035 (lr:0.00010000033471748235)
18840: accuracy:0.12 loss: 312.014 (lr:0.00010000032808963213)
18860: accuracy:0.11 loss: 305.604 (lr:0.00010000032159302213)
18880: accuracy:0.12 loss: 316.928 (lr:0.00010000031522505364)
18900: accuracy:0.09 loss: 305.121 (lr:0.00010000030898317937)
18920: accuracy:0.08 loss: 298.073 (lr:0.00010000030286490249)
18940: accuracy:0.04 loss: 319.002 (lr:0.00010000029686777562)
18960: accuracy:0.13 loss: 285.703 (lr:0.0001000002909893998)
18980: accuracy:0.1 loss: 301.976 (lr:0.00010000028522742363)
19000: accuracy:0.2 loss: 292.999 (lr:0.00010000027957954223)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
19000: ********* epoch 2 ********* test accuracy for all:0.127703 test loss: 314.155
19000: ********* epoch 2 ********* test accuracy for mode 0:0.042 test loss: 454.016
19000: ********* epoch 2 ********* test accuracy for mode 1:0.0175 test loss: 546.708
19000: ********* epoch 2 ********* test accuracy for mode 2:0.0 test loss: 334.817
19000: ********* epoch 2 ********* test accuracy for mode 24:0.0 test loss: 310.684
19000: ********* epoch 2 ********* test accuracy for mode 25:0.1325 test loss: 289.77
19000: ********* epoch 2 ********* test accuracy for mode 26:0.457 test loss: 246.85
19000: ********* epoch 2 ********* test accuracy for mode 27:0.094 test loss: 312.808
19000: ********* epoch 2 ********* test accuracy for mode 28:0.0355 test loss: 296.908
19000: ********* epoch 2 ********* test accuracy for mode 29:0.1285 test loss: 310.411
19000: ********* epoch 2 ********* test accuracy for mode 30:0.0075 test loss: 321.523
19000: ********* epoch 2 ********* test accuracy for mode 31:0.077 test loss: 321.054
19000: ********* epoch 2 ********* test accuracy for mode 32:0.047 test loss: 306.359
19000: ********* epoch 2 ********* test accuracy for mode 33:0.1415 test loss: 298.333
19000: ********* epoch 2 ********* test accuracy for mode 34:0.0015 test loss: 301.247
19000: ********* epoch 2 ********* test accuracy for mode 35:0.094 test loss: 483.296
19000: ********* epoch 2 ********* test accuracy for mode 36:0.048 test loss: 642.141
19020: accuracy:0.1 loss: 305.082 (lr:0.00010000027404349638)
19040: accuracy:0.16 loss: 296.979 (lr:0.00010000026861707158)
19060: accuracy:0.15 loss: 299.776 (lr:0.0001000002632980972)
19080: accuracy:0.15 loss: 299.926 (lr:0.00010000025808444556)
19100: accuracy:0.17 loss: 304.683 (lr:0.00010000025297403113)
19120: accuracy:0.12 loss: 305.224 (lr:0.0001000002479648097)
19140: accuracy:0.13 loss: 311.352 (lr:0.0001000002430547775)
19160: accuracy:0.18 loss: 287.752 (lr:0.00010000023824197044)
19180: accuracy:0.11 loss: 296.174 (lr:0.00010000023352446335)
19200: accuracy:0.09 loss: 307.464 (lr:0.00010000022890036916)
19220: accuracy:0.2 loss: 274.276 (lr:0.00010000022436783817)
19240: accuracy:0.11 loss: 291.605 (lr:0.00010000021992505731)
19260: accuracy:0.13 loss: 315.599 (lr:0.0001000002155702494)
19280: accuracy:0.19 loss: 281.977 (lr:0.00010000021130167247)
19300: accuracy:0.12 loss: 294.79 (lr:0.00010000020711761903)
19320: accuracy:0.19 loss: 286.943 (lr:0.00010000020301641538)
19340: accuracy:0.11 loss: 300.094 (lr:0.00010000019899642102)
19360: accuracy:0.12 loss: 299.159 (lr:0.00010000019505602788)
19380: accuracy:0.09 loss: 295.432 (lr:0.00010000019119365975)
19400: accuracy:0.09 loss: 297.802 (lr:0.00010000018740777162)
19420: accuracy:0.15 loss: 293.923 (lr:0.00010000018369684912)
19440: accuracy:0.16 loss: 297.554 (lr:0.00010000018005940779)
19460: accuracy:0.09 loss: 288.91 (lr:0.00010000017649399263)
19480: accuracy:0.21 loss: 283.784 (lr:0.00010000017299917743)
19500: accuracy:0.13 loss: 299.515 (lr:0.00010000016957356419)
19520: accuracy:0.16 loss: 288.618 (lr:0.00010000016621578265)
19540: accuracy:0.11 loss: 303.41 (lr:0.00010000016292448965)
19560: accuracy:0.14 loss: 291.324 (lr:0.00010000015969836859)
19580: accuracy:0.11 loss: 312.44 (lr:0.00010000015653612902)
19600: accuracy:0.16 loss: 294.606 (lr:0.00010000015343650599)
19620: accuracy:0.09 loss: 284.395 (lr:0.00010000015039825962)
19640: accuracy:0.12 loss: 313.19 (lr:0.00010000014742017454)
19660: accuracy:0.16 loss: 298.304 (lr:0.0001000001445010595)
19680: accuracy:0.14 loss: 298.184 (lr:0.00010000014163974682)
19700: accuracy:0.1 loss: 294.277 (lr:0.00010000013883509192)
19720: accuracy:0.11 loss: 298.466 (lr:0.00010000013608597291)
19740: accuracy:0.09 loss: 299.018 (lr:0.0001000001333912901)
19760: accuracy:0.19 loss: 291.242 (lr:0.00010000013074996559)
19780: accuracy:0.16 loss: 298.566 (lr:0.0001000001281609428)
19800: accuracy:0.12 loss: 285.032 (lr:0.00010000012562318611)
19820: accuracy:0.18 loss: 284.094 (lr:0.00010000012313568035)
19840: accuracy:0.14 loss: 283.854 (lr:0.00010000012069743052)
19860: accuracy:0.09 loss: 293.756 (lr:0.00010000011830746127)
19880: accuracy:0.14 loss: 301.085 (lr:0.00010000011596481658)
19900: accuracy:0.15 loss: 295.334 (lr:0.00010000011366855937)
19920: accuracy:0.13 loss: 295.963 (lr:0.00010000011141777108)
19940: accuracy:0.16 loss: 294.374 (lr:0.0001000001092115514)
19960: accuracy:0.15 loss: 303.566 (lr:0.0001000001070490178)
19980: accuracy:0.12 loss: 304.476 (lr:0.00010000010492930521)
20000: accuracy:0.1 loss: 291.225 (lr:0.00010000010285156577)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
20000: ********* epoch 3 ********* test accuracy for all:0.133243 test loss: 308.102
20000: ********* epoch 3 ********* test accuracy for mode 0:0.022 test loss: 441.782
20000: ********* epoch 3 ********* test accuracy for mode 1:0.01 test loss: 521.517
20000: ********* epoch 3 ********* test accuracy for mode 2:0.0005 test loss: 326.905
20000: ********* epoch 3 ********* test accuracy for mode 24:0.0115 test loss: 304.154
20000: ********* epoch 3 ********* test accuracy for mode 25:0.1645 test loss: 285.677
20000: ********* epoch 3 ********* test accuracy for mode 26:0.4565 test loss: 239.885
20000: ********* epoch 3 ********* test accuracy for mode 27:0.043 test loss: 312.308
20000: ********* epoch 3 ********* test accuracy for mode 28:0.0425 test loss: 292.319
20000: ********* epoch 3 ********* test accuracy for mode 29:0.1395 test loss: 304.022
20000: ********* epoch 3 ********* test accuracy for mode 30:0.0235 test loss: 315.133
20000: ********* epoch 3 ********* test accuracy for mode 31:0.0685 test loss: 309.963
20000: ********* epoch 3 ********* test accuracy for mode 32:0.0885 test loss: 291.992
20000: ********* epoch 3 ********* test accuracy for mode 33:0.212 test loss: 285.263
20000: ********* epoch 3 ********* test accuracy for mode 34:0.001 test loss: 295.709
20000: ********* epoch 3 ********* test accuracy for mode 35:0.102 test loss: 472.317
20000: ********* epoch 3 ********* test accuracy for mode 36:0.0845 test loss: 607.322
20020: accuracy:0.14 loss: 312.455 (lr:0.0001000001008149683)
20040: accuracy:0.11 loss: 289.304 (lr:0.00010000009881869818)
20060: accuracy:0.17 loss: 284.55 (lr:0.00010000009686195686)
20080: accuracy:0.15 loss: 283.987 (lr:0.0001000000949439616)
20100: accuracy:0.14 loss: 284.72 (lr:0.00010000009306394521)
20120: accuracy:0.18 loss: 292.515 (lr:0.00010000009122115562)
20140: accuracy:0.14 loss: 289.335 (lr:0.00010000008941485572)
20160: accuracy:0.12 loss: 298.998 (lr:0.00010000008764432296)
20180: accuracy:0.17 loss: 278.086 (lr:0.00010000008590884908)
20200: accuracy:0.1 loss: 278.49 (lr:0.0001000000842077399)
20220: accuracy:0.08 loss: 311.372 (lr:0.00010000008254031493)
20240: accuracy:0.13 loss: 296.792 (lr:0.00010000008090590718)
20260: accuracy:0.16 loss: 293.57 (lr:0.00010000007930386289)
20280: accuracy:0.19 loss: 290.775 (lr:0.0001000000777335412)
20300: accuracy:0.14 loss: 314.725 (lr:0.00010000007619431395)
20320: accuracy:0.12 loss: 295.176 (lr:0.00010000007468556545)
20340: accuracy:0.14 loss: 289.452 (lr:0.00010000007320669216)
20360: accuracy:0.15 loss: 287.622 (lr:0.00010000007175710253)
20380: accuracy:0.16 loss: 289.01 (lr:0.0001000000703362167)
20400: accuracy:0.16 loss: 301.564 (lr:0.0001000000689434663)
20420: accuracy:0.17 loss: 297.976 (lr:0.0001000000675782942)
20440: accuracy:0.16 loss: 294.665 (lr:0.00010000006624015432)
20460: accuracy:0.15 loss: 296.086 (lr:0.00010000006492851138)
20480: accuracy:0.07 loss: 300.79 (lr:0.00010000006364284072)
20500: accuracy:0.08 loss: 293.083 (lr:0.00010000006238262804)
20520: accuracy:0.12 loss: 304.192 (lr:0.00010000006114736924)
20540: accuracy:0.19 loss: 286.177 (lr:0.00010000005993657021)
20560: accuracy:0.11 loss: 290.736 (lr:0.0001000000587497466)
20580: accuracy:0.15 loss: 297.558 (lr:0.00010000005758642367)
20600: accuracy:0.13 loss: 290.384 (lr:0.00010000005644613609)
20620: accuracy:0.22 loss: 284.294 (lr:0.0001000000553284277)
20640: accuracy:0.19 loss: 275.75 (lr:0.00010000005423285144)
20660: accuracy:0.22 loss: 306.158 (lr:0.00010000005315896903)
20680: accuracy:0.13 loss: 300.267 (lr:0.00010000005210635091)
20700: accuracy:0.19 loss: 300.775 (lr:0.00010000005107457604)
20720: accuracy:0.11 loss: 305.889 (lr:0.00010000005006323167)
20740: accuracy:0.16 loss: 290.57 (lr:0.00010000004907191326)
20760: accuracy:0.14 loss: 284.917 (lr:0.00010000004810022427)
20780: accuracy:0.15 loss: 285.789 (lr:0.00010000004714777602)
20800: accuracy:0.16 loss: 286.447 (lr:0.00010000004621418751)
20820: accuracy:0.14 loss: 284.912 (lr:0.00010000004529908527)
20840: accuracy:0.1 loss: 296.393 (lr:0.0001000000444021033)
20860: accuracy:0.1 loss: 281.294 (lr:0.00010000004352288274)
20880: accuracy:0.13 loss: 280.809 (lr:0.00010000004266107192)
20900: accuracy:0.22 loss: 283.642 (lr:0.0001000000418163261)
20920: accuracy:0.12 loss: 291.943 (lr:0.00010000004098830737)
20940: accuracy:0.2 loss: 292.465 (lr:0.00010000004017668451)
20960: accuracy:0.17 loss: 286.71 (lr:0.00010000003938113284)
20980: accuracy:0.22 loss: 274.448 (lr:0.00010000003860133417)
21000: accuracy:0.11 loss: 296.989 (lr:0.00010000003783697654)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
21000: ********* epoch 3 ********* test accuracy for all:0.147027 test loss: 302.779
21000: ********* epoch 3 ********* test accuracy for mode 0:0.014 test loss: 448.819
21000: ********* epoch 3 ********* test accuracy for mode 1:0.015 test loss: 522.696
21000: ********* epoch 3 ********* test accuracy for mode 2:0.001 test loss: 318.956
21000: ********* epoch 3 ********* test accuracy for mode 24:0.033 test loss: 309.944
21000: ********* epoch 3 ********* test accuracy for mode 25:0.084 test loss: 295.111
21000: ********* epoch 3 ********* test accuracy for mode 26:0.4315 test loss: 242.159
21000: ********* epoch 3 ********* test accuracy for mode 27:0.135 test loss: 315.071
21000: ********* epoch 3 ********* test accuracy for mode 28:0.0445 test loss: 302.019
21000: ********* epoch 3 ********* test accuracy for mode 29:0.159 test loss: 309.398
21000: ********* epoch 3 ********* test accuracy for mode 30:0.0245 test loss: 315.417
21000: ********* epoch 3 ********* test accuracy for mode 31:0.1095 test loss: 301.483
21000: ********* epoch 3 ********* test accuracy for mode 32:0.246 test loss: 278.903
21000: ********* epoch 3 ********* test accuracy for mode 33:0.135 test loss: 282.534
21000: ********* epoch 3 ********* test accuracy for mode 34:0.001 test loss: 291.2
21000: ********* epoch 3 ********* test accuracy for mode 35:0.0855 test loss: 467.244
21000: ********* epoch 3 ********* test accuracy for mode 36:0.07 test loss: 594.479
21020: accuracy:0.22 loss: 272.705 (lr:0.0001000000370877542)
21040: accuracy:0.18 loss: 291.078 (lr:0.00010000003635336746)
21060: accuracy:0.2 loss: 290.429 (lr:0.00010000003563352256)
21080: accuracy:0.21 loss: 283.995 (lr:0.00010000003492793154)
21100: accuracy:0.14 loss: 292.672 (lr:0.00010000003423631215)
21120: accuracy:0.14 loss: 287.828 (lr:0.00010000003355838776)
21140: accuracy:0.16 loss: 289.206 (lr:0.00010000003289388716)
21160: accuracy:0.19 loss: 269.317 (lr:0.00010000003224254455)
21180: accuracy:0.2 loss: 293.143 (lr:0.00010000003160409939)
21200: accuracy:0.2 loss: 291.821 (lr:0.0001000000309782963)
21220: accuracy:0.16 loss: 288.543 (lr:0.00010000003036488493)
21240: accuracy:0.24 loss: 280.459 (lr:0.00010000002976361993)
21260: accuracy:0.14 loss: 284.154 (lr:0.00010000002917426076)
21280: accuracy:0.1 loss: 290.228 (lr:0.00010000002859657169)
21300: accuracy:0.16 loss: 283.045 (lr:0.00010000002803032164)
21320: accuracy:0.13 loss: 272.865 (lr:0.00010000002747528408)
21340: accuracy:0.11 loss: 289.668 (lr:0.000100000026931237)
21360: accuracy:0.11 loss: 291.622 (lr:0.00010000002639796279)
21380: accuracy:0.17 loss: 279.156 (lr:0.0001000000258752481)
21400: accuracy:0.15 loss: 304.524 (lr:0.00010000002536288386)
21420: accuracy:0.14 loss: 291.458 (lr:0.00010000002486066511)
21440: accuracy:0.15 loss: 303.493 (lr:0.00010000002436839096)
21460: accuracy:0.15 loss: 284.038 (lr:0.00010000002388586448)
21480: accuracy:0.13 loss: 297.061 (lr:0.00010000002341289268)
21500: accuracy:0.17 loss: 297.609 (lr:0.00010000002294928634)
21520: accuracy:0.19 loss: 296.2 (lr:0.00010000002249486002)
21540: accuracy:0.14 loss: 280.028 (lr:0.00010000002204943196)
21560: accuracy:0.16 loss: 307.137 (lr:0.00010000002161282395)
21580: accuracy:0.18 loss: 271.487 (lr:0.00010000002118486137)
21600: accuracy:0.21 loss: 288.968 (lr:0.000100000020765373)
21620: accuracy:0.15 loss: 278.782 (lr:0.00010000002035419106)
21640: accuracy:0.21 loss: 277.943 (lr:0.00010000001995115107)
21660: accuracy:0.17 loss: 280.597 (lr:0.00010000001955609182)
21680: accuracy:0.15 loss: 288.879 (lr:0.00010000001916885526)
21700: accuracy:0.13 loss: 300.242 (lr:0.0001000000187892865)
21720: accuracy:0.16 loss: 280.029 (lr:0.00010000001841723369)
21740: accuracy:0.14 loss: 289.168 (lr:0.00010000001805254803)
21760: accuracy:0.13 loss: 285.395 (lr:0.00010000001769508363)
21780: accuracy:0.12 loss: 297.805 (lr:0.0001000000173446975)
21800: accuracy:0.15 loss: 298.041 (lr:0.00010000001700124948)
21820: accuracy:0.15 loss: 293.591 (lr:0.00010000001666460218)
21840: accuracy:0.15 loss: 287.348 (lr:0.00010000001633462094)
21860: accuracy:0.1 loss: 309.766 (lr:0.00010000001601117378)
21880: accuracy:0.18 loss: 295.543 (lr:0.0001000000156941313)
21900: accuracy:0.13 loss: 281.281 (lr:0.00010000001538336668)
21920: accuracy:0.2 loss: 288.085 (lr:0.0001000000150787556)
21940: accuracy:0.21 loss: 276.159 (lr:0.00010000001478017625)
21960: accuracy:0.13 loss: 292.682 (lr:0.00010000001448750915)
21980: accuracy:0.2 loss: 298.509 (lr:0.00010000001420063724)
22000: accuracy:0.24 loss: 267.27 (lr:0.00010000001391944579)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
22000: ********* epoch 3 ********* test accuracy for all:0.151365 test loss: 301.469
22000: ********* epoch 3 ********* test accuracy for mode 0:0.0135 test loss: 448.416
22000: ********* epoch 3 ********* test accuracy for mode 1:0.0155 test loss: 514.808
22000: ********* epoch 3 ********* test accuracy for mode 2:0.002 test loss: 317.296
22000: ********* epoch 3 ********* test accuracy for mode 24:0.0325 test loss: 317.959
22000: ********* epoch 3 ********* test accuracy for mode 25:0.029 test loss: 315.353
22000: ********* epoch 3 ********* test accuracy for mode 26:0.413 test loss: 247.089
22000: ********* epoch 3 ********* test accuracy for mode 27:0.1405 test loss: 321.457
22000: ********* epoch 3 ********* test accuracy for mode 28:0.0935 test loss: 306.85
22000: ********* epoch 3 ********* test accuracy for mode 29:0.138 test loss: 319.071
22000: ********* epoch 3 ********* test accuracy for mode 30:0.0785 test loss: 313.642
22000: ********* epoch 3 ********* test accuracy for mode 31:0.062 test loss: 303.552
22000: ********* epoch 3 ********* test accuracy for mode 32:0.2705 test loss: 275.829
22000: ********* epoch 3 ********* test accuracy for mode 33:0.1575 test loss: 280.633
22000: ********* epoch 3 ********* test accuracy for mode 34:0.0045 test loss: 286.796
22000: ********* epoch 3 ********* test accuracy for mode 35:0.0775 test loss: 467.989
22000: ********* epoch 3 ********* test accuracy for mode 36:0.037 test loss: 597.078
22020: accuracy:0.18 loss: 293.765 (lr:0.0001000000136438223)
22040: accuracy:0.21 loss: 286.392 (lr:0.00010000001337365652)
22060: accuracy:0.16 loss: 279.679 (lr:0.00010000001310884037)
22080: accuracy:0.12 loss: 269.058 (lr:0.00010000001284926795)
22100: accuracy:0.11 loss: 274.851 (lr:0.00010000001259483539)
22120: accuracy:0.12 loss: 282.372 (lr:0.00010000001234544093)
22140: accuracy:0.1 loss: 285.909 (lr:0.00010000001210098482)
22160: accuracy:0.21 loss: 274.243 (lr:0.00010000001186136927)
22180: accuracy:0.11 loss: 291.997 (lr:0.00010000001162649842)
22200: accuracy:0.23 loss: 289.361 (lr:0.00010000001139627833)
22220: accuracy:0.15 loss: 284.556 (lr:0.0001000000111706169)
22240: accuracy:0.17 loss: 291.316 (lr:0.00010000001094942387)
22260: accuracy:0.13 loss: 291.034 (lr:0.00010000001073261075)
22280: accuracy:0.27 loss: 262.382 (lr:0.00010000001052009081)
22300: accuracy:0.18 loss: 285.847 (lr:0.00010000001031177906)
22320: accuracy:0.22 loss: 277.687 (lr:0.00010000001010759216)
22340: accuracy:0.18 loss: 286.647 (lr:0.00010000000990744843)
22360: accuracy:0.13 loss: 284.663 (lr:0.0001000000097112678)
22380: accuracy:0.19 loss: 266.619 (lr:0.00010000000951897181)
22400: accuracy:0.18 loss: 285.525 (lr:0.00010000000933048355)
22420: accuracy:0.16 loss: 291.3 (lr:0.0001000000091457276)
22440: accuracy:0.16 loss: 292.939 (lr:0.00010000000896463005)
22460: accuracy:0.14 loss: 288.884 (lr:0.00010000000878711849)
22480: accuracy:0.11 loss: 284.665 (lr:0.00010000000861312189)
22500: accuracy:0.2 loss: 265.462 (lr:0.00010000000844257064)
22520: accuracy:0.14 loss: 277.548 (lr:0.00010000000827539654)
22540: accuracy:0.09 loss: 300.031 (lr:0.0001000000081115327)
22560: accuracy:0.16 loss: 292.664 (lr:0.0001000000079509136)
22580: accuracy:0.17 loss: 292.132 (lr:0.00010000000779347496)
22600: accuracy:0.14 loss: 293.096 (lr:0.00010000000763915381)
22620: accuracy:0.17 loss: 292.142 (lr:0.00010000000748788843)
22640: accuracy:0.12 loss: 270.578 (lr:0.00010000000733961831)
22660: accuracy:0.16 loss: 279.599 (lr:0.00010000000719428413)
22680: accuracy:0.18 loss: 284.617 (lr:0.00010000000705182777)
22700: accuracy:0.2 loss: 270.075 (lr:0.00010000000691219222)
22720: accuracy:0.17 loss: 273.967 (lr:0.00010000000677532164)
22740: accuracy:0.19 loss: 289.332 (lr:0.00010000000664116129)
22760: accuracy:0.17 loss: 264.399 (lr:0.00010000000650965748)
22780: accuracy:0.19 loss: 282.022 (lr:0.00010000000638075762)
22800: accuracy:0.15 loss: 306.898 (lr:0.00010000000625441016)
22820: accuracy:0.17 loss: 283.851 (lr:0.00010000000613056454)
22840: accuracy:0.16 loss: 271.841 (lr:0.00010000000600917123)
22860: accuracy:0.14 loss: 264.557 (lr:0.00010000000589018167)
22880: accuracy:0.13 loss: 280.621 (lr:0.00010000000577354826)
22900: accuracy:0.07 loss: 308.771 (lr:0.00010000000565922434)
22920: accuracy:0.2 loss: 275.826 (lr:0.00010000000554716419)
22940: accuracy:0.16 loss: 298.143 (lr:0.00010000000543732299)
22960: accuracy:0.16 loss: 287.942 (lr:0.00010000000532965678)
22980: accuracy:0.15 loss: 285.941 (lr:0.0001000000052241225)
23000: accuracy:0.14 loss: 288.998 (lr:0.00010000000512067793)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
23000: ********* epoch 3 ********* test accuracy for all:0.161081 test loss: 296.346
23000: ********* epoch 3 ********* test accuracy for mode 0:0.017 test loss: 431.666
23000: ********* epoch 3 ********* test accuracy for mode 1:0.013 test loss: 487.777
23000: ********* epoch 3 ********* test accuracy for mode 2:0.0035 test loss: 310.102
23000: ********* epoch 3 ********* test accuracy for mode 24:0.052 test loss: 311.947
23000: ********* epoch 3 ********* test accuracy for mode 25:0.0275 test loss: 303.118
23000: ********* epoch 3 ********* test accuracy for mode 26:0.4475 test loss: 231.957
23000: ********* epoch 3 ********* test accuracy for mode 27:0.1605 test loss: 310.223
23000: ********* epoch 3 ********* test accuracy for mode 28:0.0855 test loss: 293.772
23000: ********* epoch 3 ********* test accuracy for mode 29:0.204 test loss: 295.962
23000: ********* epoch 3 ********* test accuracy for mode 30:0.136 test loss: 291.65
23000: ********* epoch 3 ********* test accuracy for mode 31:0.0905 test loss: 284.222
23000: ********* epoch 3 ********* test accuracy for mode 32:0.2445 test loss: 264.949
23000: ********* epoch 3 ********* test accuracy for mode 33:0.214 test loss: 268.498
23000: ********* epoch 3 ********* test accuracy for mode 34:0.0035 test loss: 276.981
23000: ********* epoch 3 ********* test accuracy for mode 35:0.056 test loss: 463.699
23000: ********* epoch 3 ********* test accuracy for mode 36:0.094 test loss: 563.43
23020: accuracy:0.18 loss: 268.251 (lr:0.00010000000501928172)
23040: accuracy:0.15 loss: 296.371 (lr:0.00010000000491989329)
23060: accuracy:0.15 loss: 284.303 (lr:0.00010000000482247287)
23080: accuracy:0.12 loss: 282.829 (lr:0.0001000000047269815)
23100: accuracy:0.21 loss: 278.298 (lr:0.000100000004633381)
23120: accuracy:0.18 loss: 277.939 (lr:0.00010000000454163392)
23140: accuracy:0.16 loss: 285.69 (lr:0.00010000000445170354)
23160: accuracy:0.16 loss: 298.45 (lr:0.0001000000043635539)
23180: accuracy:0.13 loss: 282.724 (lr:0.00010000000427714975)
23200: accuracy:0.16 loss: 280.057 (lr:0.00010000000419245651)
23220: accuracy:0.12 loss: 291.955 (lr:0.0001000000041094403)
23240: accuracy:0.24 loss: 267.405 (lr:0.00010000000402806794)
23260: accuracy:0.18 loss: 288.557 (lr:0.00010000000394830684)
23280: accuracy:0.19 loss: 267.497 (lr:0.00010000000387012513)
23300: accuracy:0.13 loss: 283.625 (lr:0.00010000000379349153)
23320: accuracy:0.18 loss: 273.089 (lr:0.00010000000371837536)
23340: accuracy:0.16 loss: 273.84 (lr:0.00010000000364474659)
23360: accuracy:0.16 loss: 288.705 (lr:0.00010000000357257578)
23380: accuracy:0.2 loss: 272.799 (lr:0.00010000000350183404)
23400: accuracy:0.17 loss: 273.466 (lr:0.00010000000343249308)
23420: accuracy:0.23 loss: 272.327 (lr:0.00010000000336452516)
23440: accuracy:0.21 loss: 294.186 (lr:0.00010000000329790309)
23460: accuracy:0.16 loss: 284.934 (lr:0.00010000000323260024)
23480: accuracy:0.18 loss: 279.638 (lr:0.00010000000316859046)
23500: accuracy:0.13 loss: 275.689 (lr:0.00010000000310584817)
23520: accuracy:0.18 loss: 273.154 (lr:0.00010000000304434825)
23540: accuracy:0.22 loss: 275.924 (lr:0.00010000000298406612)
23560: accuracy:0.16 loss: 299.431 (lr:0.00010000000292497766)
23580: accuracy:0.18 loss: 301.237 (lr:0.00010000000286705922)
23600: accuracy:0.14 loss: 294.284 (lr:0.00010000000281028764)
23620: accuracy:0.14 loss: 283.073 (lr:0.00010000000275464022)
23640: accuracy:0.22 loss: 285.622 (lr:0.00010000000270009468)
23660: accuracy:0.21 loss: 279.439 (lr:0.00010000000264662923)
23680: accuracy:0.23 loss: 262.421 (lr:0.00010000000259422246)
23700: accuracy:0.11 loss: 281.785 (lr:0.00010000000254285341)
23720: accuracy:0.12 loss: 277.379 (lr:0.00010000000249250154)
23740: accuracy:0.21 loss: 268.345 (lr:0.00010000000244314671)
23760: accuracy:0.14 loss: 281.399 (lr:0.00010000000239476916)
23780: accuracy:0.16 loss: 292.187 (lr:0.00010000000234734955)
23800: accuracy:0.16 loss: 294.427 (lr:0.00010000000230086892)
23820: accuracy:0.13 loss: 288.562 (lr:0.00010000000225530866)
23840: accuracy:0.21 loss: 289.399 (lr:0.00010000000221065056)
23860: accuracy:0.15 loss: 315.851 (lr:0.00010000000216687675)
23880: accuracy:0.16 loss: 267.261 (lr:0.0001000000021239697)
23900: accuracy:0.22 loss: 267.671 (lr:0.0001000000020819123)
23920: accuracy:0.13 loss: 281.996 (lr:0.00010000000204068766)
23940: accuracy:0.13 loss: 269.273 (lr:0.00010000000200027934)
23960: accuracy:0.19 loss: 289.591 (lr:0.00010000000196067116)
23980: accuracy:0.1 loss: 273.124 (lr:0.00010000000192184726)
24000: accuracy:0.25 loss: 266.942 (lr:0.00010000000188379215)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
24000: ********* epoch 3 ********* test accuracy for all:0.163635 test loss: 293.268
24000: ********* epoch 3 ********* test accuracy for mode 0:0.0085 test loss: 427.513
24000: ********* epoch 3 ********* test accuracy for mode 1:0.016 test loss: 477.002
24000: ********* epoch 3 ********* test accuracy for mode 2:0.0055 test loss: 308.932
24000: ********* epoch 3 ********* test accuracy for mode 24:0.0785 test loss: 305.495
24000: ********* epoch 3 ********* test accuracy for mode 25:0.074 test loss: 298.066
24000: ********* epoch 3 ********* test accuracy for mode 26:0.446 test loss: 229.677
24000: ********* epoch 3 ********* test accuracy for mode 27:0.152 test loss: 306.625
24000: ********* epoch 3 ********* test accuracy for mode 28:0.0815 test loss: 292.557
24000: ********* epoch 3 ********* test accuracy for mode 29:0.201 test loss: 293.184
24000: ********* epoch 3 ********* test accuracy for mode 30:0.1805 test loss: 285.104
24000: ********* epoch 3 ********* test accuracy for mode 31:0.0475 test loss: 283.665
24000: ********* epoch 3 ********* test accuracy for mode 32:0.3225 test loss: 261.016
24000: ********* epoch 3 ********* test accuracy for mode 33:0.1345 test loss: 268.465
24000: ********* epoch 3 ********* test accuracy for mode 34:0.0125 test loss: 275.427
24000: ********* epoch 3 ********* test accuracy for mode 35:0.045 test loss: 463.012
24000: ********* epoch 3 ********* test accuracy for mode 36:0.0845 test loss: 551.867
24020: accuracy:0.17 loss: 268.201 (lr:0.00010000000184649056)
24040: accuracy:0.14 loss: 281.021 (lr:0.00010000000180992759)
24060: accuracy:0.24 loss: 273.699 (lr:0.00010000000177408863)
24080: accuracy:0.1 loss: 280.262 (lr:0.00010000000173895932)
24100: accuracy:0.15 loss: 280.279 (lr:0.00010000000170452562)
24120: accuracy:0.16 loss: 278.517 (lr:0.00010000000167077375)
24140: accuracy:0.14 loss: 280.996 (lr:0.00010000000163769022)
24160: accuracy:0.17 loss: 267.205 (lr:0.00010000000160526177)
24180: accuracy:0.14 loss: 273.172 (lr:0.00010000000157347546)
24200: accuracy:0.12 loss: 288.073 (lr:0.00010000000154231856)
24220: accuracy:0.12 loss: 270.195 (lr:0.00010000000151177861)
24240: accuracy:0.18 loss: 296.435 (lr:0.00010000000148184338)
24260: accuracy:0.25 loss: 279.14 (lr:0.00010000000145250093)
24280: accuracy:0.12 loss: 277.28 (lr:0.00010000000142373948)
24300: accuracy:0.23 loss: 286.408 (lr:0.00010000000139554754)
24320: accuracy:0.2 loss: 284.125 (lr:0.00010000000136791386)
24340: accuracy:0.14 loss: 291.398 (lr:0.00010000000134082734)
24360: accuracy:0.18 loss: 275.763 (lr:0.00010000000131427718)
24380: accuracy:0.19 loss: 274.419 (lr:0.00010000000128825275)
24400: accuracy:0.19 loss: 273.675 (lr:0.00010000000126274363)
24420: accuracy:0.13 loss: 286.647 (lr:0.00010000000123773964)
24440: accuracy:0.16 loss: 286.13 (lr:0.00010000000121323075)
24460: accuracy:0.23 loss: 256.695 (lr:0.00010000000118920717)
24480: accuracy:0.17 loss: 277.977 (lr:0.00010000000116565929)
24500: accuracy:0.22 loss: 267.089 (lr:0.0001000000011425777)
24520: accuracy:0.11 loss: 296.252 (lr:0.00010000000111995313)
24540: accuracy:0.21 loss: 270.91 (lr:0.00010000000109777658)
24560: accuracy:0.17 loss: 281.962 (lr:0.00010000000107603915)
24580: accuracy:0.2 loss: 258.162 (lr:0.00010000000105473214)
24600: accuracy:0.2 loss: 285.124 (lr:0.00010000000103384704)
24620: accuracy:0.22 loss: 271.918 (lr:0.0001000000010133755)
24640: accuracy:0.22 loss: 269.078 (lr:0.00010000000099330932)
24660: accuracy:0.21 loss: 283.433 (lr:0.00010000000097364048)
24680: accuracy:0.17 loss: 278.564 (lr:0.0001000000009543611)
24700: accuracy:0.18 loss: 290.099 (lr:0.00010000000093546349)
24720: accuracy:0.17 loss: 291.032 (lr:0.00010000000091694007)
24740: accuracy:0.2 loss: 264.031 (lr:0.00010000000089878345)
24760: accuracy:0.13 loss: 304.36 (lr:0.00010000000088098634)
24780: accuracy:0.19 loss: 282.436 (lr:0.00010000000086354165)
24800: accuracy:0.19 loss: 263.523 (lr:0.00010000000084644237)
24820: accuracy:0.1 loss: 299.459 (lr:0.00010000000082968169)
24840: accuracy:0.13 loss: 266.901 (lr:0.0001000000008132529)
24860: accuracy:0.21 loss: 282.677 (lr:0.0001000000007971494)
24880: accuracy:0.15 loss: 285.84 (lr:0.00010000000078136479)
24900: accuracy:0.15 loss: 276.725 (lr:0.00010000000076589274)
24920: accuracy:0.17 loss: 277.124 (lr:0.00010000000075072704)
24940: accuracy:0.19 loss: 263.75 (lr:0.00010000000073586165)
24960: accuracy:0.19 loss: 272.77 (lr:0.00010000000072129061)
24980: accuracy:0.16 loss: 299.421 (lr:0.0001000000007070081)
25000: accuracy:0.24 loss: 274.315 (lr:0.0001000000006930084)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
25000: ********* epoch 3 ********* test accuracy for all:0.170405 test loss: 289.225
25000: ********* epoch 3 ********* test accuracy for mode 0:0.0065 test loss: 428.286
25000: ********* epoch 3 ********* test accuracy for mode 1:0.0195 test loss: 473.37
25000: ********* epoch 3 ********* test accuracy for mode 2:0.007 test loss: 315.588
25000: ********* epoch 3 ********* test accuracy for mode 24:0.131 test loss: 287.142
25000: ********* epoch 3 ********* test accuracy for mode 25:0.133 test loss: 281.516
25000: ********* epoch 3 ********* test accuracy for mode 26:0.3605 test loss: 229.409
25000: ********* epoch 3 ********* test accuracy for mode 27:0.178 test loss: 293.644
25000: ********* epoch 3 ********* test accuracy for mode 28:0.0815 test loss: 287.424
25000: ********* epoch 3 ********* test accuracy for mode 29:0.1955 test loss: 287.557
25000: ********* epoch 3 ********* test accuracy for mode 30:0.203 test loss: 282.011
25000: ********* epoch 3 ********* test accuracy for mode 31:0.084 test loss: 283.902
25000: ********* epoch 3 ********* test accuracy for mode 32:0.3135 test loss: 265.499
25000: ********* epoch 3 ********* test accuracy for mode 33:0.0975 test loss: 275.279
25000: ********* epoch 3 ********* test accuracy for mode 34:0.006 test loss: 281.283
25000: ********* epoch 3 ********* test accuracy for mode 35:0.036 test loss: 462.192
25000: ********* epoch 3 ********* test accuracy for mode 36:0.096 test loss: 551.224
25020: accuracy:0.18 loss: 275.435 (lr:0.00010000000067928592)
25040: accuracy:0.17 loss: 281.232 (lr:0.00010000000066583515)
25060: accuracy:0.2 loss: 278.746 (lr:0.00010000000065265074)
25080: accuracy:0.2 loss: 283.25 (lr:0.00010000000063972738)
25100: accuracy:0.24 loss: 259.414 (lr:0.00010000000062705993)
25120: accuracy:0.25 loss: 277.031 (lr:0.00010000000061464331)
25140: accuracy:0.13 loss: 265.403 (lr:0.00010000000060247256)
25160: accuracy:0.11 loss: 283.51 (lr:0.00010000000059054281)
25180: accuracy:0.22 loss: 273.606 (lr:0.00010000000057884927)
25200: accuracy:0.14 loss: 283.151 (lr:0.00010000000056738729)
25220: accuracy:0.14 loss: 271.305 (lr:0.00010000000055615227)
25240: accuracy:0.3 loss: 290.125 (lr:0.00010000000054513972)
25260: accuracy:0.15 loss: 273.066 (lr:0.00010000000053434522)
25280: accuracy:0.15 loss: 288.226 (lr:0.00010000000052376448)
25300: accuracy:0.12 loss: 286.946 (lr:0.00010000000051339325)
25320: accuracy:0.19 loss: 265.029 (lr:0.00010000000050322739)
25340: accuracy:0.15 loss: 278.745 (lr:0.00010000000049326281)
25360: accuracy:0.14 loss: 277.999 (lr:0.00010000000048349556)
25380: accuracy:0.16 loss: 300.939 (lr:0.0001000000004739217)
25400: accuracy:0.13 loss: 282.179 (lr:0.00010000000046453743)
25420: accuracy:0.17 loss: 276.253 (lr:0.00010000000045533896)
25440: accuracy:0.14 loss: 282.107 (lr:0.00010000000044632266)
25460: accuracy:0.21 loss: 278.796 (lr:0.00010000000043748488)
25480: accuracy:0.09 loss: 295.964 (lr:0.00010000000042882209)
25500: accuracy:0.22 loss: 270.568 (lr:0.00010000000042033085)
25520: accuracy:0.16 loss: 273.557 (lr:0.00010000000041200774)
25540: accuracy:0.21 loss: 285.454 (lr:0.00010000000040384944)
25560: accuracy:0.18 loss: 266.627 (lr:0.00010000000039585268)
25580: accuracy:0.17 loss: 267.917 (lr:0.00010000000038801428)
25600: accuracy:0.19 loss: 270.184 (lr:0.00010000000038033108)
25620: accuracy:0.16 loss: 280.302 (lr:0.00010000000037280002)
25640: accuracy:0.15 loss: 274.333 (lr:0.00010000000036541808)
25660: accuracy:0.15 loss: 288.315 (lr:0.00010000000035818232)
25680: accuracy:0.24 loss: 257.227 (lr:0.00010000000035108984)
25700: accuracy:0.18 loss: 266.583 (lr:0.0001000000003441378)
25720: accuracy:0.14 loss: 273.593 (lr:0.00010000000033732341)
25740: accuracy:0.15 loss: 275.213 (lr:0.00010000000033064395)
25760: accuracy:0.17 loss: 260.775 (lr:0.00010000000032409677)
25780: accuracy:0.16 loss: 296.521 (lr:0.00010000000031767922)
25800: accuracy:0.21 loss: 292.923 (lr:0.00010000000031138875)
25820: accuracy:0.24 loss: 267.717 (lr:0.00010000000030522284)
25840: accuracy:0.13 loss: 258.017 (lr:0.00010000000029917902)
25860: accuracy:0.22 loss: 290.294 (lr:0.00010000000029325489)
25880: accuracy:0.14 loss: 279.523 (lr:0.00010000000028744805)
25900: accuracy:0.17 loss: 266.064 (lr:0.00010000000028175619)
25920: accuracy:0.16 loss: 274.554 (lr:0.00010000000027617705)
25940: accuracy:0.15 loss: 274.26 (lr:0.00010000000027070837)
25960: accuracy:0.19 loss: 258.099 (lr:0.000100000000265348)
25980: accuracy:0.18 loss: 268.316 (lr:0.00010000000026009375)
26000: accuracy:0.24 loss: 271.173 (lr:0.00010000000025494355)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
26000: ********* epoch 3 ********* test accuracy for all:0.172203 test loss: 288.424
26000: ********* epoch 3 ********* test accuracy for mode 0:0.0055 test loss: 420.028
26000: ********* epoch 3 ********* test accuracy for mode 1:0.015 test loss: 464.752
26000: ********* epoch 3 ********* test accuracy for mode 2:0.0135 test loss: 307.183
26000: ********* epoch 3 ********* test accuracy for mode 24:0.1385 test loss: 293.374
26000: ********* epoch 3 ********* test accuracy for mode 25:0.1415 test loss: 286.134
26000: ********* epoch 3 ********* test accuracy for mode 26:0.36 test loss: 230.662
26000: ********* epoch 3 ********* test accuracy for mode 27:0.17 test loss: 295.792
26000: ********* epoch 3 ********* test accuracy for mode 28:0.114 test loss: 281.85
26000: ********* epoch 3 ********* test accuracy for mode 29:0.1855 test loss: 281.813
26000: ********* epoch 3 ********* test accuracy for mode 30:0.2205 test loss: 274.299
26000: ********* epoch 3 ********* test accuracy for mode 31:0.107 test loss: 275.156
26000: ********* epoch 3 ********* test accuracy for mode 32:0.3035 test loss: 258.963
26000: ********* epoch 3 ********* test accuracy for mode 33:0.1375 test loss: 265.626
26000: ********* epoch 3 ********* test accuracy for mode 34:0.0005 test loss: 279.484
26000: ********* epoch 3 ********* test accuracy for mode 35:0.034 test loss: 455.856
26000: ********* epoch 3 ********* test accuracy for mode 36:0.186 test loss: 533.809
26020: accuracy:0.21 loss: 271.311 (lr:0.00010000000024989532)
26040: accuracy:0.19 loss: 263.541 (lr:0.00010000000024494707)
26060: accuracy:0.15 loss: 262.412 (lr:0.00010000000024009679)
26080: accuracy:0.23 loss: 285.51 (lr:0.00010000000023534255)
26100: accuracy:0.19 loss: 274.555 (lr:0.00010000000023068246)
26120: accuracy:0.19 loss: 276.625 (lr:0.00010000000022611464)
26140: accuracy:0.18 loss: 268.308 (lr:0.00010000000022163727)
26160: accuracy:0.24 loss: 263.74 (lr:0.00010000000021724856)
26180: accuracy:0.15 loss: 298.337 (lr:0.00010000000021294676)
26200: accuracy:0.16 loss: 270.032 (lr:0.00010000000020873012)
26220: accuracy:0.25 loss: 260.63 (lr:0.00010000000020459699)
26240: accuracy:0.17 loss: 283.382 (lr:0.0001000000002005457)
26260: accuracy:0.13 loss: 286.966 (lr:0.00010000000019657463)
26280: accuracy:0.12 loss: 287.244 (lr:0.00010000000019268219)
26300: accuracy:0.17 loss: 263.251 (lr:0.00010000000018886683)
26320: accuracy:0.22 loss: 264.429 (lr:0.00010000000018512701)
26340: accuracy:0.22 loss: 260.657 (lr:0.00010000000018146126)
26360: accuracy:0.24 loss: 261.957 (lr:0.00010000000017786807)
26380: accuracy:0.23 loss: 269.715 (lr:0.00010000000017434606)
26400: accuracy:0.16 loss: 270.184 (lr:0.00010000000017089377)
26420: accuracy:0.17 loss: 289.953 (lr:0.00010000000016750985)
26440: accuracy:0.15 loss: 280.315 (lr:0.00010000000016419294)
26460: accuracy:0.15 loss: 294.971 (lr:0.0001000000001609417)
26480: accuracy:0.17 loss: 276.18 (lr:0.00010000000015775484)
26500: accuracy:0.18 loss: 272.425 (lr:0.00010000000015463107)
26520: accuracy:0.22 loss: 278.257 (lr:0.00010000000015156918)
26540: accuracy:0.12 loss: 268.261 (lr:0.0001000000001485679)
26560: accuracy:0.2 loss: 265.055 (lr:0.00010000000014562607)
26580: accuracy:0.21 loss: 259.985 (lr:0.00010000000014274247)
26600: accuracy:0.24 loss: 264.754 (lr:0.00010000000013991598)
26620: accuracy:0.2 loss: 286.873 (lr:0.00010000000013714547)
26640: accuracy:0.11 loss: 288.204 (lr:0.0001000000001344298)
26660: accuracy:0.17 loss: 267.496 (lr:0.00010000000013176792)
26680: accuracy:0.14 loss: 276.203 (lr:0.00010000000012915873)
26700: accuracy:0.15 loss: 279.957 (lr:0.00010000000012660122)
26720: accuracy:0.2 loss: 259.315 (lr:0.00010000000012409434)
26740: accuracy:0.23 loss: 272.471 (lr:0.00010000000012163712)
26760: accuracy:0.22 loss: 274.784 (lr:0.00010000000011922854)
26780: accuracy:0.17 loss: 282.068 (lr:0.00010000000011686766)
26800: accuracy:0.19 loss: 260.17 (lr:0.00010000000011455353)
26820: accuracy:0.15 loss: 262.467 (lr:0.00010000000011228521)
26840: accuracy:0.15 loss: 265.22 (lr:0.00010000000011006181)
26860: accuracy:0.18 loss: 262.485 (lr:0.00010000000010788244)
26880: accuracy:0.25 loss: 261.917 (lr:0.00010000000010574623)
26900: accuracy:0.25 loss: 276.529 (lr:0.00010000000010365231)
26920: accuracy:0.15 loss: 283.315 (lr:0.00010000000010159986)
26940: accuracy:0.2 loss: 271.651 (lr:0.00010000000009958805)
26960: accuracy:0.2 loss: 268.654 (lr:0.00010000000009761608)
26980: accuracy:0.2 loss: 270.711 (lr:0.00010000000009568315)
27000: accuracy:0.24 loss: 258.772 (lr:0.0001000000000937885)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
27000: ********* epoch 3 ********* test accuracy for all:0.169216 test loss: 288.049
27000: ********* epoch 3 ********* test accuracy for mode 0:0.0055 test loss: 417.602
27000: ********* epoch 3 ********* test accuracy for mode 1:0.027 test loss: 456.697
27000: ********* epoch 3 ********* test accuracy for mode 2:0.03 test loss: 303.158
27000: ********* epoch 3 ********* test accuracy for mode 24:0.1355 test loss: 299.391
27000: ********* epoch 3 ********* test accuracy for mode 25:0.1175 test loss: 289.169
27000: ********* epoch 3 ********* test accuracy for mode 26:0.337 test loss: 221.528
27000: ********* epoch 3 ********* test accuracy for mode 27:0.1985 test loss: 294.996
27000: ********* epoch 3 ********* test accuracy for mode 28:0.1015 test loss: 285.564
27000: ********* epoch 3 ********* test accuracy for mode 29:0.212 test loss: 287.237
27000: ********* epoch 3 ********* test accuracy for mode 30:0.186 test loss: 280.58
27000: ********* epoch 3 ********* test accuracy for mode 31:0.181 test loss: 279.394
27000: ********* epoch 3 ********* test accuracy for mode 32:0.225 test loss: 265.629
27000: ********* epoch 3 ********* test accuracy for mode 33:0.135 test loss: 269.282
27000: ********* epoch 3 ********* test accuracy for mode 34:0.0065 test loss: 277.519
27000: ********* epoch 3 ********* test accuracy for mode 35:0.028 test loss: 456.035
27000: ********* epoch 3 ********* test accuracy for mode 36:0.034 test loss: 545.762
27020: accuracy:0.16 loss: 284.675 (lr:0.00010000000009193135)
27040: accuracy:0.16 loss: 268.454 (lr:0.00010000000009011099)
27060: accuracy:0.23 loss: 271.669 (lr:0.00010000000008832668)
27080: accuracy:0.18 loss: 252.534 (lr:0.0001000000000865777)
27100: accuracy:0.21 loss: 281.643 (lr:0.00010000000008486334)
27120: accuracy:0.15 loss: 282.578 (lr:0.00010000000008318294)
27140: accuracy:0.16 loss: 277.377 (lr:0.0001000000000815358)
27160: accuracy:0.23 loss: 261.344 (lr:0.00010000000007992128)
27180: accuracy:0.2 loss: 268.413 (lr:0.00010000000007833873)
27200: accuracy:0.2 loss: 266.777 (lr:0.00010000000007678753)
27220: accuracy:0.24 loss: 267.701 (lr:0.00010000000007526703)
27240: accuracy:0.26 loss: 263.734 (lr:0.00010000000007377664)
27260: accuracy:0.2 loss: 255.566 (lr:0.00010000000007231576)
27280: accuracy:0.19 loss: 273.776 (lr:0.00010000000007088381)
27300: accuracy:0.16 loss: 282.44 (lr:0.00010000000006948022)
27320: accuracy:0.16 loss: 261.15 (lr:0.00010000000006810442)
27340: accuracy:0.17 loss: 264.065 (lr:0.00010000000006675586)
27360: accuracy:0.14 loss: 268.361 (lr:0.00010000000006543402)
27380: accuracy:0.15 loss: 280.968 (lr:0.00010000000006413833)
27400: accuracy:0.19 loss: 292.842 (lr:0.00010000000006286831)
27420: accuracy:0.18 loss: 274.615 (lr:0.00010000000006162343)
27440: accuracy:0.15 loss: 270.154 (lr:0.00010000000006040321)
27460: accuracy:0.18 loss: 271.006 (lr:0.00010000000005920715)
27480: accuracy:0.21 loss: 263.203 (lr:0.00010000000005803476)
27500: accuracy:0.2 loss: 259.348 (lr:0.0001000000000568856)
27520: accuracy:0.13 loss: 265.969 (lr:0.0001000000000557592)
27540: accuracy:0.15 loss: 288.61 (lr:0.00010000000005465508)
27560: accuracy:0.2 loss: 274.085 (lr:0.00010000000005357283)
27580: accuracy:0.13 loss: 284.899 (lr:0.00010000000005251202)
27600: accuracy:0.16 loss: 265.928 (lr:0.00010000000005147222)
27620: accuracy:0.15 loss: 299.935 (lr:0.000100000000050453)
27640: accuracy:0.16 loss: 261.504 (lr:0.00010000000004945396)
27660: accuracy:0.22 loss: 263.445 (lr:0.00010000000004847471)
27680: accuracy:0.2 loss: 264.101 (lr:0.00010000000004751484)
27700: accuracy:0.19 loss: 278.288 (lr:0.000100000000046574)
27720: accuracy:0.16 loss: 284.752 (lr:0.00010000000004565176)
27740: accuracy:0.18 loss: 285.303 (lr:0.00010000000004474779)
27760: accuracy:0.18 loss: 253.795 (lr:0.00010000000004386173)
27780: accuracy:0.18 loss: 257.033 (lr:0.00010000000004299322)
27800: accuracy:0.22 loss: 264.836 (lr:0.00010000000004214189)
27820: accuracy:0.2 loss: 295.635 (lr:0.00010000000004130743)
27840: accuracy:0.2 loss: 274.543 (lr:0.00010000000004048948)
27860: accuracy:0.16 loss: 280.612 (lr:0.00010000000003968774)
27880: accuracy:0.2 loss: 274.572 (lr:0.00010000000003890187)
27900: accuracy:0.22 loss: 262.802 (lr:0.00010000000003813156)
27920: accuracy:0.1 loss: 275.401 (lr:0.0001000000000373765)
27940: accuracy:0.18 loss: 262.801 (lr:0.0001000000000366364)
27960: accuracy:0.16 loss: 254.794 (lr:0.00010000000003591095)
27980: accuracy:0.31 loss: 252.12 (lr:0.00010000000003519986)
28000: accuracy:0.27 loss: 256.266 (lr:0.00010000000003450286)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
28000: ********* epoch 3 ********* test accuracy for all:0.175662 test loss: 283.533
28000: ********* epoch 3 ********* test accuracy for mode 0:0.0035 test loss: 416.348
28000: ********* epoch 3 ********* test accuracy for mode 1:0.021 test loss: 456.409
28000: ********* epoch 3 ********* test accuracy for mode 2:0.029 test loss: 307.9
28000: ********* epoch 3 ********* test accuracy for mode 24:0.1635 test loss: 277.109
28000: ********* epoch 3 ********* test accuracy for mode 25:0.132 test loss: 267.431
28000: ********* epoch 3 ********* test accuracy for mode 26:0.282 test loss: 215.013
28000: ********* epoch 3 ********* test accuracy for mode 27:0.203 test loss: 279.889
28000: ********* epoch 3 ********* test accuracy for mode 28:0.1475 test loss: 269.088
28000: ********* epoch 3 ********* test accuracy for mode 29:0.249 test loss: 271.189
28000: ********* epoch 3 ********* test accuracy for mode 30:0.1905 test loss: 274.924
28000: ********* epoch 3 ********* test accuracy for mode 31:0.1885 test loss: 277.216
28000: ********* epoch 3 ********* test accuracy for mode 32:0.18 test loss: 270.374
28000: ********* epoch 3 ********* test accuracy for mode 33:0.142 test loss: 275.597
28000: ********* epoch 3 ********* test accuracy for mode 34:0.0025 test loss: 282.79
28000: ********* epoch 3 ********* test accuracy for mode 35:0.022 test loss: 445.268
28000: ********* epoch 3 ********* test accuracy for mode 36:0.114 test loss: 516.731
28020: accuracy:0.2 loss: 258.269 (lr:0.00010000000003381966)
28040: accuracy:0.24 loss: 263.749 (lr:0.00010000000003314999)
28060: accuracy:0.18 loss: 265.265 (lr:0.00010000000003249357)
28080: accuracy:0.21 loss: 270.482 (lr:0.00010000000003185015)
28100: accuracy:0.18 loss: 270.351 (lr:0.00010000000003121948)
28120: accuracy:0.18 loss: 280.367 (lr:0.0001000000000306013)
28140: accuracy:0.13 loss: 273.045 (lr:0.00010000000002999535)
28160: accuracy:0.14 loss: 267.911 (lr:0.0001000000000294014)
28180: accuracy:0.13 loss: 289.741 (lr:0.00010000000002881921)
28200: accuracy:0.18 loss: 265.295 (lr:0.00010000000002824855)
28220: accuracy:0.18 loss: 278.519 (lr:0.0001000000000276892)
28240: accuracy:0.23 loss: 268.019 (lr:0.00010000000002714092)
28260: accuracy:0.15 loss: 268.0 (lr:0.0001000000000266035)
28280: accuracy:0.2 loss: 261.473 (lr:0.00010000000002607671)
28300: accuracy:0.22 loss: 284.662 (lr:0.00010000000002556036)
28320: accuracy:0.17 loss: 283.562 (lr:0.00010000000002505422)
28340: accuracy:0.18 loss: 268.87 (lr:0.00010000000002455812)
28360: accuracy:0.14 loss: 277.644 (lr:0.00010000000002407183)
28380: accuracy:0.19 loss: 264.637 (lr:0.00010000000002359517)
28400: accuracy:0.17 loss: 277.968 (lr:0.00010000000002312796)
28420: accuracy:0.21 loss: 276.944 (lr:0.00010000000002267)
28440: accuracy:0.19 loss: 280.521 (lr:0.00010000000002222111)
28460: accuracy:0.12 loss: 272.713 (lr:0.0001000000000217811)
28480: accuracy:0.16 loss: 275.654 (lr:0.0001000000000213498)
28500: accuracy:0.27 loss: 255.823 (lr:0.00010000000002092704)
28520: accuracy:0.21 loss: 270.432 (lr:0.00010000000002051266)
28540: accuracy:0.22 loss: 256.143 (lr:0.00010000000002010648)
28560: accuracy:0.22 loss: 256.82 (lr:0.00010000000001970835)
28580: accuracy:0.23 loss: 271.468 (lr:0.0001000000000193181)
28600: accuracy:0.19 loss: 270.518 (lr:0.00010000000001893557)
28620: accuracy:0.18 loss: 293.191 (lr:0.00010000000001856062)
28640: accuracy:0.15 loss: 281.39 (lr:0.0001000000000181931)
28660: accuracy:0.17 loss: 274.755 (lr:0.00010000000001783285)
28680: accuracy:0.26 loss: 263.452 (lr:0.00010000000001747974)
28700: accuracy:0.23 loss: 256.387 (lr:0.00010000000001713361)
28720: accuracy:0.13 loss: 283.845 (lr:0.00010000000001679435)
28740: accuracy:0.18 loss: 258.38 (lr:0.0001000000000164618)
28760: accuracy:0.17 loss: 272.783 (lr:0.00010000000001613583)
28780: accuracy:0.24 loss: 255.339 (lr:0.00010000000001581632)
28800: accuracy:0.28 loss: 249.992 (lr:0.00010000000001550313)
28820: accuracy:0.14 loss: 263.556 (lr:0.00010000000001519616)
28840: accuracy:0.2 loss: 274.373 (lr:0.00010000000001489525)
28860: accuracy:0.2 loss: 280.191 (lr:0.0001000000000146003)
28880: accuracy:0.12 loss: 273.738 (lr:0.0001000000000143112)
28900: accuracy:0.17 loss: 272.749 (lr:0.00010000000001402782)
28920: accuracy:0.21 loss: 272.279 (lr:0.00010000000001375005)
28940: accuracy:0.23 loss: 246.437 (lr:0.00010000000001347778)
28960: accuracy:0.18 loss: 262.902 (lr:0.0001000000000132109)
28980: accuracy:0.26 loss: 255.277 (lr:0.00010000000001294931)
29000: accuracy:0.18 loss: 272.789 (lr:0.0001000000000126929)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
29000: ********* epoch 3 ********* test accuracy for all:0.174878 test loss: 285.082
29000: ********* epoch 3 ********* test accuracy for mode 0:0.0025 test loss: 421.689
29000: ********* epoch 3 ********* test accuracy for mode 1:0.026 test loss: 463.511
29000: ********* epoch 3 ********* test accuracy for mode 2:0.0505 test loss: 300.619
29000: ********* epoch 3 ********* test accuracy for mode 24:0.156 test loss: 287.338
29000: ********* epoch 3 ********* test accuracy for mode 25:0.1755 test loss: 281.225
29000: ********* epoch 3 ********* test accuracy for mode 26:0.2095 test loss: 227.344
29000: ********* epoch 3 ********* test accuracy for mode 27:0.2035 test loss: 294.51
29000: ********* epoch 3 ********* test accuracy for mode 28:0.134 test loss: 286.501
29000: ********* epoch 3 ********* test accuracy for mode 29:0.225 test loss: 286.547
29000: ********* epoch 3 ********* test accuracy for mode 30:0.1615 test loss: 288.086
29000: ********* epoch 3 ********* test accuracy for mode 31:0.168 test loss: 284.538
29000: ********* epoch 3 ********* test accuracy for mode 32:0.2485 test loss: 269.109
29000: ********* epoch 3 ********* test accuracy for mode 33:0.113 test loss: 273.654
29000: ********* epoch 3 ********* test accuracy for mode 34:0.003 test loss: 278.703
29000: ********* epoch 3 ********* test accuracy for mode 35:0.019 test loss: 457.243
29000: ********* epoch 3 ********* test accuracy for mode 36:0.1175 test loss: 526.797
29020: accuracy:0.23 loss: 272.505 (lr:0.00010000000001244156)
29040: accuracy:0.21 loss: 264.438 (lr:0.0001000000000121952)
29060: accuracy:0.23 loss: 266.184 (lr:0.00010000000001195371)
29080: accuracy:0.23 loss: 264.153 (lr:0.00010000000001171702)
29100: accuracy:0.13 loss: 265.162 (lr:0.00010000000001148501)
29120: accuracy:0.21 loss: 273.6 (lr:0.00010000000001125759)
29140: accuracy:0.19 loss: 273.09 (lr:0.00010000000001103468)
29160: accuracy:0.11 loss: 275.203 (lr:0.00010000000001081617)
29180: accuracy:0.14 loss: 301.622 (lr:0.000100000000010602)
29200: accuracy:0.18 loss: 259.121 (lr:0.00010000000001039207)
29220: accuracy:0.16 loss: 278.637 (lr:0.00010000000001018629)
29240: accuracy:0.19 loss: 275.41 (lr:0.00010000000000998459)
29260: accuracy:0.26 loss: 278.901 (lr:0.00010000000000978688)
29280: accuracy:0.24 loss: 259.627 (lr:0.00010000000000959308)
29300: accuracy:0.22 loss: 262.957 (lr:0.00010000000000940313)
29320: accuracy:0.15 loss: 258.928 (lr:0.00010000000000921693)
29340: accuracy:0.24 loss: 261.74 (lr:0.00010000000000903443)
29360: accuracy:0.18 loss: 260.631 (lr:0.00010000000000885554)
29380: accuracy:0.2 loss: 260.589 (lr:0.00010000000000868018)
29400: accuracy:0.18 loss: 270.059 (lr:0.00010000000000850831)
29420: accuracy:0.19 loss: 273.864 (lr:0.00010000000000833982)
29440: accuracy:0.2 loss: 263.594 (lr:0.00010000000000817469)
29460: accuracy:0.19 loss: 277.901 (lr:0.00010000000000801281)
29480: accuracy:0.2 loss: 256.222 (lr:0.00010000000000785416)
29500: accuracy:0.14 loss: 269.367 (lr:0.00010000000000769863)
29520: accuracy:0.18 loss: 273.101 (lr:0.00010000000000754619)
29540: accuracy:0.17 loss: 255.667 (lr:0.00010000000000739677)
29560: accuracy:0.18 loss: 249.716 (lr:0.0001000000000072503)
29580: accuracy:0.21 loss: 262.378 (lr:0.00010000000000710673)
29600: accuracy:0.19 loss: 262.188 (lr:0.00010000000000696602)
29620: accuracy:0.2 loss: 259.664 (lr:0.00010000000000682808)
29640: accuracy:0.14 loss: 280.363 (lr:0.00010000000000669287)
29660: accuracy:0.22 loss: 275.169 (lr:0.00010000000000656035)
29680: accuracy:0.21 loss: 280.774 (lr:0.00010000000000643043)
29700: accuracy:0.12 loss: 269.591 (lr:0.00010000000000630311)
29720: accuracy:0.17 loss: 240.73 (lr:0.0001000000000061783)
29740: accuracy:0.18 loss: 258.92 (lr:0.00010000000000605597)
29760: accuracy:0.19 loss: 264.956 (lr:0.00010000000000593604)
29780: accuracy:0.17 loss: 288.64 (lr:0.0001000000000058185)
29800: accuracy:0.15 loss: 254.559 (lr:0.00010000000000570329)
29820: accuracy:0.22 loss: 254.178 (lr:0.00010000000000559035)
29840: accuracy:0.15 loss: 281.702 (lr:0.00010000000000547966)
29860: accuracy:0.15 loss: 272.349 (lr:0.00010000000000537116)
29880: accuracy:0.15 loss: 269.348 (lr:0.0001000000000052648)
29900: accuracy:0.21 loss: 269.925 (lr:0.00010000000000516055)
29920: accuracy:0.21 loss: 266.664 (lr:0.00010000000000505836)
29940: accuracy:0.21 loss: 255.905 (lr:0.0001000000000049582)
29960: accuracy:0.16 loss: 272.356 (lr:0.00010000000000486002)
29980: accuracy:0.13 loss: 281.918 (lr:0.00010000000000476379)
30000: accuracy:0.19 loss: 272.955 (lr:0.00010000000000466946)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
30000: ********* epoch 4 ********* test accuracy for all:0.172851 test loss: 285.32
30000: ********* epoch 4 ********* test accuracy for mode 0:0.0015 test loss: 423.539
30000: ********* epoch 4 ********* test accuracy for mode 1:0.0275 test loss: 462.287
30000: ********* epoch 4 ********* test accuracy for mode 2:0.0385 test loss: 301.471
30000: ********* epoch 4 ********* test accuracy for mode 24:0.155 test loss: 294.455
30000: ********* epoch 4 ********* test accuracy for mode 25:0.188 test loss: 283.633
30000: ********* epoch 4 ********* test accuracy for mode 26:0.1335 test loss: 230.522
30000: ********* epoch 4 ********* test accuracy for mode 27:0.2275 test loss: 294.162
30000: ********* epoch 4 ********* test accuracy for mode 28:0.1175 test loss: 288.399
30000: ********* epoch 4 ********* test accuracy for mode 29:0.22 test loss: 284.883
30000: ********* epoch 4 ********* test accuracy for mode 30:0.197 test loss: 283.684
30000: ********* epoch 4 ********* test accuracy for mode 31:0.162 test loss: 282.004
30000: ********* epoch 4 ********* test accuracy for mode 32:0.2585 test loss: 267.499
30000: ********* epoch 4 ********* test accuracy for mode 33:0.0765 test loss: 273.965
30000: ********* epoch 4 ********* test accuracy for mode 34:0.0045 test loss: 274.879
30000: ********* epoch 4 ********* test accuracy for mode 35:0.014 test loss: 455.604
30000: ********* epoch 4 ********* test accuracy for mode 36:0.0505 test loss: 527.278
30020: accuracy:0.12 loss: 277.629 (lr:0.00010000000000457699)
30040: accuracy:0.17 loss: 271.618 (lr:0.00010000000000448637)
30060: accuracy:0.22 loss: 272.408 (lr:0.00010000000000439753)
30080: accuracy:0.21 loss: 260.943 (lr:0.00010000000000431045)
30100: accuracy:0.33 loss: 248.321 (lr:0.0001000000000042251)
30120: accuracy:0.26 loss: 272.283 (lr:0.00010000000000414144)
30140: accuracy:0.18 loss: 282.818 (lr:0.00010000000000405943)
30160: accuracy:0.25 loss: 259.093 (lr:0.00010000000000397905)
30180: accuracy:0.18 loss: 258.588 (lr:0.00010000000000390026)
30200: accuracy:0.19 loss: 276.459 (lr:0.00010000000000382302)
30220: accuracy:0.19 loss: 265.455 (lr:0.00010000000000374733)
30240: accuracy:0.2 loss: 249.274 (lr:0.00010000000000367313)
30260: accuracy:0.22 loss: 255.048 (lr:0.0001000000000036004)
30280: accuracy:0.22 loss: 268.338 (lr:0.0001000000000035291)
30300: accuracy:0.17 loss: 261.57 (lr:0.00010000000000345922)
30320: accuracy:0.21 loss: 272.287 (lr:0.00010000000000339073)
30340: accuracy:0.22 loss: 255.703 (lr:0.00010000000000332359)
30360: accuracy:0.2 loss: 259.602 (lr:0.00010000000000325777)
30380: accuracy:0.21 loss: 253.825 (lr:0.00010000000000319326)
30400: accuracy:0.2 loss: 252.969 (lr:0.00010000000000313003)
30420: accuracy:0.21 loss: 268.125 (lr:0.00010000000000306805)
30440: accuracy:0.21 loss: 271.178 (lr:0.0001000000000030073)
30460: accuracy:0.23 loss: 269.015 (lr:0.00010000000000294776)
30480: accuracy:0.28 loss: 272.498 (lr:0.00010000000000288939)
30500: accuracy:0.19 loss: 248.085 (lr:0.00010000000000283217)
30520: accuracy:0.26 loss: 266.724 (lr:0.00010000000000277609)
30540: accuracy:0.23 loss: 256.896 (lr:0.00010000000000272112)
30560: accuracy:0.22 loss: 271.402 (lr:0.00010000000000266724)
30580: accuracy:0.2 loss: 266.133 (lr:0.00010000000000261442)
30600: accuracy:0.27 loss: 256.29 (lr:0.00010000000000256265)
30620: accuracy:0.18 loss: 266.085 (lr:0.00010000000000251191)
30640: accuracy:0.15 loss: 276.996 (lr:0.00010000000000246217)
30660: accuracy:0.21 loss: 263.387 (lr:0.00010000000000241341)
30680: accuracy:0.19 loss: 263.461 (lr:0.00010000000000236563)
30700: accuracy:0.26 loss: 251.84 (lr:0.00010000000000231879)
30720: accuracy:0.28 loss: 250.453 (lr:0.00010000000000227287)
30740: accuracy:0.18 loss: 262.822 (lr:0.00010000000000222786)
30760: accuracy:0.19 loss: 269.076 (lr:0.00010000000000218375)
30780: accuracy:0.24 loss: 270.334 (lr:0.0001000000000021405)
30800: accuracy:0.19 loss: 261.116 (lr:0.00010000000000209813)
30820: accuracy:0.18 loss: 289.24 (lr:0.00010000000000205657)
30840: accuracy:0.21 loss: 264.837 (lr:0.00010000000000201586)
30860: accuracy:0.18 loss: 266.553 (lr:0.00010000000000197594)
30880: accuracy:0.11 loss: 278.249 (lr:0.00010000000000193681)
30900: accuracy:0.17 loss: 260.156 (lr:0.00010000000000189846)
30920: accuracy:0.18 loss: 272.461 (lr:0.00010000000000186088)
30940: accuracy:0.18 loss: 269.46 (lr:0.00010000000000182403)
30960: accuracy:0.29 loss: 256.161 (lr:0.00010000000000178791)
30980: accuracy:0.13 loss: 275.203 (lr:0.00010000000000175251)
31000: accuracy:0.23 loss: 269.525 (lr:0.0001000000000017178)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
31000: ********* epoch 4 ********* test accuracy for all:0.182054 test loss: 280.707
31000: ********* epoch 4 ********* test accuracy for mode 0:0.002 test loss: 410.528
31000: ********* epoch 4 ********* test accuracy for mode 1:0.0235 test loss: 445.809
31000: ********* epoch 4 ********* test accuracy for mode 2:0.083 test loss: 301.977
31000: ********* epoch 4 ********* test accuracy for mode 24:0.179 test loss: 276.55
31000: ********* epoch 4 ********* test accuracy for mode 25:0.1835 test loss: 268.454
31000: ********* epoch 4 ********* test accuracy for mode 26:0.1575 test loss: 220.31
31000: ********* epoch 4 ********* test accuracy for mode 27:0.2165 test loss: 281.659
31000: ********* epoch 4 ********* test accuracy for mode 28:0.119 test loss: 277.511
31000: ********* epoch 4 ********* test accuracy for mode 29:0.21 test loss: 276.64
31000: ********* epoch 4 ********* test accuracy for mode 30:0.1915 test loss: 276.25
31000: ********* epoch 4 ********* test accuracy for mode 31:0.2065 test loss: 275.395
31000: ********* epoch 4 ********* test accuracy for mode 32:0.209 test loss: 266.096
31000: ********* epoch 4 ********* test accuracy for mode 33:0.1425 test loss: 269.589
31000: ********* epoch 4 ********* test accuracy for mode 34:0.003 test loss: 275.895
31000: ********* epoch 4 ********* test accuracy for mode 35:0.01 test loss: 447.144
31000: ********* epoch 4 ********* test accuracy for mode 36:0.2425 test loss: 503.41
31020: accuracy:0.17 loss: 269.009 (lr:0.00010000000000168378)
31040: accuracy:0.19 loss: 266.969 (lr:0.00010000000000165045)
31060: accuracy:0.16 loss: 282.46 (lr:0.00010000000000161777)
31080: accuracy:0.21 loss: 263.29 (lr:0.00010000000000158573)
31100: accuracy:0.17 loss: 275.147 (lr:0.00010000000000155433)
31120: accuracy:0.17 loss: 264.628 (lr:0.00010000000000152355)
31140: accuracy:0.22 loss: 257.692 (lr:0.00010000000000149338)
31160: accuracy:0.14 loss: 253.776 (lr:0.00010000000000146381)
31180: accuracy:0.19 loss: 267.5 (lr:0.00010000000000143482)
31200: accuracy:0.21 loss: 282.183 (lr:0.00010000000000140642)
31220: accuracy:0.18 loss: 261.704 (lr:0.00010000000000137857)
31240: accuracy:0.13 loss: 272.805 (lr:0.00010000000000135127)
31260: accuracy:0.21 loss: 276.884 (lr:0.00010000000000132452)
31280: accuracy:0.19 loss: 284.012 (lr:0.00010000000000129828)
31300: accuracy:0.19 loss: 274.114 (lr:0.00010000000000127257)
31320: accuracy:0.19 loss: 256.033 (lr:0.00010000000000124738)
31340: accuracy:0.14 loss: 279.305 (lr:0.00010000000000122269)
31360: accuracy:0.18 loss: 268.764 (lr:0.00010000000000119847)
31380: accuracy:0.21 loss: 277.896 (lr:0.00010000000000117474)
31400: accuracy:0.27 loss: 257.02 (lr:0.00010000000000115148)
31420: accuracy:0.2 loss: 259.975 (lr:0.00010000000000112867)
31440: accuracy:0.18 loss: 267.397 (lr:0.00010000000000110632)
31460: accuracy:0.23 loss: 267.025 (lr:0.00010000000000108442)
31480: accuracy:0.18 loss: 269.034 (lr:0.00010000000000106294)
31500: accuracy:0.21 loss: 241.828 (lr:0.0001000000000010419)
31520: accuracy:0.28 loss: 256.156 (lr:0.00010000000000102127)
31540: accuracy:0.18 loss: 270.495 (lr:0.00010000000000100105)
31560: accuracy:0.23 loss: 263.566 (lr:0.00010000000000098122)
31580: accuracy:0.17 loss: 251.794 (lr:0.0001000000000009618)
31600: accuracy:0.24 loss: 268.586 (lr:0.00010000000000094275)
31620: accuracy:0.18 loss: 286.806 (lr:0.00010000000000092408)
31640: accuracy:0.24 loss: 263.271 (lr:0.00010000000000090579)
31660: accuracy:0.15 loss: 257.276 (lr:0.00010000000000088784)
31680: accuracy:0.23 loss: 259.942 (lr:0.00010000000000087027)
31700: accuracy:0.11 loss: 285.753 (lr:0.00010000000000085304)
31720: accuracy:0.13 loss: 261.92 (lr:0.00010000000000083614)
31740: accuracy:0.22 loss: 250.195 (lr:0.0001000000000008196)
31760: accuracy:0.21 loss: 268.434 (lr:0.00010000000000080336)
31780: accuracy:0.15 loss: 282.852 (lr:0.00010000000000078745)
31800: accuracy:0.18 loss: 275.637 (lr:0.00010000000000077186)
31820: accuracy:0.22 loss: 261.08 (lr:0.00010000000000075657)
31840: accuracy:0.14 loss: 278.723 (lr:0.0001000000000007416)
31860: accuracy:0.18 loss: 264.033 (lr:0.00010000000000072691)
31880: accuracy:0.19 loss: 268.267 (lr:0.00010000000000071252)
31900: accuracy:0.21 loss: 262.77 (lr:0.00010000000000069841)
31920: accuracy:0.19 loss: 244.648 (lr:0.00010000000000068458)
31940: accuracy:0.19 loss: 262.223 (lr:0.00010000000000067102)
31960: accuracy:0.17 loss: 277.305 (lr:0.00010000000000065774)
31980: accuracy:0.19 loss: 233.129 (lr:0.00010000000000064471)
32000: accuracy:0.18 loss: 262.226 (lr:0.00010000000000063195)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
32000: ********* epoch 4 ********* test accuracy for all:0.182095 test loss: 279.949
32000: ********* epoch 4 ********* test accuracy for mode 0:0.0 test loss: 418.968
32000: ********* epoch 4 ********* test accuracy for mode 1:0.037 test loss: 452.765
32000: ********* epoch 4 ********* test accuracy for mode 2:0.0935 test loss: 302.72
32000: ********* epoch 4 ********* test accuracy for mode 24:0.2075 test loss: 270.805
32000: ********* epoch 4 ********* test accuracy for mode 25:0.2315 test loss: 261.702
32000: ********* epoch 4 ********* test accuracy for mode 26:0.197 test loss: 213.828
32000: ********* epoch 4 ********* test accuracy for mode 27:0.21 test loss: 280.685
32000: ********* epoch 4 ********* test accuracy for mode 28:0.153 test loss: 276.062
32000: ********* epoch 4 ********* test accuracy for mode 29:0.253 test loss: 279.427
32000: ********* epoch 4 ********* test accuracy for mode 30:0.1685 test loss: 282.574
32000: ********* epoch 4 ********* test accuracy for mode 31:0.1665 test loss: 284.543
32000: ********* epoch 4 ********* test accuracy for mode 32:0.209 test loss: 273.243
32000: ********* epoch 4 ********* test accuracy for mode 33:0.103 test loss: 278.745
32000: ********* epoch 4 ********* test accuracy for mode 34:0.004 test loss: 282.334
32000: ********* epoch 4 ********* test accuracy for mode 35:0.011 test loss: 447.451
32000: ********* epoch 4 ********* test accuracy for mode 36:0.065 test loss: 510.537
32020: accuracy:0.14 loss: 266.313 (lr:0.00010000000000061944)
32040: accuracy:0.27 loss: 253.589 (lr:0.00010000000000060717)
32060: accuracy:0.17 loss: 277.322 (lr:0.00010000000000059515)
32080: accuracy:0.22 loss: 267.012 (lr:0.00010000000000058336)
32100: accuracy:0.19 loss: 256.331 (lr:0.00010000000000057181)
32120: accuracy:0.24 loss: 262.888 (lr:0.00010000000000056048)
32140: accuracy:0.21 loss: 272.962 (lr:0.00010000000000054938)
32160: accuracy:0.15 loss: 262.444 (lr:0.00010000000000053851)
32180: accuracy:0.24 loss: 258.183 (lr:0.00010000000000052785)
32200: accuracy:0.27 loss: 243.783 (lr:0.0001000000000005174)
32220: accuracy:0.15 loss: 259.566 (lr:0.00010000000000050715)
32240: accuracy:0.2 loss: 256.271 (lr:0.00010000000000049711)
32260: accuracy:0.24 loss: 264.973 (lr:0.00010000000000048726)
32280: accuracy:0.28 loss: 266.478 (lr:0.00010000000000047761)
32300: accuracy:0.23 loss: 284.593 (lr:0.00010000000000046816)
32320: accuracy:0.2 loss: 266.433 (lr:0.0001000000000004589)
32340: accuracy:0.12 loss: 298.414 (lr:0.0001000000000004498)
32360: accuracy:0.14 loss: 253.244 (lr:0.0001000000000004409)
32380: accuracy:0.21 loss: 275.066 (lr:0.00010000000000043217)
32400: accuracy:0.17 loss: 252.809 (lr:0.0001000000000004236)
32420: accuracy:0.26 loss: 254.166 (lr:0.00010000000000041521)
32440: accuracy:0.2 loss: 275.684 (lr:0.000100000000000407)
32460: accuracy:0.17 loss: 286.21 (lr:0.00010000000000039894)
32480: accuracy:0.2 loss: 276.802 (lr:0.00010000000000039104)
32500: accuracy:0.2 loss: 267.197 (lr:0.0001000000000003833)
32520: accuracy:0.2 loss: 273.229 (lr:0.00010000000000037571)
32540: accuracy:0.2 loss: 254.289 (lr:0.00010000000000036827)
32560: accuracy:0.21 loss: 262.532 (lr:0.00010000000000036098)
32580: accuracy:0.18 loss: 252.229 (lr:0.00010000000000035383)
32600: accuracy:0.22 loss: 272.273 (lr:0.00010000000000034683)
32620: accuracy:0.14 loss: 272.855 (lr:0.00010000000000033996)
32640: accuracy:0.19 loss: 259.296 (lr:0.00010000000000033322)
32660: accuracy:0.1 loss: 265.748 (lr:0.00010000000000032662)
32680: accuracy:0.18 loss: 279.104 (lr:0.00010000000000032016)
32700: accuracy:0.19 loss: 257.904 (lr:0.00010000000000031381)
32720: accuracy:0.22 loss: 243.416 (lr:0.0001000000000003076)
32740: accuracy:0.16 loss: 275.214 (lr:0.00010000000000030151)
32760: accuracy:0.28 loss: 265.366 (lr:0.00010000000000029554)
32780: accuracy:0.17 loss: 276.37 (lr:0.00010000000000028969)
32800: accuracy:0.1 loss: 302.425 (lr:0.00010000000000028396)
32820: accuracy:0.21 loss: 264.936 (lr:0.00010000000000027833)
32840: accuracy:0.14 loss: 276.279 (lr:0.00010000000000027282)
32860: accuracy:0.2 loss: 255.087 (lr:0.00010000000000026742)
32880: accuracy:0.25 loss: 269.959 (lr:0.00010000000000026212)
32900: accuracy:0.17 loss: 278.943 (lr:0.00010000000000025693)
32920: accuracy:0.21 loss: 271.647 (lr:0.00010000000000025185)
32940: accuracy:0.21 loss: 261.405 (lr:0.00010000000000024686)
32960: accuracy:0.24 loss: 256.682 (lr:0.00010000000000024197)
32980: accuracy:0.17 loss: 267.366 (lr:0.00010000000000023717)
33000: accuracy:0.21 loss: 281.436 (lr:0.00010000000000023248)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
33000: ********* epoch 4 ********* test accuracy for all:0.182419 test loss: 279.125
33000: ********* epoch 4 ********* test accuracy for mode 0:0.0015 test loss: 409.777
33000: ********* epoch 4 ********* test accuracy for mode 1:0.0275 test loss: 446.914
33000: ********* epoch 4 ********* test accuracy for mode 2:0.052 test loss: 306.286
33000: ********* epoch 4 ********* test accuracy for mode 24:0.2015 test loss: 261.284
33000: ********* epoch 4 ********* test accuracy for mode 25:0.249 test loss: 252.538
33000: ********* epoch 4 ********* test accuracy for mode 26:0.173 test loss: 211.513
33000: ********* epoch 4 ********* test accuracy for mode 27:0.204 test loss: 276.077
33000: ********* epoch 4 ********* test accuracy for mode 28:0.1635 test loss: 274.14
33000: ********* epoch 4 ********* test accuracy for mode 29:0.2335 test loss: 278.645
33000: ********* epoch 4 ********* test accuracy for mode 30:0.1725 test loss: 282.494
33000: ********* epoch 4 ********* test accuracy for mode 31:0.1405 test loss: 284.324
33000: ********* epoch 4 ********* test accuracy for mode 32:0.2665 test loss: 268.534
33000: ********* epoch 4 ********* test accuracy for mode 33:0.0645 test loss: 278.914
33000: ********* epoch 4 ********* test accuracy for mode 34:0.0025 test loss: 283.238
33000: ********* epoch 4 ********* test accuracy for mode 35:0.0095 test loss: 440.169
33000: ********* epoch 4 ********* test accuracy for mode 36:0.1595 test loss: 494.854
33020: accuracy:0.28 loss: 235.731 (lr:0.00010000000000022788)
33040: accuracy:0.24 loss: 279.472 (lr:0.00010000000000022336)
33060: accuracy:0.22 loss: 280.639 (lr:0.00010000000000021895)
33080: accuracy:0.23 loss: 269.653 (lr:0.00010000000000021461)
33100: accuracy:0.25 loss: 255.275 (lr:0.00010000000000021035)
33120: accuracy:0.25 loss: 246.203 (lr:0.00010000000000020619)
33140: accuracy:0.24 loss: 261.09 (lr:0.00010000000000020211)
33160: accuracy:0.21 loss: 254.956 (lr:0.00010000000000019812)
33180: accuracy:0.25 loss: 266.583 (lr:0.00010000000000019419)
33200: accuracy:0.17 loss: 273.127 (lr:0.00010000000000019034)
33220: accuracy:0.16 loss: 257.591 (lr:0.00010000000000018657)
33240: accuracy:0.19 loss: 272.285 (lr:0.00010000000000018288)
33260: accuracy:0.15 loss: 252.646 (lr:0.00010000000000017926)
33280: accuracy:0.22 loss: 255.105 (lr:0.00010000000000017571)
33300: accuracy:0.24 loss: 249.034 (lr:0.00010000000000017223)
33320: accuracy:0.24 loss: 272.888 (lr:0.00010000000000016882)
33340: accuracy:0.2 loss: 249.042 (lr:0.00010000000000016548)
33360: accuracy:0.22 loss: 252.032 (lr:0.0001000000000001622)
33380: accuracy:0.23 loss: 238.348 (lr:0.00010000000000015899)
33400: accuracy:0.21 loss: 256.271 (lr:0.00010000000000015585)
33420: accuracy:0.18 loss: 261.173 (lr:0.00010000000000015276)
33440: accuracy:0.2 loss: 261.953 (lr:0.00010000000000014973)
33460: accuracy:0.21 loss: 261.303 (lr:0.00010000000000014677)
33480: accuracy:0.18 loss: 266.656 (lr:0.00010000000000014386)
33500: accuracy:0.15 loss: 266.433 (lr:0.000100000000000141)
33520: accuracy:0.22 loss: 276.401 (lr:0.00010000000000013821)
33540: accuracy:0.18 loss: 273.52 (lr:0.00010000000000013548)
33560: accuracy:0.24 loss: 246.248 (lr:0.00010000000000013279)
33580: accuracy:0.2 loss: 281.561 (lr:0.00010000000000013016)
33600: accuracy:0.23 loss: 267.172 (lr:0.00010000000000012759)
33620: accuracy:0.17 loss: 277.547 (lr:0.00010000000000012507)
33640: accuracy:0.14 loss: 258.692 (lr:0.00010000000000012259)
33660: accuracy:0.17 loss: 260.194 (lr:0.00010000000000012016)
33680: accuracy:0.24 loss: 247.94 (lr:0.00010000000000011778)
33700: accuracy:0.2 loss: 253.194 (lr:0.00010000000000011545)
33720: accuracy:0.19 loss: 263.993 (lr:0.00010000000000011317)
33740: accuracy:0.16 loss: 264.0 (lr:0.00010000000000011092)
33760: accuracy:0.2 loss: 280.97 (lr:0.00010000000000010872)
33780: accuracy:0.2 loss: 268.089 (lr:0.00010000000000010657)
33800: accuracy:0.21 loss: 270.988 (lr:0.00010000000000010447)
33820: accuracy:0.13 loss: 281.017 (lr:0.0001000000000001024)
33840: accuracy:0.24 loss: 270.917 (lr:0.00010000000000010037)
33860: accuracy:0.14 loss: 259.438 (lr:0.00010000000000009838)
33880: accuracy:0.14 loss: 294.827 (lr:0.00010000000000009643)
33900: accuracy:0.26 loss: 255.168 (lr:0.00010000000000009452)
33920: accuracy:0.23 loss: 261.005 (lr:0.00010000000000009265)
33940: accuracy:0.22 loss: 263.747 (lr:0.00010000000000009082)
33960: accuracy:0.2 loss: 240.552 (lr:0.00010000000000008902)
33980: accuracy:0.15 loss: 268.134 (lr:0.00010000000000008726)
34000: accuracy:0.21 loss: 245.589 (lr:0.00010000000000008553)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
34000: ********* epoch 4 ********* test accuracy for all:0.183662 test loss: 279.223
34000: ********* epoch 4 ********* test accuracy for mode 0:0.0015 test loss: 411.598
34000: ********* epoch 4 ********* test accuracy for mode 1:0.035 test loss: 450.895
34000: ********* epoch 4 ********* test accuracy for mode 2:0.1115 test loss: 296.122
34000: ********* epoch 4 ********* test accuracy for mode 24:0.2005 test loss: 279.429
34000: ********* epoch 4 ********* test accuracy for mode 25:0.207 test loss: 266.72
34000: ********* epoch 4 ********* test accuracy for mode 26:0.177 test loss: 214.406
34000: ********* epoch 4 ********* test accuracy for mode 27:0.2445 test loss: 277.83
34000: ********* epoch 4 ********* test accuracy for mode 28:0.1785 test loss: 270.581
34000: ********* epoch 4 ********* test accuracy for mode 29:0.224 test loss: 275.557
34000: ********* epoch 4 ********* test accuracy for mode 30:0.1965 test loss: 273.0
34000: ********* epoch 4 ********* test accuracy for mode 31:0.1655 test loss: 275.568
34000: ********* epoch 4 ********* test accuracy for mode 32:0.264 test loss: 261.204
34000: ********* epoch 4 ********* test accuracy for mode 33:0.083 test loss: 270.197
34000: ********* epoch 4 ********* test accuracy for mode 34:0.005 test loss: 274.976
34000: ********* epoch 4 ********* test accuracy for mode 35:0.008 test loss: 441.742
34000: ********* epoch 4 ********* test accuracy for mode 36:0.04 test loss: 511.629
34020: accuracy:0.22 loss: 252.393 (lr:0.00010000000000008384)
34040: accuracy:0.17 loss: 256.707 (lr:0.00010000000000008217)
34060: accuracy:0.22 loss: 260.56 (lr:0.00010000000000008055)
34080: accuracy:0.2 loss: 280.034 (lr:0.00010000000000007895)
34100: accuracy:0.2 loss: 265.397 (lr:0.00010000000000007739)
34120: accuracy:0.19 loss: 263.079 (lr:0.00010000000000007586)
34140: accuracy:0.18 loss: 267.204 (lr:0.00010000000000007435)
34160: accuracy:0.25 loss: 255.251 (lr:0.00010000000000007289)
34180: accuracy:0.26 loss: 263.62 (lr:0.00010000000000007144)
34200: accuracy:0.12 loss: 264.093 (lr:0.00010000000000007003)
34220: accuracy:0.21 loss: 251.075 (lr:0.00010000000000006863)
34240: accuracy:0.13 loss: 280.737 (lr:0.00010000000000006728)
34260: accuracy:0.22 loss: 271.928 (lr:0.00010000000000006595)
34280: accuracy:0.24 loss: 259.105 (lr:0.00010000000000006464)
34300: accuracy:0.19 loss: 267.075 (lr:0.00010000000000006336)
34320: accuracy:0.16 loss: 271.317 (lr:0.0001000000000000621)
34340: accuracy:0.07 loss: 279.368 (lr:0.00010000000000006088)
34360: accuracy:0.24 loss: 276.385 (lr:0.00010000000000005968)
34380: accuracy:0.2 loss: 269.903 (lr:0.0001000000000000585)
34400: accuracy:0.19 loss: 259.769 (lr:0.00010000000000005733)
34420: accuracy:0.18 loss: 250.445 (lr:0.0001000000000000562)
34440: accuracy:0.23 loss: 246.329 (lr:0.00010000000000005508)
34460: accuracy:0.18 loss: 254.906 (lr:0.000100000000000054)
34480: accuracy:0.22 loss: 252.996 (lr:0.00010000000000005293)
34500: accuracy:0.17 loss: 253.992 (lr:0.00010000000000005188)
34520: accuracy:0.17 loss: 265.365 (lr:0.00010000000000005085)
34540: accuracy:0.2 loss: 266.511 (lr:0.00010000000000004984)
34560: accuracy:0.19 loss: 254.593 (lr:0.00010000000000004886)
34580: accuracy:0.22 loss: 257.725 (lr:0.00010000000000004789)
34600: accuracy:0.16 loss: 265.841 (lr:0.00010000000000004694)
34620: accuracy:0.24 loss: 254.653 (lr:0.00010000000000004602)
34640: accuracy:0.2 loss: 270.074 (lr:0.00010000000000004511)
34660: accuracy:0.19 loss: 274.826 (lr:0.00010000000000004421)
34680: accuracy:0.22 loss: 262.672 (lr:0.00010000000000004333)
34700: accuracy:0.22 loss: 259.005 (lr:0.00010000000000004248)
34720: accuracy:0.2 loss: 264.182 (lr:0.00010000000000004164)
34740: accuracy:0.16 loss: 272.234 (lr:0.00010000000000004081)
34760: accuracy:0.21 loss: 249.523 (lr:0.00010000000000004)
34780: accuracy:0.18 loss: 255.589 (lr:0.00010000000000003921)
34800: accuracy:0.19 loss: 265.266 (lr:0.00010000000000003844)
34820: accuracy:0.22 loss: 252.422 (lr:0.00010000000000003767)
34840: accuracy:0.17 loss: 270.613 (lr:0.00010000000000003692)
34860: accuracy:0.19 loss: 241.67 (lr:0.00010000000000003619)
34880: accuracy:0.24 loss: 263.684 (lr:0.00010000000000003549)
34900: accuracy:0.25 loss: 242.554 (lr:0.00010000000000003478)
34920: accuracy:0.28 loss: 256.594 (lr:0.00010000000000003409)
34940: accuracy:0.14 loss: 286.04 (lr:0.00010000000000003341)
34960: accuracy:0.18 loss: 251.54 (lr:0.00010000000000003275)
34980: accuracy:0.17 loss: 266.314 (lr:0.0001000000000000321)
35000: accuracy:0.24 loss: 270.341 (lr:0.00010000000000003147)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
35000: ********* epoch 4 ********* test accuracy for all:0.17923 test loss: 279.452
35000: ********* epoch 4 ********* test accuracy for mode 0:0.001 test loss: 411.621
35000: ********* epoch 4 ********* test accuracy for mode 1:0.027 test loss: 462.189
35000: ********* epoch 4 ********* test accuracy for mode 2:0.119 test loss: 291.104
35000: ********* epoch 4 ********* test accuracy for mode 24:0.187 test loss: 280.238
35000: ********* epoch 4 ********* test accuracy for mode 25:0.2815 test loss: 256.302
35000: ********* epoch 4 ********* test accuracy for mode 26:0.111 test loss: 220.071
35000: ********* epoch 4 ********* test accuracy for mode 27:0.235 test loss: 277.498
35000: ********* epoch 4 ********* test accuracy for mode 28:0.174 test loss: 271.236
35000: ********* epoch 4 ********* test accuracy for mode 29:0.228 test loss: 274.407
35000: ********* epoch 4 ********* test accuracy for mode 30:0.168 test loss: 272.611
35000: ********* epoch 4 ********* test accuracy for mode 31:0.2155 test loss: 270.882
35000: ********* epoch 4 ********* test accuracy for mode 32:0.2205 test loss: 261.335
35000: ********* epoch 4 ********* test accuracy for mode 33:0.092 test loss: 266.672
35000: ********* epoch 4 ********* test accuracy for mode 34:0.0025 test loss: 272.822
35000: ********* epoch 4 ********* test accuracy for mode 35:0.007 test loss: 446.62
35000: ********* epoch 4 ********* test accuracy for mode 36:0.0485 test loss: 509.694
35020: accuracy:0.22 loss: 246.459 (lr:0.00010000000000003085)
35040: accuracy:0.23 loss: 248.571 (lr:0.00010000000000003023)
35060: accuracy:0.24 loss: 258.921 (lr:0.00010000000000002963)
35080: accuracy:0.18 loss: 242.419 (lr:0.00010000000000002905)
35100: accuracy:0.2 loss: 270.875 (lr:0.00010000000000002848)
35120: accuracy:0.21 loss: 256.896 (lr:0.00010000000000002791)
35140: accuracy:0.19 loss: 265.891 (lr:0.00010000000000002735)
35160: accuracy:0.19 loss: 260.232 (lr:0.00010000000000002681)
35180: accuracy:0.17 loss: 253.2 (lr:0.00010000000000002628)
35200: accuracy:0.19 loss: 270.32 (lr:0.00010000000000002577)
35220: accuracy:0.16 loss: 280.71 (lr:0.00010000000000002525)
35240: accuracy:0.28 loss: 262.71 (lr:0.00010000000000002475)
35260: accuracy:0.27 loss: 246.324 (lr:0.00010000000000002426)
35280: accuracy:0.16 loss: 270.286 (lr:0.00010000000000002379)
35300: accuracy:0.12 loss: 273.245 (lr:0.00010000000000002332)
35320: accuracy:0.26 loss: 251.939 (lr:0.00010000000000002285)
35340: accuracy:0.26 loss: 244.654 (lr:0.0001000000000000224)
35360: accuracy:0.25 loss: 261.74 (lr:0.00010000000000002196)
35380: accuracy:0.19 loss: 288.504 (lr:0.00010000000000002153)
35400: accuracy:0.2 loss: 253.381 (lr:0.00010000000000002109)
35420: accuracy:0.19 loss: 272.276 (lr:0.00010000000000002067)
35440: accuracy:0.15 loss: 295.383 (lr:0.00010000000000002027)
35460: accuracy:0.23 loss: 263.102 (lr:0.00010000000000001987)
35480: accuracy:0.18 loss: 278.185 (lr:0.00010000000000001948)
35500: accuracy:0.13 loss: 270.316 (lr:0.00010000000000001909)
35520: accuracy:0.24 loss: 260.321 (lr:0.00010000000000001871)
35540: accuracy:0.22 loss: 248.565 (lr:0.00010000000000001834)
35560: accuracy:0.21 loss: 272.895 (lr:0.00010000000000001798)
35580: accuracy:0.14 loss: 251.866 (lr:0.00010000000000001762)
35600: accuracy:0.23 loss: 247.197 (lr:0.00010000000000001727)
35620: accuracy:0.19 loss: 246.447 (lr:0.00010000000000001693)
35640: accuracy:0.18 loss: 274.439 (lr:0.00010000000000001659)
35660: accuracy:0.22 loss: 260.948 (lr:0.00010000000000001627)
35680: accuracy:0.22 loss: 259.121 (lr:0.00010000000000001594)
35700: accuracy:0.26 loss: 248.753 (lr:0.00010000000000001563)
35720: accuracy:0.22 loss: 256.118 (lr:0.00010000000000001532)
35740: accuracy:0.22 loss: 265.394 (lr:0.00010000000000001502)
35760: accuracy:0.16 loss: 246.216 (lr:0.00010000000000001472)
35780: accuracy:0.19 loss: 267.043 (lr:0.00010000000000001442)
35800: accuracy:0.17 loss: 279.883 (lr:0.00010000000000001414)
35820: accuracy:0.28 loss: 248.65 (lr:0.00010000000000001386)
35840: accuracy:0.17 loss: 264.684 (lr:0.00010000000000001358)
35860: accuracy:0.16 loss: 269.8 (lr:0.00010000000000001331)
35880: accuracy:0.15 loss: 274.569 (lr:0.00010000000000001306)
35900: accuracy:0.12 loss: 278.824 (lr:0.0001000000000000128)
35920: accuracy:0.19 loss: 289.512 (lr:0.00010000000000001254)
35940: accuracy:0.19 loss: 274.771 (lr:0.0001000000000000123)
35960: accuracy:0.14 loss: 281.841 (lr:0.00010000000000001205)
35980: accuracy:0.21 loss: 265.924 (lr:0.00010000000000001181)
36000: accuracy:0.21 loss: 254.842 (lr:0.00010000000000001158)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
36000: ********* epoch 4 ********* test accuracy for all:0.183514 test loss: 278.636
36000: ********* epoch 4 ********* test accuracy for mode 0:0.001 test loss: 414.133
36000: ********* epoch 4 ********* test accuracy for mode 1:0.0435 test loss: 453.024
36000: ********* epoch 4 ********* test accuracy for mode 2:0.1065 test loss: 295.445
36000: ********* epoch 4 ********* test accuracy for mode 24:0.2075 test loss: 276.445
36000: ********* epoch 4 ********* test accuracy for mode 25:0.241 test loss: 266.394
36000: ********* epoch 4 ********* test accuracy for mode 26:0.141 test loss: 212.79
36000: ********* epoch 4 ********* test accuracy for mode 27:0.2355 test loss: 281.909
36000: ********* epoch 4 ********* test accuracy for mode 28:0.191 test loss: 275.106
36000: ********* epoch 4 ********* test accuracy for mode 29:0.2145 test loss: 280.914
36000: ********* epoch 4 ********* test accuracy for mode 30:0.203 test loss: 278.251
36000: ********* epoch 4 ********* test accuracy for mode 31:0.1575 test loss: 279.94
36000: ********* epoch 4 ********* test accuracy for mode 32:0.2325 test loss: 266.681
36000: ********* epoch 4 ********* test accuracy for mode 33:0.104 test loss: 273.116
36000: ********* epoch 4 ********* test accuracy for mode 34:0.0075 test loss: 278.068
36000: ********* epoch 4 ********* test accuracy for mode 35:0.0115 test loss: 433.346
36000: ********* epoch 4 ********* test accuracy for mode 36:0.035 test loss: 507.074
36020: accuracy:0.24 loss: 253.167 (lr:0.00010000000000001135)
36040: accuracy:0.23 loss: 261.129 (lr:0.00010000000000001113)
36060: accuracy:0.21 loss: 258.743 (lr:0.0001000000000000109)
36080: accuracy:0.24 loss: 264.595 (lr:0.00010000000000001068)
36100: accuracy:0.21 loss: 272.18 (lr:0.00010000000000001048)
36120: accuracy:0.19 loss: 261.053 (lr:0.00010000000000001026)
36140: accuracy:0.23 loss: 263.813 (lr:0.00010000000000001006)
36160: accuracy:0.27 loss: 254.769 (lr:0.00010000000000000987)
36180: accuracy:0.24 loss: 264.4 (lr:0.00010000000000000967)
36200: accuracy:0.17 loss: 270.15 (lr:0.00010000000000000948)
36220: accuracy:0.25 loss: 264.609 (lr:0.00010000000000000929)
36240: accuracy:0.19 loss: 273.331 (lr:0.00010000000000000911)
36260: accuracy:0.18 loss: 253.406 (lr:0.00010000000000000894)
36280: accuracy:0.17 loss: 269.804 (lr:0.00010000000000000875)
36300: accuracy:0.22 loss: 250.486 (lr:0.00010000000000000858)
36320: accuracy:0.25 loss: 259.919 (lr:0.00010000000000000841)
36340: accuracy:0.16 loss: 266.478 (lr:0.00010000000000000824)
36360: accuracy:0.13 loss: 278.495 (lr:0.00010000000000000808)
36380: accuracy:0.23 loss: 277.242 (lr:0.00010000000000000792)
36400: accuracy:0.21 loss: 255.891 (lr:0.00010000000000000776)
36420: accuracy:0.26 loss: 273.816 (lr:0.00010000000000000761)
36440: accuracy:0.21 loss: 247.448 (lr:0.00010000000000000746)
36460: accuracy:0.22 loss: 252.801 (lr:0.00010000000000000731)
36480: accuracy:0.27 loss: 236.354 (lr:0.00010000000000000716)
36500: accuracy:0.2 loss: 264.174 (lr:0.00010000000000000703)
36520: accuracy:0.24 loss: 250.142 (lr:0.00010000000000000689)
36540: accuracy:0.21 loss: 249.873 (lr:0.00010000000000000675)
36560: accuracy:0.28 loss: 244.537 (lr:0.00010000000000000662)
36580: accuracy:0.2 loss: 268.769 (lr:0.00010000000000000648)
36600: accuracy:0.22 loss: 272.993 (lr:0.00010000000000000636)
36620: accuracy:0.24 loss: 246.68 (lr:0.00010000000000000623)
36640: accuracy:0.15 loss: 264.187 (lr:0.0001000000000000061)
36660: accuracy:0.14 loss: 261.62 (lr:0.00010000000000000598)
36680: accuracy:0.2 loss: 270.982 (lr:0.00010000000000000587)
36700: accuracy:0.18 loss: 265.251 (lr:0.00010000000000000575)
36720: accuracy:0.16 loss: 259.936 (lr:0.00010000000000000564)
36740: accuracy:0.2 loss: 265.317 (lr:0.00010000000000000552)
36760: accuracy:0.2 loss: 255.927 (lr:0.00010000000000000541)
36780: accuracy:0.21 loss: 266.637 (lr:0.0001000000000000053)
36800: accuracy:0.16 loss: 267.16 (lr:0.00010000000000000521)
36820: accuracy:0.25 loss: 263.063 (lr:0.0001000000000000051)
36840: accuracy:0.24 loss: 250.713 (lr:0.000100000000000005)
36860: accuracy:0.23 loss: 230.469 (lr:0.0001000000000000049)
36880: accuracy:0.29 loss: 237.368 (lr:0.0001000000000000048)
36900: accuracy:0.16 loss: 263.14 (lr:0.00010000000000000471)
36920: accuracy:0.16 loss: 267.688 (lr:0.00010000000000000461)
36940: accuracy:0.24 loss: 262.075 (lr:0.00010000000000000453)
36960: accuracy:0.2 loss: 265.673 (lr:0.00010000000000000444)
36980: accuracy:0.18 loss: 253.177 (lr:0.00010000000000000436)
37000: accuracy:0.17 loss: 255.023 (lr:0.00010000000000000426)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
37000: ********* epoch 4 ********* test accuracy for all:0.179568 test loss: 281.196
37000: ********* epoch 4 ********* test accuracy for mode 0:0.0025 test loss: 408.496
37000: ********* epoch 4 ********* test accuracy for mode 1:0.033 test loss: 458.284
37000: ********* epoch 4 ********* test accuracy for mode 2:0.0545 test loss: 295.781
37000: ********* epoch 4 ********* test accuracy for mode 24:0.1905 test loss: 294.553
37000: ********* epoch 4 ********* test accuracy for mode 25:0.206 test loss: 280.279
37000: ********* epoch 4 ********* test accuracy for mode 26:0.2075 test loss: 212.466
37000: ********* epoch 4 ********* test accuracy for mode 27:0.2145 test loss: 294.566
37000: ********* epoch 4 ********* test accuracy for mode 28:0.1655 test loss: 286.061
37000: ********* epoch 4 ********* test accuracy for mode 29:0.219 test loss: 290.332
37000: ********* epoch 4 ********* test accuracy for mode 30:0.1795 test loss: 282.089
37000: ********* epoch 4 ********* test accuracy for mode 31:0.186 test loss: 281.843
37000: ********* epoch 4 ********* test accuracy for mode 32:0.222 test loss: 269.124
37000: ********* epoch 4 ********* test accuracy for mode 33:0.09 test loss: 273.489
37000: ********* epoch 4 ********* test accuracy for mode 34:0.031 test loss: 270.959
37000: ********* epoch 4 ********* test accuracy for mode 35:0.003 test loss: 438.893
37000: ********* epoch 4 ********* test accuracy for mode 36:0.034 test loss: 496.117
37020: accuracy:0.2 loss: 278.039 (lr:0.00010000000000000418)
37040: accuracy:0.13 loss: 263.447 (lr:0.0001000000000000041)
37060: accuracy:0.2 loss: 275.55 (lr:0.00010000000000000402)
37080: accuracy:0.22 loss: 272.671 (lr:0.00010000000000000394)
37100: accuracy:0.23 loss: 254.939 (lr:0.00010000000000000385)
37120: accuracy:0.22 loss: 258.948 (lr:0.00010000000000000379)
37140: accuracy:0.25 loss: 259.242 (lr:0.0001000000000000037)
37160: accuracy:0.24 loss: 251.659 (lr:0.00010000000000000364)
37180: accuracy:0.21 loss: 294.611 (lr:0.00010000000000000356)
37200: accuracy:0.24 loss: 266.785 (lr:0.00010000000000000349)
37220: accuracy:0.24 loss: 247.359 (lr:0.00010000000000000342)
37240: accuracy:0.22 loss: 262.046 (lr:0.00010000000000000335)
37260: accuracy:0.21 loss: 280.166 (lr:0.00010000000000000328)
37280: accuracy:0.23 loss: 260.625 (lr:0.00010000000000000322)
37300: accuracy:0.23 loss: 255.44 (lr:0.00010000000000000316)
37320: accuracy:0.22 loss: 251.22 (lr:0.0001000000000000031)
37340: accuracy:0.19 loss: 260.812 (lr:0.00010000000000000304)
37360: accuracy:0.22 loss: 256.962 (lr:0.00010000000000000297)
37380: accuracy:0.27 loss: 249.295 (lr:0.00010000000000000292)
37400: accuracy:0.24 loss: 266.048 (lr:0.00010000000000000286)
37420: accuracy:0.18 loss: 262.764 (lr:0.0001000000000000028)
37440: accuracy:0.17 loss: 260.487 (lr:0.00010000000000000274)
37460: accuracy:0.2 loss: 257.722 (lr:0.00010000000000000269)
37480: accuracy:0.17 loss: 259.631 (lr:0.00010000000000000263)
37500: accuracy:0.17 loss: 253.91 (lr:0.0001000000000000026)
37520: accuracy:0.22 loss: 268.358 (lr:0.00010000000000000254)
37540: accuracy:0.19 loss: 250.203 (lr:0.00010000000000000248)
37560: accuracy:0.2 loss: 250.988 (lr:0.00010000000000000243)
37580: accuracy:0.13 loss: 276.182 (lr:0.00010000000000000239)
37600: accuracy:0.21 loss: 261.366 (lr:0.00010000000000000234)
37620: accuracy:0.27 loss: 238.646 (lr:0.0001000000000000023)
37640: accuracy:0.15 loss: 263.981 (lr:0.00010000000000000225)
37660: accuracy:0.26 loss: 250.831 (lr:0.0001000000000000022)
37680: accuracy:0.25 loss: 253.442 (lr:0.00010000000000000216)
37700: accuracy:0.26 loss: 253.319 (lr:0.00010000000000000212)
37720: accuracy:0.23 loss: 245.023 (lr:0.00010000000000000208)
37740: accuracy:0.16 loss: 247.1 (lr:0.00010000000000000204)
37760: accuracy:0.21 loss: 253.018 (lr:0.000100000000000002)
37780: accuracy:0.27 loss: 244.985 (lr:0.00010000000000000196)
37800: accuracy:0.21 loss: 255.214 (lr:0.00010000000000000192)
37820: accuracy:0.23 loss: 268.222 (lr:0.00010000000000000188)
37840: accuracy:0.2 loss: 259.089 (lr:0.00010000000000000185)
37860: accuracy:0.21 loss: 243.38 (lr:0.00010000000000000181)
37880: accuracy:0.19 loss: 249.569 (lr:0.00010000000000000177)
37900: accuracy:0.24 loss: 257.783 (lr:0.00010000000000000174)
37920: accuracy:0.14 loss: 288.166 (lr:0.0001000000000000017)
37940: accuracy:0.22 loss: 256.666 (lr:0.00010000000000000167)
37960: accuracy:0.21 loss: 245.993 (lr:0.00010000000000000163)
37980: accuracy:0.19 loss: 262.202 (lr:0.0001000000000000016)
38000: accuracy:0.17 loss: 281.531 (lr:0.00010000000000000158)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
38000: ********* epoch 4 ********* test accuracy for all:0.185595 test loss: 277.242
38000: ********* epoch 4 ********* test accuracy for mode 0:0.002 test loss: 409.427
38000: ********* epoch 4 ********* test accuracy for mode 1:0.0295 test loss: 459.402
38000: ********* epoch 4 ********* test accuracy for mode 2:0.088 test loss: 295.644
38000: ********* epoch 4 ********* test accuracy for mode 24:0.2165 test loss: 271.979
38000: ********* epoch 4 ********* test accuracy for mode 25:0.243 test loss: 253.728
38000: ********* epoch 4 ********* test accuracy for mode 26:0.203 test loss: 206.262
38000: ********* epoch 4 ********* test accuracy for mode 27:0.223 test loss: 273.188
38000: ********* epoch 4 ********* test accuracy for mode 28:0.194 test loss: 266.148
38000: ********* epoch 4 ********* test accuracy for mode 29:0.232 test loss: 271.51
38000: ********* epoch 4 ********* test accuracy for mode 30:0.203 test loss: 269.401
38000: ********* epoch 4 ********* test accuracy for mode 31:0.1635 test loss: 272.335
38000: ********* epoch 4 ********* test accuracy for mode 32:0.2495 test loss: 259.571
38000: ********* epoch 4 ********* test accuracy for mode 33:0.1045 test loss: 266.368
38000: ********* epoch 4 ********* test accuracy for mode 34:0.015 test loss: 271.016
38000: ********* epoch 4 ********* test accuracy for mode 35:0.002 test loss: 441.464
38000: ********* epoch 4 ********* test accuracy for mode 36:0.073 test loss: 497.391
38020: accuracy:0.22 loss: 254.514 (lr:0.00010000000000000154)
38040: accuracy:0.12 loss: 265.248 (lr:0.00010000000000000151)
38060: accuracy:0.21 loss: 253.287 (lr:0.00010000000000000148)
38080: accuracy:0.21 loss: 276.312 (lr:0.00010000000000000145)
38100: accuracy:0.18 loss: 254.162 (lr:0.00010000000000000143)
38120: accuracy:0.27 loss: 254.245 (lr:0.0001000000000000014)
38140: accuracy:0.17 loss: 277.992 (lr:0.00010000000000000136)
38160: accuracy:0.23 loss: 264.216 (lr:0.00010000000000000133)
38180: accuracy:0.3 loss: 255.505 (lr:0.00010000000000000132)
38200: accuracy:0.16 loss: 260.056 (lr:0.00010000000000000129)
38220: accuracy:0.31 loss: 267.162 (lr:0.00010000000000000127)
38240: accuracy:0.21 loss: 242.983 (lr:0.00010000000000000124)
38260: accuracy:0.27 loss: 262.262 (lr:0.00010000000000000121)
38280: accuracy:0.23 loss: 248.637 (lr:0.00010000000000000118)
38300: accuracy:0.21 loss: 260.487 (lr:0.00010000000000000117)
38320: accuracy:0.16 loss: 276.436 (lr:0.00010000000000000114)
38340: accuracy:0.23 loss: 257.223 (lr:0.00010000000000000112)
38360: accuracy:0.26 loss: 236.813 (lr:0.0001000000000000011)
38380: accuracy:0.28 loss: 245.27 (lr:0.00010000000000000108)
38400: accuracy:0.18 loss: 269.312 (lr:0.00010000000000000105)
38420: accuracy:0.21 loss: 255.284 (lr:0.00010000000000000103)
38440: accuracy:0.26 loss: 262.248 (lr:0.00010000000000000101)
38460: accuracy:0.21 loss: 280.182 (lr:0.000100000000000001)
38480: accuracy:0.22 loss: 259.173 (lr:0.00010000000000000098)
38500: accuracy:0.15 loss: 261.326 (lr:0.00010000000000000095)
38520: accuracy:0.18 loss: 264.929 (lr:0.00010000000000000094)
38540: accuracy:0.23 loss: 246.726 (lr:0.00010000000000000091)
38560: accuracy:0.22 loss: 261.649 (lr:0.0001000000000000009)
38580: accuracy:0.22 loss: 271.885 (lr:0.00010000000000000089)
38600: accuracy:0.25 loss: 251.149 (lr:0.00010000000000000086)
38620: accuracy:0.24 loss: 254.653 (lr:0.00010000000000000085)
38640: accuracy:0.17 loss: 264.862 (lr:0.00010000000000000083)
38660: accuracy:0.24 loss: 256.555 (lr:0.00010000000000000082)
38680: accuracy:0.18 loss: 267.169 (lr:0.0001000000000000008)
38700: accuracy:0.22 loss: 251.668 (lr:0.00010000000000000078)
38720: accuracy:0.16 loss: 255.908 (lr:0.00010000000000000076)
38740: accuracy:0.21 loss: 253.547 (lr:0.00010000000000000075)
38760: accuracy:0.21 loss: 279.88 (lr:0.00010000000000000074)
38780: accuracy:0.24 loss: 263.072 (lr:0.00010000000000000072)
38800: accuracy:0.16 loss: 257.807 (lr:0.00010000000000000071)
38820: accuracy:0.21 loss: 265.067 (lr:0.0001000000000000007)
38840: accuracy:0.14 loss: 262.15 (lr:0.00010000000000000068)
38860: accuracy:0.24 loss: 242.895 (lr:0.00010000000000000067)
38880: accuracy:0.32 loss: 245.341 (lr:0.00010000000000000066)
38900: accuracy:0.11 loss: 258.784 (lr:0.00010000000000000064)
38920: accuracy:0.2 loss: 254.558 (lr:0.00010000000000000063)
38940: accuracy:0.12 loss: 281.474 (lr:0.00010000000000000061)
38960: accuracy:0.19 loss: 250.447 (lr:0.0001000000000000006)
38980: accuracy:0.19 loss: 258.716 (lr:0.00010000000000000059)
39000: accuracy:0.2 loss: 271.856 (lr:0.00010000000000000059)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
39000: ********* epoch 5 ********* test accuracy for all:0.185514 test loss: 276.996
39000: ********* epoch 5 ********* test accuracy for mode 0:0.0015 test loss: 406.622
39000: ********* epoch 5 ********* test accuracy for mode 1:0.035 test loss: 453.213
39000: ********* epoch 5 ********* test accuracy for mode 2:0.11 test loss: 294.555
39000: ********* epoch 5 ********* test accuracy for mode 24:0.207 test loss: 274.162
39000: ********* epoch 5 ********* test accuracy for mode 25:0.202 test loss: 269.457
39000: ********* epoch 5 ********* test accuracy for mode 26:0.266 test loss: 205.349
39000: ********* epoch 5 ********* test accuracy for mode 27:0.1915 test loss: 286.929
39000: ********* epoch 5 ********* test accuracy for mode 28:0.1765 test loss: 274.909
39000: ********* epoch 5 ********* test accuracy for mode 29:0.249 test loss: 278.949
39000: ********* epoch 5 ********* test accuracy for mode 30:0.159 test loss: 279.57
39000: ********* epoch 5 ********* test accuracy for mode 31:0.1765 test loss: 277.715
39000: ********* epoch 5 ********* test accuracy for mode 32:0.2245 test loss: 267.065
39000: ********* epoch 5 ********* test accuracy for mode 33:0.0965 test loss: 271.293
39000: ********* epoch 5 ********* test accuracy for mode 34:0.025 test loss: 271.951
39000: ********* epoch 5 ********* test accuracy for mode 35:0.005 test loss: 433.257
39000: ********* epoch 5 ********* test accuracy for mode 36:0.0605 test loss: 484.576
39020: accuracy:0.16 loss: 274.424 (lr:0.00010000000000000057)
39040: accuracy:0.17 loss: 260.079 (lr:0.00010000000000000056)
39060: accuracy:0.24 loss: 253.655 (lr:0.00010000000000000055)
39080: accuracy:0.19 loss: 248.883 (lr:0.00010000000000000053)
39100: accuracy:0.21 loss: 264.85 (lr:0.00010000000000000052)
39120: accuracy:0.25 loss: 257.033 (lr:0.00010000000000000052)
39140: accuracy:0.26 loss: 240.881 (lr:0.0001000000000000005)
39160: accuracy:0.25 loss: 253.815 (lr:0.00010000000000000049)
39180: accuracy:0.24 loss: 261.213 (lr:0.00010000000000000049)
39200: accuracy:0.24 loss: 243.385 (lr:0.00010000000000000048)
39220: accuracy:0.23 loss: 246.054 (lr:0.00010000000000000047)
39240: accuracy:0.15 loss: 265.679 (lr:0.00010000000000000045)
39260: accuracy:0.17 loss: 261.97 (lr:0.00010000000000000045)
39280: accuracy:0.19 loss: 273.767 (lr:0.00010000000000000044)
39300: accuracy:0.26 loss: 245.502 (lr:0.00010000000000000042)
39320: accuracy:0.19 loss: 253.364 (lr:0.00010000000000000042)
39340: accuracy:0.16 loss: 260.336 (lr:0.00010000000000000041)
39360: accuracy:0.15 loss: 266.878 (lr:0.00010000000000000041)
39380: accuracy:0.2 loss: 248.879 (lr:0.0001000000000000004)
39400: accuracy:0.24 loss: 252.624 (lr:0.0001000000000000004)
39420: accuracy:0.15 loss: 262.535 (lr:0.00010000000000000038)
39440: accuracy:0.27 loss: 253.456 (lr:0.00010000000000000037)
39460: accuracy:0.23 loss: 256.452 (lr:0.00010000000000000037)
39480: accuracy:0.19 loss: 268.407 (lr:0.00010000000000000036)
39500: accuracy:0.26 loss: 246.648 (lr:0.00010000000000000036)
39520: accuracy:0.2 loss: 254.705 (lr:0.00010000000000000034)
39540: accuracy:0.27 loss: 251.68 (lr:0.00010000000000000034)
39560: accuracy:0.18 loss: 253.336 (lr:0.00010000000000000033)
39580: accuracy:0.26 loss: 243.003 (lr:0.00010000000000000033)
39600: accuracy:0.15 loss: 279.367 (lr:0.00010000000000000032)
39620: accuracy:0.19 loss: 267.61 (lr:0.00010000000000000032)
39640: accuracy:0.18 loss: 293.291 (lr:0.0001000000000000003)
39660: accuracy:0.21 loss: 242.255 (lr:0.0001000000000000003)
39680: accuracy:0.25 loss: 245.521 (lr:0.0001000000000000003)
39700: accuracy:0.23 loss: 239.372 (lr:0.00010000000000000029)
39720: accuracy:0.23 loss: 261.562 (lr:0.00010000000000000029)
39740: accuracy:0.22 loss: 262.329 (lr:0.00010000000000000028)
39760: accuracy:0.23 loss: 257.535 (lr:0.00010000000000000028)
39780: accuracy:0.2 loss: 249.326 (lr:0.00010000000000000026)
39800: accuracy:0.17 loss: 262.57 (lr:0.00010000000000000026)
39820: accuracy:0.2 loss: 265.822 (lr:0.00010000000000000026)
39840: accuracy:0.23 loss: 277.376 (lr:0.00010000000000000025)
39860: accuracy:0.13 loss: 259.368 (lr:0.00010000000000000025)
39880: accuracy:0.23 loss: 241.553 (lr:0.00010000000000000025)
39900: accuracy:0.21 loss: 235.798 (lr:0.00010000000000000024)
39920: accuracy:0.21 loss: 258.076 (lr:0.00010000000000000024)
39940: accuracy:0.22 loss: 266.222 (lr:0.00010000000000000024)
39960: accuracy:0.29 loss: 240.373 (lr:0.00010000000000000022)
39980: accuracy:0.18 loss: 267.981 (lr:0.00010000000000000022)
40000: accuracy:0.25 loss: 248.193 (lr:0.00010000000000000022)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
40000: ********* epoch 5 ********* test accuracy for all:0.186635 test loss: 276.938
40000: ********* epoch 5 ********* test accuracy for mode 0:0.0025 test loss: 413.669
40000: ********* epoch 5 ********* test accuracy for mode 1:0.027 test loss: 471.109
40000: ********* epoch 5 ********* test accuracy for mode 2:0.092 test loss: 297.12
40000: ********* epoch 5 ********* test accuracy for mode 24:0.2525 test loss: 266.705
40000: ********* epoch 5 ********* test accuracy for mode 25:0.219 test loss: 256.272
40000: ********* epoch 5 ********* test accuracy for mode 26:0.205 test loss: 205.336
40000: ********* epoch 5 ********* test accuracy for mode 27:0.246 test loss: 270.23
40000: ********* epoch 5 ********* test accuracy for mode 28:0.1985 test loss: 266.002
40000: ********* epoch 5 ********* test accuracy for mode 29:0.2615 test loss: 269.212
40000: ********* epoch 5 ********* test accuracy for mode 30:0.1575 test loss: 271.168
40000: ********* epoch 5 ********* test accuracy for mode 31:0.212 test loss: 270.057
40000: ********* epoch 5 ********* test accuracy for mode 32:0.2155 test loss: 261.797
40000: ********* epoch 5 ********* test accuracy for mode 33:0.1145 test loss: 267.012
40000: ********* epoch 5 ********* test accuracy for mode 34:0.0115 test loss: 273.737
40000: ********* epoch 5 ********* test accuracy for mode 35:0.002 test loss: 444.768
40000: ********* epoch 5 ********* test accuracy for mode 36:0.041 test loss: 504.862
40020: accuracy:0.21 loss: 250.569 (lr:0.00010000000000000021)
40040: accuracy:0.24 loss: 260.856 (lr:0.00010000000000000021)
40060: accuracy:0.24 loss: 269.758 (lr:0.00010000000000000021)
40080: accuracy:0.18 loss: 272.753 (lr:0.0001000000000000002)
40100: accuracy:0.2 loss: 280.765 (lr:0.0001000000000000002)
40120: accuracy:0.16 loss: 278.492 (lr:0.0001000000000000002)
40140: accuracy:0.17 loss: 265.514 (lr:0.0001000000000000002)
40160: accuracy:0.23 loss: 260.568 (lr:0.00010000000000000018)
40180: accuracy:0.19 loss: 270.266 (lr:0.00010000000000000018)
40200: accuracy:0.21 loss: 262.212 (lr:0.00010000000000000018)
40220: accuracy:0.23 loss: 241.759 (lr:0.00010000000000000018)
40240: accuracy:0.19 loss: 250.208 (lr:0.00010000000000000017)
40260: accuracy:0.11 loss: 269.121 (lr:0.00010000000000000017)
40280: accuracy:0.18 loss: 261.102 (lr:0.00010000000000000017)
40300: accuracy:0.26 loss: 242.356 (lr:0.00010000000000000017)
40320: accuracy:0.22 loss: 243.425 (lr:0.00010000000000000015)
40340: accuracy:0.24 loss: 253.182 (lr:0.00010000000000000015)
40360: accuracy:0.25 loss: 241.012 (lr:0.00010000000000000015)
40380: accuracy:0.14 loss: 260.796 (lr:0.00010000000000000015)
40400: accuracy:0.19 loss: 245.335 (lr:0.00010000000000000014)
40420: accuracy:0.21 loss: 257.391 (lr:0.00010000000000000014)
40440: accuracy:0.21 loss: 266.571 (lr:0.00010000000000000014)
40460: accuracy:0.28 loss: 255.823 (lr:0.00010000000000000014)
40480: accuracy:0.11 loss: 276.072 (lr:0.00010000000000000014)
40500: accuracy:0.23 loss: 259.036 (lr:0.00010000000000000013)
40520: accuracy:0.23 loss: 286.131 (lr:0.00010000000000000013)
40540: accuracy:0.31 loss: 233.451 (lr:0.00010000000000000013)
40560: accuracy:0.29 loss: 252.473 (lr:0.00010000000000000013)
40580: accuracy:0.26 loss: 263.065 (lr:0.00010000000000000013)
40600: accuracy:0.2 loss: 259.643 (lr:0.00010000000000000013)
40620: accuracy:0.25 loss: 251.118 (lr:0.00010000000000000011)
40640: accuracy:0.28 loss: 252.357 (lr:0.00010000000000000011)
40660: accuracy:0.16 loss: 255.188 (lr:0.00010000000000000011)
40680: accuracy:0.26 loss: 255.62 (lr:0.00010000000000000011)
40700: accuracy:0.16 loss: 237.626 (lr:0.00010000000000000011)
40720: accuracy:0.2 loss: 256.263 (lr:0.00010000000000000011)
40740: accuracy:0.17 loss: 258.209 (lr:0.0001000000000000001)
40760: accuracy:0.28 loss: 259.264 (lr:0.0001000000000000001)
40780: accuracy:0.23 loss: 261.449 (lr:0.0001000000000000001)
40800: accuracy:0.21 loss: 252.882 (lr:0.0001000000000000001)
40820: accuracy:0.2 loss: 263.476 (lr:0.0001000000000000001)
40840: accuracy:0.24 loss: 258.758 (lr:0.0001000000000000001)
40860: accuracy:0.23 loss: 247.812 (lr:0.0001000000000000001)
40880: accuracy:0.19 loss: 247.458 (lr:0.00010000000000000009)
40900: accuracy:0.22 loss: 261.672 (lr:0.00010000000000000009)
40920: accuracy:0.25 loss: 256.413 (lr:0.00010000000000000009)
40940: accuracy:0.2 loss: 236.11 (lr:0.00010000000000000009)
40960: accuracy:0.19 loss: 259.659 (lr:0.00010000000000000009)
40980: accuracy:0.18 loss: 261.712 (lr:0.00010000000000000009)
41000: accuracy:0.23 loss: 270.736 (lr:0.00010000000000000009)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
41000: ********* epoch 5 ********* test accuracy for all:0.188527 test loss: 277.485
41000: ********* epoch 5 ********* test accuracy for mode 0:0.0035 test loss: 407.578
41000: ********* epoch 5 ********* test accuracy for mode 1:0.0305 test loss: 463.222
41000: ********* epoch 5 ********* test accuracy for mode 2:0.095 test loss: 292.946
41000: ********* epoch 5 ********* test accuracy for mode 24:0.2005 test loss: 278.131
41000: ********* epoch 5 ********* test accuracy for mode 25:0.2575 test loss: 262.311
41000: ********* epoch 5 ********* test accuracy for mode 26:0.2165 test loss: 207.797
41000: ********* epoch 5 ********* test accuracy for mode 27:0.198 test loss: 286.385
41000: ********* epoch 5 ********* test accuracy for mode 28:0.2165 test loss: 272.584
41000: ********* epoch 5 ********* test accuracy for mode 29:0.2375 test loss: 277.347
41000: ********* epoch 5 ********* test accuracy for mode 30:0.1685 test loss: 275.811
41000: ********* epoch 5 ********* test accuracy for mode 31:0.178 test loss: 275.345
41000: ********* epoch 5 ********* test accuracy for mode 32:0.215 test loss: 263.454
41000: ********* epoch 5 ********* test accuracy for mode 33:0.1235 test loss: 265.596
41000: ********* epoch 5 ********* test accuracy for mode 34:0.0145 test loss: 270.789
41000: ********* epoch 5 ********* test accuracy for mode 35:0.0015 test loss: 448.037
41000: ********* epoch 5 ********* test accuracy for mode 36:0.043 test loss: 502.028
41020: accuracy:0.18 loss: 263.055 (lr:0.00010000000000000009)
41040: accuracy:0.25 loss: 242.605 (lr:0.00010000000000000009)
41060: accuracy:0.23 loss: 253.487 (lr:0.00010000000000000007)
41080: accuracy:0.17 loss: 262.163 (lr:0.00010000000000000007)
41100: accuracy:0.24 loss: 246.539 (lr:0.00010000000000000007)
41120: accuracy:0.18 loss: 259.784 (lr:0.00010000000000000007)
41140: accuracy:0.28 loss: 241.811 (lr:0.00010000000000000007)
41160: accuracy:0.23 loss: 258.322 (lr:0.00010000000000000007)
41180: accuracy:0.21 loss: 273.607 (lr:0.00010000000000000007)
41200: accuracy:0.23 loss: 249.336 (lr:0.00010000000000000007)
41220: accuracy:0.24 loss: 259.398 (lr:0.00010000000000000007)
41240: accuracy:0.21 loss: 264.647 (lr:0.00010000000000000007)
41260: accuracy:0.23 loss: 245.101 (lr:0.00010000000000000006)
41280: accuracy:0.23 loss: 274.208 (lr:0.00010000000000000006)
41300: accuracy:0.2 loss: 264.454 (lr:0.00010000000000000006)
41320: accuracy:0.22 loss: 250.292 (lr:0.00010000000000000006)
41340: accuracy:0.27 loss: 257.415 (lr:0.00010000000000000006)
41360: accuracy:0.22 loss: 260.606 (lr:0.00010000000000000006)
41380: accuracy:0.23 loss: 268.991 (lr:0.00010000000000000006)
41400: accuracy:0.24 loss: 255.491 (lr:0.00010000000000000006)
41420: accuracy:0.21 loss: 257.2 (lr:0.00010000000000000006)
41440: accuracy:0.17 loss: 264.249 (lr:0.00010000000000000006)
41460: accuracy:0.17 loss: 278.379 (lr:0.00010000000000000006)
41480: accuracy:0.23 loss: 263.06 (lr:0.00010000000000000006)
41500: accuracy:0.18 loss: 252.762 (lr:0.00010000000000000005)
41520: accuracy:0.28 loss: 240.098 (lr:0.00010000000000000005)
41540: accuracy:0.23 loss: 254.782 (lr:0.00010000000000000005)
41560: accuracy:0.27 loss: 270.889 (lr:0.00010000000000000005)
41580: accuracy:0.18 loss: 261.673 (lr:0.00010000000000000005)
41600: accuracy:0.21 loss: 243.508 (lr:0.00010000000000000005)
41620: accuracy:0.22 loss: 253.194 (lr:0.00010000000000000005)
41640: accuracy:0.2 loss: 248.747 (lr:0.00010000000000000005)
41660: accuracy:0.25 loss: 231.649 (lr:0.00010000000000000005)
41680: accuracy:0.2 loss: 243.812 (lr:0.00010000000000000005)
41700: accuracy:0.3 loss: 252.666 (lr:0.00010000000000000005)
41720: accuracy:0.23 loss: 245.851 (lr:0.00010000000000000005)
41740: accuracy:0.18 loss: 287.588 (lr:0.00010000000000000005)
41760: accuracy:0.27 loss: 236.516 (lr:0.00010000000000000005)
41780: accuracy:0.24 loss: 238.257 (lr:0.00010000000000000005)
41800: accuracy:0.27 loss: 244.461 (lr:0.00010000000000000005)
41820: accuracy:0.24 loss: 252.598 (lr:0.00010000000000000005)
41840: accuracy:0.28 loss: 247.832 (lr:0.00010000000000000003)
41860: accuracy:0.25 loss: 258.588 (lr:0.00010000000000000003)
41880: accuracy:0.24 loss: 259.085 (lr:0.00010000000000000003)
41900: accuracy:0.15 loss: 274.652 (lr:0.00010000000000000003)
41920: accuracy:0.23 loss: 279.578 (lr:0.00010000000000000003)
41940: accuracy:0.2 loss: 262.215 (lr:0.00010000000000000003)
41960: accuracy:0.2 loss: 252.587 (lr:0.00010000000000000003)
41980: accuracy:0.25 loss: 237.72 (lr:0.00010000000000000003)
42000: accuracy:0.14 loss: 272.42 (lr:0.00010000000000000003)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
42000: ********* epoch 5 ********* test accuracy for all:0.189473 test loss: 275.863
42000: ********* epoch 5 ********* test accuracy for mode 0:0.0045 test loss: 409.824
42000: ********* epoch 5 ********* test accuracy for mode 1:0.0365 test loss: 455.684
42000: ********* epoch 5 ********* test accuracy for mode 2:0.08 test loss: 297.482
42000: ********* epoch 5 ********* test accuracy for mode 24:0.2355 test loss: 272.709
42000: ********* epoch 5 ********* test accuracy for mode 25:0.28 test loss: 255.369
42000: ********* epoch 5 ********* test accuracy for mode 26:0.182 test loss: 203.941
42000: ********* epoch 5 ********* test accuracy for mode 27:0.218 test loss: 277.803
42000: ********* epoch 5 ********* test accuracy for mode 28:0.221 test loss: 266.223
42000: ********* epoch 5 ********* test accuracy for mode 29:0.269 test loss: 272.338
42000: ********* epoch 5 ********* test accuracy for mode 30:0.1505 test loss: 273.982
42000: ********* epoch 5 ********* test accuracy for mode 31:0.1695 test loss: 276.426
42000: ********* epoch 5 ********* test accuracy for mode 32:0.2075 test loss: 265.11
42000: ********* epoch 5 ********* test accuracy for mode 33:0.1235 test loss: 268.188
42000: ********* epoch 5 ********* test accuracy for mode 34:0.0115 test loss: 274.733
42000: ********* epoch 5 ********* test accuracy for mode 35:0.0125 test loss: 436.134
42000: ********* epoch 5 ********* test accuracy for mode 36:0.041 test loss: 494.376
42020: accuracy:0.17 loss: 268.005 (lr:0.00010000000000000003)
42040: accuracy:0.25 loss: 250.319 (lr:0.00010000000000000003)
42060: accuracy:0.15 loss: 278.331 (lr:0.00010000000000000003)
42080: accuracy:0.23 loss: 256.422 (lr:0.00010000000000000003)
42100: accuracy:0.24 loss: 259.22 (lr:0.00010000000000000003)
42120: accuracy:0.24 loss: 247.06 (lr:0.00010000000000000003)
42140: accuracy:0.27 loss: 260.295 (lr:0.00010000000000000003)
42160: accuracy:0.19 loss: 263.838 (lr:0.00010000000000000003)
42180: accuracy:0.16 loss: 278.59 (lr:0.00010000000000000003)
42200: accuracy:0.25 loss: 258.326 (lr:0.00010000000000000003)
42220: accuracy:0.22 loss: 248.702 (lr:0.00010000000000000003)
42240: accuracy:0.21 loss: 259.804 (lr:0.00010000000000000003)
42260: accuracy:0.23 loss: 255.588 (lr:0.00010000000000000003)
42280: accuracy:0.28 loss: 265.456 (lr:0.00010000000000000003)
42300: accuracy:0.25 loss: 250.366 (lr:0.00010000000000000003)
42320: accuracy:0.23 loss: 248.465 (lr:0.00010000000000000003)
42340: accuracy:0.22 loss: 253.049 (lr:0.00010000000000000003)
42360: accuracy:0.21 loss: 255.374 (lr:0.00010000000000000002)
42380: accuracy:0.2 loss: 267.447 (lr:0.00010000000000000002)
42400: accuracy:0.16 loss: 262.162 (lr:0.00010000000000000002)
42420: accuracy:0.19 loss: 265.077 (lr:0.00010000000000000002)
42440: accuracy:0.18 loss: 274.133 (lr:0.00010000000000000002)
42460: accuracy:0.27 loss: 242.539 (lr:0.00010000000000000002)
42480: accuracy:0.2 loss: 264.211 (lr:0.00010000000000000002)
42500: accuracy:0.22 loss: 247.464 (lr:0.00010000000000000002)
42520: accuracy:0.24 loss: 261.961 (lr:0.00010000000000000002)
42540: accuracy:0.26 loss: 271.798 (lr:0.00010000000000000002)
42560: accuracy:0.2 loss: 262.027 (lr:0.00010000000000000002)
42580: accuracy:0.19 loss: 268.668 (lr:0.00010000000000000002)
42600: accuracy:0.32 loss: 246.314 (lr:0.00010000000000000002)
42620: accuracy:0.19 loss: 285.353 (lr:0.00010000000000000002)
42640: accuracy:0.21 loss: 260.561 (lr:0.00010000000000000002)
42660: accuracy:0.16 loss: 269.94 (lr:0.00010000000000000002)
42680: accuracy:0.29 loss: 238.77 (lr:0.00010000000000000002)
42700: accuracy:0.24 loss: 255.06 (lr:0.00010000000000000002)
42720: accuracy:0.25 loss: 245.451 (lr:0.00010000000000000002)
42740: accuracy:0.24 loss: 246.207 (lr:0.00010000000000000002)
42760: accuracy:0.19 loss: 252.099 (lr:0.00010000000000000002)
42780: accuracy:0.32 loss: 246.667 (lr:0.00010000000000000002)
42800: accuracy:0.23 loss: 257.139 (lr:0.00010000000000000002)
42820: accuracy:0.23 loss: 259.068 (lr:0.00010000000000000002)
42840: accuracy:0.16 loss: 233.216 (lr:0.00010000000000000002)
42860: accuracy:0.25 loss: 245.649 (lr:0.00010000000000000002)
42880: accuracy:0.25 loss: 252.623 (lr:0.00010000000000000002)
42900: accuracy:0.23 loss: 246.679 (lr:0.00010000000000000002)
42920: accuracy:0.19 loss: 257.062 (lr:0.00010000000000000002)
42940: accuracy:0.2 loss: 264.924 (lr:0.00010000000000000002)
42960: accuracy:0.12 loss: 251.207 (lr:0.00010000000000000002)
42980: accuracy:0.24 loss: 250.817 (lr:0.00010000000000000002)
43000: accuracy:0.3 loss: 248.299 (lr:0.00010000000000000002)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
43000: ********* epoch 5 ********* test accuracy for all:0.189135 test loss: 275.498
43000: ********* epoch 5 ********* test accuracy for mode 0:0.004 test loss: 401.427
43000: ********* epoch 5 ********* test accuracy for mode 1:0.041 test loss: 444.034
43000: ********* epoch 5 ********* test accuracy for mode 2:0.0585 test loss: 297.133
43000: ********* epoch 5 ********* test accuracy for mode 24:0.247 test loss: 268.454
43000: ********* epoch 5 ********* test accuracy for mode 25:0.268 test loss: 255.136
43000: ********* epoch 5 ********* test accuracy for mode 26:0.2555 test loss: 201.948
43000: ********* epoch 5 ********* test accuracy for mode 27:0.1925 test loss: 278.054
43000: ********* epoch 5 ********* test accuracy for mode 28:0.257 test loss: 263.511
43000: ********* epoch 5 ********* test accuracy for mode 29:0.26 test loss: 274.359
43000: ********* epoch 5 ********* test accuracy for mode 30:0.1595 test loss: 278.208
43000: ********* epoch 5 ********* test accuracy for mode 31:0.1565 test loss: 280.852
43000: ********* epoch 5 ********* test accuracy for mode 32:0.217 test loss: 269.141
43000: ********* epoch 5 ********* test accuracy for mode 33:0.094 test loss: 273.253
43000: ********* epoch 5 ********* test accuracy for mode 34:0.02 test loss: 275.908
43000: ********* epoch 5 ********* test accuracy for mode 35:0.0125 test loss: 427.112
43000: ********* epoch 5 ********* test accuracy for mode 36:0.043 test loss: 487.918
43020: accuracy:0.21 loss: 252.173 (lr:0.00010000000000000002)
43040: accuracy:0.25 loss: 244.825 (lr:0.00010000000000000002)
43060: accuracy:0.24 loss: 249.304 (lr:0.00010000000000000002)
43080: accuracy:0.22 loss: 244.578 (lr:0.00010000000000000002)
43100: accuracy:0.22 loss: 251.201 (lr:0.00010000000000000002)
43120: accuracy:0.22 loss: 247.659 (lr:0.00010000000000000002)
43140: accuracy:0.23 loss: 237.838 (lr:0.00010000000000000002)
43160: accuracy:0.21 loss: 278.617 (lr:0.00010000000000000002)
43180: accuracy:0.14 loss: 262.068 (lr:0.00010000000000000002)
43200: accuracy:0.26 loss: 251.533 (lr:0.00010000000000000002)
43220: accuracy:0.31 loss: 244.091 (lr:0.00010000000000000002)
43240: accuracy:0.23 loss: 258.541 (lr:0.00010000000000000002)
43260: accuracy:0.21 loss: 252.885 (lr:0.00010000000000000002)
43280: accuracy:0.21 loss: 274.511 (lr:0.00010000000000000002)
43300: accuracy:0.29 loss: 255.154 (lr:0.00010000000000000002)
43320: accuracy:0.24 loss: 239.079 (lr:0.00010000000000000002)
43340: accuracy:0.17 loss: 254.851 (lr:0.00010000000000000002)
43360: accuracy:0.1 loss: 264.976 (lr:0.00010000000000000002)
43380: accuracy:0.24 loss: 246.642 (lr:0.00010000000000000002)
43400: accuracy:0.24 loss: 239.177 (lr:0.00010000000000000002)
43420: accuracy:0.27 loss: 239.834 (lr:0.00010000000000000002)
43440: accuracy:0.21 loss: 260.21 (lr:0.00010000000000000002)
43460: accuracy:0.27 loss: 229.493 (lr:0.0001)
43480: accuracy:0.22 loss: 273.296 (lr:0.0001)
43500: accuracy:0.25 loss: 263.61 (lr:0.0001)
43520: accuracy:0.2 loss: 253.782 (lr:0.0001)
43540: accuracy:0.23 loss: 257.49 (lr:0.0001)
43560: accuracy:0.19 loss: 258.545 (lr:0.0001)
43580: accuracy:0.25 loss: 244.0 (lr:0.0001)
43600: accuracy:0.26 loss: 247.354 (lr:0.0001)
43620: accuracy:0.2 loss: 258.242 (lr:0.0001)
43640: accuracy:0.12 loss: 268.29 (lr:0.0001)
43660: accuracy:0.22 loss: 253.368 (lr:0.0001)
43680: accuracy:0.22 loss: 248.597 (lr:0.0001)
43700: accuracy:0.14 loss: 256.321 (lr:0.0001)
43720: accuracy:0.12 loss: 264.717 (lr:0.0001)
43740: accuracy:0.24 loss: 237.147 (lr:0.0001)
43760: accuracy:0.26 loss: 260.175 (lr:0.0001)
43780: accuracy:0.19 loss: 259.404 (lr:0.0001)
43800: accuracy:0.15 loss: 265.186 (lr:0.0001)
43820: accuracy:0.19 loss: 255.624 (lr:0.0001)
43840: accuracy:0.2 loss: 254.969 (lr:0.0001)
43860: accuracy:0.11 loss: 284.675 (lr:0.0001)
43880: accuracy:0.27 loss: 241.863 (lr:0.0001)
43900: accuracy:0.26 loss: 248.947 (lr:0.0001)
43920: accuracy:0.22 loss: 243.824 (lr:0.0001)
43940: accuracy:0.21 loss: 253.698 (lr:0.0001)
43960: accuracy:0.22 loss: 249.567 (lr:0.0001)
43980: accuracy:0.25 loss: 248.864 (lr:0.0001)
44000: accuracy:0.23 loss: 232.296 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
44000: ********* epoch 5 ********* test accuracy for all:0.188676 test loss: 278.344
44000: ********* epoch 5 ********* test accuracy for mode 0:0.0075 test loss: 405.397
44000: ********* epoch 5 ********* test accuracy for mode 1:0.0295 test loss: 459.706
44000: ********* epoch 5 ********* test accuracy for mode 2:0.074 test loss: 289.565
44000: ********* epoch 5 ********* test accuracy for mode 24:0.1875 test loss: 295.719
44000: ********* epoch 5 ********* test accuracy for mode 25:0.2785 test loss: 268.922
44000: ********* epoch 5 ********* test accuracy for mode 26:0.2305 test loss: 208.404
44000: ********* epoch 5 ********* test accuracy for mode 27:0.1975 test loss: 285.279
44000: ********* epoch 5 ********* test accuracy for mode 28:0.2445 test loss: 269.701
44000: ********* epoch 5 ********* test accuracy for mode 29:0.227 test loss: 278.243
44000: ********* epoch 5 ********* test accuracy for mode 30:0.163 test loss: 270.733
44000: ********* epoch 5 ********* test accuracy for mode 31:0.212 test loss: 267.564
44000: ********* epoch 5 ********* test accuracy for mode 32:0.2035 test loss: 258.587
44000: ********* epoch 5 ********* test accuracy for mode 33:0.123 test loss: 260.483
44000: ********* epoch 5 ********* test accuracy for mode 34:0.017 test loss: 266.016
44000: ********* epoch 5 ********* test accuracy for mode 35:0.0075 test loss: 446.84
44000: ********* epoch 5 ********* test accuracy for mode 36:0.0265 test loss: 498.415
44020: accuracy:0.24 loss: 271.72 (lr:0.0001)
44040: accuracy:0.24 loss: 268.359 (lr:0.0001)
44060: accuracy:0.2 loss: 260.677 (lr:0.0001)
44080: accuracy:0.25 loss: 242.484 (lr:0.0001)
44100: accuracy:0.19 loss: 275.289 (lr:0.0001)
44120: accuracy:0.24 loss: 253.899 (lr:0.0001)
44140: accuracy:0.22 loss: 252.823 (lr:0.0001)
44160: accuracy:0.25 loss: 238.759 (lr:0.0001)
44180: accuracy:0.24 loss: 255.2 (lr:0.0001)
44200: accuracy:0.16 loss: 248.913 (lr:0.0001)
44220: accuracy:0.25 loss: 238.678 (lr:0.0001)
44240: accuracy:0.23 loss: 248.42 (lr:0.0001)
44260: accuracy:0.18 loss: 262.073 (lr:0.0001)
44280: accuracy:0.15 loss: 275.457 (lr:0.0001)
44300: accuracy:0.12 loss: 263.889 (lr:0.0001)
44320: accuracy:0.22 loss: 240.906 (lr:0.0001)
44340: accuracy:0.21 loss: 261.913 (lr:0.0001)
44360: accuracy:0.26 loss: 246.526 (lr:0.0001)
44380: accuracy:0.22 loss: 249.533 (lr:0.0001)
44400: accuracy:0.2 loss: 248.676 (lr:0.0001)
44420: accuracy:0.16 loss: 263.01 (lr:0.0001)
44440: accuracy:0.2 loss: 248.167 (lr:0.0001)
44460: accuracy:0.25 loss: 254.252 (lr:0.0001)
44480: accuracy:0.28 loss: 240.339 (lr:0.0001)
44500: accuracy:0.24 loss: 273.764 (lr:0.0001)
44520: accuracy:0.27 loss: 258.234 (lr:0.0001)
44540: accuracy:0.19 loss: 248.448 (lr:0.0001)
44560: accuracy:0.15 loss: 256.398 (lr:0.0001)
44580: accuracy:0.25 loss: 241.376 (lr:0.0001)
44600: accuracy:0.18 loss: 264.106 (lr:0.0001)
44620: accuracy:0.24 loss: 250.132 (lr:0.0001)
44640: accuracy:0.27 loss: 256.863 (lr:0.0001)
44660: accuracy:0.19 loss: 240.938 (lr:0.0001)
44680: accuracy:0.2 loss: 263.833 (lr:0.0001)
44700: accuracy:0.21 loss: 256.412 (lr:0.0001)
44720: accuracy:0.22 loss: 261.778 (lr:0.0001)
44740: accuracy:0.24 loss: 263.2 (lr:0.0001)
44760: accuracy:0.29 loss: 245.833 (lr:0.0001)
44780: accuracy:0.2 loss: 267.589 (lr:0.0001)
44800: accuracy:0.27 loss: 273.163 (lr:0.0001)
44820: accuracy:0.21 loss: 263.362 (lr:0.0001)
44840: accuracy:0.28 loss: 237.202 (lr:0.0001)
44860: accuracy:0.24 loss: 246.034 (lr:0.0001)
44880: accuracy:0.18 loss: 254.478 (lr:0.0001)
44900: accuracy:0.15 loss: 266.146 (lr:0.0001)
44920: accuracy:0.23 loss: 254.057 (lr:0.0001)
44940: accuracy:0.14 loss: 266.809 (lr:0.0001)
44960: accuracy:0.15 loss: 249.919 (lr:0.0001)
44980: accuracy:0.22 loss: 255.775 (lr:0.0001)
45000: accuracy:0.35 loss: 245.858 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
45000: ********* epoch 5 ********* test accuracy for all:0.189932 test loss: 277.033
45000: ********* epoch 5 ********* test accuracy for mode 0:0.0095 test loss: 410.981
45000: ********* epoch 5 ********* test accuracy for mode 1:0.032 test loss: 461.304
45000: ********* epoch 5 ********* test accuracy for mode 2:0.0705 test loss: 290.625
45000: ********* epoch 5 ********* test accuracy for mode 24:0.2075 test loss: 287.289
45000: ********* epoch 5 ********* test accuracy for mode 25:0.272 test loss: 263.681
45000: ********* epoch 5 ********* test accuracy for mode 26:0.2205 test loss: 203.698
45000: ********* epoch 5 ********* test accuracy for mode 27:0.2255 test loss: 277.619
45000: ********* epoch 5 ********* test accuracy for mode 28:0.227 test loss: 265.604
45000: ********* epoch 5 ********* test accuracy for mode 29:0.2635 test loss: 270.622
45000: ********* epoch 5 ********* test accuracy for mode 30:0.1745 test loss: 269.916
45000: ********* epoch 5 ********* test accuracy for mode 31:0.1725 test loss: 273.665
45000: ********* epoch 5 ********* test accuracy for mode 32:0.216 test loss: 262.711
45000: ********* epoch 5 ********* test accuracy for mode 33:0.092 test loss: 267.554
45000: ********* epoch 5 ********* test accuracy for mode 34:0.0245 test loss: 269.029
45000: ********* epoch 5 ********* test accuracy for mode 35:0.0145 test loss: 438.418
45000: ********* epoch 5 ********* test accuracy for mode 36:0.033 test loss: 496.962
45020: accuracy:0.21 loss: 295.844 (lr:0.0001)
45040: accuracy:0.28 loss: 236.102 (lr:0.0001)
45060: accuracy:0.19 loss: 256.953 (lr:0.0001)
45080: accuracy:0.24 loss: 242.687 (lr:0.0001)
45100: accuracy:0.24 loss: 246.519 (lr:0.0001)
45120: accuracy:0.21 loss: 252.614 (lr:0.0001)
45140: accuracy:0.17 loss: 267.347 (lr:0.0001)
45160: accuracy:0.27 loss: 245.455 (lr:0.0001)
45180: accuracy:0.24 loss: 259.701 (lr:0.0001)
45200: accuracy:0.27 loss: 247.762 (lr:0.0001)
45220: accuracy:0.22 loss: 256.764 (lr:0.0001)
45240: accuracy:0.21 loss: 246.73 (lr:0.0001)
45260: accuracy:0.28 loss: 245.22 (lr:0.0001)
45280: accuracy:0.26 loss: 263.617 (lr:0.0001)
45300: accuracy:0.19 loss: 274.414 (lr:0.0001)
45320: accuracy:0.27 loss: 248.534 (lr:0.0001)
45340: accuracy:0.22 loss: 236.512 (lr:0.0001)
45360: accuracy:0.32 loss: 249.422 (lr:0.0001)
45380: accuracy:0.21 loss: 249.742 (lr:0.0001)
45400: accuracy:0.23 loss: 241.984 (lr:0.0001)
45420: accuracy:0.16 loss: 267.752 (lr:0.0001)
45440: accuracy:0.22 loss: 268.976 (lr:0.0001)
45460: accuracy:0.21 loss: 265.361 (lr:0.0001)
45480: accuracy:0.16 loss: 282.537 (lr:0.0001)
45500: accuracy:0.22 loss: 250.896 (lr:0.0001)
45520: accuracy:0.24 loss: 248.935 (lr:0.0001)
45540: accuracy:0.22 loss: 249.432 (lr:0.0001)
45560: accuracy:0.17 loss: 269.106 (lr:0.0001)
45580: accuracy:0.24 loss: 263.545 (lr:0.0001)
45600: accuracy:0.31 loss: 244.234 (lr:0.0001)
45620: accuracy:0.24 loss: 240.162 (lr:0.0001)
45640: accuracy:0.19 loss: 255.699 (lr:0.0001)
45660: accuracy:0.26 loss: 227.771 (lr:0.0001)
45680: accuracy:0.23 loss: 255.364 (lr:0.0001)
45700: accuracy:0.21 loss: 258.795 (lr:0.0001)
45720: accuracy:0.2 loss: 240.356 (lr:0.0001)
45740: accuracy:0.16 loss: 258.286 (lr:0.0001)
45760: accuracy:0.23 loss: 239.321 (lr:0.0001)
45780: accuracy:0.26 loss: 248.086 (lr:0.0001)
45800: accuracy:0.18 loss: 249.374 (lr:0.0001)
45820: accuracy:0.26 loss: 250.427 (lr:0.0001)
45840: accuracy:0.18 loss: 247.893 (lr:0.0001)
45860: accuracy:0.2 loss: 265.603 (lr:0.0001)
45880: accuracy:0.23 loss: 253.615 (lr:0.0001)
45900: accuracy:0.16 loss: 280.367 (lr:0.0001)
45920: accuracy:0.25 loss: 255.008 (lr:0.0001)
45940: accuracy:0.3 loss: 248.056 (lr:0.0001)
45960: accuracy:0.25 loss: 229.372 (lr:0.0001)
45980: accuracy:0.23 loss: 257.859 (lr:0.0001)
46000: accuracy:0.21 loss: 244.578 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
46000: ********* epoch 5 ********* test accuracy for all:0.193081 test loss: 276.381
46000: ********* epoch 5 ********* test accuracy for mode 0:0.007 test loss: 408.523
46000: ********* epoch 5 ********* test accuracy for mode 1:0.034 test loss: 458.141
46000: ********* epoch 5 ********* test accuracy for mode 2:0.058 test loss: 297.151
46000: ********* epoch 5 ********* test accuracy for mode 24:0.221 test loss: 284.276
46000: ********* epoch 5 ********* test accuracy for mode 25:0.237 test loss: 265.651
46000: ********* epoch 5 ********* test accuracy for mode 26:0.3555 test loss: 200.723
46000: ********* epoch 5 ********* test accuracy for mode 27:0.207 test loss: 282.519
46000: ********* epoch 5 ********* test accuracy for mode 28:0.218 test loss: 275.657
46000: ********* epoch 5 ********* test accuracy for mode 29:0.2555 test loss: 280.837
46000: ********* epoch 5 ********* test accuracy for mode 30:0.1545 test loss: 279.051
46000: ********* epoch 5 ********* test accuracy for mode 31:0.1705 test loss: 280.28
46000: ********* epoch 5 ********* test accuracy for mode 32:0.2165 test loss: 268.521
46000: ********* epoch 5 ********* test accuracy for mode 33:0.083 test loss: 273.262
46000: ********* epoch 5 ********* test accuracy for mode 34:0.023 test loss: 275.185
46000: ********* epoch 5 ********* test accuracy for mode 35:0.013 test loss: 436.948
46000: ********* epoch 5 ********* test accuracy for mode 36:0.023 test loss: 492.306
46020: accuracy:0.22 loss: 268.617 (lr:0.0001)
46040: accuracy:0.18 loss: 245.411 (lr:0.0001)
46060: accuracy:0.23 loss: 238.313 (lr:0.0001)
46080: accuracy:0.31 loss: 222.801 (lr:0.0001)
46100: accuracy:0.18 loss: 260.265 (lr:0.0001)
46120: accuracy:0.23 loss: 260.789 (lr:0.0001)
46140: accuracy:0.27 loss: 260.585 (lr:0.0001)
46160: accuracy:0.25 loss: 250.873 (lr:0.0001)
46180: accuracy:0.24 loss: 257.863 (lr:0.0001)
46200: accuracy:0.19 loss: 251.42 (lr:0.0001)
46220: accuracy:0.24 loss: 250.59 (lr:0.0001)
46240: accuracy:0.16 loss: 266.525 (lr:0.0001)
46260: accuracy:0.19 loss: 248.447 (lr:0.0001)
46280: accuracy:0.19 loss: 269.57 (lr:0.0001)
46300: accuracy:0.21 loss: 241.602 (lr:0.0001)
46320: accuracy:0.27 loss: 260.454 (lr:0.0001)
46340: accuracy:0.21 loss: 251.795 (lr:0.0001)
46360: accuracy:0.31 loss: 251.67 (lr:0.0001)
46380: accuracy:0.22 loss: 255.832 (lr:0.0001)
46400: accuracy:0.23 loss: 246.305 (lr:0.0001)
46420: accuracy:0.29 loss: 248.128 (lr:0.0001)
46440: accuracy:0.27 loss: 240.925 (lr:0.0001)
46460: accuracy:0.22 loss: 257.535 (lr:0.0001)
46480: accuracy:0.17 loss: 271.388 (lr:0.0001)
46500: accuracy:0.21 loss: 270.685 (lr:0.0001)
46520: accuracy:0.21 loss: 256.313 (lr:0.0001)
46540: accuracy:0.21 loss: 255.338 (lr:0.0001)
46560: accuracy:0.18 loss: 246.56 (lr:0.0001)
46580: accuracy:0.19 loss: 270.382 (lr:0.0001)
46600: accuracy:0.2 loss: 243.868 (lr:0.0001)
46620: accuracy:0.2 loss: 247.653 (lr:0.0001)
46640: accuracy:0.18 loss: 249.361 (lr:0.0001)
46660: accuracy:0.21 loss: 255.165 (lr:0.0001)
46680: accuracy:0.21 loss: 262.643 (lr:0.0001)
46700: accuracy:0.18 loss: 258.643 (lr:0.0001)
46720: accuracy:0.23 loss: 251.158 (lr:0.0001)
46740: accuracy:0.17 loss: 283.302 (lr:0.0001)
46760: accuracy:0.29 loss: 247.553 (lr:0.0001)
46780: accuracy:0.21 loss: 249.397 (lr:0.0001)
46800: accuracy:0.25 loss: 246.915 (lr:0.0001)
46820: accuracy:0.16 loss: 258.878 (lr:0.0001)
46840: accuracy:0.25 loss: 242.888 (lr:0.0001)
46860: accuracy:0.22 loss: 259.247 (lr:0.0001)
46880: accuracy:0.23 loss: 263.6 (lr:0.0001)
46900: accuracy:0.24 loss: 253.349 (lr:0.0001)
46920: accuracy:0.21 loss: 270.927 (lr:0.0001)
46940: accuracy:0.25 loss: 248.659 (lr:0.0001)
46960: accuracy:0.21 loss: 259.942 (lr:0.0001)
46980: accuracy:0.19 loss: 272.385 (lr:0.0001)
47000: accuracy:0.24 loss: 245.166 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
47000: ********* epoch 5 ********* test accuracy for all:0.195378 test loss: 273.972
47000: ********* epoch 5 ********* test accuracy for mode 0:0.008 test loss: 405.468
47000: ********* epoch 5 ********* test accuracy for mode 1:0.0405 test loss: 448.646
47000: ********* epoch 5 ********* test accuracy for mode 2:0.096 test loss: 293.41
47000: ********* epoch 5 ********* test accuracy for mode 24:0.2675 test loss: 270.284
47000: ********* epoch 5 ********* test accuracy for mode 25:0.199 test loss: 266.344
47000: ********* epoch 5 ********* test accuracy for mode 26:0.3695 test loss: 199.674
47000: ********* epoch 5 ********* test accuracy for mode 27:0.1765 test loss: 282.364
47000: ********* epoch 5 ********* test accuracy for mode 28:0.245 test loss: 263.394
47000: ********* epoch 5 ********* test accuracy for mode 29:0.275 test loss: 268.424
47000: ********* epoch 5 ********* test accuracy for mode 30:0.1315 test loss: 271.442
47000: ********* epoch 5 ********* test accuracy for mode 31:0.1915 test loss: 271.102
47000: ********* epoch 5 ********* test accuracy for mode 32:0.228 test loss: 261.227
47000: ********* epoch 5 ********* test accuracy for mode 33:0.0785 test loss: 269.701
47000: ********* epoch 5 ********* test accuracy for mode 34:0.042 test loss: 270.033
47000: ********* epoch 5 ********* test accuracy for mode 35:0.0235 test loss: 430.209
47000: ********* epoch 5 ********* test accuracy for mode 36:0.0615 test loss: 475.062
47020: accuracy:0.18 loss: 268.217 (lr:0.0001)
47040: accuracy:0.32 loss: 236.149 (lr:0.0001)
47060: accuracy:0.26 loss: 236.78 (lr:0.0001)
47080: accuracy:0.26 loss: 266.84 (lr:0.0001)
47100: accuracy:0.27 loss: 237.745 (lr:0.0001)
47120: accuracy:0.21 loss: 265.222 (lr:0.0001)
47140: accuracy:0.23 loss: 268.4 (lr:0.0001)
47160: accuracy:0.22 loss: 245.243 (lr:0.0001)
47180: accuracy:0.22 loss: 269.517 (lr:0.0001)
47200: accuracy:0.2 loss: 250.152 (lr:0.0001)
47220: accuracy:0.27 loss: 266.465 (lr:0.0001)
47240: accuracy:0.26 loss: 250.311 (lr:0.0001)
47260: accuracy:0.21 loss: 241.054 (lr:0.0001)
47280: accuracy:0.16 loss: 263.883 (lr:0.0001)
47300: accuracy:0.19 loss: 256.814 (lr:0.0001)
47320: accuracy:0.2 loss: 255.162 (lr:0.0001)
47340: accuracy:0.21 loss: 254.581 (lr:0.0001)
47360: accuracy:0.21 loss: 246.038 (lr:0.0001)
47380: accuracy:0.21 loss: 254.079 (lr:0.0001)
47400: accuracy:0.24 loss: 256.5 (lr:0.0001)
47420: accuracy:0.19 loss: 268.893 (lr:0.0001)
47440: accuracy:0.28 loss: 250.236 (lr:0.0001)
47460: accuracy:0.19 loss: 259.789 (lr:0.0001)
47480: accuracy:0.15 loss: 260.902 (lr:0.0001)
47500: accuracy:0.17 loss: 252.693 (lr:0.0001)
47520: accuracy:0.23 loss: 237.353 (lr:0.0001)
47540: accuracy:0.28 loss: 240.841 (lr:0.0001)
47560: accuracy:0.18 loss: 252.623 (lr:0.0001)
47580: accuracy:0.25 loss: 245.708 (lr:0.0001)
47600: accuracy:0.21 loss: 259.964 (lr:0.0001)
47620: accuracy:0.25 loss: 245.434 (lr:0.0001)
47640: accuracy:0.23 loss: 261.567 (lr:0.0001)
47660: accuracy:0.25 loss: 253.139 (lr:0.0001)
47680: accuracy:0.2 loss: 256.065 (lr:0.0001)
47700: accuracy:0.27 loss: 259.317 (lr:0.0001)
47720: accuracy:0.2 loss: 263.746 (lr:0.0001)
47740: accuracy:0.29 loss: 247.483 (lr:0.0001)
47760: accuracy:0.19 loss: 258.08 (lr:0.0001)
47780: accuracy:0.26 loss: 250.691 (lr:0.0001)
47800: accuracy:0.26 loss: 258.468 (lr:0.0001)
47820: accuracy:0.27 loss: 255.494 (lr:0.0001)
47840: accuracy:0.18 loss: 249.061 (lr:0.0001)
47860: accuracy:0.23 loss: 239.275 (lr:0.0001)
47880: accuracy:0.14 loss: 253.063 (lr:0.0001)
47900: accuracy:0.28 loss: 257.158 (lr:0.0001)
47920: accuracy:0.27 loss: 263.901 (lr:0.0001)
47940: accuracy:0.23 loss: 255.514 (lr:0.0001)
47960: accuracy:0.25 loss: 246.399 (lr:0.0001)
47980: accuracy:0.18 loss: 256.367 (lr:0.0001)
48000: accuracy:0.26 loss: 242.887 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
48000: ********* epoch 5 ********* test accuracy for all:0.196378 test loss: 273.774
48000: ********* epoch 5 ********* test accuracy for mode 0:0.0095 test loss: 405.773
48000: ********* epoch 5 ********* test accuracy for mode 1:0.0385 test loss: 451.158
48000: ********* epoch 5 ********* test accuracy for mode 2:0.096 test loss: 288.299
48000: ********* epoch 5 ********* test accuracy for mode 24:0.2515 test loss: 268.685
48000: ********* epoch 5 ********* test accuracy for mode 25:0.207 test loss: 260.517
48000: ********* epoch 5 ********* test accuracy for mode 26:0.3575 test loss: 198.377
48000: ********* epoch 5 ********* test accuracy for mode 27:0.1675 test loss: 281.549
48000: ********* epoch 5 ********* test accuracy for mode 28:0.251 test loss: 262.515
48000: ********* epoch 5 ********* test accuracy for mode 29:0.2555 test loss: 267.568
48000: ********* epoch 5 ********* test accuracy for mode 30:0.156 test loss: 266.253
48000: ********* epoch 5 ********* test accuracy for mode 31:0.205 test loss: 265.867
48000: ********* epoch 5 ********* test accuracy for mode 32:0.231 test loss: 256.801
48000: ********* epoch 5 ********* test accuracy for mode 33:0.0765 test loss: 266.208
48000: ********* epoch 5 ********* test accuracy for mode 34:0.023 test loss: 268.653
48000: ********* epoch 5 ********* test accuracy for mode 35:0.017 test loss: 438.723
48000: ********* epoch 5 ********* test accuracy for mode 36:0.0535 test loss: 489.401
48020: accuracy:0.26 loss: 253.598 (lr:0.0001)
48040: accuracy:0.21 loss: 245.712 (lr:0.0001)
48060: accuracy:0.19 loss: 257.197 (lr:0.0001)
48080: accuracy:0.37 loss: 226.801 (lr:0.0001)
48100: accuracy:0.19 loss: 261.364 (lr:0.0001)
48120: accuracy:0.28 loss: 242.131 (lr:0.0001)
48140: accuracy:0.2 loss: 234.857 (lr:0.0001)
48160: accuracy:0.24 loss: 245.28 (lr:0.0001)
48180: accuracy:0.22 loss: 244.951 (lr:0.0001)
48200: accuracy:0.32 loss: 233.54 (lr:0.0001)
48220: accuracy:0.16 loss: 269.682 (lr:0.0001)
48240: accuracy:0.2 loss: 271.751 (lr:0.0001)
48260: accuracy:0.23 loss: 266.4 (lr:0.0001)
48280: accuracy:0.23 loss: 257.932 (lr:0.0001)
48300: accuracy:0.19 loss: 253.146 (lr:0.0001)
48320: accuracy:0.19 loss: 260.867 (lr:0.0001)
48340: accuracy:0.23 loss: 242.963 (lr:0.0001)
48360: accuracy:0.22 loss: 262.669 (lr:0.0001)
48380: accuracy:0.2 loss: 247.437 (lr:0.0001)
48400: accuracy:0.22 loss: 250.348 (lr:0.0001)
48420: accuracy:0.19 loss: 250.913 (lr:0.0001)
48440: accuracy:0.19 loss: 248.159 (lr:0.0001)
48460: accuracy:0.25 loss: 253.645 (lr:0.0001)
48480: accuracy:0.24 loss: 255.705 (lr:0.0001)
48500: accuracy:0.25 loss: 251.855 (lr:0.0001)
48520: accuracy:0.2 loss: 260.889 (lr:0.0001)
48540: accuracy:0.23 loss: 243.236 (lr:0.0001)
48560: accuracy:0.22 loss: 229.594 (lr:0.0001)
48580: accuracy:0.16 loss: 268.052 (lr:0.0001)
48600: accuracy:0.25 loss: 254.616 (lr:0.0001)
48620: accuracy:0.26 loss: 249.422 (lr:0.0001)
48640: accuracy:0.22 loss: 254.922 (lr:0.0001)
48660: accuracy:0.23 loss: 261.005 (lr:0.0001)
48680: accuracy:0.19 loss: 252.935 (lr:0.0001)
48700: accuracy:0.19 loss: 252.597 (lr:0.0001)
48720: accuracy:0.23 loss: 253.852 (lr:0.0001)
48740: accuracy:0.24 loss: 245.499 (lr:0.0001)
48760: accuracy:0.21 loss: 266.071 (lr:0.0001)
48780: accuracy:0.21 loss: 272.638 (lr:0.0001)
48800: accuracy:0.26 loss: 247.383 (lr:0.0001)
48820: accuracy:0.26 loss: 260.938 (lr:0.0001)
48840: accuracy:0.24 loss: 259.87 (lr:0.0001)
48860: accuracy:0.25 loss: 244.074 (lr:0.0001)
48880: accuracy:0.28 loss: 253.794 (lr:0.0001)
48900: accuracy:0.22 loss: 254.744 (lr:0.0001)
48920: accuracy:0.2 loss: 243.813 (lr:0.0001)
48940: accuracy:0.25 loss: 242.246 (lr:0.0001)
48960: accuracy:0.33 loss: 236.579 (lr:0.0001)
48980: accuracy:0.24 loss: 247.638 (lr:0.0001)
49000: accuracy:0.24 loss: 245.924 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
49000: ********* epoch 6 ********* test accuracy for all:0.196622 test loss: 273.676
49000: ********* epoch 6 ********* test accuracy for mode 0:0.0115 test loss: 397.467
49000: ********* epoch 6 ********* test accuracy for mode 1:0.054 test loss: 436.409
49000: ********* epoch 6 ********* test accuracy for mode 2:0.061 test loss: 297.471
49000: ********* epoch 6 ********* test accuracy for mode 24:0.26 test loss: 269.839
49000: ********* epoch 6 ********* test accuracy for mode 25:0.216 test loss: 261.918
49000: ********* epoch 6 ********* test accuracy for mode 26:0.383 test loss: 197.277
49000: ********* epoch 6 ********* test accuracy for mode 27:0.1795 test loss: 284.344
49000: ********* epoch 6 ********* test accuracy for mode 28:0.247 test loss: 269.136
49000: ********* epoch 6 ********* test accuracy for mode 29:0.2535 test loss: 277.938
49000: ********* epoch 6 ********* test accuracy for mode 30:0.1575 test loss: 276.421
49000: ********* epoch 6 ********* test accuracy for mode 31:0.1525 test loss: 278.505
49000: ********* epoch 6 ********* test accuracy for mode 32:0.245 test loss: 265.358
49000: ********* epoch 6 ********* test accuracy for mode 33:0.0715 test loss: 273.611
49000: ********* epoch 6 ********* test accuracy for mode 34:0.045 test loss: 271.986
49000: ********* epoch 6 ********* test accuracy for mode 35:0.033 test loss: 427.961
49000: ********* epoch 6 ********* test accuracy for mode 36:0.039 test loss: 481.514
49020: accuracy:0.2 loss: 263.555 (lr:0.0001)
49040: accuracy:0.27 loss: 248.127 (lr:0.0001)
49060: accuracy:0.23 loss: 242.972 (lr:0.0001)
49080: accuracy:0.2 loss: 251.924 (lr:0.0001)
49100: accuracy:0.28 loss: 265.049 (lr:0.0001)
49120: accuracy:0.21 loss: 257.979 (lr:0.0001)
49140: accuracy:0.29 loss: 244.242 (lr:0.0001)
49160: accuracy:0.29 loss: 244.118 (lr:0.0001)
49180: accuracy:0.15 loss: 250.662 (lr:0.0001)
49200: accuracy:0.18 loss: 250.699 (lr:0.0001)
49220: accuracy:0.15 loss: 274.693 (lr:0.0001)
49240: accuracy:0.21 loss: 255.856 (lr:0.0001)
49260: accuracy:0.21 loss: 274.99 (lr:0.0001)
49280: accuracy:0.19 loss: 263.777 (lr:0.0001)
49300: accuracy:0.28 loss: 251.354 (lr:0.0001)
49320: accuracy:0.24 loss: 244.219 (lr:0.0001)
49340: accuracy:0.21 loss: 240.509 (lr:0.0001)
49360: accuracy:0.28 loss: 238.361 (lr:0.0001)
49380: accuracy:0.22 loss: 262.104 (lr:0.0001)
49400: accuracy:0.21 loss: 267.432 (lr:0.0001)
49420: accuracy:0.26 loss: 241.982 (lr:0.0001)
49440: accuracy:0.23 loss: 260.486 (lr:0.0001)
49460: accuracy:0.21 loss: 272.19 (lr:0.0001)
49480: accuracy:0.19 loss: 261.47 (lr:0.0001)
49500: accuracy:0.22 loss: 272.408 (lr:0.0001)
49520: accuracy:0.31 loss: 251.033 (lr:0.0001)
49540: accuracy:0.26 loss: 242.137 (lr:0.0001)
49560: accuracy:0.17 loss: 259.898 (lr:0.0001)
49580: accuracy:0.28 loss: 246.271 (lr:0.0001)
49600: accuracy:0.23 loss: 263.062 (lr:0.0001)
49620: accuracy:0.28 loss: 246.808 (lr:0.0001)
49640: accuracy:0.26 loss: 240.516 (lr:0.0001)
49660: accuracy:0.17 loss: 273.947 (lr:0.0001)
49680: accuracy:0.17 loss: 269.094 (lr:0.0001)
49700: accuracy:0.18 loss: 237.629 (lr:0.0001)
49720: accuracy:0.21 loss: 247.882 (lr:0.0001)
49740: accuracy:0.29 loss: 252.914 (lr:0.0001)
49760: accuracy:0.24 loss: 261.342 (lr:0.0001)
49780: accuracy:0.26 loss: 254.143 (lr:0.0001)
49800: accuracy:0.32 loss: 222.243 (lr:0.0001)
49820: accuracy:0.2 loss: 265.316 (lr:0.0001)
49840: accuracy:0.2 loss: 262.226 (lr:0.0001)
49860: accuracy:0.24 loss: 249.496 (lr:0.0001)
49880: accuracy:0.26 loss: 249.605 (lr:0.0001)
49900: accuracy:0.22 loss: 244.724 (lr:0.0001)
49920: accuracy:0.18 loss: 267.114 (lr:0.0001)
49940: accuracy:0.25 loss: 257.984 (lr:0.0001)
49960: accuracy:0.19 loss: 256.265 (lr:0.0001)
49980: accuracy:0.2 loss: 263.588 (lr:0.0001)
50000: accuracy:0.22 loss: 250.344 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
50000: ********* epoch 6 ********* test accuracy for all:0.192392 test loss: 277.416
50000: ********* epoch 6 ********* test accuracy for mode 0:0.011 test loss: 410.358
50000: ********* epoch 6 ********* test accuracy for mode 1:0.0265 test loss: 462.267
50000: ********* epoch 6 ********* test accuracy for mode 2:0.0685 test loss: 288.512
50000: ********* epoch 6 ********* test accuracy for mode 24:0.213 test loss: 287.084
50000: ********* epoch 6 ********* test accuracy for mode 25:0.227 test loss: 273.848
50000: ********* epoch 6 ********* test accuracy for mode 26:0.329 test loss: 207.111
50000: ********* epoch 6 ********* test accuracy for mode 27:0.181 test loss: 292.004
50000: ********* epoch 6 ********* test accuracy for mode 28:0.245 test loss: 277.368
50000: ********* epoch 6 ********* test accuracy for mode 29:0.2345 test loss: 283.641
50000: ********* epoch 6 ********* test accuracy for mode 30:0.17 test loss: 275.335
50000: ********* epoch 6 ********* test accuracy for mode 31:0.1325 test loss: 275.736
50000: ********* epoch 6 ********* test accuracy for mode 32:0.2795 test loss: 255.656
50000: ********* epoch 6 ********* test accuracy for mode 33:0.077 test loss: 262.847
50000: ********* epoch 6 ********* test accuracy for mode 34:0.0175 test loss: 268.338
50000: ********* epoch 6 ********* test accuracy for mode 35:0.016 test loss: 445.832
50000: ********* epoch 6 ********* test accuracy for mode 36:0.026 test loss: 501.97
50020: accuracy:0.18 loss: 275.207 (lr:0.0001)
50040: accuracy:0.11 loss: 272.897 (lr:0.0001)
50060: accuracy:0.19 loss: 236.258 (lr:0.0001)
50080: accuracy:0.23 loss: 252.952 (lr:0.0001)
50100: accuracy:0.25 loss: 230.003 (lr:0.0001)
50120: accuracy:0.26 loss: 250.313 (lr:0.0001)
50140: accuracy:0.25 loss: 271.59 (lr:0.0001)
50160: accuracy:0.27 loss: 252.289 (lr:0.0001)
50180: accuracy:0.22 loss: 255.983 (lr:0.0001)
50200: accuracy:0.23 loss: 268.055 (lr:0.0001)
50220: accuracy:0.27 loss: 239.503 (lr:0.0001)
50240: accuracy:0.11 loss: 275.425 (lr:0.0001)
50260: accuracy:0.18 loss: 272.776 (lr:0.0001)
50280: accuracy:0.25 loss: 238.36 (lr:0.0001)
50300: accuracy:0.24 loss: 245.025 (lr:0.0001)
50320: accuracy:0.27 loss: 264.188 (lr:0.0001)
50340: accuracy:0.24 loss: 245.78 (lr:0.0001)
50360: accuracy:0.23 loss: 232.766 (lr:0.0001)
50380: accuracy:0.2 loss: 254.359 (lr:0.0001)
50400: accuracy:0.21 loss: 252.949 (lr:0.0001)
50420: accuracy:0.25 loss: 242.271 (lr:0.0001)
50440: accuracy:0.22 loss: 237.953 (lr:0.0001)
50460: accuracy:0.2 loss: 266.867 (lr:0.0001)
50480: accuracy:0.2 loss: 262.43 (lr:0.0001)
50500: accuracy:0.31 loss: 247.853 (lr:0.0001)
50520: accuracy:0.28 loss: 246.767 (lr:0.0001)
50540: accuracy:0.24 loss: 233.56 (lr:0.0001)
50560: accuracy:0.24 loss: 250.74 (lr:0.0001)
50580: accuracy:0.2 loss: 255.449 (lr:0.0001)
50600: accuracy:0.2 loss: 255.348 (lr:0.0001)
50620: accuracy:0.26 loss: 240.335 (lr:0.0001)
50640: accuracy:0.2 loss: 240.388 (lr:0.0001)
50660: accuracy:0.25 loss: 256.518 (lr:0.0001)
50680: accuracy:0.28 loss: 242.346 (lr:0.0001)
50700: accuracy:0.31 loss: 242.493 (lr:0.0001)
50720: accuracy:0.23 loss: 280.981 (lr:0.0001)
50740: accuracy:0.26 loss: 255.204 (lr:0.0001)
50760: accuracy:0.21 loss: 257.084 (lr:0.0001)
50780: accuracy:0.23 loss: 253.205 (lr:0.0001)
50800: accuracy:0.25 loss: 247.576 (lr:0.0001)
50820: accuracy:0.23 loss: 246.298 (lr:0.0001)
50840: accuracy:0.19 loss: 253.933 (lr:0.0001)
50860: accuracy:0.17 loss: 281.254 (lr:0.0001)
50880: accuracy:0.23 loss: 247.377 (lr:0.0001)
50900: accuracy:0.21 loss: 263.18 (lr:0.0001)
50920: accuracy:0.26 loss: 243.091 (lr:0.0001)
50940: accuracy:0.18 loss: 259.948 (lr:0.0001)
50960: accuracy:0.22 loss: 261.023 (lr:0.0001)
50980: accuracy:0.2 loss: 265.374 (lr:0.0001)
51000: accuracy:0.27 loss: 247.992 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
51000: ********* epoch 6 ********* test accuracy for all:0.196568 test loss: 272.842
51000: ********* epoch 6 ********* test accuracy for mode 0:0.012 test loss: 406.428
51000: ********* epoch 6 ********* test accuracy for mode 1:0.0385 test loss: 445.691
51000: ********* epoch 6 ********* test accuracy for mode 2:0.0835 test loss: 289.788
51000: ********* epoch 6 ********* test accuracy for mode 24:0.2465 test loss: 270.279
51000: ********* epoch 6 ********* test accuracy for mode 25:0.2815 test loss: 255.851
51000: ********* epoch 6 ********* test accuracy for mode 26:0.269 test loss: 199.598
51000: ********* epoch 6 ********* test accuracy for mode 27:0.19 test loss: 277.143
51000: ********* epoch 6 ********* test accuracy for mode 28:0.2775 test loss: 258.263
51000: ********* epoch 6 ********* test accuracy for mode 29:0.244 test loss: 268.641
51000: ********* epoch 6 ********* test accuracy for mode 30:0.1505 test loss: 267.303
51000: ********* epoch 6 ********* test accuracy for mode 31:0.188 test loss: 268.677
51000: ********* epoch 6 ********* test accuracy for mode 32:0.195 test loss: 259.775
51000: ********* epoch 6 ********* test accuracy for mode 33:0.122 test loss: 262.85
51000: ********* epoch 6 ********* test accuracy for mode 34:0.033 test loss: 268.041
51000: ********* epoch 6 ********* test accuracy for mode 35:0.035 test loss: 429.262
51000: ********* epoch 6 ********* test accuracy for mode 36:0.0685 test loss: 473.678
51020: accuracy:0.24 loss: 263.296 (lr:0.0001)
51040: accuracy:0.27 loss: 240.019 (lr:0.0001)
51060: accuracy:0.21 loss: 257.999 (lr:0.0001)
51080: accuracy:0.23 loss: 251.861 (lr:0.0001)
51100: accuracy:0.17 loss: 261.852 (lr:0.0001)
51120: accuracy:0.26 loss: 224.069 (lr:0.0001)
51140: accuracy:0.27 loss: 271.517 (lr:0.0001)
51160: accuracy:0.3 loss: 257.329 (lr:0.0001)
51180: accuracy:0.24 loss: 250.246 (lr:0.0001)
51200: accuracy:0.24 loss: 265.832 (lr:0.0001)
51220: accuracy:0.2 loss: 257.782 (lr:0.0001)
51240: accuracy:0.18 loss: 256.123 (lr:0.0001)
51260: accuracy:0.24 loss: 254.996 (lr:0.0001)
51280: accuracy:0.19 loss: 239.739 (lr:0.0001)
51300: accuracy:0.27 loss: 240.89 (lr:0.0001)
51320: accuracy:0.23 loss: 225.182 (lr:0.0001)
51340: accuracy:0.18 loss: 250.875 (lr:0.0001)
51360: accuracy:0.19 loss: 257.974 (lr:0.0001)
51380: accuracy:0.22 loss: 260.946 (lr:0.0001)
51400: accuracy:0.22 loss: 259.603 (lr:0.0001)
51420: accuracy:0.28 loss: 244.206 (lr:0.0001)
51440: accuracy:0.18 loss: 260.776 (lr:0.0001)
51460: accuracy:0.26 loss: 241.553 (lr:0.0001)
51480: accuracy:0.15 loss: 253.425 (lr:0.0001)
51500: accuracy:0.27 loss: 240.664 (lr:0.0001)
51520: accuracy:0.14 loss: 247.861 (lr:0.0001)
51540: accuracy:0.22 loss: 247.146 (lr:0.0001)
51560: accuracy:0.3 loss: 233.03 (lr:0.0001)
51580: accuracy:0.25 loss: 271.168 (lr:0.0001)
51600: accuracy:0.26 loss: 238.38 (lr:0.0001)
51620: accuracy:0.18 loss: 245.006 (lr:0.0001)
51640: accuracy:0.22 loss: 251.394 (lr:0.0001)
51660: accuracy:0.27 loss: 244.421 (lr:0.0001)
51680: accuracy:0.16 loss: 264.273 (lr:0.0001)
51700: accuracy:0.32 loss: 236.477 (lr:0.0001)
51720: accuracy:0.24 loss: 251.917 (lr:0.0001)
51740: accuracy:0.21 loss: 256.01 (lr:0.0001)
51760: accuracy:0.18 loss: 261.719 (lr:0.0001)
51780: accuracy:0.18 loss: 240.684 (lr:0.0001)
51800: accuracy:0.18 loss: 248.127 (lr:0.0001)
51820: accuracy:0.23 loss: 260.482 (lr:0.0001)
51840: accuracy:0.23 loss: 234.271 (lr:0.0001)
51860: accuracy:0.21 loss: 268.618 (lr:0.0001)
51880: accuracy:0.26 loss: 240.133 (lr:0.0001)
51900: accuracy:0.21 loss: 237.202 (lr:0.0001)
51920: accuracy:0.24 loss: 261.995 (lr:0.0001)
51940: accuracy:0.3 loss: 251.15 (lr:0.0001)
51960: accuracy:0.25 loss: 241.903 (lr:0.0001)
51980: accuracy:0.27 loss: 242.111 (lr:0.0001)
52000: accuracy:0.27 loss: 257.037 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
52000: ********* epoch 6 ********* test accuracy for all:0.197946 test loss: 273.033
52000: ********* epoch 6 ********* test accuracy for mode 0:0.013 test loss: 407.843
52000: ********* epoch 6 ********* test accuracy for mode 1:0.038 test loss: 449.022
52000: ********* epoch 6 ********* test accuracy for mode 2:0.092 test loss: 289.284
52000: ********* epoch 6 ********* test accuracy for mode 24:0.2335 test loss: 276.401
52000: ********* epoch 6 ********* test accuracy for mode 25:0.2655 test loss: 259.883
52000: ********* epoch 6 ********* test accuracy for mode 26:0.3515 test loss: 194.843
52000: ********* epoch 6 ********* test accuracy for mode 27:0.1855 test loss: 281.486
52000: ********* epoch 6 ********* test accuracy for mode 28:0.2525 test loss: 262.728
52000: ********* epoch 6 ********* test accuracy for mode 29:0.2635 test loss: 268.234
52000: ********* epoch 6 ********* test accuracy for mode 30:0.176 test loss: 265.224
52000: ********* epoch 6 ********* test accuracy for mode 31:0.174 test loss: 268.843
52000: ********* epoch 6 ********* test accuracy for mode 32:0.2315 test loss: 258.734
52000: ********* epoch 6 ********* test accuracy for mode 33:0.0885 test loss: 264.803
52000: ********* epoch 6 ********* test accuracy for mode 34:0.0325 test loss: 267.249
52000: ********* epoch 6 ********* test accuracy for mode 35:0.0255 test loss: 437.434
52000: ********* epoch 6 ********* test accuracy for mode 36:0.0445 test loss: 480.5
52020: accuracy:0.26 loss: 252.891 (lr:0.0001)
52040: accuracy:0.31 loss: 242.617 (lr:0.0001)
52060: accuracy:0.24 loss: 239.584 (lr:0.0001)
52080: accuracy:0.2 loss: 247.854 (lr:0.0001)
52100: accuracy:0.15 loss: 264.961 (lr:0.0001)
52120: accuracy:0.21 loss: 263.096 (lr:0.0001)
52140: accuracy:0.16 loss: 259.452 (lr:0.0001)
52160: accuracy:0.18 loss: 270.244 (lr:0.0001)
52180: accuracy:0.2 loss: 250.905 (lr:0.0001)
52200: accuracy:0.33 loss: 230.511 (lr:0.0001)
52220: accuracy:0.19 loss: 249.574 (lr:0.0001)
52240: accuracy:0.2 loss: 268.855 (lr:0.0001)
52260: accuracy:0.17 loss: 271.94 (lr:0.0001)
52280: accuracy:0.23 loss: 249.826 (lr:0.0001)
52300: accuracy:0.14 loss: 261.633 (lr:0.0001)
52320: accuracy:0.22 loss: 257.956 (lr:0.0001)
52340: accuracy:0.24 loss: 238.829 (lr:0.0001)
52360: accuracy:0.27 loss: 235.186 (lr:0.0001)
52380: accuracy:0.21 loss: 245.243 (lr:0.0001)
52400: accuracy:0.24 loss: 239.382 (lr:0.0001)
52420: accuracy:0.21 loss: 262.708 (lr:0.0001)
52440: accuracy:0.25 loss: 241.822 (lr:0.0001)
52460: accuracy:0.22 loss: 253.812 (lr:0.0001)
52480: accuracy:0.27 loss: 235.827 (lr:0.0001)
52500: accuracy:0.23 loss: 250.072 (lr:0.0001)
52520: accuracy:0.21 loss: 261.269 (lr:0.0001)
52540: accuracy:0.17 loss: 256.767 (lr:0.0001)
52560: accuracy:0.23 loss: 261.17 (lr:0.0001)
52580: accuracy:0.18 loss: 262.194 (lr:0.0001)
52600: accuracy:0.26 loss: 240.993 (lr:0.0001)
52620: accuracy:0.27 loss: 243.877 (lr:0.0001)
52640: accuracy:0.26 loss: 238.933 (lr:0.0001)
52660: accuracy:0.32 loss: 224.138 (lr:0.0001)
52680: accuracy:0.22 loss: 251.567 (lr:0.0001)
52700: accuracy:0.24 loss: 246.562 (lr:0.0001)
52720: accuracy:0.22 loss: 243.847 (lr:0.0001)
52740: accuracy:0.21 loss: 265.398 (lr:0.0001)
52760: accuracy:0.2 loss: 240.775 (lr:0.0001)
52780: accuracy:0.22 loss: 242.424 (lr:0.0001)
52800: accuracy:0.2 loss: 244.626 (lr:0.0001)
52820: accuracy:0.21 loss: 249.736 (lr:0.0001)
52840: accuracy:0.27 loss: 261.792 (lr:0.0001)
52860: accuracy:0.2 loss: 289.444 (lr:0.0001)
52880: accuracy:0.26 loss: 250.515 (lr:0.0001)
52900: accuracy:0.2 loss: 254.295 (lr:0.0001)
52920: accuracy:0.26 loss: 263.557 (lr:0.0001)
52940: accuracy:0.18 loss: 263.195 (lr:0.0001)
52960: accuracy:0.24 loss: 245.667 (lr:0.0001)
52980: accuracy:0.16 loss: 272.684 (lr:0.0001)
53000: accuracy:0.26 loss: 251.762 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
53000: ********* epoch 6 ********* test accuracy for all:0.196797 test loss: 274.31
53000: ********* epoch 6 ********* test accuracy for mode 0:0.0125 test loss: 409.225
53000: ********* epoch 6 ********* test accuracy for mode 1:0.0365 test loss: 451.715
53000: ********* epoch 6 ********* test accuracy for mode 2:0.075 test loss: 291.964
53000: ********* epoch 6 ********* test accuracy for mode 24:0.23 test loss: 282.908
53000: ********* epoch 6 ********* test accuracy for mode 25:0.24 test loss: 264.959
53000: ********* epoch 6 ********* test accuracy for mode 26:0.308 test loss: 200.821
53000: ********* epoch 6 ********* test accuracy for mode 27:0.201 test loss: 283.393
53000: ********* epoch 6 ********* test accuracy for mode 28:0.2735 test loss: 261.414
53000: ********* epoch 6 ********* test accuracy for mode 29:0.262 test loss: 268.912
53000: ********* epoch 6 ********* test accuracy for mode 30:0.166 test loss: 265.413
53000: ********* epoch 6 ********* test accuracy for mode 31:0.186 test loss: 266.653
53000: ********* epoch 6 ********* test accuracy for mode 32:0.2295 test loss: 255.977
53000: ********* epoch 6 ********* test accuracy for mode 33:0.0945 test loss: 262.596
53000: ********* epoch 6 ********* test accuracy for mode 34:0.024 test loss: 267.41
53000: ********* epoch 6 ********* test accuracy for mode 35:0.057 test loss: 437.552
53000: ********* epoch 6 ********* test accuracy for mode 36:0.042 test loss: 497.607
53020: accuracy:0.13 loss: 259.967 (lr:0.0001)
53040: accuracy:0.18 loss: 250.749 (lr:0.0001)
53060: accuracy:0.26 loss: 267.344 (lr:0.0001)
53080: accuracy:0.17 loss: 254.89 (lr:0.0001)
53100: accuracy:0.22 loss: 232.503 (lr:0.0001)
53120: accuracy:0.21 loss: 257.948 (lr:0.0001)
53140: accuracy:0.24 loss: 264.013 (lr:0.0001)
53160: accuracy:0.23 loss: 253.461 (lr:0.0001)
53180: accuracy:0.27 loss: 238.014 (lr:0.0001)
53200: accuracy:0.26 loss: 238.415 (lr:0.0001)
53220: accuracy:0.24 loss: 254.544 (lr:0.0001)
53240: accuracy:0.23 loss: 244.41 (lr:0.0001)
53260: accuracy:0.3 loss: 233.012 (lr:0.0001)
53280: accuracy:0.23 loss: 253.492 (lr:0.0001)
53300: accuracy:0.21 loss: 263.623 (lr:0.0001)
53320: accuracy:0.23 loss: 254.705 (lr:0.0001)
53340: accuracy:0.2 loss: 252.625 (lr:0.0001)
53360: accuracy:0.18 loss: 233.385 (lr:0.0001)
53380: accuracy:0.26 loss: 245.886 (lr:0.0001)
53400: accuracy:0.26 loss: 260.633 (lr:0.0001)
53420: accuracy:0.19 loss: 252.935 (lr:0.0001)
53440: accuracy:0.19 loss: 278.205 (lr:0.0001)
53460: accuracy:0.22 loss: 250.874 (lr:0.0001)
53480: accuracy:0.22 loss: 271.319 (lr:0.0001)
53500: accuracy:0.22 loss: 232.288 (lr:0.0001)
53520: accuracy:0.24 loss: 243.342 (lr:0.0001)
53540: accuracy:0.17 loss: 280.658 (lr:0.0001)
53560: accuracy:0.24 loss: 253.242 (lr:0.0001)
53580: accuracy:0.22 loss: 263.04 (lr:0.0001)
53600: accuracy:0.16 loss: 249.728 (lr:0.0001)
53620: accuracy:0.25 loss: 234.413 (lr:0.0001)
53640: accuracy:0.19 loss: 232.169 (lr:0.0001)
53660: accuracy:0.19 loss: 240.27 (lr:0.0001)
53680: accuracy:0.2 loss: 257.239 (lr:0.0001)
53700: accuracy:0.25 loss: 245.759 (lr:0.0001)
53720: accuracy:0.2 loss: 267.981 (lr:0.0001)
53740: accuracy:0.27 loss: 241.117 (lr:0.0001)
53760: accuracy:0.18 loss: 254.134 (lr:0.0001)
53780: accuracy:0.26 loss: 238.494 (lr:0.0001)
53800: accuracy:0.27 loss: 252.433 (lr:0.0001)
53820: accuracy:0.18 loss: 252.466 (lr:0.0001)
53840: accuracy:0.14 loss: 266.601 (lr:0.0001)
53860: accuracy:0.25 loss: 236.106 (lr:0.0001)
53880: accuracy:0.19 loss: 259.122 (lr:0.0001)
53900: accuracy:0.24 loss: 256.658 (lr:0.0001)
53920: accuracy:0.22 loss: 242.873 (lr:0.0001)
53940: accuracy:0.29 loss: 249.637 (lr:0.0001)
53960: accuracy:0.14 loss: 263.521 (lr:0.0001)
53980: accuracy:0.23 loss: 269.237 (lr:0.0001)
54000: accuracy:0.25 loss: 267.793 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
54000: ********* epoch 6 ********* test accuracy for all:0.198 test loss: 271.88
54000: ********* epoch 6 ********* test accuracy for mode 0:0.0185 test loss: 401.578
54000: ********* epoch 6 ********* test accuracy for mode 1:0.0355 test loss: 441.678
54000: ********* epoch 6 ********* test accuracy for mode 2:0.069 test loss: 292.623
54000: ********* epoch 6 ********* test accuracy for mode 24:0.2485 test loss: 269.936
54000: ********* epoch 6 ********* test accuracy for mode 25:0.291 test loss: 253.904
54000: ********* epoch 6 ********* test accuracy for mode 26:0.2805 test loss: 197.131
54000: ********* epoch 6 ********* test accuracy for mode 27:0.1775 test loss: 276.475
54000: ********* epoch 6 ********* test accuracy for mode 28:0.244 test loss: 255.162
54000: ********* epoch 6 ********* test accuracy for mode 29:0.289 test loss: 258.151
54000: ********* epoch 6 ********* test accuracy for mode 30:0.148 test loss: 262.461
54000: ********* epoch 6 ********* test accuracy for mode 31:0.1835 test loss: 265.453
54000: ********* epoch 6 ********* test accuracy for mode 32:0.21 test loss: 257.552
54000: ********* epoch 6 ********* test accuracy for mode 33:0.105 test loss: 265.168
54000: ********* epoch 6 ********* test accuracy for mode 34:0.03 test loss: 269.195
54000: ********* epoch 6 ********* test accuracy for mode 35:0.0815 test loss: 419.391
54000: ********* epoch 6 ********* test accuracy for mode 36:0.1225 test loss: 454.791
54020: accuracy:0.24 loss: 256.14 (lr:0.0001)
54040: accuracy:0.27 loss: 249.731 (lr:0.0001)
54060: accuracy:0.19 loss: 259.91 (lr:0.0001)
54080: accuracy:0.16 loss: 268.005 (lr:0.0001)
54100: accuracy:0.3 loss: 242.887 (lr:0.0001)
54120: accuracy:0.15 loss: 256.282 (lr:0.0001)
54140: accuracy:0.25 loss: 244.863 (lr:0.0001)
54160: accuracy:0.19 loss: 268.438 (lr:0.0001)
54180: accuracy:0.21 loss: 257.028 (lr:0.0001)
54200: accuracy:0.22 loss: 234.712 (lr:0.0001)
54220: accuracy:0.22 loss: 246.535 (lr:0.0001)
54240: accuracy:0.19 loss: 249.505 (lr:0.0001)
54260: accuracy:0.26 loss: 232.397 (lr:0.0001)
54280: accuracy:0.21 loss: 254.811 (lr:0.0001)
54300: accuracy:0.16 loss: 247.173 (lr:0.0001)
54320: accuracy:0.18 loss: 265.807 (lr:0.0001)
54340: accuracy:0.18 loss: 250.836 (lr:0.0001)
54360: accuracy:0.2 loss: 274.275 (lr:0.0001)
54380: accuracy:0.16 loss: 265.918 (lr:0.0001)
54400: accuracy:0.21 loss: 263.924 (lr:0.0001)
54420: accuracy:0.22 loss: 240.662 (lr:0.0001)
54440: accuracy:0.26 loss: 239.923 (lr:0.0001)
54460: accuracy:0.28 loss: 245.211 (lr:0.0001)
54480: accuracy:0.25 loss: 249.795 (lr:0.0001)
54500: accuracy:0.2 loss: 254.254 (lr:0.0001)
54520: accuracy:0.26 loss: 260.534 (lr:0.0001)
54540: accuracy:0.21 loss: 260.771 (lr:0.0001)
54560: accuracy:0.26 loss: 256.774 (lr:0.0001)
54580: accuracy:0.23 loss: 236.582 (lr:0.0001)
54600: accuracy:0.22 loss: 268.92 (lr:0.0001)
54620: accuracy:0.2 loss: 254.407 (lr:0.0001)
54640: accuracy:0.18 loss: 264.45 (lr:0.0001)
54660: accuracy:0.22 loss: 254.793 (lr:0.0001)
54680: accuracy:0.23 loss: 248.657 (lr:0.0001)
54700: accuracy:0.19 loss: 282.292 (lr:0.0001)
54720: accuracy:0.21 loss: 266.154 (lr:0.0001)
54740: accuracy:0.22 loss: 267.161 (lr:0.0001)
54760: accuracy:0.18 loss: 248.916 (lr:0.0001)
54780: accuracy:0.2 loss: 240.045 (lr:0.0001)
54800: accuracy:0.26 loss: 248.68 (lr:0.0001)
54820: accuracy:0.16 loss: 276.151 (lr:0.0001)
54840: accuracy:0.27 loss: 249.238 (lr:0.0001)
54860: accuracy:0.23 loss: 238.322 (lr:0.0001)
54880: accuracy:0.26 loss: 244.755 (lr:0.0001)
54900: accuracy:0.21 loss: 251.631 (lr:0.0001)
54920: accuracy:0.23 loss: 253.245 (lr:0.0001)
54940: accuracy:0.26 loss: 263.543 (lr:0.0001)
54960: accuracy:0.19 loss: 260.622 (lr:0.0001)
54980: accuracy:0.22 loss: 258.497 (lr:0.0001)
55000: accuracy:0.2 loss: 246.678 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
55000: ********* epoch 6 ********* test accuracy for all:0.198541 test loss: 273.158
55000: ********* epoch 6 ********* test accuracy for mode 0:0.0185 test loss: 406.123
55000: ********* epoch 6 ********* test accuracy for mode 1:0.0375 test loss: 449.821
55000: ********* epoch 6 ********* test accuracy for mode 2:0.0575 test loss: 288.458
55000: ********* epoch 6 ********* test accuracy for mode 24:0.2365 test loss: 281.789
55000: ********* epoch 6 ********* test accuracy for mode 25:0.2465 test loss: 268.205
55000: ********* epoch 6 ********* test accuracy for mode 26:0.3625 test loss: 197.042
55000: ********* epoch 6 ********* test accuracy for mode 27:0.207 test loss: 281.897
55000: ********* epoch 6 ********* test accuracy for mode 28:0.257 test loss: 265.674
55000: ********* epoch 6 ********* test accuracy for mode 29:0.2595 test loss: 273.419
55000: ********* epoch 6 ********* test accuracy for mode 30:0.1635 test loss: 270.511
55000: ********* epoch 6 ********* test accuracy for mode 31:0.1455 test loss: 275.052
55000: ********* epoch 6 ********* test accuracy for mode 32:0.223 test loss: 261.952
55000: ********* epoch 6 ********* test accuracy for mode 33:0.1225 test loss: 265.018
55000: ********* epoch 6 ********* test accuracy for mode 34:0.0175 test loss: 271.839
55000: ********* epoch 6 ********* test accuracy for mode 35:0.059 test loss: 428.359
55000: ********* epoch 6 ********* test accuracy for mode 36:0.0515 test loss: 473.733
55020: accuracy:0.21 loss: 260.273 (lr:0.0001)
55040: accuracy:0.18 loss: 266.025 (lr:0.0001)
55060: accuracy:0.22 loss: 249.354 (lr:0.0001)
55080: accuracy:0.22 loss: 246.832 (lr:0.0001)
55100: accuracy:0.31 loss: 251.232 (lr:0.0001)
55120: accuracy:0.24 loss: 240.643 (lr:0.0001)
55140: accuracy:0.26 loss: 255.488 (lr:0.0001)
55160: accuracy:0.27 loss: 243.042 (lr:0.0001)
55180: accuracy:0.28 loss: 243.897 (lr:0.0001)
55200: accuracy:0.2 loss: 251.161 (lr:0.0001)
55220: accuracy:0.21 loss: 243.903 (lr:0.0001)
55240: accuracy:0.23 loss: 236.819 (lr:0.0001)
55260: accuracy:0.24 loss: 263.181 (lr:0.0001)
55280: accuracy:0.22 loss: 252.232 (lr:0.0001)
55300: accuracy:0.21 loss: 259.741 (lr:0.0001)
55320: accuracy:0.18 loss: 259.115 (lr:0.0001)
55340: accuracy:0.25 loss: 244.414 (lr:0.0001)
55360: accuracy:0.19 loss: 266.24 (lr:0.0001)
55380: accuracy:0.24 loss: 243.868 (lr:0.0001)
55400: accuracy:0.2 loss: 273.055 (lr:0.0001)
55420: accuracy:0.2 loss: 252.322 (lr:0.0001)
55440: accuracy:0.25 loss: 243.664 (lr:0.0001)
55460: accuracy:0.25 loss: 236.533 (lr:0.0001)
55480: accuracy:0.22 loss: 271.558 (lr:0.0001)
55500: accuracy:0.22 loss: 249.728 (lr:0.0001)
55520: accuracy:0.2 loss: 269.643 (lr:0.0001)
55540: accuracy:0.21 loss: 253.484 (lr:0.0001)
55560: accuracy:0.28 loss: 244.761 (lr:0.0001)
55580: accuracy:0.24 loss: 244.731 (lr:0.0001)
55600: accuracy:0.21 loss: 246.92 (lr:0.0001)
55620: accuracy:0.25 loss: 232.998 (lr:0.0001)
55640: accuracy:0.28 loss: 254.979 (lr:0.0001)
55660: accuracy:0.24 loss: 238.425 (lr:0.0001)
55680: accuracy:0.18 loss: 266.811 (lr:0.0001)
55700: accuracy:0.22 loss: 260.105 (lr:0.0001)
55720: accuracy:0.18 loss: 251.322 (lr:0.0001)
55740: accuracy:0.17 loss: 256.565 (lr:0.0001)
55760: accuracy:0.22 loss: 256.26 (lr:0.0001)
55780: accuracy:0.17 loss: 265.299 (lr:0.0001)
55800: accuracy:0.28 loss: 244.313 (lr:0.0001)
55820: accuracy:0.18 loss: 259.841 (lr:0.0001)
55840: accuracy:0.25 loss: 258.804 (lr:0.0001)
55860: accuracy:0.24 loss: 261.802 (lr:0.0001)
55880: accuracy:0.2 loss: 267.533 (lr:0.0001)
55900: accuracy:0.24 loss: 238.057 (lr:0.0001)
55920: accuracy:0.17 loss: 251.176 (lr:0.0001)
55940: accuracy:0.24 loss: 236.86 (lr:0.0001)
55960: accuracy:0.33 loss: 246.121 (lr:0.0001)
55980: accuracy:0.22 loss: 258.244 (lr:0.0001)
56000: accuracy:0.28 loss: 241.507 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
56000: ********* epoch 6 ********* test accuracy for all:0.201284 test loss: 271.655
56000: ********* epoch 6 ********* test accuracy for mode 0:0.0255 test loss: 396.391
56000: ********* epoch 6 ********* test accuracy for mode 1:0.038 test loss: 435.765
56000: ********* epoch 6 ********* test accuracy for mode 2:0.074 test loss: 293.925
56000: ********* epoch 6 ********* test accuracy for mode 24:0.2375 test loss: 271.646
56000: ********* epoch 6 ********* test accuracy for mode 25:0.1955 test loss: 263.611
56000: ********* epoch 6 ********* test accuracy for mode 26:0.45 test loss: 194.151
56000: ********* epoch 6 ********* test accuracy for mode 27:0.1995 test loss: 275.736
56000: ********* epoch 6 ********* test accuracy for mode 28:0.2675 test loss: 254.961
56000: ********* epoch 6 ********* test accuracy for mode 29:0.2835 test loss: 260.35
56000: ********* epoch 6 ********* test accuracy for mode 30:0.1725 test loss: 260.177
56000: ********* epoch 6 ********* test accuracy for mode 31:0.173 test loss: 264.98
56000: ********* epoch 6 ********* test accuracy for mode 32:0.224 test loss: 255.674
56000: ********* epoch 6 ********* test accuracy for mode 33:0.0985 test loss: 262.505
56000: ********* epoch 6 ********* test accuracy for mode 34:0.026 test loss: 268.062
56000: ********* epoch 6 ********* test accuracy for mode 35:0.042 test loss: 429.573
56000: ********* epoch 6 ********* test accuracy for mode 36:0.071 test loss: 467.266
56020: accuracy:0.17 loss: 274.806 (lr:0.0001)
56040: accuracy:0.24 loss: 233.935 (lr:0.0001)
56060: accuracy:0.24 loss: 249.781 (lr:0.0001)
56080: accuracy:0.24 loss: 242.18 (lr:0.0001)
56100: accuracy:0.29 loss: 240.967 (lr:0.0001)
56120: accuracy:0.28 loss: 242.623 (lr:0.0001)
56140: accuracy:0.29 loss: 269.493 (lr:0.0001)
56160: accuracy:0.25 loss: 259.305 (lr:0.0001)
56180: accuracy:0.16 loss: 273.01 (lr:0.0001)
56200: accuracy:0.2 loss: 251.41 (lr:0.0001)
56220: accuracy:0.21 loss: 260.917 (lr:0.0001)
56240: accuracy:0.2 loss: 242.2 (lr:0.0001)
56260: accuracy:0.32 loss: 241.409 (lr:0.0001)
56280: accuracy:0.22 loss: 258.33 (lr:0.0001)
56300: accuracy:0.21 loss: 257.931 (lr:0.0001)
56320: accuracy:0.24 loss: 261.13 (lr:0.0001)
56340: accuracy:0.2 loss: 256.735 (lr:0.0001)
56360: accuracy:0.21 loss: 257.688 (lr:0.0001)
56380: accuracy:0.24 loss: 240.406 (lr:0.0001)
56400: accuracy:0.24 loss: 265.949 (lr:0.0001)
56420: accuracy:0.25 loss: 252.696 (lr:0.0001)
56440: accuracy:0.27 loss: 253.142 (lr:0.0001)
56460: accuracy:0.19 loss: 240.236 (lr:0.0001)
56480: accuracy:0.21 loss: 250.989 (lr:0.0001)
56500: accuracy:0.27 loss: 244.415 (lr:0.0001)
56520: accuracy:0.21 loss: 261.664 (lr:0.0001)
56540: accuracy:0.26 loss: 255.348 (lr:0.0001)
56560: accuracy:0.21 loss: 260.596 (lr:0.0001)
56580: accuracy:0.23 loss: 225.56 (lr:0.0001)
56600: accuracy:0.19 loss: 257.492 (lr:0.0001)
56620: accuracy:0.21 loss: 253.654 (lr:0.0001)
56640: accuracy:0.28 loss: 252.236 (lr:0.0001)
56660: accuracy:0.34 loss: 246.376 (lr:0.0001)
56680: accuracy:0.24 loss: 236.366 (lr:0.0001)
56700: accuracy:0.2 loss: 266.673 (lr:0.0001)
56720: accuracy:0.28 loss: 226.745 (lr:0.0001)
56740: accuracy:0.24 loss: 234.302 (lr:0.0001)
56760: accuracy:0.17 loss: 258.314 (lr:0.0001)
56780: accuracy:0.21 loss: 262.609 (lr:0.0001)
56800: accuracy:0.24 loss: 256.798 (lr:0.0001)
56820: accuracy:0.26 loss: 266.593 (lr:0.0001)
56840: accuracy:0.19 loss: 247.091 (lr:0.0001)
56860: accuracy:0.26 loss: 248.513 (lr:0.0001)
56880: accuracy:0.24 loss: 246.763 (lr:0.0001)
56900: accuracy:0.28 loss: 239.571 (lr:0.0001)
56920: accuracy:0.19 loss: 251.294 (lr:0.0001)
56940: accuracy:0.18 loss: 257.13 (lr:0.0001)
56960: accuracy:0.26 loss: 249.892 (lr:0.0001)
56980: accuracy:0.23 loss: 244.604 (lr:0.0001)
57000: accuracy:0.22 loss: 232.762 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
57000: ********* epoch 6 ********* test accuracy for all:0.200662 test loss: 271.107
57000: ********* epoch 6 ********* test accuracy for mode 0:0.0275 test loss: 398.689
57000: ********* epoch 6 ********* test accuracy for mode 1:0.0385 test loss: 442.952
57000: ********* epoch 6 ********* test accuracy for mode 2:0.088 test loss: 290.783
57000: ********* epoch 6 ********* test accuracy for mode 24:0.26 test loss: 268.277
57000: ********* epoch 6 ********* test accuracy for mode 25:0.237 test loss: 260.784
57000: ********* epoch 6 ********* test accuracy for mode 26:0.373 test loss: 193.845
57000: ********* epoch 6 ********* test accuracy for mode 27:0.1775 test loss: 280.265
57000: ********* epoch 6 ********* test accuracy for mode 28:0.2705 test loss: 260.684
57000: ********* epoch 6 ********* test accuracy for mode 29:0.2705 test loss: 266.03
57000: ********* epoch 6 ********* test accuracy for mode 30:0.1365 test loss: 267.022
57000: ********* epoch 6 ********* test accuracy for mode 31:0.175 test loss: 266.784
57000: ********* epoch 6 ********* test accuracy for mode 32:0.237 test loss: 255.502
57000: ********* epoch 6 ********* test accuracy for mode 33:0.104 test loss: 261.228
57000: ********* epoch 6 ********* test accuracy for mode 34:0.0265 test loss: 264.91
57000: ********* epoch 6 ********* test accuracy for mode 35:0.046 test loss: 423.182
57000: ********* epoch 6 ********* test accuracy for mode 36:0.0725 test loss: 463.12
57020: accuracy:0.18 loss: 259.431 (lr:0.0001)
57040: accuracy:0.27 loss: 252.418 (lr:0.0001)
57060: accuracy:0.24 loss: 241.818 (lr:0.0001)
57080: accuracy:0.21 loss: 251.756 (lr:0.0001)
57100: accuracy:0.17 loss: 256.313 (lr:0.0001)
57120: accuracy:0.27 loss: 260.237 (lr:0.0001)
57140: accuracy:0.24 loss: 243.792 (lr:0.0001)
57160: accuracy:0.26 loss: 260.94 (lr:0.0001)
57180: accuracy:0.19 loss: 264.26 (lr:0.0001)
57200: accuracy:0.24 loss: 261.676 (lr:0.0001)
57220: accuracy:0.19 loss: 250.504 (lr:0.0001)
57240: accuracy:0.22 loss: 236.285 (lr:0.0001)
57260: accuracy:0.27 loss: 251.676 (lr:0.0001)
57280: accuracy:0.21 loss: 259.321 (lr:0.0001)
57300: accuracy:0.26 loss: 244.277 (lr:0.0001)
57320: accuracy:0.25 loss: 231.416 (lr:0.0001)
57340: accuracy:0.22 loss: 248.685 (lr:0.0001)
57360: accuracy:0.2 loss: 257.162 (lr:0.0001)
57380: accuracy:0.22 loss: 233.623 (lr:0.0001)
57400: accuracy:0.31 loss: 242.604 (lr:0.0001)
57420: accuracy:0.16 loss: 254.096 (lr:0.0001)
57440: accuracy:0.27 loss: 242.767 (lr:0.0001)
57460: accuracy:0.2 loss: 261.744 (lr:0.0001)
57480: accuracy:0.27 loss: 232.448 (lr:0.0001)
57500: accuracy:0.32 loss: 232.662 (lr:0.0001)
57520: accuracy:0.2 loss: 254.992 (lr:0.0001)
57540: accuracy:0.22 loss: 251.605 (lr:0.0001)
57560: accuracy:0.21 loss: 249.537 (lr:0.0001)
57580: accuracy:0.22 loss: 230.341 (lr:0.0001)
57600: accuracy:0.21 loss: 240.148 (lr:0.0001)
57620: accuracy:0.25 loss: 266.154 (lr:0.0001)
57640: accuracy:0.25 loss: 252.166 (lr:0.0001)
57660: accuracy:0.29 loss: 230.624 (lr:0.0001)
57680: accuracy:0.26 loss: 235.786 (lr:0.0001)
57700: accuracy:0.32 loss: 241.581 (lr:0.0001)
57720: accuracy:0.19 loss: 253.003 (lr:0.0001)
57740: accuracy:0.16 loss: 257.911 (lr:0.0001)
57760: accuracy:0.19 loss: 250.497 (lr:0.0001)
57780: accuracy:0.25 loss: 261.926 (lr:0.0001)
57800: accuracy:0.27 loss: 247.875 (lr:0.0001)
57820: accuracy:0.23 loss: 249.725 (lr:0.0001)
57840: accuracy:0.26 loss: 253.222 (lr:0.0001)
57860: accuracy:0.23 loss: 253.249 (lr:0.0001)
57880: accuracy:0.26 loss: 238.277 (lr:0.0001)
57900: accuracy:0.34 loss: 229.615 (lr:0.0001)
57920: accuracy:0.22 loss: 259.585 (lr:0.0001)
57940: accuracy:0.19 loss: 246.881 (lr:0.0001)
57960: accuracy:0.18 loss: 263.843 (lr:0.0001)
57980: accuracy:0.22 loss: 252.269 (lr:0.0001)
58000: accuracy:0.21 loss: 250.066 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
58000: ********* epoch 6 ********* test accuracy for all:0.202068 test loss: 270.922
58000: ********* epoch 6 ********* test accuracy for mode 0:0.03 test loss: 391.937
58000: ********* epoch 6 ********* test accuracy for mode 1:0.046 test loss: 427.871
58000: ********* epoch 6 ********* test accuracy for mode 2:0.081 test loss: 290.371
58000: ********* epoch 6 ********* test accuracy for mode 24:0.264 test loss: 264.954
58000: ********* epoch 6 ********* test accuracy for mode 25:0.2495 test loss: 256.725
58000: ********* epoch 6 ********* test accuracy for mode 26:0.358 test loss: 194.039
58000: ********* epoch 6 ********* test accuracy for mode 27:0.1785 test loss: 277.635
58000: ********* epoch 6 ********* test accuracy for mode 28:0.262 test loss: 255.7
58000: ********* epoch 6 ********* test accuracy for mode 29:0.2965 test loss: 259.592
58000: ********* epoch 6 ********* test accuracy for mode 30:0.134 test loss: 263.759
58000: ********* epoch 6 ********* test accuracy for mode 31:0.187 test loss: 266.136
58000: ********* epoch 6 ********* test accuracy for mode 32:0.2 test loss: 259.61
58000: ********* epoch 6 ********* test accuracy for mode 33:0.13 test loss: 263.298
58000: ********* epoch 6 ********* test accuracy for mode 34:0.021 test loss: 269.48
58000: ********* epoch 6 ********* test accuracy for mode 35:0.09 test loss: 424.678
58000: ********* epoch 6 ********* test accuracy for mode 36:0.106 test loss: 465.569
58020: accuracy:0.16 loss: 274.386 (lr:0.0001)
58040: accuracy:0.25 loss: 254.249 (lr:0.0001)
58060: accuracy:0.26 loss: 256.715 (lr:0.0001)
58080: accuracy:0.24 loss: 263.59 (lr:0.0001)
58100: accuracy:0.18 loss: 258.277 (lr:0.0001)
58120: accuracy:0.23 loss: 250.121 (lr:0.0001)
58140: accuracy:0.21 loss: 237.418 (lr:0.0001)
58160: accuracy:0.24 loss: 248.309 (lr:0.0001)
58180: accuracy:0.31 loss: 249.252 (lr:0.0001)
58200: accuracy:0.3 loss: 244.052 (lr:0.0001)
58220: accuracy:0.28 loss: 244.091 (lr:0.0001)
58240: accuracy:0.26 loss: 235.459 (lr:0.0001)
58260: accuracy:0.32 loss: 253.606 (lr:0.0001)
58280: accuracy:0.22 loss: 265.271 (lr:0.0001)
58300: accuracy:0.22 loss: 246.667 (lr:0.0001)
58320: accuracy:0.17 loss: 266.219 (lr:0.0001)
58340: accuracy:0.15 loss: 280.376 (lr:0.0001)
58360: accuracy:0.28 loss: 253.247 (lr:0.0001)
58380: accuracy:0.3 loss: 243.827 (lr:0.0001)
58400: accuracy:0.23 loss: 273.338 (lr:0.0001)
58420: accuracy:0.15 loss: 252.704 (lr:0.0001)
58440: accuracy:0.18 loss: 258.825 (lr:0.0001)
58460: accuracy:0.24 loss: 250.835 (lr:0.0001)
58480: accuracy:0.19 loss: 242.724 (lr:0.0001)
58500: accuracy:0.22 loss: 250.301 (lr:0.0001)
58520: accuracy:0.17 loss: 245.296 (lr:0.0001)
58540: accuracy:0.26 loss: 237.992 (lr:0.0001)
58560: accuracy:0.16 loss: 261.337 (lr:0.0001)
58580: accuracy:0.37 loss: 240.369 (lr:0.0001)
58600: accuracy:0.15 loss: 259.031 (lr:0.0001)
58620: accuracy:0.21 loss: 256.006 (lr:0.0001)
58640: accuracy:0.25 loss: 242.319 (lr:0.0001)
58660: accuracy:0.26 loss: 253.214 (lr:0.0001)
58680: accuracy:0.21 loss: 248.276 (lr:0.0001)
58700: accuracy:0.28 loss: 239.464 (lr:0.0001)
58720: accuracy:0.26 loss: 248.558 (lr:0.0001)
58740: accuracy:0.28 loss: 237.787 (lr:0.0001)
58760: accuracy:0.26 loss: 235.42 (lr:0.0001)
58780: accuracy:0.29 loss: 250.938 (lr:0.0001)
58800: accuracy:0.24 loss: 250.526 (lr:0.0001)
58820: accuracy:0.27 loss: 242.245 (lr:0.0001)
58840: accuracy:0.19 loss: 242.553 (lr:0.0001)
58860: accuracy:0.21 loss: 250.242 (lr:0.0001)
58880: accuracy:0.21 loss: 256.457 (lr:0.0001)
58900: accuracy:0.28 loss: 245.669 (lr:0.0001)
58920: accuracy:0.15 loss: 276.352 (lr:0.0001)
58940: accuracy:0.17 loss: 278.814 (lr:0.0001)
58960: accuracy:0.19 loss: 241.198 (lr:0.0001)
58980: accuracy:0.2 loss: 254.804 (lr:0.0001)
59000: accuracy:0.26 loss: 233.835 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
59000: ********* epoch 7 ********* test accuracy for all:0.203095 test loss: 269.796
59000: ********* epoch 7 ********* test accuracy for mode 0:0.029 test loss: 399.361
59000: ********* epoch 7 ********* test accuracy for mode 1:0.0345 test loss: 439.497
59000: ********* epoch 7 ********* test accuracy for mode 2:0.0705 test loss: 288.683
59000: ********* epoch 7 ********* test accuracy for mode 24:0.235 test loss: 268.772
59000: ********* epoch 7 ********* test accuracy for mode 25:0.2645 test loss: 251.304
59000: ********* epoch 7 ********* test accuracy for mode 26:0.352 test loss: 193.817
59000: ********* epoch 7 ********* test accuracy for mode 27:0.227 test loss: 267.914
59000: ********* epoch 7 ********* test accuracy for mode 28:0.274 test loss: 253.233
59000: ********* epoch 7 ********* test accuracy for mode 29:0.2675 test loss: 259.012
59000: ********* epoch 7 ********* test accuracy for mode 30:0.191 test loss: 259.152
59000: ********* epoch 7 ********* test accuracy for mode 31:0.195 test loss: 262.832
59000: ********* epoch 7 ********* test accuracy for mode 32:0.2075 test loss: 257.674
59000: ********* epoch 7 ********* test accuracy for mode 33:0.1175 test loss: 262.891
59000: ********* epoch 7 ********* test accuracy for mode 34:0.0195 test loss: 267.947
59000: ********* epoch 7 ********* test accuracy for mode 35:0.0585 test loss: 427.163
59000: ********* epoch 7 ********* test accuracy for mode 36:0.0895 test loss: 460.56
59020: accuracy:0.19 loss: 262.437 (lr:0.0001)
59040: accuracy:0.17 loss: 267.296 (lr:0.0001)
59060: accuracy:0.29 loss: 246.926 (lr:0.0001)
59080: accuracy:0.34 loss: 245.336 (lr:0.0001)
59100: accuracy:0.2 loss: 265.803 (lr:0.0001)
59120: accuracy:0.23 loss: 249.722 (lr:0.0001)
59140: accuracy:0.23 loss: 267.906 (lr:0.0001)
59160: accuracy:0.22 loss: 254.154 (lr:0.0001)
59180: accuracy:0.23 loss: 246.105 (lr:0.0001)
59200: accuracy:0.22 loss: 249.562 (lr:0.0001)
59220: accuracy:0.18 loss: 252.83 (lr:0.0001)
59240: accuracy:0.22 loss: 266.253 (lr:0.0001)
59260: accuracy:0.32 loss: 236.754 (lr:0.0001)
59280: accuracy:0.25 loss: 241.084 (lr:0.0001)
59300: accuracy:0.29 loss: 257.01 (lr:0.0001)
59320: accuracy:0.29 loss: 240.741 (lr:0.0001)
59340: accuracy:0.28 loss: 232.966 (lr:0.0001)
59360: accuracy:0.22 loss: 242.254 (lr:0.0001)
59380: accuracy:0.2 loss: 258.04 (lr:0.0001)
59400: accuracy:0.25 loss: 267.375 (lr:0.0001)
59420: accuracy:0.2 loss: 232.424 (lr:0.0001)
59440: accuracy:0.2 loss: 259.023 (lr:0.0001)
59460: accuracy:0.27 loss: 251.839 (lr:0.0001)
59480: accuracy:0.24 loss: 245.999 (lr:0.0001)
59500: accuracy:0.2 loss: 241.828 (lr:0.0001)
59520: accuracy:0.27 loss: 238.759 (lr:0.0001)
59540: accuracy:0.22 loss: 231.226 (lr:0.0001)
59560: accuracy:0.15 loss: 252.593 (lr:0.0001)
59580: accuracy:0.32 loss: 249.639 (lr:0.0001)
59600: accuracy:0.3 loss: 235.194 (lr:0.0001)
59620: accuracy:0.19 loss: 269.958 (lr:0.0001)
59640: accuracy:0.19 loss: 254.793 (lr:0.0001)
59660: accuracy:0.17 loss: 242.036 (lr:0.0001)
59680: accuracy:0.25 loss: 242.41 (lr:0.0001)
59700: accuracy:0.26 loss: 241.214 (lr:0.0001)
59720: accuracy:0.2 loss: 248.42 (lr:0.0001)
59740: accuracy:0.27 loss: 229.158 (lr:0.0001)
59760: accuracy:0.16 loss: 249.351 (lr:0.0001)
59780: accuracy:0.27 loss: 233.082 (lr:0.0001)
59800: accuracy:0.21 loss: 259.864 (lr:0.0001)
59820: accuracy:0.18 loss: 240.692 (lr:0.0001)
59840: accuracy:0.28 loss: 259.083 (lr:0.0001)
59860: accuracy:0.24 loss: 245.364 (lr:0.0001)
59880: accuracy:0.22 loss: 241.373 (lr:0.0001)
59900: accuracy:0.19 loss: 246.899 (lr:0.0001)
59920: accuracy:0.2 loss: 260.788 (lr:0.0001)
59940: accuracy:0.19 loss: 253.034 (lr:0.0001)
59960: accuracy:0.34 loss: 234.751 (lr:0.0001)
59980: accuracy:0.25 loss: 255.268 (lr:0.0001)
60000: accuracy:0.3 loss: 254.73 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
60000: ********* epoch 7 ********* test accuracy for all:0.200784 test loss: 271.274
60000: ********* epoch 7 ********* test accuracy for mode 0:0.028 test loss: 403.964
60000: ********* epoch 7 ********* test accuracy for mode 1:0.029 test loss: 455.014
60000: ********* epoch 7 ********* test accuracy for mode 2:0.066 test loss: 288.916
60000: ********* epoch 7 ********* test accuracy for mode 24:0.236 test loss: 268.557
60000: ********* epoch 7 ********* test accuracy for mode 25:0.2705 test loss: 254.989
60000: ********* epoch 7 ********* test accuracy for mode 26:0.323 test loss: 195.982
60000: ********* epoch 7 ********* test accuracy for mode 27:0.223 test loss: 277.049
60000: ********* epoch 7 ********* test accuracy for mode 28:0.2675 test loss: 264.874
60000: ********* epoch 7 ********* test accuracy for mode 29:0.2365 test loss: 271.666
60000: ********* epoch 7 ********* test accuracy for mode 30:0.182 test loss: 265.327
60000: ********* epoch 7 ********* test accuracy for mode 31:0.1465 test loss: 267.33
60000: ********* epoch 7 ********* test accuracy for mode 32:0.246 test loss: 254.922
60000: ********* epoch 7 ********* test accuracy for mode 33:0.1185 test loss: 260.753
60000: ********* epoch 7 ********* test accuracy for mode 34:0.027 test loss: 266.136
60000: ********* epoch 7 ********* test accuracy for mode 35:0.0405 test loss: 434.018
60000: ********* epoch 7 ********* test accuracy for mode 36:0.0485 test loss: 469.603
60020: accuracy:0.2 loss: 272.103 (lr:0.0001)
60040: accuracy:0.18 loss: 266.032 (lr:0.0001)
60060: accuracy:0.23 loss: 255.53 (lr:0.0001)
60080: accuracy:0.2 loss: 262.082 (lr:0.0001)
60100: accuracy:0.23 loss: 276.927 (lr:0.0001)
60120: accuracy:0.16 loss: 251.616 (lr:0.0001)
60140: accuracy:0.19 loss: 243.04 (lr:0.0001)
60160: accuracy:0.19 loss: 252.136 (lr:0.0001)
60180: accuracy:0.25 loss: 248.983 (lr:0.0001)
60200: accuracy:0.29 loss: 237.012 (lr:0.0001)
60220: accuracy:0.24 loss: 261.046 (lr:0.0001)
60240: accuracy:0.21 loss: 273.007 (lr:0.0001)
60260: accuracy:0.24 loss: 241.088 (lr:0.0001)
60280: accuracy:0.25 loss: 251.354 (lr:0.0001)
60300: accuracy:0.24 loss: 251.797 (lr:0.0001)
60320: accuracy:0.25 loss: 240.064 (lr:0.0001)
60340: accuracy:0.31 loss: 221.049 (lr:0.0001)
60360: accuracy:0.2 loss: 243.495 (lr:0.0001)
60380: accuracy:0.22 loss: 243.215 (lr:0.0001)
60400: accuracy:0.21 loss: 254.384 (lr:0.0001)
60420: accuracy:0.13 loss: 253.769 (lr:0.0001)
60440: accuracy:0.31 loss: 254.169 (lr:0.0001)
60460: accuracy:0.19 loss: 257.352 (lr:0.0001)
60480: accuracy:0.25 loss: 251.606 (lr:0.0001)
60500: accuracy:0.28 loss: 239.218 (lr:0.0001)
60520: accuracy:0.21 loss: 248.969 (lr:0.0001)
60540: accuracy:0.23 loss: 243.224 (lr:0.0001)
60560: accuracy:0.3 loss: 235.189 (lr:0.0001)
60580: accuracy:0.23 loss: 241.262 (lr:0.0001)
60600: accuracy:0.33 loss: 236.908 (lr:0.0001)
60620: accuracy:0.2 loss: 251.764 (lr:0.0001)
60640: accuracy:0.25 loss: 239.979 (lr:0.0001)
60660: accuracy:0.17 loss: 270.801 (lr:0.0001)
60680: accuracy:0.26 loss: 247.874 (lr:0.0001)
60700: accuracy:0.26 loss: 236.567 (lr:0.0001)
60720: accuracy:0.24 loss: 241.596 (lr:0.0001)
60740: accuracy:0.29 loss: 241.726 (lr:0.0001)
60760: accuracy:0.3 loss: 249.536 (lr:0.0001)
60780: accuracy:0.18 loss: 258.792 (lr:0.0001)
60800: accuracy:0.27 loss: 236.087 (lr:0.0001)
60820: accuracy:0.22 loss: 260.489 (lr:0.0001)
60840: accuracy:0.25 loss: 247.838 (lr:0.0001)
60860: accuracy:0.25 loss: 258.102 (lr:0.0001)
60880: accuracy:0.18 loss: 253.023 (lr:0.0001)
60900: accuracy:0.28 loss: 247.301 (lr:0.0001)
60920: accuracy:0.22 loss: 249.896 (lr:0.0001)
60940: accuracy:0.32 loss: 241.038 (lr:0.0001)
60960: accuracy:0.23 loss: 241.235 (lr:0.0001)
60980: accuracy:0.19 loss: 262.245 (lr:0.0001)
61000: accuracy:0.32 loss: 223.875 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
61000: ********* epoch 7 ********* test accuracy for all:0.203797 test loss: 269.552
61000: ********* epoch 7 ********* test accuracy for mode 0:0.029 test loss: 397.162
61000: ********* epoch 7 ********* test accuracy for mode 1:0.05 test loss: 432.978
61000: ********* epoch 7 ********* test accuracy for mode 2:0.0825 test loss: 292.802
61000: ********* epoch 7 ********* test accuracy for mode 24:0.268 test loss: 265.695
61000: ********* epoch 7 ********* test accuracy for mode 25:0.272 test loss: 252.812
61000: ********* epoch 7 ********* test accuracy for mode 26:0.3325 test loss: 191.544
61000: ********* epoch 7 ********* test accuracy for mode 27:0.2085 test loss: 274.058
61000: ********* epoch 7 ********* test accuracy for mode 28:0.2835 test loss: 256.09
61000: ********* epoch 7 ********* test accuracy for mode 29:0.2815 test loss: 264.288
61000: ********* epoch 7 ********* test accuracy for mode 30:0.163 test loss: 266.357
61000: ********* epoch 7 ********* test accuracy for mode 31:0.1145 test loss: 275.062
61000: ********* epoch 7 ********* test accuracy for mode 32:0.236 test loss: 262.024
61000: ********* epoch 7 ********* test accuracy for mode 33:0.1055 test loss: 268.515
61000: ********* epoch 7 ********* test accuracy for mode 34:0.0245 test loss: 271.745
61000: ********* epoch 7 ********* test accuracy for mode 35:0.0675 test loss: 425.213
61000: ********* epoch 7 ********* test accuracy for mode 36:0.076 test loss: 462.767
61020: accuracy:0.26 loss: 259.138 (lr:0.0001)
61040: accuracy:0.28 loss: 244.197 (lr:0.0001)
61060: accuracy:0.21 loss: 249.609 (lr:0.0001)
61080: accuracy:0.28 loss: 239.528 (lr:0.0001)
61100: accuracy:0.29 loss: 229.555 (lr:0.0001)
61120: accuracy:0.18 loss: 284.665 (lr:0.0001)
61140: accuracy:0.26 loss: 255.656 (lr:0.0001)
61160: accuracy:0.2 loss: 264.55 (lr:0.0001)
61180: accuracy:0.22 loss: 248.53 (lr:0.0001)
61200: accuracy:0.22 loss: 237.459 (lr:0.0001)
61220: accuracy:0.18 loss: 251.933 (lr:0.0001)
61240: accuracy:0.28 loss: 237.832 (lr:0.0001)
61260: accuracy:0.19 loss: 253.366 (lr:0.0001)
61280: accuracy:0.3 loss: 224.611 (lr:0.0001)
61300: accuracy:0.28 loss: 238.364 (lr:0.0001)
61320: accuracy:0.23 loss: 259.43 (lr:0.0001)
61340: accuracy:0.15 loss: 251.966 (lr:0.0001)
61360: accuracy:0.25 loss: 242.615 (lr:0.0001)
61380: accuracy:0.21 loss: 255.233 (lr:0.0001)
61400: accuracy:0.21 loss: 268.359 (lr:0.0001)
61420: accuracy:0.19 loss: 261.05 (lr:0.0001)
61440: accuracy:0.23 loss: 255.911 (lr:0.0001)
61460: accuracy:0.23 loss: 261.18 (lr:0.0001)
61480: accuracy:0.19 loss: 257.346 (lr:0.0001)
61500: accuracy:0.2 loss: 248.968 (lr:0.0001)
61520: accuracy:0.22 loss: 256.957 (lr:0.0001)
61540: accuracy:0.26 loss: 254.495 (lr:0.0001)
61560: accuracy:0.2 loss: 266.549 (lr:0.0001)
61580: accuracy:0.24 loss: 240.485 (lr:0.0001)
61600: accuracy:0.24 loss: 258.696 (lr:0.0001)
61620: accuracy:0.23 loss: 253.156 (lr:0.0001)
61640: accuracy:0.24 loss: 261.819 (lr:0.0001)
61660: accuracy:0.18 loss: 253.544 (lr:0.0001)
61680: accuracy:0.24 loss: 271.143 (lr:0.0001)
61700: accuracy:0.23 loss: 254.363 (lr:0.0001)
61720: accuracy:0.26 loss: 259.152 (lr:0.0001)
61740: accuracy:0.27 loss: 240.62 (lr:0.0001)
61760: accuracy:0.26 loss: 257.062 (lr:0.0001)
61780: accuracy:0.22 loss: 251.71 (lr:0.0001)
61800: accuracy:0.27 loss: 241.724 (lr:0.0001)
61820: accuracy:0.16 loss: 239.574 (lr:0.0001)
61840: accuracy:0.23 loss: 256.012 (lr:0.0001)
61860: accuracy:0.18 loss: 270.999 (lr:0.0001)
61880: accuracy:0.16 loss: 265.031 (lr:0.0001)
61900: accuracy:0.16 loss: 257.855 (lr:0.0001)
61920: accuracy:0.17 loss: 237.828 (lr:0.0001)
61940: accuracy:0.24 loss: 249.023 (lr:0.0001)
61960: accuracy:0.19 loss: 268.779 (lr:0.0001)
61980: accuracy:0.32 loss: 235.062 (lr:0.0001)
62000: accuracy:0.27 loss: 252.799 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
62000: ********* epoch 7 ********* test accuracy for all:0.201378 test loss: 272.491
62000: ********* epoch 7 ********* test accuracy for mode 0:0.0295 test loss: 408.708
62000: ********* epoch 7 ********* test accuracy for mode 1:0.0265 test loss: 462.361
62000: ********* epoch 7 ********* test accuracy for mode 2:0.095 test loss: 286.491
62000: ********* epoch 7 ********* test accuracy for mode 24:0.246 test loss: 272.512
62000: ********* epoch 7 ********* test accuracy for mode 25:0.2695 test loss: 258.619
62000: ********* epoch 7 ********* test accuracy for mode 26:0.2815 test loss: 199.705
62000: ********* epoch 7 ********* test accuracy for mode 27:0.207 test loss: 282.831
62000: ********* epoch 7 ********* test accuracy for mode 28:0.278 test loss: 264.397
62000: ********* epoch 7 ********* test accuracy for mode 29:0.2485 test loss: 270.562
62000: ********* epoch 7 ********* test accuracy for mode 30:0.1635 test loss: 266.404
62000: ********* epoch 7 ********* test accuracy for mode 31:0.1815 test loss: 264.744
62000: ********* epoch 7 ********* test accuracy for mode 32:0.2285 test loss: 253.526
62000: ********* epoch 7 ********* test accuracy for mode 33:0.1245 test loss: 258.868
62000: ********* epoch 7 ********* test accuracy for mode 34:0.029 test loss: 263.459
62000: ********* epoch 7 ********* test accuracy for mode 35:0.0375 test loss: 444.556
62000: ********* epoch 7 ********* test accuracy for mode 36:0.0405 test loss: 492.403
62020: accuracy:0.23 loss: 245.199 (lr:0.0001)
62040: accuracy:0.21 loss: 250.773 (lr:0.0001)
62060: accuracy:0.23 loss: 254.71 (lr:0.0001)
62080: accuracy:0.2 loss: 258.749 (lr:0.0001)
62100: accuracy:0.25 loss: 252.63 (lr:0.0001)
62120: accuracy:0.27 loss: 268.265 (lr:0.0001)
62140: accuracy:0.24 loss: 245.697 (lr:0.0001)
62160: accuracy:0.26 loss: 239.384 (lr:0.0001)
62180: accuracy:0.25 loss: 256.187 (lr:0.0001)
62200: accuracy:0.26 loss: 239.34 (lr:0.0001)
62220: accuracy:0.22 loss: 239.647 (lr:0.0001)
62240: accuracy:0.26 loss: 261.564 (lr:0.0001)
62260: accuracy:0.22 loss: 243.437 (lr:0.0001)
62280: accuracy:0.21 loss: 246.473 (lr:0.0001)
62300: accuracy:0.25 loss: 294.056 (lr:0.0001)
62320: accuracy:0.23 loss: 257.122 (lr:0.0001)
62340: accuracy:0.19 loss: 250.347 (lr:0.0001)
62360: accuracy:0.24 loss: 256.957 (lr:0.0001)
62380: accuracy:0.22 loss: 231.977 (lr:0.0001)
62400: accuracy:0.26 loss: 257.901 (lr:0.0001)
62420: accuracy:0.21 loss: 263.414 (lr:0.0001)
62440: accuracy:0.27 loss: 246.5 (lr:0.0001)
62460: accuracy:0.19 loss: 255.336 (lr:0.0001)
62480: accuracy:0.2 loss: 245.202 (lr:0.0001)
62500: accuracy:0.25 loss: 243.577 (lr:0.0001)
62520: accuracy:0.23 loss: 237.2 (lr:0.0001)
62540: accuracy:0.24 loss: 238.586 (lr:0.0001)
62560: accuracy:0.17 loss: 251.17 (lr:0.0001)
62580: accuracy:0.23 loss: 246.217 (lr:0.0001)
62600: accuracy:0.14 loss: 269.393 (lr:0.0001)
62620: accuracy:0.17 loss: 267.634 (lr:0.0001)
62640: accuracy:0.23 loss: 265.815 (lr:0.0001)
62660: accuracy:0.17 loss: 264.365 (lr:0.0001)
62680: accuracy:0.22 loss: 239.554 (lr:0.0001)
62700: accuracy:0.19 loss: 251.613 (lr:0.0001)
62720: accuracy:0.25 loss: 248.701 (lr:0.0001)
62740: accuracy:0.25 loss: 240.994 (lr:0.0001)
62760: accuracy:0.23 loss: 249.475 (lr:0.0001)
62780: accuracy:0.34 loss: 234.507 (lr:0.0001)
62800: accuracy:0.26 loss: 239.978 (lr:0.0001)
62820: accuracy:0.22 loss: 251.852 (lr:0.0001)
62840: accuracy:0.26 loss: 240.967 (lr:0.0001)
62860: accuracy:0.21 loss: 262.528 (lr:0.0001)
62880: accuracy:0.15 loss: 251.862 (lr:0.0001)
62900: accuracy:0.24 loss: 252.989 (lr:0.0001)
62920: accuracy:0.3 loss: 244.995 (lr:0.0001)
62940: accuracy:0.24 loss: 268.599 (lr:0.0001)
62960: accuracy:0.31 loss: 226.101 (lr:0.0001)
62980: accuracy:0.28 loss: 245.742 (lr:0.0001)
63000: accuracy:0.22 loss: 250.297 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
63000: ********* epoch 7 ********* test accuracy for all:0.202486 test loss: 270.107
63000: ********* epoch 7 ********* test accuracy for mode 0:0.0355 test loss: 398.263
63000: ********* epoch 7 ********* test accuracy for mode 1:0.037 test loss: 438.721
63000: ********* epoch 7 ********* test accuracy for mode 2:0.07 test loss: 291.775
63000: ********* epoch 7 ********* test accuracy for mode 24:0.2595 test loss: 266.227
63000: ********* epoch 7 ********* test accuracy for mode 25:0.2385 test loss: 256.477
63000: ********* epoch 7 ********* test accuracy for mode 26:0.3415 test loss: 194.255
63000: ********* epoch 7 ********* test accuracy for mode 27:0.2315 test loss: 275.579
63000: ********* epoch 7 ********* test accuracy for mode 28:0.268 test loss: 261.122
63000: ********* epoch 7 ********* test accuracy for mode 29:0.2925 test loss: 266.911
63000: ********* epoch 7 ********* test accuracy for mode 30:0.158 test loss: 268.979
63000: ********* epoch 7 ********* test accuracy for mode 31:0.1325 test loss: 272.503
63000: ********* epoch 7 ********* test accuracy for mode 32:0.2525 test loss: 258.724
63000: ********* epoch 7 ********* test accuracy for mode 33:0.1195 test loss: 263.988
63000: ********* epoch 7 ********* test accuracy for mode 34:0.025 test loss: 269.577
63000: ********* epoch 7 ********* test accuracy for mode 35:0.061 test loss: 429.442
63000: ********* epoch 7 ********* test accuracy for mode 36:0.0635 test loss: 465.677
63020: accuracy:0.24 loss: 248.599 (lr:0.0001)
63040: accuracy:0.28 loss: 239.929 (lr:0.0001)
63060: accuracy:0.17 loss: 267.631 (lr:0.0001)
63080: accuracy:0.27 loss: 250.875 (lr:0.0001)
63100: accuracy:0.19 loss: 244.614 (lr:0.0001)
63120: accuracy:0.27 loss: 251.407 (lr:0.0001)
63140: accuracy:0.22 loss: 241.018 (lr:0.0001)
63160: accuracy:0.19 loss: 265.94 (lr:0.0001)
63180: accuracy:0.13 loss: 273.893 (lr:0.0001)
63200: accuracy:0.31 loss: 240.597 (lr:0.0001)
63220: accuracy:0.31 loss: 214.043 (lr:0.0001)
63240: accuracy:0.23 loss: 273.487 (lr:0.0001)
63260: accuracy:0.36 loss: 210.183 (lr:0.0001)
63280: accuracy:0.3 loss: 244.767 (lr:0.0001)
63300: accuracy:0.24 loss: 244.552 (lr:0.0001)
63320: accuracy:0.11 loss: 262.801 (lr:0.0001)
63340: accuracy:0.2 loss: 243.874 (lr:0.0001)
63360: accuracy:0.22 loss: 265.801 (lr:0.0001)
63380: accuracy:0.27 loss: 234.206 (lr:0.0001)
63400: accuracy:0.24 loss: 248.485 (lr:0.0001)
63420: accuracy:0.23 loss: 258.838 (lr:0.0001)
63440: accuracy:0.18 loss: 257.329 (lr:0.0001)
63460: accuracy:0.22 loss: 258.899 (lr:0.0001)
63480: accuracy:0.24 loss: 250.285 (lr:0.0001)
63500: accuracy:0.23 loss: 255.171 (lr:0.0001)
63520: accuracy:0.24 loss: 245.623 (lr:0.0001)
63540: accuracy:0.18 loss: 245.607 (lr:0.0001)
63560: accuracy:0.26 loss: 237.111 (lr:0.0001)
63580: accuracy:0.19 loss: 259.486 (lr:0.0001)
63600: accuracy:0.18 loss: 250.216 (lr:0.0001)
63620: accuracy:0.31 loss: 237.817 (lr:0.0001)
63640: accuracy:0.13 loss: 268.03 (lr:0.0001)
63660: accuracy:0.25 loss: 239.748 (lr:0.0001)
63680: accuracy:0.17 loss: 252.594 (lr:0.0001)
63700: accuracy:0.28 loss: 238.708 (lr:0.0001)
63720: accuracy:0.28 loss: 237.225 (lr:0.0001)
63740: accuracy:0.19 loss: 258.864 (lr:0.0001)
63760: accuracy:0.26 loss: 254.811 (lr:0.0001)
63780: accuracy:0.21 loss: 253.945 (lr:0.0001)
63800: accuracy:0.27 loss: 229.222 (lr:0.0001)
63820: accuracy:0.3 loss: 230.752 (lr:0.0001)
63840: accuracy:0.27 loss: 233.434 (lr:0.0001)
63860: accuracy:0.31 loss: 235.361 (lr:0.0001)
63880: accuracy:0.21 loss: 262.36 (lr:0.0001)
63900: accuracy:0.19 loss: 271.591 (lr:0.0001)
63920: accuracy:0.18 loss: 242.417 (lr:0.0001)
63940: accuracy:0.28 loss: 257.602 (lr:0.0001)
63960: accuracy:0.26 loss: 256.046 (lr:0.0001)
63980: accuracy:0.25 loss: 244.692 (lr:0.0001)
64000: accuracy:0.23 loss: 237.816 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
64000: ********* epoch 7 ********* test accuracy for all:0.203095 test loss: 272.18
64000: ********* epoch 7 ********* test accuracy for mode 0:0.027 test loss: 406.51
64000: ********* epoch 7 ********* test accuracy for mode 1:0.024 test loss: 444.448
64000: ********* epoch 7 ********* test accuracy for mode 2:0.0685 test loss: 285.005
64000: ********* epoch 7 ********* test accuracy for mode 24:0.235 test loss: 276.335
64000: ********* epoch 7 ********* test accuracy for mode 25:0.2195 test loss: 271.813
64000: ********* epoch 7 ********* test accuracy for mode 26:0.345 test loss: 197.197
64000: ********* epoch 7 ********* test accuracy for mode 27:0.2235 test loss: 278.175
64000: ********* epoch 7 ********* test accuracy for mode 28:0.286 test loss: 254.644
64000: ********* epoch 7 ********* test accuracy for mode 29:0.2665 test loss: 261.288
64000: ********* epoch 7 ********* test accuracy for mode 30:0.1785 test loss: 259.075
64000: ********* epoch 7 ********* test accuracy for mode 31:0.1535 test loss: 261.905
64000: ********* epoch 7 ********* test accuracy for mode 32:0.2375 test loss: 250.143
64000: ********* epoch 7 ********* test accuracy for mode 33:0.132 test loss: 254.916
64000: ********* epoch 7 ********* test accuracy for mode 34:0.0395 test loss: 259.627
64000: ********* epoch 7 ********* test accuracy for mode 35:0.1045 test loss: 428.327
64000: ********* epoch 7 ********* test accuracy for mode 36:0.09 test loss: 468.21
64020: accuracy:0.18 loss: 256.134 (lr:0.0001)
64040: accuracy:0.23 loss: 248.822 (lr:0.0001)
64060: accuracy:0.27 loss: 235.207 (lr:0.0001)
64080: accuracy:0.24 loss: 260.286 (lr:0.0001)
64100: accuracy:0.28 loss: 232.995 (lr:0.0001)
64120: accuracy:0.27 loss: 231.727 (lr:0.0001)
64140: accuracy:0.26 loss: 251.678 (lr:0.0001)
64160: accuracy:0.29 loss: 234.322 (lr:0.0001)
64180: accuracy:0.22 loss: 232.063 (lr:0.0001)
64200: accuracy:0.23 loss: 251.785 (lr:0.0001)
64220: accuracy:0.18 loss: 236.493 (lr:0.0001)
64240: accuracy:0.22 loss: 275.459 (lr:0.0001)
64260: accuracy:0.24 loss: 253.528 (lr:0.0001)
64280: accuracy:0.22 loss: 244.291 (lr:0.0001)
64300: accuracy:0.28 loss: 229.742 (lr:0.0001)
64320: accuracy:0.28 loss: 264.467 (lr:0.0001)
64340: accuracy:0.28 loss: 231.094 (lr:0.0001)
64360: accuracy:0.23 loss: 247.674 (lr:0.0001)
64380: accuracy:0.24 loss: 243.985 (lr:0.0001)
64400: accuracy:0.2 loss: 261.491 (lr:0.0001)
64420: accuracy:0.34 loss: 220.461 (lr:0.0001)
64440: accuracy:0.27 loss: 240.94 (lr:0.0001)
64460: accuracy:0.23 loss: 265.495 (lr:0.0001)
64480: accuracy:0.22 loss: 258.708 (lr:0.0001)
64500: accuracy:0.26 loss: 244.122 (lr:0.0001)
64520: accuracy:0.27 loss: 233.181 (lr:0.0001)
64540: accuracy:0.3 loss: 243.715 (lr:0.0001)
64560: accuracy:0.23 loss: 257.929 (lr:0.0001)
64580: accuracy:0.23 loss: 256.125 (lr:0.0001)
64600: accuracy:0.16 loss: 280.739 (lr:0.0001)
64620: accuracy:0.25 loss: 257.583 (lr:0.0001)
64640: accuracy:0.2 loss: 261.067 (lr:0.0001)
64660: accuracy:0.22 loss: 263.166 (lr:0.0001)
64680: accuracy:0.2 loss: 245.262 (lr:0.0001)
64700: accuracy:0.2 loss: 260.11 (lr:0.0001)
64720: accuracy:0.18 loss: 253.284 (lr:0.0001)
64740: accuracy:0.28 loss: 238.629 (lr:0.0001)
64760: accuracy:0.21 loss: 242.336 (lr:0.0001)
64780: accuracy:0.19 loss: 239.316 (lr:0.0001)
64800: accuracy:0.22 loss: 224.679 (lr:0.0001)
64820: accuracy:0.28 loss: 234.152 (lr:0.0001)
64840: accuracy:0.29 loss: 229.368 (lr:0.0001)
64860: accuracy:0.28 loss: 251.365 (lr:0.0001)
64880: accuracy:0.23 loss: 227.868 (lr:0.0001)
64900: accuracy:0.22 loss: 241.891 (lr:0.0001)
64920: accuracy:0.24 loss: 253.969 (lr:0.0001)
64940: accuracy:0.31 loss: 243.173 (lr:0.0001)
64960: accuracy:0.25 loss: 253.845 (lr:0.0001)
64980: accuracy:0.28 loss: 247.665 (lr:0.0001)
65000: accuracy:0.24 loss: 241.455 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
65000: ********* epoch 7 ********* test accuracy for all:0.208946 test loss: 267.612
65000: ********* epoch 7 ********* test accuracy for mode 0:0.028 test loss: 400.647
65000: ********* epoch 7 ********* test accuracy for mode 1:0.034 test loss: 432.039
65000: ********* epoch 7 ********* test accuracy for mode 2:0.0885 test loss: 291.069
65000: ********* epoch 7 ********* test accuracy for mode 24:0.282 test loss: 250.879
65000: ********* epoch 7 ********* test accuracy for mode 25:0.31 test loss: 238.557
65000: ********* epoch 7 ********* test accuracy for mode 26:0.314 test loss: 187.825
65000: ********* epoch 7 ********* test accuracy for mode 27:0.223 test loss: 266.749
65000: ********* epoch 7 ********* test accuracy for mode 28:0.285 test loss: 252.769
65000: ********* epoch 7 ********* test accuracy for mode 29:0.2625 test loss: 263.759
65000: ********* epoch 7 ********* test accuracy for mode 30:0.157 test loss: 264.425
65000: ********* epoch 7 ********* test accuracy for mode 31:0.1515 test loss: 268.472
65000: ********* epoch 7 ********* test accuracy for mode 32:0.235 test loss: 258.387
65000: ********* epoch 7 ********* test accuracy for mode 33:0.089 test loss: 267.908
65000: ********* epoch 7 ********* test accuracy for mode 34:0.015 test loss: 274.232
65000: ********* epoch 7 ********* test accuracy for mode 35:0.0895 test loss: 419.168
65000: ********* epoch 7 ********* test accuracy for mode 36:0.2355 test loss: 442.557
65020: accuracy:0.3 loss: 243.569 (lr:0.0001)
65040: accuracy:0.23 loss: 243.157 (lr:0.0001)
65060: accuracy:0.24 loss: 250.744 (lr:0.0001)
65080: accuracy:0.19 loss: 237.149 (lr:0.0001)
65100: accuracy:0.22 loss: 253.628 (lr:0.0001)
65120: accuracy:0.22 loss: 246.297 (lr:0.0001)
65140: accuracy:0.25 loss: 244.649 (lr:0.0001)
65160: accuracy:0.28 loss: 221.594 (lr:0.0001)
65180: accuracy:0.23 loss: 245.773 (lr:0.0001)
65200: accuracy:0.23 loss: 235.487 (lr:0.0001)
65220: accuracy:0.27 loss: 239.402 (lr:0.0001)
65240: accuracy:0.19 loss: 245.083 (lr:0.0001)
65260: accuracy:0.23 loss: 230.494 (lr:0.0001)
65280: accuracy:0.2 loss: 252.57 (lr:0.0001)
65300: accuracy:0.26 loss: 244.49 (lr:0.0001)
65320: accuracy:0.29 loss: 232.74 (lr:0.0001)
65340: accuracy:0.32 loss: 242.262 (lr:0.0001)
65360: accuracy:0.23 loss: 272.749 (lr:0.0001)
65380: accuracy:0.23 loss: 243.912 (lr:0.0001)
65400: accuracy:0.24 loss: 241.222 (lr:0.0001)
65420: accuracy:0.18 loss: 258.794 (lr:0.0001)
65440: accuracy:0.22 loss: 233.241 (lr:0.0001)
65460: accuracy:0.27 loss: 244.039 (lr:0.0001)
65480: accuracy:0.27 loss: 245.651 (lr:0.0001)
65500: accuracy:0.25 loss: 238.999 (lr:0.0001)
65520: accuracy:0.25 loss: 247.461 (lr:0.0001)
65540: accuracy:0.26 loss: 259.505 (lr:0.0001)
65560: accuracy:0.17 loss: 266.096 (lr:0.0001)
65580: accuracy:0.24 loss: 249.386 (lr:0.0001)
65600: accuracy:0.26 loss: 242.92 (lr:0.0001)
65620: accuracy:0.28 loss: 245.294 (lr:0.0001)
65640: accuracy:0.26 loss: 244.63 (lr:0.0001)
65660: accuracy:0.23 loss: 251.733 (lr:0.0001)
65680: accuracy:0.26 loss: 231.298 (lr:0.0001)
65700: accuracy:0.21 loss: 253.986 (lr:0.0001)
65720: accuracy:0.2 loss: 279.246 (lr:0.0001)
65740: accuracy:0.32 loss: 237.744 (lr:0.0001)
65760: accuracy:0.31 loss: 251.411 (lr:0.0001)
65780: accuracy:0.34 loss: 220.983 (lr:0.0001)
65800: accuracy:0.3 loss: 250.484 (lr:0.0001)
65820: accuracy:0.24 loss: 236.71 (lr:0.0001)
65840: accuracy:0.32 loss: 226.256 (lr:0.0001)
65860: accuracy:0.23 loss: 241.315 (lr:0.0001)
65880: accuracy:0.19 loss: 264.151 (lr:0.0001)
65900: accuracy:0.25 loss: 219.041 (lr:0.0001)
65920: accuracy:0.2 loss: 273.051 (lr:0.0001)
65940: accuracy:0.22 loss: 258.566 (lr:0.0001)
65960: accuracy:0.21 loss: 244.151 (lr:0.0001)
65980: accuracy:0.21 loss: 235.184 (lr:0.0001)
66000: accuracy:0.19 loss: 248.558 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
66000: ********* epoch 7 ********* test accuracy for all:0.204905 test loss: 269.91
66000: ********* epoch 7 ********* test accuracy for mode 0:0.0295 test loss: 406.32
66000: ********* epoch 7 ********* test accuracy for mode 1:0.028 test loss: 448.3
66000: ********* epoch 7 ********* test accuracy for mode 2:0.0785 test loss: 287.962
66000: ********* epoch 7 ********* test accuracy for mode 24:0.2565 test loss: 265.071
66000: ********* epoch 7 ********* test accuracy for mode 25:0.3125 test loss: 246.544
66000: ********* epoch 7 ********* test accuracy for mode 26:0.287 test loss: 192.97
66000: ********* epoch 7 ********* test accuracy for mode 27:0.2305 test loss: 269.339
66000: ********* epoch 7 ********* test accuracy for mode 28:0.299 test loss: 253.893
66000: ********* epoch 7 ********* test accuracy for mode 29:0.2605 test loss: 264.873
66000: ********* epoch 7 ********* test accuracy for mode 30:0.164 test loss: 264.818
66000: ********* epoch 7 ********* test accuracy for mode 31:0.1545 test loss: 267.1
66000: ********* epoch 7 ********* test accuracy for mode 32:0.235 test loss: 255.475
66000: ********* epoch 7 ********* test accuracy for mode 33:0.125 test loss: 261.562
66000: ********* epoch 7 ********* test accuracy for mode 34:0.019 test loss: 266.211
66000: ********* epoch 7 ********* test accuracy for mode 35:0.0485 test loss: 442.412
66000: ********* epoch 7 ********* test accuracy for mode 36:0.0585 test loss: 481.197
66020: accuracy:0.33 loss: 238.677 (lr:0.0001)
66040: accuracy:0.22 loss: 269.912 (lr:0.0001)
66060: accuracy:0.23 loss: 238.04 (lr:0.0001)
66080: accuracy:0.22 loss: 260.325 (lr:0.0001)
66100: accuracy:0.23 loss: 241.405 (lr:0.0001)
66120: accuracy:0.2 loss: 248.236 (lr:0.0001)
66140: accuracy:0.24 loss: 240.828 (lr:0.0001)
66160: accuracy:0.32 loss: 241.22 (lr:0.0001)
66180: accuracy:0.23 loss: 256.864 (lr:0.0001)
66200: accuracy:0.24 loss: 247.381 (lr:0.0001)
66220: accuracy:0.25 loss: 245.621 (lr:0.0001)
66240: accuracy:0.23 loss: 238.067 (lr:0.0001)
66260: accuracy:0.22 loss: 261.447 (lr:0.0001)
66280: accuracy:0.21 loss: 252.993 (lr:0.0001)
66300: accuracy:0.28 loss: 272.887 (lr:0.0001)
66320: accuracy:0.2 loss: 253.465 (lr:0.0001)
66340: accuracy:0.18 loss: 259.781 (lr:0.0001)
66360: accuracy:0.21 loss: 239.136 (lr:0.0001)
66380: accuracy:0.23 loss: 253.134 (lr:0.0001)
66400: accuracy:0.23 loss: 227.356 (lr:0.0001)
66420: accuracy:0.2 loss: 243.256 (lr:0.0001)
66440: accuracy:0.21 loss: 253.106 (lr:0.0001)
66460: accuracy:0.21 loss: 260.852 (lr:0.0001)
66480: accuracy:0.34 loss: 223.728 (lr:0.0001)
66500: accuracy:0.3 loss: 230.437 (lr:0.0001)
66520: accuracy:0.25 loss: 256.428 (lr:0.0001)
66540: accuracy:0.19 loss: 260.38 (lr:0.0001)
66560: accuracy:0.26 loss: 254.829 (lr:0.0001)
66580: accuracy:0.21 loss: 233.752 (lr:0.0001)
66600: accuracy:0.21 loss: 257.454 (lr:0.0001)
66620: accuracy:0.21 loss: 245.123 (lr:0.0001)
66640: accuracy:0.18 loss: 249.077 (lr:0.0001)
66660: accuracy:0.27 loss: 223.837 (lr:0.0001)
66680: accuracy:0.33 loss: 248.213 (lr:0.0001)
66700: accuracy:0.23 loss: 248.802 (lr:0.0001)
66720: accuracy:0.22 loss: 272.893 (lr:0.0001)
66740: accuracy:0.23 loss: 277.007 (lr:0.0001)
66760: accuracy:0.29 loss: 238.524 (lr:0.0001)
66780: accuracy:0.28 loss: 256.307 (lr:0.0001)
66800: accuracy:0.21 loss: 243.816 (lr:0.0001)
66820: accuracy:0.25 loss: 253.877 (lr:0.0001)
66840: accuracy:0.25 loss: 250.722 (lr:0.0001)
66860: accuracy:0.26 loss: 247.408 (lr:0.0001)
66880: accuracy:0.3 loss: 247.136 (lr:0.0001)
66900: accuracy:0.21 loss: 251.189 (lr:0.0001)
66920: accuracy:0.23 loss: 266.074 (lr:0.0001)
66940: accuracy:0.2 loss: 251.633 (lr:0.0001)
66960: accuracy:0.25 loss: 257.519 (lr:0.0001)
66980: accuracy:0.21 loss: 250.501 (lr:0.0001)
67000: accuracy:0.26 loss: 254.61 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
67000: ********* epoch 7 ********* test accuracy for all:0.204081 test loss: 270.936
67000: ********* epoch 7 ********* test accuracy for mode 0:0.0355 test loss: 405.079
67000: ********* epoch 7 ********* test accuracy for mode 1:0.028 test loss: 447.181
67000: ********* epoch 7 ********* test accuracy for mode 2:0.087 test loss: 285.52
67000: ********* epoch 7 ********* test accuracy for mode 24:0.229 test loss: 273.16
67000: ********* epoch 7 ********* test accuracy for mode 25:0.3175 test loss: 254.531
67000: ********* epoch 7 ********* test accuracy for mode 26:0.301 test loss: 196.484
67000: ********* epoch 7 ********* test accuracy for mode 27:0.2085 test loss: 281.269
67000: ********* epoch 7 ********* test accuracy for mode 28:0.2745 test loss: 263.5
67000: ********* epoch 7 ********* test accuracy for mode 29:0.28 test loss: 268.926
67000: ********* epoch 7 ********* test accuracy for mode 30:0.1475 test loss: 267.384
67000: ********* epoch 7 ********* test accuracy for mode 31:0.1675 test loss: 266.724
67000: ********* epoch 7 ********* test accuracy for mode 32:0.2365 test loss: 254.784
67000: ********* epoch 7 ********* test accuracy for mode 33:0.121 test loss: 260.189
67000: ********* epoch 7 ********* test accuracy for mode 34:0.035 test loss: 263.141
67000: ********* epoch 7 ********* test accuracy for mode 35:0.0595 test loss: 443.397
67000: ********* epoch 7 ********* test accuracy for mode 36:0.04 test loss: 485.504
67020: accuracy:0.21 loss: 261.973 (lr:0.0001)
67040: accuracy:0.23 loss: 234.403 (lr:0.0001)
67060: accuracy:0.21 loss: 250.729 (lr:0.0001)
67080: accuracy:0.23 loss: 250.235 (lr:0.0001)
67100: accuracy:0.24 loss: 247.38 (lr:0.0001)
67120: accuracy:0.28 loss: 243.208 (lr:0.0001)
67140: accuracy:0.27 loss: 241.94 (lr:0.0001)
67160: accuracy:0.26 loss: 243.614 (lr:0.0001)
67180: accuracy:0.17 loss: 283.204 (lr:0.0001)
67200: accuracy:0.23 loss: 249.956 (lr:0.0001)
67220: accuracy:0.29 loss: 243.682 (lr:0.0001)
67240: accuracy:0.3 loss: 262.521 (lr:0.0001)
67260: accuracy:0.29 loss: 238.554 (lr:0.0001)
67280: accuracy:0.25 loss: 256.357 (lr:0.0001)
67300: accuracy:0.2 loss: 257.122 (lr:0.0001)
67320: accuracy:0.22 loss: 255.89 (lr:0.0001)
67340: accuracy:0.3 loss: 242.872 (lr:0.0001)
67360: accuracy:0.21 loss: 243.929 (lr:0.0001)
67380: accuracy:0.34 loss: 245.691 (lr:0.0001)
67400: accuracy:0.22 loss: 247.943 (lr:0.0001)
67420: accuracy:0.27 loss: 242.462 (lr:0.0001)
67440: accuracy:0.23 loss: 236.411 (lr:0.0001)
67460: accuracy:0.33 loss: 248.584 (lr:0.0001)
67480: accuracy:0.28 loss: 259.625 (lr:0.0001)
67500: accuracy:0.21 loss: 248.343 (lr:0.0001)
67520: accuracy:0.19 loss: 255.191 (lr:0.0001)
67540: accuracy:0.21 loss: 236.318 (lr:0.0001)
67560: accuracy:0.25 loss: 265.022 (lr:0.0001)
67580: accuracy:0.17 loss: 241.406 (lr:0.0001)
67600: accuracy:0.25 loss: 246.955 (lr:0.0001)
67620: accuracy:0.27 loss: 225.951 (lr:0.0001)
67640: accuracy:0.24 loss: 251.915 (lr:0.0001)
67660: accuracy:0.21 loss: 224.336 (lr:0.0001)
67680: accuracy:0.34 loss: 234.388 (lr:0.0001)
67700: accuracy:0.18 loss: 267.777 (lr:0.0001)
67720: accuracy:0.24 loss: 239.24 (lr:0.0001)
67740: accuracy:0.18 loss: 241.583 (lr:0.0001)
67760: accuracy:0.21 loss: 252.982 (lr:0.0001)
67780: accuracy:0.18 loss: 255.183 (lr:0.0001)
67800: accuracy:0.26 loss: 235.771 (lr:0.0001)
67820: accuracy:0.22 loss: 236.864 (lr:0.0001)
67840: accuracy:0.29 loss: 232.222 (lr:0.0001)
67860: accuracy:0.23 loss: 242.076 (lr:0.0001)
67880: accuracy:0.16 loss: 262.992 (lr:0.0001)
67900: accuracy:0.25 loss: 218.451 (lr:0.0001)
67920: accuracy:0.13 loss: 252.642 (lr:0.0001)
67940: accuracy:0.22 loss: 248.317 (lr:0.0001)
67960: accuracy:0.2 loss: 256.264 (lr:0.0001)
67980: accuracy:0.23 loss: 256.437 (lr:0.0001)
68000: accuracy:0.35 loss: 233.209 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
68000: ********* epoch 7 ********* test accuracy for all:0.201892 test loss: 270.171
68000: ********* epoch 7 ********* test accuracy for mode 0:0.03 test loss: 402.552
68000: ********* epoch 7 ********* test accuracy for mode 1:0.053 test loss: 433.882
68000: ********* epoch 7 ********* test accuracy for mode 2:0.058 test loss: 293.844
68000: ********* epoch 7 ********* test accuracy for mode 24:0.24 test loss: 268.505
68000: ********* epoch 7 ********* test accuracy for mode 25:0.224 test loss: 260.392
68000: ********* epoch 7 ********* test accuracy for mode 26:0.458 test loss: 186.563
68000: ********* epoch 7 ********* test accuracy for mode 27:0.1875 test loss: 280.555
68000: ********* epoch 7 ********* test accuracy for mode 28:0.252 test loss: 264.097
68000: ********* epoch 7 ********* test accuracy for mode 29:0.277 test loss: 271.986
68000: ********* epoch 7 ********* test accuracy for mode 30:0.135 test loss: 275.367
68000: ********* epoch 7 ********* test accuracy for mode 31:0.162 test loss: 275.176
68000: ********* epoch 7 ********* test accuracy for mode 32:0.2205 test loss: 263.706
68000: ********* epoch 7 ********* test accuracy for mode 33:0.1155 test loss: 271.274
68000: ********* epoch 7 ********* test accuracy for mode 34:0.0225 test loss: 274.022
68000: ********* epoch 7 ********* test accuracy for mode 35:0.1215 test loss: 413.045
68000: ********* epoch 7 ********* test accuracy for mode 36:0.075 test loss: 442.004
68020: accuracy:0.29 loss: 232.841 (lr:0.0001)
68040: accuracy:0.34 loss: 246.269 (lr:0.0001)
68060: accuracy:0.22 loss: 256.071 (lr:0.0001)
68080: accuracy:0.2 loss: 245.752 (lr:0.0001)
68100: accuracy:0.25 loss: 219.462 (lr:0.0001)
68120: accuracy:0.33 loss: 235.32 (lr:0.0001)
68140: accuracy:0.28 loss: 264.88 (lr:0.0001)
68160: accuracy:0.24 loss: 254.482 (lr:0.0001)
68180: accuracy:0.2 loss: 245.155 (lr:0.0001)
68200: accuracy:0.28 loss: 231.66 (lr:0.0001)
68220: accuracy:0.2 loss: 249.544 (lr:0.0001)
68240: accuracy:0.2 loss: 263.924 (lr:0.0001)
68260: accuracy:0.22 loss: 251.895 (lr:0.0001)
68280: accuracy:0.27 loss: 236.398 (lr:0.0001)
68300: accuracy:0.22 loss: 262.871 (lr:0.0001)
68320: accuracy:0.27 loss: 224.601 (lr:0.0001)
68340: accuracy:0.24 loss: 253.016 (lr:0.0001)
68360: accuracy:0.21 loss: 277.022 (lr:0.0001)
68380: accuracy:0.22 loss: 245.135 (lr:0.0001)
68400: accuracy:0.19 loss: 244.501 (lr:0.0001)
68420: accuracy:0.16 loss: 251.221 (lr:0.0001)
68440: accuracy:0.19 loss: 265.426 (lr:0.0001)
68460: accuracy:0.22 loss: 231.7 (lr:0.0001)
68480: accuracy:0.3 loss: 248.256 (lr:0.0001)
68500: accuracy:0.18 loss: 280.622 (lr:0.0001)
68520: accuracy:0.15 loss: 279.975 (lr:0.0001)
68540: accuracy:0.23 loss: 251.495 (lr:0.0001)
68560: accuracy:0.28 loss: 238.059 (lr:0.0001)
68580: accuracy:0.15 loss: 255.556 (lr:0.0001)
68600: accuracy:0.2 loss: 253.229 (lr:0.0001)
68620: accuracy:0.23 loss: 258.83 (lr:0.0001)
68640: accuracy:0.2 loss: 253.737 (lr:0.0001)
68660: accuracy:0.21 loss: 249.735 (lr:0.0001)
68680: accuracy:0.26 loss: 240.648 (lr:0.0001)
68700: accuracy:0.19 loss: 246.385 (lr:0.0001)
68720: accuracy:0.28 loss: 245.081 (lr:0.0001)
68740: accuracy:0.25 loss: 240.787 (lr:0.0001)
68760: accuracy:0.17 loss: 253.461 (lr:0.0001)
68780: accuracy:0.22 loss: 264.728 (lr:0.0001)
68800: accuracy:0.19 loss: 266.817 (lr:0.0001)
68820: accuracy:0.19 loss: 245.746 (lr:0.0001)
68840: accuracy:0.2 loss: 240.407 (lr:0.0001)
68860: accuracy:0.16 loss: 269.408 (lr:0.0001)
68880: accuracy:0.26 loss: 233.436 (lr:0.0001)
68900: accuracy:0.19 loss: 240.203 (lr:0.0001)
68920: accuracy:0.19 loss: 255.754 (lr:0.0001)
68940: accuracy:0.22 loss: 251.797 (lr:0.0001)
68960: accuracy:0.24 loss: 229.181 (lr:0.0001)
68980: accuracy:0.3 loss: 235.123 (lr:0.0001)
69000: accuracy:0.27 loss: 238.732 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
69000: ********* epoch 8 ********* test accuracy for all:0.204635 test loss: 270.25
69000: ********* epoch 8 ********* test accuracy for mode 0:0.034 test loss: 404.205
69000: ********* epoch 8 ********* test accuracy for mode 1:0.0315 test loss: 444.81
69000: ********* epoch 8 ********* test accuracy for mode 2:0.06 test loss: 293.096
69000: ********* epoch 8 ********* test accuracy for mode 24:0.2335 test loss: 263.016
69000: ********* epoch 8 ********* test accuracy for mode 25:0.307 test loss: 249.58
69000: ********* epoch 8 ********* test accuracy for mode 26:0.323 test loss: 192.328
69000: ********* epoch 8 ********* test accuracy for mode 27:0.204 test loss: 279.072
69000: ********* epoch 8 ********* test accuracy for mode 28:0.267 test loss: 265.618
69000: ********* epoch 8 ********* test accuracy for mode 29:0.2445 test loss: 274.93
69000: ********* epoch 8 ********* test accuracy for mode 30:0.147 test loss: 272.983
69000: ********* epoch 8 ********* test accuracy for mode 31:0.152 test loss: 273.143
69000: ********* epoch 8 ********* test accuracy for mode 32:0.2135 test loss: 261.641
69000: ********* epoch 8 ********* test accuracy for mode 33:0.139 test loss: 263.427
69000: ********* epoch 8 ********* test accuracy for mode 34:0.0285 test loss: 266.89
69000: ********* epoch 8 ********* test accuracy for mode 35:0.099 test loss: 426.359
69000: ********* epoch 8 ********* test accuracy for mode 36:0.0755 test loss: 455.125
69020: accuracy:0.12 loss: 276.199 (lr:0.0001)
69040: accuracy:0.23 loss: 261.818 (lr:0.0001)
69060: accuracy:0.14 loss: 259.133 (lr:0.0001)
69080: accuracy:0.26 loss: 251.981 (lr:0.0001)
69100: accuracy:0.22 loss: 253.773 (lr:0.0001)
69120: accuracy:0.24 loss: 261.079 (lr:0.0001)
69140: accuracy:0.26 loss: 229.092 (lr:0.0001)
69160: accuracy:0.3 loss: 245.674 (lr:0.0001)
69180: accuracy:0.15 loss: 255.061 (lr:0.0001)
69200: accuracy:0.25 loss: 267.284 (lr:0.0001)
69220: accuracy:0.3 loss: 236.016 (lr:0.0001)
69240: accuracy:0.24 loss: 257.184 (lr:0.0001)
69260: accuracy:0.32 loss: 210.757 (lr:0.0001)
69280: accuracy:0.23 loss: 235.222 (lr:0.0001)
69300: accuracy:0.2 loss: 249.28 (lr:0.0001)
69320: accuracy:0.24 loss: 235.811 (lr:0.0001)
69340: accuracy:0.27 loss: 233.391 (lr:0.0001)
69360: accuracy:0.17 loss: 246.776 (lr:0.0001)
69380: accuracy:0.18 loss: 254.39 (lr:0.0001)
69400: accuracy:0.26 loss: 244.086 (lr:0.0001)
69420: accuracy:0.28 loss: 246.075 (lr:0.0001)
69440: accuracy:0.27 loss: 250.293 (lr:0.0001)
69460: accuracy:0.27 loss: 246.469 (lr:0.0001)
69480: accuracy:0.26 loss: 250.123 (lr:0.0001)
69500: accuracy:0.17 loss: 238.936 (lr:0.0001)
69520: accuracy:0.23 loss: 252.775 (lr:0.0001)
69540: accuracy:0.23 loss: 236.524 (lr:0.0001)
69560: accuracy:0.22 loss: 233.514 (lr:0.0001)
69580: accuracy:0.26 loss: 263.707 (lr:0.0001)
69600: accuracy:0.25 loss: 265.504 (lr:0.0001)
69620: accuracy:0.27 loss: 247.381 (lr:0.0001)
69640: accuracy:0.22 loss: 262.202 (lr:0.0001)
69660: accuracy:0.22 loss: 255.37 (lr:0.0001)
69680: accuracy:0.27 loss: 252.838 (lr:0.0001)
69700: accuracy:0.27 loss: 245.103 (lr:0.0001)
69720: accuracy:0.23 loss: 230.698 (lr:0.0001)
69740: accuracy:0.24 loss: 254.106 (lr:0.0001)
69760: accuracy:0.22 loss: 250.786 (lr:0.0001)
69780: accuracy:0.25 loss: 264.105 (lr:0.0001)
69800: accuracy:0.23 loss: 241.505 (lr:0.0001)
69820: accuracy:0.29 loss: 239.675 (lr:0.0001)
69840: accuracy:0.21 loss: 252.139 (lr:0.0001)
69860: accuracy:0.27 loss: 228.534 (lr:0.0001)
69880: accuracy:0.26 loss: 227.923 (lr:0.0001)
69900: accuracy:0.21 loss: 252.147 (lr:0.0001)
69920: accuracy:0.22 loss: 239.003 (lr:0.0001)
69940: accuracy:0.33 loss: 232.468 (lr:0.0001)
69960: accuracy:0.27 loss: 235.893 (lr:0.0001)
69980: accuracy:0.24 loss: 247.612 (lr:0.0001)
70000: accuracy:0.26 loss: 240.153 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
70000: ********* epoch 8 ********* test accuracy for all:0.202338 test loss: 273.005
70000: ********* epoch 8 ********* test accuracy for mode 0:0.0365 test loss: 405.313
70000: ********* epoch 8 ********* test accuracy for mode 1:0.025 test loss: 450.883
70000: ********* epoch 8 ********* test accuracy for mode 2:0.065 test loss: 286.93
70000: ********* epoch 8 ********* test accuracy for mode 24:0.235 test loss: 282.6
70000: ********* epoch 8 ********* test accuracy for mode 25:0.2715 test loss: 266.798
70000: ********* epoch 8 ********* test accuracy for mode 26:0.325 test loss: 196.403
70000: ********* epoch 8 ********* test accuracy for mode 27:0.2345 test loss: 285.382
70000: ********* epoch 8 ********* test accuracy for mode 28:0.257 test loss: 269.226
70000: ********* epoch 8 ********* test accuracy for mode 29:0.253 test loss: 274.877
70000: ********* epoch 8 ********* test accuracy for mode 30:0.175 test loss: 267.984
70000: ********* epoch 8 ********* test accuracy for mode 31:0.169 test loss: 266.065
70000: ********* epoch 8 ********* test accuracy for mode 32:0.243 test loss: 252.817
70000: ********* epoch 8 ********* test accuracy for mode 33:0.161 test loss: 256.047
70000: ********* epoch 8 ********* test accuracy for mode 34:0.018 test loss: 265.154
70000: ********* epoch 8 ********* test accuracy for mode 35:0.0705 test loss: 444.388
70000: ********* epoch 8 ********* test accuracy for mode 36:0.057 test loss: 487.667
70020: accuracy:0.34 loss: 217.407 (lr:0.0001)
70040: accuracy:0.26 loss: 219.333 (lr:0.0001)
70060: accuracy:0.23 loss: 250.991 (lr:0.0001)
70080: accuracy:0.25 loss: 239.01 (lr:0.0001)
70100: accuracy:0.18 loss: 253.083 (lr:0.0001)
70120: accuracy:0.21 loss: 269.864 (lr:0.0001)
70140: accuracy:0.23 loss: 289.109 (lr:0.0001)
70160: accuracy:0.24 loss: 250.812 (lr:0.0001)
70180: accuracy:0.22 loss: 238.491 (lr:0.0001)
70200: accuracy:0.24 loss: 250.267 (lr:0.0001)
70220: accuracy:0.24 loss: 234.984 (lr:0.0001)
70240: accuracy:0.26 loss: 239.459 (lr:0.0001)
70260: accuracy:0.29 loss: 230.436 (lr:0.0001)
70280: accuracy:0.22 loss: 257.323 (lr:0.0001)
70300: accuracy:0.36 loss: 230.743 (lr:0.0001)
70320: accuracy:0.2 loss: 265.951 (lr:0.0001)
70340: accuracy:0.17 loss: 261.94 (lr:0.0001)
70360: accuracy:0.32 loss: 242.445 (lr:0.0001)
70380: accuracy:0.28 loss: 231.97 (lr:0.0001)
70400: accuracy:0.25 loss: 246.017 (lr:0.0001)
70420: accuracy:0.16 loss: 254.316 (lr:0.0001)
70440: accuracy:0.27 loss: 245.328 (lr:0.0001)
70460: accuracy:0.22 loss: 243.182 (lr:0.0001)
70480: accuracy:0.3 loss: 232.169 (lr:0.0001)
70500: accuracy:0.25 loss: 247.364 (lr:0.0001)
70520: accuracy:0.2 loss: 258.124 (lr:0.0001)
70540: accuracy:0.21 loss: 247.218 (lr:0.0001)
70560: accuracy:0.22 loss: 261.612 (lr:0.0001)
70580: accuracy:0.25 loss: 244.295 (lr:0.0001)
70600: accuracy:0.21 loss: 261.121 (lr:0.0001)
70620: accuracy:0.21 loss: 247.555 (lr:0.0001)
70640: accuracy:0.33 loss: 232.261 (lr:0.0001)
70660: accuracy:0.29 loss: 252.332 (lr:0.0001)
70680: accuracy:0.19 loss: 256.79 (lr:0.0001)
70700: accuracy:0.34 loss: 244.575 (lr:0.0001)
70720: accuracy:0.27 loss: 243.494 (lr:0.0001)
70740: accuracy:0.31 loss: 250.987 (lr:0.0001)
70760: accuracy:0.29 loss: 251.15 (lr:0.0001)
70780: accuracy:0.34 loss: 227.444 (lr:0.0001)
70800: accuracy:0.24 loss: 234.541 (lr:0.0001)
70820: accuracy:0.26 loss: 240.492 (lr:0.0001)
70840: accuracy:0.22 loss: 268.427 (lr:0.0001)
70860: accuracy:0.29 loss: 231.886 (lr:0.0001)
70880: accuracy:0.26 loss: 230.06 (lr:0.0001)
70900: accuracy:0.27 loss: 252.696 (lr:0.0001)
70920: accuracy:0.32 loss: 239.994 (lr:0.0001)
70940: accuracy:0.16 loss: 263.694 (lr:0.0001)
70960: accuracy:0.24 loss: 242.77 (lr:0.0001)
70980: accuracy:0.22 loss: 249.697 (lr:0.0001)
71000: accuracy:0.26 loss: 246.963 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
71000: ********* epoch 8 ********* test accuracy for all:0.203973 test loss: 270.982
71000: ********* epoch 8 ********* test accuracy for mode 0:0.038 test loss: 402.421
71000: ********* epoch 8 ********* test accuracy for mode 1:0.0285 test loss: 448.457
71000: ********* epoch 8 ********* test accuracy for mode 2:0.0875 test loss: 284.737
71000: ********* epoch 8 ********* test accuracy for mode 24:0.253 test loss: 266.452
71000: ********* epoch 8 ********* test accuracy for mode 25:0.3095 test loss: 251.144
71000: ********* epoch 8 ********* test accuracy for mode 26:0.2785 test loss: 196.128
71000: ********* epoch 8 ********* test accuracy for mode 27:0.2245 test loss: 275.113
71000: ********* epoch 8 ********* test accuracy for mode 28:0.2515 test loss: 261.889
71000: ********* epoch 8 ********* test accuracy for mode 29:0.2815 test loss: 262.799
71000: ********* epoch 8 ********* test accuracy for mode 30:0.1685 test loss: 261.32
71000: ********* epoch 8 ********* test accuracy for mode 31:0.178 test loss: 260.328
71000: ********* epoch 8 ********* test accuracy for mode 32:0.2295 test loss: 249.921
71000: ********* epoch 8 ********* test accuracy for mode 33:0.159 test loss: 253.58
71000: ********* epoch 8 ********* test accuracy for mode 34:0.0105 test loss: 265.316
71000: ********* epoch 8 ********* test accuracy for mode 35:0.063 test loss: 448.882
71000: ********* epoch 8 ********* test accuracy for mode 36:0.0585 test loss: 485.765
71020: accuracy:0.21 loss: 269.092 (lr:0.0001)
71040: accuracy:0.26 loss: 226.319 (lr:0.0001)
71060: accuracy:0.22 loss: 236.183 (lr:0.0001)
71080: accuracy:0.23 loss: 254.619 (lr:0.0001)
71100: accuracy:0.26 loss: 239.599 (lr:0.0001)
71120: accuracy:0.27 loss: 229.218 (lr:0.0001)
71140: accuracy:0.25 loss: 247.595 (lr:0.0001)
71160: accuracy:0.27 loss: 239.858 (lr:0.0001)
71180: accuracy:0.33 loss: 221.689 (lr:0.0001)
71200: accuracy:0.16 loss: 249.568 (lr:0.0001)
71220: accuracy:0.23 loss: 235.603 (lr:0.0001)
71240: accuracy:0.15 loss: 253.357 (lr:0.0001)
71260: accuracy:0.25 loss: 239.216 (lr:0.0001)
71280: accuracy:0.23 loss: 248.699 (lr:0.0001)
71300: accuracy:0.19 loss: 246.76 (lr:0.0001)
71320: accuracy:0.19 loss: 252.363 (lr:0.0001)
71340: accuracy:0.17 loss: 244.825 (lr:0.0001)
71360: accuracy:0.26 loss: 246.087 (lr:0.0001)
71380: accuracy:0.28 loss: 231.923 (lr:0.0001)
71400: accuracy:0.15 loss: 258.682 (lr:0.0001)
71420: accuracy:0.26 loss: 254.471 (lr:0.0001)
71440: accuracy:0.3 loss: 228.645 (lr:0.0001)
71460: accuracy:0.23 loss: 236.521 (lr:0.0001)
71480: accuracy:0.18 loss: 246.165 (lr:0.0001)
71500: accuracy:0.21 loss: 275.098 (lr:0.0001)
71520: accuracy:0.22 loss: 262.511 (lr:0.0001)
71540: accuracy:0.2 loss: 249.67 (lr:0.0001)
71560: accuracy:0.3 loss: 224.737 (lr:0.0001)
71580: accuracy:0.25 loss: 231.897 (lr:0.0001)
71600: accuracy:0.29 loss: 242.316 (lr:0.0001)
71620: accuracy:0.18 loss: 252.899 (lr:0.0001)
71640: accuracy:0.28 loss: 236.334 (lr:0.0001)
71660: accuracy:0.24 loss: 254.509 (lr:0.0001)
71680: accuracy:0.25 loss: 256.003 (lr:0.0001)
71700: accuracy:0.25 loss: 238.632 (lr:0.0001)
71720: accuracy:0.24 loss: 228.076 (lr:0.0001)
71740: accuracy:0.29 loss: 240.725 (lr:0.0001)
71760: accuracy:0.25 loss: 244.607 (lr:0.0001)
71780: accuracy:0.25 loss: 248.615 (lr:0.0001)
71800: accuracy:0.21 loss: 256.443 (lr:0.0001)
71820: accuracy:0.26 loss: 246.13 (lr:0.0001)
71840: accuracy:0.24 loss: 265.76 (lr:0.0001)
71860: accuracy:0.24 loss: 244.025 (lr:0.0001)
71880: accuracy:0.25 loss: 252.556 (lr:0.0001)
71900: accuracy:0.25 loss: 269.821 (lr:0.0001)
71920: accuracy:0.28 loss: 248.164 (lr:0.0001)
71940: accuracy:0.3 loss: 239.922 (lr:0.0001)
71960: accuracy:0.27 loss: 242.245 (lr:0.0001)
71980: accuracy:0.33 loss: 241.252 (lr:0.0001)
72000: accuracy:0.24 loss: 251.96 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
72000: ********* epoch 8 ********* test accuracy for all:0.209473 test loss: 268.308
72000: ********* epoch 8 ********* test accuracy for mode 0:0.039 test loss: 400.346
72000: ********* epoch 8 ********* test accuracy for mode 1:0.0315 test loss: 440.465
72000: ********* epoch 8 ********* test accuracy for mode 2:0.0715 test loss: 287.223
72000: ********* epoch 8 ********* test accuracy for mode 24:0.2495 test loss: 266.046
72000: ********* epoch 8 ********* test accuracy for mode 25:0.2855 test loss: 246.578
72000: ********* epoch 8 ********* test accuracy for mode 26:0.3625 test loss: 185.636
72000: ********* epoch 8 ********* test accuracy for mode 27:0.2605 test loss: 260.772
72000: ********* epoch 8 ********* test accuracy for mode 28:0.289 test loss: 248.068
72000: ********* epoch 8 ********* test accuracy for mode 29:0.28 test loss: 256.779
72000: ********* epoch 8 ********* test accuracy for mode 30:0.1955 test loss: 255.389
72000: ********* epoch 8 ********* test accuracy for mode 31:0.18 test loss: 260.576
72000: ********* epoch 8 ********* test accuracy for mode 32:0.2045 test loss: 253.54
72000: ********* epoch 8 ********* test accuracy for mode 33:0.163 test loss: 255.943
72000: ********* epoch 8 ********* test accuracy for mode 34:0.0185 test loss: 266.679
72000: ********* epoch 8 ********* test accuracy for mode 35:0.0805 test loss: 428.573
72000: ********* epoch 8 ********* test accuracy for mode 36:0.108 test loss: 449.697
72020: accuracy:0.24 loss: 253.118 (lr:0.0001)
72040: accuracy:0.19 loss: 279.288 (lr:0.0001)
72060: accuracy:0.21 loss: 287.092 (lr:0.0001)
72080: accuracy:0.34 loss: 214.71 (lr:0.0001)
72100: accuracy:0.21 loss: 254.091 (lr:0.0001)
72120: accuracy:0.23 loss: 242.825 (lr:0.0001)
72140: accuracy:0.43 loss: 219.038 (lr:0.0001)
72160: accuracy:0.3 loss: 229.892 (lr:0.0001)
72180: accuracy:0.25 loss: 233.739 (lr:0.0001)
72200: accuracy:0.26 loss: 232.651 (lr:0.0001)
72220: accuracy:0.24 loss: 256.433 (lr:0.0001)
72240: accuracy:0.23 loss: 243.486 (lr:0.0001)
72260: accuracy:0.22 loss: 238.802 (lr:0.0001)
72280: accuracy:0.14 loss: 260.999 (lr:0.0001)
72300: accuracy:0.2 loss: 252.743 (lr:0.0001)
72320: accuracy:0.19 loss: 237.658 (lr:0.0001)
72340: accuracy:0.27 loss: 242.325 (lr:0.0001)
72360: accuracy:0.27 loss: 244.419 (lr:0.0001)
72380: accuracy:0.24 loss: 248.586 (lr:0.0001)
72400: accuracy:0.23 loss: 250.684 (lr:0.0001)
72420: accuracy:0.21 loss: 264.726 (lr:0.0001)
72440: accuracy:0.24 loss: 238.809 (lr:0.0001)
72460: accuracy:0.26 loss: 233.854 (lr:0.0001)
72480: accuracy:0.2 loss: 237.761 (lr:0.0001)
72500: accuracy:0.2 loss: 238.222 (lr:0.0001)
72520: accuracy:0.21 loss: 256.064 (lr:0.0001)
72540: accuracy:0.1 loss: 250.04 (lr:0.0001)
72560: accuracy:0.22 loss: 236.4 (lr:0.0001)
72580: accuracy:0.24 loss: 250.469 (lr:0.0001)
72600: accuracy:0.26 loss: 234.951 (lr:0.0001)
72620: accuracy:0.24 loss: 243.703 (lr:0.0001)
72640: accuracy:0.22 loss: 259.742 (lr:0.0001)
72660: accuracy:0.25 loss: 230.375 (lr:0.0001)
72680: accuracy:0.31 loss: 237.528 (lr:0.0001)
72700: accuracy:0.26 loss: 240.857 (lr:0.0001)
72720: accuracy:0.25 loss: 258.061 (lr:0.0001)
72740: accuracy:0.21 loss: 257.542 (lr:0.0001)
72760: accuracy:0.23 loss: 251.023 (lr:0.0001)
72780: accuracy:0.29 loss: 217.216 (lr:0.0001)
72800: accuracy:0.26 loss: 241.311 (lr:0.0001)
72820: accuracy:0.26 loss: 245.226 (lr:0.0001)
72840: accuracy:0.18 loss: 243.453 (lr:0.0001)
72860: accuracy:0.29 loss: 254.902 (lr:0.0001)
72880: accuracy:0.22 loss: 249.178 (lr:0.0001)
72900: accuracy:0.23 loss: 234.44 (lr:0.0001)
72920: accuracy:0.23 loss: 246.737 (lr:0.0001)
72940: accuracy:0.27 loss: 252.839 (lr:0.0001)
72960: accuracy:0.32 loss: 231.632 (lr:0.0001)
72980: accuracy:0.27 loss: 217.369 (lr:0.0001)
73000: accuracy:0.17 loss: 273.454 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
73000: ********* epoch 8 ********* test accuracy for all:0.210919 test loss: 266.959
73000: ********* epoch 8 ********* test accuracy for mode 0:0.0355 test loss: 402.171
73000: ********* epoch 8 ********* test accuracy for mode 1:0.0305 test loss: 441.472
73000: ********* epoch 8 ********* test accuracy for mode 2:0.0865 test loss: 286.326
73000: ********* epoch 8 ********* test accuracy for mode 24:0.2325 test loss: 264.656
73000: ********* epoch 8 ********* test accuracy for mode 25:0.284 test loss: 246.027
73000: ********* epoch 8 ********* test accuracy for mode 26:0.349 test loss: 186.022
73000: ********* epoch 8 ********* test accuracy for mode 27:0.241 test loss: 263.374
73000: ********* epoch 8 ********* test accuracy for mode 28:0.2985 test loss: 247.386
73000: ********* epoch 8 ********* test accuracy for mode 29:0.255 test loss: 258.34
73000: ********* epoch 8 ********* test accuracy for mode 30:0.1855 test loss: 257.024
73000: ********* epoch 8 ********* test accuracy for mode 31:0.1815 test loss: 259.66
73000: ********* epoch 8 ********* test accuracy for mode 32:0.211 test loss: 251.773
73000: ********* epoch 8 ********* test accuracy for mode 33:0.1655 test loss: 255.207
73000: ********* epoch 8 ********* test accuracy for mode 34:0.0215 test loss: 264.173
73000: ********* epoch 8 ********* test accuracy for mode 35:0.1015 test loss: 423.317
73000: ********* epoch 8 ********* test accuracy for mode 36:0.1435 test loss: 444.021
73020: accuracy:0.24 loss: 258.027 (lr:0.0001)
73040: accuracy:0.25 loss: 254.219 (lr:0.0001)
73060: accuracy:0.2 loss: 247.036 (lr:0.0001)
73080: accuracy:0.25 loss: 239.497 (lr:0.0001)
73100: accuracy:0.26 loss: 248.835 (lr:0.0001)
73120: accuracy:0.2 loss: 234.762 (lr:0.0001)
73140: accuracy:0.23 loss: 245.04 (lr:0.0001)
73160: accuracy:0.22 loss: 249.666 (lr:0.0001)
73180: accuracy:0.21 loss: 241.719 (lr:0.0001)
73200: accuracy:0.26 loss: 254.416 (lr:0.0001)
73220: accuracy:0.28 loss: 218.989 (lr:0.0001)
73240: accuracy:0.27 loss: 244.747 (lr:0.0001)
73260: accuracy:0.24 loss: 264.766 (lr:0.0001)
73280: accuracy:0.26 loss: 239.423 (lr:0.0001)
73300: accuracy:0.2 loss: 250.484 (lr:0.0001)
73320: accuracy:0.28 loss: 224.099 (lr:0.0001)
73340: accuracy:0.11 loss: 256.254 (lr:0.0001)
73360: accuracy:0.23 loss: 245.256 (lr:0.0001)
73380: accuracy:0.3 loss: 237.074 (lr:0.0001)
73400: accuracy:0.26 loss: 250.143 (lr:0.0001)
73420: accuracy:0.2 loss: 267.299 (lr:0.0001)
73440: accuracy:0.24 loss: 233.044 (lr:0.0001)
73460: accuracy:0.25 loss: 230.809 (lr:0.0001)
73480: accuracy:0.17 loss: 261.661 (lr:0.0001)
73500: accuracy:0.25 loss: 251.194 (lr:0.0001)
73520: accuracy:0.19 loss: 251.384 (lr:0.0001)
73540: accuracy:0.26 loss: 238.539 (lr:0.0001)
73560: accuracy:0.31 loss: 227.232 (lr:0.0001)
73580: accuracy:0.23 loss: 236.211 (lr:0.0001)
73600: accuracy:0.22 loss: 256.499 (lr:0.0001)
73620: accuracy:0.26 loss: 232.854 (lr:0.0001)
73640: accuracy:0.18 loss: 261.264 (lr:0.0001)
73660: accuracy:0.22 loss: 244.451 (lr:0.0001)
73680: accuracy:0.27 loss: 239.68 (lr:0.0001)
73700: accuracy:0.34 loss: 221.219 (lr:0.0001)
73720: accuracy:0.24 loss: 238.048 (lr:0.0001)
73740: accuracy:0.25 loss: 233.527 (lr:0.0001)
73760: accuracy:0.25 loss: 241.123 (lr:0.0001)
73780: accuracy:0.26 loss: 253.126 (lr:0.0001)
73800: accuracy:0.22 loss: 264.378 (lr:0.0001)
73820: accuracy:0.26 loss: 236.12 (lr:0.0001)
73840: accuracy:0.27 loss: 252.56 (lr:0.0001)
73860: accuracy:0.2 loss: 267.857 (lr:0.0001)
73880: accuracy:0.3 loss: 227.161 (lr:0.0001)
73900: accuracy:0.24 loss: 257.177 (lr:0.0001)
73920: accuracy:0.19 loss: 239.475 (lr:0.0001)
73940: accuracy:0.23 loss: 261.19 (lr:0.0001)
73960: accuracy:0.3 loss: 233.334 (lr:0.0001)
73980: accuracy:0.25 loss: 236.205 (lr:0.0001)
74000: accuracy:0.25 loss: 250.378 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
74000: ********* epoch 8 ********* test accuracy for all:0.213446 test loss: 266.909
74000: ********* epoch 8 ********* test accuracy for mode 0:0.0345 test loss: 402.422
74000: ********* epoch 8 ********* test accuracy for mode 1:0.035 test loss: 434.126
74000: ********* epoch 8 ********* test accuracy for mode 2:0.0485 test loss: 289.895
74000: ********* epoch 8 ********* test accuracy for mode 24:0.2385 test loss: 266.197
74000: ********* epoch 8 ********* test accuracy for mode 25:0.245 test loss: 253.18
74000: ********* epoch 8 ********* test accuracy for mode 26:0.4155 test loss: 180.138
74000: ********* epoch 8 ********* test accuracy for mode 27:0.2615 test loss: 256.155
74000: ********* epoch 8 ********* test accuracy for mode 28:0.304 test loss: 240.37
74000: ********* epoch 8 ********* test accuracy for mode 29:0.295 test loss: 248.091
74000: ********* epoch 8 ********* test accuracy for mode 30:0.206 test loss: 250.769
74000: ********* epoch 8 ********* test accuracy for mode 31:0.168 test loss: 257.668
74000: ********* epoch 8 ********* test accuracy for mode 32:0.225 test loss: 252.148
74000: ********* epoch 8 ********* test accuracy for mode 33:0.114 test loss: 260.944
74000: ********* epoch 8 ********* test accuracy for mode 34:0.044 test loss: 263.654
74000: ********* epoch 8 ********* test accuracy for mode 35:0.1195 test loss: 413.457
74000: ********* epoch 8 ********* test accuracy for mode 36:0.192 test loss: 431.54
74020: accuracy:0.18 loss: 249.47 (lr:0.0001)
74040: accuracy:0.21 loss: 252.177 (lr:0.0001)
74060: accuracy:0.31 loss: 225.842 (lr:0.0001)
74080: accuracy:0.28 loss: 239.937 (lr:0.0001)
74100: accuracy:0.3 loss: 227.037 (lr:0.0001)
74120: accuracy:0.34 loss: 222.494 (lr:0.0001)
74140: accuracy:0.21 loss: 231.0 (lr:0.0001)
74160: accuracy:0.23 loss: 241.705 (lr:0.0001)
74180: accuracy:0.28 loss: 257.51 (lr:0.0001)
74200: accuracy:0.18 loss: 255.529 (lr:0.0001)
74220: accuracy:0.23 loss: 255.611 (lr:0.0001)
74240: accuracy:0.26 loss: 240.494 (lr:0.0001)
74260: accuracy:0.17 loss: 251.673 (lr:0.0001)
74280: accuracy:0.18 loss: 247.064 (lr:0.0001)
74300: accuracy:0.19 loss: 266.372 (lr:0.0001)
74320: accuracy:0.22 loss: 261.338 (lr:0.0001)
74340: accuracy:0.27 loss: 234.705 (lr:0.0001)
74360: accuracy:0.24 loss: 251.763 (lr:0.0001)
74380: accuracy:0.26 loss: 243.528 (lr:0.0001)
74400: accuracy:0.19 loss: 244.293 (lr:0.0001)
74420: accuracy:0.19 loss: 247.693 (lr:0.0001)
74440: accuracy:0.31 loss: 233.551 (lr:0.0001)
74460: accuracy:0.22 loss: 248.5 (lr:0.0001)
74480: accuracy:0.2 loss: 249.906 (lr:0.0001)
74500: accuracy:0.25 loss: 231.576 (lr:0.0001)
74520: accuracy:0.21 loss: 265.335 (lr:0.0001)
74540: accuracy:0.18 loss: 269.229 (lr:0.0001)
74560: accuracy:0.24 loss: 240.421 (lr:0.0001)
74580: accuracy:0.25 loss: 252.379 (lr:0.0001)
74600: accuracy:0.19 loss: 265.447 (lr:0.0001)
74620: accuracy:0.25 loss: 231.544 (lr:0.0001)
74640: accuracy:0.26 loss: 249.251 (lr:0.0001)
74660: accuracy:0.25 loss: 262.297 (lr:0.0001)
74680: accuracy:0.3 loss: 236.352 (lr:0.0001)
74700: accuracy:0.22 loss: 242.647 (lr:0.0001)
74720: accuracy:0.21 loss: 253.021 (lr:0.0001)
74740: accuracy:0.27 loss: 233.411 (lr:0.0001)
74760: accuracy:0.27 loss: 234.98 (lr:0.0001)
74780: accuracy:0.17 loss: 256.084 (lr:0.0001)
74800: accuracy:0.17 loss: 261.744 (lr:0.0001)
74820: accuracy:0.26 loss: 236.453 (lr:0.0001)
74840: accuracy:0.26 loss: 236.492 (lr:0.0001)
74860: accuracy:0.27 loss: 244.666 (lr:0.0001)
74880: accuracy:0.28 loss: 231.406 (lr:0.0001)
74900: accuracy:0.22 loss: 242.913 (lr:0.0001)
74920: accuracy:0.25 loss: 232.171 (lr:0.0001)
74940: accuracy:0.28 loss: 256.049 (lr:0.0001)
74960: accuracy:0.25 loss: 239.865 (lr:0.0001)
74980: accuracy:0.3 loss: 223.107 (lr:0.0001)
75000: accuracy:0.28 loss: 236.573 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
75000: ********* epoch 8 ********* test accuracy for all:0.207419 test loss: 270.292
75000: ********* epoch 8 ********* test accuracy for mode 0:0.038 test loss: 411.448
75000: ********* epoch 8 ********* test accuracy for mode 1:0.025 test loss: 454.934
75000: ********* epoch 8 ********* test accuracy for mode 2:0.078 test loss: 281.298
75000: ********* epoch 8 ********* test accuracy for mode 24:0.236 test loss: 278.996
75000: ********* epoch 8 ********* test accuracy for mode 25:0.296 test loss: 262.163
75000: ********* epoch 8 ********* test accuracy for mode 26:0.3155 test loss: 190.479
75000: ********* epoch 8 ********* test accuracy for mode 27:0.2405 test loss: 279.17
75000: ********* epoch 8 ********* test accuracy for mode 28:0.257 test loss: 265.421
75000: ********* epoch 8 ********* test accuracy for mode 29:0.266 test loss: 268.43
75000: ********* epoch 8 ********* test accuracy for mode 30:0.1615 test loss: 263.607
75000: ********* epoch 8 ********* test accuracy for mode 31:0.161 test loss: 261.276
75000: ********* epoch 8 ********* test accuracy for mode 32:0.282 test loss: 246.52
75000: ********* epoch 8 ********* test accuracy for mode 33:0.111 test loss: 256.809
75000: ********* epoch 8 ********* test accuracy for mode 34:0.0215 test loss: 261.549
75000: ********* epoch 8 ********* test accuracy for mode 35:0.064 test loss: 448.161
75000: ********* epoch 8 ********* test accuracy for mode 36:0.0495 test loss: 479.973
75020: accuracy:0.15 loss: 235.049 (lr:0.0001)
75040: accuracy:0.23 loss: 268.055 (lr:0.0001)
75060: accuracy:0.18 loss: 228.047 (lr:0.0001)
75080: accuracy:0.16 loss: 243.417 (lr:0.0001)
75100: accuracy:0.24 loss: 261.381 (lr:0.0001)
75120: accuracy:0.2 loss: 243.095 (lr:0.0001)
75140: accuracy:0.22 loss: 258.193 (lr:0.0001)
75160: accuracy:0.25 loss: 238.475 (lr:0.0001)
75180: accuracy:0.25 loss: 241.944 (lr:0.0001)
75200: accuracy:0.22 loss: 241.751 (lr:0.0001)
75220: accuracy:0.19 loss: 244.056 (lr:0.0001)
75240: accuracy:0.25 loss: 260.326 (lr:0.0001)
75260: accuracy:0.21 loss: 239.087 (lr:0.0001)
75280: accuracy:0.24 loss: 255.189 (lr:0.0001)
75300: accuracy:0.27 loss: 237.774 (lr:0.0001)
75320: accuracy:0.29 loss: 229.822 (lr:0.0001)
75340: accuracy:0.25 loss: 251.637 (lr:0.0001)
75360: accuracy:0.27 loss: 246.912 (lr:0.0001)
75380: accuracy:0.19 loss: 242.95 (lr:0.0001)
75400: accuracy:0.26 loss: 236.741 (lr:0.0001)
75420: accuracy:0.26 loss: 225.023 (lr:0.0001)
75440: accuracy:0.23 loss: 236.439 (lr:0.0001)
75460: accuracy:0.21 loss: 269.001 (lr:0.0001)
75480: accuracy:0.14 loss: 261.329 (lr:0.0001)
75500: accuracy:0.17 loss: 258.657 (lr:0.0001)
75520: accuracy:0.27 loss: 231.776 (lr:0.0001)
75540: accuracy:0.3 loss: 225.435 (lr:0.0001)
75560: accuracy:0.27 loss: 233.004 (lr:0.0001)
75580: accuracy:0.28 loss: 254.774 (lr:0.0001)
75600: accuracy:0.22 loss: 252.347 (lr:0.0001)
75620: accuracy:0.2 loss: 251.752 (lr:0.0001)
75640: accuracy:0.33 loss: 249.357 (lr:0.0001)
75660: accuracy:0.22 loss: 256.373 (lr:0.0001)
75680: accuracy:0.23 loss: 257.586 (lr:0.0001)
75700: accuracy:0.25 loss: 247.253 (lr:0.0001)
75720: accuracy:0.25 loss: 253.487 (lr:0.0001)
75740: accuracy:0.25 loss: 243.551 (lr:0.0001)
75760: accuracy:0.31 loss: 222.523 (lr:0.0001)
75780: accuracy:0.17 loss: 252.277 (lr:0.0001)
75800: accuracy:0.22 loss: 272.304 (lr:0.0001)
75820: accuracy:0.26 loss: 236.446 (lr:0.0001)
75840: accuracy:0.25 loss: 239.893 (lr:0.0001)
75860: accuracy:0.28 loss: 244.061 (lr:0.0001)
75880: accuracy:0.24 loss: 247.634 (lr:0.0001)
75900: accuracy:0.21 loss: 263.108 (lr:0.0001)
75920: accuracy:0.28 loss: 249.439 (lr:0.0001)
75940: accuracy:0.21 loss: 251.739 (lr:0.0001)
75960: accuracy:0.27 loss: 236.688 (lr:0.0001)
75980: accuracy:0.21 loss: 275.685 (lr:0.0001)
76000: accuracy:0.19 loss: 252.695 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
76000: ********* epoch 8 ********* test accuracy for all:0.210162 test loss: 269.011
76000: ********* epoch 8 ********* test accuracy for mode 0:0.034 test loss: 412.21
76000: ********* epoch 8 ********* test accuracy for mode 1:0.029 test loss: 453.437
76000: ********* epoch 8 ********* test accuracy for mode 2:0.071 test loss: 287.52
76000: ********* epoch 8 ********* test accuracy for mode 24:0.236 test loss: 271.251
76000: ********* epoch 8 ********* test accuracy for mode 25:0.284 test loss: 255.452
76000: ********* epoch 8 ********* test accuracy for mode 26:0.392 test loss: 185.362
76000: ********* epoch 8 ********* test accuracy for mode 27:0.236 test loss: 276.016
76000: ********* epoch 8 ********* test accuracy for mode 28:0.266 test loss: 262.635
76000: ********* epoch 8 ********* test accuracy for mode 29:0.273 test loss: 268.821
76000: ********* epoch 8 ********* test accuracy for mode 30:0.1735 test loss: 265.724
76000: ********* epoch 8 ********* test accuracy for mode 31:0.159 test loss: 265.46
76000: ********* epoch 8 ********* test accuracy for mode 32:0.2395 test loss: 254.023
76000: ********* epoch 8 ********* test accuracy for mode 33:0.1115 test loss: 262.417
76000: ********* epoch 8 ********* test accuracy for mode 34:0.025 test loss: 264.419
76000: ********* epoch 8 ********* test accuracy for mode 35:0.086 test loss: 435.135
76000: ********* epoch 8 ********* test accuracy for mode 36:0.0625 test loss: 465.415
76020: accuracy:0.21 loss: 239.655 (lr:0.0001)
76040: accuracy:0.21 loss: 246.673 (lr:0.0001)
76060: accuracy:0.21 loss: 241.486 (lr:0.0001)
76080: accuracy:0.26 loss: 254.81 (lr:0.0001)
76100: accuracy:0.27 loss: 245.321 (lr:0.0001)
76120: accuracy:0.23 loss: 254.257 (lr:0.0001)
76140: accuracy:0.25 loss: 232.344 (lr:0.0001)
76160: accuracy:0.27 loss: 245.756 (lr:0.0001)
76180: accuracy:0.23 loss: 256.468 (lr:0.0001)
76200: accuracy:0.22 loss: 264.262 (lr:0.0001)
76220: accuracy:0.18 loss: 273.391 (lr:0.0001)
76240: accuracy:0.32 loss: 244.275 (lr:0.0001)
76260: accuracy:0.29 loss: 230.583 (lr:0.0001)
76280: accuracy:0.25 loss: 242.077 (lr:0.0001)
76300: accuracy:0.28 loss: 244.971 (lr:0.0001)
76320: accuracy:0.21 loss: 240.259 (lr:0.0001)
76340: accuracy:0.26 loss: 231.66 (lr:0.0001)
76360: accuracy:0.2 loss: 246.049 (lr:0.0001)
76380: accuracy:0.25 loss: 235.485 (lr:0.0001)
76400: accuracy:0.24 loss: 255.942 (lr:0.0001)
76420: accuracy:0.24 loss: 234.48 (lr:0.0001)
76440: accuracy:0.24 loss: 235.913 (lr:0.0001)
76460: accuracy:0.22 loss: 263.561 (lr:0.0001)
76480: accuracy:0.19 loss: 256.521 (lr:0.0001)
76500: accuracy:0.22 loss: 243.134 (lr:0.0001)
76520: accuracy:0.28 loss: 234.497 (lr:0.0001)
76540: accuracy:0.28 loss: 233.407 (lr:0.0001)
76560: accuracy:0.23 loss: 260.665 (lr:0.0001)
76580: accuracy:0.22 loss: 266.6 (lr:0.0001)
76600: accuracy:0.21 loss: 266.468 (lr:0.0001)
76620: accuracy:0.26 loss: 248.265 (lr:0.0001)
76640: accuracy:0.2 loss: 244.048 (lr:0.0001)
76660: accuracy:0.23 loss: 258.721 (lr:0.0001)
76680: accuracy:0.21 loss: 247.368 (lr:0.0001)
76700: accuracy:0.32 loss: 227.705 (lr:0.0001)
76720: accuracy:0.26 loss: 236.056 (lr:0.0001)
76740: accuracy:0.19 loss: 258.645 (lr:0.0001)
76760: accuracy:0.32 loss: 231.515 (lr:0.0001)
76780: accuracy:0.25 loss: 246.076 (lr:0.0001)
76800: accuracy:0.22 loss: 245.232 (lr:0.0001)
76820: accuracy:0.24 loss: 240.46 (lr:0.0001)
76840: accuracy:0.26 loss: 244.564 (lr:0.0001)
76860: accuracy:0.23 loss: 245.686 (lr:0.0001)
76880: accuracy:0.3 loss: 224.134 (lr:0.0001)
76900: accuracy:0.3 loss: 246.255 (lr:0.0001)
76920: accuracy:0.33 loss: 229.236 (lr:0.0001)
76940: accuracy:0.24 loss: 246.77 (lr:0.0001)
76960: accuracy:0.32 loss: 232.131 (lr:0.0001)
76980: accuracy:0.27 loss: 234.652 (lr:0.0001)
77000: accuracy:0.3 loss: 246.439 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
77000: ********* epoch 8 ********* test accuracy for all:0.212716 test loss: 266.969
77000: ********* epoch 8 ********* test accuracy for mode 0:0.0415 test loss: 398.198
77000: ********* epoch 8 ********* test accuracy for mode 1:0.0455 test loss: 426.233
77000: ********* epoch 8 ********* test accuracy for mode 2:0.057 test loss: 289.284
77000: ********* epoch 8 ********* test accuracy for mode 24:0.248 test loss: 266.434
77000: ********* epoch 8 ********* test accuracy for mode 25:0.2665 test loss: 253.417
77000: ********* epoch 8 ********* test accuracy for mode 26:0.3985 test loss: 184.118
77000: ********* epoch 8 ********* test accuracy for mode 27:0.218 test loss: 272.642
77000: ********* epoch 8 ********* test accuracy for mode 28:0.259 test loss: 254.618
77000: ********* epoch 8 ********* test accuracy for mode 29:0.286 test loss: 260.828
77000: ********* epoch 8 ********* test accuracy for mode 30:0.159 test loss: 263.542
77000: ********* epoch 8 ********* test accuracy for mode 31:0.163 test loss: 265.673
77000: ********* epoch 8 ********* test accuracy for mode 32:0.2245 test loss: 257.172
77000: ********* epoch 8 ********* test accuracy for mode 33:0.101 test loss: 266.772
77000: ********* epoch 8 ********* test accuracy for mode 34:0.031 test loss: 266.289
77000: ********* epoch 8 ********* test accuracy for mode 35:0.1215 test loss: 418.382
77000: ********* epoch 8 ********* test accuracy for mode 36:0.188 test loss: 436.671
77020: accuracy:0.26 loss: 245.287 (lr:0.0001)
77040: accuracy:0.28 loss: 231.92 (lr:0.0001)
77060: accuracy:0.19 loss: 249.077 (lr:0.0001)
77080: accuracy:0.21 loss: 246.403 (lr:0.0001)
77100: accuracy:0.23 loss: 243.426 (lr:0.0001)
77120: accuracy:0.25 loss: 229.662 (lr:0.0001)
77140: accuracy:0.31 loss: 234.979 (lr:0.0001)
77160: accuracy:0.31 loss: 225.031 (lr:0.0001)
77180: accuracy:0.2 loss: 232.999 (lr:0.0001)
77200: accuracy:0.26 loss: 245.564 (lr:0.0001)
77220: accuracy:0.26 loss: 240.07 (lr:0.0001)
77240: accuracy:0.27 loss: 224.288 (lr:0.0001)
77260: accuracy:0.26 loss: 263.533 (lr:0.0001)
77280: accuracy:0.25 loss: 261.865 (lr:0.0001)
77300: accuracy:0.21 loss: 232.168 (lr:0.0001)
77320: accuracy:0.3 loss: 240.241 (lr:0.0001)
77340: accuracy:0.23 loss: 253.571 (lr:0.0001)
77360: accuracy:0.33 loss: 239.391 (lr:0.0001)
77380: accuracy:0.2 loss: 254.55 (lr:0.0001)
77400: accuracy:0.23 loss: 240.195 (lr:0.0001)
77420: accuracy:0.33 loss: 244.479 (lr:0.0001)
77440: accuracy:0.34 loss: 260.255 (lr:0.0001)
77460: accuracy:0.29 loss: 241.353 (lr:0.0001)
77480: accuracy:0.19 loss: 229.736 (lr:0.0001)
77500: accuracy:0.22 loss: 229.935 (lr:0.0001)
77520: accuracy:0.24 loss: 237.358 (lr:0.0001)
77540: accuracy:0.25 loss: 260.865 (lr:0.0001)
77560: accuracy:0.33 loss: 221.25 (lr:0.0001)
77580: accuracy:0.27 loss: 227.004 (lr:0.0001)
77600: accuracy:0.26 loss: 234.988 (lr:0.0001)
77620: accuracy:0.19 loss: 247.884 (lr:0.0001)
77640: accuracy:0.28 loss: 248.64 (lr:0.0001)
77660: accuracy:0.22 loss: 251.191 (lr:0.0001)
77680: accuracy:0.22 loss: 243.576 (lr:0.0001)
77700: accuracy:0.17 loss: 271.287 (lr:0.0001)
77720: accuracy:0.25 loss: 244.009 (lr:0.0001)
77740: accuracy:0.32 loss: 234.081 (lr:0.0001)
77760: accuracy:0.19 loss: 236.198 (lr:0.0001)
77780: accuracy:0.22 loss: 245.13 (lr:0.0001)
77800: accuracy:0.29 loss: 219.324 (lr:0.0001)
77820: accuracy:0.23 loss: 254.992 (lr:0.0001)
77840: accuracy:0.18 loss: 254.122 (lr:0.0001)
77860: accuracy:0.22 loss: 233.773 (lr:0.0001)
77880: accuracy:0.27 loss: 245.009 (lr:0.0001)
77900: accuracy:0.25 loss: 245.756 (lr:0.0001)
77920: accuracy:0.23 loss: 239.768 (lr:0.0001)
77940: accuracy:0.25 loss: 234.984 (lr:0.0001)
77960: accuracy:0.21 loss: 259.255 (lr:0.0001)
77980: accuracy:0.27 loss: 240.952 (lr:0.0001)
78000: accuracy:0.27 loss: 236.71 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
78000: ********* epoch 9 ********* test accuracy for all:0.212797 test loss: 266.738
78000: ********* epoch 9 ********* test accuracy for mode 0:0.039 test loss: 404.628
78000: ********* epoch 9 ********* test accuracy for mode 1:0.034 test loss: 442.605
78000: ********* epoch 9 ********* test accuracy for mode 2:0.0695 test loss: 285.742
78000: ********* epoch 9 ********* test accuracy for mode 24:0.2235 test loss: 264.478
78000: ********* epoch 9 ********* test accuracy for mode 25:0.2845 test loss: 248.912
78000: ********* epoch 9 ********* test accuracy for mode 26:0.382 test loss: 186.657
78000: ********* epoch 9 ********* test accuracy for mode 27:0.2385 test loss: 269.288
78000: ********* epoch 9 ********* test accuracy for mode 28:0.2895 test loss: 251.528
78000: ********* epoch 9 ********* test accuracy for mode 29:0.2655 test loss: 262.552
78000: ********* epoch 9 ********* test accuracy for mode 30:0.1875 test loss: 262.024
78000: ********* epoch 9 ********* test accuracy for mode 31:0.1345 test loss: 267.061
78000: ********* epoch 9 ********* test accuracy for mode 32:0.2585 test loss: 255.182
78000: ********* epoch 9 ********* test accuracy for mode 33:0.115 test loss: 263.342
78000: ********* epoch 9 ********* test accuracy for mode 34:0.0315 test loss: 265.669
78000: ********* epoch 9 ********* test accuracy for mode 35:0.115 test loss: 418.099
78000: ********* epoch 9 ********* test accuracy for mode 36:0.1305 test loss: 435.397
78020: accuracy:0.16 loss: 266.135 (lr:0.0001)
78040: accuracy:0.22 loss: 230.672 (lr:0.0001)
78060: accuracy:0.32 loss: 253.901 (lr:0.0001)
78080: accuracy:0.23 loss: 242.14 (lr:0.0001)
78100: accuracy:0.27 loss: 254.629 (lr:0.0001)
78120: accuracy:0.21 loss: 242.134 (lr:0.0001)
78140: accuracy:0.31 loss: 231.787 (lr:0.0001)
78160: accuracy:0.27 loss: 251.432 (lr:0.0001)
78180: accuracy:0.31 loss: 219.092 (lr:0.0001)
78200: accuracy:0.29 loss: 235.764 (lr:0.0001)
78220: accuracy:0.26 loss: 238.716 (lr:0.0001)
78240: accuracy:0.26 loss: 242.062 (lr:0.0001)
78260: accuracy:0.28 loss: 240.02 (lr:0.0001)
78280: accuracy:0.3 loss: 246.649 (lr:0.0001)
78300: accuracy:0.24 loss: 240.065 (lr:0.0001)
78320: accuracy:0.22 loss: 228.652 (lr:0.0001)
78340: accuracy:0.31 loss: 246.357 (lr:0.0001)
78360: accuracy:0.28 loss: 233.745 (lr:0.0001)
78380: accuracy:0.29 loss: 238.364 (lr:0.0001)
78400: accuracy:0.23 loss: 256.728 (lr:0.0001)
78420: accuracy:0.2 loss: 236.373 (lr:0.0001)
78440: accuracy:0.18 loss: 255.407 (lr:0.0001)
78460: accuracy:0.3 loss: 232.849 (lr:0.0001)
78480: accuracy:0.19 loss: 259.777 (lr:0.0001)
78500: accuracy:0.24 loss: 237.587 (lr:0.0001)
78520: accuracy:0.19 loss: 246.945 (lr:0.0001)
78540: accuracy:0.27 loss: 231.146 (lr:0.0001)
78560: accuracy:0.33 loss: 233.584 (lr:0.0001)
78580: accuracy:0.27 loss: 246.421 (lr:0.0001)
78600: accuracy:0.28 loss: 246.994 (lr:0.0001)
78620: accuracy:0.22 loss: 242.473 (lr:0.0001)
78640: accuracy:0.22 loss: 245.345 (lr:0.0001)
78660: accuracy:0.24 loss: 267.424 (lr:0.0001)
78680: accuracy:0.2 loss: 259.428 (lr:0.0001)
78700: accuracy:0.22 loss: 252.239 (lr:0.0001)
78720: accuracy:0.22 loss: 242.242 (lr:0.0001)
78740: accuracy:0.29 loss: 235.365 (lr:0.0001)
78760: accuracy:0.27 loss: 240.643 (lr:0.0001)
78780: accuracy:0.27 loss: 229.614 (lr:0.0001)
78800: accuracy:0.19 loss: 242.565 (lr:0.0001)
78820: accuracy:0.24 loss: 236.101 (lr:0.0001)
78840: accuracy:0.24 loss: 236.695 (lr:0.0001)
78860: accuracy:0.3 loss: 240.93 (lr:0.0001)
78880: accuracy:0.24 loss: 234.582 (lr:0.0001)
78900: accuracy:0.26 loss: 263.972 (lr:0.0001)
78920: accuracy:0.23 loss: 239.375 (lr:0.0001)
78940: accuracy:0.3 loss: 221.524 (lr:0.0001)
78960: accuracy:0.28 loss: 239.499 (lr:0.0001)
78980: accuracy:0.29 loss: 240.509 (lr:0.0001)
79000: accuracy:0.25 loss: 255.182 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
79000: ********* epoch 9 ********* test accuracy for all:0.214189 test loss: 266.774
79000: ********* epoch 9 ********* test accuracy for mode 0:0.042 test loss: 403.683
79000: ********* epoch 9 ********* test accuracy for mode 1:0.034 test loss: 439.447
79000: ********* epoch 9 ********* test accuracy for mode 2:0.078 test loss: 284.883
79000: ********* epoch 9 ********* test accuracy for mode 24:0.25 test loss: 263.699
79000: ********* epoch 9 ********* test accuracy for mode 25:0.251 test loss: 253.793
79000: ********* epoch 9 ********* test accuracy for mode 26:0.4225 test loss: 183.692
79000: ********* epoch 9 ********* test accuracy for mode 27:0.245 test loss: 271.82
79000: ********* epoch 9 ********* test accuracy for mode 28:0.292 test loss: 255.073
79000: ********* epoch 9 ********* test accuracy for mode 29:0.247 test loss: 265.522
79000: ********* epoch 9 ********* test accuracy for mode 30:0.193 test loss: 260.732
79000: ********* epoch 9 ********* test accuracy for mode 31:0.158 test loss: 265.43
79000: ********* epoch 9 ********* test accuracy for mode 32:0.219 test loss: 255.744
79000: ********* epoch 9 ********* test accuracy for mode 33:0.1235 test loss: 261.566
79000: ********* epoch 9 ********* test accuracy for mode 34:0.0225 test loss: 266.253
79000: ********* epoch 9 ********* test accuracy for mode 35:0.1155 test loss: 421.714
79000: ********* epoch 9 ********* test accuracy for mode 36:0.1465 test loss: 445.431
79020: accuracy:0.31 loss: 220.961 (lr:0.0001)
79040: accuracy:0.18 loss: 255.078 (lr:0.0001)
79060: accuracy:0.27 loss: 236.071 (lr:0.0001)
79080: accuracy:0.27 loss: 239.817 (lr:0.0001)
79100: accuracy:0.21 loss: 239.729 (lr:0.0001)
79120: accuracy:0.26 loss: 275.694 (lr:0.0001)
79140: accuracy:0.22 loss: 243.729 (lr:0.0001)
79160: accuracy:0.26 loss: 243.464 (lr:0.0001)
79180: accuracy:0.3 loss: 247.541 (lr:0.0001)
79200: accuracy:0.2 loss: 256.087 (lr:0.0001)
79220: accuracy:0.26 loss: 245.849 (lr:0.0001)
79240: accuracy:0.26 loss: 243.537 (lr:0.0001)
79260: accuracy:0.26 loss: 229.528 (lr:0.0001)
79280: accuracy:0.2 loss: 248.44 (lr:0.0001)
79300: accuracy:0.2 loss: 243.366 (lr:0.0001)
79320: accuracy:0.24 loss: 246.011 (lr:0.0001)
79340: accuracy:0.28 loss: 229.725 (lr:0.0001)
79360: accuracy:0.2 loss: 236.398 (lr:0.0001)
79380: accuracy:0.26 loss: 246.292 (lr:0.0001)
79400: accuracy:0.24 loss: 254.245 (lr:0.0001)
79420: accuracy:0.25 loss: 250.145 (lr:0.0001)
79440: accuracy:0.22 loss: 249.727 (lr:0.0001)
79460: accuracy:0.33 loss: 232.333 (lr:0.0001)
79480: accuracy:0.3 loss: 221.047 (lr:0.0001)
79500: accuracy:0.33 loss: 217.455 (lr:0.0001)
79520: accuracy:0.28 loss: 220.05 (lr:0.0001)
79540: accuracy:0.22 loss: 250.089 (lr:0.0001)
79560: accuracy:0.25 loss: 249.537 (lr:0.0001)
79580: accuracy:0.23 loss: 226.115 (lr:0.0001)
79600: accuracy:0.28 loss: 248.089 (lr:0.0001)
79620: accuracy:0.32 loss: 233.283 (lr:0.0001)
79640: accuracy:0.29 loss: 260.399 (lr:0.0001)
79660: accuracy:0.3 loss: 231.608 (lr:0.0001)
79680: accuracy:0.23 loss: 237.949 (lr:0.0001)
79700: accuracy:0.26 loss: 240.984 (lr:0.0001)
79720: accuracy:0.27 loss: 240.634 (lr:0.0001)
79740: accuracy:0.26 loss: 256.252 (lr:0.0001)
79760: accuracy:0.24 loss: 237.391 (lr:0.0001)
79780: accuracy:0.26 loss: 235.321 (lr:0.0001)
79800: accuracy:0.28 loss: 233.599 (lr:0.0001)
79820: accuracy:0.23 loss: 246.542 (lr:0.0001)
79840: accuracy:0.31 loss: 239.261 (lr:0.0001)
79860: accuracy:0.27 loss: 245.582 (lr:0.0001)
79880: accuracy:0.24 loss: 246.648 (lr:0.0001)
79900: accuracy:0.26 loss: 244.236 (lr:0.0001)
79920: accuracy:0.17 loss: 243.461 (lr:0.0001)
79940: accuracy:0.17 loss: 238.015 (lr:0.0001)
79960: accuracy:0.24 loss: 240.824 (lr:0.0001)
79980: accuracy:0.28 loss: 245.754 (lr:0.0001)
80000: accuracy:0.26 loss: 246.501 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
80000: ********* epoch 9 ********* test accuracy for all:0.208257 test loss: 270.463
80000: ********* epoch 9 ********* test accuracy for mode 0:0.0365 test loss: 415.354
80000: ********* epoch 9 ********* test accuracy for mode 1:0.027 test loss: 456.682
80000: ********* epoch 9 ********* test accuracy for mode 2:0.075 test loss: 279.22
80000: ********* epoch 9 ********* test accuracy for mode 24:0.2195 test loss: 282.345
80000: ********* epoch 9 ********* test accuracy for mode 25:0.284 test loss: 267.123
80000: ********* epoch 9 ********* test accuracy for mode 26:0.2895 test loss: 194.863
80000: ********* epoch 9 ********* test accuracy for mode 27:0.257 test loss: 278.604
80000: ********* epoch 9 ********* test accuracy for mode 28:0.281 test loss: 262.711
80000: ********* epoch 9 ********* test accuracy for mode 29:0.2645 test loss: 266.967
80000: ********* epoch 9 ********* test accuracy for mode 30:0.1465 test loss: 262.703
80000: ********* epoch 9 ********* test accuracy for mode 31:0.192 test loss: 258.254
80000: ********* epoch 9 ********* test accuracy for mode 32:0.2355 test loss: 247.63
80000: ********* epoch 9 ********* test accuracy for mode 33:0.136 test loss: 255.272
80000: ********* epoch 9 ********* test accuracy for mode 34:0.018 test loss: 262.199
80000: ********* epoch 9 ********* test accuracy for mode 35:0.119 test loss: 437.426
80000: ********* epoch 9 ********* test accuracy for mode 36:0.076 test loss: 465.57
80020: accuracy:0.22 loss: 253.691 (lr:0.0001)
80040: accuracy:0.31 loss: 228.496 (lr:0.0001)
80060: accuracy:0.26 loss: 238.13 (lr:0.0001)
80080: accuracy:0.3 loss: 243.962 (lr:0.0001)
80100: accuracy:0.27 loss: 246.029 (lr:0.0001)
80120: accuracy:0.21 loss: 240.369 (lr:0.0001)
80140: accuracy:0.22 loss: 250.418 (lr:0.0001)
80160: accuracy:0.25 loss: 261.676 (lr:0.0001)
80180: accuracy:0.19 loss: 253.781 (lr:0.0001)
80200: accuracy:0.21 loss: 235.254 (lr:0.0001)
80220: accuracy:0.24 loss: 233.333 (lr:0.0001)
80240: accuracy:0.3 loss: 231.993 (lr:0.0001)
80260: accuracy:0.24 loss: 226.982 (lr:0.0001)
80280: accuracy:0.22 loss: 256.958 (lr:0.0001)
80300: accuracy:0.26 loss: 246.133 (lr:0.0001)
80320: accuracy:0.21 loss: 263.185 (lr:0.0001)
80340: accuracy:0.26 loss: 239.517 (lr:0.0001)
80360: accuracy:0.26 loss: 251.251 (lr:0.0001)
80380: accuracy:0.27 loss: 224.23 (lr:0.0001)
80400: accuracy:0.15 loss: 256.094 (lr:0.0001)
80420: accuracy:0.3 loss: 239.206 (lr:0.0001)
80440: accuracy:0.24 loss: 235.506 (lr:0.0001)
80460: accuracy:0.24 loss: 247.006 (lr:0.0001)
80480: accuracy:0.21 loss: 259.607 (lr:0.0001)
80500: accuracy:0.26 loss: 243.051 (lr:0.0001)
80520: accuracy:0.24 loss: 251.453 (lr:0.0001)
80540: accuracy:0.25 loss: 251.409 (lr:0.0001)
80560: accuracy:0.2 loss: 251.066 (lr:0.0001)
80580: accuracy:0.28 loss: 250.924 (lr:0.0001)
80600: accuracy:0.25 loss: 243.795 (lr:0.0001)
80620: accuracy:0.22 loss: 241.517 (lr:0.0001)
80640: accuracy:0.25 loss: 242.958 (lr:0.0001)
80660: accuracy:0.31 loss: 226.993 (lr:0.0001)
80680: accuracy:0.3 loss: 230.617 (lr:0.0001)
80700: accuracy:0.23 loss: 241.125 (lr:0.0001)
80720: accuracy:0.2 loss: 242.718 (lr:0.0001)
80740: accuracy:0.19 loss: 255.117 (lr:0.0001)
80760: accuracy:0.19 loss: 253.342 (lr:0.0001)
80780: accuracy:0.22 loss: 256.757 (lr:0.0001)
80800: accuracy:0.24 loss: 239.922 (lr:0.0001)
80820: accuracy:0.25 loss: 240.655 (lr:0.0001)
80840: accuracy:0.24 loss: 252.526 (lr:0.0001)
80860: accuracy:0.24 loss: 227.787 (lr:0.0001)
80880: accuracy:0.25 loss: 247.035 (lr:0.0001)
80900: accuracy:0.21 loss: 232.488 (lr:0.0001)
80920: accuracy:0.23 loss: 248.5 (lr:0.0001)
80940: accuracy:0.21 loss: 251.998 (lr:0.0001)
80960: accuracy:0.23 loss: 238.86 (lr:0.0001)
80980: accuracy:0.32 loss: 220.598 (lr:0.0001)
81000: accuracy:0.25 loss: 264.06 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
81000: ********* epoch 9 ********* test accuracy for all:0.206635 test loss: 271.185
81000: ********* epoch 9 ********* test accuracy for mode 0:0.042 test loss: 409.306
81000: ********* epoch 9 ********* test accuracy for mode 1:0.023 test loss: 449.775
81000: ********* epoch 9 ********* test accuracy for mode 2:0.0765 test loss: 278.105
81000: ********* epoch 9 ********* test accuracy for mode 24:0.224 test loss: 281.671
81000: ********* epoch 9 ********* test accuracy for mode 25:0.3165 test loss: 261.613
81000: ********* epoch 9 ********* test accuracy for mode 26:0.246 test loss: 192.807
81000: ********* epoch 9 ********* test accuracy for mode 27:0.262 test loss: 275.825
81000: ********* epoch 9 ********* test accuracy for mode 28:0.26 test loss: 264.152
81000: ********* epoch 9 ********* test accuracy for mode 29:0.254 test loss: 266.436
81000: ********* epoch 9 ********* test accuracy for mode 30:0.1635 test loss: 258.844
81000: ********* epoch 9 ********* test accuracy for mode 31:0.1675 test loss: 255.081
81000: ********* epoch 9 ********* test accuracy for mode 32:0.2665 test loss: 239.83
81000: ********* epoch 9 ********* test accuracy for mode 33:0.1845 test loss: 245.503
81000: ********* epoch 9 ********* test accuracy for mode 34:0.0255 test loss: 254.159
81000: ********* epoch 9 ********* test accuracy for mode 35:0.0705 test loss: 457.084
81000: ********* epoch 9 ********* test accuracy for mode 36:0.026 test loss: 502.016
81020: accuracy:0.25 loss: 249.542 (lr:0.0001)
81040: accuracy:0.26 loss: 235.898 (lr:0.0001)
81060: accuracy:0.28 loss: 236.524 (lr:0.0001)
81080: accuracy:0.22 loss: 249.594 (lr:0.0001)
81100: accuracy:0.23 loss: 250.595 (lr:0.0001)
81120: accuracy:0.27 loss: 233.139 (lr:0.0001)
81140: accuracy:0.19 loss: 239.602 (lr:0.0001)
81160: accuracy:0.18 loss: 248.312 (lr:0.0001)
81180: accuracy:0.25 loss: 244.45 (lr:0.0001)
81200: accuracy:0.27 loss: 244.024 (lr:0.0001)
81220: accuracy:0.3 loss: 240.012 (lr:0.0001)
81240: accuracy:0.24 loss: 250.035 (lr:0.0001)
81260: accuracy:0.23 loss: 246.745 (lr:0.0001)
81280: accuracy:0.23 loss: 229.531 (lr:0.0001)
81300: accuracy:0.28 loss: 230.287 (lr:0.0001)
81320: accuracy:0.17 loss: 252.103 (lr:0.0001)
81340: accuracy:0.23 loss: 247.729 (lr:0.0001)
81360: accuracy:0.29 loss: 231.122 (lr:0.0001)
81380: accuracy:0.22 loss: 248.34 (lr:0.0001)
81400: accuracy:0.2 loss: 257.098 (lr:0.0001)
81420: accuracy:0.28 loss: 240.69 (lr:0.0001)
81440: accuracy:0.25 loss: 237.077 (lr:0.0001)
81460: accuracy:0.22 loss: 238.645 (lr:0.0001)
81480: accuracy:0.29 loss: 238.514 (lr:0.0001)
81500: accuracy:0.12 loss: 261.434 (lr:0.0001)
81520: accuracy:0.29 loss: 234.782 (lr:0.0001)
81540: accuracy:0.26 loss: 241.673 (lr:0.0001)
81560: accuracy:0.22 loss: 258.456 (lr:0.0001)
81580: accuracy:0.21 loss: 233.465 (lr:0.0001)
81600: accuracy:0.25 loss: 259.628 (lr:0.0001)
81620: accuracy:0.3 loss: 245.529 (lr:0.0001)
81640: accuracy:0.21 loss: 258.824 (lr:0.0001)
81660: accuracy:0.29 loss: 245.626 (lr:0.0001)
81680: accuracy:0.28 loss: 225.813 (lr:0.0001)
81700: accuracy:0.21 loss: 237.716 (lr:0.0001)
81720: accuracy:0.25 loss: 245.476 (lr:0.0001)
81740: accuracy:0.22 loss: 237.581 (lr:0.0001)
81760: accuracy:0.23 loss: 213.906 (lr:0.0001)
81780: accuracy:0.21 loss: 249.009 (lr:0.0001)
81800: accuracy:0.27 loss: 244.954 (lr:0.0001)
81820: accuracy:0.17 loss: 257.728 (lr:0.0001)
81840: accuracy:0.21 loss: 244.207 (lr:0.0001)
81860: accuracy:0.22 loss: 249.269 (lr:0.0001)
81880: accuracy:0.36 loss: 233.136 (lr:0.0001)
81900: accuracy:0.17 loss: 246.441 (lr:0.0001)
81920: accuracy:0.22 loss: 233.422 (lr:0.0001)
81940: accuracy:0.31 loss: 215.985 (lr:0.0001)
81960: accuracy:0.3 loss: 238.102 (lr:0.0001)
81980: accuracy:0.36 loss: 211.936 (lr:0.0001)
82000: accuracy:0.25 loss: 241.896 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
82000: ********* epoch 9 ********* test accuracy for all:0.216297 test loss: 265.5
82000: ********* epoch 9 ********* test accuracy for mode 0:0.045 test loss: 398.292
82000: ********* epoch 9 ********* test accuracy for mode 1:0.045 test loss: 425.017
82000: ********* epoch 9 ********* test accuracy for mode 2:0.0555 test loss: 285.782
82000: ********* epoch 9 ********* test accuracy for mode 24:0.2405 test loss: 263.562
82000: ********* epoch 9 ********* test accuracy for mode 25:0.2765 test loss: 248.769
82000: ********* epoch 9 ********* test accuracy for mode 26:0.3895 test loss: 182.203
82000: ********* epoch 9 ********* test accuracy for mode 27:0.236 test loss: 271.646
82000: ********* epoch 9 ********* test accuracy for mode 28:0.265 test loss: 256.741
82000: ********* epoch 9 ********* test accuracy for mode 29:0.269 test loss: 266.854
82000: ********* epoch 9 ********* test accuracy for mode 30:0.1755 test loss: 266.939
82000: ********* epoch 9 ********* test accuracy for mode 31:0.1375 test loss: 271.963
82000: ********* epoch 9 ********* test accuracy for mode 32:0.228 test loss: 261.084
82000: ********* epoch 9 ********* test accuracy for mode 33:0.1425 test loss: 266.074
82000: ********* epoch 9 ********* test accuracy for mode 34:0.0255 test loss: 268.528
82000: ********* epoch 9 ********* test accuracy for mode 35:0.1565 test loss: 412.469
82000: ********* epoch 9 ********* test accuracy for mode 36:0.197 test loss: 432.587
82020: accuracy:0.34 loss: 246.46 (lr:0.0001)
82040: accuracy:0.36 loss: 233.26 (lr:0.0001)
82060: accuracy:0.25 loss: 235.2 (lr:0.0001)
82080: accuracy:0.3 loss: 237.508 (lr:0.0001)
82100: accuracy:0.24 loss: 250.902 (lr:0.0001)
82120: accuracy:0.24 loss: 248.092 (lr:0.0001)
82140: accuracy:0.33 loss: 233.598 (lr:0.0001)
82160: accuracy:0.2 loss: 249.089 (lr:0.0001)
82180: accuracy:0.33 loss: 247.796 (lr:0.0001)
82200: accuracy:0.22 loss: 252.026 (lr:0.0001)
82220: accuracy:0.24 loss: 242.927 (lr:0.0001)
82240: accuracy:0.3 loss: 230.981 (lr:0.0001)
82260: accuracy:0.3 loss: 226.998 (lr:0.0001)
82280: accuracy:0.24 loss: 253.195 (lr:0.0001)
82300: accuracy:0.28 loss: 243.342 (lr:0.0001)
82320: accuracy:0.21 loss: 260.422 (lr:0.0001)
82340: accuracy:0.16 loss: 264.618 (lr:0.0001)
82360: accuracy:0.27 loss: 240.303 (lr:0.0001)
82380: accuracy:0.23 loss: 225.57 (lr:0.0001)
82400: accuracy:0.22 loss: 250.475 (lr:0.0001)
82420: accuracy:0.18 loss: 256.951 (lr:0.0001)
82440: accuracy:0.14 loss: 260.042 (lr:0.0001)
82460: accuracy:0.34 loss: 226.219 (lr:0.0001)
82480: accuracy:0.23 loss: 232.327 (lr:0.0001)
82500: accuracy:0.31 loss: 225.783 (lr:0.0001)
82520: accuracy:0.31 loss: 242.457 (lr:0.0001)
82540: accuracy:0.23 loss: 243.504 (lr:0.0001)
82560: accuracy:0.28 loss: 230.879 (lr:0.0001)
82580: accuracy:0.29 loss: 226.563 (lr:0.0001)
82600: accuracy:0.28 loss: 242.062 (lr:0.0001)
82620: accuracy:0.16 loss: 257.295 (lr:0.0001)
82640: accuracy:0.27 loss: 245.688 (lr:0.0001)
82660: accuracy:0.23 loss: 244.334 (lr:0.0001)
82680: accuracy:0.24 loss: 248.76 (lr:0.0001)
82700: accuracy:0.29 loss: 247.15 (lr:0.0001)
82720: accuracy:0.25 loss: 261.196 (lr:0.0001)
82740: accuracy:0.29 loss: 238.559 (lr:0.0001)
82760: accuracy:0.18 loss: 252.789 (lr:0.0001)
82780: accuracy:0.15 loss: 258.767 (lr:0.0001)
82800: accuracy:0.23 loss: 238.042 (lr:0.0001)
82820: accuracy:0.18 loss: 240.01 (lr:0.0001)
82840: accuracy:0.29 loss: 236.479 (lr:0.0001)
82860: accuracy:0.21 loss: 229.442 (lr:0.0001)
82880: accuracy:0.3 loss: 223.111 (lr:0.0001)
82900: accuracy:0.18 loss: 265.511 (lr:0.0001)
82920: accuracy:0.21 loss: 241.566 (lr:0.0001)
82940: accuracy:0.26 loss: 234.012 (lr:0.0001)
82960: accuracy:0.3 loss: 241.924 (lr:0.0001)
82980: accuracy:0.25 loss: 249.785 (lr:0.0001)
83000: accuracy:0.32 loss: 239.469 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
83000: ********* epoch 9 ********* test accuracy for all:0.214973 test loss: 268.679
83000: ********* epoch 9 ********* test accuracy for mode 0:0.043 test loss: 409.787
83000: ********* epoch 9 ********* test accuracy for mode 1:0.0195 test loss: 452.516
83000: ********* epoch 9 ********* test accuracy for mode 2:0.09 test loss: 282.145
83000: ********* epoch 9 ********* test accuracy for mode 24:0.2065 test loss: 273.852
83000: ********* epoch 9 ********* test accuracy for mode 25:0.3275 test loss: 251.355
83000: ********* epoch 9 ********* test accuracy for mode 26:0.2495 test loss: 194.946
83000: ********* epoch 9 ********* test accuracy for mode 27:0.242 test loss: 278.209
83000: ********* epoch 9 ********* test accuracy for mode 28:0.2795 test loss: 262.465
83000: ********* epoch 9 ********* test accuracy for mode 29:0.2545 test loss: 266.695
83000: ********* epoch 9 ********* test accuracy for mode 30:0.16 test loss: 261.658
83000: ********* epoch 9 ********* test accuracy for mode 31:0.185 test loss: 258.563
83000: ********* epoch 9 ********* test accuracy for mode 32:0.237 test loss: 248.689
83000: ********* epoch 9 ********* test accuracy for mode 33:0.1685 test loss: 254.556
83000: ********* epoch 9 ********* test accuracy for mode 34:0.0255 test loss: 261.015
83000: ********* epoch 9 ********* test accuracy for mode 35:0.0915 test loss: 452.969
83000: ********* epoch 9 ********* test accuracy for mode 36:0.2625 test loss: 465.365
83020: accuracy:0.25 loss: 244.418 (lr:0.0001)
83040: accuracy:0.3 loss: 243.726 (lr:0.0001)
83060: accuracy:0.25 loss: 233.077 (lr:0.0001)
83080: accuracy:0.21 loss: 240.93 (lr:0.0001)
83100: accuracy:0.29 loss: 238.511 (lr:0.0001)
83120: accuracy:0.22 loss: 258.606 (lr:0.0001)
83140: accuracy:0.31 loss: 226.959 (lr:0.0001)
83160: accuracy:0.24 loss: 246.694 (lr:0.0001)
83180: accuracy:0.19 loss: 253.151 (lr:0.0001)
83200: accuracy:0.23 loss: 241.918 (lr:0.0001)
83220: accuracy:0.19 loss: 241.237 (lr:0.0001)
83240: accuracy:0.26 loss: 233.106 (lr:0.0001)
83260: accuracy:0.22 loss: 234.341 (lr:0.0001)
83280: accuracy:0.31 loss: 227.294 (lr:0.0001)
83300: accuracy:0.26 loss: 234.671 (lr:0.0001)
83320: accuracy:0.31 loss: 226.957 (lr:0.0001)
83340: accuracy:0.35 loss: 236.757 (lr:0.0001)
83360: accuracy:0.18 loss: 260.927 (lr:0.0001)
83380: accuracy:0.24 loss: 240.282 (lr:0.0001)
83400: accuracy:0.28 loss: 234.587 (lr:0.0001)
83420: accuracy:0.22 loss: 270.231 (lr:0.0001)
83440: accuracy:0.2 loss: 261.967 (lr:0.0001)
83460: accuracy:0.3 loss: 229.046 (lr:0.0001)
83480: accuracy:0.22 loss: 262.684 (lr:0.0001)
83500: accuracy:0.21 loss: 247.033 (lr:0.0001)
83520: accuracy:0.24 loss: 244.616 (lr:0.0001)
83540: accuracy:0.21 loss: 248.662 (lr:0.0001)
83560: accuracy:0.2 loss: 240.033 (lr:0.0001)
83580: accuracy:0.32 loss: 238.766 (lr:0.0001)
83600: accuracy:0.23 loss: 264.677 (lr:0.0001)
83620: accuracy:0.23 loss: 248.786 (lr:0.0001)
83640: accuracy:0.21 loss: 237.107 (lr:0.0001)
83660: accuracy:0.22 loss: 260.461 (lr:0.0001)
83680: accuracy:0.22 loss: 248.866 (lr:0.0001)
83700: accuracy:0.18 loss: 257.735 (lr:0.0001)
83720: accuracy:0.25 loss: 259.551 (lr:0.0001)
83740: accuracy:0.31 loss: 225.976 (lr:0.0001)
83760: accuracy:0.25 loss: 238.256 (lr:0.0001)
83780: accuracy:0.22 loss: 242.369 (lr:0.0001)
83800: accuracy:0.34 loss: 214.291 (lr:0.0001)
83820: accuracy:0.29 loss: 237.751 (lr:0.0001)
83840: accuracy:0.22 loss: 244.025 (lr:0.0001)
83860: accuracy:0.29 loss: 222.949 (lr:0.0001)
83880: accuracy:0.27 loss: 238.355 (lr:0.0001)
83900: accuracy:0.17 loss: 255.609 (lr:0.0001)
83920: accuracy:0.26 loss: 257.027 (lr:0.0001)
83940: accuracy:0.22 loss: 237.382 (lr:0.0001)
83960: accuracy:0.35 loss: 212.668 (lr:0.0001)
83980: accuracy:0.2 loss: 243.491 (lr:0.0001)
84000: accuracy:0.29 loss: 251.853 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
84000: ********* epoch 9 ********* test accuracy for all:0.213392 test loss: 266.97
84000: ********* epoch 9 ********* test accuracy for mode 0:0.0405 test loss: 415.071
84000: ********* epoch 9 ********* test accuracy for mode 1:0.0215 test loss: 453.763
84000: ********* epoch 9 ********* test accuracy for mode 2:0.0895 test loss: 282.995
84000: ********* epoch 9 ********* test accuracy for mode 24:0.2285 test loss: 269.12
84000: ********* epoch 9 ********* test accuracy for mode 25:0.314 test loss: 244.537
84000: ********* epoch 9 ********* test accuracy for mode 26:0.3185 test loss: 186.252
84000: ********* epoch 9 ********* test accuracy for mode 27:0.273 test loss: 262.153
84000: ********* epoch 9 ********* test accuracy for mode 28:0.2815 test loss: 250.162
84000: ********* epoch 9 ********* test accuracy for mode 29:0.271 test loss: 258.315
84000: ********* epoch 9 ********* test accuracy for mode 30:0.172 test loss: 257.002
84000: ********* epoch 9 ********* test accuracy for mode 31:0.1935 test loss: 256.531
84000: ********* epoch 9 ********* test accuracy for mode 32:0.224 test loss: 248.166
84000: ********* epoch 9 ********* test accuracy for mode 33:0.1695 test loss: 253.519
84000: ********* epoch 9 ********* test accuracy for mode 34:0.0195 test loss: 261.596
84000: ********* epoch 9 ********* test accuracy for mode 35:0.0695 test loss: 445.91
84000: ********* epoch 9 ********* test accuracy for mode 36:0.0945 test loss: 461.085
84020: accuracy:0.2 loss: 257.214 (lr:0.0001)
84040: accuracy:0.29 loss: 236.034 (lr:0.0001)
84060: accuracy:0.25 loss: 238.147 (lr:0.0001)
84080: accuracy:0.25 loss: 247.792 (lr:0.0001)
84100: accuracy:0.21 loss: 251.832 (lr:0.0001)
84120: accuracy:0.33 loss: 234.107 (lr:0.0001)
84140: accuracy:0.21 loss: 250.945 (lr:0.0001)
84160: accuracy:0.31 loss: 229.018 (lr:0.0001)
84180: accuracy:0.29 loss: 240.686 (lr:0.0001)
84200: accuracy:0.19 loss: 250.313 (lr:0.0001)
84220: accuracy:0.25 loss: 228.072 (lr:0.0001)
84240: accuracy:0.33 loss: 223.385 (lr:0.0001)
84260: accuracy:0.25 loss: 234.643 (lr:0.0001)
84280: accuracy:0.22 loss: 245.717 (lr:0.0001)
84300: accuracy:0.19 loss: 246.856 (lr:0.0001)
84320: accuracy:0.23 loss: 250.038 (lr:0.0001)
84340: accuracy:0.28 loss: 240.983 (lr:0.0001)
84360: accuracy:0.23 loss: 245.908 (lr:0.0001)
84380: accuracy:0.23 loss: 223.998 (lr:0.0001)
84400: accuracy:0.33 loss: 230.929 (lr:0.0001)
84420: accuracy:0.23 loss: 252.539 (lr:0.0001)
84440: accuracy:0.23 loss: 248.551 (lr:0.0001)
84460: accuracy:0.22 loss: 242.673 (lr:0.0001)
84480: accuracy:0.23 loss: 254.568 (lr:0.0001)
84500: accuracy:0.21 loss: 254.179 (lr:0.0001)
84520: accuracy:0.25 loss: 241.282 (lr:0.0001)
84540: accuracy:0.21 loss: 246.456 (lr:0.0001)
84560: accuracy:0.2 loss: 255.84 (lr:0.0001)
84580: accuracy:0.24 loss: 238.432 (lr:0.0001)
84600: accuracy:0.19 loss: 255.421 (lr:0.0001)
84620: accuracy:0.24 loss: 241.974 (lr:0.0001)
84640: accuracy:0.33 loss: 227.966 (lr:0.0001)
84660: accuracy:0.24 loss: 242.774 (lr:0.0001)
84680: accuracy:0.24 loss: 241.553 (lr:0.0001)
84700: accuracy:0.22 loss: 243.833 (lr:0.0001)
84720: accuracy:0.24 loss: 241.64 (lr:0.0001)
84740: accuracy:0.24 loss: 257.204 (lr:0.0001)
84760: accuracy:0.2 loss: 254.329 (lr:0.0001)
84780: accuracy:0.22 loss: 242.296 (lr:0.0001)
84800: accuracy:0.26 loss: 235.562 (lr:0.0001)
84820: accuracy:0.26 loss: 247.713 (lr:0.0001)
84840: accuracy:0.34 loss: 232.783 (lr:0.0001)
84860: accuracy:0.22 loss: 243.514 (lr:0.0001)
84880: accuracy:0.34 loss: 236.668 (lr:0.0001)
84900: accuracy:0.25 loss: 228.51 (lr:0.0001)
84920: accuracy:0.19 loss: 247.645 (lr:0.0001)
84940: accuracy:0.26 loss: 228.95 (lr:0.0001)
84960: accuracy:0.32 loss: 235.775 (lr:0.0001)
84980: accuracy:0.29 loss: 240.066 (lr:0.0001)
85000: accuracy:0.19 loss: 251.386 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
85000: ********* epoch 9 ********* test accuracy for all:0.212703 test loss: 268.212
85000: ********* epoch 9 ********* test accuracy for mode 0:0.041 test loss: 409.005
85000: ********* epoch 9 ********* test accuracy for mode 1:0.0235 test loss: 448.666
85000: ********* epoch 9 ********* test accuracy for mode 2:0.092 test loss: 280.308
85000: ********* epoch 9 ********* test accuracy for mode 24:0.231 test loss: 274.05
85000: ********* epoch 9 ********* test accuracy for mode 25:0.2905 test loss: 257.042
85000: ********* epoch 9 ********* test accuracy for mode 26:0.3125 test loss: 188.106
85000: ********* epoch 9 ********* test accuracy for mode 27:0.253 test loss: 271.783
85000: ********* epoch 9 ********* test accuracy for mode 28:0.282 test loss: 255.743
85000: ********* epoch 9 ********* test accuracy for mode 29:0.277 test loss: 259.12
85000: ********* epoch 9 ********* test accuracy for mode 30:0.1685 test loss: 255.346
85000: ********* epoch 9 ********* test accuracy for mode 31:0.1945 test loss: 250.757
85000: ********* epoch 9 ********* test accuracy for mode 32:0.2665 test loss: 240.014
85000: ********* epoch 9 ********* test accuracy for mode 33:0.1595 test loss: 249.175
85000: ********* epoch 9 ********* test accuracy for mode 34:0.02 test loss: 257.734
85000: ********* epoch 9 ********* test accuracy for mode 35:0.0815 test loss: 451.852
85000: ********* epoch 9 ********* test accuracy for mode 36:0.0695 test loss: 468.524
85020: accuracy:0.24 loss: 244.891 (lr:0.0001)
85040: accuracy:0.34 loss: 237.767 (lr:0.0001)
85060: accuracy:0.21 loss: 244.393 (lr:0.0001)
85080: accuracy:0.26 loss: 238.801 (lr:0.0001)
85100: accuracy:0.23 loss: 268.15 (lr:0.0001)
85120: accuracy:0.19 loss: 250.505 (lr:0.0001)
85140: accuracy:0.2 loss: 261.671 (lr:0.0001)
85160: accuracy:0.19 loss: 235.043 (lr:0.0001)
85180: accuracy:0.29 loss: 237.944 (lr:0.0001)
85200: accuracy:0.32 loss: 233.702 (lr:0.0001)
85220: accuracy:0.32 loss: 247.272 (lr:0.0001)
85240: accuracy:0.23 loss: 237.672 (lr:0.0001)
85260: accuracy:0.26 loss: 250.331 (lr:0.0001)
85280: accuracy:0.23 loss: 231.698 (lr:0.0001)
85300: accuracy:0.34 loss: 224.816 (lr:0.0001)
85320: accuracy:0.32 loss: 226.318 (lr:0.0001)
85340: accuracy:0.21 loss: 247.653 (lr:0.0001)
85360: accuracy:0.18 loss: 238.771 (lr:0.0001)
85380: accuracy:0.2 loss: 252.19 (lr:0.0001)
85400: accuracy:0.22 loss: 250.454 (lr:0.0001)
85420: accuracy:0.29 loss: 230.395 (lr:0.0001)
85440: accuracy:0.27 loss: 241.28 (lr:0.0001)
85460: accuracy:0.27 loss: 227.53 (lr:0.0001)
85480: accuracy:0.25 loss: 232.281 (lr:0.0001)
85500: accuracy:0.28 loss: 242.305 (lr:0.0001)
85520: accuracy:0.19 loss: 240.44 (lr:0.0001)
85540: accuracy:0.19 loss: 276.748 (lr:0.0001)
85560: accuracy:0.25 loss: 231.218 (lr:0.0001)
85580: accuracy:0.23 loss: 238.54 (lr:0.0001)
85600: accuracy:0.26 loss: 235.871 (lr:0.0001)
85620: accuracy:0.26 loss: 271.151 (lr:0.0001)
85640: accuracy:0.3 loss: 248.605 (lr:0.0001)
85660: accuracy:0.25 loss: 238.001 (lr:0.0001)
85680: accuracy:0.23 loss: 236.212 (lr:0.0001)
85700: accuracy:0.22 loss: 266.352 (lr:0.0001)
85720: accuracy:0.23 loss: 235.126 (lr:0.0001)
85740: accuracy:0.3 loss: 240.904 (lr:0.0001)
85760: accuracy:0.25 loss: 243.113 (lr:0.0001)
85780: accuracy:0.3 loss: 240.594 (lr:0.0001)
85800: accuracy:0.28 loss: 240.717 (lr:0.0001)
85820: accuracy:0.29 loss: 227.949 (lr:0.0001)
85840: accuracy:0.24 loss: 227.897 (lr:0.0001)
85860: accuracy:0.26 loss: 266.441 (lr:0.0001)
85880: accuracy:0.3 loss: 231.157 (lr:0.0001)
85900: accuracy:0.24 loss: 235.668 (lr:0.0001)
85920: accuracy:0.28 loss: 246.346 (lr:0.0001)
85940: accuracy:0.26 loss: 242.133 (lr:0.0001)
85960: accuracy:0.3 loss: 227.323 (lr:0.0001)
85980: accuracy:0.23 loss: 237.85 (lr:0.0001)
86000: accuracy:0.29 loss: 249.086 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
86000: ********* epoch 9 ********* test accuracy for all:0.224054 test loss: 265.962
86000: ********* epoch 9 ********* test accuracy for mode 0:0.04 test loss: 413.986
86000: ********* epoch 9 ********* test accuracy for mode 1:0.0145 test loss: 446.626
86000: ********* epoch 9 ********* test accuracy for mode 2:0.0645 test loss: 283.406
86000: ********* epoch 9 ********* test accuracy for mode 24:0.255 test loss: 258.951
86000: ********* epoch 9 ********* test accuracy for mode 25:0.2945 test loss: 244.98
86000: ********* epoch 9 ********* test accuracy for mode 26:0.3175 test loss: 181.285
86000: ********* epoch 9 ********* test accuracy for mode 27:0.2795 test loss: 251.283
86000: ********* epoch 9 ********* test accuracy for mode 28:0.3365 test loss: 236.047
86000: ********* epoch 9 ********* test accuracy for mode 29:0.2625 test loss: 247.616
86000: ********* epoch 9 ********* test accuracy for mode 30:0.228 test loss: 244.995
86000: ********* epoch 9 ********* test accuracy for mode 31:0.1705 test loss: 248.265
86000: ********* epoch 9 ********* test accuracy for mode 32:0.273 test loss: 237.616
86000: ********* epoch 9 ********* test accuracy for mode 33:0.157 test loss: 248.632
86000: ********* epoch 9 ********* test accuracy for mode 34:0.0215 test loss: 257.092
86000: ********* epoch 9 ********* test accuracy for mode 35:0.1155 test loss: 434.871
86000: ********* epoch 9 ********* test accuracy for mode 36:0.3705 test loss: 438.637
86020: accuracy:0.2 loss: 238.689 (lr:0.0001)
86040: accuracy:0.23 loss: 242.579 (lr:0.0001)
86060: accuracy:0.26 loss: 246.119 (lr:0.0001)
86080: accuracy:0.24 loss: 235.904 (lr:0.0001)
86100: accuracy:0.33 loss: 231.862 (lr:0.0001)
86120: accuracy:0.25 loss: 232.266 (lr:0.0001)
86140: accuracy:0.29 loss: 231.897 (lr:0.0001)
86160: accuracy:0.2 loss: 237.111 (lr:0.0001)
86180: accuracy:0.22 loss: 228.55 (lr:0.0001)
86200: accuracy:0.24 loss: 237.954 (lr:0.0001)
86220: accuracy:0.2 loss: 234.959 (lr:0.0001)
86240: accuracy:0.29 loss: 245.673 (lr:0.0001)
86260: accuracy:0.2 loss: 251.637 (lr:0.0001)
86280: accuracy:0.24 loss: 255.135 (lr:0.0001)
86300: accuracy:0.26 loss: 251.08 (lr:0.0001)
86320: accuracy:0.27 loss: 247.431 (lr:0.0001)
86340: accuracy:0.29 loss: 237.426 (lr:0.0001)
86360: accuracy:0.28 loss: 231.093 (lr:0.0001)
86380: accuracy:0.24 loss: 247.349 (lr:0.0001)
86400: accuracy:0.29 loss: 235.246 (lr:0.0001)
86420: accuracy:0.21 loss: 265.878 (lr:0.0001)
86440: accuracy:0.18 loss: 254.739 (lr:0.0001)
86460: accuracy:0.26 loss: 241.095 (lr:0.0001)
86480: accuracy:0.28 loss: 226.107 (lr:0.0001)
86500: accuracy:0.28 loss: 243.447 (lr:0.0001)
86520: accuracy:0.24 loss: 251.096 (lr:0.0001)
86540: accuracy:0.26 loss: 250.45 (lr:0.0001)
86560: accuracy:0.21 loss: 238.708 (lr:0.0001)
86580: accuracy:0.27 loss: 239.833 (lr:0.0001)
86600: accuracy:0.17 loss: 246.447 (lr:0.0001)
86620: accuracy:0.26 loss: 222.367 (lr:0.0001)
86640: accuracy:0.27 loss: 234.925 (lr:0.0001)
86660: accuracy:0.28 loss: 227.328 (lr:0.0001)
86680: accuracy:0.28 loss: 236.222 (lr:0.0001)
86700: accuracy:0.33 loss: 231.945 (lr:0.0001)
86720: accuracy:0.21 loss: 253.955 (lr:0.0001)
86740: accuracy:0.21 loss: 257.561 (lr:0.0001)
86760: accuracy:0.27 loss: 237.692 (lr:0.0001)
86780: accuracy:0.28 loss: 242.349 (lr:0.0001)
86800: accuracy:0.26 loss: 249.112 (lr:0.0001)
86820: accuracy:0.24 loss: 237.339 (lr:0.0001)
86840: accuracy:0.31 loss: 242.078 (lr:0.0001)
86860: accuracy:0.29 loss: 223.726 (lr:0.0001)
86880: accuracy:0.25 loss: 231.796 (lr:0.0001)
86900: accuracy:0.26 loss: 247.778 (lr:0.0001)
86920: accuracy:0.3 loss: 237.589 (lr:0.0001)
86940: accuracy:0.31 loss: 229.289 (lr:0.0001)
86960: accuracy:0.24 loss: 224.534 (lr:0.0001)
86980: accuracy:0.2 loss: 260.397 (lr:0.0001)
87000: accuracy:0.21 loss: 235.142 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
87000: ********* epoch 9 ********* test accuracy for all:0.22027 test loss: 265.947
87000: ********* epoch 9 ********* test accuracy for mode 0:0.046 test loss: 402.096
87000: ********* epoch 9 ********* test accuracy for mode 1:0.03 test loss: 434.791
87000: ********* epoch 9 ********* test accuracy for mode 2:0.074 test loss: 284.665
87000: ********* epoch 9 ********* test accuracy for mode 24:0.2725 test loss: 258.429
87000: ********* epoch 9 ********* test accuracy for mode 25:0.2605 test loss: 252.505
87000: ********* epoch 9 ********* test accuracy for mode 26:0.393 test loss: 183.693
87000: ********* epoch 9 ********* test accuracy for mode 27:0.26 test loss: 267.026
87000: ********* epoch 9 ********* test accuracy for mode 28:0.3155 test loss: 252.502
87000: ********* epoch 9 ********* test accuracy for mode 29:0.2755 test loss: 262.926
87000: ********* epoch 9 ********* test accuracy for mode 30:0.169 test loss: 262.256
87000: ********* epoch 9 ********* test accuracy for mode 31:0.1615 test loss: 262.049
87000: ********* epoch 9 ********* test accuracy for mode 32:0.251 test loss: 249.525
87000: ********* epoch 9 ********* test accuracy for mode 33:0.14 test loss: 259.432
87000: ********* epoch 9 ********* test accuracy for mode 34:0.0355 test loss: 264.059
87000: ********* epoch 9 ********* test accuracy for mode 35:0.092 test loss: 439.863
87000: ********* epoch 9 ********* test accuracy for mode 36:0.308 test loss: 445.199
87020: accuracy:0.21 loss: 262.947 (lr:0.0001)
87040: accuracy:0.17 loss: 234.339 (lr:0.0001)
87060: accuracy:0.33 loss: 230.324 (lr:0.0001)
87080: accuracy:0.36 loss: 227.99 (lr:0.0001)
87100: accuracy:0.23 loss: 251.659 (lr:0.0001)
87120: accuracy:0.23 loss: 263.251 (lr:0.0001)
87140: accuracy:0.24 loss: 248.104 (lr:0.0001)
87160: accuracy:0.26 loss: 232.76 (lr:0.0001)
87180: accuracy:0.22 loss: 238.832 (lr:0.0001)
87200: accuracy:0.34 loss: 231.556 (lr:0.0001)
87220: accuracy:0.3 loss: 241.832 (lr:0.0001)
87240: accuracy:0.21 loss: 259.323 (lr:0.0001)
87260: accuracy:0.32 loss: 219.63 (lr:0.0001)
87280: accuracy:0.33 loss: 235.219 (lr:0.0001)
87300: accuracy:0.23 loss: 250.653 (lr:0.0001)
87320: accuracy:0.18 loss: 237.426 (lr:0.0001)
87340: accuracy:0.28 loss: 243.079 (lr:0.0001)
87360: accuracy:0.32 loss: 237.797 (lr:0.0001)
87380: accuracy:0.27 loss: 239.573 (lr:0.0001)
87400: accuracy:0.27 loss: 227.597 (lr:0.0001)
87420: accuracy:0.22 loss: 246.925 (lr:0.0001)
87440: accuracy:0.21 loss: 267.885 (lr:0.0001)
87460: accuracy:0.25 loss: 251.841 (lr:0.0001)
87480: accuracy:0.22 loss: 252.933 (lr:0.0001)
87500: accuracy:0.24 loss: 247.281 (lr:0.0001)
87520: accuracy:0.26 loss: 242.551 (lr:0.0001)
87540: accuracy:0.25 loss: 232.984 (lr:0.0001)
87560: accuracy:0.33 loss: 231.381 (lr:0.0001)
87580: accuracy:0.2 loss: 244.964 (lr:0.0001)
87600: accuracy:0.23 loss: 232.996 (lr:0.0001)
87620: accuracy:0.31 loss: 240.62 (lr:0.0001)
87640: accuracy:0.28 loss: 242.841 (lr:0.0001)
87660: accuracy:0.28 loss: 229.89 (lr:0.0001)
87680: accuracy:0.23 loss: 231.243 (lr:0.0001)
87700: accuracy:0.19 loss: 243.124 (lr:0.0001)
87720: accuracy:0.25 loss: 235.322 (lr:0.0001)
87740: accuracy:0.34 loss: 228.3 (lr:0.0001)
87760: accuracy:0.39 loss: 215.143 (lr:0.0001)
87780: accuracy:0.31 loss: 226.038 (lr:0.0001)
87800: accuracy:0.25 loss: 229.144 (lr:0.0001)
87820: accuracy:0.3 loss: 238.463 (lr:0.0001)
87840: accuracy:0.22 loss: 240.232 (lr:0.0001)
87860: accuracy:0.23 loss: 232.149 (lr:0.0001)
87880: accuracy:0.31 loss: 222.212 (lr:0.0001)
87900: accuracy:0.25 loss: 248.698 (lr:0.0001)
87920: accuracy:0.27 loss: 236.561 (lr:0.0001)
87940: accuracy:0.27 loss: 266.471 (lr:0.0001)
87960: accuracy:0.23 loss: 244.954 (lr:0.0001)
87980: accuracy:0.21 loss: 235.552 (lr:0.0001)
88000: accuracy:0.26 loss: 227.463 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
88000: ********* epoch 10 ********* test accuracy for all:0.221068 test loss: 263.78
88000: ********* epoch 10 ********* test accuracy for mode 0:0.0435 test loss: 403.545
88000: ********* epoch 10 ********* test accuracy for mode 1:0.038 test loss: 427.419
88000: ********* epoch 10 ********* test accuracy for mode 2:0.0615 test loss: 286.796
88000: ********* epoch 10 ********* test accuracy for mode 24:0.273 test loss: 250.383
88000: ********* epoch 10 ********* test accuracy for mode 25:0.295 test loss: 239.406
88000: ********* epoch 10 ********* test accuracy for mode 26:0.385 test loss: 177.605
88000: ********* epoch 10 ********* test accuracy for mode 27:0.2725 test loss: 260.583
88000: ********* epoch 10 ********* test accuracy for mode 28:0.252 test loss: 254.132
88000: ********* epoch 10 ********* test accuracy for mode 29:0.2775 test loss: 262.702
88000: ********* epoch 10 ********* test accuracy for mode 30:0.154 test loss: 266.49
88000: ********* epoch 10 ********* test accuracy for mode 31:0.1655 test loss: 267.7
88000: ********* epoch 10 ********* test accuracy for mode 32:0.2205 test loss: 258.916
88000: ********* epoch 10 ********* test accuracy for mode 33:0.1195 test loss: 267.829
88000: ********* epoch 10 ********* test accuracy for mode 34:0.0355 test loss: 268.521
88000: ********* epoch 10 ********* test accuracy for mode 35:0.1445 test loss: 409.961
88000: ********* epoch 10 ********* test accuracy for mode 36:0.366 test loss: 418.968
88020: accuracy:0.3 loss: 225.7 (lr:0.0001)
88040: accuracy:0.25 loss: 239.156 (lr:0.0001)
88060: accuracy:0.22 loss: 258.265 (lr:0.0001)
88080: accuracy:0.22 loss: 236.597 (lr:0.0001)
88100: accuracy:0.28 loss: 244.885 (lr:0.0001)
88120: accuracy:0.33 loss: 228.65 (lr:0.0001)
88140: accuracy:0.22 loss: 249.126 (lr:0.0001)
88160: accuracy:0.24 loss: 243.768 (lr:0.0001)
88180: accuracy:0.25 loss: 247.395 (lr:0.0001)
88200: accuracy:0.21 loss: 248.928 (lr:0.0001)
88220: accuracy:0.31 loss: 224.835 (lr:0.0001)
88240: accuracy:0.21 loss: 245.786 (lr:0.0001)
88260: accuracy:0.26 loss: 240.46 (lr:0.0001)
88280: accuracy:0.24 loss: 225.862 (lr:0.0001)
88300: accuracy:0.25 loss: 238.97 (lr:0.0001)
88320: accuracy:0.31 loss: 240.287 (lr:0.0001)
88340: accuracy:0.19 loss: 258.053 (lr:0.0001)
88360: accuracy:0.24 loss: 226.303 (lr:0.0001)
88380: accuracy:0.18 loss: 260.019 (lr:0.0001)
88400: accuracy:0.17 loss: 237.13 (lr:0.0001)
88420: accuracy:0.21 loss: 239.34 (lr:0.0001)
88440: accuracy:0.32 loss: 247.006 (lr:0.0001)
88460: accuracy:0.21 loss: 241.805 (lr:0.0001)
88480: accuracy:0.27 loss: 245.914 (lr:0.0001)
88500: accuracy:0.21 loss: 243.16 (lr:0.0001)
88520: accuracy:0.23 loss: 233.189 (lr:0.0001)
88540: accuracy:0.2 loss: 244.536 (lr:0.0001)
88560: accuracy:0.24 loss: 237.098 (lr:0.0001)
88580: accuracy:0.28 loss: 238.155 (lr:0.0001)
88600: accuracy:0.32 loss: 214.869 (lr:0.0001)
88620: accuracy:0.3 loss: 252.732 (lr:0.0001)
88640: accuracy:0.29 loss: 229.583 (lr:0.0001)
88660: accuracy:0.27 loss: 234.059 (lr:0.0001)
88680: accuracy:0.2 loss: 231.91 (lr:0.0001)
88700: accuracy:0.24 loss: 244.731 (lr:0.0001)
88720: accuracy:0.34 loss: 220.146 (lr:0.0001)
88740: accuracy:0.26 loss: 230.427 (lr:0.0001)
88760: accuracy:0.26 loss: 235.908 (lr:0.0001)
88780: accuracy:0.18 loss: 244.411 (lr:0.0001)
88800: accuracy:0.23 loss: 249.837 (lr:0.0001)
88820: accuracy:0.25 loss: 236.309 (lr:0.0001)
88840: accuracy:0.22 loss: 224.174 (lr:0.0001)
88860: accuracy:0.24 loss: 254.925 (lr:0.0001)
88880: accuracy:0.29 loss: 243.777 (lr:0.0001)
88900: accuracy:0.23 loss: 243.129 (lr:0.0001)
88920: accuracy:0.2 loss: 244.123 (lr:0.0001)
88940: accuracy:0.26 loss: 243.06 (lr:0.0001)
88960: accuracy:0.23 loss: 230.172 (lr:0.0001)
88980: accuracy:0.25 loss: 224.003 (lr:0.0001)
89000: accuracy:0.32 loss: 225.945 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
89000: ********* epoch 10 ********* test accuracy for all:0.209473 test loss: 269.186
89000: ********* epoch 10 ********* test accuracy for mode 0:0.048 test loss: 410.798
89000: ********* epoch 10 ********* test accuracy for mode 1:0.0215 test loss: 448.017
89000: ********* epoch 10 ********* test accuracy for mode 2:0.0895 test loss: 281.325
89000: ********* epoch 10 ********* test accuracy for mode 24:0.1985 test loss: 277.923
89000: ********* epoch 10 ********* test accuracy for mode 25:0.3015 test loss: 253.931
89000: ********* epoch 10 ********* test accuracy for mode 26:0.2455 test loss: 192.411
89000: ********* epoch 10 ********* test accuracy for mode 27:0.2765 test loss: 268.303
89000: ********* epoch 10 ********* test accuracy for mode 28:0.2675 test loss: 256.52
89000: ********* epoch 10 ********* test accuracy for mode 29:0.2695 test loss: 259.106
89000: ********* epoch 10 ********* test accuracy for mode 30:0.1895 test loss: 252.149
89000: ********* epoch 10 ********* test accuracy for mode 31:0.2345 test loss: 250.89
89000: ********* epoch 10 ********* test accuracy for mode 32:0.188 test loss: 246.535
89000: ********* epoch 10 ********* test accuracy for mode 33:0.202 test loss: 249.166
89000: ********* epoch 10 ********* test accuracy for mode 34:0.0245 test loss: 259.638
89000: ********* epoch 10 ********* test accuracy for mode 35:0.0805 test loss: 463.381
89000: ********* epoch 10 ********* test accuracy for mode 36:0.0275 test loss: 500.046
89020: accuracy:0.21 loss: 239.42 (lr:0.0001)
89040: accuracy:0.22 loss: 249.194 (lr:0.0001)
89060: accuracy:0.29 loss: 228.972 (lr:0.0001)
89080: accuracy:0.22 loss: 248.407 (lr:0.0001)
89100: accuracy:0.3 loss: 228.158 (lr:0.0001)
89120: accuracy:0.32 loss: 235.847 (lr:0.0001)
89140: accuracy:0.2 loss: 244.863 (lr:0.0001)
89160: accuracy:0.21 loss: 280.781 (lr:0.0001)
89180: accuracy:0.26 loss: 242.438 (lr:0.0001)
89200: accuracy:0.31 loss: 232.942 (lr:0.0001)
89220: accuracy:0.3 loss: 226.309 (lr:0.0001)
89240: accuracy:0.29 loss: 245.03 (lr:0.0001)
89260: accuracy:0.3 loss: 230.031 (lr:0.0001)
89280: accuracy:0.16 loss: 249.196 (lr:0.0001)
89300: accuracy:0.27 loss: 230.565 (lr:0.0001)
89320: accuracy:0.23 loss: 234.013 (lr:0.0001)
89340: accuracy:0.22 loss: 241.646 (lr:0.0001)
89360: accuracy:0.23 loss: 245.473 (lr:0.0001)
89380: accuracy:0.34 loss: 221.283 (lr:0.0001)
89400: accuracy:0.16 loss: 262.225 (lr:0.0001)
89420: accuracy:0.23 loss: 241.128 (lr:0.0001)
89440: accuracy:0.32 loss: 234.272 (lr:0.0001)
89460: accuracy:0.28 loss: 241.424 (lr:0.0001)
89480: accuracy:0.31 loss: 246.514 (lr:0.0001)
89500: accuracy:0.2 loss: 250.562 (lr:0.0001)
89520: accuracy:0.25 loss: 242.016 (lr:0.0001)
89540: accuracy:0.21 loss: 256.299 (lr:0.0001)
89560: accuracy:0.22 loss: 263.495 (lr:0.0001)
89580: accuracy:0.27 loss: 245.669 (lr:0.0001)
89600: accuracy:0.19 loss: 239.401 (lr:0.0001)
89620: accuracy:0.28 loss: 236.222 (lr:0.0001)
89640: accuracy:0.26 loss: 222.676 (lr:0.0001)
89660: accuracy:0.26 loss: 223.979 (lr:0.0001)
89680: accuracy:0.25 loss: 257.702 (lr:0.0001)
89700: accuracy:0.25 loss: 254.156 (lr:0.0001)
89720: accuracy:0.25 loss: 239.493 (lr:0.0001)
89740: accuracy:0.27 loss: 249.6 (lr:0.0001)
89760: accuracy:0.24 loss: 239.495 (lr:0.0001)
89780: accuracy:0.28 loss: 249.958 (lr:0.0001)
89800: accuracy:0.16 loss: 256.932 (lr:0.0001)
89820: accuracy:0.33 loss: 230.158 (lr:0.0001)
89840: accuracy:0.29 loss: 223.018 (lr:0.0001)
89860: accuracy:0.25 loss: 231.399 (lr:0.0001)
89880: accuracy:0.18 loss: 270.607 (lr:0.0001)
89900: accuracy:0.23 loss: 230.862 (lr:0.0001)
89920: accuracy:0.34 loss: 222.228 (lr:0.0001)
89940: accuracy:0.21 loss: 242.225 (lr:0.0001)
89960: accuracy:0.31 loss: 230.352 (lr:0.0001)
89980: accuracy:0.33 loss: 222.33 (lr:0.0001)
90000: accuracy:0.25 loss: 245.399 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
90000: ********* epoch 10 ********* test accuracy for all:0.217824 test loss: 266.384
90000: ********* epoch 10 ********* test accuracy for mode 0:0.0455 test loss: 408.757
90000: ********* epoch 10 ********* test accuracy for mode 1:0.0245 test loss: 441.064
90000: ********* epoch 10 ********* test accuracy for mode 2:0.059 test loss: 283.279
90000: ********* epoch 10 ********* test accuracy for mode 24:0.218 test loss: 272.054
90000: ********* epoch 10 ********* test accuracy for mode 25:0.267 test loss: 255.179
90000: ********* epoch 10 ********* test accuracy for mode 26:0.346 test loss: 184.388
90000: ********* epoch 10 ********* test accuracy for mode 27:0.261 test loss: 267.135
90000: ********* epoch 10 ********* test accuracy for mode 28:0.294 test loss: 252.376
90000: ********* epoch 10 ********* test accuracy for mode 29:0.2815 test loss: 258.14
90000: ********* epoch 10 ********* test accuracy for mode 30:0.182 test loss: 257.145
90000: ********* epoch 10 ********* test accuracy for mode 31:0.1995 test loss: 255.631
90000: ********* epoch 10 ********* test accuracy for mode 32:0.248 test loss: 246.047
90000: ********* epoch 10 ********* test accuracy for mode 33:0.153 test loss: 253.79
90000: ********* epoch 10 ********* test accuracy for mode 34:0.0295 test loss: 258.894
90000: ********* epoch 10 ********* test accuracy for mode 35:0.12 test loss: 432.986
90000: ********* epoch 10 ********* test accuracy for mode 36:0.2375 test loss: 448.982
90020: accuracy:0.22 loss: 233.05 (lr:0.0001)
90040: accuracy:0.23 loss: 258.686 (lr:0.0001)
90060: accuracy:0.26 loss: 265.439 (lr:0.0001)
90080: accuracy:0.28 loss: 228.143 (lr:0.0001)
90100: accuracy:0.2 loss: 269.419 (lr:0.0001)
90120: accuracy:0.3 loss: 218.34 (lr:0.0001)
90140: accuracy:0.25 loss: 245.637 (lr:0.0001)
90160: accuracy:0.21 loss: 280.849 (lr:0.0001)
90180: accuracy:0.27 loss: 222.672 (lr:0.0001)
90200: accuracy:0.25 loss: 238.633 (lr:0.0001)
90220: accuracy:0.28 loss: 254.423 (lr:0.0001)
90240: accuracy:0.27 loss: 252.849 (lr:0.0001)
90260: accuracy:0.32 loss: 231.298 (lr:0.0001)
90280: accuracy:0.17 loss: 246.451 (lr:0.0001)
90300: accuracy:0.35 loss: 228.899 (lr:0.0001)
90320: accuracy:0.25 loss: 248.537 (lr:0.0001)
90340: accuracy:0.22 loss: 241.107 (lr:0.0001)
90360: accuracy:0.31 loss: 241.128 (lr:0.0001)
90380: accuracy:0.27 loss: 222.923 (lr:0.0001)
90400: accuracy:0.21 loss: 248.603 (lr:0.0001)
90420: accuracy:0.22 loss: 238.063 (lr:0.0001)
90440: accuracy:0.23 loss: 231.085 (lr:0.0001)
90460: accuracy:0.28 loss: 242.831 (lr:0.0001)
90480: accuracy:0.23 loss: 230.131 (lr:0.0001)
90500: accuracy:0.17 loss: 239.924 (lr:0.0001)
90520: accuracy:0.28 loss: 251.528 (lr:0.0001)
90540: accuracy:0.29 loss: 234.291 (lr:0.0001)
90560: accuracy:0.25 loss: 234.437 (lr:0.0001)
90580: accuracy:0.31 loss: 220.165 (lr:0.0001)
90600: accuracy:0.26 loss: 241.377 (lr:0.0001)
90620: accuracy:0.22 loss: 248.084 (lr:0.0001)
90640: accuracy:0.23 loss: 246.782 (lr:0.0001)
90660: accuracy:0.23 loss: 258.399 (lr:0.0001)
90680: accuracy:0.24 loss: 241.132 (lr:0.0001)
90700: accuracy:0.28 loss: 222.202 (lr:0.0001)
90720: accuracy:0.31 loss: 234.68 (lr:0.0001)
90740: accuracy:0.29 loss: 249.45 (lr:0.0001)
90760: accuracy:0.27 loss: 232.926 (lr:0.0001)
90780: accuracy:0.24 loss: 236.491 (lr:0.0001)
90800: accuracy:0.26 loss: 225.812 (lr:0.0001)
90820: accuracy:0.26 loss: 229.547 (lr:0.0001)
90840: accuracy:0.23 loss: 240.429 (lr:0.0001)
90860: accuracy:0.22 loss: 233.797 (lr:0.0001)
90880: accuracy:0.19 loss: 249.259 (lr:0.0001)
90900: accuracy:0.25 loss: 248.881 (lr:0.0001)
90920: accuracy:0.27 loss: 237.891 (lr:0.0001)
90940: accuracy:0.15 loss: 254.873 (lr:0.0001)
90960: accuracy:0.17 loss: 249.326 (lr:0.0001)
90980: accuracy:0.19 loss: 250.613 (lr:0.0001)
91000: accuracy:0.32 loss: 230.453 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
91000: ********* epoch 10 ********* test accuracy for all:0.215081 test loss: 268.046
91000: ********* epoch 10 ********* test accuracy for mode 0:0.0425 test loss: 408.007
91000: ********* epoch 10 ********* test accuracy for mode 1:0.034 test loss: 434.626
91000: ********* epoch 10 ********* test accuracy for mode 2:0.065 test loss: 284.841
91000: ********* epoch 10 ********* test accuracy for mode 24:0.2205 test loss: 277.138
91000: ********* epoch 10 ********* test accuracy for mode 25:0.279 test loss: 257.261
91000: ********* epoch 10 ********* test accuracy for mode 26:0.3905 test loss: 182.073
91000: ********* epoch 10 ********* test accuracy for mode 27:0.2725 test loss: 271.213
91000: ********* epoch 10 ********* test accuracy for mode 28:0.2895 test loss: 253.641
91000: ********* epoch 10 ********* test accuracy for mode 29:0.284 test loss: 262.497
91000: ********* epoch 10 ********* test accuracy for mode 30:0.188 test loss: 257.629
91000: ********* epoch 10 ********* test accuracy for mode 31:0.1715 test loss: 260.161
91000: ********* epoch 10 ********* test accuracy for mode 32:0.239 test loss: 248.859
91000: ********* epoch 10 ********* test accuracy for mode 33:0.144 test loss: 256.331
91000: ********* epoch 10 ********* test accuracy for mode 34:0.0275 test loss: 262.98
91000: ********* epoch 10 ********* test accuracy for mode 35:0.0965 test loss: 450.596
91000: ********* epoch 10 ********* test accuracy for mode 36:0.06 test loss: 477.395
91020: accuracy:0.35 loss: 235.251 (lr:0.0001)
91040: accuracy:0.22 loss: 243.889 (lr:0.0001)
91060: accuracy:0.29 loss: 242.695 (lr:0.0001)
91080: accuracy:0.31 loss: 248.154 (lr:0.0001)
91100: accuracy:0.18 loss: 242.554 (lr:0.0001)
91120: accuracy:0.33 loss: 231.33 (lr:0.0001)
91140: accuracy:0.25 loss: 240.628 (lr:0.0001)
91160: accuracy:0.3 loss: 212.951 (lr:0.0001)
91180: accuracy:0.25 loss: 246.883 (lr:0.0001)
91200: accuracy:0.29 loss: 239.903 (lr:0.0001)
91220: accuracy:0.25 loss: 232.027 (lr:0.0001)
91240: accuracy:0.29 loss: 240.464 (lr:0.0001)
91260: accuracy:0.22 loss: 251.803 (lr:0.0001)
91280: accuracy:0.27 loss: 258.197 (lr:0.0001)
91300: accuracy:0.31 loss: 224.315 (lr:0.0001)
91320: accuracy:0.26 loss: 238.871 (lr:0.0001)
91340: accuracy:0.21 loss: 256.081 (lr:0.0001)
91360: accuracy:0.23 loss: 243.298 (lr:0.0001)
91380: accuracy:0.26 loss: 235.986 (lr:0.0001)
91400: accuracy:0.3 loss: 247.04 (lr:0.0001)
91420: accuracy:0.24 loss: 247.054 (lr:0.0001)
91440: accuracy:0.37 loss: 210.878 (lr:0.0001)
91460: accuracy:0.18 loss: 247.091 (lr:0.0001)
91480: accuracy:0.22 loss: 224.345 (lr:0.0001)
91500: accuracy:0.25 loss: 234.52 (lr:0.0001)
91520: accuracy:0.31 loss: 239.031 (lr:0.0001)
91540: accuracy:0.29 loss: 236.179 (lr:0.0001)
91560: accuracy:0.19 loss: 263.505 (lr:0.0001)
91580: accuracy:0.29 loss: 235.74 (lr:0.0001)
91600: accuracy:0.25 loss: 237.873 (lr:0.0001)
91620: accuracy:0.27 loss: 242.974 (lr:0.0001)
91640: accuracy:0.25 loss: 231.065 (lr:0.0001)
91660: accuracy:0.32 loss: 222.161 (lr:0.0001)
91680: accuracy:0.37 loss: 226.291 (lr:0.0001)
91700: accuracy:0.26 loss: 222.02 (lr:0.0001)
91720: accuracy:0.28 loss: 241.755 (lr:0.0001)
91740: accuracy:0.25 loss: 249.066 (lr:0.0001)
91760: accuracy:0.27 loss: 243.593 (lr:0.0001)
91780: accuracy:0.23 loss: 232.816 (lr:0.0001)
91800: accuracy:0.24 loss: 245.371 (lr:0.0001)
91820: accuracy:0.32 loss: 249.576 (lr:0.0001)
91840: accuracy:0.24 loss: 246.621 (lr:0.0001)
91860: accuracy:0.23 loss: 238.406 (lr:0.0001)
91880: accuracy:0.25 loss: 236.993 (lr:0.0001)
91900: accuracy:0.27 loss: 246.02 (lr:0.0001)
91920: accuracy:0.2 loss: 230.753 (lr:0.0001)
91940: accuracy:0.26 loss: 240.004 (lr:0.0001)
91960: accuracy:0.28 loss: 242.154 (lr:0.0001)
91980: accuracy:0.28 loss: 239.863 (lr:0.0001)
92000: accuracy:0.25 loss: 231.624 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
92000: ********* epoch 10 ********* test accuracy for all:0.22277 test loss: 264.335
92000: ********* epoch 10 ********* test accuracy for mode 0:0.048 test loss: 404.751
92000: ********* epoch 10 ********* test accuracy for mode 1:0.031 test loss: 434.041
92000: ********* epoch 10 ********* test accuracy for mode 2:0.087 test loss: 283.73
92000: ********* epoch 10 ********* test accuracy for mode 24:0.235 test loss: 267.92
92000: ********* epoch 10 ********* test accuracy for mode 25:0.287 test loss: 249.198
92000: ********* epoch 10 ********* test accuracy for mode 26:0.378 test loss: 183.5
92000: ********* epoch 10 ********* test accuracy for mode 27:0.2545 test loss: 267.497
92000: ********* epoch 10 ********* test accuracy for mode 28:0.294 test loss: 248.906
92000: ********* epoch 10 ********* test accuracy for mode 29:0.278 test loss: 255.763
92000: ********* epoch 10 ********* test accuracy for mode 30:0.2035 test loss: 253.36
92000: ********* epoch 10 ********* test accuracy for mode 31:0.1605 test loss: 257.741
92000: ********* epoch 10 ********* test accuracy for mode 32:0.254 test loss: 247.168
92000: ********* epoch 10 ********* test accuracy for mode 33:0.16 test loss: 255.228
92000: ********* epoch 10 ********* test accuracy for mode 34:0.026 test loss: 262.31
92000: ********* epoch 10 ********* test accuracy for mode 35:0.115 test loss: 430.422
92000: ********* epoch 10 ********* test accuracy for mode 36:0.2455 test loss: 443.944
92020: accuracy:0.29 loss: 238.897 (lr:0.0001)
92040: accuracy:0.29 loss: 222.137 (lr:0.0001)
92060: accuracy:0.21 loss: 259.168 (lr:0.0001)
92080: accuracy:0.31 loss: 234.373 (lr:0.0001)
92100: accuracy:0.22 loss: 261.028 (lr:0.0001)
92120: accuracy:0.28 loss: 242.61 (lr:0.0001)
92140: accuracy:0.25 loss: 238.171 (lr:0.0001)
92160: accuracy:0.26 loss: 244.016 (lr:0.0001)
92180: accuracy:0.18 loss: 253.312 (lr:0.0001)
92200: accuracy:0.31 loss: 228.895 (lr:0.0001)
92220: accuracy:0.33 loss: 227.383 (lr:0.0001)
92240: accuracy:0.23 loss: 245.147 (lr:0.0001)
92260: accuracy:0.16 loss: 270.119 (lr:0.0001)
92280: accuracy:0.32 loss: 225.725 (lr:0.0001)
92300: accuracy:0.25 loss: 260.668 (lr:0.0001)
92320: accuracy:0.32 loss: 224.847 (lr:0.0001)
92340: accuracy:0.28 loss: 239.649 (lr:0.0001)
92360: accuracy:0.3 loss: 240.837 (lr:0.0001)
92380: accuracy:0.32 loss: 240.973 (lr:0.0001)
92400: accuracy:0.27 loss: 238.694 (lr:0.0001)
92420: accuracy:0.27 loss: 223.942 (lr:0.0001)
92440: accuracy:0.17 loss: 259.004 (lr:0.0001)
92460: accuracy:0.3 loss: 231.663 (lr:0.0001)
92480: accuracy:0.29 loss: 225.189 (lr:0.0001)
92500: accuracy:0.24 loss: 231.499 (lr:0.0001)
92520: accuracy:0.25 loss: 232.564 (lr:0.0001)
92540: accuracy:0.28 loss: 238.773 (lr:0.0001)
92560: accuracy:0.26 loss: 235.483 (lr:0.0001)
92580: accuracy:0.27 loss: 246.677 (lr:0.0001)
92600: accuracy:0.26 loss: 225.479 (lr:0.0001)
92620: accuracy:0.21 loss: 240.921 (lr:0.0001)
92640: accuracy:0.24 loss: 242.637 (lr:0.0001)
92660: accuracy:0.27 loss: 239.389 (lr:0.0001)
92680: accuracy:0.27 loss: 226.395 (lr:0.0001)
92700: accuracy:0.35 loss: 217.864 (lr:0.0001)
92720: accuracy:0.31 loss: 245.173 (lr:0.0001)
92740: accuracy:0.24 loss: 267.106 (lr:0.0001)
92760: accuracy:0.27 loss: 227.801 (lr:0.0001)
92780: accuracy:0.32 loss: 224.249 (lr:0.0001)
92800: accuracy:0.27 loss: 237.073 (lr:0.0001)
92820: accuracy:0.22 loss: 253.624 (lr:0.0001)
92840: accuracy:0.22 loss: 248.921 (lr:0.0001)
92860: accuracy:0.21 loss: 228.128 (lr:0.0001)
92880: accuracy:0.22 loss: 246.335 (lr:0.0001)
92900: accuracy:0.24 loss: 247.195 (lr:0.0001)
92920: accuracy:0.28 loss: 228.606 (lr:0.0001)
92940: accuracy:0.33 loss: 239.436 (lr:0.0001)
92960: accuracy:0.28 loss: 230.832 (lr:0.0001)
92980: accuracy:0.24 loss: 236.111 (lr:0.0001)
93000: accuracy:0.22 loss: 253.804 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
93000: ********* epoch 10 ********* test accuracy for all:0.216743 test loss: 265.564
93000: ********* epoch 10 ********* test accuracy for mode 0:0.0435 test loss: 416.047
93000: ********* epoch 10 ********* test accuracy for mode 1:0.0265 test loss: 449.72
93000: ********* epoch 10 ********* test accuracy for mode 2:0.089 test loss: 278.458
93000: ********* epoch 10 ********* test accuracy for mode 24:0.239 test loss: 262.009
93000: ********* epoch 10 ********* test accuracy for mode 25:0.3265 test loss: 243.765
93000: ********* epoch 10 ********* test accuracy for mode 26:0.3295 test loss: 184.03
93000: ********* epoch 10 ********* test accuracy for mode 27:0.27 test loss: 264.095
93000: ********* epoch 10 ********* test accuracy for mode 28:0.284 test loss: 254.547
93000: ********* epoch 10 ********* test accuracy for mode 29:0.2515 test loss: 264.067
93000: ********* epoch 10 ********* test accuracy for mode 30:0.1805 test loss: 258.846
93000: ********* epoch 10 ********* test accuracy for mode 31:0.1825 test loss: 258.547
93000: ********* epoch 10 ********* test accuracy for mode 32:0.2375 test loss: 248.785
93000: ********* epoch 10 ********* test accuracy for mode 33:0.151 test loss: 255.96
93000: ********* epoch 10 ********* test accuracy for mode 34:0.056 test loss: 259.741
93000: ********* epoch 10 ********* test accuracy for mode 35:0.0985 test loss: 439.075
93000: ********* epoch 10 ********* test accuracy for mode 36:0.0735 test loss: 454.419
93020: accuracy:0.25 loss: 264.725 (lr:0.0001)
93040: accuracy:0.24 loss: 234.158 (lr:0.0001)
93060: accuracy:0.29 loss: 227.156 (lr:0.0001)
93080: accuracy:0.24 loss: 248.99 (lr:0.0001)
93100: accuracy:0.17 loss: 250.358 (lr:0.0001)
93120: accuracy:0.23 loss: 245.027 (lr:0.0001)
93140: accuracy:0.23 loss: 241.126 (lr:0.0001)
93160: accuracy:0.25 loss: 245.169 (lr:0.0001)
93180: accuracy:0.3 loss: 229.622 (lr:0.0001)
93200: accuracy:0.25 loss: 239.479 (lr:0.0001)
93220: accuracy:0.34 loss: 221.973 (lr:0.0001)
93240: accuracy:0.25 loss: 230.301 (lr:0.0001)
93260: accuracy:0.28 loss: 243.519 (lr:0.0001)
93280: accuracy:0.26 loss: 230.77 (lr:0.0001)
93300: accuracy:0.24 loss: 247.495 (lr:0.0001)
93320: accuracy:0.32 loss: 225.649 (lr:0.0001)
93340: accuracy:0.31 loss: 230.898 (lr:0.0001)
93360: accuracy:0.31 loss: 237.436 (lr:0.0001)
93380: accuracy:0.25 loss: 226.784 (lr:0.0001)
93400: accuracy:0.23 loss: 254.938 (lr:0.0001)
93420: accuracy:0.17 loss: 246.723 (lr:0.0001)
93440: accuracy:0.25 loss: 255.117 (lr:0.0001)
93460: accuracy:0.33 loss: 217.455 (lr:0.0001)
93480: accuracy:0.27 loss: 242.041 (lr:0.0001)
93500: accuracy:0.38 loss: 219.634 (lr:0.0001)
93520: accuracy:0.26 loss: 251.807 (lr:0.0001)
93540: accuracy:0.21 loss: 229.446 (lr:0.0001)
93560: accuracy:0.28 loss: 218.615 (lr:0.0001)
93580: accuracy:0.21 loss: 229.389 (lr:0.0001)
93600: accuracy:0.23 loss: 234.015 (lr:0.0001)
93620: accuracy:0.16 loss: 240.914 (lr:0.0001)
93640: accuracy:0.18 loss: 251.303 (lr:0.0001)
93660: accuracy:0.33 loss: 224.608 (lr:0.0001)
93680: accuracy:0.26 loss: 239.756 (lr:0.0001)
93700: accuracy:0.25 loss: 245.11 (lr:0.0001)
93720: accuracy:0.27 loss: 248.419 (lr:0.0001)
93740: accuracy:0.26 loss: 234.149 (lr:0.0001)
93760: accuracy:0.25 loss: 245.449 (lr:0.0001)
93780: accuracy:0.27 loss: 236.992 (lr:0.0001)
93800: accuracy:0.32 loss: 222.981 (lr:0.0001)
93820: accuracy:0.27 loss: 218.511 (lr:0.0001)
93840: accuracy:0.32 loss: 235.481 (lr:0.0001)
93860: accuracy:0.24 loss: 256.366 (lr:0.0001)
93880: accuracy:0.33 loss: 219.777 (lr:0.0001)
93900: accuracy:0.31 loss: 234.815 (lr:0.0001)
93920: accuracy:0.22 loss: 255.017 (lr:0.0001)
93940: accuracy:0.16 loss: 246.918 (lr:0.0001)
93960: accuracy:0.26 loss: 219.88 (lr:0.0001)
93980: accuracy:0.26 loss: 242.635 (lr:0.0001)
94000: accuracy:0.31 loss: 221.737 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
94000: ********* epoch 10 ********* test accuracy for all:0.221378 test loss: 264.705
94000: ********* epoch 10 ********* test accuracy for mode 0:0.053 test loss: 402.842
94000: ********* epoch 10 ********* test accuracy for mode 1:0.0355 test loss: 434.163
94000: ********* epoch 10 ********* test accuracy for mode 2:0.0625 test loss: 286.792
94000: ********* epoch 10 ********* test accuracy for mode 24:0.2325 test loss: 267.789
94000: ********* epoch 10 ********* test accuracy for mode 25:0.2775 test loss: 250.611
94000: ********* epoch 10 ********* test accuracy for mode 26:0.4215 test loss: 177.57
94000: ********* epoch 10 ********* test accuracy for mode 27:0.263 test loss: 268.575
94000: ********* epoch 10 ********* test accuracy for mode 28:0.29 test loss: 257.97
94000: ********* epoch 10 ********* test accuracy for mode 29:0.2705 test loss: 266.4
94000: ********* epoch 10 ********* test accuracy for mode 30:0.17 test loss: 264.565
94000: ********* epoch 10 ********* test accuracy for mode 31:0.1885 test loss: 262.374
94000: ********* epoch 10 ********* test accuracy for mode 32:0.2245 test loss: 253.372
94000: ********* epoch 10 ********* test accuracy for mode 33:0.1665 test loss: 258.025
94000: ********* epoch 10 ********* test accuracy for mode 34:0.039 test loss: 262.647
94000: ********* epoch 10 ********* test accuracy for mode 35:0.103 test loss: 427.647
94000: ********* epoch 10 ********* test accuracy for mode 36:0.2145 test loss: 431.313
94020: accuracy:0.29 loss: 242.294 (lr:0.0001)
94040: accuracy:0.23 loss: 240.205 (lr:0.0001)
94060: accuracy:0.32 loss: 232.242 (lr:0.0001)
94080: accuracy:0.32 loss: 219.566 (lr:0.0001)
94100: accuracy:0.19 loss: 247.094 (lr:0.0001)
94120: accuracy:0.24 loss: 228.593 (lr:0.0001)
94140: accuracy:0.22 loss: 247.328 (lr:0.0001)
94160: accuracy:0.24 loss: 236.588 (lr:0.0001)
94180: accuracy:0.27 loss: 226.635 (lr:0.0001)
94200: accuracy:0.25 loss: 243.399 (lr:0.0001)
94220: accuracy:0.24 loss: 238.727 (lr:0.0001)
94240: accuracy:0.31 loss: 232.315 (lr:0.0001)
94260: accuracy:0.22 loss: 239.286 (lr:0.0001)
94280: accuracy:0.28 loss: 236.492 (lr:0.0001)
94300: accuracy:0.14 loss: 264.581 (lr:0.0001)
94320: accuracy:0.19 loss: 261.972 (lr:0.0001)
94340: accuracy:0.31 loss: 228.77 (lr:0.0001)
94360: accuracy:0.25 loss: 244.912 (lr:0.0001)
94380: accuracy:0.24 loss: 238.978 (lr:0.0001)
94400: accuracy:0.29 loss: 233.691 (lr:0.0001)
94420: accuracy:0.29 loss: 249.849 (lr:0.0001)
94440: accuracy:0.27 loss: 236.35 (lr:0.0001)
94460: accuracy:0.19 loss: 266.167 (lr:0.0001)
94480: accuracy:0.26 loss: 239.784 (lr:0.0001)
94500: accuracy:0.25 loss: 240.491 (lr:0.0001)
94520: accuracy:0.24 loss: 234.6 (lr:0.0001)
94540: accuracy:0.18 loss: 232.263 (lr:0.0001)
94560: accuracy:0.31 loss: 226.715 (lr:0.0001)
94580: accuracy:0.25 loss: 248.69 (lr:0.0001)
94600: accuracy:0.32 loss: 245.633 (lr:0.0001)
94620: accuracy:0.28 loss: 242.87 (lr:0.0001)
94640: accuracy:0.26 loss: 238.645 (lr:0.0001)
94660: accuracy:0.27 loss: 231.173 (lr:0.0001)
94680: accuracy:0.29 loss: 219.713 (lr:0.0001)
94700: accuracy:0.34 loss: 231.627 (lr:0.0001)
94720: accuracy:0.25 loss: 251.621 (lr:0.0001)
94740: accuracy:0.33 loss: 225.639 (lr:0.0001)
94760: accuracy:0.27 loss: 253.796 (lr:0.0001)
94780: accuracy:0.26 loss: 250.589 (lr:0.0001)
94800: accuracy:0.24 loss: 241.838 (lr:0.0001)
94820: accuracy:0.33 loss: 226.92 (lr:0.0001)
94840: accuracy:0.3 loss: 236.087 (lr:0.0001)
94860: accuracy:0.28 loss: 238.243 (lr:0.0001)
94880: accuracy:0.24 loss: 256.538 (lr:0.0001)
94900: accuracy:0.31 loss: 233.619 (lr:0.0001)
94920: accuracy:0.26 loss: 235.447 (lr:0.0001)
94940: accuracy:0.23 loss: 249.986 (lr:0.0001)
94960: accuracy:0.3 loss: 219.217 (lr:0.0001)
94980: accuracy:0.22 loss: 247.811 (lr:0.0001)
95000: accuracy:0.27 loss: 237.487 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
95000: ********* epoch 10 ********* test accuracy for all:0.221676 test loss: 264.355
95000: ********* epoch 10 ********* test accuracy for mode 0:0.0485 test loss: 408.625
95000: ********* epoch 10 ********* test accuracy for mode 1:0.0225 test loss: 438.414
95000: ********* epoch 10 ********* test accuracy for mode 2:0.063 test loss: 284.6
95000: ********* epoch 10 ********* test accuracy for mode 24:0.2405 test loss: 268.025
95000: ********* epoch 10 ********* test accuracy for mode 25:0.315 test loss: 245.703
95000: ********* epoch 10 ********* test accuracy for mode 26:0.308 test loss: 184.365
95000: ********* epoch 10 ********* test accuracy for mode 27:0.2655 test loss: 263.749
95000: ********* epoch 10 ********* test accuracy for mode 28:0.2685 test loss: 249.707
95000: ********* epoch 10 ********* test accuracy for mode 29:0.291 test loss: 254.175
95000: ********* epoch 10 ********* test accuracy for mode 30:0.203 test loss: 251.62
95000: ********* epoch 10 ********* test accuracy for mode 31:0.1685 test loss: 257.097
95000: ********* epoch 10 ********* test accuracy for mode 32:0.2455 test loss: 247.463
95000: ********* epoch 10 ********* test accuracy for mode 33:0.1905 test loss: 252.769
95000: ********* epoch 10 ********* test accuracy for mode 34:0.021 test loss: 261.439
95000: ********* epoch 10 ********* test accuracy for mode 35:0.1115 test loss: 430.179
95000: ********* epoch 10 ********* test accuracy for mode 36:0.277 test loss: 433.443
95020: accuracy:0.28 loss: 251.739 (lr:0.0001)
95040: accuracy:0.21 loss: 256.486 (lr:0.0001)
95060: accuracy:0.23 loss: 242.212 (lr:0.0001)
95080: accuracy:0.3 loss: 236.363 (lr:0.0001)
95100: accuracy:0.25 loss: 255.778 (lr:0.0001)
95120: accuracy:0.25 loss: 243.242 (lr:0.0001)
95140: accuracy:0.19 loss: 245.645 (lr:0.0001)
95160: accuracy:0.23 loss: 235.668 (lr:0.0001)
95180: accuracy:0.36 loss: 222.508 (lr:0.0001)
95200: accuracy:0.25 loss: 225.039 (lr:0.0001)
95220: accuracy:0.19 loss: 218.683 (lr:0.0001)
95240: accuracy:0.33 loss: 223.455 (lr:0.0001)
95260: accuracy:0.25 loss: 227.92 (lr:0.0001)
95280: accuracy:0.22 loss: 247.697 (lr:0.0001)
95300: accuracy:0.32 loss: 217.617 (lr:0.0001)
95320: accuracy:0.29 loss: 228.305 (lr:0.0001)
95340: accuracy:0.28 loss: 238.116 (lr:0.0001)
95360: accuracy:0.26 loss: 259.494 (lr:0.0001)
95380: accuracy:0.23 loss: 242.768 (lr:0.0001)
95400: accuracy:0.21 loss: 247.485 (lr:0.0001)
95420: accuracy:0.33 loss: 228.252 (lr:0.0001)
95440: accuracy:0.23 loss: 252.146 (lr:0.0001)
95460: accuracy:0.27 loss: 233.708 (lr:0.0001)
95480: accuracy:0.27 loss: 248.697 (lr:0.0001)
95500: accuracy:0.24 loss: 248.378 (lr:0.0001)
95520: accuracy:0.21 loss: 269.112 (lr:0.0001)
95540: accuracy:0.23 loss: 233.16 (lr:0.0001)
95560: accuracy:0.2 loss: 244.483 (lr:0.0001)
95580: accuracy:0.19 loss: 256.925 (lr:0.0001)
95600: accuracy:0.24 loss: 238.447 (lr:0.0001)
95620: accuracy:0.27 loss: 246.503 (lr:0.0001)
95640: accuracy:0.4 loss: 210.261 (lr:0.0001)
95660: accuracy:0.26 loss: 237.618 (lr:0.0001)
95680: accuracy:0.3 loss: 252.268 (lr:0.0001)
95700: accuracy:0.21 loss: 264.605 (lr:0.0001)
95720: accuracy:0.25 loss: 250.562 (lr:0.0001)
95740: accuracy:0.31 loss: 236.441 (lr:0.0001)
95760: accuracy:0.32 loss: 206.623 (lr:0.0001)
95780: accuracy:0.25 loss: 236.917 (lr:0.0001)
95800: accuracy:0.22 loss: 250.702 (lr:0.0001)
95820: accuracy:0.19 loss: 250.304 (lr:0.0001)
95840: accuracy:0.28 loss: 235.864 (lr:0.0001)
95860: accuracy:0.22 loss: 260.16 (lr:0.0001)
95880: accuracy:0.31 loss: 231.761 (lr:0.0001)
95900: accuracy:0.23 loss: 235.633 (lr:0.0001)
95920: accuracy:0.24 loss: 251.291 (lr:0.0001)
95940: accuracy:0.3 loss: 216.598 (lr:0.0001)
95960: accuracy:0.17 loss: 233.497 (lr:0.0001)
95980: accuracy:0.23 loss: 230.827 (lr:0.0001)
96000: accuracy:0.19 loss: 268.776 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
96000: ********* epoch 10 ********* test accuracy for all:0.225784 test loss: 262.32
96000: ********* epoch 10 ********* test accuracy for mode 0:0.044 test loss: 414.381
96000: ********* epoch 10 ********* test accuracy for mode 1:0.029 test loss: 432.95
96000: ********* epoch 10 ********* test accuracy for mode 2:0.0865 test loss: 279.459
96000: ********* epoch 10 ********* test accuracy for mode 24:0.233 test loss: 265.579
96000: ********* epoch 10 ********* test accuracy for mode 25:0.288 test loss: 241.806
96000: ********* epoch 10 ********* test accuracy for mode 26:0.315 test loss: 178.694
96000: ********* epoch 10 ********* test accuracy for mode 27:0.3 test loss: 250.119
96000: ********* epoch 10 ********* test accuracy for mode 28:0.303 test loss: 236.915
96000: ********* epoch 10 ********* test accuracy for mode 29:0.3115 test loss: 246.219
96000: ********* epoch 10 ********* test accuracy for mode 30:0.176 test loss: 251.659
96000: ********* epoch 10 ********* test accuracy for mode 31:0.19 test loss: 256.002
96000: ********* epoch 10 ********* test accuracy for mode 32:0.2265 test loss: 250.697
96000: ********* epoch 10 ********* test accuracy for mode 33:0.1325 test loss: 261.729
96000: ********* epoch 10 ********* test accuracy for mode 34:0.028 test loss: 267.307
96000: ********* epoch 10 ********* test accuracy for mode 35:0.1425 test loss: 416.98
96000: ********* epoch 10 ********* test accuracy for mode 36:0.4225 test loss: 419.334
96020: accuracy:0.29 loss: 222.232 (lr:0.0001)
96040: accuracy:0.25 loss: 255.216 (lr:0.0001)
96060: accuracy:0.35 loss: 230.143 (lr:0.0001)
96080: accuracy:0.33 loss: 212.346 (lr:0.0001)
96100: accuracy:0.3 loss: 235.843 (lr:0.0001)
96120: accuracy:0.26 loss: 274.055 (lr:0.0001)
96140: accuracy:0.25 loss: 261.581 (lr:0.0001)
96160: accuracy:0.18 loss: 242.153 (lr:0.0001)
96180: accuracy:0.3 loss: 231.945 (lr:0.0001)
96200: accuracy:0.23 loss: 257.118 (lr:0.0001)
96220: accuracy:0.22 loss: 212.515 (lr:0.0001)
96240: accuracy:0.28 loss: 236.762 (lr:0.0001)
96260: accuracy:0.23 loss: 237.751 (lr:0.0001)
96280: accuracy:0.17 loss: 250.026 (lr:0.0001)
96300: accuracy:0.25 loss: 237.111 (lr:0.0001)
96320: accuracy:0.24 loss: 236.134 (lr:0.0001)
96340: accuracy:0.26 loss: 234.787 (lr:0.0001)
96360: accuracy:0.26 loss: 237.129 (lr:0.0001)
96380: accuracy:0.26 loss: 238.445 (lr:0.0001)
96400: accuracy:0.29 loss: 236.872 (lr:0.0001)
96420: accuracy:0.29 loss: 238.429 (lr:0.0001)
96440: accuracy:0.23 loss: 245.702 (lr:0.0001)
96460: accuracy:0.28 loss: 226.986 (lr:0.0001)
96480: accuracy:0.2 loss: 253.916 (lr:0.0001)
96500: accuracy:0.17 loss: 271.184 (lr:0.0001)
96520: accuracy:0.21 loss: 230.049 (lr:0.0001)
96540: accuracy:0.33 loss: 233.657 (lr:0.0001)
96560: accuracy:0.32 loss: 218.945 (lr:0.0001)
96580: accuracy:0.26 loss: 240.423 (lr:0.0001)
96600: accuracy:0.23 loss: 241.923 (lr:0.0001)
96620: accuracy:0.26 loss: 231.649 (lr:0.0001)
96640: accuracy:0.16 loss: 272.49 (lr:0.0001)
96660: accuracy:0.3 loss: 236.183 (lr:0.0001)
96680: accuracy:0.24 loss: 252.12 (lr:0.0001)
96700: accuracy:0.28 loss: 239.977 (lr:0.0001)
96720: accuracy:0.21 loss: 233.337 (lr:0.0001)
96740: accuracy:0.23 loss: 238.249 (lr:0.0001)
96760: accuracy:0.21 loss: 226.465 (lr:0.0001)
96780: accuracy:0.21 loss: 264.265 (lr:0.0001)
96800: accuracy:0.24 loss: 246.714 (lr:0.0001)
96820: accuracy:0.22 loss: 264.99 (lr:0.0001)
96840: accuracy:0.24 loss: 230.096 (lr:0.0001)
96860: accuracy:0.25 loss: 237.315 (lr:0.0001)
96880: accuracy:0.25 loss: 238.351 (lr:0.0001)
96900: accuracy:0.35 loss: 241.406 (lr:0.0001)
96920: accuracy:0.25 loss: 230.219 (lr:0.0001)
96940: accuracy:0.25 loss: 242.451 (lr:0.0001)
96960: accuracy:0.26 loss: 220.584 (lr:0.0001)
96980: accuracy:0.22 loss: 237.591 (lr:0.0001)
97000: accuracy:0.24 loss: 248.3 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
97000: ********* epoch 10 ********* test accuracy for all:0.228108 test loss: 262.487
97000: ********* epoch 10 ********* test accuracy for mode 0:0.057 test loss: 402.116
97000: ********* epoch 10 ********* test accuracy for mode 1:0.0285 test loss: 427.307
97000: ********* epoch 10 ********* test accuracy for mode 2:0.0665 test loss: 281.871
97000: ********* epoch 10 ********* test accuracy for mode 24:0.2645 test loss: 260.913
97000: ********* epoch 10 ********* test accuracy for mode 25:0.2965 test loss: 244.04
97000: ********* epoch 10 ********* test accuracy for mode 26:0.3965 test loss: 177.552
97000: ********* epoch 10 ********* test accuracy for mode 27:0.244 test loss: 264.625
97000: ********* epoch 10 ********* test accuracy for mode 28:0.306 test loss: 248.14
97000: ********* epoch 10 ********* test accuracy for mode 29:0.266 test loss: 259.512
97000: ********* epoch 10 ********* test accuracy for mode 30:0.181 test loss: 259.251
97000: ********* epoch 10 ********* test accuracy for mode 31:0.171 test loss: 260.717
97000: ********* epoch 10 ********* test accuracy for mode 32:0.2675 test loss: 250.288
97000: ********* epoch 10 ********* test accuracy for mode 33:0.1245 test loss: 261.45
97000: ********* epoch 10 ********* test accuracy for mode 34:0.044 test loss: 261.48
97000: ********* epoch 10 ********* test accuracy for mode 35:0.132 test loss: 417.165
97000: ********* epoch 10 ********* test accuracy for mode 36:0.392 test loss: 424.596
97020: accuracy:0.25 loss: 225.862 (lr:0.0001)
97040: accuracy:0.25 loss: 221.095 (lr:0.0001)
97060: accuracy:0.26 loss: 222.625 (lr:0.0001)
97080: accuracy:0.34 loss: 224.697 (lr:0.0001)
97100: accuracy:0.27 loss: 220.556 (lr:0.0001)
97120: accuracy:0.35 loss: 223.184 (lr:0.0001)
97140: accuracy:0.36 loss: 230.125 (lr:0.0001)
97160: accuracy:0.24 loss: 229.393 (lr:0.0001)
97180: accuracy:0.33 loss: 223.847 (lr:0.0001)
97200: accuracy:0.24 loss: 230.845 (lr:0.0001)
97220: accuracy:0.28 loss: 232.23 (lr:0.0001)
97240: accuracy:0.27 loss: 242.388 (lr:0.0001)
97260: accuracy:0.25 loss: 226.988 (lr:0.0001)
97280: accuracy:0.18 loss: 237.462 (lr:0.0001)
97300: accuracy:0.32 loss: 234.24 (lr:0.0001)
97320: accuracy:0.18 loss: 251.355 (lr:0.0001)
97340: accuracy:0.21 loss: 246.782 (lr:0.0001)
97360: accuracy:0.24 loss: 239.222 (lr:0.0001)
97380: accuracy:0.27 loss: 224.685 (lr:0.0001)
97400: accuracy:0.27 loss: 228.525 (lr:0.0001)
97420: accuracy:0.33 loss: 222.656 (lr:0.0001)
97440: accuracy:0.28 loss: 255.687 (lr:0.0001)
97460: accuracy:0.2 loss: 253.046 (lr:0.0001)
97480: accuracy:0.36 loss: 209.048 (lr:0.0001)
97500: accuracy:0.27 loss: 235.951 (lr:0.0001)
97520: accuracy:0.22 loss: 247.055 (lr:0.0001)
97540: accuracy:0.3 loss: 238.746 (lr:0.0001)
97560: accuracy:0.31 loss: 235.201 (lr:0.0001)
97580: accuracy:0.29 loss: 236.288 (lr:0.0001)
97600: accuracy:0.29 loss: 248.233 (lr:0.0001)
97620: accuracy:0.3 loss: 239.296 (lr:0.0001)
97640: accuracy:0.2 loss: 252.974 (lr:0.0001)
97660: accuracy:0.32 loss: 231.748 (lr:0.0001)
97680: accuracy:0.26 loss: 211.354 (lr:0.0001)
97700: accuracy:0.28 loss: 241.941 (lr:0.0001)
97720: accuracy:0.25 loss: 251.25 (lr:0.0001)
97740: accuracy:0.27 loss: 229.536 (lr:0.0001)
97760: accuracy:0.22 loss: 238.095 (lr:0.0001)
97780: accuracy:0.21 loss: 245.169 (lr:0.0001)
97800: accuracy:0.24 loss: 245.32 (lr:0.0001)
97820: accuracy:0.35 loss: 224.174 (lr:0.0001)
97840: accuracy:0.17 loss: 241.368 (lr:0.0001)
97860: accuracy:0.29 loss: 236.49 (lr:0.0001)
97880: accuracy:0.25 loss: 227.967 (lr:0.0001)
97900: accuracy:0.29 loss: 249.647 (lr:0.0001)
97920: accuracy:0.29 loss: 233.045 (lr:0.0001)
97940: accuracy:0.18 loss: 236.34 (lr:0.0001)
97960: accuracy:0.2 loss: 235.525 (lr:0.0001)
97980: accuracy:0.29 loss: 247.312 (lr:0.0001)
98000: accuracy:0.25 loss: 225.932 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
98000: ********* epoch 11 ********* test accuracy for all:0.223568 test loss: 262.066
98000: ********* epoch 11 ********* test accuracy for mode 0:0.049 test loss: 407.644
98000: ********* epoch 11 ********* test accuracy for mode 1:0.0315 test loss: 433.933
98000: ********* epoch 11 ********* test accuracy for mode 2:0.059 test loss: 285.467
98000: ********* epoch 11 ********* test accuracy for mode 24:0.259 test loss: 260.122
98000: ********* epoch 11 ********* test accuracy for mode 25:0.3125 test loss: 241.211
98000: ********* epoch 11 ********* test accuracy for mode 26:0.355 test loss: 179.193
98000: ********* epoch 11 ********* test accuracy for mode 27:0.2595 test loss: 263.005
98000: ********* epoch 11 ********* test accuracy for mode 28:0.2625 test loss: 253.503
98000: ********* epoch 11 ********* test accuracy for mode 29:0.278 test loss: 262.106
98000: ********* epoch 11 ********* test accuracy for mode 30:0.1915 test loss: 260.725
98000: ********* epoch 11 ********* test accuracy for mode 31:0.165 test loss: 265.098
98000: ********* epoch 11 ********* test accuracy for mode 32:0.231 test loss: 254.779
98000: ********* epoch 11 ********* test accuracy for mode 33:0.1445 test loss: 264.1
98000: ********* epoch 11 ********* test accuracy for mode 34:0.033 test loss: 269.519
98000: ********* epoch 11 ********* test accuracy for mode 35:0.136 test loss: 415.61
98000: ********* epoch 11 ********* test accuracy for mode 36:0.3265 test loss: 415.291
98020: accuracy:0.22 loss: 245.83 (lr:0.0001)
98040: accuracy:0.29 loss: 235.143 (lr:0.0001)
98060: accuracy:0.26 loss: 250.315 (lr:0.0001)
98080: accuracy:0.28 loss: 232.336 (lr:0.0001)
98100: accuracy:0.29 loss: 235.281 (lr:0.0001)
98120: accuracy:0.29 loss: 226.793 (lr:0.0001)
98140: accuracy:0.26 loss: 237.328 (lr:0.0001)
98160: accuracy:0.25 loss: 234.572 (lr:0.0001)
98180: accuracy:0.28 loss: 229.163 (lr:0.0001)
98200: accuracy:0.28 loss: 237.393 (lr:0.0001)
98220: accuracy:0.28 loss: 231.712 (lr:0.0001)
98240: accuracy:0.32 loss: 228.36 (lr:0.0001)
98260: accuracy:0.25 loss: 255.883 (lr:0.0001)
98280: accuracy:0.3 loss: 234.622 (lr:0.0001)
98300: accuracy:0.23 loss: 230.452 (lr:0.0001)
98320: accuracy:0.3 loss: 227.309 (lr:0.0001)
98340: accuracy:0.3 loss: 228.734 (lr:0.0001)
98360: accuracy:0.32 loss: 225.998 (lr:0.0001)
98380: accuracy:0.28 loss: 226.598 (lr:0.0001)
98400: accuracy:0.2 loss: 243.654 (lr:0.0001)
98420: accuracy:0.16 loss: 280.382 (lr:0.0001)
98440: accuracy:0.27 loss: 235.853 (lr:0.0001)
98460: accuracy:0.26 loss: 251.857 (lr:0.0001)
98480: accuracy:0.32 loss: 265.594 (lr:0.0001)
98500: accuracy:0.3 loss: 220.622 (lr:0.0001)
98520: accuracy:0.32 loss: 229.0 (lr:0.0001)
98540: accuracy:0.32 loss: 241.084 (lr:0.0001)
98560: accuracy:0.25 loss: 226.635 (lr:0.0001)
98580: accuracy:0.22 loss: 244.613 (lr:0.0001)
98600: accuracy:0.17 loss: 262.1 (lr:0.0001)
98620: accuracy:0.26 loss: 230.663 (lr:0.0001)
98640: accuracy:0.2 loss: 247.196 (lr:0.0001)
98660: accuracy:0.26 loss: 237.663 (lr:0.0001)
98680: accuracy:0.25 loss: 251.223 (lr:0.0001)
98700: accuracy:0.27 loss: 242.236 (lr:0.0001)
98720: accuracy:0.3 loss: 239.603 (lr:0.0001)
98740: accuracy:0.3 loss: 214.095 (lr:0.0001)
98760: accuracy:0.26 loss: 245.389 (lr:0.0001)
98780: accuracy:0.28 loss: 259.115 (lr:0.0001)
98800: accuracy:0.28 loss: 230.185 (lr:0.0001)
98820: accuracy:0.31 loss: 227.818 (lr:0.0001)
98840: accuracy:0.26 loss: 244.645 (lr:0.0001)
98860: accuracy:0.32 loss: 220.304 (lr:0.0001)
98880: accuracy:0.24 loss: 225.813 (lr:0.0001)
98900: accuracy:0.3 loss: 224.368 (lr:0.0001)
98920: accuracy:0.22 loss: 236.89 (lr:0.0001)
98940: accuracy:0.32 loss: 232.662 (lr:0.0001)
98960: accuracy:0.23 loss: 267.882 (lr:0.0001)
98980: accuracy:0.24 loss: 232.416 (lr:0.0001)
99000: accuracy:0.29 loss: 226.753 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
99000: ********* epoch 11 ********* test accuracy for all:0.220878 test loss: 265.728
99000: ********* epoch 11 ********* test accuracy for mode 0:0.0475 test loss: 412.367
99000: ********* epoch 11 ********* test accuracy for mode 1:0.024 test loss: 447.161
99000: ********* epoch 11 ********* test accuracy for mode 2:0.1 test loss: 275.281
99000: ********* epoch 11 ********* test accuracy for mode 24:0.2075 test loss: 274.869
99000: ********* epoch 11 ********* test accuracy for mode 25:0.342 test loss: 251.12
99000: ********* epoch 11 ********* test accuracy for mode 26:0.248 test loss: 191.268
99000: ********* epoch 11 ********* test accuracy for mode 27:0.2735 test loss: 268.254
99000: ********* epoch 11 ********* test accuracy for mode 28:0.2645 test loss: 257.146
99000: ********* epoch 11 ********* test accuracy for mode 29:0.265 test loss: 259.631
99000: ********* epoch 11 ********* test accuracy for mode 30:0.207 test loss: 252.125
99000: ********* epoch 11 ********* test accuracy for mode 31:0.1615 test loss: 255.04
99000: ********* epoch 11 ********* test accuracy for mode 32:0.269 test loss: 241.57
99000: ********* epoch 11 ********* test accuracy for mode 33:0.1725 test loss: 250.584
99000: ********* epoch 11 ********* test accuracy for mode 34:0.034 test loss: 257.867
99000: ********* epoch 11 ********* test accuracy for mode 35:0.104 test loss: 452.982
99000: ********* epoch 11 ********* test accuracy for mode 36:0.18 test loss: 460.116
99020: accuracy:0.23 loss: 230.663 (lr:0.0001)
99040: accuracy:0.25 loss: 231.154 (lr:0.0001)
99060: accuracy:0.22 loss: 237.992 (lr:0.0001)
99080: accuracy:0.22 loss: 253.178 (lr:0.0001)
99100: accuracy:0.32 loss: 228.976 (lr:0.0001)
99120: accuracy:0.24 loss: 237.098 (lr:0.0001)
99140: accuracy:0.3 loss: 254.17 (lr:0.0001)
99160: accuracy:0.21 loss: 247.84 (lr:0.0001)
99180: accuracy:0.28 loss: 232.813 (lr:0.0001)
99200: accuracy:0.25 loss: 253.727 (lr:0.0001)
99220: accuracy:0.23 loss: 243.721 (lr:0.0001)
99240: accuracy:0.25 loss: 247.131 (lr:0.0001)
99260: accuracy:0.25 loss: 226.754 (lr:0.0001)
99280: accuracy:0.21 loss: 242.938 (lr:0.0001)
99300: accuracy:0.3 loss: 244.983 (lr:0.0001)
99320: accuracy:0.24 loss: 233.581 (lr:0.0001)
99340: accuracy:0.32 loss: 223.216 (lr:0.0001)
99360: accuracy:0.28 loss: 213.517 (lr:0.0001)
99380: accuracy:0.27 loss: 238.367 (lr:0.0001)
99400: accuracy:0.21 loss: 256.204 (lr:0.0001)
99420: accuracy:0.32 loss: 226.627 (lr:0.0001)
99440: accuracy:0.24 loss: 238.36 (lr:0.0001)
99460: accuracy:0.27 loss: 236.365 (lr:0.0001)
99480: accuracy:0.33 loss: 234.517 (lr:0.0001)
99500: accuracy:0.29 loss: 250.995 (lr:0.0001)
99520: accuracy:0.26 loss: 241.694 (lr:0.0001)
99540: accuracy:0.28 loss: 230.301 (lr:0.0001)
99560: accuracy:0.25 loss: 257.18 (lr:0.0001)
99580: accuracy:0.28 loss: 228.476 (lr:0.0001)
99600: accuracy:0.27 loss: 269.005 (lr:0.0001)
99620: accuracy:0.21 loss: 259.375 (lr:0.0001)
99640: accuracy:0.34 loss: 230.495 (lr:0.0001)
99660: accuracy:0.21 loss: 251.052 (lr:0.0001)
99680: accuracy:0.26 loss: 258.126 (lr:0.0001)
99700: accuracy:0.26 loss: 240.156 (lr:0.0001)
99720: accuracy:0.29 loss: 227.606 (lr:0.0001)
99740: accuracy:0.16 loss: 259.325 (lr:0.0001)
99760: accuracy:0.24 loss: 236.42 (lr:0.0001)
99780: accuracy:0.3 loss: 220.954 (lr:0.0001)
99800: accuracy:0.29 loss: 228.752 (lr:0.0001)
99820: accuracy:0.23 loss: 235.413 (lr:0.0001)
99840: accuracy:0.21 loss: 238.806 (lr:0.0001)
99860: accuracy:0.23 loss: 242.383 (lr:0.0001)
99880: accuracy:0.26 loss: 243.848 (lr:0.0001)
99900: accuracy:0.25 loss: 241.01 (lr:0.0001)
99920: accuracy:0.29 loss: 246.43 (lr:0.0001)
99940: accuracy:0.21 loss: 257.406 (lr:0.0001)
99960: accuracy:0.32 loss: 238.563 (lr:0.0001)
99980: accuracy:0.3 loss: 228.331 (lr:0.0001)
100000: accuracy:0.34 loss: 236.523 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
100000: ********* epoch 11 ********* test accuracy for all:0.227216 test loss: 262.16
100000: ********* epoch 11 ********* test accuracy for mode 0:0.05 test loss: 408.69
100000: ********* epoch 11 ********* test accuracy for mode 1:0.0255 test loss: 432.523
100000: ********* epoch 11 ********* test accuracy for mode 2:0.0855 test loss: 282.801
100000: ********* epoch 11 ********* test accuracy for mode 24:0.2415 test loss: 257.432
100000: ********* epoch 11 ********* test accuracy for mode 25:0.286 test loss: 241.433
100000: ********* epoch 11 ********* test accuracy for mode 26:0.4355 test loss: 175.404
100000: ********* epoch 11 ********* test accuracy for mode 27:0.2825 test loss: 259.026
100000: ********* epoch 11 ********* test accuracy for mode 28:0.293 test loss: 246.587
100000: ********* epoch 11 ********* test accuracy for mode 29:0.2765 test loss: 256.583
100000: ********* epoch 11 ********* test accuracy for mode 30:0.1795 test loss: 256.954
100000: ********* epoch 11 ********* test accuracy for mode 31:0.2045 test loss: 257.831
100000: ********* epoch 11 ********* test accuracy for mode 32:0.212 test loss: 252.51
100000: ********* epoch 11 ********* test accuracy for mode 33:0.131 test loss: 262.645
100000: ********* epoch 11 ********* test accuracy for mode 34:0.049 test loss: 264.612
100000: ********* epoch 11 ********* test accuracy for mode 35:0.1195 test loss: 436.928
100000: ********* epoch 11 ********* test accuracy for mode 36:0.267 test loss: 446.493
100020: accuracy:0.36 loss: 217.079 (lr:0.0001)
100040: accuracy:0.28 loss: 227.329 (lr:0.0001)
100060: accuracy:0.25 loss: 227.072 (lr:0.0001)
100080: accuracy:0.16 loss: 273.537 (lr:0.0001)
100100: accuracy:0.24 loss: 231.313 (lr:0.0001)
100120: accuracy:0.29 loss: 262.045 (lr:0.0001)
100140: accuracy:0.25 loss: 247.807 (lr:0.0001)
100160: accuracy:0.32 loss: 217.258 (lr:0.0001)
100180: accuracy:0.3 loss: 228.027 (lr:0.0001)
100200: accuracy:0.27 loss: 241.964 (lr:0.0001)
100220: accuracy:0.33 loss: 238.211 (lr:0.0001)
100240: accuracy:0.28 loss: 229.798 (lr:0.0001)
100260: accuracy:0.3 loss: 220.955 (lr:0.0001)
100280: accuracy:0.3 loss: 241.975 (lr:0.0001)
100300: accuracy:0.3 loss: 235.688 (lr:0.0001)
100320: accuracy:0.27 loss: 240.089 (lr:0.0001)
100340: accuracy:0.28 loss: 222.913 (lr:0.0001)
100360: accuracy:0.26 loss: 240.214 (lr:0.0001)
100380: accuracy:0.3 loss: 218.269 (lr:0.0001)
100400: accuracy:0.27 loss: 235.536 (lr:0.0001)
100420: accuracy:0.22 loss: 265.127 (lr:0.0001)
100440: accuracy:0.22 loss: 238.548 (lr:0.0001)
100460: accuracy:0.2 loss: 243.348 (lr:0.0001)
100480: accuracy:0.27 loss: 228.528 (lr:0.0001)
100500: accuracy:0.25 loss: 236.813 (lr:0.0001)
100520: accuracy:0.25 loss: 231.1 (lr:0.0001)
100540: accuracy:0.33 loss: 235.175 (lr:0.0001)
100560: accuracy:0.29 loss: 227.626 (lr:0.0001)
100580: accuracy:0.31 loss: 216.037 (lr:0.0001)
100600: accuracy:0.33 loss: 220.257 (lr:0.0001)
100620: accuracy:0.26 loss: 223.448 (lr:0.0001)
100640: accuracy:0.25 loss: 230.0 (lr:0.0001)
100660: accuracy:0.22 loss: 246.574 (lr:0.0001)
100680: accuracy:0.36 loss: 227.435 (lr:0.0001)
100700: accuracy:0.24 loss: 238.339 (lr:0.0001)
100720: accuracy:0.3 loss: 222.773 (lr:0.0001)
100740: accuracy:0.38 loss: 231.547 (lr:0.0001)
100760: accuracy:0.24 loss: 246.824 (lr:0.0001)
100780: accuracy:0.27 loss: 230.933 (lr:0.0001)
100800: accuracy:0.25 loss: 236.531 (lr:0.0001)
100820: accuracy:0.26 loss: 235.171 (lr:0.0001)
100840: accuracy:0.3 loss: 215.573 (lr:0.0001)
100860: accuracy:0.21 loss: 243.129 (lr:0.0001)
100880: accuracy:0.21 loss: 244.074 (lr:0.0001)
100900: accuracy:0.27 loss: 243.975 (lr:0.0001)
100920: accuracy:0.22 loss: 248.03 (lr:0.0001)
100940: accuracy:0.25 loss: 236.536 (lr:0.0001)
100960: accuracy:0.24 loss: 236.974 (lr:0.0001)
100980: accuracy:0.24 loss: 227.108 (lr:0.0001)
101000: accuracy:0.29 loss: 248.385 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
101000: ********* epoch 11 ********* test accuracy for all:0.215824 test loss: 267.745
101000: ********* epoch 11 ********* test accuracy for mode 0:0.0385 test loss: 421.655
101000: ********* epoch 11 ********* test accuracy for mode 1:0.0215 test loss: 461.684
101000: ********* epoch 11 ********* test accuracy for mode 2:0.092 test loss: 274.557
101000: ********* epoch 11 ********* test accuracy for mode 24:0.213 test loss: 276.999
101000: ********* epoch 11 ********* test accuracy for mode 25:0.333 test loss: 252.242
101000: ********* epoch 11 ********* test accuracy for mode 26:0.2455 test loss: 187.823
101000: ********* epoch 11 ********* test accuracy for mode 27:0.2915 test loss: 265.773
101000: ********* epoch 11 ********* test accuracy for mode 28:0.2805 test loss: 256.725
101000: ********* epoch 11 ********* test accuracy for mode 29:0.261 test loss: 259.008
101000: ********* epoch 11 ********* test accuracy for mode 30:0.209 test loss: 249.921
101000: ********* epoch 11 ********* test accuracy for mode 31:0.1865 test loss: 250.053
101000: ********* epoch 11 ********* test accuracy for mode 32:0.231 test loss: 239.546
101000: ********* epoch 11 ********* test accuracy for mode 33:0.2005 test loss: 245.832
101000: ********* epoch 11 ********* test accuracy for mode 34:0.022 test loss: 255.194
101000: ********* epoch 11 ********* test accuracy for mode 35:0.086 test loss: 458.369
101000: ********* epoch 11 ********* test accuracy for mode 36:0.0815 test loss: 462.968
101020: accuracy:0.36 loss: 224.156 (lr:0.0001)
101040: accuracy:0.29 loss: 239.388 (lr:0.0001)
101060: accuracy:0.27 loss: 250.564 (lr:0.0001)
101080: accuracy:0.27 loss: 230.564 (lr:0.0001)
101100: accuracy:0.3 loss: 235.528 (lr:0.0001)
101120: accuracy:0.31 loss: 231.494 (lr:0.0001)
101140: accuracy:0.21 loss: 242.64 (lr:0.0001)
101160: accuracy:0.24 loss: 247.428 (lr:0.0001)
101180: accuracy:0.35 loss: 213.457 (lr:0.0001)
101200: accuracy:0.22 loss: 234.127 (lr:0.0001)
101220: accuracy:0.25 loss: 231.27 (lr:0.0001)
101240: accuracy:0.22 loss: 238.124 (lr:0.0001)
101260: accuracy:0.22 loss: 233.958 (lr:0.0001)
101280: accuracy:0.27 loss: 233.774 (lr:0.0001)
101300: accuracy:0.37 loss: 225.844 (lr:0.0001)
101320: accuracy:0.35 loss: 244.284 (lr:0.0001)
101340: accuracy:0.27 loss: 237.927 (lr:0.0001)
101360: accuracy:0.32 loss: 237.898 (lr:0.0001)
101380: accuracy:0.33 loss: 225.166 (lr:0.0001)
101400: accuracy:0.21 loss: 256.634 (lr:0.0001)
101420: accuracy:0.24 loss: 231.459 (lr:0.0001)
101440: accuracy:0.24 loss: 234.04 (lr:0.0001)
101460: accuracy:0.21 loss: 267.933 (lr:0.0001)
101480: accuracy:0.3 loss: 243.215 (lr:0.0001)
101500: accuracy:0.29 loss: 231.742 (lr:0.0001)
101520: accuracy:0.29 loss: 237.292 (lr:0.0001)
101540: accuracy:0.33 loss: 231.747 (lr:0.0001)
101560: accuracy:0.23 loss: 231.142 (lr:0.0001)
101580: accuracy:0.23 loss: 227.209 (lr:0.0001)
101600: accuracy:0.31 loss: 232.667 (lr:0.0001)
101620: accuracy:0.32 loss: 224.376 (lr:0.0001)
101640: accuracy:0.29 loss: 224.648 (lr:0.0001)
101660: accuracy:0.23 loss: 248.037 (lr:0.0001)
101680: accuracy:0.25 loss: 236.465 (lr:0.0001)
101700: accuracy:0.24 loss: 235.982 (lr:0.0001)
101720: accuracy:0.25 loss: 248.019 (lr:0.0001)
101740: accuracy:0.29 loss: 225.559 (lr:0.0001)
101760: accuracy:0.32 loss: 228.928 (lr:0.0001)
101780: accuracy:0.26 loss: 237.434 (lr:0.0001)
101800: accuracy:0.28 loss: 260.074 (lr:0.0001)
101820: accuracy:0.2 loss: 244.85 (lr:0.0001)
101840: accuracy:0.28 loss: 226.839 (lr:0.0001)
101860: accuracy:0.26 loss: 239.745 (lr:0.0001)
101880: accuracy:0.18 loss: 257.609 (lr:0.0001)
101900: accuracy:0.33 loss: 239.808 (lr:0.0001)
101920: accuracy:0.28 loss: 231.793 (lr:0.0001)
101940: accuracy:0.25 loss: 223.416 (lr:0.0001)
101960: accuracy:0.23 loss: 242.379 (lr:0.0001)
101980: accuracy:0.2 loss: 237.033 (lr:0.0001)
102000: accuracy:0.35 loss: 239.322 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
102000: ********* epoch 11 ********* test accuracy for all:0.22227 test loss: 263.129
102000: ********* epoch 11 ********* test accuracy for mode 0:0.046 test loss: 410.659
102000: ********* epoch 11 ********* test accuracy for mode 1:0.024 test loss: 444.954
102000: ********* epoch 11 ********* test accuracy for mode 2:0.086 test loss: 279.249
102000: ********* epoch 11 ********* test accuracy for mode 24:0.243 test loss: 262.768
102000: ********* epoch 11 ********* test accuracy for mode 25:0.326 test loss: 243.825
102000: ********* epoch 11 ********* test accuracy for mode 26:0.3025 test loss: 183.3
102000: ********* epoch 11 ********* test accuracy for mode 27:0.2775 test loss: 261.484
102000: ********* epoch 11 ********* test accuracy for mode 28:0.2965 test loss: 248.794
102000: ********* epoch 11 ********* test accuracy for mode 29:0.2785 test loss: 254.619
102000: ********* epoch 11 ********* test accuracy for mode 30:0.1905 test loss: 251.421
102000: ********* epoch 11 ********* test accuracy for mode 31:0.1955 test loss: 251.798
102000: ********* epoch 11 ********* test accuracy for mode 32:0.2635 test loss: 242.451
102000: ********* epoch 11 ********* test accuracy for mode 33:0.134 test loss: 255.467
102000: ********* epoch 11 ********* test accuracy for mode 34:0.0345 test loss: 260.305
102000: ********* epoch 11 ********* test accuracy for mode 35:0.102 test loss: 442.812
102000: ********* epoch 11 ********* test accuracy for mode 36:0.173 test loss: 449.427
102020: accuracy:0.22 loss: 240.545 (lr:0.0001)
102040: accuracy:0.23 loss: 229.374 (lr:0.0001)
102060: accuracy:0.25 loss: 233.617 (lr:0.0001)
102080: accuracy:0.25 loss: 242.997 (lr:0.0001)
102100: accuracy:0.22 loss: 245.823 (lr:0.0001)
102120: accuracy:0.29 loss: 250.604 (lr:0.0001)
102140: accuracy:0.2 loss: 233.5 (lr:0.0001)
102160: accuracy:0.26 loss: 233.69 (lr:0.0001)
102180: accuracy:0.27 loss: 240.893 (lr:0.0001)
102200: accuracy:0.24 loss: 234.197 (lr:0.0001)
102220: accuracy:0.3 loss: 234.299 (lr:0.0001)
102240: accuracy:0.32 loss: 249.09 (lr:0.0001)
102260: accuracy:0.23 loss: 241.319 (lr:0.0001)
102280: accuracy:0.36 loss: 237.287 (lr:0.0001)
102300: accuracy:0.2 loss: 247.19 (lr:0.0001)
102320: accuracy:0.21 loss: 251.276 (lr:0.0001)
102340: accuracy:0.17 loss: 246.067 (lr:0.0001)
102360: accuracy:0.28 loss: 220.885 (lr:0.0001)
102380: accuracy:0.36 loss: 219.93 (lr:0.0001)
102400: accuracy:0.35 loss: 224.049 (lr:0.0001)
102420: accuracy:0.23 loss: 233.102 (lr:0.0001)
102440: accuracy:0.35 loss: 218.159 (lr:0.0001)
102460: accuracy:0.25 loss: 240.794 (lr:0.0001)
102480: accuracy:0.2 loss: 242.397 (lr:0.0001)
102500: accuracy:0.28 loss: 245.929 (lr:0.0001)
102520: accuracy:0.28 loss: 226.691 (lr:0.0001)
102540: accuracy:0.21 loss: 247.417 (lr:0.0001)
102560: accuracy:0.28 loss: 252.045 (lr:0.0001)
102580: accuracy:0.33 loss: 225.213 (lr:0.0001)
102600: accuracy:0.27 loss: 230.78 (lr:0.0001)
102620: accuracy:0.23 loss: 254.697 (lr:0.0001)
102640: accuracy:0.26 loss: 269.362 (lr:0.0001)
102660: accuracy:0.27 loss: 252.636 (lr:0.0001)
102680: accuracy:0.23 loss: 253.49 (lr:0.0001)
102700: accuracy:0.21 loss: 219.319 (lr:0.0001)
102720: accuracy:0.32 loss: 227.717 (lr:0.0001)
102740: accuracy:0.26 loss: 244.665 (lr:0.0001)
102760: accuracy:0.23 loss: 248.232 (lr:0.0001)
102780: accuracy:0.18 loss: 243.04 (lr:0.0001)
102800: accuracy:0.23 loss: 259.474 (lr:0.0001)
102820: accuracy:0.24 loss: 248.851 (lr:0.0001)
102840: accuracy:0.24 loss: 240.061 (lr:0.0001)
102860: accuracy:0.25 loss: 248.076 (lr:0.0001)
102880: accuracy:0.29 loss: 252.679 (lr:0.0001)
102900: accuracy:0.18 loss: 259.655 (lr:0.0001)
102920: accuracy:0.28 loss: 231.89 (lr:0.0001)
102940: accuracy:0.22 loss: 228.128 (lr:0.0001)
102960: accuracy:0.2 loss: 235.215 (lr:0.0001)
102980: accuracy:0.29 loss: 268.279 (lr:0.0001)
103000: accuracy:0.27 loss: 230.675 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
103000: ********* epoch 11 ********* test accuracy for all:0.217784 test loss: 264.488
103000: ********* epoch 11 ********* test accuracy for mode 0:0.053 test loss: 405.4
103000: ********* epoch 11 ********* test accuracy for mode 1:0.0275 test loss: 441.514
103000: ********* epoch 11 ********* test accuracy for mode 2:0.0555 test loss: 284.083
103000: ********* epoch 11 ********* test accuracy for mode 24:0.262 test loss: 258.239
103000: ********* epoch 11 ********* test accuracy for mode 25:0.3275 test loss: 238.999
103000: ********* epoch 11 ********* test accuracy for mode 26:0.278 test loss: 185.724
103000: ********* epoch 11 ********* test accuracy for mode 27:0.2535 test loss: 265.437
103000: ********* epoch 11 ********* test accuracy for mode 28:0.287 test loss: 251.727
103000: ********* epoch 11 ********* test accuracy for mode 29:0.283 test loss: 258.394
103000: ********* epoch 11 ********* test accuracy for mode 30:0.1675 test loss: 259.148
103000: ********* epoch 11 ********* test accuracy for mode 31:0.202 test loss: 256.045
103000: ********* epoch 11 ********* test accuracy for mode 32:0.2105 test loss: 248.223
103000: ********* epoch 11 ********* test accuracy for mode 33:0.1835 test loss: 254.639
103000: ********* epoch 11 ********* test accuracy for mode 34:0.0195 test loss: 264.17
103000: ********* epoch 11 ********* test accuracy for mode 35:0.0995 test loss: 446.017
103000: ********* epoch 11 ********* test accuracy for mode 36:0.12 test loss: 445.541
103020: accuracy:0.29 loss: 241.73 (lr:0.0001)
103040: accuracy:0.3 loss: 226.025 (lr:0.0001)
103060: accuracy:0.3 loss: 226.806 (lr:0.0001)
103080: accuracy:0.24 loss: 241.095 (lr:0.0001)
103100: accuracy:0.19 loss: 271.394 (lr:0.0001)
103120: accuracy:0.23 loss: 251.78 (lr:0.0001)
103140: accuracy:0.23 loss: 245.078 (lr:0.0001)
103160: accuracy:0.23 loss: 241.808 (lr:0.0001)
103180: accuracy:0.29 loss: 239.085 (lr:0.0001)
103200: accuracy:0.29 loss: 230.747 (lr:0.0001)
103220: accuracy:0.24 loss: 237.451 (lr:0.0001)
103240: accuracy:0.3 loss: 218.446 (lr:0.0001)
103260: accuracy:0.31 loss: 224.99 (lr:0.0001)
103280: accuracy:0.27 loss: 234.361 (lr:0.0001)
103300: accuracy:0.22 loss: 244.087 (lr:0.0001)
103320: accuracy:0.16 loss: 275.754 (lr:0.0001)
103340: accuracy:0.3 loss: 239.54 (lr:0.0001)
103360: accuracy:0.26 loss: 224.877 (lr:0.0001)
103380: accuracy:0.2 loss: 221.199 (lr:0.0001)
103400: accuracy:0.27 loss: 230.609 (lr:0.0001)
103420: accuracy:0.28 loss: 217.952 (lr:0.0001)
103440: accuracy:0.25 loss: 244.091 (lr:0.0001)
103460: accuracy:0.2 loss: 248.097 (lr:0.0001)
103480: accuracy:0.23 loss: 253.288 (lr:0.0001)
103500: accuracy:0.29 loss: 245.603 (lr:0.0001)
103520: accuracy:0.25 loss: 235.9 (lr:0.0001)
103540: accuracy:0.25 loss: 224.494 (lr:0.0001)
103560: accuracy:0.3 loss: 236.001 (lr:0.0001)
103580: accuracy:0.36 loss: 226.155 (lr:0.0001)
103600: accuracy:0.21 loss: 258.13 (lr:0.0001)
103620: accuracy:0.3 loss: 235.62 (lr:0.0001)
103640: accuracy:0.26 loss: 228.938 (lr:0.0001)
103660: accuracy:0.23 loss: 220.257 (lr:0.0001)
103680: accuracy:0.27 loss: 235.759 (lr:0.0001)
103700: accuracy:0.29 loss: 228.882 (lr:0.0001)
103720: accuracy:0.25 loss: 227.52 (lr:0.0001)
103740: accuracy:0.28 loss: 241.785 (lr:0.0001)
103760: accuracy:0.2 loss: 252.058 (lr:0.0001)
103780: accuracy:0.27 loss: 229.858 (lr:0.0001)
103800: accuracy:0.24 loss: 249.174 (lr:0.0001)
103820: accuracy:0.27 loss: 229.377 (lr:0.0001)
103840: accuracy:0.27 loss: 243.878 (lr:0.0001)
103860: accuracy:0.27 loss: 242.223 (lr:0.0001)
103880: accuracy:0.32 loss: 227.666 (lr:0.0001)
103900: accuracy:0.22 loss: 245.3 (lr:0.0001)
103920: accuracy:0.22 loss: 283.672 (lr:0.0001)
103940: accuracy:0.29 loss: 233.051 (lr:0.0001)
103960: accuracy:0.2 loss: 242.476 (lr:0.0001)
103980: accuracy:0.2 loss: 244.092 (lr:0.0001)
104000: accuracy:0.27 loss: 242.603 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
104000: ********* epoch 11 ********* test accuracy for all:0.224378 test loss: 264.326
104000: ********* epoch 11 ********* test accuracy for mode 0:0.0475 test loss: 413.376
104000: ********* epoch 11 ********* test accuracy for mode 1:0.0205 test loss: 448.539
104000: ********* epoch 11 ********* test accuracy for mode 2:0.0975 test loss: 274.073
104000: ********* epoch 11 ********* test accuracy for mode 24:0.243 test loss: 265.624
104000: ********* epoch 11 ********* test accuracy for mode 25:0.3245 test loss: 246.774
104000: ********* epoch 11 ********* test accuracy for mode 26:0.273 test loss: 186.145
104000: ********* epoch 11 ********* test accuracy for mode 27:0.28 test loss: 263.241
104000: ********* epoch 11 ********* test accuracy for mode 28:0.2915 test loss: 252.771
104000: ********* epoch 11 ********* test accuracy for mode 29:0.28 test loss: 256.358
104000: ********* epoch 11 ********* test accuracy for mode 30:0.2085 test loss: 251.176
104000: ********* epoch 11 ********* test accuracy for mode 31:0.1995 test loss: 252.428
104000: ********* epoch 11 ********* test accuracy for mode 32:0.211 test loss: 245.044
104000: ********* epoch 11 ********* test accuracy for mode 33:0.1735 test loss: 251.26
104000: ********* epoch 11 ********* test accuracy for mode 34:0.0405 test loss: 255.581
104000: ********* epoch 11 ********* test accuracy for mode 35:0.1085 test loss: 452.268
104000: ********* epoch 11 ********* test accuracy for mode 36:0.212 test loss: 462.039
104020: accuracy:0.19 loss: 241.611 (lr:0.0001)
104040: accuracy:0.23 loss: 225.056 (lr:0.0001)
104060: accuracy:0.3 loss: 231.14 (lr:0.0001)
104080: accuracy:0.31 loss: 233.454 (lr:0.0001)
104100: accuracy:0.32 loss: 210.752 (lr:0.0001)
104120: accuracy:0.25 loss: 233.838 (lr:0.0001)
104140: accuracy:0.26 loss: 246.037 (lr:0.0001)
104160: accuracy:0.22 loss: 239.095 (lr:0.0001)
104180: accuracy:0.25 loss: 219.883 (lr:0.0001)
104200: accuracy:0.26 loss: 252.985 (lr:0.0001)
104220: accuracy:0.23 loss: 234.979 (lr:0.0001)
104240: accuracy:0.24 loss: 251.86 (lr:0.0001)
104260: accuracy:0.35 loss: 228.76 (lr:0.0001)
104280: accuracy:0.32 loss: 206.381 (lr:0.0001)
104300: accuracy:0.28 loss: 225.544 (lr:0.0001)
104320: accuracy:0.22 loss: 237.258 (lr:0.0001)
104340: accuracy:0.27 loss: 228.242 (lr:0.0001)
104360: accuracy:0.24 loss: 228.044 (lr:0.0001)
104380: accuracy:0.26 loss: 231.24 (lr:0.0001)
104400: accuracy:0.3 loss: 237.67 (lr:0.0001)
104420: accuracy:0.23 loss: 231.248 (lr:0.0001)
104440: accuracy:0.28 loss: 246.432 (lr:0.0001)
104460: accuracy:0.27 loss: 226.491 (lr:0.0001)
104480: accuracy:0.24 loss: 244.679 (lr:0.0001)
104500: accuracy:0.3 loss: 254.007 (lr:0.0001)
104520: accuracy:0.24 loss: 233.58 (lr:0.0001)
104540: accuracy:0.22 loss: 255.771 (lr:0.0001)
104560: accuracy:0.21 loss: 242.318 (lr:0.0001)
104580: accuracy:0.23 loss: 251.711 (lr:0.0001)
104600: accuracy:0.26 loss: 245.809 (lr:0.0001)
104620: accuracy:0.28 loss: 235.094 (lr:0.0001)
104640: accuracy:0.24 loss: 244.99 (lr:0.0001)
104660: accuracy:0.29 loss: 239.721 (lr:0.0001)
104680: accuracy:0.3 loss: 234.673 (lr:0.0001)
104700: accuracy:0.3 loss: 229.62 (lr:0.0001)
104720: accuracy:0.28 loss: 210.64 (lr:0.0001)
104740: accuracy:0.3 loss: 213.115 (lr:0.0001)
104760: accuracy:0.29 loss: 258.327 (lr:0.0001)
104780: accuracy:0.25 loss: 240.8 (lr:0.0001)
104800: accuracy:0.35 loss: 234.673 (lr:0.0001)
104820: accuracy:0.29 loss: 230.846 (lr:0.0001)
104840: accuracy:0.29 loss: 245.901 (lr:0.0001)
104860: accuracy:0.23 loss: 247.678 (lr:0.0001)
104880: accuracy:0.32 loss: 229.018 (lr:0.0001)
104900: accuracy:0.29 loss: 242.687 (lr:0.0001)
104920: accuracy:0.24 loss: 226.55 (lr:0.0001)
104940: accuracy:0.28 loss: 243.7 (lr:0.0001)
104960: accuracy:0.23 loss: 244.195 (lr:0.0001)
104980: accuracy:0.24 loss: 254.577 (lr:0.0001)
105000: accuracy:0.23 loss: 261.891 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
105000: ********* epoch 11 ********* test accuracy for all:0.224635 test loss: 263.004
105000: ********* epoch 11 ********* test accuracy for mode 0:0.0405 test loss: 417.122
105000: ********* epoch 11 ********* test accuracy for mode 1:0.0185 test loss: 452.077
105000: ********* epoch 11 ********* test accuracy for mode 2:0.08 test loss: 281.218
105000: ********* epoch 11 ********* test accuracy for mode 24:0.2505 test loss: 257.328
105000: ********* epoch 11 ********* test accuracy for mode 25:0.349 test loss: 233.114
105000: ********* epoch 11 ********* test accuracy for mode 26:0.2505 test loss: 185.28
105000: ********* epoch 11 ********* test accuracy for mode 27:0.281 test loss: 253.998
105000: ********* epoch 11 ********* test accuracy for mode 28:0.274 test loss: 243.853
105000: ********* epoch 11 ********* test accuracy for mode 29:0.3045 test loss: 245.106
105000: ********* epoch 11 ********* test accuracy for mode 30:0.1985 test loss: 243.592
105000: ********* epoch 11 ********* test accuracy for mode 31:0.2195 test loss: 245.285
105000: ********* epoch 11 ********* test accuracy for mode 32:0.2185 test loss: 239.117
105000: ********* epoch 11 ********* test accuracy for mode 33:0.1925 test loss: 246.469
105000: ********* epoch 11 ********* test accuracy for mode 34:0.0355 test loss: 255.074
105000: ********* epoch 11 ********* test accuracy for mode 35:0.0895 test loss: 454.868
105000: ********* epoch 11 ********* test accuracy for mode 36:0.211 test loss: 458.925
105020: accuracy:0.25 loss: 229.646 (lr:0.0001)
105040: accuracy:0.33 loss: 235.588 (lr:0.0001)
105060: accuracy:0.26 loss: 236.356 (lr:0.0001)
105080: accuracy:0.34 loss: 211.897 (lr:0.0001)
105100: accuracy:0.24 loss: 235.485 (lr:0.0001)
105120: accuracy:0.22 loss: 249.996 (lr:0.0001)
105140: accuracy:0.29 loss: 224.054 (lr:0.0001)
105160: accuracy:0.23 loss: 251.675 (lr:0.0001)
105180: accuracy:0.27 loss: 237.38 (lr:0.0001)
105200: accuracy:0.32 loss: 228.006 (lr:0.0001)
105220: accuracy:0.25 loss: 221.663 (lr:0.0001)
105240: accuracy:0.27 loss: 230.702 (lr:0.0001)
105260: accuracy:0.25 loss: 247.924 (lr:0.0001)
105280: accuracy:0.26 loss: 245.152 (lr:0.0001)
105300: accuracy:0.26 loss: 245.619 (lr:0.0001)
105320: accuracy:0.28 loss: 228.766 (lr:0.0001)
105340: accuracy:0.27 loss: 226.273 (lr:0.0001)
105360: accuracy:0.24 loss: 217.662 (lr:0.0001)
105380: accuracy:0.22 loss: 236.012 (lr:0.0001)
105400: accuracy:0.3 loss: 228.312 (lr:0.0001)
105420: accuracy:0.32 loss: 231.662 (lr:0.0001)
105440: accuracy:0.25 loss: 254.642 (lr:0.0001)
105460: accuracy:0.28 loss: 214.061 (lr:0.0001)
105480: accuracy:0.2 loss: 244.252 (lr:0.0001)
105500: accuracy:0.19 loss: 244.678 (lr:0.0001)
105520: accuracy:0.27 loss: 236.386 (lr:0.0001)
105540: accuracy:0.23 loss: 225.636 (lr:0.0001)
105560: accuracy:0.3 loss: 224.807 (lr:0.0001)
105580: accuracy:0.25 loss: 244.208 (lr:0.0001)
105600: accuracy:0.2 loss: 264.633 (lr:0.0001)
105620: accuracy:0.28 loss: 241.309 (lr:0.0001)
105640: accuracy:0.32 loss: 230.483 (lr:0.0001)
105660: accuracy:0.24 loss: 229.515 (lr:0.0001)
105680: accuracy:0.26 loss: 239.196 (lr:0.0001)
105700: accuracy:0.25 loss: 236.182 (lr:0.0001)
105720: accuracy:0.26 loss: 244.538 (lr:0.0001)
105740: accuracy:0.28 loss: 263.01 (lr:0.0001)
105760: accuracy:0.23 loss: 251.422 (lr:0.0001)
105780: accuracy:0.26 loss: 236.095 (lr:0.0001)
105800: accuracy:0.24 loss: 262.611 (lr:0.0001)
105820: accuracy:0.3 loss: 237.458 (lr:0.0001)
105840: accuracy:0.22 loss: 266.959 (lr:0.0001)
105860: accuracy:0.24 loss: 244.63 (lr:0.0001)
105880: accuracy:0.33 loss: 222.015 (lr:0.0001)
105900: accuracy:0.28 loss: 218.537 (lr:0.0001)
105920: accuracy:0.31 loss: 222.677 (lr:0.0001)
105940: accuracy:0.28 loss: 250.924 (lr:0.0001)
105960: accuracy:0.38 loss: 216.995 (lr:0.0001)
105980: accuracy:0.21 loss: 219.578 (lr:0.0001)
106000: accuracy:0.34 loss: 220.402 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
106000: ********* epoch 11 ********* test accuracy for all:0.230243 test loss: 263.568
106000: ********* epoch 11 ********* test accuracy for mode 0:0.043 test loss: 416.143
106000: ********* epoch 11 ********* test accuracy for mode 1:0.0155 test loss: 445.455
106000: ********* epoch 11 ********* test accuracy for mode 2:0.084 test loss: 275.343
106000: ********* epoch 11 ********* test accuracy for mode 24:0.23 test loss: 264.533
106000: ********* epoch 11 ********* test accuracy for mode 25:0.313 test loss: 245.11
106000: ********* epoch 11 ********* test accuracy for mode 26:0.31 test loss: 182.105
106000: ********* epoch 11 ********* test accuracy for mode 27:0.321 test loss: 253.394
106000: ********* epoch 11 ********* test accuracy for mode 28:0.2865 test loss: 245.775
106000: ********* epoch 11 ********* test accuracy for mode 29:0.2815 test loss: 252.119
106000: ********* epoch 11 ********* test accuracy for mode 30:0.1995 test loss: 249.174
106000: ********* epoch 11 ********* test accuracy for mode 31:0.1925 test loss: 249.871
106000: ********* epoch 11 ********* test accuracy for mode 32:0.2405 test loss: 241.119
106000: ********* epoch 11 ********* test accuracy for mode 33:0.1775 test loss: 249.216
106000: ********* epoch 11 ********* test accuracy for mode 34:0.027 test loss: 257.706
106000: ********* epoch 11 ********* test accuracy for mode 35:0.1375 test loss: 442.707
106000: ********* epoch 11 ********* test accuracy for mode 36:0.3945 test loss: 445.923
106020: accuracy:0.3 loss: 217.983 (lr:0.0001)
106040: accuracy:0.31 loss: 232.362 (lr:0.0001)
106060: accuracy:0.27 loss: 228.308 (lr:0.0001)
106080: accuracy:0.25 loss: 239.287 (lr:0.0001)
106100: accuracy:0.26 loss: 246.342 (lr:0.0001)
106120: accuracy:0.33 loss: 231.658 (lr:0.0001)
106140: accuracy:0.21 loss: 224.273 (lr:0.0001)
106160: accuracy:0.27 loss: 252.784 (lr:0.0001)
106180: accuracy:0.19 loss: 235.243 (lr:0.0001)
106200: accuracy:0.23 loss: 249.302 (lr:0.0001)
106220: accuracy:0.31 loss: 225.988 (lr:0.0001)
106240: accuracy:0.28 loss: 212.169 (lr:0.0001)
106260: accuracy:0.19 loss: 246.246 (lr:0.0001)
106280: accuracy:0.23 loss: 217.494 (lr:0.0001)
106300: accuracy:0.23 loss: 239.404 (lr:0.0001)
106320: accuracy:0.26 loss: 235.769 (lr:0.0001)
106340: accuracy:0.26 loss: 233.566 (lr:0.0001)
106360: accuracy:0.24 loss: 263.099 (lr:0.0001)
106380: accuracy:0.27 loss: 236.115 (lr:0.0001)
106400: accuracy:0.21 loss: 247.923 (lr:0.0001)
106420: accuracy:0.34 loss: 225.227 (lr:0.0001)
106440: accuracy:0.3 loss: 233.916 (lr:0.0001)
106460: accuracy:0.31 loss: 233.067 (lr:0.0001)
106480: accuracy:0.24 loss: 221.888 (lr:0.0001)
106500: accuracy:0.29 loss: 228.308 (lr:0.0001)
106520: accuracy:0.25 loss: 241.863 (lr:0.0001)
106540: accuracy:0.28 loss: 233.218 (lr:0.0001)
106560: accuracy:0.26 loss: 248.232 (lr:0.0001)
106580: accuracy:0.27 loss: 235.303 (lr:0.0001)
106600: accuracy:0.24 loss: 232.021 (lr:0.0001)
106620: accuracy:0.28 loss: 256.988 (lr:0.0001)
106640: accuracy:0.28 loss: 237.052 (lr:0.0001)
106660: accuracy:0.24 loss: 221.402 (lr:0.0001)
106680: accuracy:0.3 loss: 220.919 (lr:0.0001)
106700: accuracy:0.26 loss: 242.92 (lr:0.0001)
106720: accuracy:0.3 loss: 224.466 (lr:0.0001)
106740: accuracy:0.28 loss: 246.833 (lr:0.0001)
106760: accuracy:0.21 loss: 226.594 (lr:0.0001)
106780: accuracy:0.27 loss: 254.258 (lr:0.0001)
106800: accuracy:0.28 loss: 241.919 (lr:0.0001)
106820: accuracy:0.31 loss: 231.171 (lr:0.0001)
106840: accuracy:0.22 loss: 262.731 (lr:0.0001)
106860: accuracy:0.27 loss: 218.931 (lr:0.0001)
106880: accuracy:0.3 loss: 229.664 (lr:0.0001)
106900: accuracy:0.25 loss: 227.149 (lr:0.0001)
106920: accuracy:0.29 loss: 224.798 (lr:0.0001)
106940: accuracy:0.23 loss: 256.863 (lr:0.0001)
106960: accuracy:0.22 loss: 231.735 (lr:0.0001)
106980: accuracy:0.33 loss: 216.492 (lr:0.0001)
107000: accuracy:0.22 loss: 226.015 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
107000: ********* epoch 12 ********* test accuracy for all:0.220351 test loss: 264.94
107000: ********* epoch 12 ********* test accuracy for mode 0:0.0505 test loss: 407.93
107000: ********* epoch 12 ********* test accuracy for mode 1:0.024 test loss: 446.544
107000: ********* epoch 12 ********* test accuracy for mode 2:0.0805 test loss: 277.269
107000: ********* epoch 12 ********* test accuracy for mode 24:0.2345 test loss: 265.348
107000: ********* epoch 12 ********* test accuracy for mode 25:0.34 test loss: 246.362
107000: ********* epoch 12 ********* test accuracy for mode 26:0.3355 test loss: 183.59
107000: ********* epoch 12 ********* test accuracy for mode 27:0.254 test loss: 271.872
107000: ********* epoch 12 ********* test accuracy for mode 28:0.2825 test loss: 258.768
107000: ********* epoch 12 ********* test accuracy for mode 29:0.283 test loss: 264.094
107000: ********* epoch 12 ********* test accuracy for mode 30:0.1805 test loss: 260.272
107000: ********* epoch 12 ********* test accuracy for mode 31:0.155 test loss: 259.206
107000: ********* epoch 12 ********* test accuracy for mode 32:0.281 test loss: 243.216
107000: ********* epoch 12 ********* test accuracy for mode 33:0.1675 test loss: 252.377
107000: ********* epoch 12 ********* test accuracy for mode 34:0.0465 test loss: 258.598
107000: ********* epoch 12 ********* test accuracy for mode 35:0.092 test loss: 448.55
107000: ********* epoch 12 ********* test accuracy for mode 36:0.0515 test loss: 465.968
107020: accuracy:0.31 loss: 235.285 (lr:0.0001)
107040: accuracy:0.31 loss: 230.646 (lr:0.0001)
107060: accuracy:0.27 loss: 227.084 (lr:0.0001)
107080: accuracy:0.27 loss: 238.347 (lr:0.0001)
107100: accuracy:0.3 loss: 228.061 (lr:0.0001)
107120: accuracy:0.2 loss: 242.834 (lr:0.0001)
107140: accuracy:0.28 loss: 228.677 (lr:0.0001)
107160: accuracy:0.27 loss: 236.933 (lr:0.0001)
107180: accuracy:0.24 loss: 234.793 (lr:0.0001)
107200: accuracy:0.32 loss: 235.144 (lr:0.0001)
107220: accuracy:0.32 loss: 207.762 (lr:0.0001)
107240: accuracy:0.19 loss: 249.171 (lr:0.0001)
107260: accuracy:0.2 loss: 265.204 (lr:0.0001)
107280: accuracy:0.26 loss: 251.99 (lr:0.0001)
107300: accuracy:0.19 loss: 257.061 (lr:0.0001)
107320: accuracy:0.25 loss: 232.064 (lr:0.0001)
107340: accuracy:0.27 loss: 228.579 (lr:0.0001)
107360: accuracy:0.33 loss: 210.25 (lr:0.0001)
107380: accuracy:0.32 loss: 230.126 (lr:0.0001)
107400: accuracy:0.38 loss: 214.067 (lr:0.0001)
107420: accuracy:0.22 loss: 252.506 (lr:0.0001)
107440: accuracy:0.22 loss: 252.383 (lr:0.0001)
107460: accuracy:0.19 loss: 241.892 (lr:0.0001)
107480: accuracy:0.28 loss: 255.696 (lr:0.0001)
107500: accuracy:0.31 loss: 234.621 (lr:0.0001)
107520: accuracy:0.31 loss: 237.965 (lr:0.0001)
107540: accuracy:0.2 loss: 269.928 (lr:0.0001)
107560: accuracy:0.23 loss: 244.849 (lr:0.0001)
107580: accuracy:0.32 loss: 211.372 (lr:0.0001)
107600: accuracy:0.28 loss: 216.584 (lr:0.0001)
107620: accuracy:0.31 loss: 244.498 (lr:0.0001)
107640: accuracy:0.26 loss: 237.186 (lr:0.0001)
107660: accuracy:0.19 loss: 238.022 (lr:0.0001)
107680: accuracy:0.27 loss: 219.352 (lr:0.0001)
107700: accuracy:0.24 loss: 250.814 (lr:0.0001)
107720: accuracy:0.27 loss: 239.059 (lr:0.0001)
107740: accuracy:0.32 loss: 227.806 (lr:0.0001)
107760: accuracy:0.22 loss: 243.243 (lr:0.0001)
107780: accuracy:0.26 loss: 229.363 (lr:0.0001)
107800: accuracy:0.25 loss: 232.321 (lr:0.0001)
107820: accuracy:0.38 loss: 217.912 (lr:0.0001)
107840: accuracy:0.33 loss: 222.343 (lr:0.0001)
107860: accuracy:0.26 loss: 230.361 (lr:0.0001)
107880: accuracy:0.27 loss: 218.573 (lr:0.0001)
107900: accuracy:0.17 loss: 243.295 (lr:0.0001)
107920: accuracy:0.26 loss: 235.805 (lr:0.0001)
107940: accuracy:0.24 loss: 248.682 (lr:0.0001)
107960: accuracy:0.27 loss: 222.639 (lr:0.0001)
107980: accuracy:0.21 loss: 239.467 (lr:0.0001)
108000: accuracy:0.35 loss: 236.612 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
108000: ********* epoch 12 ********* test accuracy for all:0.231135 test loss: 261.438
108000: ********* epoch 12 ********* test accuracy for mode 0:0.0545 test loss: 406.245
108000: ********* epoch 12 ********* test accuracy for mode 1:0.0245 test loss: 435.063
108000: ********* epoch 12 ********* test accuracy for mode 2:0.0645 test loss: 281.535
108000: ********* epoch 12 ********* test accuracy for mode 24:0.2195 test loss: 269.857
108000: ********* epoch 12 ********* test accuracy for mode 25:0.308 test loss: 245.122
108000: ********* epoch 12 ********* test accuracy for mode 26:0.3695 test loss: 178.028
108000: ********* epoch 12 ********* test accuracy for mode 27:0.286 test loss: 257.73
108000: ********* epoch 12 ********* test accuracy for mode 28:0.3095 test loss: 242.52
108000: ********* epoch 12 ********* test accuracy for mode 29:0.2835 test loss: 252.887
108000: ********* epoch 12 ********* test accuracy for mode 30:0.196 test loss: 251.999
108000: ********* epoch 12 ********* test accuracy for mode 31:0.192 test loss: 254.492
108000: ********* epoch 12 ********* test accuracy for mode 32:0.2315 test loss: 246.867
108000: ********* epoch 12 ********* test accuracy for mode 33:0.157 test loss: 256.024
108000: ********* epoch 12 ********* test accuracy for mode 34:0.054 test loss: 258.442
108000: ********* epoch 12 ********* test accuracy for mode 35:0.149 test loss: 417.828
108000: ********* epoch 12 ********* test accuracy for mode 36:0.4155 test loss: 417.779
108020: accuracy:0.25 loss: 239.292 (lr:0.0001)
108040: accuracy:0.23 loss: 243.474 (lr:0.0001)
108060: accuracy:0.3 loss: 230.881 (lr:0.0001)
108080: accuracy:0.29 loss: 243.069 (lr:0.0001)
108100: accuracy:0.28 loss: 251.241 (lr:0.0001)
108120: accuracy:0.32 loss: 210.629 (lr:0.0001)
108140: accuracy:0.23 loss: 247.339 (lr:0.0001)
108160: accuracy:0.19 loss: 238.868 (lr:0.0001)
108180: accuracy:0.27 loss: 239.531 (lr:0.0001)
108200: accuracy:0.29 loss: 229.44 (lr:0.0001)
108220: accuracy:0.22 loss: 274.362 (lr:0.0001)
108240: accuracy:0.19 loss: 244.2 (lr:0.0001)
108260: accuracy:0.27 loss: 243.759 (lr:0.0001)
108280: accuracy:0.23 loss: 246.665 (lr:0.0001)
108300: accuracy:0.25 loss: 227.651 (lr:0.0001)
108320: accuracy:0.17 loss: 261.503 (lr:0.0001)
108340: accuracy:0.13 loss: 242.836 (lr:0.0001)
108360: accuracy:0.39 loss: 210.519 (lr:0.0001)
108380: accuracy:0.31 loss: 227.158 (lr:0.0001)
108400: accuracy:0.32 loss: 217.688 (lr:0.0001)
108420: accuracy:0.26 loss: 232.979 (lr:0.0001)
108440: accuracy:0.2 loss: 266.001 (lr:0.0001)
108460: accuracy:0.28 loss: 218.954 (lr:0.0001)
108480: accuracy:0.28 loss: 234.478 (lr:0.0001)
108500: accuracy:0.19 loss: 252.626 (lr:0.0001)
108520: accuracy:0.24 loss: 252.493 (lr:0.0001)
108540: accuracy:0.27 loss: 232.515 (lr:0.0001)
108560: accuracy:0.25 loss: 242.037 (lr:0.0001)
108580: accuracy:0.26 loss: 223.319 (lr:0.0001)
108600: accuracy:0.23 loss: 251.006 (lr:0.0001)
108620: accuracy:0.25 loss: 243.973 (lr:0.0001)
108640: accuracy:0.28 loss: 236.85 (lr:0.0001)
108660: accuracy:0.25 loss: 232.926 (lr:0.0001)
108680: accuracy:0.27 loss: 233.785 (lr:0.0001)
108700: accuracy:0.32 loss: 217.702 (lr:0.0001)
108720: accuracy:0.3 loss: 250.357 (lr:0.0001)
108740: accuracy:0.32 loss: 231.384 (lr:0.0001)
108760: accuracy:0.35 loss: 208.89 (lr:0.0001)
108780: accuracy:0.25 loss: 222.997 (lr:0.0001)
108800: accuracy:0.26 loss: 248.101 (lr:0.0001)
108820: accuracy:0.3 loss: 232.772 (lr:0.0001)
108840: accuracy:0.26 loss: 249.931 (lr:0.0001)
108860: accuracy:0.25 loss: 245.445 (lr:0.0001)
108880: accuracy:0.35 loss: 217.295 (lr:0.0001)
108900: accuracy:0.26 loss: 248.454 (lr:0.0001)
108920: accuracy:0.29 loss: 227.441 (lr:0.0001)
108940: accuracy:0.28 loss: 234.727 (lr:0.0001)
108960: accuracy:0.25 loss: 239.837 (lr:0.0001)
108980: accuracy:0.26 loss: 222.917 (lr:0.0001)
109000: accuracy:0.21 loss: 240.394 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
109000: ********* epoch 12 ********* test accuracy for all:0.225486 test loss: 263.005
109000: ********* epoch 12 ********* test accuracy for mode 0:0.0505 test loss: 410.45
109000: ********* epoch 12 ********* test accuracy for mode 1:0.027 test loss: 447.886
109000: ********* epoch 12 ********* test accuracy for mode 2:0.1015 test loss: 275.445
109000: ********* epoch 12 ********* test accuracy for mode 24:0.249 test loss: 262.249
109000: ********* epoch 12 ********* test accuracy for mode 25:0.347 test loss: 243.569
109000: ********* epoch 12 ********* test accuracy for mode 26:0.306 test loss: 184.304
109000: ********* epoch 12 ********* test accuracy for mode 27:0.271 test loss: 266.415
109000: ********* epoch 12 ********* test accuracy for mode 28:0.2905 test loss: 251.209
109000: ********* epoch 12 ********* test accuracy for mode 29:0.27 test loss: 255.861
109000: ********* epoch 12 ********* test accuracy for mode 30:0.203 test loss: 250.149
109000: ********* epoch 12 ********* test accuracy for mode 31:0.203 test loss: 248.039
109000: ********* epoch 12 ********* test accuracy for mode 32:0.254 test loss: 238.862
109000: ********* epoch 12 ********* test accuracy for mode 33:0.168 test loss: 251.131
109000: ********* epoch 12 ********* test accuracy for mode 34:0.038 test loss: 258.811
109000: ********* epoch 12 ********* test accuracy for mode 35:0.1075 test loss: 444.527
109000: ********* epoch 12 ********* test accuracy for mode 36:0.1025 test loss: 450.845
109020: accuracy:0.34 loss: 223.693 (lr:0.0001)
109040: accuracy:0.25 loss: 262.12 (lr:0.0001)
109060: accuracy:0.26 loss: 245.193 (lr:0.0001)
109080: accuracy:0.34 loss: 229.892 (lr:0.0001)
109100: accuracy:0.26 loss: 225.233 (lr:0.0001)
109120: accuracy:0.2 loss: 251.057 (lr:0.0001)
109140: accuracy:0.26 loss: 248.301 (lr:0.0001)
109160: accuracy:0.28 loss: 248.41 (lr:0.0001)
109180: accuracy:0.35 loss: 229.043 (lr:0.0001)
109200: accuracy:0.29 loss: 223.757 (lr:0.0001)
109220: accuracy:0.3 loss: 227.055 (lr:0.0001)
109240: accuracy:0.28 loss: 218.749 (lr:0.0001)
109260: accuracy:0.27 loss: 241.395 (lr:0.0001)
109280: accuracy:0.25 loss: 254.627 (lr:0.0001)
109300: accuracy:0.33 loss: 233.392 (lr:0.0001)
109320: accuracy:0.34 loss: 225.529 (lr:0.0001)
109340: accuracy:0.19 loss: 244.012 (lr:0.0001)
109360: accuracy:0.28 loss: 244.964 (lr:0.0001)
109380: accuracy:0.29 loss: 238.896 (lr:0.0001)
109400: accuracy:0.25 loss: 233.839 (lr:0.0001)
109420: accuracy:0.25 loss: 230.188 (lr:0.0001)
109440: accuracy:0.31 loss: 229.968 (lr:0.0001)
109460: accuracy:0.22 loss: 241.414 (lr:0.0001)
109480: accuracy:0.26 loss: 233.67 (lr:0.0001)
109500: accuracy:0.24 loss: 264.075 (lr:0.0001)
109520: accuracy:0.24 loss: 237.943 (lr:0.0001)
109540: accuracy:0.25 loss: 257.767 (lr:0.0001)
109560: accuracy:0.3 loss: 236.306 (lr:0.0001)
109580: accuracy:0.31 loss: 231.33 (lr:0.0001)
109600: accuracy:0.29 loss: 226.112 (lr:0.0001)
109620: accuracy:0.33 loss: 231.117 (lr:0.0001)
109640: accuracy:0.26 loss: 233.232 (lr:0.0001)
109660: accuracy:0.25 loss: 239.289 (lr:0.0001)
109680: accuracy:0.29 loss: 214.469 (lr:0.0001)
109700: accuracy:0.27 loss: 239.818 (lr:0.0001)
109720: accuracy:0.28 loss: 245.391 (lr:0.0001)
109740: accuracy:0.25 loss: 243.795 (lr:0.0001)
109760: accuracy:0.37 loss: 223.021 (lr:0.0001)
109780: accuracy:0.31 loss: 207.985 (lr:0.0001)
109800: accuracy:0.23 loss: 257.544 (lr:0.0001)
109820: accuracy:0.16 loss: 261.189 (lr:0.0001)
109840: accuracy:0.31 loss: 246.811 (lr:0.0001)
109860: accuracy:0.32 loss: 232.707 (lr:0.0001)
109880: accuracy:0.3 loss: 241.609 (lr:0.0001)
109900: accuracy:0.33 loss: 221.62 (lr:0.0001)
109920: accuracy:0.26 loss: 239.649 (lr:0.0001)
109940: accuracy:0.17 loss: 253.139 (lr:0.0001)
109960: accuracy:0.29 loss: 235.14 (lr:0.0001)
109980: accuracy:0.34 loss: 213.591 (lr:0.0001)
110000: accuracy:0.23 loss: 231.135 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
110000: ********* epoch 12 ********* test accuracy for all:0.226932 test loss: 263.0
110000: ********* epoch 12 ********* test accuracy for mode 0:0.0485 test loss: 405.542
110000: ********* epoch 12 ********* test accuracy for mode 1:0.0295 test loss: 436.602
110000: ********* epoch 12 ********* test accuracy for mode 2:0.0685 test loss: 279.352
110000: ********* epoch 12 ********* test accuracy for mode 24:0.243 test loss: 264.351
110000: ********* epoch 12 ********* test accuracy for mode 25:0.3545 test loss: 242.96
110000: ********* epoch 12 ********* test accuracy for mode 26:0.272 test loss: 185.513
110000: ********* epoch 12 ********* test accuracy for mode 27:0.266 test loss: 269.841
110000: ********* epoch 12 ********* test accuracy for mode 28:0.2945 test loss: 256.264
110000: ********* epoch 12 ********* test accuracy for mode 29:0.26 test loss: 264.667
110000: ********* epoch 12 ********* test accuracy for mode 30:0.1975 test loss: 256.088
110000: ********* epoch 12 ********* test accuracy for mode 31:0.187 test loss: 257.654
110000: ********* epoch 12 ********* test accuracy for mode 32:0.2205 test loss: 249.378
110000: ********* epoch 12 ********* test accuracy for mode 33:0.1575 test loss: 257.228
110000: ********* epoch 12 ********* test accuracy for mode 34:0.0795 test loss: 259.193
110000: ********* epoch 12 ********* test accuracy for mode 35:0.114 test loss: 433.136
110000: ********* epoch 12 ********* test accuracy for mode 36:0.2895 test loss: 429.387
110020: accuracy:0.24 loss: 243.001 (lr:0.0001)
110040: accuracy:0.27 loss: 225.614 (lr:0.0001)
110060: accuracy:0.27 loss: 238.603 (lr:0.0001)
110080: accuracy:0.31 loss: 233.154 (lr:0.0001)
110100: accuracy:0.29 loss: 242.629 (lr:0.0001)
110120: accuracy:0.24 loss: 253.998 (lr:0.0001)
110140: accuracy:0.3 loss: 234.791 (lr:0.0001)
110160: accuracy:0.3 loss: 238.836 (lr:0.0001)
110180: accuracy:0.2 loss: 267.192 (lr:0.0001)
110200: accuracy:0.25 loss: 230.019 (lr:0.0001)
110220: accuracy:0.22 loss: 227.854 (lr:0.0001)
110240: accuracy:0.25 loss: 223.852 (lr:0.0001)
110260: accuracy:0.33 loss: 235.684 (lr:0.0001)
110280: accuracy:0.31 loss: 228.969 (lr:0.0001)
110300: accuracy:0.24 loss: 238.45 (lr:0.0001)
110320: accuracy:0.27 loss: 231.178 (lr:0.0001)
110340: accuracy:0.28 loss: 224.233 (lr:0.0001)
110360: accuracy:0.32 loss: 239.162 (lr:0.0001)
110380: accuracy:0.25 loss: 231.11 (lr:0.0001)
110400: accuracy:0.28 loss: 264.993 (lr:0.0001)
110420: accuracy:0.31 loss: 213.867 (lr:0.0001)
110440: accuracy:0.3 loss: 223.06 (lr:0.0001)
110460: accuracy:0.25 loss: 254.574 (lr:0.0001)
110480: accuracy:0.37 loss: 204.962 (lr:0.0001)
110500: accuracy:0.26 loss: 236.175 (lr:0.0001)
110520: accuracy:0.29 loss: 247.08 (lr:0.0001)
110540: accuracy:0.19 loss: 240.372 (lr:0.0001)
110560: accuracy:0.27 loss: 242.86 (lr:0.0001)
110580: accuracy:0.22 loss: 260.744 (lr:0.0001)
110600: accuracy:0.27 loss: 228.707 (lr:0.0001)
110620: accuracy:0.29 loss: 241.009 (lr:0.0001)
110640: accuracy:0.3 loss: 223.684 (lr:0.0001)
110660: accuracy:0.3 loss: 259.047 (lr:0.0001)
110680: accuracy:0.27 loss: 232.047 (lr:0.0001)
110700: accuracy:0.28 loss: 231.355 (lr:0.0001)
110720: accuracy:0.26 loss: 252.849 (lr:0.0001)
110740: accuracy:0.35 loss: 215.684 (lr:0.0001)
110760: accuracy:0.29 loss: 230.529 (lr:0.0001)
110780: accuracy:0.23 loss: 248.001 (lr:0.0001)
110800: accuracy:0.29 loss: 246.46 (lr:0.0001)
110820: accuracy:0.24 loss: 230.746 (lr:0.0001)
110840: accuracy:0.26 loss: 241.171 (lr:0.0001)
110860: accuracy:0.21 loss: 250.641 (lr:0.0001)
110880: accuracy:0.27 loss: 227.166 (lr:0.0001)
110900: accuracy:0.26 loss: 222.435 (lr:0.0001)
110920: accuracy:0.28 loss: 247.193 (lr:0.0001)
110940: accuracy:0.34 loss: 228.002 (lr:0.0001)
110960: accuracy:0.33 loss: 221.177 (lr:0.0001)
110980: accuracy:0.26 loss: 257.394 (lr:0.0001)
111000: accuracy:0.3 loss: 235.129 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
111000: ********* epoch 12 ********* test accuracy for all:0.219527 test loss: 264.321
111000: ********* epoch 12 ********* test accuracy for mode 0:0.0465 test loss: 408.997
111000: ********* epoch 12 ********* test accuracy for mode 1:0.023 test loss: 443.724
111000: ********* epoch 12 ********* test accuracy for mode 2:0.0785 test loss: 278.576
111000: ********* epoch 12 ********* test accuracy for mode 24:0.2265 test loss: 266.302
111000: ********* epoch 12 ********* test accuracy for mode 25:0.3535 test loss: 240.711
111000: ********* epoch 12 ********* test accuracy for mode 26:0.265 test loss: 183.598
111000: ********* epoch 12 ********* test accuracy for mode 27:0.299 test loss: 253.512
111000: ********* epoch 12 ********* test accuracy for mode 28:0.3045 test loss: 240.49
111000: ********* epoch 12 ********* test accuracy for mode 29:0.3005 test loss: 247.038
111000: ********* epoch 12 ********* test accuracy for mode 30:0.2155 test loss: 244.6
111000: ********* epoch 12 ********* test accuracy for mode 31:0.19 test loss: 249.539
111000: ********* epoch 12 ********* test accuracy for mode 32:0.2355 test loss: 240.244
111000: ********* epoch 12 ********* test accuracy for mode 33:0.176 test loss: 251.678
111000: ********* epoch 12 ********* test accuracy for mode 34:0.0405 test loss: 259.556
111000: ********* epoch 12 ********* test accuracy for mode 35:0.0915 test loss: 465.866
111000: ********* epoch 12 ********* test accuracy for mode 36:0.037 test loss: 486.493
111020: accuracy:0.32 loss: 207.033 (lr:0.0001)
111040: accuracy:0.33 loss: 220.599 (lr:0.0001)
111060: accuracy:0.33 loss: 233.701 (lr:0.0001)
111080: accuracy:0.33 loss: 224.054 (lr:0.0001)
111100: accuracy:0.24 loss: 232.236 (lr:0.0001)
111120: accuracy:0.2 loss: 220.843 (lr:0.0001)
111140: accuracy:0.26 loss: 243.084 (lr:0.0001)
111160: accuracy:0.17 loss: 247.654 (lr:0.0001)
111180: accuracy:0.27 loss: 232.031 (lr:0.0001)
111200: accuracy:0.28 loss: 247.072 (lr:0.0001)
111220: accuracy:0.33 loss: 227.662 (lr:0.0001)
111240: accuracy:0.24 loss: 246.529 (lr:0.0001)
111260: accuracy:0.38 loss: 226.061 (lr:0.0001)
111280: accuracy:0.24 loss: 236.976 (lr:0.0001)
111300: accuracy:0.28 loss: 228.765 (lr:0.0001)
111320: accuracy:0.27 loss: 239.118 (lr:0.0001)
111340: accuracy:0.28 loss: 239.517 (lr:0.0001)
111360: accuracy:0.25 loss: 247.956 (lr:0.0001)
111380: accuracy:0.25 loss: 221.82 (lr:0.0001)
111400: accuracy:0.22 loss: 228.141 (lr:0.0001)
111420: accuracy:0.34 loss: 219.475 (lr:0.0001)
111440: accuracy:0.29 loss: 230.501 (lr:0.0001)
111460: accuracy:0.31 loss: 228.443 (lr:0.0001)
111480: accuracy:0.21 loss: 243.975 (lr:0.0001)
111500: accuracy:0.28 loss: 235.865 (lr:0.0001)
111520: accuracy:0.23 loss: 247.53 (lr:0.0001)
111540: accuracy:0.24 loss: 253.477 (lr:0.0001)
111560: accuracy:0.22 loss: 252.319 (lr:0.0001)
111580: accuracy:0.32 loss: 227.429 (lr:0.0001)
111600: accuracy:0.24 loss: 233.838 (lr:0.0001)
111620: accuracy:0.21 loss: 240.577 (lr:0.0001)
111640: accuracy:0.28 loss: 236.251 (lr:0.0001)
111660: accuracy:0.24 loss: 224.142 (lr:0.0001)
111680: accuracy:0.26 loss: 220.097 (lr:0.0001)
111700: accuracy:0.27 loss: 232.23 (lr:0.0001)
111720: accuracy:0.25 loss: 222.766 (lr:0.0001)
111740: accuracy:0.25 loss: 245.336 (lr:0.0001)
111760: accuracy:0.28 loss: 218.983 (lr:0.0001)
111780: accuracy:0.26 loss: 218.739 (lr:0.0001)
111800: accuracy:0.2 loss: 221.967 (lr:0.0001)
111820: accuracy:0.29 loss: 233.537 (lr:0.0001)
111840: accuracy:0.28 loss: 224.328 (lr:0.0001)
111860: accuracy:0.25 loss: 230.187 (lr:0.0001)
111880: accuracy:0.33 loss: 240.575 (lr:0.0001)
111900: accuracy:0.24 loss: 231.687 (lr:0.0001)
111920: accuracy:0.26 loss: 230.495 (lr:0.0001)
111940: accuracy:0.17 loss: 258.989 (lr:0.0001)
111960: accuracy:0.22 loss: 240.838 (lr:0.0001)
111980: accuracy:0.22 loss: 233.415 (lr:0.0001)
112000: accuracy:0.26 loss: 223.925 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
112000: ********* epoch 12 ********* test accuracy for all:0.225216 test loss: 264.203
112000: ********* epoch 12 ********* test accuracy for mode 0:0.051 test loss: 407.743
112000: ********* epoch 12 ********* test accuracy for mode 1:0.025 test loss: 445.941
112000: ********* epoch 12 ********* test accuracy for mode 2:0.085 test loss: 277.659
112000: ********* epoch 12 ********* test accuracy for mode 24:0.234 test loss: 267.003
112000: ********* epoch 12 ********* test accuracy for mode 25:0.323 test loss: 246.695
112000: ********* epoch 12 ********* test accuracy for mode 26:0.2805 test loss: 187.453
112000: ********* epoch 12 ********* test accuracy for mode 27:0.2545 test loss: 272.399
112000: ********* epoch 12 ********* test accuracy for mode 28:0.2765 test loss: 256.094
112000: ********* epoch 12 ********* test accuracy for mode 29:0.268 test loss: 259.248
112000: ********* epoch 12 ********* test accuracy for mode 30:0.2195 test loss: 249.899
112000: ********* epoch 12 ********* test accuracy for mode 31:0.171 test loss: 251.913
112000: ********* epoch 12 ********* test accuracy for mode 32:0.27 test loss: 240.062
112000: ********* epoch 12 ********* test accuracy for mode 33:0.182 test loss: 247.51
112000: ********* epoch 12 ********* test accuracy for mode 34:0.055 test loss: 253.768
112000: ********* epoch 12 ********* test accuracy for mode 35:0.1135 test loss: 442.056
112000: ********* epoch 12 ********* test accuracy for mode 36:0.2425 test loss: 445.463
112020: accuracy:0.28 loss: 231.489 (lr:0.0001)
112040: accuracy:0.29 loss: 249.696 (lr:0.0001)
112060: accuracy:0.29 loss: 240.816 (lr:0.0001)
112080: accuracy:0.24 loss: 231.474 (lr:0.0001)
112100: accuracy:0.29 loss: 252.246 (lr:0.0001)
112120: accuracy:0.23 loss: 241.897 (lr:0.0001)
112140: accuracy:0.26 loss: 249.404 (lr:0.0001)
112160: accuracy:0.28 loss: 249.436 (lr:0.0001)
112180: accuracy:0.21 loss: 247.535 (lr:0.0001)
112200: accuracy:0.26 loss: 231.844 (lr:0.0001)
112220: accuracy:0.29 loss: 226.599 (lr:0.0001)
112240: accuracy:0.22 loss: 240.046 (lr:0.0001)
112260: accuracy:0.21 loss: 259.186 (lr:0.0001)
112280: accuracy:0.26 loss: 235.076 (lr:0.0001)
112300: accuracy:0.18 loss: 270.365 (lr:0.0001)
112320: accuracy:0.24 loss: 232.955 (lr:0.0001)
112340: accuracy:0.24 loss: 230.394 (lr:0.0001)
112360: accuracy:0.2 loss: 251.064 (lr:0.0001)
112380: accuracy:0.29 loss: 233.063 (lr:0.0001)
112400: accuracy:0.3 loss: 253.073 (lr:0.0001)
112420: accuracy:0.3 loss: 216.874 (lr:0.0001)
112440: accuracy:0.37 loss: 206.984 (lr:0.0001)
112460: accuracy:0.27 loss: 247.68 (lr:0.0001)
112480: accuracy:0.3 loss: 218.083 (lr:0.0001)
112500: accuracy:0.31 loss: 221.436 (lr:0.0001)
112520: accuracy:0.29 loss: 237.376 (lr:0.0001)
112540: accuracy:0.29 loss: 237.867 (lr:0.0001)
112560: accuracy:0.28 loss: 239.897 (lr:0.0001)
112580: accuracy:0.25 loss: 240.565 (lr:0.0001)
112600: accuracy:0.26 loss: 244.976 (lr:0.0001)
112620: accuracy:0.3 loss: 240.369 (lr:0.0001)
112640: accuracy:0.23 loss: 236.627 (lr:0.0001)
112660: accuracy:0.24 loss: 243.576 (lr:0.0001)
112680: accuracy:0.27 loss: 244.512 (lr:0.0001)
112700: accuracy:0.29 loss: 232.089 (lr:0.0001)
112720: accuracy:0.23 loss: 247.121 (lr:0.0001)
112740: accuracy:0.25 loss: 241.008 (lr:0.0001)
112760: accuracy:0.2 loss: 239.523 (lr:0.0001)
112780: accuracy:0.28 loss: 226.293 (lr:0.0001)
112800: accuracy:0.27 loss: 245.91 (lr:0.0001)
112820: accuracy:0.26 loss: 247.331 (lr:0.0001)
112840: accuracy:0.3 loss: 223.869 (lr:0.0001)
112860: accuracy:0.32 loss: 235.117 (lr:0.0001)
112880: accuracy:0.28 loss: 228.688 (lr:0.0001)
112900: accuracy:0.26 loss: 229.042 (lr:0.0001)
112920: accuracy:0.21 loss: 235.679 (lr:0.0001)
112940: accuracy:0.26 loss: 221.49 (lr:0.0001)
112960: accuracy:0.33 loss: 228.875 (lr:0.0001)
112980: accuracy:0.24 loss: 246.679 (lr:0.0001)
113000: accuracy:0.25 loss: 231.863 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
113000: ********* epoch 12 ********* test accuracy for all:0.228703 test loss: 263.177
113000: ********* epoch 12 ********* test accuracy for mode 0:0.048 test loss: 413.231
113000: ********* epoch 12 ********* test accuracy for mode 1:0.0155 test loss: 447.611
113000: ********* epoch 12 ********* test accuracy for mode 2:0.057 test loss: 282.648
113000: ********* epoch 12 ********* test accuracy for mode 24:0.2495 test loss: 263.267
113000: ********* epoch 12 ********* test accuracy for mode 25:0.317 test loss: 242.935
113000: ********* epoch 12 ********* test accuracy for mode 26:0.257 test loss: 189.873
113000: ********* epoch 12 ********* test accuracy for mode 27:0.2535 test loss: 269.305
113000: ********* epoch 12 ********* test accuracy for mode 28:0.2625 test loss: 255.082
113000: ********* epoch 12 ********* test accuracy for mode 29:0.2775 test loss: 259.949
113000: ********* epoch 12 ********* test accuracy for mode 30:0.203 test loss: 254.362
113000: ********* epoch 12 ********* test accuracy for mode 31:0.1855 test loss: 256.128
113000: ********* epoch 12 ********* test accuracy for mode 32:0.2385 test loss: 245.987
113000: ********* epoch 12 ********* test accuracy for mode 33:0.1815 test loss: 255.122
113000: ********* epoch 12 ********* test accuracy for mode 34:0.0285 test loss: 261.999
113000: ********* epoch 12 ********* test accuracy for mode 35:0.13 test loss: 445.835
113000: ********* epoch 12 ********* test accuracy for mode 36:0.367 test loss: 446.526
113020: accuracy:0.29 loss: 232.453 (lr:0.0001)
113040: accuracy:0.33 loss: 217.534 (lr:0.0001)
113060: accuracy:0.27 loss: 234.716 (lr:0.0001)
113080: accuracy:0.17 loss: 237.789 (lr:0.0001)
113100: accuracy:0.33 loss: 210.793 (lr:0.0001)
113120: accuracy:0.32 loss: 236.924 (lr:0.0001)
113140: accuracy:0.33 loss: 215.723 (lr:0.0001)
113160: accuracy:0.3 loss: 219.328 (lr:0.0001)
113180: accuracy:0.24 loss: 243.065 (lr:0.0001)
113200: accuracy:0.27 loss: 215.272 (lr:0.0001)
113220: accuracy:0.21 loss: 251.188 (lr:0.0001)
113240: accuracy:0.25 loss: 218.814 (lr:0.0001)
113260: accuracy:0.3 loss: 236.222 (lr:0.0001)
113280: accuracy:0.19 loss: 236.634 (lr:0.0001)
113300: accuracy:0.24 loss: 235.04 (lr:0.0001)
113320: accuracy:0.2 loss: 252.394 (lr:0.0001)
113340: accuracy:0.31 loss: 242.516 (lr:0.0001)
113360: accuracy:0.23 loss: 228.866 (lr:0.0001)
113380: accuracy:0.27 loss: 235.613 (lr:0.0001)
113400: accuracy:0.3 loss: 223.935 (lr:0.0001)
113420: accuracy:0.18 loss: 260.501 (lr:0.0001)
113440: accuracy:0.23 loss: 230.271 (lr:0.0001)
113460: accuracy:0.24 loss: 239.94 (lr:0.0001)
113480: accuracy:0.22 loss: 230.247 (lr:0.0001)
113500: accuracy:0.2 loss: 255.546 (lr:0.0001)
113520: accuracy:0.32 loss: 236.407 (lr:0.0001)
113540: accuracy:0.25 loss: 236.497 (lr:0.0001)
113560: accuracy:0.26 loss: 231.41 (lr:0.0001)
113580: accuracy:0.26 loss: 229.518 (lr:0.0001)
113600: accuracy:0.32 loss: 249.382 (lr:0.0001)
113620: accuracy:0.29 loss: 253.334 (lr:0.0001)
113640: accuracy:0.28 loss: 244.767 (lr:0.0001)
113660: accuracy:0.26 loss: 233.985 (lr:0.0001)
113680: accuracy:0.3 loss: 234.4 (lr:0.0001)
113700: accuracy:0.21 loss: 257.912 (lr:0.0001)
113720: accuracy:0.31 loss: 218.402 (lr:0.0001)
113740: accuracy:0.24 loss: 232.54 (lr:0.0001)
113760: accuracy:0.22 loss: 236.547 (lr:0.0001)
113780: accuracy:0.37 loss: 231.553 (lr:0.0001)
113800: accuracy:0.33 loss: 228.546 (lr:0.0001)
113820: accuracy:0.34 loss: 212.423 (lr:0.0001)
113840: accuracy:0.25 loss: 265.381 (lr:0.0001)
113860: accuracy:0.23 loss: 236.05 (lr:0.0001)
113880: accuracy:0.27 loss: 251.953 (lr:0.0001)
113900: accuracy:0.31 loss: 219.764 (lr:0.0001)
113920: accuracy:0.3 loss: 233.299 (lr:0.0001)
113940: accuracy:0.33 loss: 213.214 (lr:0.0001)
113960: accuracy:0.32 loss: 222.618 (lr:0.0001)
113980: accuracy:0.3 loss: 242.886 (lr:0.0001)
114000: accuracy:0.29 loss: 241.219 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
114000: ********* epoch 12 ********* test accuracy for all:0.234108 test loss: 261.745
114000: ********* epoch 12 ********* test accuracy for mode 0:0.0485 test loss: 409.674
114000: ********* epoch 12 ********* test accuracy for mode 1:0.029 test loss: 431.857
114000: ********* epoch 12 ********* test accuracy for mode 2:0.046 test loss: 280.703
114000: ********* epoch 12 ********* test accuracy for mode 24:0.26 test loss: 264.634
114000: ********* epoch 12 ********* test accuracy for mode 25:0.273 test loss: 249.983
114000: ********* epoch 12 ********* test accuracy for mode 26:0.422 test loss: 174.933
114000: ********* epoch 12 ********* test accuracy for mode 27:0.2735 test loss: 261.401
114000: ********* epoch 12 ********* test accuracy for mode 28:0.2825 test loss: 251.095
114000: ********* epoch 12 ********* test accuracy for mode 29:0.2985 test loss: 261.493
114000: ********* epoch 12 ********* test accuracy for mode 30:0.1755 test loss: 262.667
114000: ********* epoch 12 ********* test accuracy for mode 31:0.194 test loss: 262.247
114000: ********* epoch 12 ********* test accuracy for mode 32:0.2325 test loss: 252.313
114000: ********* epoch 12 ********* test accuracy for mode 33:0.167 test loss: 261.591
114000: ********* epoch 12 ********* test accuracy for mode 34:0.0375 test loss: 264.243
114000: ********* epoch 12 ********* test accuracy for mode 35:0.201 test loss: 406.975
114000: ********* epoch 12 ********* test accuracy for mode 36:0.461 test loss: 408.741
114020: accuracy:0.25 loss: 242.935 (lr:0.0001)
114040: accuracy:0.25 loss: 247.481 (lr:0.0001)
114060: accuracy:0.3 loss: 222.962 (lr:0.0001)
114080: accuracy:0.27 loss: 229.33 (lr:0.0001)
114100: accuracy:0.27 loss: 234.812 (lr:0.0001)
114120: accuracy:0.3 loss: 231.682 (lr:0.0001)
114140: accuracy:0.26 loss: 224.288 (lr:0.0001)
114160: accuracy:0.25 loss: 234.957 (lr:0.0001)
114180: accuracy:0.17 loss: 263.748 (lr:0.0001)
114200: accuracy:0.31 loss: 237.004 (lr:0.0001)
114220: accuracy:0.23 loss: 238.928 (lr:0.0001)
114240: accuracy:0.28 loss: 244.015 (lr:0.0001)
114260: accuracy:0.29 loss: 244.682 (lr:0.0001)
114280: accuracy:0.24 loss: 254.279 (lr:0.0001)
114300: accuracy:0.32 loss: 238.742 (lr:0.0001)
114320: accuracy:0.37 loss: 204.376 (lr:0.0001)
114340: accuracy:0.23 loss: 233.423 (lr:0.0001)
114360: accuracy:0.28 loss: 238.848 (lr:0.0001)
114380: accuracy:0.27 loss: 251.584 (lr:0.0001)
114400: accuracy:0.27 loss: 233.983 (lr:0.0001)
114420: accuracy:0.29 loss: 234.585 (lr:0.0001)
114440: accuracy:0.27 loss: 224.689 (lr:0.0001)
114460: accuracy:0.23 loss: 233.03 (lr:0.0001)
114480: accuracy:0.28 loss: 251.183 (lr:0.0001)
114500: accuracy:0.27 loss: 225.368 (lr:0.0001)
114520: accuracy:0.25 loss: 251.727 (lr:0.0001)
114540: accuracy:0.29 loss: 228.626 (lr:0.0001)
114560: accuracy:0.37 loss: 222.73 (lr:0.0001)
114580: accuracy:0.24 loss: 231.796 (lr:0.0001)
114600: accuracy:0.29 loss: 238.596 (lr:0.0001)
114620: accuracy:0.29 loss: 229.919 (lr:0.0001)
114640: accuracy:0.39 loss: 212.719 (lr:0.0001)
114660: accuracy:0.32 loss: 220.284 (lr:0.0001)
114680: accuracy:0.29 loss: 251.04 (lr:0.0001)
114700: accuracy:0.29 loss: 233.211 (lr:0.0001)
114720: accuracy:0.35 loss: 227.054 (lr:0.0001)
114740: accuracy:0.29 loss: 248.013 (lr:0.0001)
114760: accuracy:0.22 loss: 239.856 (lr:0.0001)
114780: accuracy:0.28 loss: 224.717 (lr:0.0001)
114800: accuracy:0.27 loss: 230.225 (lr:0.0001)
114820: accuracy:0.27 loss: 216.857 (lr:0.0001)
114840: accuracy:0.31 loss: 218.455 (lr:0.0001)
114860: accuracy:0.31 loss: 226.956 (lr:0.0001)
114880: accuracy:0.28 loss: 232.878 (lr:0.0001)
114900: accuracy:0.23 loss: 248.315 (lr:0.0001)
114920: accuracy:0.39 loss: 200.254 (lr:0.0001)
114940: accuracy:0.25 loss: 228.397 (lr:0.0001)
114960: accuracy:0.25 loss: 225.187 (lr:0.0001)
114980: accuracy:0.26 loss: 244.66 (lr:0.0001)
115000: accuracy:0.25 loss: 220.896 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
115000: ********* epoch 12 ********* test accuracy for all:0.231716 test loss: 261.039
115000: ********* epoch 12 ********* test accuracy for mode 0:0.0505 test loss: 404.819
115000: ********* epoch 12 ********* test accuracy for mode 1:0.04 test loss: 423.167
115000: ********* epoch 12 ********* test accuracy for mode 2:0.062 test loss: 281.307
115000: ********* epoch 12 ********* test accuracy for mode 24:0.2425 test loss: 263.359
115000: ********* epoch 12 ********* test accuracy for mode 25:0.2915 test loss: 245.357
115000: ********* epoch 12 ********* test accuracy for mode 26:0.4195 test loss: 173.529
115000: ********* epoch 12 ********* test accuracy for mode 27:0.2765 test loss: 258.158
115000: ********* epoch 12 ********* test accuracy for mode 28:0.2865 test loss: 248.685
115000: ********* epoch 12 ********* test accuracy for mode 29:0.3105 test loss: 258.202
115000: ********* epoch 12 ********* test accuracy for mode 30:0.1645 test loss: 260.227
115000: ********* epoch 12 ********* test accuracy for mode 31:0.1825 test loss: 261.781
115000: ********* epoch 12 ********* test accuracy for mode 32:0.2205 test loss: 250.967
115000: ********* epoch 12 ********* test accuracy for mode 33:0.187 test loss: 258.504
115000: ********* epoch 12 ********* test accuracy for mode 34:0.0275 test loss: 265.539
115000: ********* epoch 12 ********* test accuracy for mode 35:0.143 test loss: 430.836
115000: ********* epoch 12 ********* test accuracy for mode 36:0.379 test loss: 429.483
115020: accuracy:0.26 loss: 233.234 (lr:0.0001)
115040: accuracy:0.24 loss: 278.656 (lr:0.0001)
115060: accuracy:0.22 loss: 243.917 (lr:0.0001)
115080: accuracy:0.19 loss: 263.506 (lr:0.0001)
115100: accuracy:0.28 loss: 227.734 (lr:0.0001)
115120: accuracy:0.26 loss: 229.171 (lr:0.0001)
115140: accuracy:0.24 loss: 230.198 (lr:0.0001)
115160: accuracy:0.33 loss: 208.698 (lr:0.0001)
115180: accuracy:0.23 loss: 225.211 (lr:0.0001)
115200: accuracy:0.21 loss: 235.312 (lr:0.0001)
115220: accuracy:0.31 loss: 223.143 (lr:0.0001)
115240: accuracy:0.29 loss: 215.074 (lr:0.0001)
115260: accuracy:0.29 loss: 245.079 (lr:0.0001)
115280: accuracy:0.33 loss: 240.343 (lr:0.0001)
115300: accuracy:0.23 loss: 238.477 (lr:0.0001)
115320: accuracy:0.2 loss: 252.705 (lr:0.0001)
115340: accuracy:0.33 loss: 216.006 (lr:0.0001)
115360: accuracy:0.27 loss: 237.489 (lr:0.0001)
115380: accuracy:0.24 loss: 245.635 (lr:0.0001)
115400: accuracy:0.17 loss: 256.797 (lr:0.0001)
115420: accuracy:0.24 loss: 248.861 (lr:0.0001)
115440: accuracy:0.27 loss: 219.667 (lr:0.0001)
115460: accuracy:0.27 loss: 227.45 (lr:0.0001)
115480: accuracy:0.25 loss: 232.883 (lr:0.0001)
115500: accuracy:0.3 loss: 223.151 (lr:0.0001)
115520: accuracy:0.29 loss: 241.936 (lr:0.0001)
115540: accuracy:0.23 loss: 237.379 (lr:0.0001)
115560: accuracy:0.23 loss: 256.389 (lr:0.0001)
115580: accuracy:0.26 loss: 211.231 (lr:0.0001)
115600: accuracy:0.21 loss: 245.045 (lr:0.0001)
115620: accuracy:0.23 loss: 227.684 (lr:0.0001)
115640: accuracy:0.23 loss: 251.154 (lr:0.0001)
115660: accuracy:0.2 loss: 235.941 (lr:0.0001)
115680: accuracy:0.21 loss: 262.444 (lr:0.0001)
115700: accuracy:0.24 loss: 246.329 (lr:0.0001)
115720: accuracy:0.29 loss: 230.252 (lr:0.0001)
115740: accuracy:0.28 loss: 234.114 (lr:0.0001)
115760: accuracy:0.21 loss: 240.668 (lr:0.0001)
115780: accuracy:0.27 loss: 238.236 (lr:0.0001)
115800: accuracy:0.24 loss: 241.494 (lr:0.0001)
115820: accuracy:0.24 loss: 229.276 (lr:0.0001)
115840: accuracy:0.25 loss: 238.006 (lr:0.0001)
115860: accuracy:0.25 loss: 227.413 (lr:0.0001)
115880: accuracy:0.22 loss: 255.991 (lr:0.0001)
115900: accuracy:0.22 loss: 242.569 (lr:0.0001)
115920: accuracy:0.3 loss: 229.163 (lr:0.0001)
115940: accuracy:0.24 loss: 239.448 (lr:0.0001)
115960: accuracy:0.29 loss: 232.173 (lr:0.0001)
115980: accuracy:0.31 loss: 229.875 (lr:0.0001)
116000: accuracy:0.26 loss: 232.16 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
116000: ********* epoch 12 ********* test accuracy for all:0.225662 test loss: 264.443
116000: ********* epoch 12 ********* test accuracy for mode 0:0.0535 test loss: 410.014
116000: ********* epoch 12 ********* test accuracy for mode 1:0.026 test loss: 447.861
116000: ********* epoch 12 ********* test accuracy for mode 2:0.0875 test loss: 275.3
116000: ********* epoch 12 ********* test accuracy for mode 24:0.2455 test loss: 264.076
116000: ********* epoch 12 ********* test accuracy for mode 25:0.335 test loss: 244.402
116000: ********* epoch 12 ********* test accuracy for mode 26:0.345 test loss: 184.659
116000: ********* epoch 12 ********* test accuracy for mode 27:0.2415 test loss: 271.464
116000: ********* epoch 12 ********* test accuracy for mode 28:0.2705 test loss: 257.355
116000: ********* epoch 12 ********* test accuracy for mode 29:0.289 test loss: 258.383
116000: ********* epoch 12 ********* test accuracy for mode 30:0.1995 test loss: 250.991
116000: ********* epoch 12 ********* test accuracy for mode 31:0.219 test loss: 249.359
116000: ********* epoch 12 ********* test accuracy for mode 32:0.209 test loss: 241.417
116000: ********* epoch 12 ********* test accuracy for mode 33:0.233 test loss: 246.38
116000: ********* epoch 12 ********* test accuracy for mode 34:0.017 test loss: 260.067
116000: ********* epoch 12 ********* test accuracy for mode 35:0.0925 test loss: 464.241
116000: ********* epoch 12 ********* test accuracy for mode 36:0.1215 test loss: 473.314
116020: accuracy:0.22 loss: 243.252 (lr:0.0001)
116040: accuracy:0.21 loss: 244.956 (lr:0.0001)
116060: accuracy:0.33 loss: 224.273 (lr:0.0001)
116080: accuracy:0.26 loss: 225.588 (lr:0.0001)
116100: accuracy:0.31 loss: 237.091 (lr:0.0001)
116120: accuracy:0.27 loss: 244.756 (lr:0.0001)
116140: accuracy:0.22 loss: 242.874 (lr:0.0001)
116160: accuracy:0.2 loss: 263.94 (lr:0.0001)
116180: accuracy:0.18 loss: 254.163 (lr:0.0001)
116200: accuracy:0.31 loss: 217.737 (lr:0.0001)
116220: accuracy:0.26 loss: 222.956 (lr:0.0001)
116240: accuracy:0.25 loss: 229.357 (lr:0.0001)
116260: accuracy:0.26 loss: 222.725 (lr:0.0001)
116280: accuracy:0.31 loss: 232.575 (lr:0.0001)
116300: accuracy:0.19 loss: 249.671 (lr:0.0001)
116320: accuracy:0.27 loss: 215.185 (lr:0.0001)
116340: accuracy:0.33 loss: 225.299 (lr:0.0001)
116360: accuracy:0.32 loss: 230.751 (lr:0.0001)
116380: accuracy:0.36 loss: 211.738 (lr:0.0001)
116400: accuracy:0.24 loss: 243.661 (lr:0.0001)
116420: accuracy:0.19 loss: 223.74 (lr:0.0001)
116440: accuracy:0.28 loss: 233.02 (lr:0.0001)
116460: accuracy:0.28 loss: 240.995 (lr:0.0001)
116480: accuracy:0.25 loss: 234.033 (lr:0.0001)
116500: accuracy:0.3 loss: 215.505 (lr:0.0001)
116520: accuracy:0.31 loss: 224.153 (lr:0.0001)
116540: accuracy:0.25 loss: 251.82 (lr:0.0001)
116560: accuracy:0.2 loss: 234.568 (lr:0.0001)
116580: accuracy:0.22 loss: 235.05 (lr:0.0001)
116600: accuracy:0.25 loss: 240.513 (lr:0.0001)
116620: accuracy:0.2 loss: 242.067 (lr:0.0001)
116640: accuracy:0.28 loss: 228.738 (lr:0.0001)
116660: accuracy:0.34 loss: 224.453 (lr:0.0001)
116680: accuracy:0.35 loss: 227.251 (lr:0.0001)
116700: accuracy:0.26 loss: 231.515 (lr:0.0001)
116720: accuracy:0.3 loss: 219.469 (lr:0.0001)
116740: accuracy:0.27 loss: 243.255 (lr:0.0001)
116760: accuracy:0.22 loss: 250.671 (lr:0.0001)
116780: accuracy:0.25 loss: 253.792 (lr:0.0001)
116800: accuracy:0.18 loss: 226.269 (lr:0.0001)
116820: accuracy:0.28 loss: 240.804 (lr:0.0001)
116840: accuracy:0.32 loss: 228.677 (lr:0.0001)
116860: accuracy:0.34 loss: 209.929 (lr:0.0001)
116880: accuracy:0.28 loss: 219.683 (lr:0.0001)
116900: accuracy:0.27 loss: 230.25 (lr:0.0001)
116920: accuracy:0.31 loss: 227.072 (lr:0.0001)
116940: accuracy:0.24 loss: 230.349 (lr:0.0001)
116960: accuracy:0.19 loss: 260.461 (lr:0.0001)
116980: accuracy:0.28 loss: 216.284 (lr:0.0001)
117000: accuracy:0.36 loss: 233.926 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
117000: ********* epoch 13 ********* test accuracy for all:0.232365 test loss: 261.352
117000: ********* epoch 13 ********* test accuracy for mode 0:0.0465 test loss: 415.781
117000: ********* epoch 13 ********* test accuracy for mode 1:0.0145 test loss: 450.135
117000: ********* epoch 13 ********* test accuracy for mode 2:0.098 test loss: 273.46
117000: ********* epoch 13 ********* test accuracy for mode 24:0.245 test loss: 259.497
117000: ********* epoch 13 ********* test accuracy for mode 25:0.341 test loss: 236.382
117000: ********* epoch 13 ********* test accuracy for mode 26:0.3055 test loss: 179.386
117000: ********* epoch 13 ********* test accuracy for mode 27:0.302 test loss: 249.085
117000: ********* epoch 13 ********* test accuracy for mode 28:0.284 test loss: 240.934
117000: ********* epoch 13 ********* test accuracy for mode 29:0.2985 test loss: 245.63
117000: ********* epoch 13 ********* test accuracy for mode 30:0.2115 test loss: 242.275
117000: ********* epoch 13 ********* test accuracy for mode 31:0.2 test loss: 244.41
117000: ********* epoch 13 ********* test accuracy for mode 32:0.2475 test loss: 236.256
117000: ********* epoch 13 ********* test accuracy for mode 33:0.199 test loss: 245.363
117000: ********* epoch 13 ********* test accuracy for mode 34:0.0135 test loss: 259.304
117000: ********* epoch 13 ********* test accuracy for mode 35:0.119 test loss: 440.429
117000: ********* epoch 13 ********* test accuracy for mode 36:0.3775 test loss: 433.965
117020: accuracy:0.34 loss: 233.945 (lr:0.0001)
117040: accuracy:0.26 loss: 242.532 (lr:0.0001)
117060: accuracy:0.29 loss: 230.098 (lr:0.0001)
117080: accuracy:0.21 loss: 234.277 (lr:0.0001)
117100: accuracy:0.26 loss: 238.387 (lr:0.0001)
117120: accuracy:0.29 loss: 225.154 (lr:0.0001)
117140: accuracy:0.22 loss: 247.668 (lr:0.0001)
117160: accuracy:0.28 loss: 231.627 (lr:0.0001)
117180: accuracy:0.26 loss: 226.062 (lr:0.0001)
117200: accuracy:0.26 loss: 232.711 (lr:0.0001)
117220: accuracy:0.32 loss: 248.241 (lr:0.0001)
117240: accuracy:0.13 loss: 250.446 (lr:0.0001)
117260: accuracy:0.3 loss: 237.422 (lr:0.0001)
117280: accuracy:0.27 loss: 230.268 (lr:0.0001)
117300: accuracy:0.27 loss: 222.49 (lr:0.0001)
117320: accuracy:0.19 loss: 245.549 (lr:0.0001)
117340: accuracy:0.27 loss: 232.845 (lr:0.0001)
117360: accuracy:0.25 loss: 244.357 (lr:0.0001)
117380: accuracy:0.29 loss: 223.309 (lr:0.0001)
117400: accuracy:0.28 loss: 242.225 (lr:0.0001)
117420: accuracy:0.28 loss: 231.435 (lr:0.0001)
117440: accuracy:0.21 loss: 256.854 (lr:0.0001)
117460: accuracy:0.28 loss: 239.415 (lr:0.0001)
117480: accuracy:0.24 loss: 232.846 (lr:0.0001)
117500: accuracy:0.27 loss: 243.82 (lr:0.0001)
117520: accuracy:0.29 loss: 233.391 (lr:0.0001)
117540: accuracy:0.27 loss: 244.881 (lr:0.0001)
117560: accuracy:0.3 loss: 237.065 (lr:0.0001)
117580: accuracy:0.2 loss: 249.167 (lr:0.0001)
117600: accuracy:0.24 loss: 247.561 (lr:0.0001)
117620: accuracy:0.3 loss: 217.167 (lr:0.0001)
117640: accuracy:0.27 loss: 218.31 (lr:0.0001)
117660: accuracy:0.28 loss: 228.668 (lr:0.0001)
117680: accuracy:0.25 loss: 237.136 (lr:0.0001)
117700: accuracy:0.27 loss: 236.918 (lr:0.0001)
117720: accuracy:0.27 loss: 240.58 (lr:0.0001)
117740: accuracy:0.33 loss: 207.951 (lr:0.0001)
117760: accuracy:0.26 loss: 224.378 (lr:0.0001)
117780: accuracy:0.22 loss: 263.035 (lr:0.0001)
117800: accuracy:0.28 loss: 239.853 (lr:0.0001)
117820: accuracy:0.27 loss: 251.414 (lr:0.0001)
117840: accuracy:0.25 loss: 247.696 (lr:0.0001)
117860: accuracy:0.25 loss: 232.541 (lr:0.0001)
117880: accuracy:0.25 loss: 203.526 (lr:0.0001)
117900: accuracy:0.28 loss: 256.702 (lr:0.0001)
117920: accuracy:0.3 loss: 225.748 (lr:0.0001)
117940: accuracy:0.35 loss: 225.337 (lr:0.0001)
117960: accuracy:0.33 loss: 249.405 (lr:0.0001)
117980: accuracy:0.28 loss: 230.111 (lr:0.0001)
118000: accuracy:0.26 loss: 234.209 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
118000: ********* epoch 13 ********* test accuracy for all:0.232068 test loss: 262.07
118000: ********* epoch 13 ********* test accuracy for mode 0:0.055 test loss: 409.248
118000: ********* epoch 13 ********* test accuracy for mode 1:0.0265 test loss: 440.79
118000: ********* epoch 13 ********* test accuracy for mode 2:0.0865 test loss: 274.808
118000: ********* epoch 13 ********* test accuracy for mode 24:0.2305 test loss: 267.433
118000: ********* epoch 13 ********* test accuracy for mode 25:0.331 test loss: 244.935
118000: ********* epoch 13 ********* test accuracy for mode 26:0.3425 test loss: 180.708
118000: ********* epoch 13 ********* test accuracy for mode 27:0.263 test loss: 267.362
118000: ********* epoch 13 ********* test accuracy for mode 28:0.2815 test loss: 251.996
118000: ********* epoch 13 ********* test accuracy for mode 29:0.2845 test loss: 256.695
118000: ********* epoch 13 ********* test accuracy for mode 30:0.1945 test loss: 250.262
118000: ********* epoch 13 ********* test accuracy for mode 31:0.228 test loss: 247.479
118000: ********* epoch 13 ********* test accuracy for mode 32:0.192 test loss: 242.09
118000: ********* epoch 13 ********* test accuracy for mode 33:0.2365 test loss: 245.728
118000: ********* epoch 13 ********* test accuracy for mode 34:0.024 test loss: 257.637
118000: ********* epoch 13 ********* test accuracy for mode 35:0.115 test loss: 443.907
118000: ********* epoch 13 ********* test accuracy for mode 36:0.3655 test loss: 446.169
118020: accuracy:0.31 loss: 225.141 (lr:0.0001)
118040: accuracy:0.28 loss: 238.849 (lr:0.0001)
118060: accuracy:0.26 loss: 230.135 (lr:0.0001)
118080: accuracy:0.18 loss: 244.935 (lr:0.0001)
118100: accuracy:0.23 loss: 254.094 (lr:0.0001)
118120: accuracy:0.31 loss: 216.672 (lr:0.0001)
118140: accuracy:0.28 loss: 243.286 (lr:0.0001)
118160: accuracy:0.32 loss: 236.377 (lr:0.0001)
118180: accuracy:0.22 loss: 246.341 (lr:0.0001)
118200: accuracy:0.32 loss: 239.349 (lr:0.0001)
118220: accuracy:0.28 loss: 242.646 (lr:0.0001)
118240: accuracy:0.33 loss: 226.621 (lr:0.0001)
118260: accuracy:0.18 loss: 241.465 (lr:0.0001)
118280: accuracy:0.29 loss: 236.97 (lr:0.0001)
118300: accuracy:0.28 loss: 239.084 (lr:0.0001)
118320: accuracy:0.33 loss: 234.757 (lr:0.0001)
118340: accuracy:0.31 loss: 235.408 (lr:0.0001)
118360: accuracy:0.26 loss: 244.543 (lr:0.0001)
118380: accuracy:0.21 loss: 244.829 (lr:0.0001)
118400: accuracy:0.28 loss: 233.107 (lr:0.0001)
118420: accuracy:0.27 loss: 236.38 (lr:0.0001)
118440: accuracy:0.22 loss: 236.975 (lr:0.0001)
118460: accuracy:0.27 loss: 240.759 (lr:0.0001)
118480: accuracy:0.27 loss: 237.606 (lr:0.0001)
118500: accuracy:0.26 loss: 249.403 (lr:0.0001)
118520: accuracy:0.27 loss: 250.13 (lr:0.0001)
118540: accuracy:0.3 loss: 217.363 (lr:0.0001)
118560: accuracy:0.32 loss: 218.647 (lr:0.0001)
118580: accuracy:0.32 loss: 213.416 (lr:0.0001)
118600: accuracy:0.35 loss: 221.908 (lr:0.0001)
118620: accuracy:0.26 loss: 224.946 (lr:0.0001)
118640: accuracy:0.34 loss: 223.395 (lr:0.0001)
118660: accuracy:0.16 loss: 262.712 (lr:0.0001)
118680: accuracy:0.18 loss: 237.788 (lr:0.0001)
118700: accuracy:0.23 loss: 236.263 (lr:0.0001)
118720: accuracy:0.22 loss: 234.13 (lr:0.0001)
118740: accuracy:0.25 loss: 238.309 (lr:0.0001)
118760: accuracy:0.26 loss: 234.065 (lr:0.0001)
118780: accuracy:0.24 loss: 236.209 (lr:0.0001)
118800: accuracy:0.34 loss: 225.792 (lr:0.0001)
118820: accuracy:0.34 loss: 222.17 (lr:0.0001)
118840: accuracy:0.27 loss: 239.415 (lr:0.0001)
118860: accuracy:0.31 loss: 247.478 (lr:0.0001)
118880: accuracy:0.35 loss: 215.64 (lr:0.0001)
118900: accuracy:0.22 loss: 220.012 (lr:0.0001)
118920: accuracy:0.27 loss: 221.74 (lr:0.0001)
118940: accuracy:0.3 loss: 229.078 (lr:0.0001)
118960: accuracy:0.26 loss: 224.424 (lr:0.0001)
118980: accuracy:0.25 loss: 227.4 (lr:0.0001)
119000: accuracy:0.23 loss: 247.844 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
119000: ********* epoch 13 ********* test accuracy for all:0.237041 test loss: 259.644
119000: ********* epoch 13 ********* test accuracy for mode 0:0.0545 test loss: 406.667
119000: ********* epoch 13 ********* test accuracy for mode 1:0.0245 test loss: 436.71
119000: ********* epoch 13 ********* test accuracy for mode 2:0.088 test loss: 279.261
119000: ********* epoch 13 ********* test accuracy for mode 24:0.242 test loss: 259.395
119000: ********* epoch 13 ********* test accuracy for mode 25:0.3375 test loss: 235.083
119000: ********* epoch 13 ********* test accuracy for mode 26:0.327 test loss: 177.266
119000: ********* epoch 13 ********* test accuracy for mode 27:0.2925 test loss: 250.447
119000: ********* epoch 13 ********* test accuracy for mode 28:0.3105 test loss: 238.516
119000: ********* epoch 13 ********* test accuracy for mode 29:0.3155 test loss: 245.409
119000: ********* epoch 13 ********* test accuracy for mode 30:0.1795 test loss: 246.685
119000: ********* epoch 13 ********* test accuracy for mode 31:0.2075 test loss: 246.931
119000: ********* epoch 13 ********* test accuracy for mode 32:0.228 test loss: 240.049
119000: ********* epoch 13 ********* test accuracy for mode 33:0.176 test loss: 251.028
119000: ********* epoch 13 ********* test accuracy for mode 34:0.049 test loss: 257.481
119000: ********* epoch 13 ********* test accuracy for mode 35:0.155 test loss: 425.16
119000: ********* epoch 13 ********* test accuracy for mode 36:0.402 test loss: 422.778
119020: accuracy:0.2 loss: 256.492 (lr:0.0001)
119040: accuracy:0.33 loss: 238.831 (lr:0.0001)
119060: accuracy:0.31 loss: 231.71 (lr:0.0001)
119080: accuracy:0.31 loss: 215.142 (lr:0.0001)
119100: accuracy:0.24 loss: 251.721 (lr:0.0001)
119120: accuracy:0.32 loss: 210.113 (lr:0.0001)
119140: accuracy:0.25 loss: 220.604 (lr:0.0001)
119160: accuracy:0.19 loss: 229.647 (lr:0.0001)
119180: accuracy:0.24 loss: 246.564 (lr:0.0001)
119200: accuracy:0.36 loss: 232.693 (lr:0.0001)
119220: accuracy:0.22 loss: 230.357 (lr:0.0001)
119240: accuracy:0.22 loss: 225.4 (lr:0.0001)
119260: accuracy:0.22 loss: 247.23 (lr:0.0001)
119280: accuracy:0.23 loss: 246.023 (lr:0.0001)
119300: accuracy:0.2 loss: 267.728 (lr:0.0001)
119320: accuracy:0.31 loss: 224.837 (lr:0.0001)
119340: accuracy:0.28 loss: 233.842 (lr:0.0001)
119360: accuracy:0.28 loss: 242.248 (lr:0.0001)
119380: accuracy:0.23 loss: 242.679 (lr:0.0001)
119400: accuracy:0.3 loss: 225.75 (lr:0.0001)
119420: accuracy:0.24 loss: 239.251 (lr:0.0001)
119440: accuracy:0.24 loss: 222.387 (lr:0.0001)
119460: accuracy:0.29 loss: 251.015 (lr:0.0001)
119480: accuracy:0.31 loss: 231.722 (lr:0.0001)
119500: accuracy:0.24 loss: 244.25 (lr:0.0001)
119520: accuracy:0.3 loss: 241.882 (lr:0.0001)
119540: accuracy:0.3 loss: 236.564 (lr:0.0001)
119560: accuracy:0.3 loss: 224.069 (lr:0.0001)
119580: accuracy:0.28 loss: 244.291 (lr:0.0001)
119600: accuracy:0.25 loss: 242.414 (lr:0.0001)
119620: accuracy:0.27 loss: 210.484 (lr:0.0001)
119640: accuracy:0.33 loss: 216.518 (lr:0.0001)
119660: accuracy:0.35 loss: 234.811 (lr:0.0001)
119680: accuracy:0.24 loss: 240.35 (lr:0.0001)
119700: accuracy:0.32 loss: 237.37 (lr:0.0001)
119720: accuracy:0.24 loss: 250.902 (lr:0.0001)
119740: accuracy:0.29 loss: 214.353 (lr:0.0001)
119760: accuracy:0.23 loss: 271.214 (lr:0.0001)
119780: accuracy:0.26 loss: 236.658 (lr:0.0001)
119800: accuracy:0.21 loss: 251.203 (lr:0.0001)
119820: accuracy:0.22 loss: 235.405 (lr:0.0001)
119840: accuracy:0.29 loss: 223.562 (lr:0.0001)
119860: accuracy:0.2 loss: 238.821 (lr:0.0001)
119880: accuracy:0.3 loss: 238.214 (lr:0.0001)
119900: accuracy:0.29 loss: 215.385 (lr:0.0001)
119920: accuracy:0.23 loss: 245.715 (lr:0.0001)
119940: accuracy:0.3 loss: 232.749 (lr:0.0001)
119960: accuracy:0.31 loss: 222.513 (lr:0.0001)
119980: accuracy:0.29 loss: 238.417 (lr:0.0001)
120000: accuracy:0.27 loss: 243.58 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
120000: ********* epoch 13 ********* test accuracy for all:0.234203 test loss: 259.202
120000: ********* epoch 13 ********* test accuracy for mode 0:0.056 test loss: 403.51
120000: ********* epoch 13 ********* test accuracy for mode 1:0.0385 test loss: 419.492
120000: ********* epoch 13 ********* test accuracy for mode 2:0.055 test loss: 284.917
120000: ********* epoch 13 ********* test accuracy for mode 24:0.243 test loss: 258.57
120000: ********* epoch 13 ********* test accuracy for mode 25:0.2965 test loss: 238.651
120000: ********* epoch 13 ********* test accuracy for mode 26:0.4495 test loss: 170.695
120000: ********* epoch 13 ********* test accuracy for mode 27:0.2825 test loss: 251.912
120000: ********* epoch 13 ********* test accuracy for mode 28:0.2975 test loss: 242.334
120000: ********* epoch 13 ********* test accuracy for mode 29:0.276 test loss: 256.907
120000: ********* epoch 13 ********* test accuracy for mode 30:0.1775 test loss: 259.324
120000: ********* epoch 13 ********* test accuracy for mode 31:0.1575 test loss: 264.144
120000: ********* epoch 13 ********* test accuracy for mode 32:0.2455 test loss: 252.6
120000: ********* epoch 13 ********* test accuracy for mode 33:0.1285 test loss: 266.679
120000: ********* epoch 13 ********* test accuracy for mode 34:0.0575 test loss: 265.579
120000: ********* epoch 13 ********* test accuracy for mode 35:0.2225 test loss: 400.907
120000: ********* epoch 13 ********* test accuracy for mode 36:0.4685 test loss: 393.696
120020: accuracy:0.26 loss: 220.954 (lr:0.0001)
120040: accuracy:0.23 loss: 250.252 (lr:0.0001)
120060: accuracy:0.33 loss: 219.183 (lr:0.0001)
120080: accuracy:0.25 loss: 250.477 (lr:0.0001)
120100: accuracy:0.31 loss: 243.643 (lr:0.0001)
120120: accuracy:0.22 loss: 212.609 (lr:0.0001)
120140: accuracy:0.32 loss: 215.348 (lr:0.0001)
120160: accuracy:0.28 loss: 225.391 (lr:0.0001)
120180: accuracy:0.29 loss: 238.166 (lr:0.0001)
120200: accuracy:0.22 loss: 239.834 (lr:0.0001)
120220: accuracy:0.28 loss: 243.574 (lr:0.0001)
120240: accuracy:0.24 loss: 237.777 (lr:0.0001)
120260: accuracy:0.33 loss: 234.263 (lr:0.0001)
120280: accuracy:0.29 loss: 244.176 (lr:0.0001)
120300: accuracy:0.23 loss: 237.404 (lr:0.0001)
120320: accuracy:0.28 loss: 259.147 (lr:0.0001)
120340: accuracy:0.19 loss: 250.424 (lr:0.0001)
120360: accuracy:0.22 loss: 226.319 (lr:0.0001)
120380: accuracy:0.24 loss: 246.786 (lr:0.0001)
120400: accuracy:0.25 loss: 247.19 (lr:0.0001)
120420: accuracy:0.27 loss: 253.665 (lr:0.0001)
120440: accuracy:0.26 loss: 242.755 (lr:0.0001)
120460: accuracy:0.33 loss: 225.564 (lr:0.0001)
120480: accuracy:0.32 loss: 238.509 (lr:0.0001)
120500: accuracy:0.17 loss: 250.405 (lr:0.0001)
120520: accuracy:0.28 loss: 227.464 (lr:0.0001)
120540: accuracy:0.32 loss: 224.792 (lr:0.0001)
120560: accuracy:0.27 loss: 241.171 (lr:0.0001)
120580: accuracy:0.28 loss: 232.246 (lr:0.0001)
120600: accuracy:0.29 loss: 226.438 (lr:0.0001)
120620: accuracy:0.3 loss: 210.585 (lr:0.0001)
120640: accuracy:0.23 loss: 254.885 (lr:0.0001)
120660: accuracy:0.29 loss: 212.48 (lr:0.0001)
120680: accuracy:0.24 loss: 239.533 (lr:0.0001)
120700: accuracy:0.21 loss: 242.88 (lr:0.0001)
120720: accuracy:0.28 loss: 227.48 (lr:0.0001)
120740: accuracy:0.33 loss: 224.412 (lr:0.0001)
120760: accuracy:0.29 loss: 234.879 (lr:0.0001)
120780: accuracy:0.27 loss: 224.357 (lr:0.0001)
120800: accuracy:0.32 loss: 216.212 (lr:0.0001)
120820: accuracy:0.32 loss: 220.616 (lr:0.0001)
120840: accuracy:0.27 loss: 232.602 (lr:0.0001)
120860: accuracy:0.27 loss: 231.797 (lr:0.0001)
120880: accuracy:0.33 loss: 222.921 (lr:0.0001)
120900: accuracy:0.18 loss: 227.467 (lr:0.0001)
120920: accuracy:0.24 loss: 228.209 (lr:0.0001)
120940: accuracy:0.27 loss: 233.522 (lr:0.0001)
120960: accuracy:0.31 loss: 241.779 (lr:0.0001)
120980: accuracy:0.26 loss: 233.055 (lr:0.0001)
121000: accuracy:0.33 loss: 217.682 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
121000: ********* epoch 13 ********* test accuracy for all:0.234649 test loss: 260.738
121000: ********* epoch 13 ********* test accuracy for mode 0:0.051 test loss: 410.547
121000: ********* epoch 13 ********* test accuracy for mode 1:0.018 test loss: 440.525
121000: ********* epoch 13 ********* test accuracy for mode 2:0.0905 test loss: 272.5
121000: ********* epoch 13 ********* test accuracy for mode 24:0.245 test loss: 264.276
121000: ********* epoch 13 ********* test accuracy for mode 25:0.3195 test loss: 241.061
121000: ********* epoch 13 ********* test accuracy for mode 26:0.343 test loss: 177.991
121000: ********* epoch 13 ********* test accuracy for mode 27:0.279 test loss: 256.455
121000: ********* epoch 13 ********* test accuracy for mode 28:0.3005 test loss: 242.727
121000: ********* epoch 13 ********* test accuracy for mode 29:0.2815 test loss: 251.709
121000: ********* epoch 13 ********* test accuracy for mode 30:0.214 test loss: 247.207
121000: ********* epoch 13 ********* test accuracy for mode 31:0.186 test loss: 250.944
121000: ********* epoch 13 ********* test accuracy for mode 32:0.266 test loss: 240.236
121000: ********* epoch 13 ********* test accuracy for mode 33:0.1505 test loss: 253.433
121000: ********* epoch 13 ********* test accuracy for mode 34:0.065 test loss: 256.304
121000: ********* epoch 13 ********* test accuracy for mode 35:0.149 test loss: 427.891
121000: ********* epoch 13 ********* test accuracy for mode 36:0.426 test loss: 420.11
121020: accuracy:0.32 loss: 226.031 (lr:0.0001)
121040: accuracy:0.31 loss: 249.476 (lr:0.0001)
121060: accuracy:0.27 loss: 222.393 (lr:0.0001)
121080: accuracy:0.25 loss: 255.177 (lr:0.0001)
121100: accuracy:0.28 loss: 244.237 (lr:0.0001)
121120: accuracy:0.33 loss: 230.387 (lr:0.0001)
121140: accuracy:0.32 loss: 229.221 (lr:0.0001)
121160: accuracy:0.33 loss: 228.169 (lr:0.0001)
121180: accuracy:0.24 loss: 250.351 (lr:0.0001)
121200: accuracy:0.24 loss: 246.168 (lr:0.0001)
121220: accuracy:0.28 loss: 233.252 (lr:0.0001)
121240: accuracy:0.24 loss: 242.627 (lr:0.0001)
121260: accuracy:0.24 loss: 236.973 (lr:0.0001)
121280: accuracy:0.23 loss: 243.659 (lr:0.0001)
121300: accuracy:0.32 loss: 229.642 (lr:0.0001)
121320: accuracy:0.21 loss: 248.273 (lr:0.0001)
121340: accuracy:0.24 loss: 253.61 (lr:0.0001)
121360: accuracy:0.26 loss: 233.409 (lr:0.0001)
121380: accuracy:0.22 loss: 237.084 (lr:0.0001)
121400: accuracy:0.32 loss: 224.483 (lr:0.0001)
121420: accuracy:0.25 loss: 226.225 (lr:0.0001)
121440: accuracy:0.26 loss: 214.963 (lr:0.0001)
121460: accuracy:0.26 loss: 245.856 (lr:0.0001)
121480: accuracy:0.25 loss: 228.049 (lr:0.0001)
121500: accuracy:0.31 loss: 233.399 (lr:0.0001)
121520: accuracy:0.2 loss: 228.737 (lr:0.0001)
121540: accuracy:0.3 loss: 223.001 (lr:0.0001)
121560: accuracy:0.27 loss: 244.787 (lr:0.0001)
121580: accuracy:0.25 loss: 246.332 (lr:0.0001)
121600: accuracy:0.3 loss: 217.131 (lr:0.0001)
121620: accuracy:0.28 loss: 242.646 (lr:0.0001)
121640: accuracy:0.2 loss: 237.054 (lr:0.0001)
121660: accuracy:0.25 loss: 219.38 (lr:0.0001)
121680: accuracy:0.3 loss: 239.111 (lr:0.0001)
121700: accuracy:0.28 loss: 236.72 (lr:0.0001)
121720: accuracy:0.19 loss: 229.81 (lr:0.0001)
121740: accuracy:0.3 loss: 229.888 (lr:0.0001)
121760: accuracy:0.26 loss: 241.84 (lr:0.0001)
121780: accuracy:0.24 loss: 229.743 (lr:0.0001)
121800: accuracy:0.31 loss: 210.095 (lr:0.0001)
121820: accuracy:0.29 loss: 241.02 (lr:0.0001)
121840: accuracy:0.29 loss: 233.035 (lr:0.0001)
121860: accuracy:0.32 loss: 233.472 (lr:0.0001)
121880: accuracy:0.3 loss: 226.334 (lr:0.0001)
121900: accuracy:0.33 loss: 234.481 (lr:0.0001)
121920: accuracy:0.33 loss: 218.836 (lr:0.0001)
121940: accuracy:0.28 loss: 223.311 (lr:0.0001)
121960: accuracy:0.37 loss: 221.833 (lr:0.0001)
121980: accuracy:0.24 loss: 230.86 (lr:0.0001)
122000: accuracy:0.23 loss: 243.678 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
122000: ********* epoch 13 ********* test accuracy for all:0.238865 test loss: 258.546
122000: ********* epoch 13 ********* test accuracy for mode 0:0.061 test loss: 401.467
122000: ********* epoch 13 ********* test accuracy for mode 1:0.038 test loss: 424.275
122000: ********* epoch 13 ********* test accuracy for mode 2:0.062 test loss: 278.628
122000: ********* epoch 13 ********* test accuracy for mode 24:0.2665 test loss: 254.936
122000: ********* epoch 13 ********* test accuracy for mode 25:0.306 test loss: 241.182
122000: ********* epoch 13 ********* test accuracy for mode 26:0.4035 test loss: 173.442
122000: ********* epoch 13 ********* test accuracy for mode 27:0.2795 test loss: 255.813
122000: ********* epoch 13 ********* test accuracy for mode 28:0.3025 test loss: 242.254
122000: ********* epoch 13 ********* test accuracy for mode 29:0.278 test loss: 255.275
122000: ********* epoch 13 ********* test accuracy for mode 30:0.16 test loss: 258.275
122000: ********* epoch 13 ********* test accuracy for mode 31:0.223 test loss: 253.673
122000: ********* epoch 13 ********* test accuracy for mode 32:0.2225 test loss: 248.573
122000: ********* epoch 13 ********* test accuracy for mode 33:0.147 test loss: 259.324
122000: ********* epoch 13 ********* test accuracy for mode 34:0.086 test loss: 257.845
122000: ********* epoch 13 ********* test accuracy for mode 35:0.1695 test loss: 399.379
122000: ********* epoch 13 ********* test accuracy for mode 36:0.473 test loss: 378.652
122020: accuracy:0.23 loss: 240.479 (lr:0.0001)
122040: accuracy:0.29 loss: 239.133 (lr:0.0001)
122060: accuracy:0.27 loss: 238.931 (lr:0.0001)
122080: accuracy:0.28 loss: 216.834 (lr:0.0001)
122100: accuracy:0.31 loss: 227.985 (lr:0.0001)
122120: accuracy:0.23 loss: 235.381 (lr:0.0001)
122140: accuracy:0.28 loss: 230.881 (lr:0.0001)
122160: accuracy:0.28 loss: 226.247 (lr:0.0001)
122180: accuracy:0.32 loss: 226.04 (lr:0.0001)
122200: accuracy:0.3 loss: 219.877 (lr:0.0001)
122220: accuracy:0.34 loss: 217.194 (lr:0.0001)
122240: accuracy:0.27 loss: 232.945 (lr:0.0001)
122260: accuracy:0.31 loss: 236.908 (lr:0.0001)
122280: accuracy:0.22 loss: 239.257 (lr:0.0001)
122300: accuracy:0.27 loss: 231.475 (lr:0.0001)
122320: accuracy:0.32 loss: 207.282 (lr:0.0001)
122340: accuracy:0.29 loss: 240.518 (lr:0.0001)
122360: accuracy:0.33 loss: 227.923 (lr:0.0001)
122380: accuracy:0.26 loss: 247.657 (lr:0.0001)
122400: accuracy:0.32 loss: 226.936 (lr:0.0001)
122420: accuracy:0.29 loss: 228.46 (lr:0.0001)
122440: accuracy:0.31 loss: 229.158 (lr:0.0001)
122460: accuracy:0.25 loss: 260.373 (lr:0.0001)
122480: accuracy:0.29 loss: 240.812 (lr:0.0001)
122500: accuracy:0.3 loss: 221.734 (lr:0.0001)
122520: accuracy:0.31 loss: 239.883 (lr:0.0001)
122540: accuracy:0.34 loss: 228.949 (lr:0.0001)
122560: accuracy:0.3 loss: 231.169 (lr:0.0001)
122580: accuracy:0.3 loss: 234.69 (lr:0.0001)
122600: accuracy:0.28 loss: 220.909 (lr:0.0001)
122620: accuracy:0.18 loss: 245.194 (lr:0.0001)
122640: accuracy:0.29 loss: 229.502 (lr:0.0001)
122660: accuracy:0.32 loss: 218.048 (lr:0.0001)
122680: accuracy:0.27 loss: 241.517 (lr:0.0001)
122700: accuracy:0.27 loss: 231.7 (lr:0.0001)
122720: accuracy:0.33 loss: 211.327 (lr:0.0001)
122740: accuracy:0.24 loss: 231.561 (lr:0.0001)
122760: accuracy:0.28 loss: 227.655 (lr:0.0001)
122780: accuracy:0.27 loss: 245.784 (lr:0.0001)
122800: accuracy:0.24 loss: 237.758 (lr:0.0001)
122820: accuracy:0.3 loss: 234.337 (lr:0.0001)
122840: accuracy:0.31 loss: 237.048 (lr:0.0001)
122860: accuracy:0.26 loss: 234.796 (lr:0.0001)
122880: accuracy:0.3 loss: 227.336 (lr:0.0001)
122900: accuracy:0.28 loss: 228.086 (lr:0.0001)
122920: accuracy:0.34 loss: 223.757 (lr:0.0001)
122940: accuracy:0.26 loss: 235.086 (lr:0.0001)
122960: accuracy:0.35 loss: 221.376 (lr:0.0001)
122980: accuracy:0.27 loss: 228.726 (lr:0.0001)
123000: accuracy:0.25 loss: 236.834 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
123000: ********* epoch 13 ********* test accuracy for all:0.226716 test loss: 263.176
123000: ********* epoch 13 ********* test accuracy for mode 0:0.0505 test loss: 417.896
123000: ********* epoch 13 ********* test accuracy for mode 1:0.018 test loss: 455.753
123000: ********* epoch 13 ********* test accuracy for mode 2:0.08 test loss: 273.279
123000: ********* epoch 13 ********* test accuracy for mode 24:0.243 test loss: 269.941
123000: ********* epoch 13 ********* test accuracy for mode 25:0.3555 test loss: 242.969
123000: ********* epoch 13 ********* test accuracy for mode 26:0.198 test loss: 187.089
123000: ********* epoch 13 ********* test accuracy for mode 27:0.304 test loss: 255.873
123000: ********* epoch 13 ********* test accuracy for mode 28:0.2895 test loss: 243.785
123000: ********* epoch 13 ********* test accuracy for mode 29:0.2865 test loss: 247.212
123000: ********* epoch 13 ********* test accuracy for mode 30:0.2105 test loss: 241.407
123000: ********* epoch 13 ********* test accuracy for mode 31:0.2225 test loss: 242.256
123000: ********* epoch 13 ********* test accuracy for mode 32:0.254 test loss: 231.945
123000: ********* epoch 13 ********* test accuracy for mode 33:0.239 test loss: 240.181
123000: ********* epoch 13 ********* test accuracy for mode 34:0.043 test loss: 251.908
123000: ********* epoch 13 ********* test accuracy for mode 35:0.1085 test loss: 459.853
123000: ********* epoch 13 ********* test accuracy for mode 36:0.1875 test loss: 469.663
123020: accuracy:0.29 loss: 237.969 (lr:0.0001)
123040: accuracy:0.29 loss: 203.832 (lr:0.0001)
123060: accuracy:0.29 loss: 217.209 (lr:0.0001)
123080: accuracy:0.28 loss: 228.413 (lr:0.0001)
123100: accuracy:0.27 loss: 211.911 (lr:0.0001)
123120: accuracy:0.32 loss: 221.949 (lr:0.0001)
123140: accuracy:0.28 loss: 230.289 (lr:0.0001)
123160: accuracy:0.29 loss: 248.744 (lr:0.0001)
123180: accuracy:0.37 loss: 208.423 (lr:0.0001)
123200: accuracy:0.36 loss: 218.015 (lr:0.0001)
123220: accuracy:0.25 loss: 219.437 (lr:0.0001)
123240: accuracy:0.27 loss: 243.238 (lr:0.0001)
123260: accuracy:0.33 loss: 213.103 (lr:0.0001)
123280: accuracy:0.28 loss: 229.398 (lr:0.0001)
123300: accuracy:0.27 loss: 230.93 (lr:0.0001)
123320: accuracy:0.26 loss: 243.988 (lr:0.0001)
123340: accuracy:0.31 loss: 225.854 (lr:0.0001)
123360: accuracy:0.23 loss: 241.69 (lr:0.0001)
123380: accuracy:0.23 loss: 250.729 (lr:0.0001)
123400: accuracy:0.38 loss: 218.667 (lr:0.0001)
123420: accuracy:0.25 loss: 225.766 (lr:0.0001)
123440: accuracy:0.3 loss: 214.88 (lr:0.0001)
123460: accuracy:0.26 loss: 236.357 (lr:0.0001)
123480: accuracy:0.29 loss: 233.48 (lr:0.0001)
123500: accuracy:0.18 loss: 241.71 (lr:0.0001)
123520: accuracy:0.31 loss: 225.9 (lr:0.0001)
123540: accuracy:0.31 loss: 216.748 (lr:0.0001)
123560: accuracy:0.29 loss: 240.628 (lr:0.0001)
123580: accuracy:0.32 loss: 238.58 (lr:0.0001)
123600: accuracy:0.32 loss: 221.339 (lr:0.0001)
123620: accuracy:0.2 loss: 236.464 (lr:0.0001)
123640: accuracy:0.3 loss: 220.865 (lr:0.0001)
123660: accuracy:0.21 loss: 253.434 (lr:0.0001)
123680: accuracy:0.29 loss: 236.589 (lr:0.0001)
123700: accuracy:0.37 loss: 214.103 (lr:0.0001)
123720: accuracy:0.27 loss: 225.87 (lr:0.0001)
123740: accuracy:0.21 loss: 255.326 (lr:0.0001)
123760: accuracy:0.22 loss: 223.735 (lr:0.0001)
123780: accuracy:0.24 loss: 250.723 (lr:0.0001)
123800: accuracy:0.29 loss: 217.949 (lr:0.0001)
123820: accuracy:0.3 loss: 226.193 (lr:0.0001)
123840: accuracy:0.37 loss: 223.361 (lr:0.0001)
123860: accuracy:0.25 loss: 240.443 (lr:0.0001)
123880: accuracy:0.31 loss: 225.033 (lr:0.0001)
123900: accuracy:0.25 loss: 239.62 (lr:0.0001)
123920: accuracy:0.15 loss: 249.08 (lr:0.0001)
123940: accuracy:0.34 loss: 200.986 (lr:0.0001)
123960: accuracy:0.22 loss: 226.723 (lr:0.0001)
123980: accuracy:0.28 loss: 223.278 (lr:0.0001)
124000: accuracy:0.26 loss: 224.079 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
124000: ********* epoch 13 ********* test accuracy for all:0.234689 test loss: 259.951
124000: ********* epoch 13 ********* test accuracy for mode 0:0.06 test loss: 408.483
124000: ********* epoch 13 ********* test accuracy for mode 1:0.0285 test loss: 441.225
124000: ********* epoch 13 ********* test accuracy for mode 2:0.105 test loss: 275.834
124000: ********* epoch 13 ********* test accuracy for mode 24:0.262 test loss: 257.798
124000: ********* epoch 13 ********* test accuracy for mode 25:0.34 test loss: 238.646
124000: ********* epoch 13 ********* test accuracy for mode 26:0.304 test loss: 180.02
124000: ********* epoch 13 ********* test accuracy for mode 27:0.294 test loss: 257.863
124000: ********* epoch 13 ********* test accuracy for mode 28:0.29 test loss: 249.092
124000: ********* epoch 13 ********* test accuracy for mode 29:0.265 test loss: 255.675
124000: ********* epoch 13 ********* test accuracy for mode 30:0.219 test loss: 247.865
124000: ********* epoch 13 ********* test accuracy for mode 31:0.184 test loss: 250.957
124000: ********* epoch 13 ********* test accuracy for mode 32:0.2595 test loss: 240.194
124000: ********* epoch 13 ********* test accuracy for mode 33:0.202 test loss: 251.033
124000: ********* epoch 13 ********* test accuracy for mode 34:0.036 test loss: 259.29
124000: ********* epoch 13 ********* test accuracy for mode 35:0.1105 test loss: 447.531
124000: ********* epoch 13 ********* test accuracy for mode 36:0.322 test loss: 438.984
124020: accuracy:0.27 loss: 226.914 (lr:0.0001)
124040: accuracy:0.23 loss: 240.139 (lr:0.0001)
124060: accuracy:0.31 loss: 226.454 (lr:0.0001)
124080: accuracy:0.31 loss: 221.899 (lr:0.0001)
124100: accuracy:0.23 loss: 246.88 (lr:0.0001)
124120: accuracy:0.25 loss: 226.019 (lr:0.0001)
124140: accuracy:0.22 loss: 230.916 (lr:0.0001)
124160: accuracy:0.23 loss: 234.461 (lr:0.0001)
124180: accuracy:0.31 loss: 235.317 (lr:0.0001)
124200: accuracy:0.22 loss: 229.466 (lr:0.0001)
124220: accuracy:0.28 loss: 231.745 (lr:0.0001)
124240: accuracy:0.23 loss: 234.867 (lr:0.0001)
124260: accuracy:0.21 loss: 235.279 (lr:0.0001)
124280: accuracy:0.31 loss: 221.233 (lr:0.0001)
124300: accuracy:0.25 loss: 248.898 (lr:0.0001)
124320: accuracy:0.31 loss: 222.985 (lr:0.0001)
124340: accuracy:0.26 loss: 229.329 (lr:0.0001)
124360: accuracy:0.26 loss: 233.126 (lr:0.0001)
124380: accuracy:0.29 loss: 251.897 (lr:0.0001)
124400: accuracy:0.29 loss: 220.491 (lr:0.0001)
124420: accuracy:0.25 loss: 244.82 (lr:0.0001)
124440: accuracy:0.29 loss: 202.779 (lr:0.0001)
124460: accuracy:0.23 loss: 241.44 (lr:0.0001)
124480: accuracy:0.15 loss: 274.118 (lr:0.0001)
124500: accuracy:0.26 loss: 237.578 (lr:0.0001)
124520: accuracy:0.33 loss: 218.94 (lr:0.0001)
124540: accuracy:0.19 loss: 244.401 (lr:0.0001)
124560: accuracy:0.26 loss: 239.021 (lr:0.0001)
124580: accuracy:0.3 loss: 233.358 (lr:0.0001)
124600: accuracy:0.25 loss: 232.295 (lr:0.0001)
124620: accuracy:0.31 loss: 216.547 (lr:0.0001)
124640: accuracy:0.25 loss: 234.364 (lr:0.0001)
124660: accuracy:0.27 loss: 232.012 (lr:0.0001)
124680: accuracy:0.28 loss: 238.911 (lr:0.0001)
124700: accuracy:0.26 loss: 238.193 (lr:0.0001)
124720: accuracy:0.28 loss: 250.607 (lr:0.0001)
124740: accuracy:0.28 loss: 227.794 (lr:0.0001)
124760: accuracy:0.24 loss: 254.972 (lr:0.0001)
124780: accuracy:0.25 loss: 242.991 (lr:0.0001)
124800: accuracy:0.26 loss: 217.452 (lr:0.0001)
124820: accuracy:0.23 loss: 259.668 (lr:0.0001)
124840: accuracy:0.27 loss: 230.615 (lr:0.0001)
124860: accuracy:0.36 loss: 215.323 (lr:0.0001)
124880: accuracy:0.32 loss: 247.299 (lr:0.0001)
124900: accuracy:0.2 loss: 247.162 (lr:0.0001)
124920: accuracy:0.23 loss: 242.503 (lr:0.0001)
124940: accuracy:0.23 loss: 230.995 (lr:0.0001)
124960: accuracy:0.22 loss: 226.184 (lr:0.0001)
124980: accuracy:0.23 loss: 234.755 (lr:0.0001)
125000: accuracy:0.21 loss: 246.913 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
125000: ********* epoch 13 ********* test accuracy for all:0.235689 test loss: 261.367
125000: ********* epoch 13 ********* test accuracy for mode 0:0.05 test loss: 414.732
125000: ********* epoch 13 ********* test accuracy for mode 1:0.018 test loss: 450.476
125000: ********* epoch 13 ********* test accuracy for mode 2:0.081 test loss: 275.112
125000: ********* epoch 13 ********* test accuracy for mode 24:0.249 test loss: 259.847
125000: ********* epoch 13 ********* test accuracy for mode 25:0.3245 test loss: 234.716
125000: ********* epoch 13 ********* test accuracy for mode 26:0.3245 test loss: 177.417
125000: ********* epoch 13 ********* test accuracy for mode 27:0.296 test loss: 250.584
125000: ********* epoch 13 ********* test accuracy for mode 28:0.303 test loss: 240.712
125000: ********* epoch 13 ********* test accuracy for mode 29:0.266 test loss: 250.552
125000: ********* epoch 13 ********* test accuracy for mode 30:0.237 test loss: 241.592
125000: ********* epoch 13 ********* test accuracy for mode 31:0.1895 test loss: 246.331
125000: ********* epoch 13 ********* test accuracy for mode 32:0.2705 test loss: 235.644
125000: ********* epoch 13 ********* test accuracy for mode 33:0.209 test loss: 245.64
125000: ********* epoch 13 ********* test accuracy for mode 34:0.023 test loss: 257.692
125000: ********* epoch 13 ********* test accuracy for mode 35:0.141 test loss: 440.272
125000: ********* epoch 13 ********* test accuracy for mode 36:0.3865 test loss: 430.35
125020: accuracy:0.36 loss: 220.179 (lr:0.0001)
125040: accuracy:0.29 loss: 229.172 (lr:0.0001)
125060: accuracy:0.26 loss: 228.725 (lr:0.0001)
125080: accuracy:0.31 loss: 231.903 (lr:0.0001)
125100: accuracy:0.19 loss: 231.014 (lr:0.0001)
125120: accuracy:0.23 loss: 233.924 (lr:0.0001)
125140: accuracy:0.39 loss: 212.023 (lr:0.0001)
125160: accuracy:0.28 loss: 230.199 (lr:0.0001)
125180: accuracy:0.2 loss: 256.555 (lr:0.0001)
125200: accuracy:0.27 loss: 231.551 (lr:0.0001)
125220: accuracy:0.32 loss: 227.301 (lr:0.0001)
125240: accuracy:0.22 loss: 247.595 (lr:0.0001)
125260: accuracy:0.28 loss: 225.872 (lr:0.0001)
125280: accuracy:0.17 loss: 241.349 (lr:0.0001)
125300: accuracy:0.3 loss: 229.931 (lr:0.0001)
125320: accuracy:0.28 loss: 222.477 (lr:0.0001)
125340: accuracy:0.3 loss: 237.789 (lr:0.0001)
125360: accuracy:0.31 loss: 243.267 (lr:0.0001)
125380: accuracy:0.33 loss: 228.497 (lr:0.0001)
125400: accuracy:0.24 loss: 234.334 (lr:0.0001)
125420: accuracy:0.27 loss: 243.017 (lr:0.0001)
125440: accuracy:0.34 loss: 244.209 (lr:0.0001)
125460: accuracy:0.31 loss: 222.8 (lr:0.0001)
125480: accuracy:0.33 loss: 221.456 (lr:0.0001)
125500: accuracy:0.31 loss: 217.871 (lr:0.0001)
125520: accuracy:0.32 loss: 236.557 (lr:0.0001)
125540: accuracy:0.32 loss: 209.059 (lr:0.0001)
125560: accuracy:0.16 loss: 248.711 (lr:0.0001)
125580: accuracy:0.24 loss: 248.281 (lr:0.0001)
125600: accuracy:0.34 loss: 207.647 (lr:0.0001)
125620: accuracy:0.28 loss: 236.12 (lr:0.0001)
125640: accuracy:0.22 loss: 251.872 (lr:0.0001)
125660: accuracy:0.36 loss: 225.412 (lr:0.0001)
125680: accuracy:0.27 loss: 218.95 (lr:0.0001)
125700: accuracy:0.37 loss: 213.771 (lr:0.0001)
125720: accuracy:0.2 loss: 233.905 (lr:0.0001)
125740: accuracy:0.33 loss: 222.52 (lr:0.0001)
125760: accuracy:0.26 loss: 262.978 (lr:0.0001)
125780: accuracy:0.29 loss: 229.573 (lr:0.0001)
125800: accuracy:0.27 loss: 234.661 (lr:0.0001)
125820: accuracy:0.23 loss: 221.199 (lr:0.0001)
125840: accuracy:0.27 loss: 244.42 (lr:0.0001)
125860: accuracy:0.3 loss: 211.984 (lr:0.0001)
125880: accuracy:0.25 loss: 255.768 (lr:0.0001)
125900: accuracy:0.27 loss: 240.256 (lr:0.0001)
125920: accuracy:0.31 loss: 239.097 (lr:0.0001)
125940: accuracy:0.24 loss: 212.043 (lr:0.0001)
125960: accuracy:0.24 loss: 243.783 (lr:0.0001)
125980: accuracy:0.22 loss: 236.052 (lr:0.0001)
126000: accuracy:0.29 loss: 234.544 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
126000: ********* epoch 13 ********* test accuracy for all:0.222189 test loss: 268.528
126000: ********* epoch 13 ********* test accuracy for mode 0:0.0475 test loss: 426.668
126000: ********* epoch 13 ********* test accuracy for mode 1:0.021 test loss: 470.241
126000: ********* epoch 13 ********* test accuracy for mode 2:0.085 test loss: 272.394
126000: ********* epoch 13 ********* test accuracy for mode 24:0.2395 test loss: 268.074
126000: ********* epoch 13 ********* test accuracy for mode 25:0.3715 test loss: 245.583
126000: ********* epoch 13 ********* test accuracy for mode 26:0.222 test loss: 193.478
126000: ********* epoch 13 ********* test accuracy for mode 27:0.2775 test loss: 274.757
126000: ********* epoch 13 ********* test accuracy for mode 28:0.267 test loss: 261.559
126000: ********* epoch 13 ********* test accuracy for mode 29:0.267 test loss: 264.069
126000: ********* epoch 13 ********* test accuracy for mode 30:0.21 test loss: 249.432
126000: ********* epoch 13 ********* test accuracy for mode 31:0.2015 test loss: 245.082
126000: ********* epoch 13 ********* test accuracy for mode 32:0.28 test loss: 232.256
126000: ********* epoch 13 ********* test accuracy for mode 33:0.2 test loss: 244.453
126000: ********* epoch 13 ********* test accuracy for mode 34:0.033 test loss: 254.829
126000: ********* epoch 13 ********* test accuracy for mode 35:0.078 test loss: 498.581
126000: ********* epoch 13 ********* test accuracy for mode 36:0.0435 test loss: 524.232
126020: accuracy:0.27 loss: 232.04 (lr:0.0001)
126040: accuracy:0.28 loss: 251.801 (lr:0.0001)
126060: accuracy:0.29 loss: 244.743 (lr:0.0001)
126080: accuracy:0.29 loss: 229.569 (lr:0.0001)
126100: accuracy:0.27 loss: 251.654 (lr:0.0001)
126120: accuracy:0.26 loss: 227.484 (lr:0.0001)
126140: accuracy:0.36 loss: 210.076 (lr:0.0001)
126160: accuracy:0.33 loss: 218.842 (lr:0.0001)
126180: accuracy:0.3 loss: 218.521 (lr:0.0001)
126200: accuracy:0.23 loss: 236.457 (lr:0.0001)
126220: accuracy:0.24 loss: 223.0 (lr:0.0001)
126240: accuracy:0.25 loss: 237.109 (lr:0.0001)
126260: accuracy:0.27 loss: 247.197 (lr:0.0001)
126280: accuracy:0.26 loss: 244.318 (lr:0.0001)
126300: accuracy:0.33 loss: 210.987 (lr:0.0001)
126320: accuracy:0.24 loss: 250.976 (lr:0.0001)
126340: accuracy:0.32 loss: 227.8 (lr:0.0001)
126360: accuracy:0.34 loss: 220.693 (lr:0.0001)
126380: accuracy:0.28 loss: 211.499 (lr:0.0001)
126400: accuracy:0.27 loss: 233.818 (lr:0.0001)
126420: accuracy:0.25 loss: 214.569 (lr:0.0001)
126440: accuracy:0.3 loss: 222.865 (lr:0.0001)
126460: accuracy:0.21 loss: 235.027 (lr:0.0001)
126480: accuracy:0.28 loss: 246.163 (lr:0.0001)
126500: accuracy:0.33 loss: 266.289 (lr:0.0001)
126520: accuracy:0.28 loss: 230.063 (lr:0.0001)
126540: accuracy:0.28 loss: 234.211 (lr:0.0001)
126560: accuracy:0.26 loss: 231.8 (lr:0.0001)
126580: accuracy:0.31 loss: 220.298 (lr:0.0001)
126600: accuracy:0.28 loss: 243.729 (lr:0.0001)
126620: accuracy:0.27 loss: 233.78 (lr:0.0001)
126640: accuracy:0.27 loss: 260.646 (lr:0.0001)
126660: accuracy:0.3 loss: 222.552 (lr:0.0001)
126680: accuracy:0.22 loss: 247.522 (lr:0.0001)
126700: accuracy:0.23 loss: 235.24 (lr:0.0001)
126720: accuracy:0.33 loss: 224.39 (lr:0.0001)
126740: accuracy:0.18 loss: 235.625 (lr:0.0001)
126760: accuracy:0.3 loss: 213.241 (lr:0.0001)
126780: accuracy:0.22 loss: 210.46 (lr:0.0001)
126800: accuracy:0.23 loss: 253.842 (lr:0.0001)
126820: accuracy:0.2 loss: 237.645 (lr:0.0001)
126840: accuracy:0.38 loss: 213.901 (lr:0.0001)
126860: accuracy:0.29 loss: 235.935 (lr:0.0001)
126880: accuracy:0.26 loss: 242.688 (lr:0.0001)
126900: accuracy:0.29 loss: 210.237 (lr:0.0001)
126920: accuracy:0.29 loss: 212.021 (lr:0.0001)
126940: accuracy:0.3 loss: 232.731 (lr:0.0001)
126960: accuracy:0.24 loss: 233.587 (lr:0.0001)
126980: accuracy:0.29 loss: 248.861 (lr:0.0001)
127000: accuracy:0.25 loss: 234.226 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
127000: ********* epoch 14 ********* test accuracy for all:0.240365 test loss: 257.982
127000: ********* epoch 14 ********* test accuracy for mode 0:0.056 test loss: 405.857
127000: ********* epoch 14 ********* test accuracy for mode 1:0.0345 test loss: 428.081
127000: ********* epoch 14 ********* test accuracy for mode 2:0.097 test loss: 276.45
127000: ********* epoch 14 ********* test accuracy for mode 24:0.2465 test loss: 259.228
127000: ********* epoch 14 ********* test accuracy for mode 25:0.33 test loss: 237.868
127000: ********* epoch 14 ********* test accuracy for mode 26:0.3575 test loss: 175.818
127000: ********* epoch 14 ********* test accuracy for mode 27:0.2895 test loss: 252.147
127000: ********* epoch 14 ********* test accuracy for mode 28:0.315 test loss: 238.156
127000: ********* epoch 14 ********* test accuracy for mode 29:0.271 test loss: 249.851
127000: ********* epoch 14 ********* test accuracy for mode 30:0.2415 test loss: 243.822
127000: ********* epoch 14 ********* test accuracy for mode 31:0.169 test loss: 252.303
127000: ********* epoch 14 ********* test accuracy for mode 32:0.242 test loss: 243.529
127000: ********* epoch 14 ********* test accuracy for mode 33:0.181 test loss: 254.224
127000: ********* epoch 14 ********* test accuracy for mode 34:0.0425 test loss: 260.132
127000: ********* epoch 14 ********* test accuracy for mode 35:0.176 test loss: 421.761
127000: ********* epoch 14 ********* test accuracy for mode 36:0.432 test loss: 416.055
127020: accuracy:0.29 loss: 214.429 (lr:0.0001)
127040: accuracy:0.25 loss: 249.75 (lr:0.0001)
127060: accuracy:0.3 loss: 219.915 (lr:0.0001)
127080: accuracy:0.29 loss: 218.1 (lr:0.0001)
127100: accuracy:0.2 loss: 247.528 (lr:0.0001)
127120: accuracy:0.29 loss: 219.775 (lr:0.0001)
127140: accuracy:0.31 loss: 229.99 (lr:0.0001)
127160: accuracy:0.28 loss: 221.195 (lr:0.0001)
127180: accuracy:0.27 loss: 236.718 (lr:0.0001)
127200: accuracy:0.26 loss: 256.74 (lr:0.0001)
127220: accuracy:0.35 loss: 209.908 (lr:0.0001)
127240: accuracy:0.25 loss: 217.018 (lr:0.0001)
127260: accuracy:0.26 loss: 221.763 (lr:0.0001)
127280: accuracy:0.24 loss: 244.186 (lr:0.0001)
127300: accuracy:0.28 loss: 231.031 (lr:0.0001)
127320: accuracy:0.27 loss: 238.453 (lr:0.0001)
127340: accuracy:0.26 loss: 223.323 (lr:0.0001)
127360: accuracy:0.24 loss: 225.373 (lr:0.0001)
127380: accuracy:0.22 loss: 226.478 (lr:0.0001)
127400: accuracy:0.34 loss: 218.149 (lr:0.0001)
127420: accuracy:0.27 loss: 233.449 (lr:0.0001)
127440: accuracy:0.26 loss: 233.123 (lr:0.0001)
127460: accuracy:0.2 loss: 267.043 (lr:0.0001)
127480: accuracy:0.3 loss: 210.016 (lr:0.0001)
127500: accuracy:0.33 loss: 224.577 (lr:0.0001)
127520: accuracy:0.24 loss: 238.107 (lr:0.0001)
127540: accuracy:0.23 loss: 240.774 (lr:0.0001)
127560: accuracy:0.33 loss: 212.333 (lr:0.0001)
127580: accuracy:0.27 loss: 222.95 (lr:0.0001)
127600: accuracy:0.26 loss: 226.224 (lr:0.0001)
127620: accuracy:0.21 loss: 241.288 (lr:0.0001)
127640: accuracy:0.27 loss: 240.273 (lr:0.0001)
127660: accuracy:0.31 loss: 235.719 (lr:0.0001)
127680: accuracy:0.26 loss: 230.549 (lr:0.0001)
127700: accuracy:0.22 loss: 220.26 (lr:0.0001)
127720: accuracy:0.19 loss: 226.969 (lr:0.0001)
127740: accuracy:0.29 loss: 221.848 (lr:0.0001)
127760: accuracy:0.27 loss: 219.085 (lr:0.0001)
127780: accuracy:0.32 loss: 236.751 (lr:0.0001)
127800: accuracy:0.34 loss: 217.645 (lr:0.0001)
127820: accuracy:0.31 loss: 239.835 (lr:0.0001)
127840: accuracy:0.4 loss: 214.4 (lr:0.0001)
127860: accuracy:0.24 loss: 243.462 (lr:0.0001)
127880: accuracy:0.31 loss: 236.67 (lr:0.0001)
127900: accuracy:0.25 loss: 231.527 (lr:0.0001)
127920: accuracy:0.19 loss: 244.492 (lr:0.0001)
127940: accuracy:0.37 loss: 214.665 (lr:0.0001)
127960: accuracy:0.29 loss: 230.209 (lr:0.0001)
127980: accuracy:0.33 loss: 237.76 (lr:0.0001)
128000: accuracy:0.3 loss: 243.616 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
128000: ********* epoch 14 ********* test accuracy for all:0.237176 test loss: 259.082
128000: ********* epoch 14 ********* test accuracy for mode 0:0.0535 test loss: 412.384
128000: ********* epoch 14 ********* test accuracy for mode 1:0.0175 test loss: 447.316
128000: ********* epoch 14 ********* test accuracy for mode 2:0.086 test loss: 274.768
128000: ********* epoch 14 ********* test accuracy for mode 24:0.2375 test loss: 258.244
128000: ********* epoch 14 ********* test accuracy for mode 25:0.3615 test loss: 229.704
128000: ********* epoch 14 ********* test accuracy for mode 26:0.263 test loss: 180.171
128000: ********* epoch 14 ********* test accuracy for mode 27:0.3215 test loss: 242.829
128000: ********* epoch 14 ********* test accuracy for mode 28:0.314 test loss: 234.412
128000: ********* epoch 14 ********* test accuracy for mode 29:0.2905 test loss: 244.062
128000: ********* epoch 14 ********* test accuracy for mode 30:0.2165 test loss: 241.474
128000: ********* epoch 14 ********* test accuracy for mode 31:0.2295 test loss: 242.634
128000: ********* epoch 14 ********* test accuracy for mode 32:0.227 test loss: 239.292
128000: ********* epoch 14 ********* test accuracy for mode 33:0.185 test loss: 250.318
128000: ********* epoch 14 ********* test accuracy for mode 34:0.074 test loss: 254.871
128000: ********* epoch 14 ********* test accuracy for mode 35:0.145 test loss: 430.901
128000: ********* epoch 14 ********* test accuracy for mode 36:0.378 test loss: 426.269
128020: accuracy:0.29 loss: 228.864 (lr:0.0001)
128040: accuracy:0.23 loss: 250.579 (lr:0.0001)
128060: accuracy:0.23 loss: 263.796 (lr:0.0001)
128080: accuracy:0.23 loss: 247.842 (lr:0.0001)
128100: accuracy:0.3 loss: 221.431 (lr:0.0001)
128120: accuracy:0.28 loss: 231.27 (lr:0.0001)
128140: accuracy:0.22 loss: 243.193 (lr:0.0001)
128160: accuracy:0.29 loss: 244.74 (lr:0.0001)
128180: accuracy:0.29 loss: 252.197 (lr:0.0001)
128200: accuracy:0.26 loss: 266.316 (lr:0.0001)
128220: accuracy:0.31 loss: 208.74 (lr:0.0001)
128240: accuracy:0.26 loss: 248.964 (lr:0.0001)
128260: accuracy:0.24 loss: 240.509 (lr:0.0001)
128280: accuracy:0.28 loss: 228.414 (lr:0.0001)
128300: accuracy:0.31 loss: 230.023 (lr:0.0001)
128320: accuracy:0.26 loss: 232.384 (lr:0.0001)
128340: accuracy:0.27 loss: 226.388 (lr:0.0001)
128360: accuracy:0.29 loss: 244.482 (lr:0.0001)
128380: accuracy:0.22 loss: 235.993 (lr:0.0001)
128400: accuracy:0.26 loss: 233.958 (lr:0.0001)
128420: accuracy:0.3 loss: 226.96 (lr:0.0001)
128440: accuracy:0.25 loss: 238.878 (lr:0.0001)
128460: accuracy:0.29 loss: 231.531 (lr:0.0001)
128480: accuracy:0.32 loss: 232.808 (lr:0.0001)
128500: accuracy:0.21 loss: 230.08 (lr:0.0001)
128520: accuracy:0.3 loss: 233.394 (lr:0.0001)
128540: accuracy:0.26 loss: 234.353 (lr:0.0001)
128560: accuracy:0.27 loss: 243.001 (lr:0.0001)
128580: accuracy:0.24 loss: 249.15 (lr:0.0001)
128600: accuracy:0.28 loss: 230.905 (lr:0.0001)
128620: accuracy:0.3 loss: 211.031 (lr:0.0001)
128640: accuracy:0.29 loss: 224.736 (lr:0.0001)
128660: accuracy:0.32 loss: 219.605 (lr:0.0001)
128680: accuracy:0.22 loss: 246.106 (lr:0.0001)
128700: accuracy:0.25 loss: 228.248 (lr:0.0001)
128720: accuracy:0.31 loss: 242.824 (lr:0.0001)
128740: accuracy:0.34 loss: 207.343 (lr:0.0001)
128760: accuracy:0.31 loss: 225.573 (lr:0.0001)
128780: accuracy:0.28 loss: 235.333 (lr:0.0001)
128800: accuracy:0.27 loss: 243.101 (lr:0.0001)
128820: accuracy:0.34 loss: 211.338 (lr:0.0001)
128840: accuracy:0.32 loss: 240.836 (lr:0.0001)
128860: accuracy:0.3 loss: 235.738 (lr:0.0001)
128880: accuracy:0.28 loss: 240.783 (lr:0.0001)
128900: accuracy:0.32 loss: 239.857 (lr:0.0001)
128920: accuracy:0.32 loss: 216.841 (lr:0.0001)
128940: accuracy:0.25 loss: 232.812 (lr:0.0001)
128960: accuracy:0.3 loss: 230.4 (lr:0.0001)
128980: accuracy:0.33 loss: 207.057 (lr:0.0001)
129000: accuracy:0.29 loss: 244.147 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
129000: ********* epoch 14 ********* test accuracy for all:0.232041 test loss: 259.638
129000: ********* epoch 14 ********* test accuracy for mode 0:0.048 test loss: 414.253
129000: ********* epoch 14 ********* test accuracy for mode 1:0.0225 test loss: 446.639
129000: ********* epoch 14 ********* test accuracy for mode 2:0.0985 test loss: 275.671
129000: ********* epoch 14 ********* test accuracy for mode 24:0.247 test loss: 261.45
129000: ********* epoch 14 ********* test accuracy for mode 25:0.346 test loss: 237.163
129000: ********* epoch 14 ********* test accuracy for mode 26:0.3265 test loss: 177.091
129000: ********* epoch 14 ********* test accuracy for mode 27:0.294 test loss: 255.426
129000: ********* epoch 14 ********* test accuracy for mode 28:0.2795 test loss: 245.334
129000: ********* epoch 14 ********* test accuracy for mode 29:0.291 test loss: 250.999
129000: ********* epoch 14 ********* test accuracy for mode 30:0.212 test loss: 246.249
129000: ********* epoch 14 ********* test accuracy for mode 31:0.196 test loss: 248.323
129000: ********* epoch 14 ********* test accuracy for mode 32:0.249 test loss: 239.362
129000: ********* epoch 14 ********* test accuracy for mode 33:0.1895 test loss: 249.677
129000: ********* epoch 14 ********* test accuracy for mode 34:0.0295 test loss: 260.921
129000: ********* epoch 14 ********* test accuracy for mode 35:0.1455 test loss: 441.707
129000: ********* epoch 14 ********* test accuracy for mode 36:0.167 test loss: 452.446
129020: accuracy:0.25 loss: 213.429 (lr:0.0001)
129040: accuracy:0.34 loss: 223.331 (lr:0.0001)
129060: accuracy:0.35 loss: 218.055 (lr:0.0001)
129080: accuracy:0.27 loss: 220.397 (lr:0.0001)
129100: accuracy:0.3 loss: 222.32 (lr:0.0001)
129120: accuracy:0.29 loss: 233.017 (lr:0.0001)
129140: accuracy:0.32 loss: 221.363 (lr:0.0001)
129160: accuracy:0.31 loss: 243.852 (lr:0.0001)
129180: accuracy:0.23 loss: 218.532 (lr:0.0001)
129200: accuracy:0.24 loss: 248.588 (lr:0.0001)
129220: accuracy:0.35 loss: 212.518 (lr:0.0001)
129240: accuracy:0.3 loss: 208.458 (lr:0.0001)
129260: accuracy:0.33 loss: 231.151 (lr:0.0001)
129280: accuracy:0.27 loss: 226.86 (lr:0.0001)
129300: accuracy:0.32 loss: 228.896 (lr:0.0001)
129320: accuracy:0.32 loss: 236.269 (lr:0.0001)
129340: accuracy:0.19 loss: 245.534 (lr:0.0001)
129360: accuracy:0.33 loss: 229.209 (lr:0.0001)
129380: accuracy:0.32 loss: 229.779 (lr:0.0001)
129400: accuracy:0.25 loss: 227.877 (lr:0.0001)
129420: accuracy:0.23 loss: 221.025 (lr:0.0001)
129440: accuracy:0.26 loss: 242.004 (lr:0.0001)
129460: accuracy:0.21 loss: 266.903 (lr:0.0001)
129480: accuracy:0.31 loss: 219.842 (lr:0.0001)
129500: accuracy:0.3 loss: 236.673 (lr:0.0001)
129520: accuracy:0.21 loss: 250.727 (lr:0.0001)
129540: accuracy:0.31 loss: 226.928 (lr:0.0001)
129560: accuracy:0.28 loss: 212.753 (lr:0.0001)
129580: accuracy:0.19 loss: 232.443 (lr:0.0001)
129600: accuracy:0.31 loss: 238.437 (lr:0.0001)
129620: accuracy:0.35 loss: 223.195 (lr:0.0001)
129640: accuracy:0.27 loss: 254.049 (lr:0.0001)
129660: accuracy:0.18 loss: 250.469 (lr:0.0001)
129680: accuracy:0.33 loss: 231.193 (lr:0.0001)
129700: accuracy:0.27 loss: 231.877 (lr:0.0001)
129720: accuracy:0.25 loss: 247.645 (lr:0.0001)
129740: accuracy:0.3 loss: 251.197 (lr:0.0001)
129760: accuracy:0.25 loss: 235.099 (lr:0.0001)
129780: accuracy:0.21 loss: 234.311 (lr:0.0001)
129800: accuracy:0.23 loss: 226.84 (lr:0.0001)
129820: accuracy:0.28 loss: 225.401 (lr:0.0001)
129840: accuracy:0.25 loss: 234.258 (lr:0.0001)
129860: accuracy:0.22 loss: 244.434 (lr:0.0001)
129880: accuracy:0.27 loss: 239.373 (lr:0.0001)
129900: accuracy:0.22 loss: 241.561 (lr:0.0001)
129920: accuracy:0.24 loss: 222.826 (lr:0.0001)
129940: accuracy:0.24 loss: 244.927 (lr:0.0001)
129960: accuracy:0.26 loss: 228.167 (lr:0.0001)
129980: accuracy:0.2 loss: 227.776 (lr:0.0001)
130000: accuracy:0.27 loss: 242.177 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
130000: ********* epoch 14 ********* test accuracy for all:0.237743 test loss: 260.292
130000: ********* epoch 14 ********* test accuracy for mode 0:0.054 test loss: 412.353
130000: ********* epoch 14 ********* test accuracy for mode 1:0.0185 test loss: 442.433
130000: ********* epoch 14 ********* test accuracy for mode 2:0.075 test loss: 273.966
130000: ********* epoch 14 ********* test accuracy for mode 24:0.2195 test loss: 274.657
130000: ********* epoch 14 ********* test accuracy for mode 25:0.3055 test loss: 248.691
130000: ********* epoch 14 ********* test accuracy for mode 26:0.3355 test loss: 176.488
130000: ********* epoch 14 ********* test accuracy for mode 27:0.2985 test loss: 255.699
130000: ********* epoch 14 ********* test accuracy for mode 28:0.2765 test loss: 245.732
130000: ********* epoch 14 ********* test accuracy for mode 29:0.283 test loss: 253.066
130000: ********* epoch 14 ********* test accuracy for mode 30:0.222 test loss: 246.784
130000: ********* epoch 14 ********* test accuracy for mode 31:0.2125 test loss: 250.424
130000: ********* epoch 14 ********* test accuracy for mode 32:0.228 test loss: 243.569
130000: ********* epoch 14 ********* test accuracy for mode 33:0.198 test loss: 251.179
130000: ********* epoch 14 ********* test accuracy for mode 34:0.0415 test loss: 257.273
130000: ********* epoch 14 ********* test accuracy for mode 35:0.179 test loss: 423.007
130000: ********* epoch 14 ********* test accuracy for mode 36:0.422 test loss: 420.672
130020: accuracy:0.3 loss: 222.68 (lr:0.0001)
130040: accuracy:0.22 loss: 236.967 (lr:0.0001)
130060: accuracy:0.3 loss: 226.73 (lr:0.0001)
130080: accuracy:0.17 loss: 245.844 (lr:0.0001)
130100: accuracy:0.31 loss: 212.835 (lr:0.0001)
130120: accuracy:0.36 loss: 209.671 (lr:0.0001)
130140: accuracy:0.35 loss: 206.092 (lr:0.0001)
130160: accuracy:0.3 loss: 237.301 (lr:0.0001)
130180: accuracy:0.32 loss: 229.527 (lr:0.0001)
130200: accuracy:0.22 loss: 236.767 (lr:0.0001)
130220: accuracy:0.26 loss: 210.975 (lr:0.0001)
130240: accuracy:0.25 loss: 236.253 (lr:0.0001)
130260: accuracy:0.28 loss: 225.436 (lr:0.0001)
130280: accuracy:0.24 loss: 227.404 (lr:0.0001)
130300: accuracy:0.23 loss: 241.675 (lr:0.0001)
130320: accuracy:0.25 loss: 234.077 (lr:0.0001)
130340: accuracy:0.26 loss: 229.906 (lr:0.0001)
130360: accuracy:0.3 loss: 233.598 (lr:0.0001)
130380: accuracy:0.34 loss: 229.327 (lr:0.0001)
130400: accuracy:0.31 loss: 223.304 (lr:0.0001)
130420: accuracy:0.24 loss: 240.13 (lr:0.0001)
130440: accuracy:0.2 loss: 246.736 (lr:0.0001)
130460: accuracy:0.24 loss: 245.962 (lr:0.0001)
130480: accuracy:0.26 loss: 236.69 (lr:0.0001)
130500: accuracy:0.28 loss: 232.661 (lr:0.0001)
130520: accuracy:0.29 loss: 231.235 (lr:0.0001)
130540: accuracy:0.15 loss: 259.343 (lr:0.0001)
130560: accuracy:0.28 loss: 238.697 (lr:0.0001)
130580: accuracy:0.31 loss: 217.61 (lr:0.0001)
130600: accuracy:0.23 loss: 219.302 (lr:0.0001)
130620: accuracy:0.34 loss: 217.14 (lr:0.0001)
130640: accuracy:0.29 loss: 215.113 (lr:0.0001)
130660: accuracy:0.29 loss: 224.283 (lr:0.0001)
130680: accuracy:0.28 loss: 241.508 (lr:0.0001)
130700: accuracy:0.25 loss: 243.914 (lr:0.0001)
130720: accuracy:0.31 loss: 217.096 (lr:0.0001)
130740: accuracy:0.26 loss: 227.426 (lr:0.0001)
130760: accuracy:0.24 loss: 236.237 (lr:0.0001)
130780: accuracy:0.3 loss: 231.074 (lr:0.0001)
130800: accuracy:0.28 loss: 246.52 (lr:0.0001)
130820: accuracy:0.24 loss: 235.158 (lr:0.0001)
130840: accuracy:0.34 loss: 216.471 (lr:0.0001)
130860: accuracy:0.27 loss: 225.729 (lr:0.0001)
130880: accuracy:0.29 loss: 227.215 (lr:0.0001)
130900: accuracy:0.34 loss: 232.681 (lr:0.0001)
130920: accuracy:0.17 loss: 251.53 (lr:0.0001)
130940: accuracy:0.32 loss: 212.83 (lr:0.0001)
130960: accuracy:0.32 loss: 223.632 (lr:0.0001)
130980: accuracy:0.32 loss: 247.005 (lr:0.0001)
131000: accuracy:0.27 loss: 226.776 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
131000: ********* epoch 14 ********* test accuracy for all:0.239392 test loss: 258.688
131000: ********* epoch 14 ********* test accuracy for mode 0:0.053 test loss: 411.932
131000: ********* epoch 14 ********* test accuracy for mode 1:0.027 test loss: 433.734
131000: ********* epoch 14 ********* test accuracy for mode 2:0.088 test loss: 271.886
131000: ********* epoch 14 ********* test accuracy for mode 24:0.2445 test loss: 264.617
131000: ********* epoch 14 ********* test accuracy for mode 25:0.333 test loss: 245.482
131000: ********* epoch 14 ********* test accuracy for mode 26:0.279 test loss: 182.345
131000: ********* epoch 14 ********* test accuracy for mode 27:0.2815 test loss: 259.476
131000: ********* epoch 14 ********* test accuracy for mode 28:0.3175 test loss: 241.06
131000: ********* epoch 14 ********* test accuracy for mode 29:0.2755 test loss: 249.077
131000: ********* epoch 14 ********* test accuracy for mode 30:0.235 test loss: 242.366
131000: ********* epoch 14 ********* test accuracy for mode 31:0.1975 test loss: 248.277
131000: ********* epoch 14 ********* test accuracy for mode 32:0.213 test loss: 241.511
131000: ********* epoch 14 ********* test accuracy for mode 33:0.216 test loss: 248.016
131000: ********* epoch 14 ********* test accuracy for mode 34:0.06 test loss: 254.272
131000: ********* epoch 14 ********* test accuracy for mode 35:0.1745 test loss: 432.056
131000: ********* epoch 14 ********* test accuracy for mode 36:0.4225 test loss: 423.736
131020: accuracy:0.23 loss: 235.988 (lr:0.0001)
131040: accuracy:0.28 loss: 214.42 (lr:0.0001)
131060: accuracy:0.32 loss: 235.681 (lr:0.0001)
131080: accuracy:0.34 loss: 212.591 (lr:0.0001)
131100: accuracy:0.27 loss: 247.8 (lr:0.0001)
131120: accuracy:0.24 loss: 235.57 (lr:0.0001)
131140: accuracy:0.35 loss: 220.909 (lr:0.0001)
131160: accuracy:0.3 loss: 227.691 (lr:0.0001)
131180: accuracy:0.27 loss: 235.544 (lr:0.0001)
131200: accuracy:0.26 loss: 224.217 (lr:0.0001)
131220: accuracy:0.31 loss: 239.111 (lr:0.0001)
131240: accuracy:0.29 loss: 221.847 (lr:0.0001)
131260: accuracy:0.37 loss: 204.952 (lr:0.0001)
131280: accuracy:0.18 loss: 247.935 (lr:0.0001)
131300: accuracy:0.31 loss: 223.395 (lr:0.0001)
131320: accuracy:0.24 loss: 224.778 (lr:0.0001)
131340: accuracy:0.32 loss: 221.413 (lr:0.0001)
131360: accuracy:0.32 loss: 226.176 (lr:0.0001)
131380: accuracy:0.25 loss: 236.295 (lr:0.0001)
131400: accuracy:0.31 loss: 238.615 (lr:0.0001)
131420: accuracy:0.27 loss: 206.99 (lr:0.0001)
131440: accuracy:0.3 loss: 230.333 (lr:0.0001)
131460: accuracy:0.33 loss: 218.27 (lr:0.0001)
131480: accuracy:0.25 loss: 244.206 (lr:0.0001)
131500: accuracy:0.34 loss: 217.942 (lr:0.0001)
131520: accuracy:0.24 loss: 230.377 (lr:0.0001)
131540: accuracy:0.32 loss: 219.313 (lr:0.0001)
131560: accuracy:0.39 loss: 213.857 (lr:0.0001)
131580: accuracy:0.19 loss: 252.157 (lr:0.0001)
131600: accuracy:0.29 loss: 235.465 (lr:0.0001)
131620: accuracy:0.28 loss: 224.306 (lr:0.0001)
131640: accuracy:0.3 loss: 226.936 (lr:0.0001)
131660: accuracy:0.27 loss: 242.705 (lr:0.0001)
131680: accuracy:0.29 loss: 225.861 (lr:0.0001)
131700: accuracy:0.22 loss: 240.152 (lr:0.0001)
131720: accuracy:0.26 loss: 226.764 (lr:0.0001)
131740: accuracy:0.2 loss: 245.258 (lr:0.0001)
131760: accuracy:0.37 loss: 219.209 (lr:0.0001)
131780: accuracy:0.27 loss: 241.862 (lr:0.0001)
131800: accuracy:0.24 loss: 243.004 (lr:0.0001)
131820: accuracy:0.34 loss: 231.855 (lr:0.0001)
131840: accuracy:0.28 loss: 245.888 (lr:0.0001)
131860: accuracy:0.24 loss: 225.273 (lr:0.0001)
131880: accuracy:0.27 loss: 242.787 (lr:0.0001)
131900: accuracy:0.25 loss: 257.06 (lr:0.0001)
131920: accuracy:0.33 loss: 208.642 (lr:0.0001)
131940: accuracy:0.24 loss: 225.557 (lr:0.0001)
131960: accuracy:0.3 loss: 224.586 (lr:0.0001)
131980: accuracy:0.28 loss: 245.432 (lr:0.0001)
132000: accuracy:0.28 loss: 228.734 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
132000: ********* epoch 14 ********* test accuracy for all:0.238068 test loss: 258.321
132000: ********* epoch 14 ********* test accuracy for mode 0:0.0585 test loss: 406.684
132000: ********* epoch 14 ********* test accuracy for mode 1:0.0295 test loss: 428.958
132000: ********* epoch 14 ********* test accuracy for mode 2:0.0655 test loss: 279.468
132000: ********* epoch 14 ********* test accuracy for mode 24:0.253 test loss: 258.536
132000: ********* epoch 14 ********* test accuracy for mode 25:0.3305 test loss: 235.419
132000: ********* epoch 14 ********* test accuracy for mode 26:0.3815 test loss: 171.864
132000: ********* epoch 14 ********* test accuracy for mode 27:0.277 test loss: 257.537
132000: ********* epoch 14 ********* test accuracy for mode 28:0.2765 test loss: 248.923
132000: ********* epoch 14 ********* test accuracy for mode 29:0.287 test loss: 257.67
132000: ********* epoch 14 ********* test accuracy for mode 30:0.207 test loss: 254.311
132000: ********* epoch 14 ********* test accuracy for mode 31:0.174 test loss: 258.158
132000: ********* epoch 14 ********* test accuracy for mode 32:0.2515 test loss: 246.788
132000: ********* epoch 14 ********* test accuracy for mode 33:0.172 test loss: 257.208
132000: ********* epoch 14 ********* test accuracy for mode 34:0.049 test loss: 261.763
132000: ********* epoch 14 ********* test accuracy for mode 35:0.1575 test loss: 433.906
132000: ********* epoch 14 ********* test accuracy for mode 36:0.4395 test loss: 421.371
132020: accuracy:0.25 loss: 230.164 (lr:0.0001)
132040: accuracy:0.24 loss: 247.704 (lr:0.0001)
132060: accuracy:0.15 loss: 251.993 (lr:0.0001)
132080: accuracy:0.28 loss: 239.834 (lr:0.0001)
132100: accuracy:0.28 loss: 229.426 (lr:0.0001)
132120: accuracy:0.27 loss: 235.608 (lr:0.0001)
132140: accuracy:0.29 loss: 236.809 (lr:0.0001)
132160: accuracy:0.34 loss: 216.762 (lr:0.0001)
132180: accuracy:0.26 loss: 246.448 (lr:0.0001)
132200: accuracy:0.31 loss: 227.64 (lr:0.0001)
132220: accuracy:0.37 loss: 219.238 (lr:0.0001)
132240: accuracy:0.24 loss: 233.553 (lr:0.0001)
132260: accuracy:0.32 loss: 234.102 (lr:0.0001)
132280: accuracy:0.31 loss: 213.748 (lr:0.0001)
132300: accuracy:0.29 loss: 218.788 (lr:0.0001)
132320: accuracy:0.28 loss: 216.828 (lr:0.0001)
132340: accuracy:0.27 loss: 232.583 (lr:0.0001)
132360: accuracy:0.3 loss: 207.711 (lr:0.0001)
132380: accuracy:0.24 loss: 238.216 (lr:0.0001)
132400: accuracy:0.28 loss: 254.698 (lr:0.0001)
132420: accuracy:0.31 loss: 237.082 (lr:0.0001)
132440: accuracy:0.27 loss: 234.477 (lr:0.0001)
132460: accuracy:0.27 loss: 242.751 (lr:0.0001)
132480: accuracy:0.27 loss: 232.151 (lr:0.0001)
132500: accuracy:0.27 loss: 230.994 (lr:0.0001)
132520: accuracy:0.26 loss: 228.43 (lr:0.0001)
132540: accuracy:0.27 loss: 241.104 (lr:0.0001)
132560: accuracy:0.26 loss: 240.718 (lr:0.0001)
132580: accuracy:0.24 loss: 248.05 (lr:0.0001)
132600: accuracy:0.31 loss: 245.834 (lr:0.0001)
132620: accuracy:0.27 loss: 227.989 (lr:0.0001)
132640: accuracy:0.23 loss: 246.331 (lr:0.0001)
132660: accuracy:0.22 loss: 224.402 (lr:0.0001)
132680: accuracy:0.22 loss: 233.653 (lr:0.0001)
132700: accuracy:0.29 loss: 221.691 (lr:0.0001)
132720: accuracy:0.3 loss: 240.054 (lr:0.0001)
132740: accuracy:0.25 loss: 228.476 (lr:0.0001)
132760: accuracy:0.22 loss: 244.234 (lr:0.0001)
132780: accuracy:0.26 loss: 225.707 (lr:0.0001)
132800: accuracy:0.26 loss: 229.809 (lr:0.0001)
132820: accuracy:0.31 loss: 218.941 (lr:0.0001)
132840: accuracy:0.26 loss: 237.557 (lr:0.0001)
132860: accuracy:0.3 loss: 223.606 (lr:0.0001)
132880: accuracy:0.22 loss: 226.927 (lr:0.0001)
132900: accuracy:0.37 loss: 214.702 (lr:0.0001)
132920: accuracy:0.29 loss: 237.964 (lr:0.0001)
132940: accuracy:0.3 loss: 228.598 (lr:0.0001)
132960: accuracy:0.29 loss: 224.64 (lr:0.0001)
132980: accuracy:0.4 loss: 227.485 (lr:0.0001)
133000: accuracy:0.33 loss: 223.319 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
133000: ********* epoch 14 ********* test accuracy for all:0.240554 test loss: 257.94
133000: ********* epoch 14 ********* test accuracy for mode 0:0.0635 test loss: 402.666
133000: ********* epoch 14 ********* test accuracy for mode 1:0.0285 test loss: 427.647
133000: ********* epoch 14 ********* test accuracy for mode 2:0.0865 test loss: 275.41
133000: ********* epoch 14 ********* test accuracy for mode 24:0.252 test loss: 257.28
133000: ********* epoch 14 ********* test accuracy for mode 25:0.309 test loss: 239.721
133000: ********* epoch 14 ********* test accuracy for mode 26:0.3575 test loss: 174.212
133000: ********* epoch 14 ********* test accuracy for mode 27:0.286 test loss: 253.946
133000: ********* epoch 14 ********* test accuracy for mode 28:0.3055 test loss: 240.456
133000: ********* epoch 14 ********* test accuracy for mode 29:0.2925 test loss: 248.503
133000: ********* epoch 14 ********* test accuracy for mode 30:0.218 test loss: 246.063
133000: ********* epoch 14 ********* test accuracy for mode 31:0.193 test loss: 249.764
133000: ********* epoch 14 ********* test accuracy for mode 32:0.2615 test loss: 239.6
133000: ********* epoch 14 ********* test accuracy for mode 33:0.1775 test loss: 251.739
133000: ********* epoch 14 ********* test accuracy for mode 34:0.0705 test loss: 256.386
133000: ********* epoch 14 ********* test accuracy for mode 35:0.158 test loss: 426.924
133000: ********* epoch 14 ********* test accuracy for mode 36:0.4185 test loss: 412.045
133020: accuracy:0.28 loss: 248.967 (lr:0.0001)
133040: accuracy:0.24 loss: 228.617 (lr:0.0001)
133060: accuracy:0.32 loss: 236.236 (lr:0.0001)
133080: accuracy:0.37 loss: 233.062 (lr:0.0001)
133100: accuracy:0.29 loss: 219.898 (lr:0.0001)
133120: accuracy:0.3 loss: 211.25 (lr:0.0001)
133140: accuracy:0.27 loss: 230.285 (lr:0.0001)
133160: accuracy:0.28 loss: 221.584 (lr:0.0001)
133180: accuracy:0.28 loss: 231.119 (lr:0.0001)
133200: accuracy:0.34 loss: 214.069 (lr:0.0001)
133220: accuracy:0.3 loss: 236.453 (lr:0.0001)
133240: accuracy:0.36 loss: 229.261 (lr:0.0001)
133260: accuracy:0.19 loss: 239.758 (lr:0.0001)
133280: accuracy:0.29 loss: 243.627 (lr:0.0001)
133300: accuracy:0.3 loss: 228.299 (lr:0.0001)
133320: accuracy:0.29 loss: 214.524 (lr:0.0001)
133340: accuracy:0.28 loss: 225.665 (lr:0.0001)
133360: accuracy:0.25 loss: 229.562 (lr:0.0001)
133380: accuracy:0.18 loss: 243.771 (lr:0.0001)
133400: accuracy:0.27 loss: 255.391 (lr:0.0001)
133420: accuracy:0.25 loss: 233.29 (lr:0.0001)
133440: accuracy:0.31 loss: 225.796 (lr:0.0001)
133460: accuracy:0.36 loss: 214.46 (lr:0.0001)
133480: accuracy:0.35 loss: 228.396 (lr:0.0001)
133500: accuracy:0.24 loss: 243.114 (lr:0.0001)
133520: accuracy:0.29 loss: 240.84 (lr:0.0001)
133540: accuracy:0.23 loss: 240.39 (lr:0.0001)
133560: accuracy:0.25 loss: 236.55 (lr:0.0001)
133580: accuracy:0.3 loss: 210.924 (lr:0.0001)
133600: accuracy:0.29 loss: 223.326 (lr:0.0001)
133620: accuracy:0.27 loss: 217.672 (lr:0.0001)
133640: accuracy:0.25 loss: 237.535 (lr:0.0001)
133660: accuracy:0.29 loss: 231.404 (lr:0.0001)
133680: accuracy:0.29 loss: 217.937 (lr:0.0001)
133700: accuracy:0.27 loss: 245.17 (lr:0.0001)
133720: accuracy:0.26 loss: 262.58 (lr:0.0001)
133740: accuracy:0.32 loss: 231.947 (lr:0.0001)
133760: accuracy:0.22 loss: 242.184 (lr:0.0001)
133780: accuracy:0.25 loss: 233.161 (lr:0.0001)
133800: accuracy:0.29 loss: 223.61 (lr:0.0001)
133820: accuracy:0.31 loss: 231.961 (lr:0.0001)
133840: accuracy:0.29 loss: 225.941 (lr:0.0001)
133860: accuracy:0.3 loss: 215.249 (lr:0.0001)
133880: accuracy:0.28 loss: 248.852 (lr:0.0001)
133900: accuracy:0.3 loss: 231.914 (lr:0.0001)
133920: accuracy:0.27 loss: 237.257 (lr:0.0001)
133940: accuracy:0.27 loss: 232.104 (lr:0.0001)
133960: accuracy:0.25 loss: 233.755 (lr:0.0001)
133980: accuracy:0.33 loss: 212.543 (lr:0.0001)
134000: accuracy:0.32 loss: 207.234 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
134000: ********* epoch 14 ********* test accuracy for all:0.238108 test loss: 259.669
134000: ********* epoch 14 ********* test accuracy for mode 0:0.056 test loss: 412.216
134000: ********* epoch 14 ********* test accuracy for mode 1:0.0265 test loss: 437.155
134000: ********* epoch 14 ********* test accuracy for mode 2:0.0685 test loss: 279.925
134000: ********* epoch 14 ********* test accuracy for mode 24:0.245 test loss: 263.085
134000: ********* epoch 14 ********* test accuracy for mode 25:0.359 test loss: 240.104
134000: ********* epoch 14 ********* test accuracy for mode 26:0.3195 test loss: 174.866
134000: ********* epoch 14 ********* test accuracy for mode 27:0.2845 test loss: 263.181
134000: ********* epoch 14 ********* test accuracy for mode 28:0.3 test loss: 251.139
134000: ********* epoch 14 ********* test accuracy for mode 29:0.26 test loss: 264.626
134000: ********* epoch 14 ********* test accuracy for mode 30:0.216 test loss: 254.841
134000: ********* epoch 14 ********* test accuracy for mode 31:0.196 test loss: 256.477
134000: ********* epoch 14 ********* test accuracy for mode 32:0.2345 test loss: 246.182
134000: ********* epoch 14 ********* test accuracy for mode 33:0.1905 test loss: 254.335
134000: ********* epoch 14 ********* test accuracy for mode 34:0.039 test loss: 262.593
134000: ********* epoch 14 ********* test accuracy for mode 35:0.1355 test loss: 433.926
134000: ********* epoch 14 ********* test accuracy for mode 36:0.3855 test loss: 429.97
134020: accuracy:0.23 loss: 238.146 (lr:0.0001)
134040: accuracy:0.3 loss: 229.811 (lr:0.0001)
134060: accuracy:0.28 loss: 234.91 (lr:0.0001)
134080: accuracy:0.26 loss: 217.78 (lr:0.0001)
134100: accuracy:0.22 loss: 235.472 (lr:0.0001)
134120: accuracy:0.3 loss: 224.907 (lr:0.0001)
134140: accuracy:0.25 loss: 226.281 (lr:0.0001)
134160: accuracy:0.33 loss: 233.077 (lr:0.0001)
134180: accuracy:0.4 loss: 222.849 (lr:0.0001)
134200: accuracy:0.25 loss: 238.059 (lr:0.0001)
134220: accuracy:0.25 loss: 221.802 (lr:0.0001)
134240: accuracy:0.31 loss: 226.188 (lr:0.0001)
134260: accuracy:0.29 loss: 218.994 (lr:0.0001)
134280: accuracy:0.27 loss: 232.694 (lr:0.0001)
134300: accuracy:0.3 loss: 230.364 (lr:0.0001)
134320: accuracy:0.18 loss: 247.486 (lr:0.0001)
134340: accuracy:0.19 loss: 246.112 (lr:0.0001)
134360: accuracy:0.31 loss: 227.238 (lr:0.0001)
134380: accuracy:0.26 loss: 232.075 (lr:0.0001)
134400: accuracy:0.28 loss: 222.0 (lr:0.0001)
134420: accuracy:0.25 loss: 258.802 (lr:0.0001)
134440: accuracy:0.18 loss: 230.683 (lr:0.0001)
134460: accuracy:0.33 loss: 218.885 (lr:0.0001)
134480: accuracy:0.3 loss: 233.095 (lr:0.0001)
134500: accuracy:0.29 loss: 223.012 (lr:0.0001)
134520: accuracy:0.3 loss: 235.161 (lr:0.0001)
134540: accuracy:0.33 loss: 217.821 (lr:0.0001)
134560: accuracy:0.19 loss: 245.695 (lr:0.0001)
134580: accuracy:0.26 loss: 232.162 (lr:0.0001)
134600: accuracy:0.39 loss: 211.165 (lr:0.0001)
134620: accuracy:0.28 loss: 224.44 (lr:0.0001)
134640: accuracy:0.32 loss: 219.499 (lr:0.0001)
134660: accuracy:0.33 loss: 219.171 (lr:0.0001)
134680: accuracy:0.24 loss: 217.256 (lr:0.0001)
134700: accuracy:0.21 loss: 238.229 (lr:0.0001)
134720: accuracy:0.24 loss: 230.828 (lr:0.0001)
134740: accuracy:0.32 loss: 209.77 (lr:0.0001)
134760: accuracy:0.27 loss: 219.634 (lr:0.0001)
134780: accuracy:0.18 loss: 245.162 (lr:0.0001)
134800: accuracy:0.31 loss: 228.171 (lr:0.0001)
134820: accuracy:0.34 loss: 215.561 (lr:0.0001)
134840: accuracy:0.25 loss: 244.182 (lr:0.0001)
134860: accuracy:0.35 loss: 235.961 (lr:0.0001)
134880: accuracy:0.28 loss: 245.463 (lr:0.0001)
134900: accuracy:0.31 loss: 239.116 (lr:0.0001)
134920: accuracy:0.27 loss: 242.326 (lr:0.0001)
134940: accuracy:0.25 loss: 231.271 (lr:0.0001)
134960: accuracy:0.23 loss: 243.862 (lr:0.0001)
134980: accuracy:0.24 loss: 223.918 (lr:0.0001)
135000: accuracy:0.27 loss: 227.968 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
135000: ********* epoch 14 ********* test accuracy for all:0.240811 test loss: 257.704
135000: ********* epoch 14 ********* test accuracy for mode 0:0.051 test loss: 414.761
135000: ********* epoch 14 ********* test accuracy for mode 1:0.0205 test loss: 440.125
135000: ********* epoch 14 ********* test accuracy for mode 2:0.0695 test loss: 279.264
135000: ********* epoch 14 ********* test accuracy for mode 24:0.251 test loss: 256.354
135000: ********* epoch 14 ********* test accuracy for mode 25:0.342 test loss: 232.849
135000: ********* epoch 14 ********* test accuracy for mode 26:0.3265 test loss: 175.308
135000: ********* epoch 14 ********* test accuracy for mode 27:0.307 test loss: 249.501
135000: ********* epoch 14 ********* test accuracy for mode 28:0.294 test loss: 244.165
135000: ********* epoch 14 ********* test accuracy for mode 29:0.285 test loss: 253.275
135000: ********* epoch 14 ********* test accuracy for mode 30:0.2095 test loss: 249.612
135000: ********* epoch 14 ********* test accuracy for mode 31:0.171 test loss: 252.912
135000: ********* epoch 14 ********* test accuracy for mode 32:0.281 test loss: 240.279
135000: ********* epoch 14 ********* test accuracy for mode 33:0.1725 test loss: 252.522
135000: ********* epoch 14 ********* test accuracy for mode 34:0.0525 test loss: 259.963
135000: ********* epoch 14 ********* test accuracy for mode 35:0.1625 test loss: 427.018
135000: ********* epoch 14 ********* test accuracy for mode 36:0.434 test loss: 411.532
135020: accuracy:0.23 loss: 250.337 (lr:0.0001)
135040: accuracy:0.16 loss: 273.493 (lr:0.0001)
135060: accuracy:0.28 loss: 227.705 (lr:0.0001)
135080: accuracy:0.27 loss: 227.438 (lr:0.0001)
135100: accuracy:0.28 loss: 218.595 (lr:0.0001)
135120: accuracy:0.18 loss: 246.59 (lr:0.0001)
135140: accuracy:0.3 loss: 209.477 (lr:0.0001)
135160: accuracy:0.32 loss: 230.374 (lr:0.0001)
135180: accuracy:0.24 loss: 230.728 (lr:0.0001)
135200: accuracy:0.25 loss: 236.616 (lr:0.0001)
135220: accuracy:0.26 loss: 242.463 (lr:0.0001)
135240: accuracy:0.27 loss: 212.993 (lr:0.0001)
135260: accuracy:0.33 loss: 229.182 (lr:0.0001)
135280: accuracy:0.36 loss: 215.683 (lr:0.0001)
135300: accuracy:0.38 loss: 216.659 (lr:0.0001)
135320: accuracy:0.29 loss: 238.616 (lr:0.0001)
135340: accuracy:0.34 loss: 210.448 (lr:0.0001)
135360: accuracy:0.34 loss: 228.749 (lr:0.0001)
135380: accuracy:0.28 loss: 223.929 (lr:0.0001)
135400: accuracy:0.28 loss: 225.166 (lr:0.0001)
135420: accuracy:0.3 loss: 214.59 (lr:0.0001)
135440: accuracy:0.28 loss: 202.513 (lr:0.0001)
135460: accuracy:0.34 loss: 219.611 (lr:0.0001)
135480: accuracy:0.3 loss: 219.694 (lr:0.0001)
135500: accuracy:0.25 loss: 249.124 (lr:0.0001)
135520: accuracy:0.28 loss: 226.589 (lr:0.0001)
135540: accuracy:0.2 loss: 243.896 (lr:0.0001)
135560: accuracy:0.3 loss: 216.513 (lr:0.0001)
135580: accuracy:0.28 loss: 227.216 (lr:0.0001)
135600: accuracy:0.3 loss: 221.285 (lr:0.0001)
135620: accuracy:0.27 loss: 221.017 (lr:0.0001)
135640: accuracy:0.24 loss: 242.401 (lr:0.0001)
135660: accuracy:0.29 loss: 241.839 (lr:0.0001)
135680: accuracy:0.28 loss: 239.866 (lr:0.0001)
135700: accuracy:0.28 loss: 231.678 (lr:0.0001)
135720: accuracy:0.36 loss: 238.163 (lr:0.0001)
135740: accuracy:0.19 loss: 268.935 (lr:0.0001)
135760: accuracy:0.26 loss: 235.614 (lr:0.0001)
135780: accuracy:0.21 loss: 224.99 (lr:0.0001)
135800: accuracy:0.27 loss: 227.541 (lr:0.0001)
135820: accuracy:0.2 loss: 247.829 (lr:0.0001)
135840: accuracy:0.23 loss: 227.814 (lr:0.0001)
135860: accuracy:0.28 loss: 229.938 (lr:0.0001)
135880: accuracy:0.34 loss: 212.393 (lr:0.0001)
135900: accuracy:0.22 loss: 238.581 (lr:0.0001)
135920: accuracy:0.33 loss: 226.035 (lr:0.0001)
135940: accuracy:0.29 loss: 213.584 (lr:0.0001)
135960: accuracy:0.31 loss: 217.908 (lr:0.0001)
135980: accuracy:0.22 loss: 229.576 (lr:0.0001)
136000: accuracy:0.25 loss: 243.453 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
136000: ********* epoch 14 ********* test accuracy for all:0.241716 test loss: 258.879
136000: ********* epoch 14 ********* test accuracy for mode 0:0.053 test loss: 415.708
136000: ********* epoch 14 ********* test accuracy for mode 1:0.025 test loss: 441.096
136000: ********* epoch 14 ********* test accuracy for mode 2:0.095 test loss: 272.46
136000: ********* epoch 14 ********* test accuracy for mode 24:0.2705 test loss: 255.072
136000: ********* epoch 14 ********* test accuracy for mode 25:0.3505 test loss: 234.17
136000: ********* epoch 14 ********* test accuracy for mode 26:0.3155 test loss: 175.82
136000: ********* epoch 14 ********* test accuracy for mode 27:0.271 test loss: 257.741
136000: ********* epoch 14 ********* test accuracy for mode 28:0.2925 test loss: 244.869
136000: ********* epoch 14 ********* test accuracy for mode 29:0.295 test loss: 250.164
136000: ********* epoch 14 ********* test accuracy for mode 30:0.199 test loss: 249.12
136000: ********* epoch 14 ********* test accuracy for mode 31:0.1925 test loss: 248.154
136000: ********* epoch 14 ********* test accuracy for mode 32:0.256 test loss: 236.914
136000: ********* epoch 14 ********* test accuracy for mode 33:0.2095 test loss: 245.946
136000: ********* epoch 14 ********* test accuracy for mode 34:0.044 test loss: 255.513
136000: ********* epoch 14 ********* test accuracy for mode 35:0.1665 test loss: 434.464
136000: ********* epoch 14 ********* test accuracy for mode 36:0.433 test loss: 415.058
136020: accuracy:0.32 loss: 228.347 (lr:0.0001)
136040: accuracy:0.2 loss: 254.834 (lr:0.0001)
136060: accuracy:0.25 loss: 235.898 (lr:0.0001)
136080: accuracy:0.3 loss: 212.604 (lr:0.0001)
136100: accuracy:0.31 loss: 211.395 (lr:0.0001)
136120: accuracy:0.32 loss: 212.778 (lr:0.0001)
136140: accuracy:0.26 loss: 216.818 (lr:0.0001)
136160: accuracy:0.31 loss: 215.839 (lr:0.0001)
136180: accuracy:0.25 loss: 256.416 (lr:0.0001)
136200: accuracy:0.27 loss: 228.393 (lr:0.0001)
136220: accuracy:0.25 loss: 214.031 (lr:0.0001)
136240: accuracy:0.22 loss: 239.4 (lr:0.0001)
136260: accuracy:0.26 loss: 241.971 (lr:0.0001)
136280: accuracy:0.3 loss: 223.685 (lr:0.0001)
136300: accuracy:0.27 loss: 233.439 (lr:0.0001)
136320: accuracy:0.26 loss: 251.318 (lr:0.0001)
136340: accuracy:0.26 loss: 244.105 (lr:0.0001)
136360: accuracy:0.37 loss: 223.466 (lr:0.0001)
136380: accuracy:0.24 loss: 242.901 (lr:0.0001)
136400: accuracy:0.24 loss: 222.767 (lr:0.0001)
136420: accuracy:0.27 loss: 236.57 (lr:0.0001)
136440: accuracy:0.26 loss: 239.851 (lr:0.0001)
136460: accuracy:0.2 loss: 237.774 (lr:0.0001)
136480: accuracy:0.33 loss: 199.108 (lr:0.0001)
136500: accuracy:0.29 loss: 221.158 (lr:0.0001)
136520: accuracy:0.25 loss: 244.335 (lr:0.0001)
136540: accuracy:0.28 loss: 224.702 (lr:0.0001)
136560: accuracy:0.35 loss: 211.689 (lr:0.0001)
136580: accuracy:0.36 loss: 223.293 (lr:0.0001)
136600: accuracy:0.24 loss: 244.559 (lr:0.0001)
136620: accuracy:0.26 loss: 241.218 (lr:0.0001)
136640: accuracy:0.23 loss: 224.282 (lr:0.0001)
136660: accuracy:0.25 loss: 230.029 (lr:0.0001)
136680: accuracy:0.31 loss: 219.93 (lr:0.0001)
136700: accuracy:0.24 loss: 214.819 (lr:0.0001)
136720: accuracy:0.24 loss: 254.174 (lr:0.0001)
136740: accuracy:0.25 loss: 229.697 (lr:0.0001)
136760: accuracy:0.33 loss: 244.087 (lr:0.0001)
136780: accuracy:0.27 loss: 243.774 (lr:0.0001)
136800: accuracy:0.26 loss: 220.55 (lr:0.0001)
136820: accuracy:0.22 loss: 265.146 (lr:0.0001)
136840: accuracy:0.31 loss: 233.955 (lr:0.0001)
136860: accuracy:0.27 loss: 244.01 (lr:0.0001)
136880: accuracy:0.31 loss: 199.09 (lr:0.0001)
136900: accuracy:0.24 loss: 242.223 (lr:0.0001)
136920: accuracy:0.27 loss: 209.111 (lr:0.0001)
136940: accuracy:0.28 loss: 231.214 (lr:0.0001)
136960: accuracy:0.22 loss: 234.634 (lr:0.0001)
136980: accuracy:0.28 loss: 233.955 (lr:0.0001)
137000: accuracy:0.25 loss: 234.992 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
137000: ********* epoch 15 ********* test accuracy for all:0.239365 test loss: 257.973
137000: ********* epoch 15 ********* test accuracy for mode 0:0.0535 test loss: 414.711
137000: ********* epoch 15 ********* test accuracy for mode 1:0.024 test loss: 439.411
137000: ********* epoch 15 ********* test accuracy for mode 2:0.0885 test loss: 276.121
137000: ********* epoch 15 ********* test accuracy for mode 24:0.241 test loss: 258.359
137000: ********* epoch 15 ********* test accuracy for mode 25:0.3515 test loss: 231.901
137000: ********* epoch 15 ********* test accuracy for mode 26:0.3325 test loss: 173.688
137000: ********* epoch 15 ********* test accuracy for mode 27:0.299 test loss: 248.366
137000: ********* epoch 15 ********* test accuracy for mode 28:0.298 test loss: 238.822
137000: ********* epoch 15 ********* test accuracy for mode 29:0.3035 test loss: 243.254
137000: ********* epoch 15 ********* test accuracy for mode 30:0.247 test loss: 239.763
137000: ********* epoch 15 ********* test accuracy for mode 31:0.1655 test loss: 249.518
137000: ********* epoch 15 ********* test accuracy for mode 32:0.281 test loss: 237.584
137000: ********* epoch 15 ********* test accuracy for mode 33:0.144 test loss: 253.348
137000: ********* epoch 15 ********* test accuracy for mode 34:0.06 test loss: 258.955
137000: ********* epoch 15 ********* test accuracy for mode 35:0.1565 test loss: 441.46
137000: ********* epoch 15 ********* test accuracy for mode 36:0.304 test loss: 444.706
137020: accuracy:0.29 loss: 234.21 (lr:0.0001)
137040: accuracy:0.28 loss: 223.197 (lr:0.0001)
137060: accuracy:0.26 loss: 224.958 (lr:0.0001)
137080: accuracy:0.27 loss: 238.0 (lr:0.0001)
137100: accuracy:0.37 loss: 211.637 (lr:0.0001)
137120: accuracy:0.28 loss: 234.76 (lr:0.0001)
137140: accuracy:0.19 loss: 248.404 (lr:0.0001)
137160: accuracy:0.29 loss: 232.007 (lr:0.0001)
137180: accuracy:0.19 loss: 261.738 (lr:0.0001)
137200: accuracy:0.3 loss: 217.78 (lr:0.0001)
137220: accuracy:0.26 loss: 226.101 (lr:0.0001)
137240: accuracy:0.25 loss: 235.907 (lr:0.0001)
137260: accuracy:0.24 loss: 242.415 (lr:0.0001)
137280: accuracy:0.27 loss: 233.852 (lr:0.0001)
137300: accuracy:0.38 loss: 230.133 (lr:0.0001)
137320: accuracy:0.28 loss: 233.255 (lr:0.0001)
137340: accuracy:0.4 loss: 207.845 (lr:0.0001)
137360: accuracy:0.35 loss: 235.204 (lr:0.0001)
137380: accuracy:0.32 loss: 226.02 (lr:0.0001)
137400: accuracy:0.35 loss: 229.249 (lr:0.0001)
137420: accuracy:0.28 loss: 229.583 (lr:0.0001)
137440: accuracy:0.26 loss: 233.986 (lr:0.0001)
137460: accuracy:0.32 loss: 207.038 (lr:0.0001)
137480: accuracy:0.24 loss: 225.791 (lr:0.0001)
137500: accuracy:0.31 loss: 246.168 (lr:0.0001)
137520: accuracy:0.31 loss: 211.16 (lr:0.0001)
137540: accuracy:0.24 loss: 224.046 (lr:0.0001)
137560: accuracy:0.31 loss: 239.883 (lr:0.0001)
137580: accuracy:0.26 loss: 233.571 (lr:0.0001)
137600: accuracy:0.28 loss: 215.865 (lr:0.0001)
137620: accuracy:0.28 loss: 211.554 (lr:0.0001)
137640: accuracy:0.31 loss: 224.867 (lr:0.0001)
137660: accuracy:0.19 loss: 244.695 (lr:0.0001)
137680: accuracy:0.39 loss: 209.479 (lr:0.0001)
137700: accuracy:0.33 loss: 220.19 (lr:0.0001)
137720: accuracy:0.3 loss: 240.559 (lr:0.0001)
137740: accuracy:0.38 loss: 227.849 (lr:0.0001)
137760: accuracy:0.21 loss: 225.45 (lr:0.0001)
137780: accuracy:0.3 loss: 224.7 (lr:0.0001)
137800: accuracy:0.38 loss: 210.248 (lr:0.0001)
137820: accuracy:0.18 loss: 250.266 (lr:0.0001)
137840: accuracy:0.38 loss: 226.524 (lr:0.0001)
137860: accuracy:0.22 loss: 236.598 (lr:0.0001)
137880: accuracy:0.22 loss: 248.969 (lr:0.0001)
137900: accuracy:0.31 loss: 232.772 (lr:0.0001)
137920: accuracy:0.33 loss: 232.326 (lr:0.0001)
137940: accuracy:0.25 loss: 235.369 (lr:0.0001)
137960: accuracy:0.28 loss: 211.399 (lr:0.0001)
137980: accuracy:0.27 loss: 254.921 (lr:0.0001)
138000: accuracy:0.36 loss: 212.239 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
138000: ********* epoch 15 ********* test accuracy for all:0.240297 test loss: 257.754
138000: ********* epoch 15 ********* test accuracy for mode 0:0.056 test loss: 413.406
138000: ********* epoch 15 ********* test accuracy for mode 1:0.027 test loss: 432.373
138000: ********* epoch 15 ********* test accuracy for mode 2:0.0785 test loss: 276.438
138000: ********* epoch 15 ********* test accuracy for mode 24:0.2545 test loss: 254.051
138000: ********* epoch 15 ********* test accuracy for mode 25:0.3395 test loss: 230.97
138000: ********* epoch 15 ********* test accuracy for mode 26:0.3745 test loss: 170.973
138000: ********* epoch 15 ********* test accuracy for mode 27:0.2965 test loss: 251.116
138000: ********* epoch 15 ********* test accuracy for mode 28:0.284 test loss: 243.536
138000: ********* epoch 15 ********* test accuracy for mode 29:0.2615 test loss: 256.012
138000: ********* epoch 15 ********* test accuracy for mode 30:0.2155 test loss: 250.882
138000: ********* epoch 15 ********* test accuracy for mode 31:0.1925 test loss: 254.558
138000: ********* epoch 15 ********* test accuracy for mode 32:0.2405 test loss: 245.637
138000: ********* epoch 15 ********* test accuracy for mode 33:0.1675 test loss: 257.685
138000: ********* epoch 15 ********* test accuracy for mode 34:0.05 test loss: 260.134
138000: ********* epoch 15 ********* test accuracy for mode 35:0.162 test loss: 435.69
138000: ********* epoch 15 ********* test accuracy for mode 36:0.4 test loss: 431.048
138020: accuracy:0.3 loss: 235.125 (lr:0.0001)
138040: accuracy:0.21 loss: 252.734 (lr:0.0001)
138060: accuracy:0.31 loss: 229.683 (lr:0.0001)
138080: accuracy:0.3 loss: 218.645 (lr:0.0001)
138100: accuracy:0.3 loss: 227.886 (lr:0.0001)
138120: accuracy:0.26 loss: 238.298 (lr:0.0001)
138140: accuracy:0.26 loss: 241.994 (lr:0.0001)
138160: accuracy:0.25 loss: 222.039 (lr:0.0001)
138180: accuracy:0.36 loss: 233.409 (lr:0.0001)
138200: accuracy:0.28 loss: 242.065 (lr:0.0001)
138220: accuracy:0.26 loss: 245.76 (lr:0.0001)
138240: accuracy:0.29 loss: 237.2 (lr:0.0001)
138260: accuracy:0.3 loss: 223.609 (lr:0.0001)
138280: accuracy:0.32 loss: 225.225 (lr:0.0001)
138300: accuracy:0.34 loss: 223.392 (lr:0.0001)
138320: accuracy:0.37 loss: 217.981 (lr:0.0001)
138340: accuracy:0.28 loss: 226.837 (lr:0.0001)
138360: accuracy:0.21 loss: 235.155 (lr:0.0001)
138380: accuracy:0.29 loss: 239.917 (lr:0.0001)
138400: accuracy:0.26 loss: 219.376 (lr:0.0001)
138420: accuracy:0.27 loss: 222.858 (lr:0.0001)
138440: accuracy:0.33 loss: 210.96 (lr:0.0001)
138460: accuracy:0.26 loss: 241.492 (lr:0.0001)
138480: accuracy:0.26 loss: 234.029 (lr:0.0001)
138500: accuracy:0.43 loss: 223.324 (lr:0.0001)
138520: accuracy:0.22 loss: 237.653 (lr:0.0001)
138540: accuracy:0.3 loss: 238.281 (lr:0.0001)
138560: accuracy:0.28 loss: 231.019 (lr:0.0001)
138580: accuracy:0.21 loss: 253.202 (lr:0.0001)
138600: accuracy:0.31 loss: 220.412 (lr:0.0001)
138620: accuracy:0.32 loss: 248.994 (lr:0.0001)
138640: accuracy:0.22 loss: 251.539 (lr:0.0001)
138660: accuracy:0.28 loss: 227.632 (lr:0.0001)
138680: accuracy:0.33 loss: 226.182 (lr:0.0001)
138700: accuracy:0.29 loss: 223.827 (lr:0.0001)
138720: accuracy:0.25 loss: 242.181 (lr:0.0001)
138740: accuracy:0.26 loss: 242.529 (lr:0.0001)
138760: accuracy:0.32 loss: 251.002 (lr:0.0001)
138780: accuracy:0.34 loss: 242.616 (lr:0.0001)
138800: accuracy:0.25 loss: 234.453 (lr:0.0001)
138820: accuracy:0.42 loss: 204.679 (lr:0.0001)
138840: accuracy:0.31 loss: 207.843 (lr:0.0001)
138860: accuracy:0.25 loss: 232.899 (lr:0.0001)
138880: accuracy:0.28 loss: 239.483 (lr:0.0001)
138900: accuracy:0.26 loss: 222.226 (lr:0.0001)
138920: accuracy:0.3 loss: 236.553 (lr:0.0001)
138940: accuracy:0.29 loss: 219.652 (lr:0.0001)
138960: accuracy:0.27 loss: 229.701 (lr:0.0001)
138980: accuracy:0.32 loss: 205.464 (lr:0.0001)
139000: accuracy:0.27 loss: 257.122 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
139000: ********* epoch 15 ********* test accuracy for all:0.239986 test loss: 258.466
139000: ********* epoch 15 ********* test accuracy for mode 0:0.0595 test loss: 410.541
139000: ********* epoch 15 ********* test accuracy for mode 1:0.0315 test loss: 436.13
139000: ********* epoch 15 ********* test accuracy for mode 2:0.07 test loss: 276.781
139000: ********* epoch 15 ********* test accuracy for mode 24:0.272 test loss: 251.517
139000: ********* epoch 15 ********* test accuracy for mode 25:0.329 test loss: 232.909
139000: ********* epoch 15 ********* test accuracy for mode 26:0.3185 test loss: 177.772
139000: ********* epoch 15 ********* test accuracy for mode 27:0.2885 test loss: 254.617
139000: ********* epoch 15 ********* test accuracy for mode 28:0.2875 test loss: 244.812
139000: ********* epoch 15 ********* test accuracy for mode 29:0.267 test loss: 254.244
139000: ********* epoch 15 ********* test accuracy for mode 30:0.2125 test loss: 248.896
139000: ********* epoch 15 ********* test accuracy for mode 31:0.218 test loss: 248.437
139000: ********* epoch 15 ********* test accuracy for mode 32:0.2295 test loss: 240.714
139000: ********* epoch 15 ********* test accuracy for mode 33:0.2155 test loss: 249.462
139000: ********* epoch 15 ********* test accuracy for mode 34:0.0375 test loss: 257.771
139000: ********* epoch 15 ********* test accuracy for mode 35:0.1445 test loss: 430.954
139000: ********* epoch 15 ********* test accuracy for mode 36:0.386 test loss: 415.449
139020: accuracy:0.35 loss: 205.563 (lr:0.0001)
139040: accuracy:0.29 loss: 248.482 (lr:0.0001)
139060: accuracy:0.25 loss: 236.671 (lr:0.0001)
139080: accuracy:0.33 loss: 233.509 (lr:0.0001)
139100: accuracy:0.31 loss: 216.929 (lr:0.0001)
139120: accuracy:0.31 loss: 224.313 (lr:0.0001)
139140: accuracy:0.26 loss: 232.016 (lr:0.0001)
139160: accuracy:0.34 loss: 215.566 (lr:0.0001)
139180: accuracy:0.29 loss: 220.254 (lr:0.0001)
139200: accuracy:0.3 loss: 227.047 (lr:0.0001)
139220: accuracy:0.36 loss: 209.074 (lr:0.0001)
139240: accuracy:0.26 loss: 216.794 (lr:0.0001)
139260: accuracy:0.22 loss: 236.536 (lr:0.0001)
139280: accuracy:0.32 loss: 209.458 (lr:0.0001)
139300: accuracy:0.38 loss: 208.243 (lr:0.0001)
139320: accuracy:0.27 loss: 234.061 (lr:0.0001)
139340: accuracy:0.25 loss: 216.14 (lr:0.0001)
139360: accuracy:0.37 loss: 223.526 (lr:0.0001)
139380: accuracy:0.29 loss: 230.764 (lr:0.0001)
139400: accuracy:0.3 loss: 230.54 (lr:0.0001)
139420: accuracy:0.31 loss: 234.245 (lr:0.0001)
139440: accuracy:0.21 loss: 233.848 (lr:0.0001)
139460: accuracy:0.25 loss: 222.65 (lr:0.0001)
139480: accuracy:0.22 loss: 233.116 (lr:0.0001)
139500: accuracy:0.32 loss: 219.938 (lr:0.0001)
139520: accuracy:0.32 loss: 235.013 (lr:0.0001)
139540: accuracy:0.32 loss: 224.667 (lr:0.0001)
139560: accuracy:0.24 loss: 233.113 (lr:0.0001)
139580: accuracy:0.3 loss: 221.154 (lr:0.0001)
139600: accuracy:0.19 loss: 251.342 (lr:0.0001)
139620: accuracy:0.34 loss: 222.481 (lr:0.0001)
139640: accuracy:0.32 loss: 232.674 (lr:0.0001)
139660: accuracy:0.29 loss: 224.825 (lr:0.0001)
139680: accuracy:0.21 loss: 230.433 (lr:0.0001)
139700: accuracy:0.27 loss: 240.393 (lr:0.0001)
139720: accuracy:0.29 loss: 220.27 (lr:0.0001)
139740: accuracy:0.26 loss: 241.224 (lr:0.0001)
139760: accuracy:0.29 loss: 221.497 (lr:0.0001)
139780: accuracy:0.26 loss: 225.789 (lr:0.0001)
139800: accuracy:0.18 loss: 248.133 (lr:0.0001)
139820: accuracy:0.31 loss: 233.386 (lr:0.0001)
139840: accuracy:0.31 loss: 221.042 (lr:0.0001)
139860: accuracy:0.33 loss: 244.021 (lr:0.0001)
139880: accuracy:0.33 loss: 231.346 (lr:0.0001)
139900: accuracy:0.25 loss: 256.583 (lr:0.0001)
139920: accuracy:0.26 loss: 233.683 (lr:0.0001)
139940: accuracy:0.26 loss: 222.877 (lr:0.0001)
139960: accuracy:0.27 loss: 239.77 (lr:0.0001)
139980: accuracy:0.23 loss: 241.345 (lr:0.0001)
140000: accuracy:0.28 loss: 240.528 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
140000: ********* epoch 15 ********* test accuracy for all:0.232351 test loss: 262.258
140000: ********* epoch 15 ********* test accuracy for mode 0:0.0535 test loss: 418.098
140000: ********* epoch 15 ********* test accuracy for mode 1:0.025 test loss: 451.926
140000: ********* epoch 15 ********* test accuracy for mode 2:0.08 test loss: 276.099
140000: ********* epoch 15 ********* test accuracy for mode 24:0.2405 test loss: 264.359
140000: ********* epoch 15 ********* test accuracy for mode 25:0.346 test loss: 241.067
140000: ********* epoch 15 ********* test accuracy for mode 26:0.238 test loss: 185.668
140000: ********* epoch 15 ********* test accuracy for mode 27:0.2995 test loss: 259.115
140000: ********* epoch 15 ********* test accuracy for mode 28:0.284 test loss: 253.786
140000: ********* epoch 15 ********* test accuracy for mode 29:0.264 test loss: 257.958
140000: ********* epoch 15 ********* test accuracy for mode 30:0.2075 test loss: 247.209
140000: ********* epoch 15 ********* test accuracy for mode 31:0.23 test loss: 242.424
140000: ********* epoch 15 ********* test accuracy for mode 32:0.2375 test loss: 235.047
140000: ********* epoch 15 ********* test accuracy for mode 33:0.2265 test loss: 243.953
140000: ********* epoch 15 ********* test accuracy for mode 34:0.048 test loss: 256.82
140000: ********* epoch 15 ********* test accuracy for mode 35:0.098 test loss: 467.101
140000: ********* epoch 15 ********* test accuracy for mode 36:0.1875 test loss: 465.925
140020: accuracy:0.27 loss: 239.432 (lr:0.0001)
140040: accuracy:0.36 loss: 237.402 (lr:0.0001)
140060: accuracy:0.28 loss: 241.543 (lr:0.0001)
140080: accuracy:0.25 loss: 237.459 (lr:0.0001)
140100: accuracy:0.31 loss: 227.714 (lr:0.0001)
140120: accuracy:0.33 loss: 228.066 (lr:0.0001)
140140: accuracy:0.25 loss: 227.601 (lr:0.0001)
140160: accuracy:0.2 loss: 249.966 (lr:0.0001)
140180: accuracy:0.29 loss: 237.239 (lr:0.0001)
140200: accuracy:0.33 loss: 216.575 (lr:0.0001)
140220: accuracy:0.3 loss: 227.009 (lr:0.0001)
140240: accuracy:0.33 loss: 218.926 (lr:0.0001)
140260: accuracy:0.21 loss: 249.797 (lr:0.0001)
140280: accuracy:0.22 loss: 232.305 (lr:0.0001)
140300: accuracy:0.29 loss: 226.237 (lr:0.0001)
140320: accuracy:0.27 loss: 245.32 (lr:0.0001)
140340: accuracy:0.32 loss: 233.206 (lr:0.0001)
140360: accuracy:0.3 loss: 226.068 (lr:0.0001)
140380: accuracy:0.39 loss: 203.689 (lr:0.0001)
140400: accuracy:0.29 loss: 212.139 (lr:0.0001)
140420: accuracy:0.24 loss: 220.005 (lr:0.0001)
140440: accuracy:0.35 loss: 216.815 (lr:0.0001)
140460: accuracy:0.36 loss: 213.015 (lr:0.0001)
140480: accuracy:0.22 loss: 238.974 (lr:0.0001)
140500: accuracy:0.31 loss: 232.99 (lr:0.0001)
140520: accuracy:0.27 loss: 226.555 (lr:0.0001)
140540: accuracy:0.38 loss: 239.765 (lr:0.0001)
140560: accuracy:0.23 loss: 227.8 (lr:0.0001)
140580: accuracy:0.32 loss: 233.711 (lr:0.0001)
140600: accuracy:0.26 loss: 232.227 (lr:0.0001)
140620: accuracy:0.28 loss: 242.065 (lr:0.0001)
140640: accuracy:0.31 loss: 227.473 (lr:0.0001)
140660: accuracy:0.29 loss: 239.729 (lr:0.0001)
140680: accuracy:0.3 loss: 226.659 (lr:0.0001)
140700: accuracy:0.3 loss: 230.329 (lr:0.0001)
140720: accuracy:0.28 loss: 229.014 (lr:0.0001)
140740: accuracy:0.25 loss: 246.182 (lr:0.0001)
140760: accuracy:0.28 loss: 241.743 (lr:0.0001)
140780: accuracy:0.36 loss: 209.023 (lr:0.0001)
140800: accuracy:0.26 loss: 243.873 (lr:0.0001)
140820: accuracy:0.2 loss: 233.778 (lr:0.0001)
140840: accuracy:0.24 loss: 222.058 (lr:0.0001)
140860: accuracy:0.21 loss: 241.418 (lr:0.0001)
140880: accuracy:0.3 loss: 216.123 (lr:0.0001)
140900: accuracy:0.3 loss: 232.617 (lr:0.0001)
140920: accuracy:0.27 loss: 258.747 (lr:0.0001)
140940: accuracy:0.22 loss: 242.863 (lr:0.0001)
140960: accuracy:0.28 loss: 227.522 (lr:0.0001)
140980: accuracy:0.27 loss: 252.417 (lr:0.0001)
141000: accuracy:0.29 loss: 246.382 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
141000: ********* epoch 15 ********* test accuracy for all:0.240149 test loss: 259.409
141000: ********* epoch 15 ********* test accuracy for mode 0:0.0505 test loss: 418.086
141000: ********* epoch 15 ********* test accuracy for mode 1:0.014 test loss: 448.164
141000: ********* epoch 15 ********* test accuracy for mode 2:0.079 test loss: 273.419
141000: ********* epoch 15 ********* test accuracy for mode 24:0.2525 test loss: 263.903
141000: ********* epoch 15 ********* test accuracy for mode 25:0.305 test loss: 244.693
141000: ********* epoch 15 ********* test accuracy for mode 26:0.342 test loss: 175.63
141000: ********* epoch 15 ********* test accuracy for mode 27:0.298 test loss: 248.844
141000: ********* epoch 15 ********* test accuracy for mode 28:0.3165 test loss: 235.319
141000: ********* epoch 15 ********* test accuracy for mode 29:0.304 test loss: 239.842
141000: ********* epoch 15 ********* test accuracy for mode 30:0.2035 test loss: 238.504
141000: ********* epoch 15 ********* test accuracy for mode 31:0.226 test loss: 238.628
141000: ********* epoch 15 ********* test accuracy for mode 32:0.261 test loss: 231.705
141000: ********* epoch 15 ********* test accuracy for mode 33:0.1775 test loss: 246.228
141000: ********* epoch 15 ********* test accuracy for mode 34:0.0415 test loss: 256.634
141000: ********* epoch 15 ********* test accuracy for mode 35:0.1845 test loss: 428.815
141000: ********* epoch 15 ********* test accuracy for mode 36:0.4155 test loss: 418.421
141020: accuracy:0.3 loss: 223.313 (lr:0.0001)
141040: accuracy:0.28 loss: 241.158 (lr:0.0001)
141060: accuracy:0.35 loss: 222.796 (lr:0.0001)
141080: accuracy:0.38 loss: 217.209 (lr:0.0001)
141100: accuracy:0.28 loss: 222.519 (lr:0.0001)
141120: accuracy:0.22 loss: 246.922 (lr:0.0001)
141140: accuracy:0.29 loss: 236.89 (lr:0.0001)
141160: accuracy:0.26 loss: 224.127 (lr:0.0001)
141180: accuracy:0.31 loss: 217.304 (lr:0.0001)
141200: accuracy:0.31 loss: 215.229 (lr:0.0001)
141220: accuracy:0.28 loss: 227.84 (lr:0.0001)
141240: accuracy:0.32 loss: 230.325 (lr:0.0001)
141260: accuracy:0.32 loss: 209.087 (lr:0.0001)
141280: accuracy:0.29 loss: 231.173 (lr:0.0001)
141300: accuracy:0.24 loss: 259.312 (lr:0.0001)
141320: accuracy:0.28 loss: 228.876 (lr:0.0001)
141340: accuracy:0.2 loss: 246.752 (lr:0.0001)
141360: accuracy:0.29 loss: 236.107 (lr:0.0001)
141380: accuracy:0.26 loss: 234.28 (lr:0.0001)
141400: accuracy:0.22 loss: 248.127 (lr:0.0001)
141420: accuracy:0.18 loss: 238.51 (lr:0.0001)
141440: accuracy:0.35 loss: 226.42 (lr:0.0001)
141460: accuracy:0.26 loss: 227.269 (lr:0.0001)
141480: accuracy:0.26 loss: 231.176 (lr:0.0001)
141500: accuracy:0.34 loss: 233.528 (lr:0.0001)
141520: accuracy:0.26 loss: 229.272 (lr:0.0001)
141540: accuracy:0.27 loss: 240.214 (lr:0.0001)
141560: accuracy:0.33 loss: 209.034 (lr:0.0001)
141580: accuracy:0.29 loss: 230.039 (lr:0.0001)
141600: accuracy:0.31 loss: 220.939 (lr:0.0001)
141620: accuracy:0.22 loss: 237.124 (lr:0.0001)
141640: accuracy:0.28 loss: 241.067 (lr:0.0001)
141660: accuracy:0.27 loss: 228.456 (lr:0.0001)
141680: accuracy:0.3 loss: 234.151 (lr:0.0001)
141700: accuracy:0.28 loss: 222.32 (lr:0.0001)
141720: accuracy:0.41 loss: 211.68 (lr:0.0001)
141740: accuracy:0.21 loss: 219.225 (lr:0.0001)
141760: accuracy:0.19 loss: 235.786 (lr:0.0001)
141780: accuracy:0.25 loss: 239.091 (lr:0.0001)
141800: accuracy:0.41 loss: 207.237 (lr:0.0001)
141820: accuracy:0.33 loss: 232.325 (lr:0.0001)
141840: accuracy:0.24 loss: 249.732 (lr:0.0001)
141860: accuracy:0.38 loss: 220.596 (lr:0.0001)
141880: accuracy:0.27 loss: 232.701 (lr:0.0001)
141900: accuracy:0.34 loss: 228.163 (lr:0.0001)
141920: accuracy:0.31 loss: 231.872 (lr:0.0001)
141940: accuracy:0.29 loss: 220.173 (lr:0.0001)
141960: accuracy:0.27 loss: 219.631 (lr:0.0001)
141980: accuracy:0.2 loss: 251.159 (lr:0.0001)
142000: accuracy:0.29 loss: 235.569 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
142000: ********* epoch 15 ********* test accuracy for all:0.240378 test loss: 256.573
142000: ********* epoch 15 ********* test accuracy for mode 0:0.059 test loss: 400.193
142000: ********* epoch 15 ********* test accuracy for mode 1:0.04 test loss: 413.319
142000: ********* epoch 15 ********* test accuracy for mode 2:0.073 test loss: 280.682
142000: ********* epoch 15 ********* test accuracy for mode 24:0.254 test loss: 256.645
142000: ********* epoch 15 ********* test accuracy for mode 25:0.33 test loss: 232.277
142000: ********* epoch 15 ********* test accuracy for mode 26:0.4265 test loss: 166.431
142000: ********* epoch 15 ********* test accuracy for mode 27:0.267 test loss: 256.273
142000: ********* epoch 15 ********* test accuracy for mode 28:0.2695 test loss: 247.375
142000: ********* epoch 15 ********* test accuracy for mode 29:0.2885 test loss: 257.655
142000: ********* epoch 15 ********* test accuracy for mode 30:0.195 test loss: 257.381
142000: ********* epoch 15 ********* test accuracy for mode 31:0.17 test loss: 262.745
142000: ********* epoch 15 ********* test accuracy for mode 32:0.2255 test loss: 253.245
142000: ********* epoch 15 ********* test accuracy for mode 33:0.1785 test loss: 260.96
142000: ********* epoch 15 ********* test accuracy for mode 34:0.068 test loss: 263.639
142000: ********* epoch 15 ********* test accuracy for mode 35:0.2005 test loss: 401.227
142000: ********* epoch 15 ********* test accuracy for mode 36:0.4545 test loss: 395.427
142020: accuracy:0.22 loss: 235.569 (lr:0.0001)
142040: accuracy:0.2 loss: 243.024 (lr:0.0001)
142060: accuracy:0.27 loss: 232.219 (lr:0.0001)
142080: accuracy:0.3 loss: 233.141 (lr:0.0001)
142100: accuracy:0.27 loss: 223.422 (lr:0.0001)
142120: accuracy:0.29 loss: 220.824 (lr:0.0001)
142140: accuracy:0.28 loss: 232.117 (lr:0.0001)
142160: accuracy:0.2 loss: 252.655 (lr:0.0001)
142180: accuracy:0.28 loss: 254.484 (lr:0.0001)
142200: accuracy:0.36 loss: 223.962 (lr:0.0001)
142220: accuracy:0.24 loss: 234.03 (lr:0.0001)
142240: accuracy:0.26 loss: 237.552 (lr:0.0001)
142260: accuracy:0.31 loss: 227.827 (lr:0.0001)
142280: accuracy:0.26 loss: 244.587 (lr:0.0001)
142300: accuracy:0.3 loss: 222.269 (lr:0.0001)
142320: accuracy:0.31 loss: 234.947 (lr:0.0001)
142340: accuracy:0.35 loss: 221.173 (lr:0.0001)
142360: accuracy:0.3 loss: 231.01 (lr:0.0001)
142380: accuracy:0.24 loss: 227.278 (lr:0.0001)
142400: accuracy:0.31 loss: 216.093 (lr:0.0001)
142420: accuracy:0.24 loss: 240.744 (lr:0.0001)
142440: accuracy:0.3 loss: 224.283 (lr:0.0001)
142460: accuracy:0.31 loss: 225.69 (lr:0.0001)
142480: accuracy:0.28 loss: 228.359 (lr:0.0001)
142500: accuracy:0.25 loss: 239.906 (lr:0.0001)
142520: accuracy:0.3 loss: 230.88 (lr:0.0001)
142540: accuracy:0.28 loss: 228.299 (lr:0.0001)
142560: accuracy:0.31 loss: 218.916 (lr:0.0001)
142580: accuracy:0.34 loss: 229.568 (lr:0.0001)
142600: accuracy:0.28 loss: 234.451 (lr:0.0001)
142620: accuracy:0.26 loss: 240.756 (lr:0.0001)
142640: accuracy:0.25 loss: 234.444 (lr:0.0001)
142660: accuracy:0.29 loss: 230.659 (lr:0.0001)
142680: accuracy:0.36 loss: 209.02 (lr:0.0001)
142700: accuracy:0.27 loss: 235.222 (lr:0.0001)
142720: accuracy:0.29 loss: 221.481 (lr:0.0001)
142740: accuracy:0.29 loss: 244.613 (lr:0.0001)
142760: accuracy:0.34 loss: 226.747 (lr:0.0001)
142780: accuracy:0.26 loss: 228.898 (lr:0.0001)
142800: accuracy:0.27 loss: 232.331 (lr:0.0001)
142820: accuracy:0.31 loss: 229.613 (lr:0.0001)
142840: accuracy:0.22 loss: 256.533 (lr:0.0001)
142860: accuracy:0.28 loss: 231.735 (lr:0.0001)
142880: accuracy:0.24 loss: 239.002 (lr:0.0001)
142900: accuracy:0.33 loss: 236.345 (lr:0.0001)
142920: accuracy:0.24 loss: 237.801 (lr:0.0001)
142940: accuracy:0.3 loss: 229.699 (lr:0.0001)
142960: accuracy:0.25 loss: 236.259 (lr:0.0001)
142980: accuracy:0.2 loss: 263.84 (lr:0.0001)
143000: accuracy:0.27 loss: 223.306 (lr:0.0001)
Model saved in file: /Users/Pharrell_WANG/PycharmProjects/proj_vcmd/checkpoint/md_6_BN_conv_dropout_model.ckpt
143000: ********* epoch 15 ********* test accuracy for all:0.226486 test loss: 266.037
143000: ********* epoch 15 ********* test accuracy for mode 0:0.0515 test loss: 422.141
143000: ********* epoch 15 ********* test accuracy for mode 1:0.024 test loss: 460.002
143000: ********* epoch 15 ********* test accuracy for mode 2:0.0985 test loss: 270.05
143000: ********* epoch 15 ********* test accuracy for mode 24:0.2345 test loss: 271.111
143000: ********* epoch 15 ********* test accuracy for mode 25:0.3915 test loss: 241.612
143000: ********* epoch 15 ********* test accuracy for mode 26:0.237 test loss: 190.146
143000: ********* epoch 15 ********* test accuracy for mode 27:0.282 test loss: 266.94
143000: ********* epoch 15 ********* test accuracy for mode 28:0.291 test loss: 254.488
143000: ********* epoch 15 ********* test accuracy for mode 29:0.285 test loss: 257.289
143000: ********* epoch 15 ********* test accuracy for mode 30:0.2005 test loss: 245.663
143000: ********* epoch 15 ********* test accuracy for mode 31:0.234 test loss: 243.283
143000: ********* epoch 15 ********* test accuracy for mode 32:0.1965 test loss: 235.958
143000: ********* epoch 15 ********* test accuracy for mode 33:0.2495 test loss: 242.01
143000: ********* epoch 15 ********* test accuracy for mode 34:0.0575 test loss: 252.117
143000: ********* epoch 15 ********* test accuracy for mode 35:0.0885 test loss: 503.105
143000: ********* epoch 15 ********* test accuracy for mode 36:0.0385 test loss: 535.283
143020: accuracy:0.33 loss: 221.018 (lr:0.0001)
143040: accuracy:0.37 loss: 224.971 (lr:0.0001)
143060: accuracy:0.36 loss: 231.933 (lr:0.0001)
143080: accuracy:0.27 loss: 249.628 (lr:0.0001)
143100: accuracy:0.36 loss: 211.981 (lr:0.0001)
143120: accuracy:0.24 loss: 225.759 (lr:0.0001)
143140: accuracy:0.31 loss: 228.775 (lr:0.0001)
143160: accuracy:0.32 loss: 224.206 (lr:0.0001)
143180: accuracy:0.18 loss: 245.945 (lr:0.0001)
143200: accuracy:0.33 loss: 221.43 (lr:0.0001)
143220: accuracy:0.21 loss: 240.243 (lr:0.0001)
143240: accuracy:0.34 loss: 210.897 (lr:0.0001)
143260: accuracy:0.23 loss: 229.799 (lr:0.0001)
143280: accuracy:0.31 loss: 249.017 (lr:0.0001)
143300: accuracy:0.3 loss: 233.945 (lr:0.0001)
143320: accuracy:0.28 loss: 232.101 (lr:0.0001)
143340: accuracy:0.34 loss: 208.093 (lr:0.0001)
143360: accuracy:0.19 loss: 243.82 (lr:0.0001)
143380: accuracy:0.26 loss: 224.654 (lr:0.0001)
143400: accuracy:0.29 loss: 224.751 (lr:0.0001)
143420: accuracy:0.26 loss: 230.756 (lr:0.0001)
143440: accuracy:0.31 loss: 216.188 (lr:0.0001)
143460: accuracy:0.31 loss: 216.624 (lr:0.0001)
143480: accuracy:0.34 loss: 213.928 (lr:0.0001)
143500: accuracy:0.26 loss: 241.902 (lr:0.0001)
143520: accuracy:0.23 loss: 220.403 (lr:0.0001)
143540: accuracy:0.34 loss: 218.282 (lr:0.0001)
143560: accuracy:0.32 loss: 230.213 (lr:0.0001)
143580: accuracy:0.25 loss: 226.859 (lr:0.0001)
143600: accuracy:0.33 loss: 224.937 (lr:0.0001)
143620: accuracy:0.27 loss: 228.341 (lr:0.0001)
143640: accuracy:0.29 loss: 206.736 (lr:0.0001)
143660: accuracy:0.25 loss: 218.132 (lr:0.0001)
143680: accuracy:0.25 loss: 244.447 (lr:0.0001)
143700: accuracy:0.26 loss: 248.506 (lr:0.0001)
143720: accuracy:0.27 loss: 237.193 (lr:0.0001)
143740: accuracy:0.27 loss: 227.331 (lr:0.0001)
143760: accuracy:0.32 loss: 210.489 (lr:0.0001)
143780: accuracy:0.25 loss: 235.048 (lr:0.0001)
143800: accuracy:0.24 loss: 231.221 (lr:0.0001)
^Z
[2]+  Stopped                 python3 md_6.0_BN_conv_relu_dropout.py
Pharrell-WANGs-MacBook-Pro:proj_vcmd Pharrell_WANG$ 
