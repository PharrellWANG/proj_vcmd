# encoding: UTF-8# Copyright 2016 Google.com## Licensed under the Apache License, Version 2.0 (the "License");# you may not use this file except in compliance with the License.# You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an "AS IS" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.import tensorflow as tffrom a_vcmd_read_data import read_data_setstf.set_random_seed(0)# neural network with 1 layer of 10 softmax neurons## · · · · · · · · · ·       (input data, flattened pixels)       X [batch, 784]        # 784 = 28 * 28# \x/x\x/x\x/x\x/x\x/    -- fully connected layer (softmax)      W [784, 10]     b[10]#   · · · · · · · ·                                              Y [batch, 10]# The model is:## Y = softmax( X * W + b)#              X: matrix for 100 grayscale images of 28x28 pixels, flattened (there are 100 images in a mini-batch)#              W: weight matrix with 784 lines and 10 columns#              b: bias vector with 10 dimensions#              +: add with broadcasting: adds the vector to each line of the matrix (numpy)#              softmax(matrix) applies softmax on each line#              softmax(line) applies an exp to each value then divides by the norm of the resulting line#              Y: output matrix with 100 lines and 10 columns# Download images and labels into mnist.test (10K images+labels) and mnist.train (60K images+labels)mode_decision = read_data_sets(reshape=False, validation_size=0)print("============")print(mode_decision.train.images[3:5])